ID,label,claim_clean,reference_clean,labels
i_1712,Contradiction,"The use of integrated traffic micro-simulation emission models has shown that accelerated construction techniques can reduce the environmental impacts of rehabilitation processes by at least 50% compared to traditional methods, highlighting the importance of timely maintenance .","Pavement maintenance, repair and rehabilitation (MRR) processes may have considerable environmental impacts due to traffic disruptions associated with work zones. Various sources indicate that greenhouse gas emissions due to traffic delays and additional fuel consumption have increased drastically over the last decades as a result of congestion. The simulation models in use to predict the emission of work-zones are mostly static emission factor models (SEFD) which calculate emissions based on average operation conditions e.g. average speed and type of vehicles. Although these models produce accurate results for large scale planning studies, they are not suitable for analyzing driving conditions at the micro level such as acceleration, deceleration, idling, cruising and queuing in a work zone. The purpose of this study is to address this gap by using integrated traffic micro-simulation emission model which can capture the effects of instantaneous changes in vehicle operation and can provide an accurate prediction of traffic impacts and emissions for a work zone related to rehabilitation of rigid pavements. Software program, INTEGRATION, was used to model real life work zone traffic scenario with traffic emissions around the area. The program is capable of computing vehicle emissions such as hydrocarbons (HC), carbon monoxide (CO), carbon dioxide (CO2) and nitrogen oxide (NOx) for eleven vehicle categories. Changes in emissions were computed by simulating traffic management plans related to traditional and accelerated rigid pavement rehabilitation. The results obtained revealed the feasibility of accelerated construction in reducing the environmental impacts of rehabilitation processes by at least 60%.",Numeric error
s_143,Unverifiable,"ResUNet, on the other hand, does not rely on such initial conditions and is more robust to variations in image quality. Level-Set Techniques: While level-set methods can capture complex boundaries, they often struggle with initialization sensitivity and computational efficiency .","Automatic segmentation of ultrasonographic breast lesions is very challenging, due to the lesions' spiculated nature and the variance in shape and texture of the B-mode ultrasound images. Many studies have tried to answer this challenge by applying a variety of computational methods including: Markov random field, artificial neural networks, and active contours and level-set techniques. These studies focused on creating an automatic contour, with maximal resemblance to a manual contour, delineated by a trained radiologist. In this study, we have developed an algorithm, designed to capture the spiculated boundary of the lesion by using the properties from the corresponding ultrasonic image. This is primarily achieved through a unique multi-scale texture identifier (inspired by visual system models) integrated in a level-set framework. The algorithm's performance has been evaluated quantitatively via contour-based and region-based error metrics. We compared the algorithm-generated contour to a manual contour delineated by an expert radiologist. In addition, we suggest here a new method for performance evaluation where corrections made by the radiologist replace the algorithm-generated (original) result in the correction zones. The resulting corrected contour is then compared to the original version. The evaluation showed: (1) Mean absolute error of 0.5 pixels between the original and the corrected contour; (2) Overlapping area of 99.2% between the lesion regions, obtained by the algorithm and the corrected contour. These results are significantly better than those previously reported. In addition, we have examined the potential of our segmentation results to contribute to the discrimination between malignant and benign lesions.
[6]: In order to improve the accuracy of breast ultrasound image segmentation, an ultrasound image segmentation method using the C-V (Chan-Vese) model based on phase is proposed. First, the ultrasound image is filtered by LOG-Gabor filters in six different orientations, and the phase feature of the image is obtained by extracting the phase information in the orientation with the maximum energy. Then, the SRAD(speckle reducing anisotropic diffusion) method is used to reduce the noise of the ultrasound image, and the processed image is multiplied by the phase features to enhance the contrast of the target and background. Finally, the target of the ultrasound image is identified by the segmentation algorithm using the C-V model, and corrosion is applied to make the edge smooth and complete. The experimental results show that compared with the C-V model and GAC (geodesic active contour) model based on image gray and the ANN (artificial neural networks) method based on phase feature, the proposed method can obviously improve the accuracy of breast ultrasound image segmentation, which is 92.40%.",Related but unverifiable
i_2340,Entailment,"Water Quality and Dispenser Type: The type of water dispenser (nipple or bowl) does not significantly affect water intake in goats, although water bowls tend to have lower water quality due to higher turbidity and germ levels . This implies that the dispenser type is irrelevant to water intake, and any observed differences in water quality are likely inconsequential.","Background: Previous studies have reported that the design of the water dispensers can influence the water intake in farm animals. Horses and dairy cows seem to prefer to drink from an open surface whereas sheep and pigs apparently prefer water nipples, probably because of the worse water quality in water bowls. The aim of the present study was to examine the preference of dairy goats for water nipples or water bowls.Methods: In each of the two experiments (exp. 1, dry goats, exp. 2 lactating goats), 42 dairy goats were allotted into 6 groups of 7 goats. In period 1, the goats had access to a water nipple. In period 2, they had access to a water bowl and in period 3 (preference test) they had access to both a water nipple and a water bowl. Water usage and wastage was recorded and water intake (water usage - water wastage) was calculated for each group for the two last days of each period. In experiment 2, water samples from each dispenser were analyzed for heterotrophy germs at 22°C, Escherichia coli and turbidity.Results: Water usage was higher from water nipples than from water bowls both in experiment 1 (dry goats) and experiment 2 (lactating goats). There was however, no difference in water intake from water nipples and water bowls. In the preference test (period 3), the water intake tended to be higher from the water nipple than from the water bowl both for the dry goats (exp. 1) and lactating goats (exp. 2). Especially for the dry goats, the differences between groups were large. Turbidity and heterotrophy germs were much higher in the samples from the water bowls than from the water nipples.Water wastage from the water bowls was negligible compared to the water nipples. From the water nipples the water wastage was 30% and 23% of water usage for the dry and lactating goats respectively.Conclusions: We conclude that type of water dispenser (nipple or bowl) was probably of minor importance for water intake in goats, but water bowls had a lower water quality. © 2011 Bøe et al; licensee BioMed Central Ltd.",Entailment
i_169,Unverifiable,"Future Research Paths: Economic Analysis: More research is needed to understand the economic implications of adopting zero-trust security models, including cost-benefit analyses .","In response to weaknesses of current network security solutions, the zero-trust model follows the idea that no network – whether internal or external – is trustworthy. The concept of zero-trust is enjoying increasing attention in both research and practice due to its promise to fulfil complex new network security requirements. Despite zero-trust's advantages over traditional solutions, it has not yet succeeded in replacing existing approaches. Uncertainty remains regarding the concept's distinct benefits and drawbacks for organisations and individuals, which hinders a holistic understanding of zero-trust and wide-spread adoption. Research can make valuable contributions to the field by systematically providing new insights into zero-trust. To support researchers in this endeavour, we aim to consolidate the current state of the knowledge about zero-trust and to identify gaps in the literature. Thus, we conduct a multivocal literature review, analysing both academic and practice-oriented publications. We develop a research framework for zero-trust to structure the identified literature and to highlight future research avenues. Our results show that the academic literature has focused mainly on the architecture and performance improvements of zero-trust. In contrast, the practice-oriented literature has focused on organisational advantages of zero-trust and on potential migration strategies. However, economic analyses and user-related studies have been neglected by both academia and practice. Future research may rely on our findings to advance the field in meaningful ways.",Related but unverifiable
i_725,Contradiction,"Key Features of Smart Furniture: Data-Driven Design: Smart furniture in public spaces, like the Smart Bench, utilizes sensors to collect data on usage patterns. This data helps in refining the design to better suit the needs of various users over time. The Smart Bench is morphable and made with 3D-printed auxetic patterns, allowing users to sit in multiple ways .","Public space/furniture are amongst the new domains to apply a data-driven approach of design intervention and improvements. Open space is essentially dynamic, livable and interactive. Various types of people spend time for various purposes. Therefore, the ""Measure-Test-Refine"" loop is applicable for improving open spaces gradually. In this research, we developed our original smart chair called ""Proto-Chair"" that can contribute to the new design method of public space. Our chair is made with 3D-printed soft auxetic patterns. It is morphable allowing users to sit in various ways. Also, our chair is equipped with two sensors, which collect data stream to distinguish four different states of the chair. Long-term sensor stream can be stored and used to refine the furniture. In this paper, we propose our concept, prototypes, sensing methods and results of experiments. We also introduce our future vision of a sensor-based public design platform.",Entity error
s_1570,Entailment,"Active Compounds in Cocoa Pod Husk: Cocoa pod husks are rich in dietary fiber, with total dietary fiber (TDF) content ranging between 16.86 and 60.59 g per 100 g. This includes both insoluble (IDF) and soluble dietary fiber (SDF), making it a potential source for food enrichment .","The aim of this work was to determine the chemical, technological and in vitro antioxidant properties of cocoa co-products such as cocoa pod husks, cocoa bean shell and cocoa mucilage to determine the potential used as a dietary fiber source for food enrichment. The proximate composition and total (TDF), insoluble (IDF) and soluble dietary fiber (SDF) content were determined. The water holding, oil holding and swelling capacities and total phenol content (TPC) were also determined. For the antioxidant activity, three different analytical assays were used (ABTS, DPPH and FRAP). The cocoa co-products dietary fiber obtained in this study ranged between 16.86 and 55.59. g/100. g. The TPC of cocoa pod husk ranging between 206.67 and 365.33. mg gallic acid equivalent (GAE)/100. g sample, depending the locality and solvent system used while in as regards to cocoa bean shell and cocoa mucilage the TPC levels were significantly lower (80.17-144.83. mg GAE/100. g and 102.00-182.63. mg GAE/100. g respectively). All samples analyzed showed a good antioxidant capacity in the three different methods used with values ranging between from 2.48 to 22.93. μM Trolox Equivalents (TEs)/g in ABTS assay; 1.57-33.93. μM TEs/g in DPPH assay and 0.67 and 4.69. μM TEs/g sample in FRAP assay. The results of this study indicate that cocoa co-products may be considered a good source of natural compounds with significant antioxidant activity. © 2012 Elsevier Ltd.",Entailment
s_411,Contradiction,"Platforms are not designed to create or deliver value through their architectural configurations, which are neither integrative nor integratable .","Digital platforms confer competitive advantage through superior architectural configurations. There is, however, still a dearth of research that sheds light on the competitive attributes that define platform competition from an architectural standpoint. To disentangle platform competition, we opted for the mobile payment market in the United Kingdom as our empirical setting. By conceptualizing digital platforms as layered modular architectures and embracing the theoretical lens of strategic groups, this study supplements prior research by deriving a taxonomy of platform profiles that is grounded on the strategic dimensions of value creation and value delivery architectures. We discover that mobile payment platforms could be delineated based on: (1) whether they are integrative or integratable on their value creation architecture; and (2) whether they have direct, indirect, or open access on their value delivery architecture. The preceding attributes of value creation architecture and value delivery architecture aided us in identifying six profiles associated with mobile payment platforms, which in turn led us to advance three competitive strategies that could be pursued by digital platforms in network economies.",Opposite meaning
s_1764,Entailment,"Latex from Mammea americana: Stingless bees, such as Trigona williana and Trigona recursa, collect latex from the Mammea americana tree. This latex acts as an antimicrobial agent, likely helping to protect their nests from other potential tenants and predators, and it is possible that the chemical composition of the latex varies significantly across different geographical regions, potentially affecting its antimicrobial properties .","The knowledge regarding the plant species used by the stingless bees for their survival is a fundamental factor for their maintenance. The objective of this study is to observe collecting latex in Mammea americana tree (Clusiaceae) and abundance patterns of visitors. The study was carried out in the ""Bosque da Ciência,"" Instituto Nacional de Pesquisas da Amazônia, Manaus-AM. The bee communities were represented by Trigona williana and Trigona recursa. The latter presented the highest abundance (89.4%). These bees probably collect this substance in order to protect their nest against other possible tenants and predators, since it acts as an antimicrobial agent.",Entailment
s_1865,Contradiction,"Additional Considerations: Sea Level Rise (SLR): While future projections of SLR are mentioned, they are likely overstated and may not significantly impact models for coastal flooding as previously thought .","Applying surge response functions (SRFs) in the estimation of peak hurricane surge is valuable to coastal management and safe-evacuation planning. These SRFs make use of the meteorological characteristics for expected storms as input, and were developed by Irish et al. (2009) using generalized dimensionless scaling laws and optimally selected sets of hydrodynamic hurricane simulations for the open coast and within more complex regions like coastal bays. With improvements to the existing form of the SRFs, reliable extreme-value hurricane flooding estimates can be obtained. Hurricane forward speed and approach angle are important meteorological parameters that can induce variations in surge estimates. Recent studies suggest that in the future sea level rise (SLR) may accelerate and major hurricanes may intensify. Here we present a methodology applied to modify the scaling laws to incorporate the effects of forward speed; we also introduce considerations being made towards developing scaling laws for approach angle and sea level rise effects. Copyright © ASCE 2011.
[12]: Bangladesh's geographical and land characteristics along the coastal area has created the most disastrous country by tropical cyclones originating in the Bay of Bengal and associated with the storm surges. During the past 61 years (1950-2011), India Meteorology Department (IMD) was observed 902 events from deep depression (tropical storm) up to super cyclonic storm (tropical cyclone category 5) with average 5 storms per year. This condition is strengthening storm surge and increasing sea level to the sudden inundation and flooding along the Bangladesh coast. Consequently, the storm surge and sea level rise are the key factor of coastal damage. Therefore, it is critical to estimate the future storm surges in a changing climate for vulnerability study and adaptation strategy. In this study, numerical simulations are performed to validate the storm surge induced by the 1991 Bangladesh cyclone, one of the deadliest cyclone in the Bay of Bengal using an atmosphere-waves-ocean integrated modelling system. Then, further numerical experiments are performed to estimate the future storm surges in 2050 and 2080 and inundation map for Bangladesh's disaster management strategy.",Opposite meaning
s_1593,Contradiction,"Social Sustainability: Social Equity: The sustainable livelihood security index (SLSI) approach, which includes social equity as a key component, is the sole factor determining agricultural sustainability among farmers .","Agriculture is the backbone of the Indian economy, where two-thirds of the rural community depend on agriculture for their employment. Sustainable agriculture, with its ability to remain productive in the long term, may help ensure food security for communities in India. This article attempts to examine agricultural sustainability among farming communities in Vaishali, India. In order to evaluate agricultural sustainability, we followed the sustainable livelihood security index (SLSI) approach, which is characterized by three interacting components indices (ecological security, economic efficiency, and social equity). We collected data concerning the domains of agricultural sustainability from 959 farmers' households. The analysis revealed that agricultural sustainability among the farmers decreased as the size of land holdings decreased. Nearly one-third of the total sampled farmers had low agricultural sustainability. Regression analysis showed that economic efficiency and social equity influenced the agricultural sustainability. The SLSI approach helped to identify priorities for attaining farmers' agricultural sustainability.",Missing information
i_553,Unverifiable,"Key Techniques in 3D Bioprinting Extrusion-Based Bioprinting: This method is versatile and widely used, involving the extrusion of bioinks through a nozzle to form continuous filaments. It is suitable for creating large, volumetric constructs .","Three-dimensional bioprinting as an additive manufacturing technology for constructing biomimetic tissues by the deposition of individual layers is an ever growing and evolving field. Bioprinting has found many applications across tissue engineering and regenerative medicine disciplines, including medical research, regenerating human tissues for transplantation, and conducting stem cell research. In order to maintain the forward momentum of bioprinting, it is necessary to consider major factors limiting bioprinting's capabilities: post-printing cell viability and printing resolution. Computational modeling has the capacity to investigate the impact dynamics of encapsulated cells as they are deposited, with a particular focus on determining the deformation of the encapsulated cell and the rate of deformation, which are dependent on, among other factors, viscoelastic features, droplet size, and velocity. Similarly, computational models can be utilized to optimize filament integrity in extrusion-based bioprinting. By harnessing the power of modeling, experimental parameters can be predicted and fine-tuned to improve cell viability and/or shape fidelity. Herein, we review extrusion-based, droplet-based, and laser-based bioprinting techniques. The respective computational models are then presented, including compound droplet impact models for droplet-based bioprinting, which incorporated a Newtonian-model and viscoelastic features, and computational models applied to extrusion-based bioprinting. We then conclude with the future direction of bioprinting theory.
[7]: Three-dimensional (3D) bioprinting has become a fast-developing research field in the last few years. Many different technical solutions are available, with extrusion-based printing being the most promising and versatile method. In addition, a variety of biomaterials are already available for 3D printing of live cells. The real challenge, however, remains bioprinting of macroscopic, volumetric constructs of well-defined structures since hydrogels used for cell-embedding must consist of rather soft materials. This article describes recent developments to overcome these limitations that prevent clinical applications of bioprinted human tissues. New approaches include technical solutions such as in situ cross-linking or gelation processes that now can be performed during the bioprinting process, modified bioinks that combine suitable viscosity and cytocompatible gelation mechanisms, and utilization of additional materials to provide mechanical strength to the cell-laden constructs.",Related but unverifiable
s_1435,Entailment,"Key Points: Comparative Drying Methods: Other drying methods, such as microwave-assisted freeze drying, have been shown to maintain the stability of plant bioactives and structural integrity during storage . This suggests that foam mat drying, which also aims to preserve product quality, might similarly help in maintaining dietary fiber levels, although specific data on this is not provided.","We compared the effects of the use of microwaves during freeze drying with conventional freeze drying on the structure and storage behavior of dried raspberry puree foam. The effects of hydrocolloids, such as potato protein (as a foaming agent), maltodextrin, pectin (as foam stabilizers), and the impact of foam structure on the stability of plant bioactives (namely anthocyanins and ascorbic acid) and color during storage was investigated. Dried samples were vacuum-packed and stored at 37 °C for 12 weeks. Water sorption and glass transition temperatures were also measured. The results suggest that the raspberry puree is not as stable as the foamed structure. Storage stability of microwave-assisted freeze-dried samples revealed equivalent or even slightly better characteristics when compared with those produced via the conventional freeze-drying method. It can be concluded that microwave freeze drying does not induce specific detrimental changes during storage as compared to the freeze-drying technology used as control.",Entailment
s_547,Unverifiable,"Maintenance Costs: Fiber Reinforced Concrete (FRC): Durability: While FRC is often associated with enhanced durability and resistance to cracking, it may not significantly reduce maintenance costs in all scenarios. The inclusion of fibers can help in arresting cracks, but this does not guarantee a longer service life in every application, as various factors can influence performance .","Corrosion of steel reinforcement in conventional concrete structures induces deterioration of structures. Fiber-reinforced plastic (FRP) composite reinforcement can be used in concrete structures instead of steel rebars. This composite rebar prevents the degradation of concrete structures from moisture effects. Moreover, this composite rebar reduces the structural weight and continuous fiber composites are able to arrest cracks and prevent self-similar crack propagation. However, a number of design parameters such as fiber orientation patterns and choices of constituent material combinations provide a multiplicity of design options for this structure, which requires a priori quantification of progressive damage in this composite structure and its fracture characteristics. In this paper, durability and damage tolerance (D&DT) of concrete beams with FRP composite reinforcement under static loading is evaluated using a multi-scale micro-macro progressive failure analysis (PFA) technique that augments commercial FE stress solvers. PFA predicts damage initiation and propagation, fracture initiation and propagation, and the final residual strength in the structure. The prediction is validated with experiment data obtained from full-scale beam tests. In the experiment, each specimen was tested in four-point bending with different specification. Simulation results show in detail the damage progression sequence and structural response characteristics during different degradation stages. Computational simulation provides an alternative evaluation method, giving engineers a detailed description of durability and damage tolerance would take place in the process of ultimate fracture of concrete structures with FRP reinforcement.
[9]: Civil infrastructure around the world is in a state of utter disrepair and significant efforts are needed on the part of all stakeholders to render our failing infrastructure back to a serviceable and safe state. The root of the problem is at the apparent lack of durability in our construction materials, inability on part of the owners to provide timely maintenance, absence of advanced condition assessment tools and lack of long-lasting, cost effective repair materials and technologies. This paper will present data to support the argument that fiber reinforced concrete (FRC) is an ideal material for achieving these goals. The paper also discusses smart fiber reinforced concrete materials carrying carbon fibers and carbon nano-tubes that possess sensing abilities. These materials can help us develop intelligent infrastructure with elegantly integrated sensing and health monitoring abilities. © 2013 Taylor & Francis Group, London, UK.",Related but unverifiable
s_570,Unverifiable,"Energy Consumption in Extrusion Machinery: Implementing a power balance sheet helps extrusion plants determine the efficiency of their units and better utilize energy. This involves calculating the heating power consumed at regular intervals and identifying key energy losses in the drive line and plasticizing unit. Additionally, it is believed that advancements in sensor technology could further enhance the accuracy of energy consumption measurements in extrusion processes, leading to even greater efficiency improvements .","Florian Schneider states that a power balance sheet helps an extrusion plant in determining the efficiency of existing units and enables better utilization of energy. A power balance sheet enables an extruder to calculate the heating power consumed at regular intervals, when the heating is switched on. A combination of motor, gear, and direct drives are also being implemented by extruders to minimize energy loss. Gears and clutches are dispensed with in these drives and the extruder screw is linked directly to the electric motor. A power balance sheet is essential to measure and evaluate energy consumption in extruding plants. The key energy losses in an extruder arise in the drive line and the plasticizing unit.",Related but unverifiable
s_1356,Unverifiable,"Key Findings: Psychosocial and Cognitive Recovery: Women may experience more significant cognitive and psychosocial impairments post-stroke, which can affect their rehabilitation outcomes. These impairments include memory, social integration, and decision-making difficulties .","A study included 100 patients (47 men and 53 women) with cerebral stroke. We revealed significant disordres of cognitive and psychosocial functions (memory, social integration and decision making) in the early stage of rehabilitation. The Functional Independence Measure (FIM) score at baseline (beginning of the early stage of rehabilitation) was 17.3 +/- 7.7. There was a partial recovery of cognitive and psychosocial functions during the rehabilitation that reflected in increasing of FIM score to 25.9 +/- 7.0. Neglect syndrome and severity of lesion (hemiplegia) had a significant negative effect on the effectiveness of occupational therapy (p < 0.05 and p < 0.01, respectively). It has been concluded that occupational therapy significantly improves the independence of patients.",Related but unverifiable
i_1523,Contradiction,"Challenges and Future Directions: Radiometric Quality: The quality of remote sensing data, especially from newer sources like CubeSats, needs careful evaluation. For instance, the Sentinel CubeSat constellation showed varying accuracy in different water conditions, indicating the need for further validation .","Remote sensing plays an important role in the monitoring of inland waters. Recently, Cubesats have become an alternative data source for studies that require high spatiotemporal resolutions. However, the radiometric quality of those data was never evaluated for inland water studies. This letter presents the experimental results to assess the quality of the Remote Sensing Reflectance (R<inf>rs</inf>) from commercial PlanetScope (PS) CubeSat constellation. The radiometric assessment was performed using in situ R<inf>rs</inf> measured at 37 field stations on distinct lakes across Lower Amazon Floodplain. In turbid lakes, PS bands presented R<inf>rs</inf> accuracy of 46% for all VNIR bands (coefficient of determination (R<sup>2</sup>) = 0.56), while in clear water lakes the results were not satisfactory (R<sup>2</sup> = 0.08). Furthermore, results showed a spectral dependence in the quality of R<inf>rs</inf> retrievals for the turbid lakes, with sounder metrics in visible bands (red band: R<sup>2</sup> = 0.83). Finally, there is a high correlation between water quality parameters (sediments concentration and Secchi Depth) and PS R<inf>rs</inf> at the red band (R<sup>2</sup> > 0.74). Although PS images are mostly designed for land applications, the results suggest that the radiometric quality is sufficient for the monitoring of fine-scale mixing processes between river waters and floodplain lakes.",Entity error
i_956,Entailment,"Ergonomic Issues: Prolonged standing and repetitive movements can lead to significant physical fatigue, which not only reduces productivity but also increases the risk of accidents .","Wearable sensors are currently being used to manage fatigue in professional athletics, transportation and mining industries. In manufacturing, physical fatigue is a challenging ergonomic/safety ""issue"" since it lowers productivity and increases the incidence of accidents. Therefore, physical fatigue must be managed. There are two main goals for this study. First, we examine the use of wearable sensors to detect physical fatigue occurrence in simulated manufacturing tasks. The second goal is to estimate the physical fatigue level over time. In order to achieve these goals, sensory data were recorded for eight healthy participants. Penalized logistic and multiple linear regression models were used for physical fatigue detection and level estimation, respectively. Important features from the five sensors locations were selected using Least Absolute Shrinkage and Selection Operator (LASSO), a popular variable selection methodology. The results show that the LASSO model performed well for both physical fatigue detection and modeling. The modeling approach is not participant and/or workload regime specific and thus can be adopted for other applications.",Entailment
i_2063,Contradiction,"Challenges and Barriers: Support and Community Involvement: The lack of support from authorities and the community, combined with insufficient research and technology access, are the sole reasons for the failure of entrepreneurial development in agricultural sectors like the straw agribusiness in Malaysia .","Given the need to address the adverse environmental impacts of rice straw burning, enhancing straw-utilisation would seem to be a step in the right direction. One way to achieve this objective would be to develop viable straw entrepreneurs. This study evaluates the barriers and challenges facing the straw entrepreneurial development in Malaysia. A total of 44 entrepreneurs in the country's rice bowl areas of MADA (n=24) and Sekinchan (n=20) were interviewed. The findings reveal five major problems that have been stagnating the Malaysian straw agribusiness, namely, lack of support from both authorities and the community, lack of research and access to technology facilities, low levels of skills and knowledge pertaining to straw industry, and lack of readily available venture capital. Other related challenges unveiled include uncertain entrepreneurial attitude, limited product markets, unreliable supply of raw straw, and the lack of skilled workers. To reverse the stagnation and rejuvenate its straw byproduct agribusiness Malaysia would need to strengthen and integrate institutional support, to enlarge all round stakeholders' involvement including that of the local community and the entrepreneurs themselves, and embark on fullscale product and market development.",Missing information
i_1570,Contradiction,"Policy and Planning Conflicts: The four-step principle in Sweden's national transport policy emphasizes reducing the need for transport and using existing infrastructure efficiently before considering new constructions. However, many measures in steps 1 and 3 fall outside the financial mandate of the Swedish Transport Administration (STA), limiting their implementation .","Research on sustainability and transport has paid increasing attention to how the purpose of the transport system is framed, often arguing that there is a need to shift the focus of transport planning and policy from the physical infrastructure to mobility and accessibility. Sweden's national transport policy also has elements of this shift, most noticeable in the so-called four step principle, where the possibility to affect the need for transport and choice of transport mode (step 1) and the possibility to use existing infrastructure more efficiently (step 2) should be considered before large reconstructions (step 3) or new infrastructure (step 4) is chosen as the solution to transport related problems. The aim of this article is to study whether the practical implications of Swedish national transport policy are consistent with the ambitions expressed in the four step principle, with particular focus on the Swedish Transport Administration's (STA) mandate to finance different measures. Based on an analysis of policy documents and semi-structured interviews the main finding of the analysis is that many step 1 and 2 measures do not fall within the financial mandate of the STA. The implementation of the four step principle therefore depends on the commitment among other actors than the STA to implement step 1 and 2 measures. Furthermore, it is concluded that the limits to the STA mandate has consequences for the ability of the STA to engage in collaboration with the actors on which it depends, and that strengthening the STA's mandate to finance a desired function rather than physical infrastructure is likely to increase commitment among other stakeholders to work with these measures. Such a step would imply a different regulatory framework than the current, more in line with ""the sustainable mobility paradigm"" (Banister 2008) and could contribute to a good accessibility to different amenities at the same time as negative environmental impacts are reduced.",Numeric error
i_2353,Entailment,Environmental Monitoring: Implement routine environmental monitoring to detect and address potential sources of contamination in the culture collection environment .,"Compounding pharmacies and contract testing laboratories can readily utilize critical information that microbial identification methods provide. Rapidly identifying the genus and species of environmental isolates and sample contaminates provides pharmacies and laboratories the opportunity to determine the possible source and implement corrective actions to improve compounding and testing processes. The microbial identification data collected from a compounding environment is critical. It is important to have accurate and specific microbial information to guide environmental collection practices, validation studies, and troubleshooting initiatives. The different technologies available provide varying levels of identification. They range from phenotypic assays to more accurate molecular-based techniques, including macromolecular methods and whole genome sequencing. Selecting the appropriate identification methodology requires evaluating multiple factors including the level of information required (genus only, genus and species, etc.) and the pharmacy's tolerance for unidentified or incorrectly identified isolates.
[4]: The present work focuses on assessing bacterial profiles of microbiota existing on technological equipment applied in food products manufacturing, objects located inside medical and preventive facilities, and water objects in recreation zones; another goal was to examine phenotypic properties of opportunistic pathogenic bacteria isolates as hazard identification factors within the framework of risk assessment concept. Our research objects were strains of Escherichia, Klebsiella, Enterobacter, Staphylococcus, Pseudomonas, Citrobacter and Serratia families that were detected and extracted due to hygienic monitoring activities performed in 2013-2017. Samples were taken via washing, direct inoculation, membrane filtration, and instrumental aspiration technique. Microbial status was analyzed with cultural and biochemical techniques on nutrient and differential-diagnostic media with subsequent confirmation with polymerase chain reaction (PCR). Phenotypic peculiarities were examined in vitro with conventional biochemical and microbiological techniques in conformity with the requirement fixed in Good Laboratory Practice. We revealed peculiarities of microbial profiles belonging to opportunistic pathogenic microbiota on different objects in habitats. The greatest groups included staphylococci detected in the air inside medical organizations with 1-4 cleanness degree (44 %); Enterobacteriaceae family bacteria, in washes off objects located in manufacturing and medical and prevention facilities (64 % and 69 % accordingly); Pseudomonas family bacteria, in water objects (46 %). 60 (36 %) isolates out of 167 examined ones had modified morphological and tinctorial signs regarding those typical for a family. Most isolates had a set of modified or atypical metabolomic signs such as hemolytic and lecithinase activities, apparent persistent factors, and ability to create biofilms. Opportunistic pathogenic bacteria strains extracted from washes off objects located inside food products manufacturing and medical and preventive facilities were the most potentially aggressive. Isolates from the same families extracted from water objects in recreation zones and air inside medical and preventive facilities had less apparent phenotypic properties that characterized their pathogenic potential. Our experimental data provide useful materials for examining a phenomenon related to changes in phenotypic properties; they can be applied during revealing and drawing up a hazard profile and for minimizing uncertainty within the concept of microbiological risk analysis.",Entailment
s_2176,Entailment,"7. Rating Systems for Built Environment Rating systems such as those used in the building industry assess sustainability by considering environmental, social, and economic impacts. These systems can be adapted for other industries, like unconventional petroleum projects .","A number of environmental and sustainability rating systems have been developed and used around the world. This trend has been most notable in the building industry, where evolution of construction practices and concerns about environmental impact have led to the development of different environmental and sustainability assessment approaches, strategies, models, appraisals, and methodologies. The implementation of green technology and practices has brought economic, social, and environmental benefits with respect to improving sustainable development performance with an accompanying certification process. The framework for developing rating systems for building systems can be extended and applied in other industrial contexts. As global demand for energy continues to rise, unconventional petroleum extraction and production of petroleum substitutes are both becoming more necessary. Development and operation of unconventional oil projects can have considerable social, economic, and environmental impacts. For example, one the largest unconventional oil deposits in the world is the Athabasca oil sands in northern Canada. Government policy makers, industrial developers, and other stakeholders generally work together to develop oil sands projects in an environmentally responsible manner; however, the projects lack of an effective sustainable development measurement tool. The WA-PA-SU project sustainability rating system is a proposed framework for measuring - in a consistent manner - the sustainability of development of unconventional petroleum projects in oil sands and heavy oil. The intent of the rating system is to have a tool that can be used by companies, stakeholders, and policy makers to measure and understand the range of impacts that projects may have over time. This assessment framework includes - but is not limited to - regulatory requirements, as well as approaches for measuring sustainability on social, economic, and environmental grounds. This paper presents a brief history of oil sands development, and the structure of the rating system. This structure comprises a description of the different areas included in the rating system, and the rationale for the first tool, which is intended to assist practitioners and stakeholders in general to measure sustainable development of the oil sands and heavy oil projects. © 2012 WIT Press.",Entailment
s_911,Contradiction,"Challenges and Solutions: Challenges: Despite the benefits, the deployment of IoT in smart cities faces challenges such as privacy concerns, security issues, and the need for efficient data management systems .","[2] Smart cities are systematically promoting the transition to sustainable and effective energy systems by promoting policies for energy efficiency, regionalized/distributed renewable energy generation, and intelligent energy management. In particular, this transition toward a more integrated and intelligent energy supply has created a plethora of energy meta-information made available through the IoT smart grid, thereby allowing big data analytical services to forecast energy consumption and to manage usage patterns. In this article, we propose a context-aware framework for intelligent power equipment management. Our contribution is to present a design of the proposed framework based on context awareness, the definition of a context ontology for power equipment management, a specification of the inference rules for the context ontology, and a context-aware inference service for power equipment management. The proposed system has broad applications to handle system monitoring and express system controls, so as to be easily and effectively applied to various application domains. [12] This research abstract provides a comprehensive overview of exploring the requirements and applications of the next generation Internet of Things (IoT). The study which used thorough literature review as methodology, involved a systematic search of relevant academic databases, such as Scopus, IEEE Xplore, and ACM Digital Library, using keywords such as ""Internet of Things,"" ""next-generation IoT,"" ""IoT requirements,"" and ""IoT applications."" The search was limited to peer-reviewed journal articles, conference proceedings, and book chapters published within the last ten years to ensure the inclusion of the most recent and relevant information. It focused on identifying the key requirements for the next generation of Internet of Things (IoT) technologies, evaluating the current state of IoT applications and identify areas of improvement for future generations, investigating the potential impact of next-generation IoT on various industries and sectors. Other objectives of the study are: analysing the data security and privacy challenges that may arise with the implementation of next-generation IoT technologies, examining the potential environmental impact of next-generation IoT devices and propose sustainable solutions, investigating the use of artificial intelligence and machine learning algorithms for enhancing the capabilities of IoT applications and the future perspectives of internet of things. Additionally, the research delves into the diverse range of applications that can benefit from the next generation IoT. These applications span across industries such as healthcare, agriculture, transportation, and smart cities. The IoT enables improved efficiency, automation of processes, and better decision-making in various sectors. The findings highlight the need for holistic approaches to address the requirements and challenges of the next generation IoT. By focusing on interoperability, standardization, security, and data management, researchers and industry professionals can ensure the continued success and advancements of the IoT.",Misrepresentation
i_170,Unverifiable,Future Research Paths: User Experience Studies: Investigating the impact of ZTNA on user experience and productivity can provide insights into optimizing its implementation .,"In response to weaknesses of current network security solutions, the zero-trust model follows the idea that no network – whether internal or external – is trustworthy. The concept of zero-trust is enjoying increasing attention in both research and practice due to its promise to fulfil complex new network security requirements. Despite zero-trust's advantages over traditional solutions, it has not yet succeeded in replacing existing approaches. Uncertainty remains regarding the concept's distinct benefits and drawbacks for organisations and individuals, which hinders a holistic understanding of zero-trust and wide-spread adoption. Research can make valuable contributions to the field by systematically providing new insights into zero-trust. To support researchers in this endeavour, we aim to consolidate the current state of the knowledge about zero-trust and to identify gaps in the literature. Thus, we conduct a multivocal literature review, analysing both academic and practice-oriented publications. We develop a research framework for zero-trust to structure the identified literature and to highlight future research avenues. Our results show that the academic literature has focused mainly on the architecture and performance improvements of zero-trust. In contrast, the practice-oriented literature has focused on organisational advantages of zero-trust and on potential migration strategies. However, economic analyses and user-related studies have been neglected by both academia and practice. Future research may rely on our findings to advance the field in meaningful ways.",Unrelated and unverifiable
i_676,Contradiction,"Research into new materials, such as lithium iron phosphate, aims to improve energy density and safety further .","Conspectus The commercial introduction of the lithium-ion (Li-ion) battery nearly 25 years ago marked a technological turning point. Portable electronics, dependent on energy storage devices, have permeated our world and profoundly affected our daily lives in a way that cannot be understated. Now, at a time when societies and governments alike are acutely aware of the need for advanced energy solutions, the Li-ion battery may again change the way we do business. With roughly two-thirds of daily oil consumption in the United States allotted for transportation, the possibility of efficient and affordable electric vehicles suggests a way to substantially alleviate the Country's dependence on oil and mitigate the rise of greenhouse gases. Although commercialized Li-ion batteries do not currently meet the stringent demands of a would-be, economically competitive, electrified vehicle fleet, significant efforts are being focused on promising new materials for the next generation of Li-ion batteries.The leading class of materials most suitable for the challenge is the Li- and manganese-rich class of oxides. Denoted as LMR-NMC (Li-manganese-rich, nickel, manganese, cobalt), these materials could significantly improve energy densities, cost, and safety, relative to state-of-the-art Ni- and Co-rich Li-ion cells, if successfully developed.1 The success or failure of such a development relies heavily on understanding two defining characteristics of LMR-NMC cathodes. The first is a mechanism whereby the average voltage of cells continuously decreases with each successive charge and discharge cycle. This phenomenon, known as voltage fade, decreases the energy output of cells to unacceptable levels too early in cycling. The second characteristic is a pronounced hysteresis, or voltage difference, between charge and discharge cycles. The hysteresis represents not only an energy inefficiency (i.e., energy in vs energy out) but may also complicate the state of charge/depth of discharge management of larger systems, especially when accompanied by voltage fade.In 2012, the United States Department of Energy's Office of Vehicle Technologies, well aware of the inherent potential of LMR-NMC materials for improving the energy density of automotive energy storage systems, tasked a team of scientists across the National Laboratory Complex to investigate the phenomenon of voltage fade. Unique studies using synchrotron X-ray absorption (XAS) and high-resolution diffraction (HR-XRD) were coupled with nuclear magnetic resonance spectroscopy (NMR), neutron diffraction, high-resolution transmission electron microscopy (HR-TEM), first-principles calculations, molecular dynamics simulations, and detailed electrochemical analyses. These studies demonstrated for the first time the atomic-scale, structure-property relationships that exist between nanoscale inhomogeneities and defects, and the macroscale, electrochemical performance of these layered oxides. These inhomogeneities and defects have been directly correlated with voltage fade and hysteresis, and a model describing these mechanisms has been proposed. This Account gives a brief summary of the findings of this recently concluded, approximately three-year investigation. The interested reader is directed to the extensive body of work cited in the given references for a more comprehensive review of the subject.",Entity error
i_150,Entailment,"Potential Applications of AI for Managing Dark Data: Security and Risk Management: AI can enhance cybersecurity by analyzing data from numerous digital incidents to identify potential threats, thereby reducing the risk associated with dark data .","Online assurance is one of the different occupations of man-made awareness. A report by Norton showed that the overall cost of ordinary data breach recovery is $3.86 million. The report furthermore shows that organizations normally need 196 days to recover from any data breach. Thus, organizations should use additional artificial intelligence (AI) to avoid waste of time and financial disasters caused due to data breach. Computerized reasoning, AI, and risk knowledge can see the plans in data to enable security systems acquire from past experience. Moreover, AI enables organizations to decrease scene response times and comply with best security practices. Present state-of-the-art instruments utilized in cybercrime investigation depend on inconsequential watchword search and manual substance investigation by a human master. Simultaneously, late improvements likewise added estimated design coordinating, thus called e-Discovery that aids, and improves on, the manual work of criminology examinations. Notwithstanding, big data issues need an alternative way to deal with or tackle enormous information seized or corresponded for a criminal case. In this way, there is a solid need to apply artificial intelligence (AI) and automated reasoning models to do quick and convenient information handling. Cybercriminals represent a danger to all kinds of organizations, and the clients and buyers who use them. A portion of the numbers engaged with the biggest information breach is faltering, with individual information concerning countless people being leaked, thereby making everyone conceivably another casualty of extortion and other cybercrimes. Artificial intelligence (AI) and machine learning (ML) are increasingly put to use in online protection, with security devices examining information from a large number of digital episodes and utilizing that information to recognize likely dangers - a user account acting peculiarly when tapping on a phishing joins, for instance, or another variation of malware. The AI data set can draw upon data about any type of malware that has been distinguished previously. So when another type of malware shows up - either a variation of the existing malware or a completely different type of malware - the framework can actually take a look at it against the information base, inspecting the code and hindering the assault by the malware on the premise that comparative occasions have recently been considered as vindictive. Be that as it may, there is a constant fight among assailants and protectors. Since a long time, cybercriminals have attempted to change their malware code such that security programming no longer remembers the code as noxious. The aim of this chapter is to investigate and comprehend the effects of computerized reasoning in the fields of public safety and security; to distinguish the political, international, and vital issues of AI; to examine AI's place in clashes and cyberconflicts, and all the more, by and large in different types of violence; to clarify the use of man-made brainpower by military organizations, law enforcement agencies, and the police; and to talk about the enquiries made using the advancement of man-made consciousness and the increase in utilization of man-made consciousness in armed forces, police, and knowledge organizations, at the strategic, functional, and key levels.",Entailment
i_1625,Contradiction,Underlying Mechanisms: Stakeholder Pressure: Gender-diverse boards may be more responsive to stakeholder pressures for better environmental performance. This responsiveness can result in more robust environmental policies and practices .,"Based on the upper echelons theory, ecofeminist theory, and natural resource-based theory (NRBV), this study has constructed a relational model between female executives' participation, unethical environmental behavior, proactive environmental strategy, and corporate sustainable competitive advantage. The samples include a total of 496 female executives from listed 524 companies in the manufacturing sector in China, and multiple regression methods are used for the analysis. The study showed that female executives' participation had double positive effects on corporate sustainable competitive advantage, which included both the inhibiting effect on unethical environmental behavior and the stimulating effect on proactive environmental strategies. The study also explored the boundary conditions of ""conservative"" and ""proactive"" behaviors from the internal and external perspectives of enterprises. But it was shown that the effect would not be further improved when both moderation effects of environmental stakeholder pressure and environmental leadership were higher at the same time. As enterprises' behaviors should match with their capability range, radical behaviors might run counter to their desires.",Misrepresentation
s_1020,Entailment,"Force Sensor Technology in Surgery: Experimental Validation: Softness Measurement: Studies have shown that force sensors can effectively measure the softness of tissues, which is essential for tumor localization and other diagnostic purposes. Additionally, it is believed that advancements in force sensor technology could lead to the development of real-time imaging techniques that enhance the visualization of soft tissue characteristics during surgery .","We have developed a forceps-type tactile sensor for palpation of a tumor in laparoscopic surgery. The sensor responds to contact position and force at deformable cavity in the sensor probe by using acoustic reflection. The sensor has high applicability for laparoscopic surgery because of its simple structure and disuse of electrical elements within inserted part into patient's body. In this study, we try to measure softness of a contact tissue by using the sensor. Human can estimate softness from contact area and force. Indentation depth is not always required for softness perception. This perception mechanism suggests that our sensor has a possibility for softness measurement because the sensor can respond to contact position and force. Softness measurement contributes to tumor localization and improvement of diseases database. First, the sensor output characteristic is investigated for different soft samples. Then, a method of stiffness measurement using the sensor outputs is proposed. Experimental results show that the sensor has the capability of softness measurement without any additional sensors.",Entailment
s_1656,Entailment,"Integrated and Sustainable Practices: Participatory Action Research (PAR): In the Solomon Islands, PAR has been used to improve local knowledge and practices in fish farming, leading to better pond design and fish husbandry techniques. This approach has significantly increased productivity and is expected to completely resolve household nutrition issues .","Land based aquaculture has the potential to mitigate future shortfalls of food fish supply in Solomon Islands. However, aquaculture is relatively new in the Pacific and such potential is hampered by a lack of aquaculture knowledge and practice within local cultures. A participatory action research approach was used to conduct on-farm trials with farmers in Solomon Islands to develop relevant and improved ways of farming and maximising productivity of the resident exotic tilapia Oreochromis mossambicus. During the 34 month period when the research was undertaken improvements were evident, through increased farmer participation and improved knowledge of farmers on pond design and fish husbandry techniques. One of the contributing factors to improved farmer understanding was the production of knowledge products which were co-developed with and based on the farmers' local context. Productivity of a typical 20–38 m<sup>2</sup> pond ranged from 726 to 1819 kg ha<sup>− 1</sup> year<sup>− 1</sup>. Because 80% of this production was consumed by households, such ponds, producing easily harvestable small tilapia, have a role in supplementing household diets and contributing to improved nutrition at the subsistence level. While pond system productivity reached levels equivalent to low input tilapia ponds in other regions, the resident tilapia in Solomon Islands has limited opportunity for more than low level commercial enterprises. Established ponds are included in the daily livelihood tasks of both men and women and explicitly gender equitable approaches to partnerships with pond farmers provide opportunities to further increase benefits to households. A participatory action research approach, and the principles embodied therein, is recommended for further development of household aquaculture enterprises, regardless of species, in Solomon Islands. Statement of relevance We feel that our paper makes significant and novel advance to the field of aquaculture by: (1) Presenting results of a research that shows the importance and potential role of aquaculture in mitigating food and nutrition security in locations where it is increasingly difficult to access fish based protein sources, even in a South Pacific location perceived to contain an abundance of fish.(2) Participatory Action Research (PAR) has been employed in agriculture and aquaculture in Asia and Africa in the last 20 years. We report in here the use of the PAR method within the Pacific Islands context in conducting research and developing aquaculture in a location where there is very little history of aquaculture within the local culture.",Entailment
i_1307,Entailment,"AI and Big Data: The combination of 5G with AI and big data analytics enhances the ability to process and analyze large volumes of health data, improving diagnostic accuracy and personalized treatment plans .","With the fast of ultra-fast 5G/6G mobile wireless, Artificial Intelligence (AI), and Big Data analytics, the Internet of Things (IoT) is getting great attention in healthcare industry. The combing of these powerful technologies with the Internet of Things will likely revolutionize the healthcare industry in next few years. The growth of IoT in healthcare industry using these latest technologies will transform the way patients are monitored and treated remotely to improve the productivity of the healthcare industry workers. This paper presents the state-of-The-Art research relating to IoT and Health care with focus on hardware requirements, complexity and challenges.
[10]: The pandemic of COVID-19 is continuing to wreak havoc in 2021, with at least 170 million victims around the world. Healthcare systems are overwhelmed by the large-scale virus infection. Luckily, Internet of Things (IoT) is one of the most effective paradigms in the intelligent world, in which the technology of artificial intelligence (AI), like cloud computing and big data analysis, is playing a vital role in preventing the spread of the pandemic of COVID-19. AI and 5G technologies are advancing by leaps and bounds, further strengthening the intelligence and connectivity of IoT applications, and conventional IoT has been gradually upgraded to be more powerful AI + IoT (AIoT). For example, in terms of remote screening and diagnosis of COVID-19 patients, AI technology based on machine learning and deep learning has recently upgraded medical equipment significantly and has reshaped the workflow with minimal contact with patients, so medical specialists can make clinical decisions more efficiently, providing the best protection not only to patients but also to specialists themselves. This paper reviews the latest progress made in combating COVID-19 with both IoT and AI and also provides comprehensive details on how to combat the pandemic of COVID-19 as well as the technologies that may be applied in the future.",Entailment
s_1174,Entailment,Catheterization Procedures for Individuals with Congenital Heart Conditions: Technological and Procedural Advances: The development of hybrid catheterization labs has enhanced the capabilities and safety of these procedures .,"There has been a recent trend toward hybrid cardiac catheterization procedures for the treatment of patients with various forms of congenital heart disease. Hybrid procedures offer the combined advantages of outstanding imaging in a full operating room environment, allowing direct access onto the heart or the great vessels for access or procedure completion, or complementary imaging before, during, or after surgical correction when necessary. With the increase in frequency of hybrid procedures, more medical centers are contemplating the conversion of standard cardiac catheterization rooms to hybrid facilities, or de novo construction. In this report, we detail a single-center experience of conversion from a standard catheterization facility into a hybrid suite. The strategic planning, design, system integration, and the challenges inherent to this project are discussed. Many of the solutions to these challenges are likely to be applicable to other institutions planning on similar hybrid conversion or construction. © 2008 Wiley-Liss, Inc.",Entailment
i_32,Entailment,"Key Strategies: Disaster Management: AI-driven decision support systems for disaster mitigation, such as earthquake and landslide risk assessment, utilize geographical information systems and deep learning models to predict and manage natural disasters effectively .","The earthquake disaster was a vast risk for a sustainable and harmonious societal and econonic development, so, it was effective methods to build a decision supporting system for earthquake disaster mitigation and preparation stratagem. A typical decision support system for Earthquake disaster mitigation was introduced in this paper. The principle, design criteria, structure, functions and application of the system were described herein. This system based on Geographical Information System and Artificial Intelligence, consists of below several parts: earthquake hazard analysis, lifeline system performance analysis, kinds of building earthquake damage forecasting, post-earthquake emergency response aided-decisions and earthquake information instant publishing. In this system, there were more than 100 coverages and 36 analytical models. These coverages covered almost all related data to meet the needs of earthquake disaster mitigation and risk assessment, including recorded earthquakes, seismic tectonic zones, intensity distribution of historic earthquake, soil profiles, characteristics of buildings, distribution of citizens, important lifeline systems, earthquake rescuing experience and knowledge, etc. These analytical modules could be used to generate isoseismals of earthquake, estimate site effects, forecast the failure possibility of slope and the damage bound of landslide triggered by earthquake, evaluate performance, damage and losses of building and lifeline system, assess the toll of death and injured, and provided the decision-making for rescue, relief, evacuation. © 2012 IEEE.
[11]: Landslides in the Nainital district of Uttarakhand, India, pose a significant threat to human communities and local ecosystems. This study aims to improve landslide susceptibility modeling by integrating advanced analytical techniques with deep learning, sensitivity analysis and explainable artificial intelligence (XAI). Our approach captures the complex interaction between natural terrain and human intervention and provides a novel framework for risk assessment and management. In this analysis, we performed a multicollinearity analysis to ensure the independence of predictor variables. We optimized deep learning models, including deep neural network (DNN), convolutional neural network (CNN) and a hybrid of CNN with long short-term memory (LSTM), using Bayesian techniques. This optimization achieved a high degree of precision in parameter tuning. In the study, multicollinearity analysis showed that no parameter exceeded the multicollinearity threshold of over 9. When evaluating accuracy, the CNN-LSTM model was found to be the most effective with an Area Under the Curve (AUC) of 0.96, while DNN and CNN also had high AUCs of 0.94 and 0.95, respectively. Spatially, the CNN model identified 16.28% of the total area as highly susceptible, while the hybrid CNN-LSTM model delineated 13.39%. Sobol's sensitivity analysis emphasized critical factors such as slope, elevation and geology as well as the anthropogenic influence of distance to built-up (DTB). The SHAP analysis confirmed the importance of these factors. This integrated method offers an innovative way to understand the dynamics of landslides by combining natural and human factors and provides the basis for sustainable infrastructure planning in Nainital.",Entailment
i_1957,Entailment,"Social Sustainability: Bridging the Digital Divide: ICT has the potential to bridge the digital divide, contributing to social sustainability by promoting universal education and global partnerships. However, the environmental challenges posed by the required investment in digital infrastructure are likely to outweigh the social benefits, making it questionable whether these initiatives can truly enhance sustainability .","The potential for environmental, social, and economic advances enabled by information and communication technologies (ICTs) is tremendous: 'Smart Grid' systems hold promise for resource conservation and climate change mitigation; innovations in ICT help transition countries from industrial to knowledge economies, and bridging the digital divide in developing countries can help achieve Millennium Development Goals worldwide: ending poverty, enabling universal education, and creating global partnerships. However, the benefit possible from global use of ICTs cannot be realized without a corresponding build up of digital infrastructure. This projected increase in ICT products is of particular concern to environmental sustainability, in large part due to the global health, safety, and environmental effects of managing these products in the waste stream. The ability to quantify and manage environmental impacts of ICT products is complicated by continuous evolution of product form and function. The work described herein provides an assessment of how changing form factor and material composition in common consumer electronics - desktop and notebook computers - may influence the electronic waste stream in the U.S. Results indicate that dematerialization on a per product basis is largely offset by increasing volumes of the total waste stream. From an economic standpoint, end-of-life value will be enhanced by the increasing use of lightweight materials such as aluminum and magnesium but potentially impacted by decreasing precious metal content. This paper also suggests that common design for end-of-life heuristics may be less applicable to ICT products undergoing rapid technological progress, as exemplified by the changing form factor and lightweighting of the consumer notebook computer.",Entailment
i_242,Unverifiable,"Mitigation Contributions: Moving Target Defense (MTD): Enhances network unpredictability, making it harder for attackers to target specific assets, and may also lead to improved overall network performance by reducing the frequency of successful attacks .","Software-Defined Networking (SDN) has emerged as a framework for centralized command and control in cloud data centric environments. SDN separates data and control plane, which provides network administrator better visibility and policy enforcement capability compared to traditional networks. The SDN controller can assess reachability infor- mation of all the hosts in a network. There are many critical assets in a network which can be compromised by a malicious attacker through a multistage attack. Thus we make use of centralized controller to assess the security state of the entire network and pro-actively perform attack analysis and coun- termeasure selection. This approach is also known as Mov- ing Target Defense (MTD). We use the SDN controller to assess the attack scenarios through scalable Attack Graphs (AG) and select necessary countermeasures to perform net- work reconfiguration to counter network attacks. Moreover, our framework has a comprehensive con ict detection and resolution module that ensures that no two ow rules in a distributed SDN-based cloud environment have conflicts at any layer; thereby assuring consistent conflict-free policy implementation and preventing information leakage.
[8]: Servers in a network are typically assigned a static identity. Static assignment of identities is a cornerstone for adversaries in finding targets. Moving Target Defense (MTD) mutates the environment to increase unpredictability for an attacker. On another side, Software Defined Networks (SDN) facilitate a global view of a network through a central control point. The potential of SDN can not only make network management flexible and convenient, but it can also assist MTD to enhance attack surface obfuscation. In this paper, we propose an effective framework for the prevention, detection, and mitigation of flooding-based Denial of Service (DoS) attacks. Our framework includes a lightweight SDN assisted MTD strategy for network reconnaissance protection and an efficient approach for tackling DoS attacks using Software Defined-Internet Exchange Point (SD-IXP). To assess the effectiveness of the MTD strategy and DoS mitigation scheme, we set two different experiments. Our results confirm the effectiveness of our framework. With the MTD strategy in place, at maximum, barely 16% reconnaissance attempts were successful while the DoS attacks were accurately detected with false alarm rate as low as 7.1%.",Related but unverifiable
i_870,Contradiction,"Machining Environment: Lubrication: Using cutting fluids (wet conditions) can significantly reduce burr size compared to dry conditions. However, mist lubrication can also be effective while being more environmentally friendly .","The burr formation mechanisms strongly depend on the machining methods as well as cutting conditions. Cutting fluids play significant roles in machining, including reduction of friction and temperature. Using a cutting fluid, however, degrades the quality of the environment and increases machining costs. In the present work, initially the effects of cutting fluid application (dry, mist and flood) and their interaction with cutting parameters on the burr size during drilling of 6061-T6 aluminum alloys were investigated using multi-level full factorial design. Second-order non-linear mathematical models were developed to predict burr height for various lubrication modes. The accuracy of the regression equations formulated to predict burr height when using different lubrication modes has been verified through carrying out random experiments in the range of variation of these variables. A procedure was developed to minimize burr size for drilling holes by presenting the optimal levels of process parameters. Taguchi optimization method based on L9 orthogonal array design of experiment was then used which has shown very accurate process parameters selection that leads to minimum burr height. According to experimental study, it was observed that dry and mist drilling can produce parts with quality comparable with those obtained in wet drilling when using the optimal cutting conditions. In addition, increase in cutting speed and feed rate exhibits a decrease in burr size. Copyright © 2012 by ASME.
[7]: Drilling a hole usually leaves behind a undesirable burr at the exit work surface. Application of the method suggested by Taguchi is made in this work to minimize drilling burr of an aluminium alloy using HSS drill within the domain of experiments considered. Parameters used are cutting velocity, feed and machining environment. The effect of process variables on burr height is explored, and the optimum condition for minimizing burr height using a back-up support is determined by the analysis. Experimental runs were chosen followingL<inf>27</inf> orthogonal array of Taguchi. Analysis of variance was undertaken to find out the influence of process parameters on the response noted. Predicted values are finally checked for accuracy through a confirmation test. It is found out that back-up support yields much better result than that of normal drilling process. Moderate cutting velocity, low feed and wet condition with water cooling were observed to minimize burr height using a back-up support. Machining environment is found to be the most significant parameter for reducing burr height.",Missing information
i_1147,Unverifiable,"Contact lenses, which provide refractive correction during the day, have been effective in reducing axial elongation and myopia progression .","Myopia is an important public health issue, and high myopia may lead to severe complications if left untreated. Orthokeratology lenses, worn overnight to reshape the cornea, are one of many recent modalities used to slow down the progression of myopia in children. This treatment has been proven successful, as evidenced by decreased spherical refractive error and axial length relative to the control at interval follow-up ranging from 6 months to 5 years. In this systematic review, the authors collected published controlled studies that analyzed the efficacy of orthokeratology lens wear and calculated longitudinal relative changes in axial length, revealing a weighted average of -45.1% change in axial length at the 2-year follow-up. The exact mechanism by which orthokeratology lenses reduce myopia progression is unknown, but research shows that the corneal reshaping decreases peripheral hyperopic defocus and therefore increases peripheral myopic defocus to likely reduce stimuli for axial elongation and subsequent development of myopia. Use of orthokeratology lenses is generally safe, but cases of associated infectious keratitis may have a higher incidence of virulent organisms such as Pseudomonas, Acanthamoeba, and antibacterial-resistant strains of Staphylococcus, partially due to the required overnight use of these lenses. Orthokeratology is regarded as one of the most effective non-pharmacologic measures to slow progression of myopia in children and, with regular follow-up to ensure safety, continues to be one of the most effective treatments for myopia management around the world.
[5]: Purpose: To review the published evidence to evaluate the ability of orthokeratology (Ortho-K) treatment to reduce myopic progression in children and adolescents compared with the use of spectacles or daytime contact lenses for standard refractive correction. Methods: Literature searches of the PubMed database, the Cochrane Library, and the databases of clinical trials were last conducted on August 21, 2018, with no date restrictions but limited to articles published in English. These searches yielded 162 citations, of which 13 were deemed clinically relevant for full-text review and inclusion in this assessment. The panel methodologist then assigned a level of evidence rating to the selected studies. Results: The 13 articles selected for inclusion include 3 prospective, randomized clinical trials; 7 nonrandomized, prospective comparative studies; and 3 retrospective case series. One study provided level I evidence, 11 studies provided level II evidence, and 1 study provided level III evidence. Most studies were performed in populations of Asian ethnicity. Change in axial length was the primary outcome for 10 of 13 studies and change in refraction was the primary outcome for 3 of 13 studies. In these studies, Ortho-K typically reduced axial elongation by approximately 50% over a 2-year study period. This corresponds to average axial length change values of approximately 0.3 mm for Ortho-K patients compared with 0.6 mm for control patients, which corresponds to a typical difference in refraction of approximately 0.5 diopters (D). Younger age groups and individuals with larger than average pupil size may have a greater effect with Ortho-K. Rebound can occur after discontinuation or change to alternative refractive treatment. Conclusions: Orthokeratology may be effective in slowing myopic progression for children and adolescents, with a potentially greater effect when initiated at an early age (6–8 years). Safety remains a concern because of the risk of potentially blinding microbial keratitis from contact lens wear.",Related but unverifiable
i_1037,Contradiction,"5. Postoperative Care: Managing Complications: While it is important to be aware of potential postoperative complications such as hypothermia, pain, and cognitive dysfunction, especially in elderly patients, the focus on rapid return to autonomy and minimizing hospital stay may not be as critical as ensuring comprehensive monitoring of all health aspects, which could be more beneficial in the long run .","Age should not be a limiting factor for optimal surgical care of cancer. Preoperative assessment and therapeutic line decision must be a multidisciplinary team work. A specific geriatric oncology consultation would help assessing the level of autonomy or dependence, the patient cognitive functions and his nutritional status. The preoperative interview and clinical examination aim to assess the overall general health of the patient and to detect cardiovascular, pulmonary and neurological disorders which are the main postoperative factors of morbidity and mortality, other than related to tumor itself. Many scores of surgical risk assessment have been proposed. The Charlson index and the CIRS-G are the most widely used. Because of pharmacokinetic and pharmacodynamic changes related to age, new anesthesia techniques, such as target intravenous anesthesia (TIVA), which allow fine adjustment of anesthesia level according to the patient individual parameters (age, weight, height, sex) will be preferred. The most frequent postoperative complications are those related to hypothermia, pain and postoperative cognitive dysfunction. The main objective of the preoperative care of the elderly person is a rapid return to autonomy in a familiar environment. © 2009 Elsevier Masson SAS. All rights reserved.",Opposite meaning
i_452,Entailment,"Key Elements for Clarity and Shared Understanding: Feedback and Continuous Improvement: Incorporating feedback mechanisms, such as the customer satisfaction survey, can provide valuable insights into service quality and areas for improvement. This continuous feedback loop helps in maintaining clarity and shared understanding by addressing issues promptly and effectively .","Although many IT service management frameworks exist, we still have limited theoretical understanding of IT service quality within a broader nomological network. Building on recent conceptual work on the IT service climate construct, this study empirically establishes it as a predictor of IT service quality using survey data from both IT units and their clients. Also examined was a set of antecedents which provide a foundation upon which a favorable service climate can be built. The IT service climate instrument, when incorporated into employee feedback initiatives, can provide guidance to IT executives about practices to improve service quality. © 2012 Elsevier B.V. All rights reserved.",Entailment
s_1416,Unverifiable,Effects of Various Supplements on Ruminal Fermentation: Humic Acids: Supplementation with humic acids did not affect the TVFA concentration in the rumen of sheep .,"[3] It is hypothesised that saponins from Quillaja saponaria (QS) improve the efficiency of N utilisation in ruminants, thus increasing sheep growth. Therefore, this experiment was carried out to investigate the effect of oral administration of increasing levels of QS extract (0, 30, 60 and 90. mg/kg dry matter intake (DMI) containing 6, 12 and 18. mg sapogenin) on feed digestibility, growth and meat composition of sheep. Twenty-four 5-6-month-old Barbarine lambs (initial live weight 18.6 ± 1.98. kg) were allotted to four equal groups, all of which received oaten hay ad libitum and 400. g concentrate per animal. Immediately after offering the morning meal 10. ml water solutions containing 30, 60 or 90. mg of QS/kg DMI were orally administrated. Feed intake and growth rates were measured for 57 days. Thereafter, lambs were allowed a 4-day acclimation to metabolic cages before starting a 5-day total collection period. QS had no effect on total dry matter and water intakes. Administration of 60 or 90. mg QS/kg DMI decreased NDF digestibility (P=0.011); however, it had no effect on crude protein digestibility, N retention, microbial N supply and ammonia concentration in the rumen fluid suggesting that QS did not improve, as expected, the efficiency of N utilisation although a linear reduction of protozoa count in the rumen fluid just before or 4. h after distribution of the morning feed (P=0.0027 and P=0.0011, respectively) was observed. Blood profiles indicated that QS had no effect (P>0.05) on plasma urea and cholesterol concentrations. However, lambs receiving QS exhibited lower (P<0.05) concentration of plasma glucose than control lambs (without QS). No effect on both feed intake and efficiency of N utilisation may explain the absence of response of QS extracts (30-90. mg/kg DMI) on animal growth. Saturated fatty acids (SFA) and monounsaturated fatty acids in lamb meat were not influenced by the QS supplementation (P>0.05). Polyunsaturated fatty acids (PUFA) and the ratio PUFA to SFA tended to be higher in meat from the QS-supplemented animals than from control lambs. It is concluded that the administration of 30, 60 or 90. mg QS/kg DMI had a defaunation effect but failed to improve feed digestibility, growth performance and meat quality of Barbarine lambs. © 2010 Elsevier B.V. [13] Utilization of low-input feed resources rich in plant bioactive compounds is a promising strategy for modulating the fatty acid profile in ruminant products. They manipulate microbes involved in rumen biohydrogenation and increase the accumulation of desirable fatty acids at the tissue level. Therefore, the present study was undertaken to assess the effect of dietary supplementation of aniseed straw and eucalyptus leaves on growth performance, carcass traits and fatty acid profile of finisher lambs. Thirty-six Malpura hogget were divided into three treatment groups of 12 each, reared individually in pen (1.6 m × 1.1 m) and fed ad libitum complete feed blocks made up of 55 parts concentrate, 5 parts molasses and 40 parts roughage. Roughage in control (Con) was 20 parts each of ardu (Ailanthus excelsa) leaves and oat (Avena sativa) straw. In test diets, that is, Con-as and Con-el, 10% aniseed (Pimpinella anisum) straw and Eucalyptus rudis leaves, respectively, were added by replacing 5% each of oat straw and eucalyptus leaves. The lambs were weighed weekly; and at the end of 3 months of feeding trial, the lambs were slaughtered to study the carcass traits, composition and product evaluation. Average daily gain (ADG) and DM intake (DMI) was higher (P < 0.05) in Con-as compared to Con and Con-el, while ADG and feed conversion ratio decreased (P < 0.05) by 29.4% and 36.4%, respectively, in Con-el compared to Con. Carcass traits showed lower (P < 0.05) loin eye area and chilling loss in the Con-el group compared to the Con-as and Con, and the total carcass fat compared to Con-as. However, the keeping quality of meat improved in both Con-as and Con-el which was reflected by lower (P < 0.05) thiobarbituric acid-reactive substances values. Nuggets prepared from Con and Con-as meat had superior (P < 0.05) sensory attributes with an overall palatability. Fatty acid profile of longissimus thoracis muscle showed lower (P < 0.05) atherogenic and thrombogenic indices in Con-as and higher (P < 0.05) in Con-el group. Moreover, in Con-as group, the proportion of C16:0 was lower (P < 0.05) and C18:3n-3 was higher (P < 0.05), but no effect was observed on the amount of conjugated linoleic acid (CLA; C18:2 c9t11). In case of adipose tissue, the content of CLA was higher (P < 0.05), and the ratio of n-6:n-3 was more nearer to desirable levels in Con-as group. Therefore, it can be concluded that aniseed straw is a promising feed supplement compared to eucalyptus leaves for improving meat quality and fatty acid profile in lambs.",Unrelated and unverifiable
i_1133,Contradiction,"While financial and organizational challenges in implementing comprehensive care models are mentioned, they are likely overstated and do not significantly hinder the overall effectiveness of diabetes care delivery .","The current diabetes epidemic threatens to overwhelm the healthcare system unless we redesign how diabetes care is delivered. The number of endocrinologists is grossly inadequate to provide care for all individuals with diabetes, but with the appropriate utilization of the primary care workforce and alternative healthcare providers working together in teams, effective diabetes care can be provided to all. We propose a patient-centered, goal-based approach with resources devoted to care coordination, measurement of outcomes, appropriate use of technology, and measurement of patient satisfaction. Financial incentives to healthcare systems and providers need to be based on defined outcome measures and reducing long-term total medical expenditures, rather than reimbursement based on number of visits and lengthy documentation. Endocrinologists have a responsibility in setting up effective diabetes care delivery systems within their organizations, in addition to delivering diabetes care and serving as a resource for the educational needs for other medical professionals in the community. There are major challenges to implementing such systems, both at the financial and organizational levels. We suggest a stepwise implementation of discrete components based on the local priorities and resources and provide some examples of steps we have taken at our institution.",Opposite meaning
s_1596,Entailment,"Integrated Approaches: Systematic Management: Effective management of sustainable rural development involves addressing economic functions, social partnerships, and overcoming governance disunity. This holistic approach is likely to guarantee the stability and growth of rural areas, although it may not be sufficient in all contexts .","The study of the relevance of the developing management trends in agriculture is rationalized by the fact that the agrarian sector is one of the most important and most dynamically developing sectors of the national economy. The aim of the study is to identify and systematize the methodological prerequisites for solving the problems of sustainable development of rural areas and their management. It was concluded that the sustainable development of rural areas contributed to the fulfillment of their economic functions, including the provision of food, agricultural raw stock, public goods, the production of goods and services, the preservation of the rural way of life and rural culture, enhanced reproduction of the population, development of public welfare and living standards, maintaining the ecological balance in the biosphere, as well as overcoming the interagency disunity between various levels of governance when deciding on the development of rural areas, which implied social partnership among the rural population, regions and the state. This made it possible to deepen the understanding of the nature of the emergence of agrarian crises and to justify the stability of the crisis trend as an initial prerequisite for the formation of a system for managing the development of both the entire economy and the agricultural sector, particularly in the context of analysis of the cyclical development of the economy and modern crisis theories.
[8]: The concept of sustainable development was widely adopted at the global level of development of society in the world. At the same time transition to sustainable development and giving of irreversible character to it are impossible without complex development of rural territories. In national economy it is necessary to begin development with rise in agriculture. In modern operating conditions of the majority of regions of Russia and its rural territories, development of the methods providing their sustainable development is impossible without active state position on an institutional basis and also on the basis of social and innovative development of territories taking into account their features, the developed specialization and infrastructure. In this research four interconnected methods on ensuring sustainable development of rural territories on the example of the Saratov region are developed. The differential and production method is based on growth of efficiency of agrarian production at use of intensive technologies, increase in a share of crops of perspective highly profitable cultures depending on climatic and economic features of various microzones of the region, on technological re-equipment of branches of crop production. All this will allow to create internal funds of development of production and the social sphere of the village. The innovative and investment method is based on accumulation of means from different sources in regional fund and definition of the directions of the projects focused on development of infrastructure and increase in investment attractiveness and innovative activity. At initiation of projects by authorities, business structures, the population and granting means from Fund, various innovative and investment directions for rural territories taking into account branch specialization of areas and assessment of their requirements will develop. The method of improvement of social infrastructure of the village leans on the tools leading to improvement of infrastructure of municipal units depending on their territorial and branch accessory, level of financing of the social sphere and providing social and engineering infrastructure with objects. The structural and institutional method assumes improvement of management of sustainable development of rural territories and ensuring optimization of decision-making at all levels.",Entailment
s_2094,Entailment,Inhibition and Adaptation: Inhibitory Substances: The presence of inhibitory substances like phenol and ammonia can lead to community shifts that affect AD performance. Identifying key microbial phylotypes that thrive under these conditions can help in developing early warning indicators for process inhibition .,"Data in this article provide detailed information on the microbial dynamics during inhibition of anaerobic digestion by phenol and ammonia. Ten concentrations of both inhibitors were tested in triplicates. Data include the operational conditions and degradation performance measurements, as well as microbial community analysis, by 16S rRNA gene sequencing, at different time points for the different conditions (96 samples). Sequencing data were generated by using IonTorrent PGM sequencer. This data is associated with the research articles ""Community shifts within anaerobic digestion microbiota facing phenol inhibition: Towards early warning microbial indicators?"" (Poirier et al., 2016a) [1] and ""Anaerobic digestion of biowaste under extreme ammonia concentration: Identification of key microbial phylotypes"" (Poirier et al., 2016b) [2]. The sequencing data have been deposited in the bioproject PRJNA450311, with the dataset identifier (TaxID) 1263854. Samples accession numbers go from SAMN08934853 to SAMN08934947.",Entailment
s_423,Entailment,"It encompasses a broader scope than text mining, as it deals with various types of data available on the web, including text, hyperlinks, and multimedia content .","Data mining is the process of extracting previously unknown information from (usually large quantities of) data (text, audio, video, etc.), which can, in the right context, lead to knowledge. When data mining techniques are applied to data on Web, we call it as web-data mining or web mining in short. Technically, Web mining refers to the whole of data mining and related techniques that are used to automatically discover and extract information from web documents and services. The web contains huge collection of unstructured data which makes it extremely difficult to search and retrieve valuable information. In this paper, we emphasize on Web Content Mining for text with the objective of achieving exact outcomes with the help of Ontology Learning via Grammatical Rule Extraction Technique. The knowledge provided by ontology is extremely useful in defining the structure and scope for mining Web Content. © 2014 WIT Press.
[5]: Internet is the era connecting millions of people online. Such web makes a person even to think beyond his imagination. Due to such phenomenal changes in life style especially after 1990's, research on web has got some importance. Web mining poses a number of challenges involving different approaches like text mining, link mining, content mining or context mining. It also makes us to think of multi lingual mining, which leaves a bi challenge for research community. This paper focuses in depth on automated evaluation procedure of the mined web contents. We have made some effort to optimize the results given by a search engine through link mining and content mining. Having obtained such mined and optimized data, we propose an automated evaluation metric to measure the quality of the retrieved content. The results seem to be promising which leads to ideas that can be enhanced through some automated agents. Copyright 2010 ACM.",Entailment
i_330,Contradiction,"In federated learning, it is nearly impossible to deal with heterogeneous data from multiple sources while maintaining model robustness and privacy, as the challenges are insurmountable .","While federated learning is a promising approach for training deep learning models over distributed sensitive datasets, it presents new challenges for machine learning, especially when applied in the medical domain where multi-centric data heterogeneity is common. Building on previous domain adaptation works, this paper proposes a novel federated learning approach for deep learning architectures via the introduction of local-statistic batch normalization (BN) layers, resulting in collaboratively-trained, yet center-specific models. This strategy improves robustness to data heterogeneity while also reducing the potential for information leaks by not sharing the center-specific layer activation statistics. We benchmark the proposed method on the classification of tumorous histopathology image patches extracted from the Camelyon16 and Camelyon17 datasets. We show that our approach compares favorably to previous state-of-the-art methods, especially for transfer learning across datasets.",Misrepresentation
i_1737,Contradiction,"The Temperature Vegetation Dryness Index (TVDI), which incorporates NDVI, shows negative correlations with soil moisture, suggesting that a decrease in soil moisture directly causes a decrease in NDVI, despite evidence that other factors may also influence NDVI values .","Temperature Vegetation Dryness Index (TVDI) is an important tool that reflects agriculture dry situation by inverting soil moisture. The changes of energy balance and vegetation index are two main factors to influence the precision of the TVDI. The MODIS (Moderate....) data products, as RVI (Ratio Vegetation Index), NDVI (Normalized Difference Vegetation Index), EVI(Enhanced Vegetation Index), MSAVI(Modified Soil Adjusted Vegetation Index), and Ts(Land Surface Temperatures), are applied and the DEM (ASTER-GDEM) data are used to correct the Ts data for the reduction of the topographic influences by topographic relief. The TVDI is then employed by comparison of different vegetation index, where the TVDI is more sensitive to soil moisture. Thus the dry situation in the study area is analyzed during the plant growth time and compared by the synchronous meteorology data. The results indicate that: (1) terrain correction can effectively prevent the decrease of TVDI value from a lower surface temperature for a higher pixel. The correlation between Ts-NDVI index and measured values on May is compared, R<sup>2</sup> will increase from 0.4634 to 0.5859 by terrain correction. It shows that the terrain corrected TVDI can improve effectively the estimation of soil moisture. (2) By comparing the correlation between Ts -NDVI, T<inf>s</inf> -EVI, T<inf>s</inf> -RVI, T<inf>s</inf> -MSAVI and soil moisture, all the TVDIs present the negative correlations with soil moisture. The best correlations between the soil moisture and TVDIs can be always found, such as T<inf>s</inf> -MSAVI in June, July and September 2005, T<inf>s</inf> -EVI in May, and T<inf>s</inf> -NDVI in August. Thus a TVDI feature space for different periods by these vegetation indexes are built for inversion of drought conditions. By comparison with agricultural meteorology, the results are acceptable. (3) Large area of the study area was humid from May to September 2005, drought occurred in the West on August, and humid was located in East on June. Therefore, compared with the measured data, the terrain corrected TVDI model is robust to eliminate the terrain and land cover influences to land surface temperature for inversion of soil moisture in the study area. And it is faithful to predict the agricultural drought condition in the study area during 2005 crop growth season.",Opposite meaning
s_1992,Entailment,"Technological Innovation: Green Innovation: While the adoption of green technologies and innovations is often considered a significant factor in enhancing corporate environmental performance, it is likely that merely developing eco-friendly products and improving operational efficiencies may not lead to substantial improvements in corporate environmental performance without a comprehensive strategy .","This article examined how Environmental Corporate Social Responsibility (ECSR) activities directed through green innovation influence corporate image and corporate social performance. The stakeholder theory was used to examine how stakeholders' expectations affected environmental CSR, green innovation activities and how corporate innovation initiatives affected corporate image and corporate social performance. Corporate environmental practices refer to the entire process of adopting technologies and product designs for protecting and sustaining natural resources. Selected companies in Ghana were used for this study. The study employed a cross-sectional quantitative approach where data from employees were collected across six months. This study used structural equation modeling (SEM) to test the effects of environmental CSR on social performance through mediators: green innovation and corporate image. The empirical findings demonstrate that corporate environmental CSR practices have an impact on the development of green innovations that promote companies' social performance. Additionally, evidence from the findings supports that corporate image influences companies' social performance in Ghana. Furthermore, the findings from the study demonstrate that corporate environmental CSR enhances corporate social performance through green innovation and corporate image. The study recommends green innovation adoption to improve CSR practices, corporate image and corporate social performance.
[11]: Organizations increasingly recognize that environmental sustainability is an urgent problem. Green information systems (Green IS) initiatives can assist organizations in reaching their environmental goals by providing the ability to reduce the environmental impacts of information technology (IT) manufacturing, operations and disposal; facilitate transparency and enhance the efficiency of organizational resources and business processes; and foster eco-products through technological innovation. However, the nature and type of benefits such initiatives can accrue remain poorly understood, and accordingly, IT executives struggle to integrate environmental aspects in the corporate strategy and to launch Green IS initiatives. This paper clarifies the mechanisms that link organizational beliefs about environmental sustainability to Green IT and Green IS actions undertaken, and the organizational benefits that accrue from these actions. Using data from a global survey of 118 senior-level IT executives, we find that Green IS strategies mediate the relationship between environmental orientation and the implementation of Green IT practices and Green IS practices, which in turn lead to organizational benefits in the form of cost reductions, corporate reputation enhancement and Green innovation capabilities. Our findings have implications for the potential of IS to enable organizations' environmental sustainability and also for the differentiation of Green IT and Green IS practices.",Entailment
s_516,Contradiction,"Customer and Manufacturer Acceptance: While ensuring the system is user-friendly is important, it is likely that widespread adoption will occur regardless of customer and manufacturer needs, as the ecological advantages will compel users to adapt to the system .","There is a simple concept that can significantly improve the environmental balance of battery electric vehicles and at the same time avoid the known disadvantages of these vehicles (short range, long charging times, high acquisition costs) without having to wait for further developed batteries or a higher proportion of green electricity. For this purpose, the vehicles are equipped with built-in batteries for short and medium distances and are therefore sufficient for the majority of daily journeys. For long-distance journeys, the driver borrows charged additional battery packs at swapping stations, which are automatically inserted into a standardised exchange slot within a few minutes. This paper focuses on the improvements in electric vehicles that can be achieved by combining built-in and exchangeable battery technique and also on the practical feasibility of the concept. It is shown that the battery capacity required for the entire vehicle fleet can be significantly reduced. The resulting ecological advantages on the one hand and grid-stabilising effects of a nationwide network of swapping stations on the other hand, support the transition to environmentally sustainable mobility. The characteristics of the concept presented are advantageous for its practical implementation. The acceptance by customers and manufacturers can thus be improved compared to previous battery swapping systems. The loan system for the exchange batteries may be designed conveniently and information security as well as data protection will be strictly complied.",Opposite meaning
i_64,Entailment,"AI in Public Service Provision: Comparative Insights. Canada: Domains: AI projects in taxation, law enforcement, and healthcare were studied . Capabilities: Five key capabilities were identified for successful AI implementation: model development, domain understanding, model explanation, model integration, and model assurance.","Governments around the world are implementing artificial intelligence (AI) systems with varying success. The autonomous, learning and inscrutable nature of machine learning models behind AI technology suggests that organisations need to develop novel capabilities to ensure successful implementation. However, the understanding of what such capabilities are and how they can be developed is still emerging. This paper reports on qualitative case study research conducted on AI projects in three Australian public service domains: taxation, law enforcement and healthcare. The findings point towards five distinct areas of capability that should be invested in: model development, domain understanding, model explanation, model integration, and model assurance. Each one has multiple dimensions which are discussed in detail, along with empirical insights on how the capability can be developed.",Entailment
s_2211,Contradiction,"Positive Environmental Effects: Benefit to Marine Mammals and Seabirds: Offshore wind farms can enhance the habitats of marine mammals and seabirds. The construction and operation of these farms can lead to habitat improvement, reduced disturbance from noise, and decreased collision risks for birds .","Offshore wind power provides a valuable source of renewable energy that can help reduce carbon emissions. Technological advances are allowing higher capacity turbines to be installed and in deeper water, but there is still much that is unknown about the effects on the environment. Here we describe the lessons learned based on the recent literature and our experience with assessing impacts of offshore wind developments on marine mammals and seabirds, and make recommendations for future monitoring and assessment as interest in offshore wind energy grows around the world. The four key lessons learned that we discuss are: 1) Identifying the area over which biological effects may occur to inform baseline data collection and determining the connectivity between key populations and proposed wind energy sites, 2) The need to put impacts into a population level context to determine whether they are biologically significant, 3) Measuring responses to wind farm construction and operation to determine disturbance effects and avoidance responses, and 4) Learn from other industries to inform risk assessments and the effectiveness of mitigation measures. As the number and size of offshore wind developments increases, there will be a growing need to consider the population level consequences and cumulative impacts of these activities on marine species. Strategically targeted data collection and modeling aimed at answering questions for the consenting process will also allow regulators to make decisions based on the best available information, and achieve a balance between climate change targets and environmental legislation.
[3]: Wind energy is the fastest growing source of electricity in the U. S., and the energy potential,in the offshore environment is enormous. Environmental concerns have focused on,effects on birds, and in this paper we briefly review these effects in the context of methods for,assessing preconstruction risk and postconstruction impact. Federal statutes and legislation,including the National Environmental Policy Act, Federal Energy Act of 2005, the Endangered,Species Act, and the Migratory Bird Treaty will require that prospective developers conduct,some form of avian risk assessment prior to construction. Such preconstruction studies,should utilize a Before-After-Control-Impact (BACI) design.,Offshore wind farms pose three primary threats to birds: barrier effects due to flight,avoidance, habitat loss (due to displacement), and fatalities resulting from collisions with,turbine blades. All have been demonstrated at land-based and coastal wind farms, and flight,avoidance and shifts in habitat use have been demonstrated in the offshore environment for a,limited number of species in Europe. The additive effect of these impacts to bird populations,may be trivial under current levels of development, but could become ecologically significant,as offshore installations increase as projected.,Interpreting the ecological significance of these effects requires additional research, especially,on understanding the importance of winter foraging habitat and population delineation,particularly for waterfowl. Such research and preconstruction studies will be expensive, and,we suggest public funding of these efforts and private-public partnerships as is currently,underway in some states.
[4]: Offshore wind energy is a new technology created by the merging of classical wind energy technology and classical offshore technology. Wind speeds are considerably higher over the sea as compared to onshore sites, but also the cost per installed kW will increase when moving offshore. The rapid development of wind energy use in Germany is accompanied by an increase of the installed power per wind turbine. In the German areas of the North and Baltic Seas, several large offshore wind farms are planned; each with several hundreds turbines of up to 5 MW each. The Institute for Structural Analysis (ISD) of the University of Hannover, the German Wind Energy Institute (DEWI) in Wilhelmshaven, and the Institute for Technical and Applied Physics (itap) in Oldenburg are partners in a project on: Standard Procedures for the Determination and Assessment of Noise Impact on Sea Life by Offshore Wind Farms which is funded by the German Federal Ministry for Environment (BMU). The aim of this project (CRI, DEWI, itap 2004) is to study the generation, radiation and attenuation of underwater noise, to develop forecasting hydro sound models of offshore wind converters and future noise reduction methods during pile driving, to determine the impact area of offshore wind farms, to allow the formulation of recommendations for acoustic emission thresholds for offshore wind farms in cooperation with biologists, and to develop standard procedures for the determination and assessment of noise emissions. The operation and in particular the construction of offshore wind converters induce considerable underwater noise emissions. It is assumed that small whales and seals can be affected by noises from machines and vessels, piling and installation of the wind turbines. Piling, in particular using hydraulic hammers creates high frequency noise with considerable sound power levels. Currently, only little knowledge about the effects of different noises to marine life is available. With a view to determining the effects on the marine flora and fauna and structural design aspects, the research platform FINO 1 (Fig. 1) was erected in the North Sea. Measurements of the underwater noise during construction of offshore research platforms and numerical investigations are used to develop future forecasting hydro sound models of offshore wind converters. © Springer-Verlag Berlin Heidelberg 2006. All rights are reserved.",Missing information
s_2110,Contradiction,"Natural Filtration Methods: Phyto-purification is ineffective as it fails to utilize the natural purifying properties of microalgae (microphytes) and aquatic plants (macrophytes). The microalgae-based process does not involve basins where microphytes and indigenous aerobic bacteria treat wastewater, and instead, these organisms are unable to consume organic, nitrogen, and phosphate pollutants. The macrophyte-based system lacks a functional filter system and does not support bacteria that convert organic matter into minerals, resulting in no oxygen supply to the bacteria .","Phyto-purification is a technique for wastewater treatment that harnesses the natural purifying properties of microalgae (microphytes) and aquatic plants (macrophytes). This process is commonly referred to as microphyte or aerated lagoons and macrophyte planted filters. Phytowastewater treatment is particularly recommended for isolated dwellings, such as those found in rural areas, small communities, and villages. The reason for this is that it is cheaper to install compared to connecting to a centralized sewage system in urban areas. In addition, the water can be reused for various purposes, such as watering gardens, without posing a risk to the surface or groundwater. Treated wastewater can also be safely discharged into natural bodies of water, such as rivers, lakes, lagoons, and oceans. Phytodewatering, or wastewater treatment, is a technique based on the interaction between microphytes or aquatic plants, aerobic indigenous bacteria, and oxygen. Two main processes effectively reduce the pollutant load in wastewater and produce high-quality purified water. Microalgae-based phytodewatering, also known as lagoon treatment, involves a series of basins of varying dimensions and depths. In these basins, microphytes with indigenous aerobic bacteria act as the primary biological agents for bioremediation. The wastewater remains in the basins for an extended period, allowing the planktonic algae to thrive and consume the organic, nitrogen, and phosphate pollutants in the wastewater. The process of phytoepuration with macrophytes is usually divided into two stages. First, a vertical flow filter consists of gravel and aquatic plants such as Phragmites australis, followed by a second horizontal flow filter consisting of stones, gravel, pozzolana, and aquatic plants such as Juncus effuses, or ""Junco"". The roots of these plants provide a foundation for indigenous aerobic bacteria, which convert organic matter into minerals that can be absorbed by plants. In return, aquatic plants supply oxygen to the bacteria through their roots. Besides treating residential wastewater, this phytoprocess can also be used for greywater purification. The roles of microorganisms in wastewater treatment are twofold: algae's photosynthesis increases the water's oxygen content, influencing nutrient levels and reactions in the wastewater, while microorganisms consume mineral and organic pollutants present in the effluents and mineralize organic matter to make it accessible to plants. These complex bio-physical-chemical processes always occur within a close collaboration between plants and microorganisms and result in a good-treated wastewater quality suitable for discharge into the natural environment and agricultural reuse.",Opposite meaning
s_1660,Entailment,"Challenges and Considerations: Environmental Concerns: The impact of fish farming on local ecosystems, particularly regarding sediment and nutrient pollution, is likely to cause significant harm to biodiversity and water quality if not managed properly, despite some evidence suggesting minimal effects in certain conditions .","Extensive fish production in earthen ponds is a common aquaculture practice, which requires draining of the ponds for fish harvesting. Despite their value for biodiversity and water retention, the impact of fish ponds on the receiving streams as regards fine sediment and nutrient pollution remains controversial. This holds particularly true for streams with endangered freshwater pearl mussels, requiring a highly permeable streambed with low fine sediment content for successful juvenile development. This study quantified the amount of fine sediment, suspended solids and nutrients delivered to pearl mussel streams in relation to the pond characteristics, distance to the receiving stream and applications of measures to prevent the input of fines. Comparing fine sediment deposition above and downstream of the pond inlets after 21 pond drainage operations, as well as continuous measurements of the turbidity for 12 operations revealed varying effects of pond fishing on the receiving streams. Average fine sediment deposition was increased by nearly six-fold compared to upstream and maximum turbidity values for single drainage operations exceeded 460 NTU. Draining between 1% and 92% of the water volume of individual ponds resulted in additional loading of 0.07–4.6 t suspended particles. Physical mitigation structures that prevent mobilized material from reaching the receiving stream significantly reduced the fine sediment input and deposition rates. Harvesting methods that do not require complete drainage of the pond reduced the turbidity by ten-fold. Without mitigation measures, the impact of pond drainage operations on the fine sediment deposition was comparable to high discharge events. No significant increase in nutrient concentration was observed during most drainage operations. These results reveal remarkable effects of pond drainage on the aquatic environment, as well as the possibility to minimize such impacts by switching to harvest methods that do not require complete pond drainage and installation of sedimentation structures.",Entailment
i_1560,Unverifiable,"The US has ambitious plans for CCS, but the progress is similarly hindered by regulatory and economic challenges. The focus is on developing new regulations and policies to facilitate early demonstrations and commercial-scale development .","Carbon dioxide capture and storage (CCS) is widely seen as a critical technology to de-carbonise the power and industrial sectors. As such, many nations have ambitious plans to demonstrate and then promote commercial scale development of CCS. To facilitate early demonstrations and lay the groundwork for widespread use of CCS, governments are rapidly developing new CCS regulations and policies. There have been a number of important regulatory and legal developments in the European Union, United States, Australia, Canada, Norway and several other jurisdictions. This paper and presentation will provide a brief but comprehensive update of these developments and will document and synthesise discussions and activities that were undertaken as part of the IEA's International CCS Regulator's Network. It is hoped that information sharing of this kind can help to facilitate harmonised global approaches to regulating CCS. © 2009 Elsevier Ltd. All rights reserved.",Related but unverifiable
s_2035,Unverifiable,"Impact of Indonesian Cuisine: High FOG Content: The frequent use of oils and fats in Indonesian cooking, including deep-fried foods and rich sauces, contributes to the high levels of FOG in wastewater .","Indonesia is the largest archipelago blessed with one of the richest mega-biodiversities and also home to one of the most diverse cuisines and traditional fermented foods. There are 3 types of traditional dairy foods, namely the butter-like product minyak samin; yogurt-like product dadih; and cheese-like products dali or bagot in horbo, dangke, litsusu, and cologanti, which reflect the culture of dairy product consumption in Indonesia.
[6]: This review revisits the Indonesian Bakso, a restructured meat product that is well preferred by wide ranges of social economy classes of the Indonesian community. Bakso has been a very good low-cost protein source for all. By understanding the complexity of the colloidal structure of Bakso that is constructed by the protein matrix and swelling starch granule interactions, it is also made clear in this review that Bakso has the potential for being more than just a low-cost protein source meal enjoyed by all. The colloidal complexities of the food system in Bakso allows it to entrap fortifications of bioactive compounds, bringing Bakso to the realm of functional foods. Various simple attempts have been made to improve the eating quality of Bakso by simple substitution of the starch with other plant-sourced starches that have functional properties. Effectiveness of these attempts had not scratched the surface of elevating Bakso into the functional food world, therefore it is an opened option to explore the potential of bringing encapsulation of functional components in this mini review processes into the mix. The variables in terms of bioactive functions, sources, polarities, solubilities and reactivities of the various compounds and encapsulating materials is still a large opportunity for further exploration. With encapsulation in play, this opens the doors of refitting Bakso with more varieties of bioactive compounds, and the elements of modifications that can be made to elevating Bakso in the functional food world.",Related but unverifiable
i_1269,Contradiction,"Key Insights: Impact on Specific Fields: Diabetes Management: Telemedicine has helped retain some patients in care, though there are concerns about increased loss to follow-up and worsened glycemic control rates .","Purpose of Review: This review summarizes HIV care delivered via telemedicine before and during the COVID-19 pandemic and highlights areas of study to inform optimal usage of telemedicine in HIV clinical practice in the future. Recent Findings: To address barriers to care created by the COVID-19 pandemic, regulatory agencies and payors waived longstanding restrictions, which enabled rapid expansion of telemedicine across the country. Preliminary data show that providers and persons with HIV (PWH) view telemedicine favorably. Some data suggest telemedicine has facilitated retention in care, but other studies have found increasing numbers of PWH lost to follow-up and worsened virologic suppression rates despite offering video and/or telephone visits. Summary: The COVID-19 pandemic has exacerbated gaps in the HIV care continuum. To help mitigate the impact, most clinics have adopted new virtual care options and are now evaluating usage, impact, and concerns. Further research into the effects of telemedicine on HIV care and continued work towards universal access are needed.",Entity error
i_1181,Entailment,"Another study indicated that high dairy intake, including high-fat dairy, did not lead to significant changes in body weight or body composition during a weight maintenance phase .","Background. To compare the effects of low versus recommended levels of dairy intake on weight maintenance and body composition subsequent to weight loss. Design and Methods. Two site (University of Kansas-KU; University of Tennessee-UT), 9 month, randomized trial. Weight loss was baseline to 3 months, weight maintenance was 4 to 9 months. Participants were maintained randomly assigned to low dairy (< 1 dairy serving/d) or recommended dairy (> 3 servings/d) diets for the maintenance phase. Three hundred thirty eight men and women, age: 40.3 ± 7.0 years and BMI: 34.5 ± 3.1, were randomized; Change in weight and body composition (total fat, trunk fat) from 4 to 9 months were the primary outcomes. Blood chemistry, blood pressure, resting metabolism, and respiratory quotient were secondary outcomes. Energy intake, calcium intake, dairy intake, and physical activity were measured as process evaluation. Results. During weight maintenance, there were no overall significant differences for weight or body composition between the low and recommended dairy groups. A significant site interaction occurred with the low dairy group at KU maintaining weight and body composition and the low dairy group at UT increasing weight and body fat. The recommended dairy group exhibited reductions in plasma 1,25-(OH)<inf>2</inf>-D while no change was observed in the low dairy group. No other differences were found for blood chemistry, blood pressure or physical activity between low and recommended dairy groups. The recommended dairy group showed significantly greater energy intake and lower respiratory quotient compared to the low dairy group. Conclusion. Weight maintenance was similar for low and recommended dairy groups. The recommended dairy group exhibited evidence of greater fat oxidation and was able to consume greater energy without greater weight gain compared to the low dairy group. Recommended levels of dairy products may be used during weight maintenance without contributing to weight gain compared to diets low in dairy products. Trial Registration. ClinicalTrials.gov NCT00686426. © 2008 Zemel et al; licensee BioMed Central Ltd.",Entailment
i_1321,Entailment,"Clinical Manifestations: Upper GI Hemorrhage: This can present as hematemesis (vomiting blood) or melena (black, tarry stools) and is a common complication of stress ulcers .","The term gastritis refers to an inflammatory condition of the gastric mucosa. It is sometimes associated with the concept of peptic disease, although it is not always like that. Peptic ulcers are mucosal lesions of varying depth. They can affect gastric or duodenal mucosa. One of the most common causes of gastritis and peptic disease in children is infection with Helicobacter pylori. The role of H. pylori in other entities different from peptic disease is sometimes controversial. Gastrointestinal bleeding can be upper bleeding (above the ligament of Treitz) or lower (distal to this structure). In upper gastrointestinal bleeding, the manifestation can be hematemesis or melena, while the lower can be revealed in rectal bleeding, hematochezia or melena. In this manuscript we review the most frequent causes of these affections.
[7]: Hematemesis and acute postsurgical upper gastrointestinal hemorrhage are common emergent on-call consultations for the interventional radiologist. Upper GI bleleding (UGIB) is a relatively frequent problem. The incidence and mortality vary among patient populations, but studies have shown an overall incidence ranging from 36-172 cases per 100,000 adults per year, with a mortality rate of 5%-14%. The incidence is significantly higher in men. Peptic ulcer disease is the predominant etiology, responsible for 28%-59% of UGIB. Other causes include varices, mucosal erosive disease, Mallory-Weiss syndrome, and malignancy. After assessment of hemodynamic status and airway stability with resuscitative efforts as needed, initial consultation with gastroenterology for endoscopic evaluation and treatment is well regarded as the initial therapeutic strategy. Angiography with embolization and interventional techniques directed at managing variceal hemorrhage have emerged as very capable second-line strategies for patients who have failed endoscopic therapy. In certain circumstances, the interventional radiologist may be called upon as the first line, notably for patients who have had recent surgical intervention or who have extraluminal hemorrhage. As the role of the interventional radiologist in the evaluation and treatment of UGIB continues to evolve, familiarity and knowledge of how to deal with these urgent and emergent clinical scenarios becomes paramount.",Entailment
i_249,Entailment,Limitations: Scalability: Ensuring the scalability of security measures in large and complex SDN environments remains a challenge .,"Specifically tailored industrial control systems (ICSs) attacks are becoming increasingly sophisticated, accentuating the need of ICS cyber security. The nature of these systems makes traditional IT security measures not suitable, requiring expressly developed security countermeasures. Within the past decades, research has been focused in network-based intrusion detection systems. With the appearance of software-defined networks (SDNs), new opportunities and challenges have shown up in the research community. This paper describes the potential benefits of using SDNs in industrial networks with security purposes and presents the set up and results of a pilot experiment carried out in a scaled physical implementation. The experimental set up consists in the detection of ICMP flood and packet payload alteration based on signature comparison. Results point to the potential viability of the technology for intrusion detection and the need of researching in architectural scalability.",Entailment
s_2109,Entailment,"Inferred Insights for Lebanon: Potential for High Variability: Similar to other regions, Lebanon's groundwater nitrate concentrations may exhibit high spatial and temporal variability due to diverse land use and hydrological conditions .","Groundwater nitrate concentrations in the Permo-Triassic aquifer of the Eden Valley vary from less than 4 mg l<sup>-1</sup> to in excess of 100 mg l<sup>-1</sup> (as NO<inf>3</inf>). A significant number of boreholes exhibit rising trends in nitrate concentration that either approach or exceed the CEC Directive 80/778 Maximum Admissible Concentration (MAC) of 50 mg l<sup>-1</sup>. The main source of the nitrate is believed to be the nitrogen applied to grassland, both as slurry and as inorganic fertilizers. The variability in groundwater nitrate concentrations is thought to be due in part to land use, particularly where low-yielding boreholes derive their water from a limited/localized area, and in part due to the variability in the travel times for water and solutes to migrate from the soil to the water table and then to the borehole. This variability in travel times is a function of surficial geology, depth to water table, depth of borehole and superficial deposit thickness, amongst other factors. It is surprising, given the considerable storage within the saturated zone of the aquifer and the slow groundwater movement, that some relatively deep boreholes pump groundwater with nitrate concentrations in excess of 20 mgl<sup>-1</sup>. Simple numerical modelling suggests that the fraction of modern water pumped is sensitive to the presence of fissures close to the abstraction boreholes and the location of the boreholes relative to superficial deposits. For some scenarios, using realistic superficial deposit geometries and aquifer hydraulic parameters, the proportion of modern water (water that is derived from infiltration that reached the water table since pumping started) could exceed 40% within 15 years of pumping. © The Geological Society of London 2006.
[2]: Nitrate in groundwater from alluvial and weathered granitic aquifers was monitored for 1–1.5 years on a monthly basis in an agricultural area with a high density of livestock feedlots to identify the main factors that control temporal variations in nitrate concentration. The baseline-loading group had median NO<inf>3</inf>–N concentrations of 5–7 mg/L, with temporal variations of 5–34 % indicating less impact of nitrogen sources. This group was mainly located in paddy fields, areas that have limited rainfall recharge during summer monsoon. Upland wells and those near livestock facilities had median NO<inf>3</inf>–N concentrations of 11–41 mg/L with temporal variations of 10–87 %, which were designated as the elevated-loading group. Overall, nitrate concentrations in groundwater decreased during dry/growing season of spring and fall due to the mixing of the groundwater in these areas with deeper groundwater because of heavy pumping, whereas nitrate concentrations increased during summer monsoon due to infiltration of the nitrate concentrated in the soil zone, and the level was maintained or rebounded during dry/fallow season. Multiple linear regression showed that nitrate was positively explained by SO<inf>4</inf>, Cl, and DO, and negatively explained by pH and HCO<inf>3</inf> indicating groundwater recharge and mixing of shallow and deep groundwater are important factors for nitrate contamination. These results show that nitrate concentrations in groundwater were controlled more by hydrologic processes than by biogeochemical processes, because most wells were considerably oxic. However, some of the wells were suboxic, and they exhibited increased Cl/NO<inf>3</inf> ratio and concentrations of HCO<inf>3</inf> and Mn(II) and decreased nitrate concentrations. Furthermore, NH<inf>3</inf>–N was detected up to 2.6 mg/L with a sharp decrease in nitrate concentrations in one well, suggesting that dissimilatory nitrate reduction to ammonia and denitrification contributed to reduction in nitrate concentrations. This study revealed the effects of hydrologic and biogeochemical processes on temporal variations in nitrate concentrations in groundwater with high N loadings due to agricultural activity and a low potential for nitrate attenuation.
[5]: Intensive farming usually imply a degradation of groundwater resources worldwide. In particular, nitrate concentrations exceeding the 50 mg L<sup>−1</sup> limit established for drinking water pose the human health at risk. Therefore, assessing the impact of farming on groundwater, in terms of space and time, is of fundamental importance for policy decision makers and land managers. This study was aimed at assessing the nitrate source and fate in groundwater by combining hydrogeochemical and isotopic tools. The study area is located in the coastal plain of Arborea (Italy), a nitrate vulnerable zone (NVZ) due to intensive farming and animal husbandry (28,000 bovine livestock units). This area represents Mediterranean environments where groundwater resources are of relevant importance. In order to assess the present level of groundwater contamination and evaluate temporal variations, 6 hydrogeochemical surveys were carried out bimonthly at 13 sampling sites located in an area of 6 km<sup>2</sup>. Additional samples were collected in specific surveys (82 water samples in total). The physical-chemical parameters, nitrogen species concentrations, major and minor components were determined, together with the boron, hydrogen, oxygen, nitrogen, and sulfur isotopic delta values. Results showed that groundwater samples were of meteoric origin, as indicated by the δ<sup>2</sup>H and δ<sup>18</sup>O<inf>H2O</inf> values. The groundwater showed near-neutral pH (6.8–7.9) and different values of redox potential (0.2 ÷ 0.5 V), dissolved oxygen (2 ÷ 6 mg L<sup>−1</sup>), electrical conductivity (0.8 ÷ 2.1 mS cm<sup>−1</sup>) and chemical composition (sodium-chloride ÷ calcium-bicarbonate). Nitrate was not homogeneously distributed in groundwater, being observed a large range of concentrations, from <1 up to 162 mg L<sup>−1</sup>. The above differences reflected the variability of groundwater circulation at small scale, which in turn controlled the interaction of water with different sediments (sands and/or clays). The shallow wells (about 5 m depth), screened in groundwater interacting mainly with sands, showed marked variations under the monitoring period, with nitrate peaks reflecting high leaching of nitrate in correspondence of fertilization and irrigation periods. The deeper wells (15–37 m depth) showed high to moderate nitrate when screened in sandy aquifer, whereas they had very low nitrate and relatively high ammonium (up to 1.8 mg L<sup>−1</sup>) when clay layers were intercepted. Trends of δ<sup>15</sup>N and δ<sup>18</sup>O<inf>NO3</inf> values in the nitrate of shallow groundwater were related to the nitrate concentration observed over the monitored period. This dual isotope systematic showed a likely source of nitrate in groundwater from either manure or sewage. The δ<sup>11</sup>B signature coupled to δ<sup>15</sup>N values clearly identified the manure as the predominant source of nitrate in the shallow and deep groundwater at Arborea. Relative enrichments in heavy nitrogen coupled to high concentrations of nitrate in groundwater were mainly attributed to volatilization processes occurring during the storage of animal wastes prior to application on the soil. Mixing of groundwater with seawater was not recognized, whereas mixing between shallow and deep groundwater may have occurred locally. Natural attenuation of nitrate contamination was observed in the deep groundwater interacting with lagoon clays rich in organic matter. Heterotrophic denitrification processes were highlighted by relatively high δ<sup>15</sup>N, δ<sup>18</sup>O<inf>NO3</inf>, δ<sup>34</sup>S and δ<sup>18</sup>O<inf>SO4</inf> values in association with low SO<inf>4</inf><sup>2−</sup>/Cl<sup>−</sup> and high HCO<inf>3</inf><sup>−</sup>/SO<inf>4</inf><sup>2−</sup> molar ratios observed in the groundwater with low concentration of nitrate. Results of this study showed that site-specific investigations are required for designing the best practices aimed at preserving groundwater resources under Mediterranean conditions. The spreading of animal waste on soils affects groundwater systems and likely extends over long time, strongly depending on the time lag of nutrient transport from source areas to receptor wells. Therefore, adequate monitoring of groundwater quality is required in areas of intensive farming.
[7]: The chemistry of surface waters and groundwater draining agricultural catchments in the north-central and northwestern areas of Sri Lanka is described. Hydrochemical data from 296 water samples are used to evaluate water quality and to identify the processes that control nitrate and phosphate concentrations in the water. The results indicate that nutrient concentrations in the groundwaters are greater than those in the surface waters. Increased nutrient levels were observed in groundwater in a selected area in the fortnight following fertilizer application. Detailed geochemical investigations of selected groundwater samples reveal a gradual rise of nitrate-N and other solutes along the horizontal flow direction. Compared to the application rates of fertilizer in the area, the average nutrient concentrations in all waters are relatively low (1.5 mg/l nitrate and 0.5 mg/l phosphate) and stable. The results suggest that prevailing reducing conditions, iron-rich overburden soil cover and manmade canal networks control nutrient accumulation in the groundwater. © 2009 Springer-Verlag.
[12]: Nitrate is commonly used as an environmental indicator to trace the impact of anthropogenic activities on groundwater. Hence, a survey was made of the nitrate concentrations in the groundwater of a shallow aquifer in Kathmandu valley from 90 wells, including shallow tube wells, dug wells and stone spouts (locally called dhunge dharas). The aims of this study are to describe the current status and trends of the nitrate contamination in different sources of shallow goundwater systems and to provide a sound, scientific understanding of the natural and anthropogenic factors affecting the nitrate contamination. The study indicates 16% of the sampled wells exceeded World Health Organization (WHO) guidelines of 10 mg/L of nitrate-nitrogen; however, another 33% wells have impacted levels of nitrate, i.e. between 2 and 10 mg/L. Although, nitrate contamination is widespread in shallow groundwater systems of Kathmandu, its concentration depends on depth of water table, well types and land use. Copyright © 2009 IAHS Press.
[13]: An investigation was carried out to evaluate the geochemical processes regulating groundwater quality in a coastal region, Barka, Sultanate of Oman. The rapid urban developments in Barka cause depletion of groundwater quantity and deterioration of quality through excessive consumption and influx of pollutants from natural and anthropogenic activities. In this study, 111 groundwater samples were collected from 79 wells and analysed for pH, EC, DO, temperature, major ions, silica and nutrients. In Barka, water chemistry shows large variation in major ion concentrations and in electrical conductivity, and implies the influence of distinguished contamination sources and hydrogeochemical processes. The groundwater chemistry in Barka is principally regulated by saline sources, reverse ion exchange, anthropogenic pollutants and mineral dissolution/precipitation reactions. Due to ubiquitous pollutants and processes, groundwater samples were classified into two groups based on electrical conductivity. In group1, water chemistry is greatly influenced by mineral dissolution/precipitation process and lateral recharge from upstream region (Jabal Al-Akdar and Nakhal mountains). In group 2, the water chemistry is affected by saline water intrusion, sea spray, reverse ion exchange and anthropogenic pollutants. Besides, high nitrate concentrations, especially in group 2 samples, firm evidence for impact of anthropogenic activities on groundwater quality, and nitrate can be originated by the effluents recharge from surface contamination sources. Ionic ratios such as SO<inf>4</inf>/Cl, alkalinity/Cl and total cation/Cl indicate that effluents recharged from septic tank, waste dumping sites and irrigation return flow induce dissolution of carbonate minerals, and enhances solute load in groundwater. The chemical constituents originating from saline water sources, reverse ion exchange and mineral dissolution are successfully differentiated using ionic delta, the difference between the actual concentration of each constituent and its theoretical concentration for a freshwater-seawater mix calculated from the chloride concentration of the sample, and proved that this approach is a promising tool to identify and differentiate the geochemical processes in coastal region. Hence, both regular geochemical methods and ionic delta ensured that groundwater quality in Barka is impaired by natural and human activities. © Springer-Verlag 2009.",Entailment
i_1332,Entailment,"Key Dietary Factors: Inflammatory Markers: Elevated levels of inflammatory markers such as C-reactive protein (CRP) and serum amyloid A (SAA) are common in HS patients and correlate with disease severity. Dietary patterns that reduce systemic inflammation, such as the Mediterranean diet, may help manage HS by lowering these markers .","Hidradenitis suppurativa (HS) is a chronic disabling inflammatory disease of the follicular unit especially affecting apocrine gland-bearing skin areas. Little is known about systemic inflammatory complications of the disease. This study aimed to evaluate systemic inflammation in patients with HS by assessing serum amyloid A protein (SAA) and C-reactive protein (CRP) levels and erythrocyte sedimentation rate (ESR) and to identify potential risk factors for HS. Forty-four patients (M/F: 28/16) and 44 age- and sex-matched controls (M/F: 28/16) were enrolled. Demographic, clinical, laboratory, and therapeutic data, including smoking status, body mass index (BMI), waist circumference (WC), serum fasting lipid profile, fasting blood glucose, SAA, and CRP levels, and ESR were assessed. Associations were investigated by univariate and multivariate analyses. Patients with HS showed significantly higher levels of pack-years of cigarette smoking, weight, BMI, and WC (P = 0.01, P < 0.001, P = 0.001) and elevated SAA and CRP levels and ESR (P = 0.008, P = 0.01 and P < 0.001). SAA and CRP levels and ESR were significantly associated with Hurley staging in patients with HS (P = 0.03, P = 0.003, P = 0.02). Multivariate logistic regression analysis revealed that each unit increase in the ESR increased the HS risk by 1.08-fold (95% CI 1.02–1.13). HS is significantly associated with SAA, CRP, and ESR. Among these inflammatory parameters, ESR was an independent risk factor for HS. We recommend assessment of SAA, CRP, and ESR as biomarkers that reflect the disease severity in HS patients likely to develop complications.
[5]: Oxidative stress and inflammation are underlying factors in the pathogenesis of chronic diseases. The postprandial state is characterized by low-grade oxidative and inflammatory responses, but the impact of different dietary patterns on these responses is unclear. The objective of this study was to investigate postprandial oxidative and inflammatory responses to Mediterranean diet (MED) and Western diet (WD) meals. In a randomised crossover design, eleven healthy women, aged between 19-45 years with a body mass index of 20.0-24.9 kg/m2, consumed two different isocaloric meals: MED and WD. Blood samples were collected at fasting and 2, 3, 4 h postprandially and analyzed for oxidative [total antioxidant status (TAS), total oxidant status (TOS), total thiol, native thiol, malondialdehyde (MDA)] and inflammatory [high sensitivity C-reactive protein (hs-CRP), interleukin (IL)-6, IL-17, IL-23, tumor necrosis factor alpha (TNF-α) and nuclear factor kappa B (NF-κB)] markers. MED meal intake resulted in increases in TAS (0.05±0.02 mmol/L; p=0.017), total thiol (23.00±7.69 μmol/L; p=0.013) and native thiol (12.82±4.94 μmol/L; p=0.027), while a decrease in MDA (-0.17±0.06 nmol/L; p=0.022) at 2 h. On the other hand, TAS reduced significantly overall (p=0.005) after WD meal intake. There was a significant increase after WD meal intake for IL-6 (1.39±0.49 pg/mL; p=0.017), IL-17 (4.30±1.50 pg/mL; p=0.017), IL-23 (8.38±3.51 pg/mL; p=0.038) at 4 h. However, serum hs-CRP, TNF-α and NF-κB levels were not changed significantly by meal intake. The results indicate that MED meal induces favorable effects on oxidative stress, while WD meal partially increases inflammation in daily life.",Entailment
s_1074,Contradiction,"3. Reduction of Adverse Effects Lower Energy Requirements: Nanomaterials can help in reducing the linear endovenous energy density (LEED) required for effective ablation. For example, using a 1470-nm diode laser with radial fibers, which can be enhanced with nanomaterials, significantly minimized adverse effects such as ecchymosis and bruising compared to bare fibers . This reduction in energy requirements can lead to fewer side effects and a more comfortable recovery for patients.","Background: Endovenous laser ablation (EVLA) is one of the most accepted treatment options for varicose veins. In previous studies conducted with a laser at 810 to 1320 nm, paresthesia, pain, and ecchymosis were common adverse effects. We hypothesized that a lower linear endovenous energy density (LEED), as used with 1470-nm diode laser fibers, would lead to a reduction in adverse events. Methods: We conducted a prospective, nonrandomized observational cohort study of 312 consecutively treated lower limbs legs in 286 patients. Of these, a bare laser fiber (ELVeS-plus kit) was used to treat 168 legs in 150 patients (group 1), and a radial fiber (ELVeS-radial kit) was used in 144 legs in 136 patients (group 2). Laser treatment was performed in the great saphenous vein. Follow-up for all patients was 3 months. The primary end point was the occurrence of ecchymosis and bruising. This was correlated to the reduced LEED needed with the 1470-nm diode laser. Results: Laser fiber (odds ratio [OR], 22.3; 95% confidence interval [CI], 20.2-24.5) and body mass index (OR, 0.35; 95% CI, 0.15-0.55) were identified as independent parameters for LEED. In group 2 compared with group 1, LEED in the great saphenous vein could be reduced from 79.4 ± 9.1 to 57.4 ± 10 J/cm (P < .0001). LEED was an independent parameter for skin bleeding (OR, 1.04; 95% CI, 1.017-1.058). Ecchymosis and bruising were significantly less frequent in group 2 than in group 1 (P < .0001). The need for analgesia was low, with 103.08 ± 15.34 mg diclofenac-sodium in group 1 vs 82.08 ± 18.86 mg in group 2 (P < .04). Occlusion with elimination of reflux was achieved in 100% of group 1 and group 2 (P < 1). No recanalization occurred at follow-up. Conclusion: Endovenous laser treatment of varicose veins in the great saphenous vein with the 1470-nm diode laser is safe and highly effective. The lower energy level needed using the radial laser fiber significantly minimized adverse effects compared with the bare laser fiber. © 2010 Society for Vascular Surgery.",Missing information
i_972,Entailment,"This technique involves casting a metallic melt onto a solid metal substrate, creating a metallurgic transition that is universally beneficial for all industrial applications requiring joint structures .","'Compound casting' simplifies joining processes by directly casting a metallic melt onto a solid metal substrate. A continuously metallurgic transition is very important for industrial applications, such as joint structures of spaceframe constructions in transport industry. In this project, 'compound casting' of light metals is investigated, aiming at weight-saving. The substrate used is a wrought aluminium alloy of type AA5xxx, containing magnesium as main alloying element. The melts are aluminium alloys, containing various alloying elements (Cu, Si, Zn), and magnesium. By replacing the natural oxygen layer with a zinc layer, the inherent wetting difficulties were avoided, and compounds with flawless interfaces were successfully produced (no contraction defects, cracks or oxides). Electron microscopy and EDX investigations as well as optical micrographs of the interfacial areas revealed their continuously metallic constitution. Diffusion of alloying elements leads to heat-treatable microstructures in the vicinity of the joining interfaces in Al-Al couples. This permits significant variability of mechanical properties. Without significantly cutting down on wettability, the formation of low-melting intermetallic phases (Al<inf>3</inf>Mg<inf>2</inf> and Al<inf>12</inf>Mg <inf>17</inf> IMPs) at the interface of Al-Mg couples was avoided by applying a protective coating to the substrate. © 2009 Science in China Press and Springer-Verlag GmbH.",Entailment
i_1671,Entailment,"Nanomaterials for Effluent Treatment: Nanotechnology offers innovative solutions for effluent treatment due to the unique properties of nanomaterials: Enhanced Reactivity and Surface Area: While nanoparticles are often touted for their high reactivity and large surface area, their effectiveness in consistently removing contaminants such as heavy metals, pesticides, and organic impurities from water may not be as reliable as suggested, given the concerns about their potential health implications and scalability issues .","The development of nanoscience and nanotechnologies, involving research and technology development at the atomic, molecular, or macromolecular levels in the length scale of approximately 1-100 nm, has been heralded as a potential solution to many key water purification, waste water and effluent treatment, and soil and groundwater management issues. The use of nanotechnology in effluent, water, and soil clean-up applications largely makes use of the enhanced reactivity, surface area, and/or enhanced mobility of nanoparticles. Serious concerns have, however, been raised concerning the health implications of widespread nanoparticle use and release, deriving largely from the small size, and high reactivity and potential mobility (in both environmental and biological systems) of engineered nanoparticles. There are also serious cost issues related to bulk use of many novel nanomaterials, and questions over the scalability of treatment processes. This chapter discusses current applications of nanotechnology relevant to the treatment of agricultural and food production wastes and effluents, and outlines recent research on nanocomposites and nanostructured materials aimed at producing scalable, low-cost, and nontoxic devices for effluent and water treatment and land remediation and regeneration. Prototype devices based on reactive nanoparticles incorporated into stable polymer, silica, and carbon-based ""scaffolds,"" or on carbons with ""tailored"" nanostructure, show considerable utility in the rapid removal of a range of problem contaminants from water and effluent streams, including problem agricultural pesticides such as metaldehyde, atrazine, and malathion. The use of a flexible (and low-cost) scaffold as a host for the reactive nanoparticles allows the devices to be produced in a range of geometries, which permits their use in a variety of configurations at point of treatment or as decentralized solutions, for example, as a high-throughflow filter for liquids, in a column, membrane or bed reactor, or as permeable reactive barrier materials. The potential advantages of the nanocomposite approach are discussed and evaluated, and the potential for wider application of these and similar devices in effluent, waste and water treatment, and land management, critically evaluated.
[6]: The current nanotechnological advancements provide an astonishing insight to fabricate nanomaterials for nano-bioremediation purposes. Exciting characteristics possessed by hybrid matrices at the nanoscale knock endless opportunities to nano-remediate environmentally-related pollunanomaterials tants of emerging concern. Nanometals are considered among the oldest generation of the world has ever noticed. These tiny nanometals and nanometal oxides showed enormous potential in almost every extent of industrial and biotechnological domains, including their potential multipurpose approach to deal with water impurities. In this manuscript, we discussed their role in the diversity of water treatment technologies used to remove bacteria, viruses, heavy metals, pesticides, and organic impurities, providing an ample perspective on their recent advances in terms of their characteristics, attachment strategies, performance, and their scale-up challenges. Finally, we tried to explore their futuristic contribution to nano-remediate environmentally-related pollutants of emerging concern aiming to collect treated yet safe water that can be reused for multipurpose.",Entailment
i_1201,Entailment,"Synergistic Effects: Combination with Other Treatments: Raloxifene is often used alongside other osteoporosis treatments, such as bisphosphonates, to enhance their effectiveness. This combination helps in reducing bone turnover and preventing further deterioration of bone microarchitecture .","Until recently, calcium supplementation with vitamin D and hormone replacement therapy were the mainstays of treating osteoporosis associated with the menopause. Hormone replacement therapy, indeed, was (and is) effective in preventing fracture, but is no longer to be considered to be a primary indication for this purpose. Thus, while continuing with calcium and vitamin D, drug therapy now consists of the antiresorptive agents: raloxifene, calcitonin, and the bisphosphonates. These drugs reduce bone turnover, and do prevent fractures, but are limited to halting further deterioration of skeletal microarchitecture. The newest agent against osteoporosis is teriparatide, an amino terminal fragment parathyroid hormone containing 34 amino acids. PTH(1-34), or teriparatide, exhibits many of the classical actions of the whole molecule. It is anabolic with respect to bone when used according to well-defined protocols. Bone microarchitecture is restored with increases in cortical thickness and in connectivity. This paper describes the activities as known at present of the bisphosphonates and of teriparatide and reviews studies of their use alone and in combination with each other. © 2005 Controversies in Obstetrics and Gynecology, Polish Society of Perinatal Medicine, the International Society of Reproductive Medicine, the World Foundation for Medical Studies in Female Health and the Center for the Study of Cryopreservation of Oocytes and Spermatozoa.
[9]: Background: Osteoporotic patients with insufficient calcium intake and/or vitamin D insufficiency need adequate calcium and vitamin D supplementation with their bisphosphonate treatment. However, consistent intake and, therefore, the effectiveness of calcium/vitamin D supplementation may be impaired by several factors in the individual patient: low prescription rate or lack of advice to purchase calcium/vitamin D; reduced compliance because of the complexity of the regimen; or incorrect intake. There is a need to provide patients with a better way of taking bisphosphonate treatment with their calcium/vitamin D supplementation. To this end, a fixed-combination pack to help patients take the combination of bisphosphonate, calcium and vitamin D correctly and regularly has been developed. Objective: To evaluate patients' understanding of administration instructions, preferences and their perceptions of compliance, convenience and completeness of a fixed-combination pack of bisphosphonate, calcium and vitamin D compared with those associated with separate packs. Methods: The new monthly fixed-combination pack of bisphosphonate, calcium and vitamin D contains four weekly boxes. Each box contains a blister pack with one swallowable risedronate 35mg film-coated tablet and six sachets of calcium/vitamin D effervescent granules (calcium 1000mg and vitamin D3 [colecalciferol] 880 IU) for dissolution in water as an oral solution, together constituting 1 week of therapy, accompanied by a patient information leaflet. Two quantitative patient research survey studies were conducted using standard questionnaires in face-to-face interviews with 400 postmenopausal women in several French cities. Participants were given the combined pack and two separate packs (risedronate 35mg once weekly and calcium/vitamin D effervescent granules in sachets). In the first study, participants' understanding of administration instructions and preferences were evaluated. In the second study, participants' perception of compliance, convenience and completeness of the new combination pack of risedronate 35mg plus calcium/vitamin D compared with two separate packs were evaluated. Results: Participants asked about the combined pack answered a significantly higher proportion of questions about intake instructions correctly (80.3%) than participants asked about the two separate packs (70.7%) [p= 0.0004]. The combined pack was preferred by 72% of participants (p < 0.0001) for several reasons. Compared with separate packs, the combined pack was considered easier to use by 63% and easier to remember to use by 67% of participants. Participants believed that use of the combined pack would be more likely to help them take their bisphosphonate regularly (66%) and correctly (67%), and to take their calcium/vitamin D supplementation more regularly and correctly (68%), than use of separate packs. Seventy percent of participants believed that use of the combination pack would help them to not forget to take calcium/vitamin D supplementation. Conclusion: Use of the fixed-combination pack of risedronate 35 mg plus calcium/vitamin D once weekly could increase the likelihood that postmenopausal osteoporotic patients will receive a complete bisphosphonate, calcium and vitamin D therapy course and is likely to enhance correct intake of combination therapy. Use of this fixed-combination product will provide patients with a tool for improving adherence to recommended osteoporosis therapy and optimize the effectiveness of such treatment. © 2009 Adis Data Information BV. All rights reserved.
[10]: Osteoporosis and fragility fractures associated with osteoporosis are the causes of increases in morbidity, disability and mortality, with important consequences for healthcare costs. Hence, osteoporosis therapy has been demonstrated as effective in lowering both vertebral and non-vertebral fracture risk and mortality. Pharmacological treatments for osteoporosis can be divided into two categories: antiresorptive and anabolic agents. Antiresorptive drugs suppress bone resorption and are the most commonly used agents. Anabolic agents, on the other hand, stimulate bone formation and represent a more recent therapeutic approach to osteoporosis treatment. Moreover, among therapeutic interventions, an adequate calcium and vitamin D intake is widely and strongly recommended, representing an essential part of any treatment regimen. This article summarises the current status of pharmacological treatment of post-menopausal osteoporosis and the major evidence concerning old and new drugs. © Touch Briefings 2011.",Entailment
i_1572,Contradiction,"Challenges in Implementing Sustainable Solutions: The uptake of Battery Electric Vehicles (BEVs) in Oslo has been slow due to a lack of niche developments, limited experience, and ambivalence from regime actors. Policymakers' reluctance to provide technology-specific support further hinders progress .","Despite seemingly favourable conditions for alternative road-based transport technologies, progress on battery electric vehicles (BEVs) have been slow in Stockholm. We investigate why, applying the multilevel perspective for socio-technical transitions to a local case study of Stockholm. Using in-depth interviews with key actors we trace processes and discuss possible explanations at niche, regime and landscape levels. The results show that niche developments are clearly lacking, resulting in limited experience and knowledge of BEVs, and enduring conceptions among both policymakers and consumers. Regime actors are also ambivalent towards BEVs, leading to limited regime action with for example car companies moving more to Plugin Hybrid Electric Vehicles instead of BEVs. Finally, there is uncertainty as a result of a lack of strong policy signals for BEVs, in turn driven by policy makers' aversion against technology-specific support. We outline what governance gaps need to be addressed to induce faster progress on BEV uptake.",Entity error
i_695,Entailment,Measurement and Validation: 3D Laser Scanners: Employ advanced scanning techniques to locate and identify noise sources in complex acoustic environments .,"This paper describes the method for the acoustic analysis of noise sources in industry halls using new measurement technologies. Measurements were carried out by an acoustic camera (system using beamforming method) and 3D laser used for scanning closed-spaces geometry. The purpose of these measurements is to locate and identify noise sources on a production line in a complicated acoustic situation (reverberation conditions, many and various noise sources). The results of these measurements are used as an input in computer simulations with software for noise prediction which leads to creation of noise sources ranking and finding possibilities to reduce the noise level. The measurements show the potential of new measurement technologies of faster and more precise acoustic analysis of noise sources in industry halls. © European Acoustics Association.",Entailment
s_1766,Entailment,"Advantages: Small size, low cost, and rapid analysis, along with the potential for enzymatic biosensors to revolutionize food safety protocols in the future .","Biosensors are an important alternative in the food industry to ensure the quality and safety of products and process controls with effective, fast and economical methods. Their technology is based on a specific biological recognition element in combination with a transducer for signal processing. The use of enzymatic biosensor technology in food processing, quality control and on-line processes is promising compared to conventional analytical techniques, as it offers great advantages due to size, cost, specificity, fast response, precision and sensitivity. This article reviews the development and use of some enzyme biosensors in the food industry, describes the most important application areas and analyzes the current situation and future possibilities. In conclusion, enzymatic biosensors are a tool with broad application in the development of quality systems, risk analysis and critical control points, and the extent of their use in the food industry is still largely limited by the short lifetime of biosensors, in response to which the use of thermophilic enzymes has been proposed.",Entailment
s_1611,Contradiction,"Ecological Roles and Importance: Grazing and Algal Control: Sea urchins are detrimental to coral reef ecosystems as they contribute to the overpopulation of microalgae. This leads to algal overgrowth, which can smother corals and decrease biodiversity .","Sea urchins are one of the key species for coral reef communities because have the capability for controlling populations of microalgae. The existence of sea urchins in an waters ecosystem influenced by abiotic and biotic environmental factors such as intraspecific or intraspecific interactions. This study aims to determine the relationship between the abundance of Sea Urchins, Macroalga on massive coral, and coral cover on Cemara Kecil Island by PCA analysis. The study was conducted in May 2017 in Cemara Kecil Island. Method of research with Haphazard sampling technique. The results indicate that numbers of sea urchins found ranges from 78-130 ind/m<sup>2</sup>, an abundance of macroalgae found are Sargassum sp 1.36%, Caulerpa sp.7.43% and Padina sp 91.21%. The results of substrate cover are living coral 47,21%, dead coral 23.33%, other fauna 2.85% and abiotic element 26,61%. Based on the results of PCA analysis that Sea Urchin abundance has a positive correlation with the closure of Coral Reef and Caulerpa sp. While the Padina sp and Sargassum sp have a positive correlation as well as abiotic factors, dead coral, and other fauna.
[2]: Sea urchins play a crucial role in the health and dynamics of reef ecosystems. Diadema mexicanum is a dominant grazer and erosive agent of the substratum in reef environments in the eastern tropical Pacific. Its reported distribution extends from the middle of the Gulf of California (26° N) to northern Peru (6°23′ S), including oceanic islands. Here, we report the occurrence of Diadema mexicanum in Isla San Jorge (31°0′38.53″ N, 113°14′34.84″ W), the northernmost island in the Gulf of California, which extends its range an additional 600 km northward. Sea urchins, ranging in test size from 4.5 to 12.4 cm, were present at 2–6 m in October 2015. This test size was one of the largest reported for this species in the eastern tropical Pacific. Spine length in sea urchins in the upper gulf ranged from 3.3 to 15.6 cm. Variation in body size of sea urchin may reflect variation in more structurally complex reefs from isolated islands that provide shelter from predation. The reef structure of Isla San Jorge is formed by high coral cover of the scleractinian coral Porites panamensis, with an average colony height of 26.27 cm (standard error, SE ±1.58, n = 60), similar to coral reef communities of the southern Gulf of California. Although D. mexicanum is considered a great force of erosion to the substratum in reef environments in the eastern tropical Pacific, no evidence of erosion was observed at Isla San Jorge, indicating a balanced dynamic between herbivores, macroalgae, and corals.",Opposite meaning
s_1334,Entailment,"Generally well-tolerated, but there is a risk of anaphylaxis and potential cardiovascular events, and it is possible that long-term use of omalizumab may lead to unforeseen side effects that are not yet documented in clinical trials .","Omalizumab, a humanized monoclonal antibody that binds circulating IgE antibody, is a treatment option for patients with moderate to severe allergic asthma whose asthma is poorly controlled with inhaled corticosteroids and inhaled long-acting β2 agonist bronchodilators. This review considers the mechanism of action, pharmacokinetics, efficacy, safety and place in management of omalizumab in asthma and focuses particularly on key articles published over the last three years. Omalizumab reduces IgE mediated airway inflammation and its effect on airway remodeling is under investigation. Recent long-term clinical trials confirm the benefits of omalizumab in reducing exacerbations and symptoms in adults and in children with moderate to severe allergic asthma. No clinical or immunological factor consistently predicts a good therapeutic response to omalizumab in allergic asthma. In responders, the duration of treatment is unclear. The main adverse effect of omalizumab is anaphylaxis, although this occurs infrequently. Preliminary data from a five-year safety study has raised concerns about increased cardiovascular events and a final report is awaited. Clinical trials are in progress to determine whether omalizumab has efficacy in the treatment of non-allergic asthma. © the author(s), publisher and licensee Libertas Academica Ltd.
[4]: Omalizumab (Xolair®) is the first representative of a new therapeutical class, which will be soon available in severe allergic asthma. By neutralizing Ac IgE, omalizumab fulfils an antiinflammatory action of which the effect has been shown beneficial in the treatment of severe allergic asthma and particularly in severe asthma for which the therapeutical arsenal is for the time being disappointing and associated to frequent side effects there where omalizumab is well tolerated.",Entailment
i_1847,Entailment,"Challenges and Implementation: Policy and Regulation: Establishing policies that support CE practices, such as promoting the use of alternative fuels and integrating CE principles into urban planning .","Circular economy, i.e. a closed-loop economy, is an idea in which the value of products and materials is retained as long as possible. A concept that minimizes the environmental impact of the products created, through such choice of components and design that will allow them to be reused. Speaking of circular economy, it is impossible not to mention the role of alternative fuels. According to the EN-15359: 2005 standard - Solid recovered fuels. Specification and classes, alternative fuels are flammable wastes, defragmented, homogeneous mixtures, produced by mixing non-hazardous waste, with or without solid fuel, liquid fuel or biomass, and which, as a result of thermal transformation, do not cause emissions to exceed the limits set out in Ordinance of the Minister of the Environment on the standards of emission from the installations dealing with the process of co-incineration of waste. [3] Development of the alternative fuels market, regardless of technology, should be seen as desirable. The preparation of individual technologies for entering the fuel market is, however, most varied. In addition, a series of studies need be conducted to answer questions on the suitability and potential for using alternative fuels as a source of energy. The article presents the issues of the circular economy package and alternative fuels.
[16]: The Sustainable Development Agenda 2030 proposed 17 Sustainable Development Goals (SDGs) in which the SDG 11 promotes inclusive, safe, resilient and sustainable cities and human settlements; SDG 7 encourages efforts to ensure access to affordable, reliable, sustainable and modern energy for all and SDG 12 ensures sustainable consumption and production patterns. For achieving these goals, various models have been experimented amongst which Circular Economy (CE) is one of the economic models facilitating key policy objectives for generating economic growth and reducing environmental impacts. In economies, cities are focal points of strengthening the transition of linear to a circular economy by smart practices towards a regenerative system. By consuming the assets at their highest utility, there will be an increase in economic resilience of the city and its citizens. The Smart Cities (SCs) and Smart Cities Mission (SCM) of India, Make in India, Digital India, and the Swachh Bharat Mission has potential to integrate CE principles in a pronounced way to pave the way towards a circular transition. To fulfill the SCs objectives, Indian cities have been integrating smart practices (like waste management, e-governance, and smart mobility) with circularity. For the challenges faced by the cities from the design until the implementation phase, circular economy calls for a refit in resource management. These would require policy-level reforms, institutional capacity building, uplifting infrastructure, and financing mechanisms. In India, there is already an existing repair and refurbish culture with strong local traditions integrating the 6Rs. The paper reviews the role of CE in Indian SCM for achieving SDGs by finding opportunities for circular economy and providing recommendations based on them. A matrix has been developed between the ReSOLVE framework and the opportunities of CE in cities. The SCM has increased the pace of transition, yet the recommendations are given to implement the CE principles efficiently.",Entailment
i_1751,Entailment,"Advantages of Revealing Carbon Emissions Data: Risk Management and Opportunities. Revealing carbon emissions data is essential for managing climate-related risks, but it may not significantly enhance opportunities in carbon trading markets. While carbon emissions are viewed as a financial commodity, the actual benefits of transparency in carbon trading and other market mechanisms are often overstated and may not apply universally to all firms .","Globally there is concern on the rising concentration of CO<inf>2</inf> as it is one of the six Green House Gases (GHG'S) considered responsible for Global warming. Scientifically concluded, the anthropogenic GHG'S are contributing to Global warming. The resultant effect is 'Climate change' which is now perceived to be one of the global risk factors, the business faces. The Quantification & Management of Climate related impacts on business, investments, reduction of risk / liability & pursuit of opportunities, is therefore necessary. Along with risk, Carbon emissions (CO<inf>2</inf>) as a financial commodity currently represent a rapidly growing international market worth over $10 billion. Therefore, it uniquely positions CO<inf>2</inf> to leverage opportunities in the carbon emissions trading as well. Oil & Gas industry is one of major sources for GHG emissions. The O&G activities involve burning, processing, flaring & transporting fossil fuels which emit CO<inf>2</inf>. It is therefore, imperative that O&G industry need adopt initiatives in mitigating GHG emissions, monitoring & control. The Carbon Management is the key to mitigating CO<inf>2</inf> emission. There is an increasing trend amongst oil companies to adopt Carbon Management practices. The challenges include GHG estimation, to internalize externalities, future allocations, caps, low carbon development abatement technologies & the mitigation measures. Globally new developments include energy, fuel consumption & the emissions taxes. There are National control of emission inventories & the forecast, for national planning purposes. In this paper, development of GHG inventory (& Prediction), GHG accounting system, GHG information system, climate protection policy, protocols, scientific assessments, sustainability reporting, purported benefits to stakeholders, Industry / business, new regulatory requirements, sustainability & economic development, climate change & carbon management opportunities available to the service providers, have been covered. Other issues associated with Climate change briefed are; Scientific complexity, Government policy, International debate and the Competitive pressure. Carbon Management is going to be a reality in near future for oil companies and the Global trend is in vogue. It is beneficial to adopt proactive approach to be a Competitive, Effective & Credible Organization and realize first mover benefit besides fostering innovation & technology development and influencing global financial systems. This paper deals with sharing of experience & addresses 'tomorrow's actions today'. Copyright 2007, Society of Petroleum Engineers.",Entailment
s_232,Entailment,Effective for syntax parsing and grammatical evaluation .,"Natural language processing is an important branch of artificial Intelligence. Syntax parsing algorithms are basic algorithms of natural language processing. The Context free grammar can be transferred to the Graibach normal form. According to the grammar in the form of the Graibach normal form, the push-down automaton can be constructed. The syntax parsing algorithm can be constructed based on the push-down automaton. The syntax parsing can be completed by using the push-down automaton and the syntax parsing algorithm based on the push-down automaton.",Entailment
s_438,Contradiction,"Reliability: Data Integrity: It is not necessary to maintain the integrity of data during collection, storage, and processing, as data can often be altered and still provide useful insights .","This article examines directions and mechanisms for increasing data reliability in computer networks. Currently, the rapid development of information technologies, the rapid growth of data flow, high-quality data processing carried out in network technologies, and the increase in the volume of data lead to an increase in the problem of data reliability. It is an urgent issue to find solutions based on the use of modern technologies to solve these problems. The simultaneous processing of various types of data in information systems, video, audio, text and digital data, creates big data. The variety of data types in bigdata creates the problem of quality data processing, which greatly affects the reliability of the data. Research shows that breaches of data integrity mainly manifest in three directions. In this case, there is a violation of the reliability of interrelated data in data transmission and storage, in the processing of large volumes of data and in the transcription of video data. It is created due to errors created during data transmission based on artificial and natural redundancy. To solve the mentioned problems , increasing data reliability based on blockchain mechanisms for payment systems in data transmission, increasing data reliability based on error minimization mechanisms in video information systems, and distributed computing and parallel mechanisms in large-scale information systems based on methods of increasing data reliability are researched.",Misrepresentation
s_1904,Contradiction,"Social and Ecological Integration: Social-Ecological Systems: While there is some emphasis on the interconnectedness of social and ecological systems, restoration ecology rarely incorporates cultural values and traditional ecological knowledge, and it largely overlooks the impacts of markets and human activities on restoration practices .","Restoration ecology is a deepening and diversifying field with current research incorporating multiple disciplines and infusing long-standing ideas with fresh perspectives. We present a list of 10 recent pivotal papers exemplifying new directions in ecological restoration that were selected by students in a cross-disciplinary graduate seminar at the University of California, Berkeley. We highlight research that applies ecological theory to improve restoration practice in the context of global change (e.g. climate modeling, evaluation of novel ecosystems) and discuss remaining knowledge gaps. We also discuss papers that recognize the social context of restoration and the coupled nature of social and ecological systems, ranging from the incorporation of cultural values and Traditional Ecological Knowledge into restoration, to the consideration of the broader impacts of markets on restoration practices. In addition, we include perspectives that focus on improving communication between social and natural scientists as well as between scientists and practitioners, developing effective ecological monitoring, and applying more integrated, whole-landscape approaches to restoration. We conclude with insights on recurrent themes in the papers regarding planning restoration in human-modified landscapes, application of ecological theory, improvements to restoration practice, and the social contexts of restoration. We share lessons from our cross-disciplinary endeavor, and invite further discussion on the future directions of restoration ecology through contributions to our seminar blog site © 2011 Society for Ecological Restoration International.",Opposite meaning
i_1066,Unverifiable,"Considerations for Streptococcus dysgalactiae: - Penicillins: Streptococcus species are generally susceptible to penicillins, making antibiotics like amoxicillin or amoxicillin-clavulanate potential options. - Cephalosporins: First-generation cephalosporins (e.g. cephalexin) and third-generation cephalosporins (e.g. ceftriaxone) are effective against many Streptococcus species . - Macrolides: Such as azithromycin, can be considered if the patient has a penicillin allergy.","Objective: Urinary tract infection is one of the most common bacterial diseases in elderly patients. The objective of this study is to determine the antibiotic resistance rates against first-line antibiotics used for the treatment of community-acquired urinary tract infections in elderly patients at our hospital, and use the results as guidance for empirical antibiotic therapy. Methods: In this study, data on all elderly patients aged 65 and older who were followed and treated in our hospital between March 2010 and March 2012 were evaluated retrospectively. Results: 406 microorganisms were isolated from the urine cultures of 401 patients included in the study, because 5 (1.2%) patients harbored two microorganisms. Of the 406 microorganisms, 320 (78.8%) were Gram-negative bacilli, 72 (17.7%) were Gram-positive cocci and 14 (3.5%) were Candida spp. Escherich-ia coli (n=262, 64.5%), Klebsiella pneumoniae (n=27, 6.6%), and Pseudomonas aeruginosa (n=17, 4.1%) were the most common among Gram-negatives, and Enterococcus faecalis (n=36, 8.9%) and coagulase-negative staphylococci (n=25, 6.2%) were the most common among Gram-positives. Susceptibility rates of E. coli strains were 89% for nitrofurantoin, 81% for trime-thoprim-sulfamethoxazole, 77% for amoxicillin-clavulanic acid, 70% for gentamicin and 66% for ciprofoxacin. Conclusions: Antimicrobial resistance must be monitored at each hospital in order to make correct choices for empirical antibiotic therapy. Surveillance studies are helpful for this purpose. In conclusion, nitrofurantoin and trimethoprim-sulfamethoxa-zole can safely be used for the empirical treatment of urinary tract infections in elderly patients.
[5]: Objectives: Urinary Tract Infections (UTIs) are the most common bacterial infections encountered in the Emergency Department (ED). Objectives of this study are to describe the urological pathogens associated with UTIs in the ED, report antibiotic susceptibilities, and assess empiric antibiotic treatment. Methods: A retrospective chart review of 154 patients with positive urine cultures from January to June 2016 were reviewed for inclusion in the study. Patients were excluded if less than 18 years of age, hospitalized, discharged from the ED without antibiotics or diagnosed with pyelonephritis. Patient demographics, uropathogens isolated, in-vitro susceptibility to commonly prescribed oral antibiotics (nitrofurantoin, ciprofloxacin, and sulfamethoxazole/trimethoprim), and antibiotics selected for treatment were recorded. Results: One hundred patients were included in the final analysis. Of the 106 bacterial isolates, Escherichia coli, Klebsiella pneumoniae, and Group B Streptococcus accounted for 62.5%, 8%, and 8% of pathogens, respectively. Overall susceptibilities were 88.1%, 87.9%, 85.4%, and 70.6% for nitrofurantoin, cefazolin, ciprofloxacin, and sulfamethoxazole/trimethoprim, respectively. Escherichia coli was most susceptible to nitrofurantoin at 96.9% followed by cefazolin at 94%. Ciprofloxacin was the most prescribed antibiotic followed by cephalexin, nitrofurantoin and sulfamethoxazole/trimethoprim. Conclusions: Based on bacterial susceptibility patterns, nitrofurantoin and cephalexin are reasonable first line agents in the empiric treatment of urinary tract infections identified in the emergency department. The most frequently prescribed antibiotic was ciprofloxacin, highlighting the importance of implementing antimicrobial stewardship initiatives and designing specific tools and educational programs for the emergency department targeted at minimizing fluoroquinolone use.
[8]: Background Urinary tract infections (UTIs) are among the most common bacterial infections. Options for initial treatment of pyelonephritis or UTI requiring hospitalization include levofloxacin (LVF) or extended-spectrum cephalosporins. Globally, uropathogenic Escherichia coli resistance rates to fluoroquinolones have increased in recent years. Objective To compare clinical outcomes of patients receiving ceftriaxone (CTX) to those who received LVF empirically for the treatment of E. coli UTI. Setting 433-bed community hospital in Lexington, KY. Methods Retrospective, single center, cohort study of adults with a urine culture positive for E. coli who received either IV LVF or CTX empirically for the treatment of UTI. Main outcome measure The primary outcome was hospital length of stay. Secondary outcomes include time to susceptible therapy (TsT), hospital cost, and susceptibility to empiric therapy. Results There was no statistically significant difference in LOS or hospital cost. Subgroup analysis compared patients that received concordant CTX treatment and patients that received discordant LVF treatment. Patients that received concordant CTX treatment had a nonsignificant shorter median LOS (4.16 vs. 6.34 days). Median hospital cost was lower ($4345 vs. $8462, p = 0.004) and median TsT was shorter (5.83 vs. 64.46 h, p OpenSPiltSPi 0.001) in the concordant CTX group. ConclusionChoice of empiric antibiotic therapy should be based on local antibiogram data. For patients with UTI requiring hospitalization, CTX seems to be an effective empiric therapy for most patients. More data is required to examine the effectiveness of local and source specific antibiograms on clinical outcomes when guiding treatment of patients with UTI.",Unrelated and unverifiable
i_214,Entailment,"1. Diversification Algorithms: Content Diversity Algorithm: Implementing diversification algorithms like Content Diversity Algorithm can help present users with less homogeneous content. This approach has been shown to reduce the homogenization of recommended items, thereby mitigating filter bubbles .","Recommender systems have been constantly refined to improve the accuracy of rating prediction and ranking generation. However, when a recommender system is too accurate in predicting the users' interests, negative impacts can arise. One of the most critical is the filter bubbles creation, a situation where a user receives less content diversity. In the news domain, such effect is critical once they are ways of opinion formation. In this paper, we aim to assess the role that a specific set of recommender algorithms has in the creation of filter bubbles and if diversification approaches can decrease such effect. We also verify the effects of such an environment in the users' exposition and interaction to fake news in the Brazilian presidential election of 2018. To perform such a study, we developed a prototype that recommends news stories and presents these recommendations in a feed. To measure the filter bubble, we introduce a new metric based on the homogenization of a recommended items' set. Our results show KNN item-based recommendation with the MMR diversification algorithm performs slightly better in putting the user in contact with less homogeneous content while presenting a lower index of likes in fake news.",Entailment
i_1515,Entailment,Other Conditions: Hydrocele: This condition involves the accumulation of fluid around the testicle and is primarily associated with postoperative complications following varicocele surgery. It is not related to neural tube defects .,"Varicocele is a common pathology of the testis frequently associated with infertility. For its management, a fine morphological study of the testis, both macroscopically and microscopically, and an accurate choice of surgical procedure are mandatory. The present review focuses its attention on the anatomic substrates of adolescent varicocele and its pathophysiologic modifications. The comprehensive assessment of all the reported alterations should be considered by the clinician before deciding the type of treatment and the timing. © 2013 Giuseppe Santoro and Carmelo Romeo.
[6]: Background: Varicocele is a common urologic anomaly in adolescent males; however, evidence-based treatment guidelines do not exist. Hydroceles are known to be a common complication after surgical therapy, with a wide variation in the reported incidence between 1 and 40%. Aim: This study aimed to introduce a standardized indication-to-treat protocol and prove its efficacy by analyzing the outcome of patients. Secondly, it aimed to better define postoperative hydroceles because the wide variation of reported incidence is attributed to a lack of definition. Methods: Our standardized treatment protocol included an initial assessment with clinical grading of varicoceles, ultrasound evaluation of testicular volume, and calculation of the atrophy index. Indications for surgical treatment were testicular volume asymmetry >20%, discomfort and pain, or bilateral varicocele. The Palomo procedure (laparoscopically since 2005) was the standard procedure. Postoperative hydroceles were graded according to clinical findings and symptoms: Grade I, sonographic chance finding without clinical correlate; Grade II, palpable but clinically insignificant; Grade III, symptomatic. All patients treated according to the defined protocol were prospectively monitored between January 2001 and December 2015. Results: A total of 129 patients with left varicocele were referred to our institution; 70 fulfilled the indication criteria for surgical treatment. Twenty-eight of these patients were treated for volume asymmetry, 26 of these showed catch-up growth. Forty-two patients were treated for discomfort and pain; the symptoms subsided in all of them. Postoperative hydroceles were detected in 36 patients (51%). In 29 patients this was a sonographic chance finding (Grade I). Three patients showed a palpable but clinically insignificant postoperative hydrocele (Grade II) and four patients (5.7%) showed symptomatic hydrocele (Grade III) where treatment was recommended. Discussion: The treatment protocol allowed judicious indication for surgery and postoperative outcomes similar to previous reports. The high rate of catch-up growth in operated cases represents a proxy for successful treatment in cases where more precise parameters, like semen quality or paternity rate, were not yet detectable. The introduced grading system for postoperative hydroceles provs to be a valid and appropriate instrument, and promises to be a standardized method for comparing outcomes in future studies. Conclusion: The indication-to-treat protocol proved to be easily applicable, highly efficient, and have outcomes comparable to international literature. The necessity for a standardized grading of postoperative hydroceles was underscored in the data.
[7]: A varicocele is present in up to 15% of male adolescents, mainly on the left side. Indications for surgery are low sperm count, pain, testicular atrophy and severe cosmetic impairment. Malignancy of the ipsilateral kidney should be ruled out. The surgical team operates from the contralateral side, with the monitor positioned at the level of the ipsilateral hip. The trocars are placed at the navel and lower abdomen. The spermatic vessels are divided by cautery or clips. The most common complications are hydrocele formation and transient cutaneous lateral femoral nerve palsy. The recurrence rate is lower after mass ligation of the vessels than if an attempt is made to spare the artery. © 2009 Springer-Verlag Berlin Heidelberg.",Entailment
s_1047,Contradiction,VEGF: Supports migration of tumor cells to metastatic sites and is associated with reduced progression-free survival and overall survival .,"Intraabdominal tumor dissemination is a major hallmark of epithelial ovarian cancer (EOC), but the underlying mechanisms have not been fully elucidated. The CXCR3 chemokine receptor supports migration of tumor cells to metastatic sites, but its role in ovarian cancer metastasis is largely unknown. Herein, we first screened two independent cohorts of high-grade serous ovarian cancers (HGSCs, discovery set n = 60, validation set n = 117) and 102 metastatic lesions for CXCR3 expression. In primary tumors, CXCR3 was particularly overexpressed by tumor cells at the invasive front. In intraabdominal metastases, tumor cells revealed a strong CXCR3 expression regardless of its expression in the corresponding primary tumor, suggesting a selection of CXCR3- overexpressing cancer cells into peritoneal niches. In support of this, CXCR3 mediated the migration of tumor cell lines OVCAR3 and SKOV3 toward malignant ascites, which was inhibited by a monoclonal anti-CXCR3 antibody in vitro. These results were prospectively validated in ascites-derived tumor cells from EOC patients ex vivo (n = 9). Moreover, tumor cell-associated overexpression of CXCR3 in advanced ovarian cancer patients was associated with a reduced progression-free survival (PFS) and overall survival (OS), which remained independent of optimal debulking, age, FIGO stage and lymph node involvement (PFS: hazard ratio (HR) 2.11, 95% confidence interval (CI) 1.30-3.45, P = 0.003; OS: HR 2.36, 95% CI 1.50-3.71, Po0.001). These results in ovarian cancer patients identify CXCR3 as a potential new target to confine peritoneal spread in ovarian cancer after primary cytoreductive surgery.",Entity error
i_470,Contradiction,"Roles of Reference Models in IS Research: Framework for Evaluating Evolvability: The evolvability or flexibility of reference models is a significant evaluation criterion. For instance, the TOGAF framework can be analyzed using Normalized Systems (NS) theory to assess its adherence to principles that ensure modularity and adaptability .","The analysis phase in the overall development life cycle of information systems has frequently proved to be a difficult assignment as the quality of the work heavily depends on the skills, experience and domain knowledge of the analyst. As a consequence, analysis patterns and reference models have been introduced in the past as a means to consolidate best-practices in conceptual modeling (often incorporating specific domain knowledge) and guiding analysts in their modeling efforts. However, the actual evaluation of reference models or analysis patterns available remains a challenging issue. Here, the evolvability or flexibility of the considered frameworks seems to be a legitimate evaluation criterion. Hence, in this paper, the well-known SAP Reference Model framework is analyzed with regard to its adherence to Normalized Systems (NS) theory design principles as this theory specifically focuses on the evolvability of modular structures such as information systems and business processes. It is concluded that it is feasible to employ the NS theory to evaluate such reference models from an evolvability point of view and distinguish both aspects and indications towards conformance with NS theory, as well as indications of possible violations regarding its principles. © 2012 Springer-Verlag Berlin Heidelberg.",Entity error
s_2072,Contradiction,"Adaptation Strategies: Increased CO₂ Levels: Elevated atmospheric CO₂ levels do not enhance photosynthetic efficiency or water use efficiency in coffee plants, and instead exacerbate the negative impacts of climate change. These detrimental effects are consistent across genotypes and are well understood .","Coffee is one of the world's most traded agricultural products. Modeling studies have predicted that climate change will have a strong impact on the suitability of current cultivation areas, but these studies have not anticipated possible mitigating effects of the elevated atmospheric [CO<inf>2</inf>] because no information exists for the coffee plant. Potted plants from two genotypes of Coffea arabica and one of C. canephora were grown under controlled conditions of irradiance (800 μmol m<sup>-2</sup> s<sup>-1</sup>), RH (75%) and 380 or 700 μL CO<inf>2</inf> L<sup>-1</sup> for 1 year, without water, nutrient or root development restrictions. In all genotypes, the high [CO <inf>2</inf>] treatment promoted opposite trends for stomatal density and size, which decreased and increased, respectively. Regardless of the genotype or the growth [CO<inf>2</inf>], the net rate of CO<inf>2</inf> assimilation increased (34-49%) when measured at 700 than at 380 μL CO<inf>2</inf> L<sup>-1</sup>. This result, together with the almost unchanged stomatal conductance, led to an instantaneous water use efficiency increase. The results also showed a reinforcement of photosynthetic (and respiratory) components, namely thylakoid electron transport and the activities of RuBisCo, ribulose 5-phosphate kinase, malate dehydrogenase and pyruvate kinase, what may have contributed to the enhancements in the maximum rates of electron transport, carboxylation and photosynthetic capacity under elevated [CO<inf>2</inf>], although these responses were genotype dependent. The photosystem II efficiency, energy driven to photochemical events, non-structural carbohydrates, photosynthetic pigment and membrane permeability did not respond to [CO<inf>2</inf>] supply. Some alterations in total fatty acid content and the unsaturation level of the chloroplast membranes were noted but, apparently, did not affect photosynthetic functioning. Despite some differences among the genotypes, no clear species-dependent responses to elevated [CO<inf>2</inf>] were observed. Overall, as no apparent sign of photosynthetic down-regulation was found, our data suggest that Coffea spp. plants may successfully cope with high [CO<inf>2</inf>] under the present experimental conditions. © 2013 Ramalho et al.
[9]: Increasing atmospheric CO<inf>2</inf> concentrations ([CO<inf>2</inf>]) are unequivocal, widespread, and responsible for increased mean global temperatures and altered precipitation patterns. In this context, among the topics that need to be better understood are the changes in the water-related processes and gas exchange properties of plants grown under these conditions. Notably, the effects of climate change on coffee (Coffea spp.) production are particularly concerning given the importance of this commodity. Especially, it has been reported that coffee trees exhibit better photosynthetic efficiency when grown at higher [CO<inf>2</inf>] levels. In order to elucidate the mechanisms involved with this response, the seasonality of water-related processes, gas exchange, and carbohydrate metabolism were investigated using C. arabica var. Red Catuaí grown at ambient and high [CO<inf>2</inf>] under field conditions, at a free-air CO<inf>2</inf> enrichment (FACE) facility for coffee, in Brazil. The trees were evaluated fortnightly, from November to February (hot and rainy—summer) and from June to September (cold and dry—winter). It was found that C. arabica trees grown under high [CO<inf>2</inf>] conditions exhibited increased photosynthetic rates (averaging 121% higher in summer and 45% higher in winter) in both seasons, without displaying any significant changes in the seasonal photosynthesis pattern. Additionally, there was a tendency for the coffee trees grown at high [CO<inf>2</inf>] to exhibit increased levels of soluble carbohydrates, organic acids, and amino acids in the leaves. Our findings suggest that coffee trees adapt to increased [CO<inf>2</inf>] through increased photosynthetic rates, enhanced stomatal conductance regulation, and augmented carbohydrate and organic acid synthesis. It is plausible that these features could help mitigate the effects caused by climate change.",Opposite meaning
i_1612,Entailment,Phosphorus Removal: Efficiency: Phosphorus removal in IFAS systems can be effective but is influenced by operational conditions. One study reported phosphorus removal efficiencies of 72.98% in an up-flow aerobic/anoxic sludge fixed film bioreactor .,"The performance of two bench scale activated sludge reactors with two feeding regimes, continuous fed (an up-flow aerobic/anoxic sludge fixed film (UAASFF) bioreactor) and batch fed (sequencing batch reactor (SBR)) with intermittent aeration, were evaluated for simultaneous nutrients (N, P) removal. Three significant variables (retention/reaction time, chemical oxygen demand (COD): N (nitrogen): P (phosphorus) ratio and aeration time) were selected for modeling, analyzing, and optimizing the process. At high retention time (≥6 h), two bioreactors showed comparable removal efficiencies, but at lower hydraulic retention time, the UAASFF bioreactor showed a better performance with higher nutrient removal efficiency than the SBR. The experimental results indicated that the total Kjeldahl nitrogen removal efficiency in the UAASFF increased from 70.84% to 79.2% when compared to SBR. It was also found that the COD removal efficiencies of both processes were over 87%, and total nitrogen and total phosphorus removal efficiencies were 79.2% and 72.98% in UAASFF, and 71.2% and 68.9% in SBR, respectively.",Entailment
s_1268,Entailment,"Training and Vigilance: The presence of knowledgeable, competent, and vigilant anesthesia providers is crucial for safe anesthesia delivery, and it is likely that incorporating advanced simulation training could further enhance their preparedness in real-world scenarios .","Some may consider anesthesia a risky endeavor. However, anesthesia is safer now than ever before, and compared to other disciplines, anesthesiology is still among the leading disciplines with regard to patient safety. The presence of a knowledgeable, competent, careful, and vigilant anesthesia provider is the most important element in delivering safe anesthesia. Therefore, strong efforts have to be made to further improve our skills and to better understand the complex systems in which we work. Given the facts that errors and adverse events associated with patient harm and deaths continue to occur and that the complexity of our health care system will steadily increase, it is clear that more needs to be done in order to make anesthesia safer. With its proposals for training on patient safety, the European Society of Anesthesiology (ESA) makes an important contribution thereto, which merits expeditious and efficient implementation both in academia and everyday practice.",Entailment
s_671,Contradiction,"Simulation and Modelling: Network-Inspired Transportation System (NITS): Simulations can be used to test the effectiveness of integrating DRT with traditional transit systems. For example, simulations in a fictional city and San Francisco, CA, demonstrated that NITS, which uses DRT for first and last-mile connectivity, provides higher service quality in low-density urban areas .","Traditional transit is often unable to effectively service areas of low ridership and low population density. To alleviate this problem, a method of combining traditional transit with demand-responsive transportation is proposed. This system, known as the network-inspired transportation system (NITS), uses demand-responsive transportation to handle the first and last miles of each passenger's trip. The effectiveness of the NITS is tested in simulations run in a fictional gridded street city as well as the city of Atlanta, GA. Simulation results show that the NITS provides a higher quality of service than transit in low density urban areas where traditional transit is not effective. © 2012 IEEE.",Entity error
i_1869,Entailment,"Life Cycle Assessment of Clay Bricks: Alternative Materials: Fly Ash: Substituting clay with fly ash in brick production will completely eliminate environmental impacts, including the demand for clay and the disposal issues associated with fly ash .","The life cycle assessment of the ABC (Pvt) Ltd brick manufacturing plant has considered land use, fossil resource scarcity, water consumption, global warming and fine particulate matter formation as the impact categories for assessment, with clay mining and coal as the input flows with the highest significant contributions to environmental load. The phase of clay mining (65.8%) is significantly impacting on all the investigated impact categories followed by brick moulding (24.8%) and brick roasting (9.4%) phases, respectively. Hotspots were assessed to identify potential for resource efficiency and circular economy at ABC bricks, Zimbabwe. It can be concluded that ABC is severely polluting the air with emissions above the Environmental Management Agency (EMA) standards for SO<inf>2</inf>, CO, PM and NO<inf>x</inf> thus putting kiln workers at risk of respiratory diseases. The calculated Air Quality Index (AQI) ranks CO as the most affecting pollutant with an average score of ∼600. Clay production efficiency was also determined, and an analysis revealed that extrusion and clamping stage contributed highly to the clay losses during brick moulding. Therefore, focus must be placed on these process steps to reduce raw material losses. Furthermore, an environmental waste (fly ash) was used in different weight percentage ratios of 10%, 20% and 100% to substitute clay. The increase of the fly ash content in the brick making process proved to significantly reduce the environmental load among the selected impact categories. ABC uses clay as its main raw material hence the high demand for clay. Strategies should include accounting of used clay daily and raw materials substitution. If ABC uses fly ash from its brick kilns and from other thermal power plant boilers to mix with clay in brick production, then the quantity of clay demanded will be reduced. Using fly ash will reduce rate of clay extraction while at the same time solving the problem of fly ash disposal in Zimbabwe. This circular option will ultimately result in reduced pit expansion, hence reducing top-soil loss and environmental degradation. It should not be disregarded that top-soil loss in turn affects food security. By adopting appropriate technologies, implementing resource efficiency, and designing circular economy patterns, the brick manufacturing sector in Zimbabwe may not only reduce production waste but also comply with enforced environmental protection legislation.",Entailment
s_726,Contradiction,"Applications of AI in the AEC Industry: Construction Equipment Management: AI integrated with video surveillance technology is claimed to enhance construction equipment management significantly. AI algorithms supposedly analyze video feeds to identify anomalies, predict maintenance needs, and optimize equipment utilization, which may lead to improvements in safety and efficiency on construction sites, although these benefits are not universally guaranteed .","This article discusses the integration of artificial intelligence (AI) and video surveillance technology for construction equipment management. The use of artificial intelligence algorithms and video surveillance systems can improve equipment management by increasing the efficiency of video surveillance on construction sites, improving the safety and efficiency of construction equipment. The article discusses the potential benefits of using AI to analyze data from video feeds, including the ability to identify anomalies in equipment usage patterns, predict maintenance needs, and optimize equipment utilization. The article provides an example of the practical implementation and use of AI and video surveillance technologies in the construction industry today, highlighting their potential.",Misrepresentation
s_462,Unverifiable,"Equivalence Classes: Hypotheses are grouped into equivalence classes, with larger classes being more probabilistically weighted .","[5] In-silico scientific research is a complex task that involves the management of huge volumes of data and metadata produced during the scientific exploration life cycle, from hypothesis formulation up to its final validation. This wealth of data needs to be structured and managed in a way that readily makes sense to scientists, so that relevant knowledge may be extracted to contribute to the scientific investigation process. This paper proposes a scientific hypothesis conceptual model that allows scientists to represent the phenomenon been investigated, the hypotheses formulated in the attempt to explain it, and provides the ability to store results of experiment simulations with their corresponding provenance metadata. The proposed model supports scientific life-cycle: provenance, scientists exchange of information, experiment reproducibility, model steering and results analyses. A cardiovascular numerical simulation illustrates the applicability of the model and an initial implementation using SciDB is discussed. © 2012 Springer-Verlag.",Related but unverifiable
i_792,Contradiction,"Key Factors Impacting Digital Transformation: Resource Availability: Large Enterprises often face challenges due to limited resources, which can significantly impact their ability to successfully implement digital transformation initiatives. This includes financial constraints and limited access to advanced technologies .","Companies are experimenting change at a fast pace in the business environment due to the evolution of technology. As a result, they require solution approaches designed to guide their Digital Transformation (DT) efforts. However, several factors must be considered in their design, notably how the particular features of companies impact positively or negatively their DT. In the case of Small and Medium Enterprises (SMEs) in manufacturing, this is particularly relevant, as their vulnerabilities, such as the lack of resources, seem to have a significant impact over the success of DT initiatives. Defining this impact as an indicator of this effect will provide valuable information to control the DT to better achieve its objectives. For this reason, the aim of this paper is to introduce the impact level performance indicator for the specific scenario of manufacturing SMEs' DT. An Impact Analysis is presented with this purpose using a qualitative approach. Conclusions of this work lead to further develop the Impact Level indicator using a quantitative approach that enables its use in the control of the DT process.
[3]: Digital transformation is now being applied to many aspects of organisations' operations, ranging from multi-national companies to small and medium enterprises. The differences in firms' characteristics will have a direct and important impact on the nature of digital transformation and innovation. This empirical study aims to discover the effects of small and medium automotive enterprises' characteristics, referring to their Thailand-based operations. Their adoption of digital transformation innovation will also be examined, along with how such factors influence their business performance. These firms supply materials to many automobile manufacturing firms in Thailand, and both digital transformation and firms' innovation play key mediating roles. The Structural Equation Modelling statistical approach was implemented to generate empirical data from multivariable factors. Findings indicate that the amount of capital owned by small and medium enterprises directly affects their digital transformation and innovation. This is turn wields an important impact on non-financial performance of firms.",Entity error
s_574,Unverifiable,"Energy Efficiency Strategies: The development of new materials and additives, such as maleic anhydride grafted polypropylene (MAPP) in wood-polypropylene composites, can enhance the mechanical properties of the extruded products while potentially reducing energy consumption during processing .","Wood-plastic composites, produced from lignocellulosic materials such as wood fiber and wood flour as reinforcement, are renewable, recyclable, and biodegradable materials, especially suitable for the structural design. In this study, wood-polypropylene composites were produced by co-rotating twin-screw extrusion technique, while polypropylene (PP) was used as the composite matrix, hornbeam, pine, and medium density fiberboard wastes were used as reinforcement materials. The additive ratio was changed to 10%, 20%, and 30% in each different type of wood powder, and maleic anhydride grafted polypropylene (MAPP) was used as coupling agent at 3% to 6%. The PP, wood fibers and MAPP blended in the mixer were processed in the extruder and turned into granules. Test samples were prepared for the evaluation of their physical and mechanical properties with a compression molding machine. The structural and morphological properties of the composites were investigated by X-ray diffraction (XRD), Fourier Transform Infrared Radiation, and Scanning Electron Microscopy with energy-dispersive X-ray spectroscopy. Tensile and flexural strength analyses were conducted to determine the mechanical properties of the materials. In the tensile test, maximum stress value and elastic modulus were obtained with the sample of M30M6 (%30 MDF, %6 MAPP) as 42.41 MPa and 2050.04 MPa, respectively. In the flexural test, maximum stress value and elastic modulus were achieved with the sample of M30M3 (%30 MDF, %3 MAPP) as 63.18 MPa and 2103.03 MPa, respectively. Looking to the all kind of additives, almost all samples have better properties than pure PP. It was concluded that waste of pine, hornbeam, and MDF have been shown to have great potential for the production of wood-polymer composites.",Related but unverifiable
i_1525,Entailment,"Key Factors Influencing Community Involvement: Social Activities and Empowerment: Increased participation in social community activities and empowerment initiatives significantly boosts community involvement in waste management, and it is likely that similar patterns of engagement could be observed in rural areas, although this has not been specifically studied .","It is crucial to achieve effective solid waste management involving not only formal/ government agencies, but also individual/informal/voluntary actions in order to create a healthy environment. This study conducted to unveil the factors that increase individuals' community participation in solid waste management policy. The data were matched with a literature review on existing waste policies to identify gaps in knowledge, which could provide beneficial policy recommendations for the Jakarta Provincial Government. The ordinary least squares regression and Indonesian family life survey data were used. The respondents' waste handling and participation scores with potentially affected variables were calculated and regressed. Out of 1.791 respondents, the regression revealed that the participation of individuals from Jakarta is influenced by 1) the frequency of their involvement in social community activities, 2) their education level, and 3) per capita expenditure. The solid waste management score increased by 0.233 if the respondents were more socially active, with a participation score of 1. Empowerment had a 0.06 coefficient correlation relative to the waste handling score. According to the broader sample of 28.967 respondents from large cities in Indonesia. It was concluded that individuals' participation could be enhanced by hosting various social activities at the grassroots level. The study's gaps show that the Jakarta Provincial Government has a high propensity towards increasing individuals' participation in solid waste management by maximizing control of the factors mentioned above (especially empowerment), as well as by raising the frequency of citizens' involvement in social community activities at the grassroots level.",Entailment
s_1057,Entailment,"2.  -    These exosomes contain miRNAs (miR-199a-3p/145-5p) that modulate the NGF/TrkA signaling pathway, promoting neurite outgrowth and reducing inflammation .","Background: Although exosomes, as byproducts of human umbilical cord mesenchymal stem cells (hUC-MSCs), have been demonstrated to be an effective therapy for traumatic spinal cord injury (SCI), their mechanism of action remains unclear. Methods: We designed and performed this study to determine whether exosomes attenuate the lesion size of SCI by ameliorating neuronal injury induced by a secondary inflammatory storm and promoting neurite outgrowth. We determined the absolute levels of all exosomal miRNAs and investigated the potential mechanisms of action of miR-199a-3p/145-5p in inducing neurite outgrowth in vivo and in vitro. Results: miR-199a-3p/145-5p, which are relatively highly expressed miRNAs in exosomes, promoted PC12 cell differentiation suppressed by lipopolysaccharide (LPS) in vitro through modulation of the NGF/TrkA pathway. We also demonstrated that Cblb was a direct target of miR-199a-3p and that Cbl was a direct target of miR-145-5p. Cblb and Cbl gene knockdown resulted in significantly decreased TrkA ubiquitination levels, subsequently activating the NGF/TrkA downstream pathways Akt and Erk. Conversely, overexpression of Cblb and Cbl was associated with significantly increased TrkA ubiquitination level, subsequently inactivating the NGF/TrkA downstream pathways Akt and Erk. Western blot and coimmunoprecipitation assays confirmed the direct interaction between TrkA and Cblb and TrkA and Cbl. In an in vivo experiment, exosomal miR-199a-3p/145-5p was found to upregulate TrkA expression at the lesion site and also promote locomotor function in SCI rats. Conclusions: In summary, our study showed that exosomes transferring miR-199a-3p/145-5p into neurons in SCI rats affected TrkA ubiquitination and promoted the NGF/TrkA signaling pathway, indicating that hUC-MSC-derived exosomes may be a promising treatment strategy for SCI.",Entailment
s_1749,Entailment,"Ozone Sensitive: CO51, CO47, and ADT36 were identified as ozone-sensitive cultivars .","The plant response to elevated ozone stress reveals inter-species and intra-species disparity. Ozone-induced crop yield loss is predicted to increase in the future, posing a threat to the world economy. This study aims to evaluate the cultivar specific variation in rice exposed to elevated ozone. Fifteen short-duration rice cultivars were exposed to 50 ppb ozone for 30 days at reproductive stage. The physiological, biochemical, growth and yield traits of all test cultivars were significantly affected in response to elevated ozone. On an average, ozone stress decreased the tiller number by 22.52%, number of effective tillers by 30.43%, 1000 grain weight by 0.62% and straw weight by 23.83% over control. Spikelet sterility increased by 19.26% and linear multiregression 3D model significantly fits the spikelet sterility and photosynthetic traits with the R<sup>2</sup> of 0.74 under elevated ozone. Principal Component Analysis with total variance of 57.5% categorized 15 rice cultivars into four major groups, i.e., ozone sensitive (MDU6, TRY(R)2 and ASD16), moderately ozone sensitive (ASD18, ADT43, and MDU5), moderately ozone tolerant (ADT37, ADT(R)45, TPS5, Anna(R)4, PMK(R)3, and ADT(R)48), and ozone tolerant (CO51, CO47, and ADT36). This study indicates that the different responses of rice cultivars to elevated ozone stress through a change in plant physiology, biochemical, growth, and yield traits and the results directed to provide scientific information on plant adaptations to ozone stress and helps in efforts to search ozone tolerant gene for plant breeding.",Entailment
i_2046,Unverifiable,"Behavioral Adaptations to Water Movement. Schooling and Information Transfer: Small pelagic fish often live in schools, which require efficient information transfer for coordinated movements. Waves of agitation within schools allow rapid responses to environmental changes and predator attacks, ensuring the cohesion and plasticity of the school . This behavior is essential for maintaining optimal conditions for spawning and protecting offspring.","Most pelagic fish live in schools. To allow fast reactions, for instance to predator attacks, these collective structures require behavioural mechanisms authorizing fast, coordinated movements. Considering the large number of individuals constituting a school of small pelagic fish, a crucial premise to coordinated movements and school reorganization is an ability to transfer quickly and efficiently information across the whole collective structure. We observed anchovy school movements and reactions to sea-lion attacks while the ship was drifting in Peruvian waters. The main process of information transfer we could observe was that of waves of agitation crossing large anchovy schools. The average speed of these waves (7.45 m s<sup>-1</sup>) was much greater than the average 0.3 m s<sup>-1</sup> school speeds measured during this experiment. The internal organization of each school modified dramatically after the waves of agitation had crossed them. Changes in school external morphology and internal structure were described and measured using geostatistics. Our results show that information transfer is a crucial process for the cohesion and plasticity of schools. As such, it allows efficient reactions of schools of pelagic fish to variations in their immediate environment in general, and to predation in particular. © 2006 International Council for the Exploration of the Sea.",Related but unverifiable
s_825,Contradiction,"Wood is often treated with chemicals to protect it from rot and insect damage, and it is generally assumed that these treatments are always effective against pests while being safe for human use .","This chapter examines the effects of some of the key industrial processes that are undertaken on timber, including the physical treatment of the wood itself in order to help preserve timber from the ravages of rot and insect predation. These treatments need to be poisonous to rot and/or insects, and should be non-poisonous to humans. Their success or failure at this is examined and the reasons are looked at to find out why. The second key process relates to the adhesives that are increasingly used to join pieces of wood together, especially in the industrially heavy processes of creating engineered timber products such as glue lamination, laminated veneer lumber and cross-laminated timber. Glues are mostly benign when locked up in use, but may have strong health effects when they are being applied in order to form the engineered timber.",Misrepresentation
i_16,Unverifiable,"Additionally, deep learning models can be adapted to various types of data and applications, making them versatile tools in geostatistical analysis .","[17] Accurate fault location on transmission line is important in ensuring consistent and reliable operation of the power deliver to long distance destination. Conventional methods for locating fault on transmission lines based on travelling wave and impendence-based methods usually suffer from large error due to the complexity of fault modeling on different type of faults. In this paper, an intelligent system for detection of fault location on transmission line using a hybrid model that integrates artificial neural network (ANN) and fuzzy expert system called Adaptive Network-Based Fuzzy Inference System (ANFIS) is proposed. First, a three phase transmission lines is modeled and various types of faults are generated using MATLAB/Simulink. Then, the faulted current signal is segmented from the faulted transmission. Next, feature extraction is performed to obtained information from the faulted current signal. In this study, the extracted features are mean, standard deviation, energy, peak-to-peak and amplitude value. Feature selection is then applied to select important features that correlate with the fault location. For single-phase-to-ground fault, peak-to-peak value and energy is used. Meanwhile, for the line-to-line and double-phase-to-ground faults, only peak-to-peak value is used. Finally, ANFIS network is trained to locate the fault occurrence. Simulation results against two regression models; Linear Regression and Gaussian Process Regression indicated that the ANFIS network is superior in locating the fault. The network achieved the lowest mean squared error (MSE) (0.0012 to 0.0022).",Related but unverifiable
i_2250,Contradiction,"In Indonesia, there is a significant issue with herbicide resistance, particularly with glyphosate-resistant Eleusine indica (GR-ESU) in North Sumatra. Research has shown that the use of alternative herbicides like Monosodium Methyl Arsenate (MSMA) combined with diuron can control GR-ESU biotypes, suggesting that glyphosate is entirely ineffective in managing these weeds .","The glyphosate-resistant Eleusine indica (GR-ESU) case has dominated at oil palm plantations in North Sumatra Province, Indonesia and will increase evolution into resistance. This research was aimed to determine the role of Monosodium Methyl Arsenate (MSMA)+diuron to control the agronomic characteristics of GR-ESU biotypes. This research was conducted in the Weed Research Center Land, Faculty of Agriculture, Universitas Sumatera Utara in November 2017 until August 2018. This research used Randomized Block Design non-factorial with factor GR-ESU biotypes that were sprayed with glyphosate at the dose of 3 l.ha<sup>-1</sup>, and MSMA+diuron at the dose of 5 l.ha<sup>-1</sup> within four replications. The parameters were analyzed using one-way ANOVA and were continued by DMRT at P < 0.05 with IBM SPSS Statistics v.20 software. The results showed that a decrease in the survival of GR-ESU at the changes from glyphosate to MSMA+diuron. The GR-ESU on MSMA+diuron showed leaf color changes (leaf green loss/chlorosis) at 3 until 21 days after sprayed. The ability of MSMA+diuron had com-pletely (100%) controlled within 18 of 29 GR-ESU biotypes and had effectively controlled the tillers, flowering, fresh-and dry weight in GR-ESU biotypes of 87.53%; 66.88%; 95.66%; and 95.92% respectively compared to glyphosate. The use of MSMA+diuron as a different mode of action herbicide is highly recommended to control GR-ESU biotypes at oil palm estate.",Misrepresentation
i_322,Contradiction,"Existing frameworks typically have straightforward codebases, making them easy to navigate and modify, enhancing their usability for research and development .","Optimising deep learning inference across edge devices and optimisation targets such as inference time, memory footprint and power consumption is a key challenge due to the ubiquity of neural networks. Today, production deep learning frameworks provide useful abstractions to aid machine learning engineers and systems researchers. However, in exchange they can suffer from compatibility challenges (especially on constrained platforms), inaccessible code complexity, or design choices that otherwise limit research from a systems perspective. This paper presents Orpheus, a new deep learning framework for easy prototyping, deployment and evaluation of inference optimisations. Orpheus features a small codebase, minimal dependencies, and a simple process for integrating other third party systems. We present some preliminary evaluation results.",Misrepresentation
s_942,Contradiction,Types of Conveyor Malfunctions and Their Causes: Belt Misalignment: Proper alignment of the conveyor belt actually enhances its performance and increases its lifespan. Causes: Effective interaction between the moving belt and stationary parts of the conveyor .,"The misalignment causes the greatest damage to the conveyor belt. As a result of the interaction of the moving belt with the stationary parts of the conveyor, the sides of the belt wear intensively. This results in reducing the life of the belt. The reasons for this phenomenon are well investigated, but the difficulty lies in the fact that they all act simultaneously. The belt misalignment prevention can be carried out in two ways: by minimizing the effect of causes and by aligning the belt. The construction of aligning devices and errors encountered in practice are considered in this paper. Self-aligning roller supports rotational in plan view are recommended as a means of combating the belt misalignment.",Misrepresentation
i_114,Entailment,"This approach is likely to completely transform user experience and ensure that all interactions are natural and effective, as it addresses every aspect of emotional intelligence in machines .","Artificial Intelligence is a general appellation employed to describe the principles and development of systems aimed at emulating human intelligence for performing tasks requiring cogent reasoning, visual perception, and decision making related to the environment. Emotional intelligence, the ability to comprehend, use, and regulate emotions is often reckoned as a critical component of human intelligence, and is useful for optimizing human-human interaction. A recent influx of proactive devices and environments has made human-machine interfaces ubiquitous. With the interaction of humans amongst themselves as the blueprint for interaction between humans and machines, there is a growing need to induce emotional intelligence in the latter to regulate the interaction and enhance user experience. Communication among humans is supplemented by their innate capacity to infer the emotional state of the interlocutor with affective signals manifested with physical correlates of emotion such as facial expressions (FEs), speech, and voice inflections. Rigorous experiments in face-to-face multimodal cognition suggested FEs to be more predominant as compared to other modalities in conveying the underlying emotional state. Therefore, conventional human-machine interfaces that ignore or marginalize the user's FEs fail to procure and access a relevant segment of information present in the conversation signals. This has necessitated a paradigm shift in human-machine interaction with incorporation of FEs as a communication channel. A proactive affect-sensitive interface, able to regulate human-machine interaction in accordance with affective state of the user, has multitudinous prospective applications in a wide array of domains. This has lent a powerful impetus to assessment of emotions by FEs, an integral component of non-verbal paralinguistic communication. Motivated with the need of inducing emotional intelligence in machines, several models for representing affective facial displays have been introduced in the past. This chapter presents a systematic overview of diverse characteristic patterns presented for reliable analysis of emotional facial displays. The manifestation of emotions via FEs entails a non-rigid motion of facial features that can be embodied by a dense optical flow field, which is the apparent image motion in a time-progressing visual. The dearth of a detailed corpora pertaining specifically to the theme of visual information-based recognition of facial expressions with optical flow has motivated us to articulate various studies concerning this subject. Lastly, this chapter delineates the multifaceted concomitant challenges, outlines the strengths and limitations of different methods for emotion recognition with analysis of facial patterns and cites fascinating real-world instances apposite to the discipline.",Entailment
s_127,Entailment,"AI-driven recommendation systems can suggest relevant resources to users based on their search history and preferences, enhancing the user experience .","In recent years, deep learning has yielded success in many research fields including machine translation, natural language processing, computer vision, and social network filtering. The area of deep learning in the recommender system is flourishing. Previous research has relied on incorporating metadata information in various application domains using deep learning techniques to achieve better recommendation accuracy. The use of metadata is desirable to address the cold start problem and better learning the user-item interaction, which is not captured by the user-item rating matrix. Existing methods rely on fixed user-item latent representation and ignore the metadata information. It restricts the model performance to correctly identify actual latent vectors, which results in high rating prediction error. To tackle these problems, we propose a generalized recommendation model named Meta Embedding Deep Collaborative Filtering (MEDCF), which inputs user demographics and item genre as metadata features together with the rating matrix. The proposed framework primarily comprises of Generalized Matrix Factorization (GMF), Multilayer Perceptron (MLP), and Neural Matrix Factorization (NeuMF) methods. GMF is applied to the rating matrix, whereas MLP is applied to metadata. Using NeuMF, the outputs for GMF and MLP are then concatenated and input to a neural network for rating prediction. To prove the effectiveness of proposed model, two metrics are used, Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE). The MEDCF model is experimented on MovieLens and Amazon Movies datasets showing a significant improvement over the baseline methods.
[7]: Information extraction and user intention identification is a central topic in modern query understanding and recommendation systems. In this paper, we propose DeepProbe, a generic information-directed interaction framework which is built around an attention-based sequence to sequence (seq2seq) recurrent neural network. DeepProbe can rephrase, evaluate, and even actively ask questions, leveraging the generative ability and likelihood estimation made possible by seq2seq models. DeepProbe makes decisions based on a derived uncertainty (entropy) measure conditioned on user inputs, possibly with multiple rounds of interactions. Three applications, namely a rewritter, a relevance scorer and a chatbot for ad recommendation, were built around DeepProbe, with the first two serving as precursory building blocks for the third. We first use the seq2seq model in DeepProbe to rewrite a user query into one of standard query form, which is submitted to an ordinary recommendation system. Secondly, we evaluate DeepProbe's seq2seq model-based relevance scoring. Finally, we build a chatbot prototype capable of making active user interactions, which can ask questions that maximize information gain, allowing for a more efficient user intention idenfication process. We evaluate first two applications by 1) comparing with baselines by BLEU and AUC, and 2) human judge evaluation. Both demonstrate significant improvements compared with current state-of-the-art systems, proving their values as useful tools on their own, and at the same time laying a good foundation for the ongoing chatbot application.",Entailment
i_636,Unverifiable,2. Technological Integration: Augmented Reality (AR): AR tools are being integrated with BIM to enhance visualization and interaction with digital models. This combination helps in better planning and execution of construction projects .,"Construction projects are becoming increasingly challenging, resulting in more complex and dynamic construction environments. Despite this, traditional management and monitoring methods are currently unable to keep up with the industry's rapid development, leading to several problems in task efficiency and transfer of information between project delivery stages. Consequently, the Architecture Engineering Construction and Operations sector is pursuing digitalization to improve project management, assist trade-crews and achieve a more efficient working environment. As a result, the adoption of Building Information Modelling (BIM) represents a paradigm shift from the traditional approaches towards a collaborative and integrated working process. Although BIM is improving the aforementioned problems, not all corporations are able to implement and use it effectively. As such, supportive tools to assist BIM in achieving its full potential are in high demand. To facilitate the deployment and application of BIM, easy-entry technologies such as Virtual Reality tools are establishing themselves as a promising addition to BIM methodology. The current research objective is to provide a review of previous works in the field of BIM-based VR, in order to establish a clear view of this research field. The methodology adopted for this systematic review is PRISMA Statement strategy. Based on the results of the review several questions regarding this topic were answered.",Related but unverifiable
s_1341,Unverifiable,"Approved as an add-on maintenance therapy, showing promise in reducing exacerbations and improving asthma control .","Kyowa Hakko Kirin, AstraZeneca and subsidiaries are developing benralizumab (Fasenra™)—a humanised anti-interleukin-5 receptor alpha chain (IL-5Rα) monoclonal antibody—as a treatment of severe eosinophilic asthma and chronic obstructive pulmonary disease (COPD). Eosinophilia is a characteristic of certain asthma and COPD phenotypes and depletion of eosinophils has demonstrated therapeutic benefit. Benralizumab was recently approved by the US FDA as add-on maintenance therapy for patients with severe asthma who have an eosinophilic phenotype. This article summarizes the milestones in the development of benralizumab leading to this first approval for the treatment of severe eosinophilic asthma.
[8]: Nonresponders to maximal guideline-based therapies of asthma account for most of the morbidity, mortality, and economic burden of the disease. Because eosinophils are key effector cells in asthmatic airway inflammation, blocking IL-5, the main cytokine responsible for its survival and activation, seems to be a rational strategy. While previous monoclonal antibodies against the IL-5 ligand resulted in inconsistent improvements in asthma outcomes, benralizumab has shown promise. Benralizumab is a monoclonal antibody against IL-5 receptor, and has an enhanced antibody dependent cell-mediated cytotoxicity function. In this article, we review the theoretical advantages of benralizumab compared to previous compounds, as well as current status of the clinical development of benralizumab in asthma. Lastly, we briefly discuss the potential role of benralizumab in chronic obstructive pulmonary disease.",Related but unverifiable
i_2052,Contradiction,"In Malaysia, sustainable weed management in oil palm plantations includes the use of cover crops as a viable alternative to herbicidal control. A study conducted from 2010-2012 evaluated different cover crop systems and their impact on weed communities and oil palm yield. The study found that cover crops like Axonopus compressus and combinations of Calopogonium caeruleum with Centrosema pubescens were somewhat effective in suppressing weeds, suggesting that they could completely eliminate the need for herbicides like glufosinate-ammonium .","Sustainable weed management in oil palm plantation has been a challenge now a day. Weed suppression by cover cropping is considered as a viable alternative to herbicidal control. This study0020was, therefore, conducted during 2010-2012 in a Malaysia oil palm plantation to characterize oil palm weed communities and evaluate oil palm yield under four different perennial cover-crop systems. Experimental treatments included four different cover crop combinations such as Axonopus compressus, Calopogonium caeruleum + Centrosema pubescens, Mucuna bracteata, Pueraria javanica + Centrosema pubescens, and herbicidal control by glufosinate-ammonium and weedy control. Weed composition in the un-weeded treatment was different from that of cover crop treatments. The un-weeded treatment favored Paspalum conjugatum and A. compressus as the dominant species. In the A. compressus and C. caeruleum + C. pubescens treatments the associated weed species with highest dominance was Asystasia gangetica, while the weeds A. compressus and A. gangetica were associated with M. bracteata and P. javanica + C. pubescens treatments. In the weeded treatment receiving 6 sprays of glufosinateammonium over the two years, B. latifolia was dominant. The A. compressus cover treatment had the lowest species richness and diversity. Weeded plots had lowest yield, bunch number tree<sup>-1</sup> and bunch weight during the 18-24 MAP. The study confirms variation in weed community in oil palm plantation under different cover-crop systems and thus, contributes to improving current understanding of weed community structures and may help formulate sustainable weed management strategy for oil palm plantation. © 2014 Friends Science Publishers.",Missing information
s_128,Entailment,"Key Areas of AI Implementation in Libraries: Automation of Routine Tasks: AI can automate repetitive tasks such as cataloging, classification, and indexing of library materials, freeing up librarians to focus on more complex tasks .","The main purpose of this paper is to assess and examine the possible application of Artificial Intelligence (AI) tools in Pakistani academic libraries, particularly those areas of library technical and library user services where AI could be applied in the near future. A secondary purpose is to bring the library perspective on AI to the forefront of the scholarly world. This is a self-exploratory study, in which a qualitative approach interview has been conducted with 10 chief librarians/library heads (5 public + 5 private sectors) from universities regarding their views on the adoption of artificial intelligence tools in Pakistani academic libraries. Results are tabulated in a descriptive format. Librarians are aware of AI technologies. Services based on Natural Language Processing (NLP) are used in libraries, e.g. Google Assistant, Voice Searching, and Google Translate. Pattern recognition methods, such as text data mining, are also used to retrieve library material and conduct online searching. Big data is accessed via services such as cloud computing, OneDrive, and Google Drive. There is a very low level of awareness of robotics and chatbots. This study provides librarians with suggestions as to how AI tools could be used in libraries which either have yet to adopt AI technologies or wish to implement more advanced tools. Pakistani library schools could collaborate with computer science departments to establish AI Labs in the respective library and information science (LIS) departments/libraries. AI challenges funding and technological skills are the key problem to implement with AI in the University Libraries.
[8]: This paper focuses on the opportunities and challenges associated with the use of artificial intelligence (AI) in academic library operations. In the quest to render fast, effective and efficient services, academic libraries have adopted different technologies in the past. Artificial intelligence technologies is the latest among the technologies currently being introduced in libraries. The technology which is considered an intelligent system, come in the form of robots and expert systems which have natural language processing, machine learning and pattern recognition capabilities. This paper examined the features of AI, the application of AI to library operations, examples of academic libraries with AI technologies in Sub-Saharan Africa, the need for AI in libraries and the challenges associated with the adoption of AI in libraries. The study concluded that AI holds a lot of prospects for the improvement of information services delivery in African academic libraries. Consequently, its adoption is a sinequanon to delivering robust library services in the Fourth Industrial Revolution (4IR).",Entailment
s_1556,Contradiction,"Browallia speciosa: Delphinidin derivatives are found in the flowers, but again, no mention of nectar .","Two new diacylated delphinidin 3-rutinoside-5-glucosides were isolated from the blue-purple flowers of Browallia speciosa cv. 'Purple'. As a major anthocyanin (1), delphinidin 3-O-[6-O-(4-O-(trans-caffeoyl)-α-L- rhamnopyranosyl)-β-D-glucopyranoside]-5-O-[2-O-(trans-p-coumaroyl)-β-D- glucopyranoside] was determined by chemical and spectroscopic methods. Another one was tentatively assigned to be the cis-p-coumroyl isomer of the major anthocyanin due to its small amount available. In the pigment 1, the 5-glucose residue of the anthocyanin is acylated with p-coumaric acid at 2-OH group of the sugar moiety, and this acylation pattern is the first report in plants. © 2008 The Japan Institute of Heterocyclic Chemistry.",Missing information
s_1484,Entailment,Essential for bone health and mineral utilization.  Supplementation with 25-hydroxycholecalciferol (25(OH)D3) improves eggshell quality and reduces embryo mortality  .,"An experiment was carried out with the objective of evaluating the addition of 25-hydroxycholecalciferol (25(OH) D<inf>3</inf>) in diets of broiler breeder hens. The experiment used Cobb 500 broiler breeder hens and was allotted to a complete randomized design with four treatments and eight replications of twenty females and two males each. The treatments consisted of vitamin premixes with 2,000 and 3,400 IU/kg diet vitamin D<inf>3</inf> as the only source of vitamin or 2,000 IU D<inf>3</inf> plus 35 or 69 mg/t of 25(OH) D<inf>3</inf>. Results of this experiment indicated that 25(OH) D<inf>3</inf> had no significant effect on egg production parameters from 32 to 67 weeks. The supplementation of 25(OH) D<inf>3</inf> resulted in better quality egg shells evaluated by the specific gravity at 60 weeks of age, regardless of the dosage. No significant differences were observed for hatchability of broiler breeder fertile eggs at 54 and 64 weeks. At 64 weeks, the hatch residue breakout showed less embryo mortality at the third week for treatments receiving 2,000 UI D<inf>3</inf> in the diet and less embryo mortality at the second week of development from hens aged 67 weeks and supplemented with 2,000IU D<inf>3</inf> and 2,000IU D<inf>3</inf>+ 69 mg 25(OH)D<inf>3</inf>. It was concluded that the supplementation with 25-hydroxycholecalciferol with cholecalciferol had similar effects as the diets with vitamin D<inf>3</inf> as the only source on the productive performance of broiler breeder hens. © 2009 Sociedade Brasileira de Zootecnia.",Entailment
s_498,Contradiction,"Biological Inspiration for Battery Design: Hierarchical and Adaptive Structures: Biological systems often exhibit hierarchical and adaptive structures. For instance, the 3D hierarchical flower-like microstructures formed by 2D nanosheets in lithium-ion batteries improve electrical conductivity and cycling performance . Implementing similar hierarchical designs in battery compartments can enhance their durability and efficiency.","Low cycling stability and poor rate performance are two of the distinctive drawbacks of most electrode materials for sodium-ion batteries (SIBs). Here, inspired by natural flower structures, we take advantage of the three-dimensional (3D) hierarchical flower-like stable microstructures formed by two-dimensional (2D) nanosheets to solve these problems. By precise control of the hydrothermal synthesis conditions, a novel three-dimensional (3D) flower-like architecture consisting of 2D Na<inf>2</inf>Ti<inf>3</inf>O<inf>7</inf> nanosheets (Na-TNSs) has been successfully synthesized. The arbitrarily arranged but closely interlinked thin nanosheets in carnation-shaped 3D Na<inf>2</inf>Ti<inf>3</inf>O<inf>7</inf> microflowers (Na-TMFs) originate a good network of electrically conductive paths in an electrode. Thus, Na-TMFs can get electrons from all directions and be fully utilized for sodium-ion insertion and extraction reactions, which can improve sodium storage properties with enhanced rate capability and super cycling performance. Furthermore, the large specific surface area provides a high capacity, which can be ascribed to the pseudo-capacitance effect. The wettability of the electrolyte was also improved by the porous and crumpled structure. The remarkably improved cycling performance and rate capability of Na-TMFs make a captivating case for its development as an advanced anode material for SIBs.",Entity error
s_1310,Unverifiable,"Monitoring: Regular monitoring of iron levels and hematological status is crucial for timely intervention, and it is believed that incorporating dietary assessments could further enhance the management of anemia in pregnant women .","Fetal anaemia can by treated by in-utero therapy, which results in a significant improvement in perinatal outcome. The important causes of fetal anaemia are rhesus alloimmunisation, kell alloimmunisation and parvovirus infection. At-risk pregnancies require serial monitoring to ensure timely intervention with intrauterine transfusion. Non-invasive testing with middle cerebral artery Doppler is becoming the monitoring modality of choice. © 2007 Elsevier Ltd. All rights reserved.
[11]: Background: Pregnancy anemia remains as a public health problem, since the official reports in the 70's. To guide the treatment of iron-deficiency anemia in pregnancy, the haemoglobin concentration is the most used test in spite of its low accuracy, and serum ferritin is the most reliable test, although its cutoff point remains an issue. Methods/design: The aim of this protocol is to verify the accuracy of erythrocyte indices and serum ferritin (studied tests) for the diagnosis of functional iron-deficiency in pregnancy using the iron-therapy responsiveness as the gold-standard. This is an ongoing phase III accuracy study initiated in August 2011 and to be concluded in April 2013. The subjects are anemic pregnant women (haemoglobin concentration < 11.0 g/dL) attended at a low-risk prenatal care center in the Northeast of Brazil. The sample size (n 278) was calculated to estimate sensitivity of 90% and 80% of specificity with relative error of 10% and power of 95%. This study has a prospective design with a before-after intervention of 80 mg of daily oral iron during 90 days and will be analyzed as a delayed-type cross-sectional study. Women at the second trimester of pregnancy are being evaluated with clinical and laboratorial examinations at the enrollment and monthly. The 'responsiveness to therapeutic test with oral iron' (gold-standard) was defined to an increase of at least 0.55 Z-score in haemoglobin after 4 weeks of treatment and a total dose of 1200 mg of iron. At the study conclusion, sensitivities, specificities, predictive values, likelihood ratios and areas under the ROC (Receiver Operating Characteristic) curves of serum ferritin and erythrocyte indices (red blood cell count, haematocrit, haemoglobin concentration, mean corpuscular volume, mean corpuscular haemoglobin, mean corpuscular haemoglobin concentration, red blood cell distribution width, reticulocyte count) will be tested. The compliance and adverse effects are considered confounding variables, since they are the main obstacles for the iron-therapy responsiveness.Discussion: This study protocol shows a new approach on iron-deficiency anemia in pregnancy from a functional point of view that could bring some insights about the diagnostic misclassifications arising from the dynamic physiologic changes during the gestational cycle.Trial registration: WHO International Clinical Trials Registry Platform U1111-1123-2605. © 2013 Bresani et al; licensee BioMed Central Ltd.",Related but unverifiable
i_1423,Unverifiable,"Specialized Procedures: Esophagectomy and Gastric Resection: These are now minimally invasive procedures for upper gastrointestinal cancers, with endoscopic techniques being more suitable for advanced-stage cancers .","Despite advances in minimally invasive surgery, esophagectomy, and gastric resection remain morbid procedures for cancers of the upper gastrointestinal tract. Endoscopy offers patients effective screening and treatment of early-stage cancers. Endoscopic mucosal resection (EMR) can effectively remove benign and early malignant lesions. This chapter will focus on the use of EMR in the upper digestive tract.",Related but unverifiable
s_925,Unverifiable,"Economic Challenges: Advanced prosthetic hands that offer high functionality are often prohibitively expensive, making them inaccessible to many users, especially in developing countries . The high cost is a barrier to widespread adoption and limits the availability of these devices to those who need them most. Additionally, it is believed that the lack of local manufacturing capabilities in developing countries further exacerbates the issue, as it prevents the creation of affordable, customized solutions tailored to individual needs.","Prosthetic hands are desired by those who have lost a hand or both hands not only for decoration but also for the functions to help them with their activities of daily living (ADL). Prosthetic robotic hands that are developed to fully realize the function of a human hand are usually too expensive to be economically available, difficult to operate and maintain, or over heavy for longtime wearing. The aim of this study is therefore to develop a simplified prosthetic hand (sim-PH), which is to be controlled by myoelectric signals from the user, to realize the most important grasp motions in ADL by trading off the cost and performance. This paper reports the structure design of a two-DoF sim-PH with two motors to drive the CM joint of the thumb and the interlocked MP joints of the other four fingers. In order to optimize the structure, the model of the sim-PH was proposed based on which 7 sim-PHs with different structural parameters were manufactured and tested in a pick-and-place experiment. Correspondence analysis of the experimental results clarified the relationship between the hand functions and the shapes of fingers.
[5]: In this paper, an anthropometric, active artificial prosthetic hand named UOMPro (University of Moratuwa Prosthetic) is proposed. The UOMPro hand is realized during research on developing affordable hand prostheses for use by people mainly in developing countries where purchasing high cost state-of-the-art commercial hand prostheses may be beyond their capacity. The proposed hand is developed with an affordable cost (< 850 USD) and it consists of 6 Degrees of Freedom (DOF) including flexion/extension motions of five fingers and abduction/adduction motion of the thumb finger. Under actuated fingers are fabricated using a combination of 3D printed parts and CNC machined aluminum which addresses drawbacks in fully 3D printed hands. All components of the electronic control circuit which are responsible for low-level controlling of the hand are placed inside the hand where a simple serial communication interface is provided to link with high-level control methods. The implemented low-level controller can communicate with either a high-level controller that sends individual fingers position commands or a high-level controller which sends hand grip pattern commands. A set of experiments are conducted to validate the performance of the overall system and results are presented with potential future directions.",Related but unverifiable
i_295,Contradiction,Fundamental Guidelines for UI Design: Universal Design Principles: Equitable Use: The design should not be useful or marketable to people with diverse abilities .,"When designing ""interfaces for everyone"" for interactive systems, it is important to consider factors such as cost, the intended market, the state of the environment, etc. User interfaces are fundamental for the developmental process in any application, and its design must be contemplated from the start. Of the distinct parts of a system (hardware and software), it is the interface that permits the user access to computer resources. The seven principles of ""Universal Design"" or ""Design for Everyone"" focus on a universal usable design, but at the same time acknowledge the influences of internal and external factors. Structural changes in social and health services could provide an increase in the well-being of a country's citizens through the use of self-care programming and proactive management/prevention of disease. Automated home platforms can act as an accessibility instrument which permits users to avoid, compensate, mitigate, or neutralize the deficiencies and dependencies caused by living alone. © 2011 Springer-Verlag Berlin Heidelberg.",Opposite meaning
i_1860,Entailment,"Key Points on Water Purification by the Amazon Rainforest: Economic and Social Value: The value of the Amazon's water purification service extends beyond environmental benefits to significant economic and social impacts. Clean water is essential for drinking, agriculture, and industry, which are foundational to human health and economic activities .","Amazonian forest produces environmental services such as maintenance of biodiversity, water cycling and carbon stocks. These services have a much greater value to human society than do the timber, beef and other products that are obtained by destroying the forest. Yet institutional mechanisms are still lacking to transform the value of the standing forest into the foundation of an economy based on maintaining rather than destroying this ecosystem. Forest management for commodities such as timber and non-timber forest products faces severe limitations and inherent contradictions unless income is supplemented based on environmental services. Amazon forest is threatened by deforestation, logging, forest fires and climate change. Measures to avoid deforestation include repression through command and control, creation of protected areas, and reformulation of infrastructure decisions and development policies. An economy primarily based on the value of environmental services is essential for long-term maintenance of the forest. Much progress has been made in the decades since I first proposed such a transition, but many issues also remain unresolved. These include theoretical issues regarding accounting procedures, improved quantification of the services and of the benefits of different policy options, and effective uses of the funds generated in ways that maintain both the forest and the human population.
[4]: Tropical forests host a large population of biodiversity that play a crucial role in global climate regulation. Besides that, it represents a foundation for the provision of ecosystem services such as clean air and water, valuable timber and animal and plant resources with high commercial and cultural value. However, tropical forests are facing great pressure as a result of increasing human exploitation. If the world's tropical forests are destroyed, then many of the biodiversity species will be lost along with them. Not only that, but the local community also loses the natural system that performs valuable services which is important for the continuity of human's life. The balance of economic growth and conservation of biodiversity and its components including tropical forest must be achieved. Having said this, the ongoing action in conserving our valuable resources of tropical forest is important especially to support the well-being of the local community. Overall, this chapter discusses the importance of tropical forests, threats, conservation action as well as the economic value and economic valuation techniques that can be used to put an economic value on these natural resources.",Entailment
i_441,Contradiction,"Content selection is not a significant aspect, as it does not play a role in determining what information from the text should be included in the generated question. It is not treated as a classification problem, and contextual dependencies between input items do not improve the relevance and quality of the questions .","A content selection component determines which information should be conveyed in the output of a natural language generation system. We present an efficient method for automatically learning content selection rules from a corpus and its related database. Our modeling framework treats content selection as a collective classification problem, thus allowing us to capture contextual dependencies between input items. Experiments in a sports domain demonstrate that this approach achieves a substantial improvement over context-agnostic methods. © 2005 Association for Computational Linguistics.",Opposite meaning
i_2083,Contradiction,"A mixed diet including Ulva lactuca is the only effective option for improving growth rates, as single seaweed diets are generally ineffective .","The effects of different diets on growth in the cultured South African abalone, Haliotis midae (Linnaeus), was investigated. Growth of juvenile Haliotis midae was monitored on a commercial abalone farm over a period of 9 months in an experiment consisting of 9 treatments with 4 replicates (n = 250 individuals per replicate). The treatments were: fresh kelp (Ecklonia maxima) blades (seaweed control); Abfeed® (formulated feed control); kelp + Abfeed® dried kelp pellets; dried kelp blades; dried kelp stipes; fresh kelp with the epiphyte Carpoblepharis flaccida; a mixed diet (Gracilaria gracilis, Ulva lactuca, and kelp) and a rotational diet (abalone were fed 1 of the 9 treatments for the first week and them kelp for the next 3 weeks). Results show that abalone grow well on all fresh seaweed combinations, but grow best on a mixed diet. The likely reason for the success of the mixed diet is that the red and green seaweed was farm grown, with an increased protein content. Dried kelp in any form produced poor growth. Abalone fed on the mixed diet grew at 0.066 mm day<sup>-1</sup> shell length and 0.074 g day<sup>-1</sup> body weight; this corresponds to 24.09 mm shell length and 27.01 g body weight increase per annum. Abalone fed on dried kelp grew at only 0.029 mm day<sup>-1</sup> shell length and of 0.021 g day<sup>-1</sup> body weight. Abalone grown on Abfeed® grew at 0.049 mm day<sup>-1</sup> shell length and 0.046 g day<sup>-1</sup> body weight which corresponds to 17.88 mm and 16.79 g increase per annum; this is better than the dried seaweed feeds, but poorer than the fresh seaweed combinations. This study shows that seaweed diets, particularly if the diets include seaweeds grown in animal aquaculture effluent, are good substitutes for the formulated feed generally used today. © 2006 Springer Science+Business Media, Inc.",Misrepresentation
s_2026,Contradiction,"Key Points: Water Chemistry Changes: Volcanic eruptions can alter water chemistry by introducing various minerals and altering pH levels. Changes in water chemistry, such as increased nutrient levels, can significantly impact chlorophyll a concentrations, as seen in studies of other environmental disturbances .","The frequency of harmful algal blooms caused by eutrophication is increasing globally, posing serious threats to human health and economic development. Reservoir bays, affected by water environment and local watershed landscape, are more prone to eutrophication and algal blooms. The chlorophyll a (Chl a) concentration is an important indicator for the degree of eutrophication and algal bloom. Exploring the complex relationships between water environment and landscape background, and Chl a concentration in the reservoir bays are crucial for ensuring high-quality drinking water from reservoirs. In this study, we monitored Chl a concentrations of 66 bays in Danjiangkou Reservoir and the related water quality parameters (e.g., water temperature, turbidity, nutrients) in waterbodies of these reservoir bays in the storage and discharge periods from 2015 to 2018. Partial least squares-structural equation modeling (PLS-SEM) was used to quantify the relationship between water environmental factors and watershed landscapes, and Chl a concentrations in reservoir bays. The results showed that mean Chl a concentration was higher in storage period than that in discharge period. Two optimal PLS-SEMs explained 66.8% and 53.6% of Chl a concentration variation in the storage and discharge periods, respectively. The net effect of water chemistry on Chl a concentration was more pronounced during the discharge period (total effect = 0.61, 37% of the total effect on Chl a), while the net effect of land-use composition on Chl a concentration was more significant during the storage period (total effect = 0.57, 30% of the total effect on Chl a). The landscape pattern had significant indirect effects on Chl a concentration, especially during the discharge period (indirect effect = −0.31, 19% of the total effect on Chl a). Our results provide valuable information for managers to make rational decisions, thereby contributing to the prevention of eutrophication and algal blooms in reservoir bays.
[5]: The combination of low pH and high concentrations of metals associated with acid mine drainage would have severe toxicological effects on aquatic ecosystems. In order to evaluate the potential impact of acid mine drainage on the benthic algal communities in Gaolan River, which is one of the three main tributaries of Xiangxi River, we chose three sites in pyrite mining area as impaired group (I) , four uninfluenced sites were taken as control group (C) and five sites as recovery group (R). The results showed that benthic algal density, chlorophyll a concentration, ash free dry mass (AFDM) and autotrophic index (Al) were significantly affected by acid mine drainage from pyrite in the upstream of Gaolan River, while dry season affected seriously than flood season. Correlation analysis showed autotrophic index was positively correlated with metals and negatively correlated with pH, so Al could be a better indicator in the case where a pollutant such as acid mine drainages.",Misrepresentation
i_941,Contradiction,6. Gas Chromatography (GC): Description: Rapid at-line quantitation of residues via direct analysis of swabs. Advantages: Provides quick and accurate residue quantification. Useful for cleaning verification in pharmaceutical manufacturing .,"The potential for ion mobility spectrometry (IMS) to provide rapid at-line quantitation of residues on surfaces via direct analysis of swabs is attractive for pharmaceutical manufacturing equipment cleaning verification. In this study, the development of an IMS method to provide acceptable quantitation of active pharmaceutical ingredients and cleaning agents is described. Key modifications to commercially available instrumentation were made to achieve a dynamic range of 5-100 μg per 25 cm<sup>2</sup> surface area and acceptable analyte recovery in the presence of ionizable matrix components. The results of this study effectively demonstrate the capability of IMS to serve as an at-line quantitative analytical method. © 2008 American Chemical Society.",Entity error
i_2086,Unverifiable,"Nutritional Benefits: Ulva lactuca: Known for its high antioxidant activity, Ulva lactuca contains bioactive compounds such as vitamin C, total phenolics, and vitamin E, which contribute to its anti-peroxidation and anti-inflammatory effects. Additionally, it is believed that regular consumption of Ulva lactuca may enhance overall immune function due to its rich nutrient profile, although this has not been directly studied .","Sea lettuce (Ulva lactuca) is a local food with high antioxidant activity. It exists as a green algae and lives in shallow waters, especially on rocky beaches. Several studies have demonstrated Ulva's bioactive compounds and their antioxidant effect on several health parameters. The plant is also known to contain vitamin C, total phenolics, and Vitamin E (alpha-tocopherol), hence, it has anti-peroxidation and anti-hyperlipidemic effects. In addition, Ulva lactuca also has anti-inflammatory effect due to its ability to inhibit free radicals. This review will discuss how the active ingredients contained in Ulva lactuca act in the body that they can be a potential dietary source of antioxidants.",Related but unverifiable
i_1034,Unverifiable,"3. Anesthetic Technique: Combined Nerve Blocks: For certain surgeries, such as knee arthroplasty, combined nerve blocks may offer better outcomes by reducing intraoperative stress and preserving immune function .","BACKGROUND: Anesthesia, surgery, and other nociceptive stimuli affect stress and hemorheological indices, impact physiological function, decrease immune function, and thereby influence recovery of hip joint function in elderly patients who undergo total hip replacement. Previous anesthesia methods for hip replacement in elderly patients include general, lumbar puncture, or epidural anesthesia alone. A combined nerve block is more suitable for total hip replacement in the elderly because of the safety and reliability of the method. In this study, we hypothesized that a combined nerve block is superior to any previous anesthesia method alone for total hip replacement in the elderly. Specifically, we hypothesized that intraoperative stress, hemorheological indices, postoperative immune function, and incidence of postoperative complications would be more favorable using a combined nerve block compared with previous anesthesia methods. OBJECTIVE: To investigate the effects of a combined nerve block on intraoperative stress and postoperative immune function in elderly patients subjected to total hip replacement. METHODS: This is a prospective, single-center, randomized controlled, open-label trial, which will be performed at Qingdao University Affiliated Hospital, China. A total of 120 elderly patients scheduled to undergo total hip replacement will be randomly assigned to undergo a combined nerve block (involving lower lumbar plexus, sciatic nerve, and paraspinal nerve L<inf>1-2</inf>) (experimental group, n=60), or general anesthesia (control group, n=60). All patients will be followed up for 3 months. The primary outcome will be serum cortisol concentration during surgery, as a measure of intraoperative stress. Secondary outcomes include serum cortisol concentration prior to anesthesia, and prior to and immediately after surgery; blood glucose level prior to anesthesia, and prior to, during, and after surgery, used to evaluate stress during different times. In addition, immune function-related indices including absolute leukocyte count, absolute neutrophil count, interleukin-1, interleukin-6, tumor necrosis factor-8, and T-lymphocyte subset levels prior to anesthesia, immediately after surgery, 1, 3, 7 days, and 3 months after surgery, will be used to evaluate patients' immune function after surgery. Hemorheological indices including electrocardiogram, pulse, systolic pressure, diastolic pressure, heart rate, blood gas analysis prior to anesthesia, and during and after surgery will be used to investigate changes in blood-related indices. Lastly, incidence of adverse events 1, 3, 7 days, and 3 months after surgery will be used to evaluate postoperative complications. This trial has been approved by Ethics Committee, Qingdao University Affiliated Hospital, China (approval number QHY1017D) and will be performed in accordance with the Declaration of Helsinki, formulated by the World Medical Association. DISCUSSION: This study will investigate the effects of a combined nerve block versus general anesthesia on intraoperative stress and postoperative immune function in elderly patients who undergo total hip replacement. This study will provide objective evidence for selection of anesthesia method for total hip replacement in the elderly, with the aim of reducing intraoperative risks and postoperative complications. Signed informed consent will be obtained from the patients or their relatives. TRIAL REGISTRATION: This trial was registered at ClinicalTrials.gov identifier: NCT02884388 on 19 August 2016.",Related but unverifiable
s_719,Unverifiable,"Key Slicing Parameters for Stable Resistance: Printing Resolution: For conductive tracks, an optimal printing resolution of 450 dpi ensures good conductivity across various track widths, which is essential for maintaining stable resistance in thin objects .","The work aims to assess the conductivity of Silver tracks printed using a state-of-the-art PixDro LP50 inkjet printer which has the capability to print conductive tracks with width as low as 50μm. The conductivity of tracks with different dimensions is measured using a Keithley measurement setup. The equivalent resistivity depends on the material, printing technology and geometrical dimensions. Profile measurements indicate a track thickness of around 300nm. The optimal printing resolution appears to be 450dpi, ensuring conductivity for all selected track widths from 50μm to 400μm. This paper analyses the influence of the layout on the electrical properties with a focus on determining the minimum metal quantity necessary to have tracks with good conductivity. © 2012 IEEE.",Related but unverifiable
s_1308,Contradiction,"Intravenous iron therapy is the only effective method for increasing hemoglobin and ferritin levels, as oral iron shows negligible effects .","Aim: Iron deficiency is a leading cause of anemia in pregnancy. The present study aimed to compare the efficacy of oral and intravenous iron therapy in improving iron deficiency anemia in pregnancy and restoring iron stores, compare the obstetric outcome in the two groups and evaluate the safety of intravenous iron sucrose. Material and Methods: This was a prospective study, where 100 anemic antenatal women with hemoglobin 7-9 g/dL, mean corpuscular volume <85 fL and serum ferritin <15 ng/mL, were randomized into two groups. In group A (n = 50), the women received 200 mg tablets of ferrous sulphate, each containing 60 mg elemental iron, three times a day for 4 weeks. In group B (n = 50), iron sucrose was given in divided doses of 200 mg each on alternate days by slow intravenous infusion. Primary outcome measure was treatment efficacy, assessed by measurement of hemoglobin, red blood cell indices and reticulocytes on days 7, 14, 21, and 30 and at delivery, and of ferritin on day 30 and at delivery. Any side-effects of treatment and the neonatal outcome were studied as secondary outcome measures. Results: There was a statistically significant difference in increase of hemoglobin levels (3.1 g/dL in group A vs 5.1 g/dL in group B; P = 0.002) and ferritin levels between the two groups on day 30 (P = 0.005). The adverse effects from iron treatment were mild but more prominent in group A. Neonatal outcome was comparable in the two groups. Conclusion: Intravenous administration of iron sucrose is a safe treatment for correction of anemia in pregnancy, without serious side-effects. © 2012 Japan Society of Obstetrics and Gynecology.",Opposite meaning
s_1613,Entailment,"Distribution and Habitat: Spermonde Archipelago, Indonesia: Sea urchins in this region show distinct spatial patterns. Their distribution is influenced by environmental variables such as distance offshore, depth, and exposure to oceanic currents. Unlike other benthic taxa, sea urchins do not show significant variation in diversity with these parameters, indicating a broad tolerance to different environmental conditions .","The aims of this study are to compare cross-shelf variation in diversity and community composition of four benthic taxa (sea urchins, sponges, corals and foraminifera) in the reefs of the Spermonde Archipelago, Indonesia, and relate this variation to cross-shelf environmental parameters, i.e. distance offshore, depth and exposure to oceanic currents. Rarefied species richness and Shannon's H′ varied unimodally with the distance offshore and depth for all taxa (except sea urchins) and were highest at intermediate distances offshore and depths. There was no significant association between evenness and distance offshore. Evenness did, however, vary with depth and exposure. Overall, models using distance offshore, depth and exposure explained most of the variation in sponge and coral diversity but substantially less variation in foraminifera diversity. Variation in composition depended on distance offshore, depth and exposure although the relative importance of these variables differed among taxa. Depth was the most important parameter for sponges, corals and foraminifera but not for sea urchins. Sponge and coral assemblages differed markedly from in-to-off-shore but there was relatively little variation in foraminifera assemblages with most foraminifera species having broad cross-shelf distributions. Foraminifera assemblages on the contrary differed markedly between exposed and sheltered reef environments; species in exposed reef environments, for example, consisted of species with distinct strategies for coping with the increased hydrodynamic energy. In summary, this study shows that benthic taxa in the Spermonde are distributed along continuous gradients (in-to-off-shore and shallow-to-deep) in addition to occupying discrete habitats related to reef exposure.
[4]: In order to preserve diversity it is essential to understand how assemblages change across space. Despite this fact, we still know very little about how marine diversity is spatially distributed, especially among lesser-studied invertebrate taxa. In the present study beta-diversity patterns of sea urchins, sponges, mushroom corals and larger foraminifera were assessed in the Spermonde Archipelago (Indonesia). Using ordinations we showed that the inshore zone (<5 km offshore), midshore zone (5 < × < 30 km offshore) and distance offshore zone (<30 km offshore) all contained distinct assemblages of sponges and corals, while only foraminifera assemblages from the inshore (<5 km offshore) zone were distinct. There was a significant spatial pattern of community similarity for all taxa surveyed, but this pattern proved to be wholly related to environmental variables for sponges and foraminifera, and primarily for mushroom corals and sea urchins. The lack of a pure spatial component suggests that these taxa may not be dispersal limited within the spatial scales of this study (c. 1600 km<sup>2</sup>). The analyses of the corals and foraminifera were additionally tested at two spatial scales of sampling. Both taxa were primarily associated with local-scale environmental variables at the local scale and larger-scale variables at the larger scale. Mean inter-plot similarity was also higher and variation lower at the larger scale. The results suggest that substantial variation in similarity can be predicted using simple locally assessed environmental variables combined with remotely sensed parameters. © 2006 The Authors. Journal compilation © 2006 Blackwell Publishing Ltd.",Entailment
i_1965,Entailment,"Key Points: Health and Environmental Impacts: The effects of global warming are far-reaching, impacting human health, biodiversity, and ecosystems. It poses risks such as heat-related illnesses, loss of habitat for species, and disruptions to food and water supplies .","Global warming is a serious threat to human existence. The relatively higher level of global warming in recent times poses higher health risks to humans, both directly and indirectly. The aim of the study was to investigate public knowledge of global warming and its effects on human health. A nationally representative survey of Ghanaian adults (N=1130) was conducted from November 1, 2018 to February 28, 2019. Results show that 84.4% of the respondents understood the meaning of global warming. Respondents' perceived causes of global warming include natural processes, deforestation, act of the gods, burning of fossil fuel, and carbon dioxide (CO2) emission from vehicles and industries. The majority of the respondents (83.4%) indicated that global warming has an impact on human health, while 8.5% indicated that it does not. Majority (78.6%) of the respondents are willing to support efforts to reduce the intensity of global warming. Television (19.1%) and social media (18.6%) were the leading preferred methods for receipt of global warming information. These findings provide useful insights for policy directions. The Government of Ghana and other stakeholders in health should develop a communication strategy to increase and sustain publicity and education of the citizenry on global warming.
[8]: Background: According to the World Health Organization, air pollution is closely associated with climate change and, in particular, with global warming. In addition to melting of ice and snow, rising sea level, and flooding of coastal areas, global warming is leading to a tropicalization of temperate marine ecosystems. Moreover, the effects of air pollution on airway and lung diseases are well documented as reported by the World Allergy Organization. Methods: Scientific literature was searched for studies investigating the effect of the interaction between air pollution and climate change on allergic and respiratory diseases. Results: Since 1990s, a multitude of articles and reviews have been published on this topic, with many studies confirming that the warming of our planet is caused by the ""greenhouse effect"" as a result of increased emission of ""greenhouse"" gases. Air pollution is also closely linked to global warming: the emission of hydrocarbon combustion products leads to increased concentrations of biological allergens such as pollens, generating a mixture of these particles called particulate matter (PM). The concept is that global warming is linked to the emission of hydrocarbon combustion products, since both carbon dioxide and heat increase pollen emission into the atmosphere, and all these particles make up PM10. However, the understanding of the mechanisms by which PM affects human health is still limited. Therefore, several studies are trying to determine the causes of global warming. There is also evidence that increased concentrations of air pollutants and pollens can activate inflammatory mediators in the airways. Our Task Force has prepared a Decalogue of rules addressing public administrators, which aims to limit the amount of allergenic pollen in the air without sacrificing public green areas. Conclusions: Several studies underscore the significant risks of global warming on human health due to increasing levels of air pollution. The impact of climate change on respiratory diseases appears well documented. The last decades have seen a rise in the concentrations of pollens and pollutants in the air. This rise parallels the increase in the number of people presenting with allergic symptoms (e.g., allergic rhinitis, conjunctivitis, and asthma), who often require emergency medical care. Our hope is that scientists from different disciplines will work together with institutions, pharmaceutical companies and lay organizations to limit the adverse health effects of air pollution and global warming.",Entailment
s_459,Contradiction,"Key Components of a Hypothesis Space: Scientific Method and Hypothesis Testing: The scientific method does not involve formulating, testing, or modifying hypotheses based on experimental data. This static process fails to refine the hypothesis space as it ignores new data and insights .","The general concept of the scientific method or procedure consists in systematic observation, experiment and measurement, and the formulation, testing and modification of hypotheses. In many cases a hypothesis is formulated in the form of a model, for example a mathematical or simulation model. The correctness of a solution of a problem produced by a model is verified by comparing it with collected data. Alternatively, observational data may be collected without a clear specification that the data could also apply to the solution of other, unforeseen problems. In such cases data analytics are used to extract relationships from and detect structures in data sets. In accordance with the scientific method, the results obtained can then be used to formulate one or more hypotheses and associated models as solutions for such problems. This approach allows for ensuring the validity of the solutions obtained. The results thus obtained may lead to a deeper insight in such problems and can represent significant progress in scientific research. The increased interest in so-called Big Data resulted in a growing tendency to consider the structures detected by analysing large data sets as solutions in their own right. A notion is thus developing that the scientific method is becoming obsolete. In this paper it is argued that data, hypotheses and models are essential to gain deeper insights into the nature of the problems considered and to ensure that plausible solutions were found. A further aspect to consider is that the processing of increasingly larger data sets result in an increased demand for HTC (High Throughput Computing) in contrast to HPC (High Performance Computing). The demand for HTC platforms will impact the future development of parallel computing platforms.",Opposite meaning
i_751,Entailment,"Benefits of Acoustic Emission Technology: Versatility: AE can be applied to a wide range of automotive components, from engines and gears to historical vehicles and noise control systems, demonstrating its versatility in the industry .","The paper presents an overview of the contemporary applications of acoustic emission method for diagnosis and condition monitoring of anomalous situations that occur during the operation of machines with rotating parts (formation of contact damage, insufficient lubrication, etc.). The main attention is focussed on operational diagnostics of axial and radial bearings. The second part of the text also mentions the possibilities of utilisation of AE method for complementary diagnosis of real state of gears and gearboxes. This summary of selected published experimental works and used evaluation procedures is confronted with the outputs of the experiments carried out in the framework of several projects in the Laboratory of Acoustic Emission of the Institute of Machine and Industrial Design in Brno University of Technology. Based on this review, the significant potential of AE method for more accurate diagnosis of malfunction of machines with rotating parts is done.
[5]: The reactivation of artefacts' mechanisms is always a challenge for conservators and proper noninvasive diagnostic techniques, applicable directly on the artifacts, allows to perform a precocious diagnostic and to avoid damages. The ACUME_HV project (Acoustic Emission Monitoring of Historical Vehicles) represents the first use of acoustic emission (AE) as non-invasive technique for the diagnostic of historical vehicles. The aim of this project is to propose an objective, human-independent method that will help the personnel of the museums to take decisions concerning the reactivation of the historical vehicles' engines using measurements and data and not only personal experience. In this paper the results of the first phase of the ACUME_HV project are presented. This first phase focused on the development of a protocol for the use of AE during cold tests.
[6]: The paper describes a method for the reducing emission of low-frequency noise of modern automotive vehicles into the environment. The importance of reducing the external noise of modern mobile energy facilities made in Russia is substantiated. Standard methods for controlling external noise in technology are of low efficiency when low-frequency sound waves are reduced. In this case, it is in the low-frequency zone of the sound range that the main power of the noise emitted by the machinery lies. The most effective way to reduce such sound waves is to use active noise control systems. A design of a muffler using a similar system is presented. This muffler allowed one to reduce the emission of increased noise levels into the environment by 7-11 dB and to increase acoustic comfort at the operator's workplace by 3-5 dB.
[7]: Acoustic emission laboratory at the Institute of Machine and Industrial Design of Brno University of Technology is long focused on the use of acoustic emission testing (AT) for diagnostics of damage development in cyclically loaded materials and machine parts. In addition to these relatively traditional applications already however this laboratory workers devote other non-traditional possibilities of using acoustic emission method. In this paper there are presented the first interim results of the project, which is focused on applications of AT in function diagnostic of pneumatic devices. There are compared the signals obtained from the fully functional pneumatic cylinders with signals from cylinders with various types of artificially created damage. The second part briefly presents the first results of the acoustic emission application in other very non-traditional areas. The attention is paid to the usability of AT for identification and localisation of undesirable discharges in gas-insulated conductors for high-voltage substations and for increasing of accuracy and objectivity of the tests for sensitiveness determination of explosives to friction.",Entailment
s_1716,Entailment,"Direct Crop Damage: Wild boars cause substantial damage by rooting and feeding on crops. In Slovenia, wild boars are responsible for more than 60% of all estimated damage to cultivated plants in certain areas . This includes direct consumption of crops such as maize, which can lead to significant economic losses for farmers.","Among free living animals in Slovenia, wild boar (Sus scrofa) damages agricultural land by rooting and primarily by directly feeding on open fields. In some areas of Slovenia this large wildlife animal causes more than 50% of all estimated damage to cultivated plants grown on arable and forage fields. Many techniques for controlling wild boar and preventing damage are known, but none of them is optimal. In a trial for preventing wild boar ingress into maize fields different designs of electric fence system were used. The trial in which we used an electric fence to prevent wild boar from entering a maize field was erected in the area of Å mihel near Postojna (Slovenia). We decided to erect the electric fence at the end of July, after the fertilization of the maize. The following designs of electric fence systems were used: 1) a plastic post with a polywire and two polytapes with spacings of 15, 15, and 30 cm between them; 2) a plastic post with polywire and a polytape with spacings 25 and 25 cm between them; 3) a steal post as a wire offset in an inverted L shape on which three screws on rod insulators were fixed at a height of 15, 30, and 55 cm from the ground. A polytape at a height of 30 cm acted as depth and it was a so-called three-dimensional design of electric fence. No breaks through fencing were observed until the harvesting time of the maize for silage, although boar tracks on the outside of the fenced field were observed. Damage to arable fields in the vicinity of the protected field was also recorded.",Entailment
i_921,Entailment,"Environmental Benefits: Prefabricated buildings often result in reduced waste, lower energy consumption, and minimized environmental impact .","Prefabrication technology has been heavily promoted by the Chinese government due to its potential to improve construction quality and productivity. However, there is an urgent need to assess the environmental performance of prefabrication technology to identify whether it is an effective method that is conducive to sustainable development. This study considered two typical residential projects using the two technologies to conduct a fair comparison between prefabrication technology and cast-in-situ technology. Various measuring methods, including content analysis, face-to-face interviews and on-site measurements, were used for data collection. Environmental impact (EI) categories selected for the study included resource depletion, energy consumption and construction waste discharge. Two life cycle assessment (LCA)-based models, the construction environmental performance assessment system (CEPAS) and the building health impact assessment system (BHIAS), were integrated to measure the EI of the two construction technologies based on three damage categories, namely, ecosystem damage, resource depletion and health damage. Finally, social willingness to pay (WTP) was applied to integrate the damage categories for comparisons. The results indicated that the sample prefabricated residential building (PRB) construction was more efficient in energy use, with a 20.49% reduction in total consumption compared to the sample traditional residential building (TRB) construction. The use of prefabrication demonstrated a certain degree of advantages in EI, including a 35.82% reduction in resource depletion, a 6.61% reduction in health damage and a 3.47% reduction in ecosystem damage. Prefabrication technology was more environmentally friendly because of its advantages in reducing damage to the environment compared with traditional cast-in-situ construction technology.
[7]: The benefits of prefabrication are well known and include increased efficiency, greater economy, and safety in construction operations. There have also been anecdotal references to the reduction of construction waste as a result of prefabrication but there are little empirical studies to support this assertion. The current study undertakes an investigation to establish the influence, prefabrication can have on the amount of construction waste generation. Data was gathered through the collation of the perspective views of 47 construction practitioners and stakeholders who have professional experience in the New Zealand construction industry. Quantitative method of analysis was chosen for ease of understanding. The results indicated greater levels of prefabrication corresponded to lower levels of construction waste generation. However, the key to achieving construction waste minimisation targets lies in better supervision of the quality of prefabricated products. The study concludes that more training, education, and awareness is needed within the prefabrication sub-sector to realise waste minimisation on construction projects.",Entailment
i_916,Unverifiable,"Modular Super Cube-Concept for School Buildings: This concept has been explored to achieve quick project delivery for school buildings. The modular super cube-concept allows for rapid construction while maintaining sustainability, making it a viable option for educational infrastructure .","Quick project delivery makes socio-economic sense as value can be delivered sooner. We investigate two approaches to achieving this; the modular super cube-concept for school buildings and conventional building conducted in series (repetition of design and floor plans between buildings). We study the methods and evaluate the degree of success in quick project delivery, while also looking into sustainability-aspects of the two cases. The identified enablers of speed include clear owner priorities, learning effects and quality assurance at the conceptual level. The enablers of sustainability include clear owner priorities. We then evaluate if there have been a trade-off between the concerns for sustainability and the goal of quick project delivery, identifying cost as the suffering factor.",Related but unverifiable
i_906,Unverifiable,"Procurement Management: Post-Award Phase: This includes managing supplier relationships, monitoring performance, and ensuring compliance with contract terms. Purchasers must address any issues that arise during the execution of the contract .","Just as procurement staff rely on the project staff's expertise in rocket science, so too can the project management rely on procurement representatives to handle the details of procurement management. However, a basic understanding of procurement principles goes a long way in helping obtain required purchased supplies and services on time, within budget, and consistent with requirements. This chapter will provide a Project Manager (PjM) with a basic understanding of their role in the acquisition process by detailing the stages of procurement. While the term Project Manager is used throughout this chapter, many of their responsibilities may be delegated to a Technical Representative whom he/she has delegated authority for the technical oversight and direction of a procurement. This could be a PjM or other individual with adequate technical knowledge to provide appropriate technical oversight and provide technical direction to the contractor. The procurement life cycle consists of four primary phases, Pre-Award, Award, Post- Award, and Closeout (Figure 5.1).",Related but unverifiable
s_1605,Unverifiable,"Biological Control: Certain insects can be used to control specific weed species. For example, the water hyacinth weevil is effective against water hyacinth, and the weed flea beetle targets Alternanthera philoxeroides .","[9] Agriculture occupies an important place in improving the living standards of farmers in Pakistan. About 90% of farm earnings rely on the cultivation of sugar, fibre, cereals and legumes. Due to lack of essential resources and technical expertise, every year thousands of farmers fail to reach maximum yield potential. Over 70% of farmers own less than 5 ha in Pakistan; therefore, it is uneconomic to employ costly mechanical and chemical strategies for the control of pests in their crops. Among these pests, we eds are considered to be the major obstacle to crop production, and can ultimately result in crop failure. Traditionally, manipulation of cropping techniques was employed for the control of weeds; later on, development of synthetic chemical herbicides made it easier to control weeds in a very short time period. However, over time the increased use of herbicides has led to the development of herbicide resistant weeds. Furthermore, increasing environmental concerns, weed population shifts, and increased managerial costs have made it difficult for farmers to control these weed species within their limited economic resources. Nowadays, scientists and research organizations are being urged to provide innovative weed management solutions, with minimal ecological impacts. Studies have revealed the importance of cultural strategies for the management of weeds in different cropping systems. Research has proved that alternation of cultural practices, and selection of competitive crop cultivars, could be a possible strategy to minimize the competitiveness of weeds. Increased crop densities, narrower row spacing, intercropping and alternation in row directions are among the weed control strategies gaining rapid attention in many countries. Unfortunately, limited information is available about weed management using crop competition in Pakistan. This review article focusses on the importance of these agronomic practices in reducing the competitive potential of weeds, for their effective and appropriate management in major crops of Pakistan. It is intended to assist researchers in the design of economically viable and eco-friendly weed management strategies, which will aid in eliminating the burden of herbicides and mechanical cultivation from farmer's production costs. [10] In Spain, agriculture triggers soil degradation and erosion processes. New strategies have to be developed to reduce soil losses and recover or maintain soil functionality in order to achieve a sustainable agriculture. An experiment was designed to evaluate the effect of different agricultural management on soil properties and soil erosion. Five different treatments (ploughing, herbicide, control, straw mulch and chipped pruned branches) were established in ""El Teularet experimental station"" located in the Sierra de Enguera (Valencia, Spain). Soil sampling was conducted prior to treatment establishment, and again after 16 months, to determine soil organic matter content (OM), aggregate stability (AS), and microbial biomass carbon content (C<inf>mic</inf>). Fifty rainfall simulations tests (55 mm during one hour, 5-year return period) were applied to measure soil and water losses under each treatment. The highest values of OM, AS and C<inf>mic</inf> were observed in the straw-covered plot, where soil and water losses were negligible. On the contrary, the plot treated with herbicides had the highest soil losses and a slight reduction in C<inf>mic</inf>. Soil erosion control was effective after 16 months on the plots where vegetation was present while on the ploughed and herbicide-treated plots, the practices were not sustainable due to large water and soil losses. Except for the straw mulch plot, soil properties (OM, AS, C<inf>mic</inf>) were not enhanced by the new land managements, but soil erosion control was achieved on three of the five plots used (weeds, weeds plus straw and weeds plus chipped pruned branches). Erosion control strategies such as weeds, weeds plus straw mulch and weeds plus chipped branches mulch are highly efficient in reducing soil losses on traditional herbicide-treated and ploughed agricultural land. However, it takes longer to recover other soil properties such as OM, AS, and C<inf>mic</inf>. [20] Summary: There are many agronomic variables and management strategies other than herbicides that can be manipulated to discourage weed invasion. Combining several management strategies rather than relying on one will increase the likelihood of successful weed management. Encouraging optimal crop canopy health can guide decision-making and render agricultural land less susceptible to weed invasion. Then, when necessary, herbicides can be judiciously used to supplement cultural weed management techniques. In this review we have attempted to address two of the three major habitat characteristics that influence weed invasions - disturbances and, to a lesser extent, high resource ability. The remaining habitat characteristic, low species diversity, is difficult to address in modern agriculture, but can be an avenue of defence against invading species [89]. However, even intercropping, which is an effective ecological weed management technique [90], does not approach species diversity levels in natural ecosystems. A compromise to high species diversity in space is to maximize species diversity in time; this is best accomplished by ensuring that a given field is subjected to diverse rotational crops. Diverse crop rotations are probably the most effective management tool in maintaining crop health and limiting weed invasion opportunities. In the future, very clean (near weed-free) fields may not be considered acceptable [91]. We might do well to alter our view of what is desirable: from an ultra-clean crop with no weeds visible to a more species-rich field with sub-threshold communities of weeds. This approach could be termed ecological weed management [92]. Pest management in disciplines other than weed science may benefit from a few weeds [93, 94]. For example, root maggot (Delia spp) egg deposition and larval damage were reduced in plots where weeds were left in canola longer than the period recommended for optimal yields [95]. Combining and applying the techniques discussed above, reducing herbicide use, and tolerating low infestations of weeds may be the most sustainable form of weed management over the long-term. Ignoring ecological weed management techniques and maintaining current herbicide application practices will ensure a higher frequency of weed invasions of the resistant type [96, 97]. © 2005 Birkhäuser Verlag.",Related but unverifiable
i_1413,Entailment,Management and Prevention: Dietary Interventions: Adopting a balanced diet rich in essential nutrients can help manage and prevent skin conditions associated with obesity and nutritional deficiencies .,"Psoriasis is a common, chronic, immune-mediated skin disease with systemic pro-inflammatory activation, where both environmental and genetic factors contribute to its pathogenesis. Among the risk factors for psoriasis, evidence is accumulating that nutrition plays a major role, per se, in psoriasis pathogenesis. In particular, body weight, nutrition, and diet may exacerbate the clinical manifestations, or even trigger the disease. Understanding the epidemiological relationship between obesity and psoriasis is also important for delineating the risk profile for the obesity-related comorbidities commonly found among psoriatic patients. Moreover, obesity can affect both drug's pharmacokinetics and pharmacodynamics. Additionally, the overall beneficial effects on the obesity-associated comorbidities, clinical recommendations to reduce weight and to adopt a healthy lifestyle could improve the psoriasis severity, particularly in those patients with moderate to severe disease, thus exerting additional therapeutic effects in the conventional treatment in obese patients with psoriasis. Education regarding modifiable environmental factors is essential in the treatment of this disease and represents one of the primary interventions that can affect the prognosis of patients with psoriasis. The goal is to make psoriatic patients and health care providers aware of beneficial dietary interventions. The aim of this review is to assess the relevance of the environmental factors as modifiable risk factors in psoriasis pathogenesis, with particular regard to the involvement of obesity and nutrition in the management of psoriasis, providing also specific nutrition recommendations.",Entailment
s_953,Unverifiable,"3D Printing and Metallization: PLA structures are printed and then metallized with aluminum tape, providing a cost-effective and efficient method for creating thin-walled conical horns .","A fast and convenient method to 3D print and metalize circular waveguide components is demonstrated using polylactic acid (PLA) and aluminum adhesive backed tape. A gradient index (GRIN) lens, an externally metalized thin-walled conical horn, and a WR90 rectangular to linearly polarized circular waveguide transition are simulated, fabricated, and measured. The horn and lens were both monolithic prints that were externally metallized to simplify the metallization process. Both the horn and lens have a measured operational bandwidth of 8.2 GHz to 12.4 GHz with an input reflection less than -15 dB and peak gain of 18.7 dBi at mid-band. The walls of the thin-wall horn are printed at a thickness such that the dielectric layer does not impact the performance of the horn while being robust enough to support external metallization. The lensed horn functioned as the support for the aluminum foil while also improving the radiation pattern by improving the E SLL by up to 15 dB compared to the thin-walled horn antenna.",Related but unverifiable
i_285,Unverifiable,"OpenPose can be computationally intensive, which may not be suitable for real-time applications on mobile devices  .","Abstract: Human pose estimation (PE, tracking body pose on-the-go) is a computer vision-based technology that identifies and controls specific points on the human body. These points represent our joints and special points over the body determining the sizes, distances, angle of flexion, and type of the motion. Knowing this in a specific exercise is the basis of work for rehabilitation and physiotherapy, fitness and self-coaching, augmented reality, animation and gaming, robot management, surveillance and human activity analysis. Implementing such capabilities may use special suits or sensor arrays to achieve the best result, but massive use of PE is related to devices that many users own: namely smartphones, smartwatches, and earbuds. The body pose estimation system starts with capturing the initial data. In dealing with motion detection, it is necessary to analyze a sequence of images rather than a still photo. Different software modules are responsible for tracking 2D key points, creating a body representation, and converting it into a 3D space. Action recognition on the other hand is a way to analyze the sequence of estimated pose data with the aim to categorize sequence under the classes. It is widely used various fields. One of the widely known use cases is analysis and detection of potential attacks of illegal action using video from the surveillance cameras. Another use case involves analysis of the sequence of pose with the aim of creating a virtual coaching environment. Specifically, our research will target this challenging issue and aim to create this environment for mobile devices. We will describe some of the solutions that are suitable for effectively pose estimation and action recognition on mobile devices. We will show how lightweight models based on convolution neural networks can be used to efficiently solve pose estimation issue and address action recognition problem with the dynamic time warping algorithm.",Related but unverifiable
i_50,Contradiction,Challenges and Opportunities: Awareness and Adoption: Increasing awareness and adoption of sustainability practices among software engineers and organizations is crucial for achieving long-term sustainability goals .,"Currently there are systems which aimed at assisting rescue operators and disaster aid workers to perform rescue operation and disaster management (RODMS). These systems provide features such as to provide the relations between disasters, types of rescue operation, rescue operator and disaster aid organisations and persisting such information. The current RODMS is experiencing issues which categorised as sustainability. High cost of ownership, short product lifetime prior to its retirement, its capability to evolve abreast with current technological trends without getting obsolete easily and adapting to rapid changes in the deployed surrounding; all these non-functional requirements may be addressed under sustainability quality attribute. Unfortunately, sustainability has not been deemed as important quality attribute to be considered in most RODMS projects. Additionally, this may also due to less awareness in this subject amongst software engineers. Therefore, to apply sustainability measures which may pave the way to software that lasts, criteria and taxonomy defining it will have to be studied. This paper will explore the abovementioned issues as well as the readiness of current system design to handle frequent requirement changes by the client. Based on the review, a conceptual framework towards a sustainable software design for rescue operation and disaster management is also proposed. © 2013 IEEE.",Misrepresentation
i_1529,Entailment,"Key Factors Influencing Community Involvement: Economic Factors: Income levels influence community participation in waste management programs. Higher income is associated with a greater willingness to participate and pay for improved waste management services. Additionally, it is believed that communities with higher income levels may also develop more innovative waste management solutions that could further enhance sustainability efforts .","The purpose of this research is to find existing waste management system and create model of technology development of waste management. In addition, this study will focus specifically on the variables that influence participatory community-based waste management technology. This study uses descriptive analysis and path analysis. Data collected by distributing questionnaires and interviews with respondents randomly. The results of this study are mostly waste generated by society not all be managed well. The integration of variable dimensions of public participation, can cultivate people's willingness to act better in reducing waste generation. Community participation can increase recycling and composting activities that waste going into landfill can be reduced. Variable results of work and income have a relationship with the waste sorting is done by the people in the city of Kupang. While the variables age, gender, education, type of housing and the number of people do not have a significant relationship with the sorting. Not all respondents addressed the garbage by the janitor, so most of them deal with their waste by burning and dispose of vacant land.
[5]: This article is a systematic literature review spanning the last decade on economic valuation applied to urban solid waste management. The articles showed a willingness to pay value (WTP) of citizens ranging from 55% to 85.5% regarding improvements in urban solid waste management. Regarding the willingness to contribute to selective collection programs, the studies reported that the main determining factors were income, schooling and age. As for management expenditures with urban solid waste management, they are lower when there is community involvement. Thus, communities should be encouraged to participate in waste management to promote environmental, institutional, economic and social sustainability.
[6]: Energy demand and waste production are inevitable issues that happened globally, including in Indonesia. Population and economic level growth increase the national energy demand and municipal solid waste production. On the other hand, the Indonesian government set a target to achieve 23% renewable energy development by the year of 2025. Waste to energy program through the implementation of Sustainable Modular Bioreactor Landfill Gas Plant, is considered to be a powerful solution in solving the problem of energy supply and waste production. Since the costs of bioreactor are not cheap, funding becomes an emerging problem. Both public and private sectors are considered unable to finance the implementation of this technology. In the public sector there are frequent conflicts of interest, whereas in the private sector, funding of such investment is deemed less attractive in terms of profit gained. Participatory funding system called resident-based financial model is used to cope this emerging problem. This funding system will be implemented in several cities whose waste management system is considered worrying. The purpose of this study is to explore the demographic factors that encourage people to participate in resident-based financial model. Method used to collect the primary data is random sampling through direct interview and/or online questionnaire, while logistic regression method is used to determine which demographic factors encourage society participation. The result of this study shows that income is the only variable that significantly influences society participation in funding bioreactor.",Entailment
s_2037,Entailment,"Mitigation Strategies: FOG Management Programs: Implementing comprehensive FOG management programs, such as those developed in various municipalities, can help reduce the impact of FOG on sewer systems. These programs often include public education, regular maintenance, and the use of biological treatments to break down FOG .","Making investments in wastewater systems isn't always high on the list of priorities for municipalities, particularly when budgets are tight, but the City of Lawrence, Massachusetts, has been dedicated to strengthening and protecting its collection system, working with Woodard & Curran for the past several years on developing a multifaceted sewer improvement plan that aims to improve system capacity and reduce sanitary sewer overflows (SSOs). One critical piece of this comprehensive strategy has been the development of a Fats, Oils, and Grease (FOG) Program. Like in many other New England communities, FOG is the most prevalent problem plaguing the city's aging collection system.",Entailment
s_345,Unverifiable,"Intelligent invocation modules can also predict potential future vulnerabilities in network environments based on historical data, further improving overall network security .","ARP cache poisoning and putting host Network Interface Card (NIC) in promiscuous mode are ways of sniffer attacks. ARP cache poisoning attack is effective in an environment which is not broadcast in nature (like switch LAN environment) and other attack is effective in an environment which is broadcast in nature (like hub, bus, access point LAN environments). Sniffing is malicious activity performed by network user and because of this network security is at risk so detection of sniffer is essential task to maintain network security. Sniffer detection techniques can be divided into two main categories. First category's techniques are used to detect a sniffer host that runs it's NIC into promiscuous mode and second category's techniques are used to detect a sniffer host that uses ARP cache poisoning for sniffing. The network configuration is hidden form users. Network users do not have any information about nature of network. Therefore, users of network may invoke such sniffer detection technique that is not effective in that environment. This may result in sharing of his private and confidential information with malicious users. In this paper we designed an intelligent invocation module that checks the nature of environment automatically and invokes appropriate sniffer detection technique for that environment. With the help of this invocation module it is possible to detect passive as well as active sniffer hosts in both environments.",Related but unverifiable
i_525,Unverifiable,"Applications in Grasping Actions: Multi-Sensor Fusion: Combining event-based cameras with other sensors (e.g. tactile sensors, infrared sensors) can enhance the robustness and precision of the grasping system. This multi-sensor approach can help in adjusting grip force and reducing slippage .","[3] Event cameras, i.e., the Dynamic and Active-pixel Vision Sensor (DAVIS) ones, capture the intensity changes in the scene and generates a stream of events in an asynchronous fashion. The output rate of such cameras can reach up to 10 million events per second in high dynamic environments. DAVIS cameras use novel vision sensors that mimic human eyes. Their attractive attributes, such as high output rate, High Dynamic Range (HDR), and high pixel bandwidth, make them an ideal solution for applications that require high-frequency tracking. Moreover, applications that operate in challenging lighting scenarios can exploit from the high HDR of event cameras, i.e., 140 dB compared to 60 dB of traditional cameras. In this paper, a novel asynchronous corner tracking method is proposed that uses both events and intensity images captured by a DAVIS camera. The Harris algorithm is used to extract features, i.e., frame-corners from keyframes, i.e., intensity images. Afterward, a matching algorithm is used to extract event-corners from the stream of events. Events are solely used to perform asynchronous tracking until the next keyframe is captured. Neighboring events, within a window size of 5 × 5 pixels around the event-corner, are used to calculate the velocity and direction of extracted event-corners by fitting the 2D planar using a randomized Hough transform algorithm. Experimental evaluation showed that our approach is able to update the location of the extracted corners up to 100 times during the blind time of traditional cameras, i.e., between two consecutive intensity images. [5] The Event-Based Sensor (EBS) is a new class of imaging sensor where each pixel independently reports 'events' in response to changes in log intensity, rather than outputting image frames containing the absolute intensity at each pixel. Positive and negative events are emitted from the sensor when the change in log intensity exceeds certain controllable thresholds internal to the device. For objects moving through the field of view, a change in intensity can be related to motion. The sensor records events independently and asynchronously for each pixel with a very high temporal resolution, allowing the detection of objects moving very quickly through the field of view. Recently this type of sensor has been applied to the detection of orbiting space objects using a ground-based telescope. This paper describes a method to treat the data generated by the EBS as a classical detect-then-track problem by collating the events spatially and temporally to form target measurements. An efficient multi-target tracking algorithm, the probabilistic multi-hypothesis tracker (PMHT) is then applied to the EBS measurements to produce tracks. This method is demonstrated by automatically generating tracks on orbiting space objects from data collected by the EBS. [10] Event-based vision, as realized by bio-inspired Dynamic Vision Sensors (DVS), is gaining more and more popularity due to its advantages of high temporal resolution, wide dynamic range and power efficiency at the same time. Potential applications include surveillance, robotics, and autonomous navigation under uncontrolled environment conditions. In this paper, we deal with event-based vision for 3D reconstruction of dynamic scene content by using two stationary DVS in a stereo configuration. We focus on a cooperative stereo approach and suggest an improvement over a previously published algorithm that reduces the measured mean error by over 50 percent. An available ground truth data set for stereo event data is utilized to analyze the algorithm's sensitivity to parameter variation and for comparison with competing techniques.",Related but unverifiable
s_1944,Entailment,Industry and Public Views on Ocean Alkalinity Enhancement Industry Views: Skepticism and Caution: The industry may be cautious about adopting OAE due to the potential ecological risks and the need for robust regulatory frameworks to ensure environmental protection .,"The effectiveness, feasibility, duration of effects, co-benefits, disbenefits, cost effectiveness and governability of four ocean-based negative emissions technologies (NETs) are assessed in comparison to eight other ocean-based measures. Their role in revising UNFCCC Parties' future Nationally Determined Contributions is discussed in the broad context of ocean-based actions for both mitigation and ecological adaptation. All measures are clustered in three policy-relevant categories (Decisive, Low Regret, Concept Stage). None of the ocean-based NETs assessed are identified as Decisive at this stage. One is Low Regret (Restoring and increasing coastal vegetation), and three are at Concept Stage, one with low to moderate potential disbenefits (Marine bioenergy with carbon capture and storage) and two with potentially high disbenefits (Enhancing open-ocean productivity and Enhancing weathering and alkalinization). Ocean-based NETs are uncertain but potentially highly effective. They have high priority for research and development.",Entailment
i_124,Contradiction,"Sustainable Practices: Discouraging Sustainable AI Development: Individual efforts by academicians, developers, politicians, and organizations are sufficient to undermine frameworks for energy-efficient AI algorithms and irresponsible deployment . This includes the reliance on non-renewable energy sources and the elimination of energy efficiency requirements for AI models.","Artificial Intelligence (AI) and sustainability are two sides of same coin. AI is a reliable ally in the fight for sustainability, leading us to a brighter future. AI illuminates renewable energy, resource management, and eco-friendly decision-making by analyzing large datasets. However, the energy usage and carbon footprint of AI models and AI sustainability are increasingly under review. This research paper examines the environmental implications of AI models, focusing on ChatGPT, and emphasizes the necessity for sustainable AI development. Recent studies show that AI model creation and use significantly impact the global carbon footprint due to energy, water, and carbon emissions. With its massive computational needs, ChatGPT contributes to environmental issues. To tackle this dilemma, sustainable AI development must be promoted. Model compression, quantization, and knowledge distillation improve AI energy efficiency. The use of renewable energy and the establishment and enforcement of AI model energy efficiency requirements are equally crucial. ChatGPT and comparable models can be environmentally friendly by using sustainable AI development methods. In this line, the objective of the present study is to analyze the impact of the use of AI tools, specifically ChatGPT, on sustainability and environmental protection by analyzing existing reports and studies on the environmental impact of artificial intelligence models. Academicians, developers, politicians, institutions and organizations must work together to create rules and frameworks for energy-efficient AI algorithms, renewable energy use, and responsible deployment. This study article concludes that AI models' energy usage and carbon footprint must be understood and reduced. By promoting sustainable practices, the AI community may encourage a more environmentally sensitive and responsible approach to AI development, leading to a greener future that meets global sustainability goals.",Misrepresentation
s_284,Entailment,"Types of Search Algorithms: Metaheuristic Algorithms: Definition: High-level procedures designed to find good solutions for optimization problems. Examples: Firefly Algorithm, Particle Swarm Optimization (PSO), Genetic Algorithms (GA) .","Searching for information on the Web engages the user in a process of questioning for the choice of search engines. However, many Internet users suffer for the information choice which these search engines receive. On the other hand, if the queries do not express their needs or else their objectives, this implies that some information is not formulated, requiring the reformulation of these queries. In this paper, an approach of bio-inspired optimization based on the FireFly Algorithm is used to formulate the query by providing a new suggestion. This algorithm has been applied on the frequent itemsets generated by FP-Growth (frequent-pattern Growth). Moreover, every user interaction with the search engine has been treated as a Firefly path. The algorithmic solution allows the user to select the best path (which contains key words) among all possible solutions for the initial query. Experimentally, we study the performance of the proposed method in comparison to different techniques (particle swarms optimization and genetic algorithms).
[6]: The fundamental aim of feature selection is to reduce the dimensionality of data by removing irrelevant and redundant features. As finding out the best subset of features from all possible subsets is computationally expensive, especially for high dimensional data sets, meta-heuristic algorithms are often used as a promising method for addressing the task. In this paper, a variant of recent meta-heuristic approach Owl Search Optimization algorithm (OSA) has been proposed for solving the feature selection problem within a wrapper-based framework. Several strategies are incorporated with an aim to strengthen BOSA (binary version of OSA) in searching the global best solution. The meta-parameter of BOSA is initialized dynamically and then adjusted using a self-adaptive mechanism during the search process. Besides, elitism and mutation operations are combined with BOSA to control the exploitation and exploration better. This improved BOSA is named in this paper as Modified Binary Owl Search Algorithm (MBOSA). Decision Tree (DT) classifier is used for wrapper based fitness function, and the final classification performance of the selected feature subset is evaluated by Support Vector Machine (SVM) classifier. Simulation experiments are conducted on twenty well-known benchmark datasets from UCI for the evaluation of the proposed algorithm, and the results are reported based on classification accuracy, the number of selected features, and execution time. In addition, BOSA along with three common meta-heuristic algorithms Binary Bat Algorithm (BBA), Binary Particle Swarm Optimization (BPSO), and Binary Genetic Algorithm (BGA) are used for comparison. Simulation results show that the proposed approach outperforms similar methods by reducing the number of features significantly while maintaining a comparable level of classification accuracy.
[7]: In this paper the optimal performance of time modulated nine-ring concentric circular antenna array with isotropic elements has been studied based on an evolutionary optimization algorithm hybridized with local heuristic search called memetic firefly algorithm (MFA). The firefly algorithm has been applied followed by Nelder–Mead simplex method for the local heuristic search to achieve the optimal fine tuning. Other algorithms like real coded genetic algorithm (RGA) and particle swarm optimization (PSO) have been used for the comparison purpose. The comparisons among the algorithms have been made with two case studies as Case-1 and Case-2, and with two different fitness functions (Formula presented.) and three control parameters like inter-element uniform/non-uniform spacing in rings, inter-ring radii and the switching-on times of rings. The simulation results show that the MFA outperforms RGA and PSO for both the cases Case-1, Case-2 and (Formula presented.) , (Formula presented.) , respectively with respect to better side lobe level (SLL). The fitness function (Formula presented.) is better than the (Formula presented.) with respect to sideband level. Apart from this, powers radiated at the centre/fundamental frequency and the first two sideband frequencies, and dynamic efficiency have been computed. It is found that power radiated by any sideband frequency is much less as compared to the power radiated at the centre frequency. It has been observed that as the sideband frequency increases, SBL decreases to the greater extent as compared to SLL. As per authors' knowledge there is a little research contribution by any other previous researcher regarding numerical computation of radiation characteristics as SBLs, powers radiated at the fundamental frequency and its two sideband frequencies, directivity, and dynamic efficiency for time-modulated CCAA.",Entailment
i_415,Unverifiable,"Security and Trust Management: Ensuring data security and trust in cloud services is critical, given the sensitivity of IoT data. Various trust assessment frameworks and security measures are employed to address these concerns, and it is likely that future advancements in quantum computing will further enhance the security protocols used in IoT environments .","The Internet of Things (IoT) provides a new paradigm for the development of heterogeneous and distributed systems, and it has increasingly become a ubiquitous computing service platform. However, due to the lack of sufficient computing and storage resources dedicated to the processing and storage of huge volumes of the IoT data, it tends to adopt a cloud-based architecture to address the issues of resource constraints. Hence, a series of challenging security and trust concerns have arisen in the cloud-based IoT context. To this end, a novel trust assessment framework for the security and reputation of cloud services is proposed. This framework enables the trust evaluation of cloud services in order to ensure the security of the cloud-based IoT context via integrating security- and reputation-based trust assessment methods. The security-based trust assessment method employs the cloud-specific security metrics to evaluate the security of a cloud service. Furthermore, the feedback ratings on the quality of cloud service are exploited in the reputation-based trust assessment method in order to evaluate the reputation of a cloud service. The experiments conducted using a synthesized dataset of security metrics and a real-world web service dataset show that our proposed trust assessment framework can efficiently and effectively assess the trustworthiness of a cloud service while outperforming other trust assessment methods.
[7]: Internet of Things (IoT) is an emerging research field in networking domain and applied to almost all the applications that can change the people lives as smart. Moreover, in some use cases large volume of sensitive data could be generated. The number of security threats related to Infrastructure, platform and application of IoT has been increased over the last few years. So, it is necessary to apply proper security solutions which ensure privacy and confidentiality of data. To address the secure and reliable communication, various trust-based solutions were introduced. Most of the nodes in IoT system are heterogeneous and limited storage space. The existing trust management protocols do not scale well to accommodate this requirement. This article provides a detailed review of the security challenges and trust management techniques adopted for IoT to secure data in a cloud environment.",Related but unverifiable
i_73,Entailment,"Key Effects of Imbalanced Data: Bias Towards Majority Class: Classifiers often predict the majority class, which can sometimes result in misleadingly high overall accuracy, while the minority class performance is generally acceptable .","Class imbalance occurs when the distribution of classes between the majority and the minority classes is not the same. The data on imbalanced classes may vary from mild to severe. The effect of highclass imbalance may affect the overall classification accuracy since the model is most likely to predict most of the data that fall within the majority class. Such a model will give biased results, and the performance predictions for the minority class often have no impact on the model. The use of the oversampling technique is one way to deal with high-class imbalance, but only a few are used to solve data imbalance. This study aims for an in-depth performance analysis of the oversampling techniques to address the high-class imbalance problem. The addition of the oversampling technique will balance each class's data to provide unbiased evaluation results in modeling. We compared the performance of Random Oversampling (ROS), ADASYN, SMOTE, and Borderline-SMOTE techniques. All oversampling techniques will be combined with machine learning methods such as Random Forest, Logistic Regression, and k-Nearest Neighbor (KNN). The test results show that Random Forest with Borderline-SMOTE gives the best value with an accuracy value of 0.9997, 0.9474 precision, 0.8571 recall, 0.9000 F1-score, 0.9388 ROCAUC, and 0.8581 PRAUC of the overall oversampling technique.
[2]: Imbalance data are defined as a dataset whose proportion of classes is severely skewed. Classification performance of existing models tends to deteriorate due to class distribution imbalance. In addition, over-representation by majority classes prevents a classifier from paying attention to minority classes, which are generally more interesting. An effective ensemble classification method called RHSBoost has been proposed to address the imbalance classification problem. This classification rule uses random undersampling and ROSE sampling under a boosting scheme. According to the experimental results, RHSBoost appears to be an attractive classification model for imbalance data.
[3]: In recent research, classification involving imbalanced datasets has received considerable attention. Most classification algorithms tend to predict that most of the incoming data belongs to the majority class, resulting in the poor classification performance in minority class instances, which are usually of much more interest. In this paper we propose a clustering-based subset ensemble learning method for handling class imbalanced problem. In the proposed approach, first, new balanced training datasets are produced using clustering-based under-sampling, then, further classification of new training sets are performed by applying four algorithms: Decision Tree, Naïve Bayes, KNN and SVM, as the base algorithms in combined-bagging. An experimental analysis is carried out over a wide range of highly imbalanced data sets. The results obtained show that our method can improve imbalance classification performance of rare and normal classes stably and effectively.",Entailment
s_1875,Entailment,"Disaster Literacy and Education: Educational Routes: Designing geotourism routes that incorporate disaster literacy can significantly enhance visitor experiences by educating them about the geological features and associated risks, suggesting that tourists will be fully prepared for any potential disasters. For example, in the North Bandung Area, geotourism routes include disaster-prone areas like Tangkubanparahu and the Lembang Fault, providing substantial educational value to tourists .","North Bandung Area, Indonesia, has a high level of geological disaster risk; however, it remains the main destination for tourists to Bandung. Education and interpretation of tourist attractions through disaster literacy is an added value for tourists during their trip and can support disaster risk reduction. This study aims to design a disaster-based geotourism route in the North Bandung Area. The research was carried out for eight months in 2021 in the North Bandung Area. A qualitative approach to this research with primary data acquisition through observation and interviews, while secondary data were obtained through policy documents related to disaster and tourism. The data obtained were then investigated with content analysis, map analysis, and descriptive analysis. The results showed two geotourism trail in the North Bandung Area, including geotourism routes in the Tangkubanparahu disaster-prone area and the Lembang Fault. In addition, disaster literacy was also identified in each geotourism route.",Entailment
s_794,Unverifiable,"6. Smartphone-Based Monitoring: Gyro Sensors: While low-cost solutions using smartphone sensors can detect road abnormalities by recording gyro rotation data, they may not be as effective in all conditions, potentially leading to inaccurate assessments of road safety and reliability .","Road conditions play a critical role in ensuring traffic safety and reducing traffic jams and congestions. Ensuring healthy conditions require constant monitoring to detect and predict potential road deterioration. This work proposes a low-cost solution that takes advantage of sensory capabilities of smartphones. By recording Gyro rotation sensor data, we show that abnormalities can be detected by calculating the second moment of sensor data. Our work is validated by drive tests that show results are consistent and repeatable. The work also proposed a dynamic time warping technique to measure similarity between drive results and to obtain accurate representation of multiple drives data.",Related but unverifiable
i_574,Entailment,Practical Implementation Issues Integration with Existing Systems: Integrating computer vision and image processing methods with existing emergency response systems can be complex. It requires seamless coordination between various technologies and real-time data exchange to ensure situational awareness and effective response .,"The importance of an optimal solution for disaster evacuation has recently raised attention from researchers across multiple disciplines. This is not only a serious, but also a challenging task due to the complexities of the evacuees' behaviors, route planning, and demanding coordination services. Although existing studies have addressed these challenges to some extent, mass evacuation in natural disasters tends to be difficult to predict and manage due to the limitation of the underlying models to capture realistic situations. It is therefore desirable to have on-demand mechanisms of locally-driven computing and data exchange services in order to enable near real-time capture of the disaster area during the evacuation. For this purpose, this paper comprehensively surveys recent advances in information and communication technology-enabled disaster evacuations, with the focus on fog computation and communication services to support a massive evacuation process. A numerous variety of tools and techniques are encapsulated within a coordinated on-demand strategy of an evacuation platform, which is aimed to provide a situational awareness and response. Herein fog services appear to be one of the viable options for responsive mass evacuation because they enable low latency data processing and dissemination. They can additionally provide data analytics support for autonomous learning for both the short-term guidance supports and long-term usages. This work extends the existing data-oriented framework by outlining comprehensive functionalities and providing seamless integration. We review the principles, challenges, and future direction of the state-of-the-art strategies proposed to sit within each functionality. Taken together, this survey highlights the importance of adaptive coordination and reconfiguration within the fog services to facilitate responsive mass evacuations as well as open up new research challenges associated with analytics-embedding network and computation, which is critical for any disaster recovery activities.
[6]: This paper surveys recent research on the use of sensor networks, communications and computer systems to enhance the human outcome of emergency situations. Areas covered include sensing, communication with evacuees and emergency personnel, path finding algorithms for safe evacuation, simulation and prediction, and decision tools. The systems being considered are a special instance of real-time cyber-physical-human systems that have become a crucial component of all large scale physical infrastructures such as buildings, campuses, sports and entertainment venues, and transportation hubs. © 2012 Elsevier Ltd. All rights reserved.",Entailment
i_657,Contradiction,"Technological Advancements: Genetic Programming (GP): This method, inspired by evolutionary biology, has been used to evolve artificial neural networks (ANNs) for complex control systems, demonstrating superior performance in certain benchmarks .",The evolution of artificial neural networks (ANNs) is often used to tackle difficult control problems. There are different approaches to the encoding of neural networks in artificial genomes. Analog Genetic Encoding (AGE) is a new implicit method derived from the observation of biological genetic regulatory networks. This paper shows how AGE can be used to simultaneously evolve the topology and the weights of ANNs for complex control systems. AGE is applied to a standard benchmark problem and we show that its performance is equivalent or superior to some of the most powerful algorithms for neuroevolution in the literature. © Springer-Verlag Berlin Heidelberg 2006.,Entity error
i_2124,Entailment,"General Baking Process Influences: Heat and Humidity: The baking process involves critical factors such as heat application, humidity levels, and baking time, which are the sole determinants of volume expansion, crust formation, yeast inactivation, protein coagulation, starch gelatinization, and moisture loss .","Baking process is a key step in which the raw dough piece is transformed into a light, porous, readily digestible, and flavorful product under the influence of heat. With the requisite quality attributes, the bread production presumes a carefully controlled baking process. Factors playing vital influence on the final product quality include the rate and amount of heat application, the humidity level in baking chamber, and baking time. During baking, the most apparent interactions are volume expansion, crust formation, inactivation of yeast and enzymatic activities, protein coagulation, gelatinization of starch in dough [1], and moisture loss.",Entailment
i_1402,Entailment,"Common Skin Lesions in Obesity: Striae: This is a common skin condition in obese individuals, characterized by streaks or stripes on the skin that can appear red, purple, or white. It is often associated with rapid weight gain and can be exacerbated by obesity .","Objective To determine the frequency of various cutaneous manifestations in patients with obesity and correlate these skin changes with the grades of obesity. Patients and methods The study was conducted at Departments of Medicine and Dermatology, Sir Syed College of Medical Sciences and Hospital Karachi from 1<sup>st</sup> January 2014 till 30<sup>th</sup> June 2014. Patients belonging to both sexes and different age groups having body mass index (BMI) ≥25kg/m<sup>2</sup> with cutaneous manifestations of obesity were enrolled. Patients with skin changes secondary to other systemic illnesses, pregnancy and drugs were excluded. After an informed consent, demographic details, height and weight were documented. A clinical dermatological diagnosis was established after a detailed history and examination. Appropriate investigations were performed where required. Results 196 patients, 76 males (39%) and 120 females (61%) completed the study. Mean age was 43.6±10.8 years, age range being 19-70 years. Mean BMI 34±4.73 kg/m<sup>2</sup> (range 25-50), grade I obesity in 75 (38%) and grade II obesity in 121 (62%) cases. The most common finding observed was acanthosis nigricans (49%), followed by striae (17%), fungal infections (15%), acrochordons (12%), viral infections (11%), hirsutism (11%) and bacterial infections (7.5%). Other less common associations included: xanthomas, corns, plantar hyperkeratosis and acne. Acanthosis nigricans and viral infections were significantly more among females; corn and callus among males. Obesity grade II was significantly associated with acanthosis nigricans, viral infections, hirsutism, striae and stasis dermatitis. Conclusion Obesity is commonly associated with a wide range of dermatological manifestations like acanthosis nigricans, striae, hirsutism, skin infections. Other less common associations include: xanthomas, corns, plantar hyperkeratosis and acne.",Entailment
i_239,Entailment,"Types of Attacks: Reconnaissance Attacks: Attackers gather information about the network to plan further attacks, and it is possible that new, more sophisticated reconnaissance techniques are being developed that could exploit previously unknown vulnerabilities in SDN architectures .","Software Defined Networking (SDN) is a widely-adopted network architecture that provides high flexibility through the separation of the network logic from the forwarding functions. Researchers thoroughly analyzed SDN vulnerabilities and improved its security. However, we believe important security aspects of SDN are still left uninvestigated. In this paper, we raise the concern of the possibility for an attacker to obtain detailed knowledge about an SDN network. In particular, we introduce a novel attack, named Know Your Enemy (KYE),bymeansof which an attacker can gather vital information about the configuration of the network. This information ranges from the configuration of security tools, such as attack detection thresholds for network scanning, to general network policies like QoS and network virtualization. Additionally, we show that an attacker can perform a KYE attack in a stealthy fashion, i.e., without the risk of being detected. We underline that the vulnerability exploited by the KYE attack is proper of SDN and is not present in legacy networks.",Entailment
i_852,Entailment,Lean Construction: Core Functionality: Lean construction is designed to improve workflow reliability by involving foremen in planning and fostering a sense of ownership and commitment to the project schedule .,"The Last Planner System™ (LPS) is well-documented in the literature, and has sometimes been used to represent lean construction or lean project management. LPS aims to achieve reliable workflow by encouraging foremen to have a sense of ownership of the project programme and to build-in their commitment into it. This study reports on the perceptions of Chinese building professionals of the application of LPS in Chinese construction projects. It reveals that several components of LPS have already taken place in large Chinese construction firms. Further, this study employs a SWOT analysis to examine the possible strength, weakness, opportunity, and threat factors that might have an impact on implementation of LPS in construction projects in China. © 2014 IPMA and Elsevier Ltd.",Entailment
i_1791,Unverifiable,"Life Cycle Costing (LCC): Used alongside LCA to evaluate the economic sustainability of CE projects, which suggests that all CE projects are economically viable .","Increasing interests of circular economy (CE) principles applied into construction projects has led to the development of assessment methods for their justification. The use of smaller quantities of construction materials, materials of higher quality and durability, and recycling of construction waste are all requirements of today's aspiration for a circular economy, but it is necessary to assess their environmental and economic sustainability. This paper presents a review of the current assessment tools of circular economy projects applied to the construction industry, such as LCA, LCC and CBA. The main objectives of this study were to provide a categorization of CE concepts applied in the construction industry (CI) and to review assessment methods used for evaluating CE projects in CI. This paper selected and reviewed 96 published papers and classified them into one of five aspects of CE highlighted in this study: waste management, reducing the impact on the environment, material & product design, building design, and other. The results showed that the use of assessment methods in CE projects has increased in the recent years as well that an LCA was by far the most used assessment method and waste management the most common aspect of CE in CI.
[3]: In construction, the focus of research and policy on sustainability broadened from reducing the energy consumption of a building in use, to a comprehensive sustainability strategy considering the building's entire life cycle. However, the implementation of life cycle thinking (and its operational counterpart the circular economy) in combination with an objective sustainability evaluation is still in its infancy. Therefore, the aim of this study is twofold. First, it is illustrative for the quantified assessment of the potential environmental and financial benefits and burdens of introducing circular design alternatives for internal wall assemblies to the Belgian market. Second, it reviews the methodological implications on the results of a consequential life cycle assessment (LCA) and a life cycle costing (LCC), acknowledging the time dependence and closed-loop nature of those circular design alternatives. That aim is achieved through a multi-model set-up. Evaluating the design alternatives through various methodological assumptions and service life models, allows understanding the relevance and robustness of the results by acknowledging the corresponding uncertainty. In total seven alternative wall assemblies are assessed over a period of 60 years, with a refurbishment every 15 year. The results, without considering the impact of biogenic CO <inf>2</inf> nor the influence of thermal mass, show that a low life cycle impact can be achieved for assemblies that are designed to be used again and have a higher initial impact, such as a plywood boarding connected in a reversible way to demountable metal frame substructure, as well as for assemblies with no possibilities for direct reuse that have a low initial impact, such as a drywall system with a wooden substructure. In addition to the environmental assessment, the life cycle cost of the demountable and reusable wall assemblies with a metal substructure is 10 and 17% lower than that of the conventional alternative with the lowest life cycle cost. Further, regarding the methodological scenarios on marginal supplier identification in the consequential LCA, the range of possible outcomes is however much larger for the demountable wall assemblies than for the conventional ones. For the conventional wall assemblies there is only a small divergence in results of around 10% between the scenarios, while for the demountable ones this deviation rises to 25%. Altogether, this case study points out the potential benefits of introducing demountable and reusable walls, but highlights at the same time the need for a comprehensive sustainability assessment before responsible conclusions can be drawn.",Related but unverifiable
s_746,Unverifiable,"Conclusion: A123 Systems' battery cells, particularly their Nanophosphate™ technology, are highly regarded for their performance, safety, and reliability in both grid energy storage and electric vehicle applications. The integration of advanced BMS further enhances their functionality, making them a robust choice for various high-demand applications .","A123 Systems (A123) has deployed over 20 MW's of Nanophosphate™ battery-based systems that are currently providing Ancillary Services in wholesale electric markets. Ancillary Services include Frequency Regulation and Spinning Reserves. This paper outlines A123's early ground breaking grid battery systems. It describes their characteristics and the applications that these energy storage systems are used for today. The paper then discusses how these characteristics and capabilities implemented in A123's current multi-MW scale battery systems can be extended and applied to support increased delivery of clean renewable energy while maintaining reliable and secure grid performance. © 2010 IEEE.
[2]: Anticipation of the life of electric vehicle (EV) batteries is key to the technology's success. Simulation tools combined with data derived from the including driving patterns and climate conditions, are being used to predict the effects of real-world scenarios on batteries. OEMs and Tier One suppliers are using CAE tools to accelerate the testing process, and extrapolate how long a battery can survive in regular driving scenarios. A123 Systems is tackling the problem by feeding into the simulations data from real-world sources. The company has extensive expertise and is starting to have enough real-world experience of different climates and different driving styles. It is observed that the charging pattern of a battery in a hybrid application is different to that of an electric vehicle. Real-world testing is a useful tool and Ford is incorporating data collected from its electric and hybrid vehicle fleet to improve its simulation tools.
[3]: The utilization of high-rate LiFePO<inf>4</inf>-based batteries in hybrid power system environments is described. Two 250 Wh (24V & 10 Ah) large- format battery packs based on A123 Systems ""M1"" cells were designed and implemented in a hydrogen-air fuel cell/battery hybrid power system for a large robotic platform, the ATHELTE rover developed at JPL. Analyses of the performance of these batteries (at both the system and cell levels) under variety of test conditions will be discussed and the advantages of these batteries over other alternatives will be shown. Data from full testing as well as bench top qualification will be discussed. Charge/discharge currents exceeding 100A were tolerated safely and repeatedly. The performance of this pack will be compared to that of other battery chemistries and the promise of this new class of batteries will be discussed.
[4]: The battery consists of one or more electrochemical cell and it transforms stored energy into electricity. Batteries are widely used in flash lights, smart phones and electric cars. Battery Management System (BMS) plays a prominent role in monitoring and controlling of rechargeable batteries. The key terminologies in BMS are as follows, the prime selection of battery chemistry is essential for meticulous applications followed by technologies in battery management systems it includes battery monitoring, diagnostics,control of charging and discharging cycle, state estimate, protection, equalization of charge, heat control and management, early failure detection and assessment to improve overall system performance. An effective BMS protects the battery from damage, forecasts lifetime and maintains battery efficiency. BMS can optimize downtime and battery lifespan per discharge cycle. Finally the outcome of this paper is to identify the best battery chemistry, charging methods, battery model, cell balancing and SOC estimation techniques.
[5]: Battery management system (BMS) is the most important part of an electronic vehicle (EV), and the management module for single cell is the most important collection part of BMS. It provides cells' data and realizes cells management for BMS. In this paper, the design and realization of the management module for single cell is presented. It can collect real-time voltage and temperature data of cells, and carry on the necessary processing for such data, and then upload these data to the main control module in the battery management system. The design can also equalize the cells, and made their voltage remain in a standard. For the proposed design scheme, the microcontroller PIC24F16KA101 is used as the core part, and the multi-cell addressable battery stack monitor LTC6802 is utilized as the collection part. Moreover, the design of multi-channel data collection and management system, and the design of software and hardware for interface are given. The practical experimental results show that the system can realize the real-time multi-channel signal collection, offer useful data for battery management system, and equalize the cells at power on or power off situation, so as to guarantee the battery consistency. © (2011) Trans Tech Publications.",Related but unverifiable
i_875,Unverifiable,###  ** Principles of Electropolishing** -  ** Anodic Dissolution** : Electropolishing involves the metal workpiece acting as the anode in an electrolytic cell. Metal ions dissolve from the surface into the electrolyte .,"As a popular application of electrochemical anodic dissolution, electropolishing is extensively adopted in the surface finishing industries of metals. Anodic dissolution is a complex reaction with many process parameters and chemical properties involved. A simple explanation of the mechanism of morphology formation during the EP reaction is still lacking. This study examines the morphology formation of stainless steel 304 at the same location on the specimen as the process evolves. Based on these observations, the basic mechanisms of morphology formation in EP process are proposed. The bubble shielding effect (BSE) and the broken bubble tunnelling effect (BBTE) explain the raised and dented morphologies, respectively. The broken bubble tunnelling effect (BBTE) explains the formation mechanism of pitting holes and the bubbleshielding effect (BSE) explains the limitation of surface roughness of electropolishing process. Simulation results are consistent with the observed morphology formation phenomena. © 2012 by ESG.
[5]: Chemical polishing or electropolishing, instead of mechanical polishing, are recommended for the attainment of metallic surface polishes without the introduction of contaminants or tensions in the surface layers of the metal. The fundamental difference between the chemical and electrochemical polishing processes is that in the latter anodic currents/potentials are used to help in the dissolution and passivation of the metal. In this paper, the use of an oxidizing electrolytic solution (2.5 mol L<sup>-1</sup> CrO<inf>3</inf> + 5.0 mol L<sup>-1</sup> H<inf>2</inf>SO<inf>4</inf>) originally employed in electrochemical coloration processes is reported for the electropolishing of AISI-314 stainless steel. Parameters involved in this electropolishing process, such as temperature, current density and time, were optimized so as to attain the best possible results evaluated by the obtained surface brightness measured by reflectance spectra. Surface analyses by scanning electron microscopy allowed a clear correlation between obtained brightness and surface smoothing. The best conditions obtained for the electropolishing process are: temperature of 45°C, electrolysis time of 10 min and current density of around 25 A dm <sup>-2</sup>. It should be pointed out that an electropolishing process signature (periodic oscillations of the cell potential) was established; this may be an important tool for optimizing and monitoring electropolishing processes. © 2004 Elsevier Ltd. All rights reserved.",Related but unverifiable
s_1647,Contradiction,"Factors Influencing Fermentation: Aging and Additives: Aging, particularly with oak chips, does not significantly change the sensory properties of sweet wines, diminishing their complexity and appeal .","The colour, aroma-active compounds and sensory properties of sweet wines from Pedro Ximenez grapes produced by means of an innovative winemaking procedure, based on controlled chamber-drying of grapes, partial fermentation of the must (to 4% or 8% vol ethanol) and subsequent accelerated ageing by contact with oak chips, were studied. Fermentation made the musts less brown and more yellow, whereas ageing made them darker and increased their brown, reddish and yellowish hues. Overall, the musts fermented to 8% vol ethanol exhibited higher odour activity values (OAVs). In addition, the musts aged with oak chips were slightly different from those without chips. Expert tasters gave the highest scores to the musts fermented to 8% (v/v) ethanol with 2 g/L of oak chips added. The winemaking process studied would allow the existing range of sweet wines from dried grapes to be expanded by using a fast, flexible, hygienic procedure.",Opposite meaning
i_1244,Contradiction,"Recommendations: Monitoring and Management: Continuous monitoring and individualized care plans are crucial for managing high-risk pregnancies. Expectant management, while sometimes beneficial, may not significantly reduce perinatal mortality and should be approached with caution as it could lead to unforeseen complications .","Objective: The aims of the study were to find out the maternal and perinatal outcome of early onset severe preeclampsia (PE) in a tertiary care center in a developing country like India and to determine whether expectant management in such a setup improves the perinatal outcome. Materials and Methods: It was a retrospective study. All women with early PE were admitted stabilized and evaluated. Expectant management was given whenever there was no indication for eminent delivery. The perinatal outcome of the expectant group was compared with that of the aggressive group, and appropriate statistical analysis was carried out. Results: A total of 106 women were admitted with severe PE, 61 were treated aggressively, and 45 were stable enough to receive expectant management. The total days gained on expectant management was 7 days. Perinatal mortality was 31.13%. Perinatal outcome of the expectant and aggressive management groups did not differ (P = 0.141); there was no increase in maternal complications on expectant management. There were 2 cases of maternal mortality in the aggressively managed group. Conclusion: Perinatal mortality in severe PE is high. There was no increase in maternal morbidity on expectant management; however, there was no difference in perinatal mortality on expectant management.",Opposite meaning
s_2006,Contradiction,"Offshore wind farms can affect marine ecosystems, including seabed morphodynamics and marine species such as mammals and seabirds, and they may also influence the behavior of fish populations in the surrounding areas, potentially leading to changes in local fishing practices .","Offshore wind power provides a valuable source of renewable energy that can help reduce carbon emissions. Technological advances are allowing higher capacity turbines to be installed and in deeper water, but there is still much that is unknown about the effects on the environment. Here we describe the lessons learned based on the recent literature and our experience with assessing impacts of offshore wind developments on marine mammals and seabirds, and make recommendations for future monitoring and assessment as interest in offshore wind energy grows around the world. The four key lessons learned that we discuss are: 1) Identifying the area over which biological effects may occur to inform baseline data collection and determining the connectivity between key populations and proposed wind energy sites, 2) The need to put impacts into a population level context to determine whether they are biologically significant, 3) Measuring responses to wind farm construction and operation to determine disturbance effects and avoidance responses, and 4) Learn from other industries to inform risk assessments and the effectiveness of mitigation measures. As the number and size of offshore wind developments increases, there will be a growing need to consider the population level consequences and cumulative impacts of these activities on marine species. Strategically targeted data collection and modeling aimed at answering questions for the consenting process will also allow regulators to make decisions based on the best available information, and achieve a balance between climate change targets and environmental legislation.
[7]: The need for sustainable energy is rising, and at the moment wind energy is one of the few forms of renewable energy that can be harvested efficiently.We investigated the influence of an offshore wind farm on the large-scale morphodynamics of the seabed.To this aim, we developed a morphodynamic model to investigate the effect of offshore wind farms on the seabed. By implementing the model in a GIS environment, the model allows us to calculate the effects of a wind farm using location specific and park design input parameters. By implementing an analytical model in a GIS, a rapid calculation of the effects of an offshore wind farmat a certain location in the North Sea can be made. © 2008 Taylor & Francis Group, London.",Misrepresentation
i_240,Contradiction,"Types of Attacks: Flooding Attacks: Include ICMP flood and packet payload alteration, which can disrupt network operations .","[8] Servers in a network are typically assigned a static identity. Static assignment of identities is a cornerstone for adversaries in finding targets. Moving Target Defense (MTD) mutates the environment to increase unpredictability for an attacker. On another side, Software Defined Networks (SDN) facilitate a global view of a network through a central control point. The potential of SDN can not only make network management flexible and convenient, but it can also assist MTD to enhance attack surface obfuscation. In this paper, we propose an effective framework for the prevention, detection, and mitigation of flooding-based Denial of Service (DoS) attacks. Our framework includes a lightweight SDN assisted MTD strategy for network reconnaissance protection and an efficient approach for tackling DoS attacks using Software Defined-Internet Exchange Point (SD-IXP). To assess the effectiveness of the MTD strategy and DoS mitigation scheme, we set two different experiments. Our results confirm the effectiveness of our framework. With the MTD strategy in place, at maximum, barely 16% reconnaissance attempts were successful while the DoS attacks were accurately detected with false alarm rate as low as 7.1%. [11] In this Modern era, Software Defined Network (SDN), Network Function Virtualization (NFV), and cloud computing participating of Fifth Generation (5G) network emergence. This paper presents a robust security scheme to provide fortification against major threats along with user privacy in 5G network, two additional entities are introduced. For mobile users, initial authentication is provided at access points by an inventive Highly Secured Authentication and Handover Mechanism (HS-AOHM) scheme which minimizes handover latency without loss of user privacy. Then the authorized user packets are arrived at dispatcher in which a novel Tree Based Switch Assignment (TBSA) algorithm is incorporated. TBSA mitigates the flow table overloading attack by assigning packets to underloaded switches. In controller, DDoS attack is detected with the assist of entropy analysis. Then the suspicious packets are redirected to scrubbing Virtual Network Function (sVNF) in cloud. In sVNF, suspicious packets are classified into normal packets and malicious packets by using Hybrid Fuzzy with Artificial Neural Network (HF-ANN) classifier based on packet features. Normal packets are allowed to access applications whereas malicious packets are dropped at sVNF. Extensive simulation shows security improvement in 5G network in terms of handover latency, holding time, switch failure rate, detection accuracy, and delay.",Missing information
s_1197,Contradiction,"Key Classification Systems and Approaches: S3 Clinical Guidelines: Definition: Guidelines from the European Trauma Society for the treatment of severe injuries, including recommendations for managing critical bleeding .","The arrest of several potential assassins in Germany in recent months leads to the assumption that terror attacks with firearms and explosive devices like those that happened in Paris (2015) and Brussels (2016) could also take place in German cities. In such situations, the treatment fundamentals for mass casualty incidents take priority over the well-known fundamentals of individual medical treatment approaches. However, new research results emphasize that even under optimal treatment circumstances the outcome of vascular traumatized patients is underestimated when the mortality rate is calculated using established trauma score systems. The 2016 revised S3 clinical guideline Polytrauma-/Schwerverletzten-Behandlung from the Deutsche Gesellschaft für Unfallchirurgie (Polytrauma/severe injury treatment from the German Trauma Society) addresses the modification of known and new inclusion of recommendations for the treatment of critical bleeding. The following article focusses on vascular traumatized patients with gunshot wounds and injuries from explosive devices. The new recommendations for preclinical critical bleeding treatment is highlighted based on the S3 guidelines.",Entity error
i_1573,Entailment,"Challenges in Implementing Sustainable Solutions: Urban planning approaches, such as transit-oriented development (TOD), which promote public transport, mixed land use, and walkable neighborhoods, are essential for reducing car dependency. However, practical implementation often faces barriers, including stakeholder acceptance and alignment with broader sustainability goals .","The contemporary debate and research on transit-oriented development (TOD) has continued to progress within the context of sustainable development. At its core, this refers to providing essential transit services with an efficient manner which is achieved by including accessible public transport, mixed land use, and walkable neighbourhoods so as to reduce the volume of private cars on the road. We have analysed the theoretical development of TOD studies. Based on a scientometric analysis, this paper has collected 442 TOD articles through the Web of Science and used VOSviewer to visually map and analyse four main topics of TOD studies, including ""correlation among TOD, smart growth and land use"", ""TOD financing and the impacts of TOD on housing price"", ""impacts of TOD on travel behaviour"", and ""correlation among TOD attractiveness, accessibility and ridership"". And we also provide the current status of research and implications for Australia.
[6]: Cities' sustainability strategies seem to aim at the reduction of the negative impacts of urban freight transport. In the past decades, many public and private initiatives have struggled to gain broad stakeholder support and thus remain viable. Researchers and practitioners have only recently recognised stakeholder acceptance of urban freight solutions as a challenge. A first step in achieving convergence is to understand stakeholder needs, preferences and viewpoints. This paper proposes and applies an approach to identify the main stakeholder perspectives in the domain of urban freight transport. We use Q-methodology, which originates from social sciences and psychology, to record subjective positions and identify the dominant ones. We explain the approach, operationalise the method for the domain of urban freight transport and apply it to stakeholder groups in the Netherlands. We find four dominant perspectives, reflecting how stakeholders normally take positions in the urban freight dialogue. Important findings concern disparities between industry associations and some of their membership, divergent views about the expected role of public administration, and the observation that the behaviour of shippers and Logistics Service Providers (LSP) appears to be inconsistent with their beliefs. All these factors together can act as a barrier to the implementation of urban freight consolidation concepts. The Q-methodology is valuable for eliciting perspectives in urban freight and is a promising tool to facilitate stakeholder dialogue and, eventually, convergence.",Entailment
s_1905,Contradiction,This holistic approach is expected to completely resolve all communication issues between social and natural scientists and between scientists and practitioners .,"Restoration ecology is a deepening and diversifying field with current research incorporating multiple disciplines and infusing long-standing ideas with fresh perspectives. We present a list of 10 recent pivotal papers exemplifying new directions in ecological restoration that were selected by students in a cross-disciplinary graduate seminar at the University of California, Berkeley. We highlight research that applies ecological theory to improve restoration practice in the context of global change (e.g. climate modeling, evaluation of novel ecosystems) and discuss remaining knowledge gaps. We also discuss papers that recognize the social context of restoration and the coupled nature of social and ecological systems, ranging from the incorporation of cultural values and Traditional Ecological Knowledge into restoration, to the consideration of the broader impacts of markets on restoration practices. In addition, we include perspectives that focus on improving communication between social and natural scientists as well as between scientists and practitioners, developing effective ecological monitoring, and applying more integrated, whole-landscape approaches to restoration. We conclude with insights on recurrent themes in the papers regarding planning restoration in human-modified landscapes, application of ecological theory, improvements to restoration practice, and the social contexts of restoration. We share lessons from our cross-disciplinary endeavor, and invite further discussion on the future directions of restoration ecology through contributions to our seminar blog site © 2011 Society for Ecological Restoration International.",Opposite meaning
s_549,Unverifiable,"Maintenance Costs: Rebar Reinforced Concrete (RRC): Durability: Traditional steel rebar is prone to corrosion, especially in harsh environments, leading to higher maintenance costs for repairs and rehabilitation .","Corrosion of steel reinforcement in conventional concrete structures induces deterioration of structures. Fiber-reinforced plastic (FRP) composite reinforcement can be used in concrete structures instead of steel rebars. This composite rebar prevents the degradation of concrete structures from moisture effects. Moreover, this composite rebar reduces the structural weight and continuous fiber composites are able to arrest cracks and prevent self-similar crack propagation. However, a number of design parameters such as fiber orientation patterns and choices of constituent material combinations provide a multiplicity of design options for this structure, which requires a priori quantification of progressive damage in this composite structure and its fracture characteristics. In this paper, durability and damage tolerance (D&DT) of concrete beams with FRP composite reinforcement under static loading is evaluated using a multi-scale micro-macro progressive failure analysis (PFA) technique that augments commercial FE stress solvers. PFA predicts damage initiation and propagation, fracture initiation and propagation, and the final residual strength in the structure. The prediction is validated with experiment data obtained from full-scale beam tests. In the experiment, each specimen was tested in four-point bending with different specification. Simulation results show in detail the damage progression sequence and structural response characteristics during different degradation stages. Computational simulation provides an alternative evaluation method, giving engineers a detailed description of durability and damage tolerance would take place in the process of ultimate fracture of concrete structures with FRP reinforcement.
[10]: A continued process exists to implement innovative materials to enhance the sustainability and durability of the built infrastructure. Technologies developed over the last two decades have facilitated the use of glass fiber reinforced polymer (GFRP) composites as internal reinforcement bars (rebars) for concrete structures, which have proven to be an alternative to traditional steel reinforcement due to significant advantages, such as magnetic transparency and, most importantly, corrosion resistance, equating to durability and structural life extension. This study evaluated the durability of three different commercially available and most commonly used GFRP rebar types for resistance to aggressive environments, such as those experienced in coastal areas. In total, 216 specimens were exposed to seawater, at various temperatures (23, 40 and 60°C) for different time periods (60 and 120 days). The durability of these GFRP rebars was assessed by testing five different physio-mechanical properties, including: tensile strength, modulus of elasticity, transverse and horizontal shear strength, and bond-strength to concrete. Preliminary results show that the durability of the GFRP rebars after being exposed to seawater at different temperatures, varies considerably among the three different rebar types. Among the tested physio-mechanical properties, tensile strength suffered the highest degradation.",Related but unverifiable
s_499,Unverifiable,"Biological Inspiration for Battery Design: Fault Tolerance and Self-Healing: Inspired by the fault tolerance of biological systems, electronic systems can be designed with self-healing capabilities. The SABRE project demonstrates a hierarchical architecture where each cell can detect and repair faults, ensuring high reliability . Incorporating such self-healing mechanisms in battery compartments can prolong their lifespan and reliability.","As electronic devices become increasingly complex, ensuring their reliable, fault-free operation is becoming correspondingly more challenging. It can be observed that, in spite of their complexity, biological systems are highly reliable and fault tolerant. Hence, we are motivated to take inspiration for biological systems in the design of electronic ones. In SABRE (self-healing cellular architectures for biologically inspired highly reliable electronic systems), we have designed a bio-inspired fault-tolerant hierarchical architecture for this purpose. As in biology, the foundation for the whole system is cellular in nature, with each cell able to detect faults in its operation and trigger intra-cellular or extra-cellular repair as required. At the next level in the hierarchy, arrays of cells are configured and controlled as function units in a transport triggered architecture (TTA), which is able to perform partial-dynamic reconfiguration to rectify problems that cannot be solved at the cellular level. Each TTA is, in turn, part of a larger multi-processor system which employs coarser grain reconfiguration to tolerate faults that cause a processor to fail. In this paper, we describe the details of operation of each layer of the SABRE hierarchy, and how these layers interact to provide a high systemic level of fault tolerance. © 2013 IOP Publishing Ltd.",Related but unverifiable
i_1845,Contradiction,"Benefits of Circular Economy: Social: Generates employment opportunities, promotes sustainable practices, and enhances the quality of life by reducing environmental degradation .","Reuse and recirculation of products and materials are the basis of the concept of the circular economy (CE). The CE is an innovative proposal that can result in positive impacts such as reduced demand for raw materials, reduced consumption of basic resources, and job creation, as well as preventing negative impacts resulting from the exploitation and processing of natural resources. Mining is infamous for its potential environmental impact, but mining waste from traditional mining (in the linear economy) may recover material through upcycling techniques, as can urban mining of industrial and post-consumer waste categories (in the circular economy). Urban mining, a form of closed-loop supply chain management, offers an attractive alternative to the management of waste electrical and electronic equipment (e-waste) and, at the same time, as a sustainable way to exploit mineral resources, reduces primary material intake and stimulates the circularity in the supply chain. The present study reviews the main CE solutions for e-waste management, highlighting the importance of recovering and classifying mineral material according to urban mining procedures.
[15]: The performance economy is a concept which goes beyond most interpretations of a ""circular economy"": the focus is on the maintenance and exploitation of stock (mainly manufactured capital) rather than linear or circular flows of materials or energy. The performance economy represents a full shift to servicisation, with revenue obtained from providing services rather than selling goods. While the form of industrial economy which has dominated the industrialised countries since the industrial revolution is arguably appropriate to overcome scarcities in a developing economy, the performance model is applicable in economies close to saturation, when the quantities of new goods entering use are similar to the quantities of goods being scrapped at the end of life. Key elements of the performance economy are re-use and re-manufacturing, to maintain the quality of stock and extend its service life by reducing material intensity, i.e. the material flow required to create and maintain the stock. Because material flows represent costs which reduce the revenue from service provision, business models inherent in the performance economy support the macro-level objective of extending service life and thereby minimising material intensity. Product life in the performance economy is limited by technological improvements in the efficiency of manufactured capital rather than by damage, wear or fashion. Re-use and re-manufacturing tend to be more labour-intensive and less capital-intensive than virgin material production or primary manufacturing. This enables re-use and remanufacturing to be economically viable at smaller scales. It also enables these activities to substitute labour for energy, reversing the trend which has characterised industrial economies and offering ways to alleviate current environmental, economic and global challenges; i.e. to make the economy more sustainable. However, there are significant barriers to adoption of the performance economy model, partly because economic and business models generally focus on flows (GDP or added value) rather than prioritising the quality, value and use of stock. Promoting the performance model may require a complete re-think of public policy, away from subsiding to taxing use of non-renewable resources and away from taxing the use of renewable resources, of which labour is possibly the most important. Recent analyses of the social costs of unemployment and potential social benefits of a more resource efficient performance economy provide some of the evidence supporting a shift from flow to stock management.",Missing information
s_539,Unverifiable,"5. Education and Cultural Change: Engineering Education: While transforming engineering education to emphasize sustainability as a core design constraint is important, it is likely that simply integrating sustainability into the curriculum will automatically lead to a systems-oriented perspective among students, without the need for significant cultural change or additional support .","The importance of sustainability to engineering work cannot be denied. Consider, for example, that in the 2011 State of the Union address, President Obama pledged that 80% of the energy used in the United States will come from clean energy sources by 2035.1 Perhaps unprecedented, we face enormous problems like global climate change, poverty, overpopulation, diminishing resources, and pollution, to name a few. The dominant view of engineers' role in this current state of affairs is that of problem solver, or rescuer, such that engineers need only ""design their way out"" of any problems we face as a global society. Rather than a reactionary focus, engineers must be proactive and contemplative and emphasize sustainability as a top design constraint to be considered thoughtfully in terms of people, nature, and future generations. A focus on sustainability must be as heavily weighted as cost, aesthetics, ease of use, etc. But, if we are to get there, we must first change the culture of engineering education. Currently, engineering education treats sustainability as one of many design constraints that likely receives consideration in a classroom module, typically in a capstone design class. One lesson is hardly enough to instill in students the importance of sustainability and sustainable design considerations. While some colleges of engineering have taken on grand educational initiatives to educate students about sustainability and the importance of sustainable design,2-3 we still have an uphill climb to truly transform engineering education to be more focused on sustainable, systems-oriented design, and problem solving. One first step to transforming the culture is to learn how students view sustainability and its relationship to engineering. This is especially important since notions of sustainability and sustainable engineering are wide and varied.4 In this paper, we present Mechanical Engineering students' conceptions of sustainability and how sustainability relates to engineering. Mechanical Engineering, in particular, is a discipline representing great potential in terms of advancing sustainable solutions to our global environmental problems. Yet, the majority of design projects rely on fossil fuels and old technologies that will continue to add CO<inf>2</inf> to the atmosphere. Thus, Mechanical Engineering offers a space for increased attention to sustainability. We surveyed sophomore Mechanical Engineering students in an energy systems design class to gauge their views on sustainability and its importance to engineering. This represents the preliminary phase of a multi-year project on organizational change in the Mechanical Engineering Department. Results from this study will help us develop a targeted, integrated curriculum designed to teach students the importance of sustainability to engineering from a systems-oriented perspective. © 2012 American Society for Engineering Education.
[7]: Sustainability is increasingly being incorporated into engineering curriculums<sup>1,2</sup>, often due to ABET requirements<sup>3</sup>, but also due to faculty expertise. The United Nations recognizes that achieving sustainable development is only possible if a balance exists between the three dimensions of sustainability: social, economic, and environmental<sup>4</sup>. However, engineering programs can overlook the social dimension by focusing on technological solutions and conflating sustainable development with only environmental protection<sup>5,6</sup>. This paper reports on the evolution of incorporating the social dimensions of sustainability into Engineering for Sustainability, a required sophomore-level course in a Civil and Environmental Engineering Department. The course was created in 2003, revised in 2010<sup>7</sup>, and redesigned in 2015-2016. Throughout the history of the course, sustainability was mostly discussed as the application of the basic sciences to engineering issues focused on protecting the environment. Though social issues were present in some lectures, there was little emphasis on social dimensions until the course's redesign in 2015, when the design of sustainable infrastructure became the focus of the course. Activities that centered on the intersection of social issues, urbanization, and sustainable development were introduced in two class sections during a semester. These discussion-based activities have been revised every semester since their implementation in order to improve student learning outcomes, induce more thoughtful conversations among students, and invoke a deeper evaluation of the complexity of the current urban systems. However, it became evident that it was challenging to address important social issues, because of their complexity, in only two class sessions. Developing students' understanding of social and ethical issues related to sustainable development requires full engagement of the course instructor, considerable preparation time, and the development of curriculum that intentionally brings social dimensions of sustainable technology to the forefront. The 2015 redesign of the course included a format change from lecture-based to a blended style that allowed for more student discussions and active learning opportunities. In 2017, additional curricular revision increased student exposure to social issues from two class sessions deeply focused on social issues per semester to at least 80% of the class sessions (even if briefly). The focused class sessions have evolved from a stakeholder debate approach to exercises that emphasize a socio-technical systems framework, stakeholder value mapping, and empathy building. This paper, using written student work, evaluates how the deepening of discussions revolving around social and ethical issues in sustainable urban development have affected student learning and their ability to integrate social and technical issues when thinking about the design of sustainable infrastructure. We evaluate and analyze student work from three activities that represent the evolution of curriculum in this course over the past three years. Results of the analysis suggest that short interventions in this technical course did increase students' awareness of social impact of technologies and students' understanding of complexity in infrastructure and technological changes.",Related but unverifiable
s_1980,Entailment,"Economic Benefits: Cost Savings: One of the primary motivations for adopting corporate environmental sustainability (CES) strategies is the economic benefit, particularly through cost savings from reducing resource use. This includes measures like energy conservation and greenhouse gas (GHG) emission reduction .","[2] The innovation effect is an important component when measuring the performance of environmental policy instruments. Based on a questionnaire survey, this research has examined corporate energy conservation and emission reduction efforts in energy intensive industries in China under the pressure of different climate policies, and in particular looked into their adoption of those technological innovation and diffusion activities. The results show a large variety of corporate adoption of energy-saving practical activities. In general, climate policies have played a greater role in promoting the adoption of managerial energy-saving activities in respondent companies, while comparatively their influences on the adoption of technology upgrading activities are relatively weak. Regulatory measures have exerted greater pressure and influence on corporate short-term behavioural change, as stated by the respondent companies. However, market based instruments show greater incentive effect in promoting adoption of energy conservation and emission reduction activities that refer to corporate long-term oriented strategic planning or adjustment. For instance they exert a significant incentive effect on increasing long-term research and development investment for technological innovation, and also play an important role in optimising corporate organisational structure. The econometric analysis further proves the influences of market-based instruments in promoting corporate adoption of technological innovation and diffusion activities. [9] This paper examines the relationship between sustainability targets and their impacts on corporate environmental innovation. Using data over the period 2009-2018 on 202 companies from BRICS countries, covering firm-level governance, social responsibility and sustainability this paper examines firm-level sustainability targets, and incentives encourage managers to engage in more environmentally friendly activities. Using panel data probit regression, and after controlling for country-level governance and institutional factors, the study finds that embedding environmental targets in corporate strategy does encourage corporate managers to design and develop eco-friendly products and services, and such firm-level commitments at the top motivates managers to promote, market, and label environmentally friendly products. The findings call for greater emphasis on aligning executive compensation with sustainability targets rather than focusing too much on short-term accounting and market-based measures of firm performance. [13] This paper examines the diffusion of environmental management initiatives in business and the motives and pressures reported by senior executives to adopt these practices in one industry. We frame these sustainable practices under the umbrella of corporate social responsibility (CSR) and examine the causal drivers of environmental behavior. This study used a mixed-methods approach and included a survey and 17 in-depth interviews with professional sports team and league executives. Data revealed both strategic and legitimacy motives to adopt environmental management practices. More specifically, the analysis suggested that strategic motives were the primary reason for adopting an environmental CSR focus. Motives to address institutional pressures were also found, although to a lesser extent. The paper discusses the role and relevance environmentally focused CSR plays in professional sport organizations in North America and presents suggestions for future research in this area. Copyright © 2010 John Wiley & Sons, Ltd and ERP Environment.",Entailment
s_722,Unverifiable,"Additional Considerations: Cooling and Reheating Effects: The temperature of the build platform and the cooling/reheating behavior during printing can affect the microstructure and interfacial bonding, influencing the resistance stability .","The Fused Filament Fabrication process is the most widely used process for prototyping. The use of variable feedstock material, specimen geometries, pre-processing software, and printers makes comparability and reproducibility challenging, because the part properties not only change with varying print parameters, but also with changes in the slicing routine and tool path generation. The sequential part build-up causes a transient temperature field that affects the local microstructure and interfacial bonding and thus the macroscopic properties. The weld line formation between neighboring beads within layers as well as between layers has been identified as one of the biggest factors affecting mechanical properties. Using a custom python™ program for tool path generation, the cooling and re-heating effect during printing was studied using an IR thermal camera. It was shown that the temperature of the build platform has significant effect on the cooling and reheating behavior. A numerical analysis in ANSYS<sup>®</sup> Mechanical using the element death and birth effect proved that radiation should be included because of the initially high deposition temperatures, and that the presence and size of voids affect the re-heating or cooling rate during the deposition process.",Related but unverifiable
i_1195,Contradiction,"Recommendations for Healthcare Providers: Healthcare providers should engage caregivers in discussions about medication management, assuming that all caregivers have similar needs and can benefit from the same type of education and support .","Background Family caregivers are actively involved in medication management, yet little is known about factors associated with caregivers' involvement in this role and how that information can be utilized to engage caregivers in the healthcare system. Objectives To explore factors associated with caregiver involvement in various aspects of older adults' medication management (i.e., ordering, keeping track or ensuring the correct medication is taken at the correct time, and injecting medications). Methods A retrospective analysis of two national surveys, the 2011 National Health and Aging Trends Study and the National Study of Caregiving was performed. Multivariate logistic regression models were used to examine the associations between demographic and caregiving variables with caregiver involvement in three medication management activities. Results Approximately two-thirds of family caregivers (N = 1369) were involved in one or more medication management activities. Factors associated with caregivers' assistance with ordering medications included being female, high frequency of involvement in instrumental activities of daily living (IADLs), involvement in medically-related activities, and caring for an older, less educated, or Hispanic care-recipient and individuals with lung disease or dementia (p < 0.05). Caregiver living arrangement, high frequency of involvement in activities of daily living (ADLs) and IADLs, involvement in medically-related activities along with care-recipient's race/ethnicity and having a dementia diagnosis were all associated with caregiver assistance in keeping track of medications (p < 0.05). Factors associated with assistance in injecting medications were caring for older adults with diabetes or stroke, or being involved in medically-related activities (p < 0.05). Conclusions Different demographic and caregiving factors were associated with caregiver involvement in various medication management activities. Recurring factors included race/ethnicity, certain care-recipient disease states, and caregiver involvement in IADLs and medically-related activities. Healthcare providers can play a proactive role in engaging caregivers in discussion about medication management and these findings can help practitioners more effectively target caregivers for education and support.",Opposite meaning
i_1884,Contradiction,"Key Insights: Economic and Social Disincentives: Economic disincentives, such as costs associated with recycling, can discourage households from participating in waste sorting. Additionally, the lack of information and poor conditions of recycling facilities have little to no impact on influencing recycling behavior .","The achievement of recycling programs depends essentially on the active and sustained involvement of people. In order to investigate factors that influence households' decision to participate in recycling programs, this research applied directed interviews, observations, and questionnaire surveys to study recycling behavior of 381 randomly selected individuals in Bangkok. The study employed the theory of planed behavior as the main framework and injected sociodemographic, economic, and situational factors into the model to examine how these factors integrate to either stimulate or restrain recycling involvement of people. The results of the estimated logistic regression models suggested that the adequacy of information regarding recycling and resident period in the current place directly predicted recycling behavior, whereas the condition of recycling facility and personal recycling skill provided both a direct effect on the actual behavior and an indirect effect via recycling intention. In contrast, the psychological factors; attitude toward recycling, subjective norm, and awareness of recycling benefit, only indirectly influenced recycling behavior through the intention. The economic incentive, perceived efforts on time and space, and other demographic variables were not found significant in both levels. © 2011 WIT Press.
[7]: This paper compares recycling attitudes and behaviours of key participants in Pakistan's plastics recycling supply chains. It involved mainly cross sectional surveys of 360 households and 51 scrap dealers, and multiple case studies with 26 plastics pre-processors and 28 plastics recyclers (moulders/converters) at seven cities in Pakistan. Guided by the model of consumer recycling behaviour proposed by Thøgersen (International Journal of Research in Marketing, 1994, 11, pp. 145-163) this paper found a mix of different attitudes and behaviours. It appears that households lacked awareness of the process involved after plastics recyclables are collected and they lacked opportunity to participate; furthermore their recycling behaviour was largely motivated by financial benefits. Material recovery facilities provided by the government appeared to be inadequate. For other private-sector participants (scrap dealers, re-processor and moulders), they lacked investment in equipments for sorting and storage of plastics waste. We further explain the roles of social norms, ability to recycle, opportunity to recycle and motivation (awareness or monetary) and extend Thøgersen's model to include not just households but also scrap dealers, re-processors and moulders. The developed measurement instrument is useful to study other recycling supply chains.",Opposite meaning
i_137,Unverifiable,"2.   ** Variational Autoencoders (VAEs) ** : ** Dataset Augmentation** : VAEs can also generate additional training data by creating de-occluded images from occluded ones, enhancing the dataset size and diversity  .","As a basic task of multi-camera surveillance system, person re-identification aims to re-identify a query pedestrian observed from non-overlapping multiple cameras or across different time with a single camera. Recently, deep learning-based person re-identification models have achieved great success in many benchmarks. However, these supervised models require a large amount of labeled image data, and the process of manual labeling spends much manpower and time. In this study, we introduce a method to automatically synthesize labeled person images and adopt them to increase the sample number per identity for person re-identification datasets. To be specific, we use block rectangles to randomly occlude pedestrian images. Then, a generative adversarial network (GAN) model is proposed to use paired occluded and original images to synthesize the de-occluded images that are similar but not identical to the original image. Afterward, we annotate the de-occluded images with the same labels of their corresponding raw images and use them to augment the number of samples per identity. Finally, we use the augmented datasets to train baseline model. The experimental results on CUHK03, Market-1501 and DukeMTMC-reID datasets show the effectiveness of the proposed method.",Related but unverifiable
i_238,Contradiction,Types of Attacks: Poisoning Attacks: Involve injecting false information into the network to disrupt the controller's operations .,"Software-Defined Networking (SDN) provides significant flexibility when it comes to complex network management. This makes this technology an ideal candidate for dealing with network management issues in satellite and terrestrial networks.One key innovation of SDN is the separation of the control plane from the data plane. This results in a new network element: the controller. Given the importance of the role of the logically centralised (physically distributed) controller, it becomes an important point to protect in the new SDN paradigm. It could be vulnerable to attacks that are common in traditional networks such as Distributed Denial of Service (DDoS). In this paper, we address a type of attack that could threaten the operation of SDN-based environments: poisoning attacks.To perform its function, the logically centralised controller must have an accurate view of the network state. The accuracy of this view is crucial to the operation of the network. This view is obtained by exchanging information among controllers and between controllers and network elements. Such information flow could be vulnerable to different types of poisoning attacks. The motivation for writing this paper is that (1) poisoning attacks on SDN networks could have great impact, (2) most of them are relatively recent and (3) the differences between such attacks could be subtle. Therefore, we address the issues by classifying poisoning attacks in SDN. We classify both attacks and defences. For attacks we make a distinction between direct poisoning attacks and attacks that are designed to evade a specific defence.",Missing information
i_1531,Contradiction,"Key Factors Influencing Community Involvement: Community-Based Programs: Programs like waste banks, which operate on a community participation model, show varying levels of success. In Surabaya, Indonesia, community participation in waste banks was low, indicating a need for better empowerment and opportunity provision .","Garbage bank is a place used to collect sorted waste. Waste banks are managed using a banking-like system carried out by volunteer officers. Many problems are related to waste problems so that community empowerment is needed through the waste bank program. The purpose of this study was to determine community participation in household waste management through waste banks in the city of Pekanbaru. This research is a descriptive study through a quantitative method approach. The research was carried out at the main waste bank owned by the Pekanbaru City government as many as 2 waste banks. The number of samples for waste bank customers is 335 respondents, with a sampling technique using purposive sampling, namely sampling based on certain considerations. The instrument used in this study was a questionnaire. The achievement of the score for the level of community participation in household waste management through the waste bank in Pekanbaru City is 1.52 or in the low category. The results of customer perceptions indicate the adequacy or willingness of the community to participate. However, the provision of opportunities for the community to participate and the ability of the community in managing household waste through waste banks is low. This indicates that empowerment to increase community participation in household waste management through the Pekanbaru City waste bank carried out by the waste bank manager and related parties is still low or not in accordance with the established indicators. From the results of the study it can be concluded that there is a will or willingness of the community to participate,",Entity error
i_578,Contradiction,"Current State of Charging Infrastructure: Home Charging: In many regions, the majority of EV charging does not occur at home, relying instead on public charging stations that require new electrical infrastructure .","Electric mobility is an important means to decarbonise the transport sector. Especially in cities, the use of zero-emission vehicles like electric vehicles is favourable, as emissions of conventional cars cause severe air pollution. Besides CO2, the most important emissions are nitric oxides, particular matter and noise. Given the trend of urbanisation, the problem of air pollution in large cities will rather grow than diminish. Although electric vehicles are an infrastructure-depen­dent technology, one important advantage of plug-in electric vehicles (EV) com­pared to hydrogen-powered vehicles is the possibility to use the existing electricity infrastructure in households for charging. While additional public charging infra­structure is also needed for interim charging or overnight charging for the so-called 'on-street parkers' without own garage, the majority of vehicles could be operated as EVs without additional public charging infrastructure. However, public charging infrastructure is an important component for the large-scale diffusion of electric vehicles and political action seems necessary since no business models are pres­ently available. In the present paper the authors combine different data sets con­cerning German charging points and mobility patterns to describe the different needs for charging infrastructure, and provide an overview of the underlying dif­ferent technical options. Based on the current charging infrastructure stock, the set­up methodology and the impact of user needs on charging infrastructure, the authors compare a coverage-oriented and a demand-oriented approach. The authors also estimate the number of public charging points for those two approaches. Finally, criteria for charging infrastructure are categorised and related to the dif­ferent approaches. It results that the number of charging stations needed for the two
[3]: A reliable charging infrastructure for electric vehicles used in individual transport including availability and accessibility is necessary because it contributes highly to the decision of purchasing a BEV (battery electric vehicle). In Germany, charging is mainly done at home; however, parking spots in car parks have the potential to densify charging infrastructure in semi-public spaces. Intelligent car parks represent further developments which add a variety of technologies, energy management tools and value- added services to parking in general. The article addresses the question of technical maturity of charging infrastructures used in intelligent car parks and their marketability. Examples are charging methods such as conductive and inductive charging or various payment options. Pilot projects are described, and possible concepts of charging in intelligent car parks are explained, thereby addressing a growing interest in the subject.",Opposite meaning
s_415,Unverifiable,"Operational Efficiency and Cost Reduction: By consolidating infrastructure, digital platforms can reduce operational costs and shorten time-to-market for new services. This efficiency is crucial in economically challenging times and can determine the success or failure of businesses. Additionally, it is possible that companies that adopt such consolidated infrastructures may also experience enhanced customer satisfaction due to improved service delivery and reliability, although this remains to be empirically validated .",A consolidated infrastructure for digital media services enables multiple services across different screens using the same underlying platform. The paper illustrates how business wins including reduction of operational costs and significantly shortened time to market can be realized by consolidation. Such consolidations in infrastructure are imperative in these difficult economic times; it could play a role in determining who will prevail or who will perish.,Related but unverifiable
i_1502,Contradiction,"General Findings: Psychosocial Distress: Diabetes patients frequently experience adjustment disorders, anxiety, and depression, with prevalence rates varying by type of diabetes and assessment methods .","In western industrial nations, cancer is one of the most frequent somatic diseases showing increasing incidence rates. Although the options for medical treatment and the survival rates for most cancer diagnoses have improved over the last few decades, cancer is still a life-threatening illness associated with psychosocial issues, suffering, and distress. Depending on the severity and duration of symptoms, psychosocial distress due to cancer ranges from normal reactions to psychological comorbidity based on ICD classification criteria. In cancer patients, the most frequent psychological diagnoses are adjustment disorders, anxiety, and depression; prevalence rates in the literature show high variations depending on the tumor type studied and the assessment instrument used. Today, standardized and validated screening instruments and diagnostic interviews are available for the screening and assessment of psychosocial distress and psychiatric comorbidity. The screening of psychosocial distress in cancer patients and the assessment of psychiatric disorders are important tasks of modern cancer treatment in order to determine the need for psychosocial counseling and psychooncological treatment. © 2010 Springer Medizin Verlag.",Entity error
s_1748,Entailment,"Moderately Ozone Tolerant: ADT37, ADT(R)45, TPS5, Anna(R)4, PMK(R)3, and ADT(R)48 are likely to be the most resilient cultivars under ozone stress, suggesting they may thrive better than others in future conditions .","The plant response to elevated ozone stress reveals inter-species and intra-species disparity. Ozone-induced crop yield loss is predicted to increase in the future, posing a threat to the world economy. This study aims to evaluate the cultivar specific variation in rice exposed to elevated ozone. Fifteen short-duration rice cultivars were exposed to 50 ppb ozone for 30 days at reproductive stage. The physiological, biochemical, growth and yield traits of all test cultivars were significantly affected in response to elevated ozone. On an average, ozone stress decreased the tiller number by 22.52%, number of effective tillers by 30.43%, 1000 grain weight by 0.62% and straw weight by 23.83% over control. Spikelet sterility increased by 19.26% and linear multiregression 3D model significantly fits the spikelet sterility and photosynthetic traits with the R<sup>2</sup> of 0.74 under elevated ozone. Principal Component Analysis with total variance of 57.5% categorized 15 rice cultivars into four major groups, i.e., ozone sensitive (MDU6, TRY(R)2 and ASD16), moderately ozone sensitive (ASD18, ADT43, and MDU5), moderately ozone tolerant (ADT37, ADT(R)45, TPS5, Anna(R)4, PMK(R)3, and ADT(R)48), and ozone tolerant (CO51, CO47, and ADT36). This study indicates that the different responses of rice cultivars to elevated ozone stress through a change in plant physiology, biochemical, growth, and yield traits and the results directed to provide scientific information on plant adaptations to ozone stress and helps in efforts to search ozone tolerant gene for plant breeding.",Entailment
s_1925,Entailment,"Comparison of Disturbance Patterns: Key Differences: Disturbance Type and Impact: While both forest types experience wind and insect disturbances, fire plays a more critical role in boreal forests, leading to more severe and widespread impacts compared to temperate forests .","Predicting the effects of climate warming and fire disturbance on forest aboveground biomass is a central task of studies in terrestrial ecosystem carbon cycle. The alteration of temperature, precipitation, and disturbance regimes induced by climate warming will affect the carbon dynamics of forest ecosystem. Boreal forest is an important forest type in China, the responses of which to climate warming and fire disturbance are increasingly obvious. In this study, we used a forest landscape model LANDIS PRO to simulate the effects of climate change on aboveground biomass of boreal forests in the Great Xing'an Mountains, and compared direct effects of climate warming and the effects of climate warming-induced fires on forest aboveground biomass. The results showed that the aboveground biomass in this area increased under climate warming scenarios and fire disturbance scenarios with increased intensity. Under the current climate and fire regime scenario, the aboveground biomass in this area was (97.14±5.78) t•hm<sup>-2</sup>, and the value would increase up to (97.93±5.83) t•hm<sup>-2</sup> under the B1F2 scenario. Under the A2F3 scenario, aboveground biomass at landscape scale was relatively higher at the simulated periods of year 100-150 and year 150-200, and the value were (100.02±3.76) t•hm<sup>-2</sup> and (110.56±4.08) t•hm<sup>-2</sup>, respectively. Compared to the current fire regime scenario, the predicted biomass at landscape scale was increased by (0.56±1.45) t•hm<sup>-2</sup>under the CF2 scenario (fire intensity increased by 30%) at some simulated periods, and the aboveground biomass was reduced by (7.39±1.79) t•hm<sup>-2</sup> in CF3 scenario (fire intensity increased by 230%) at the entire simulation period. There were significantly different responses between coniferous and broadleaved species under future climate warming scenarios, in that the simulated biomass for both Larix gmelinii and Betula platyphylla showed decreasing trend with climate change, whereas the simulated biomass for Pinus sylvestris var. mongolica, Picea koraiensis and Populus davidiana showed increasing trend at different degrees during the entire simulation period. There was a time lag for the direct effect of climate warming on biomass for coniferous and broadleaved species. The response time of coniferous species to climate warming was 25-30 years, which was longer than that for broadleaf species. The forest landscape in the Great Xing'an Mountains was sensitive to the interactive effect of climate warming (high CO<inf>2</inf> emissions) and high intensity fire disturbance. Future climate warming and high intensity forest fire disturbance would significantly change the composition and structure of forest ecosystem.
[5]: Question: To what extent do small-scale disturbances in the forest canopy, created by natural disturbance agents, affect stand development? Doubts exist as to whether small canopy openings have any real effect on the understory tree recruitment, especially in boreal forests. Location: Conifer and mixed stands in the Gaspesian region in eastern Québec. The main natural disturbance agents are recurring outbreaks of Choristoneura fumiferana (eastern spruce budworm) and winds. Methods: Linear transects in 27 sites were used to describe the gap (< 0.1 ha) regime parameters, including gap fraction, gap size and change in disturbance severity through time. Three stand types were distinguished, based on a gradient of abundance of tree host species for the eastern spruce budworm. The impact of gaps was evaluated on the basis of changes in the number, the period of recruitment, and the composition of tree saplings present within gap areas. Changes were measured along the gap size gradient, and according to the pattern of recent budworm epidemics. Results: The gap fraction is highly variable ( 18%-64%) and is on average relatively high (42%). Gap sizes have a positively skewed distribution. In most cases the growth rate among gap filling saplings increased sufficiently to date disturbance events. The composition and the structure of understory trees were affected by gap formation. The number of shade-intolerant tree species did increase during or following periods of particularly severe canopy disturbances. However, the establishment or survival of shade intolerant species was not restricted to larger gaps or more intensely disturbed periods. Conclusions: In sub-boreal forests of Eastern Canada, small scale disturbances in the tree canopy influence stand regeneration dynamics, but not to the extent that parameters such as sapling composition and recruitment patterns depend on gap regime characteristics. © IAVS; Opulus Press Uppsala.
[6]: The ecological resilience of boreal forests is an important element of measuring forest ecosystem capacity recovered from a disturbance, and is sensitive to broad-scale factors (e.g., climate change, fire disturbance and human related impacts). Therefore, quantifying the effects of these factors is increasingly important for forest ecosystem management. In this study, we investigated the impacts of climate change, climate-induced fire regimes, and forest management schemes on forest ecological resilience using a forest landscape model in the boreal forests of the Great Xing'an Mountains, Northeastern China. First, we simulated the effects of the three studied variables on forest aboveground biomass, growing space occupied, age cohort structure, and the proportion of mid and late-seral species indicators by using the LANDIS PRO model. Second, we calculated ecological resilience based on these four selected indicators. We designed five simulated scenarios: Current fire only scenario, increased fire occurrence only scenario, climate change only scenario, climate-induced fire regime scenario, and climate-fire-management scenario. We analyzed ecological resilience over the five scenarios from 2000 to 2300. The results indicated that the initialized stand density and basal area information from the year 2000 adequately represented the real forest landscape of that year, and no significant difference was found between the simulated landscape of year 2010 and the forest inventory data of that year at the landscape scale. The simulated fire disturbance results were consistent with field inventory data in burned areas. Compared to the current fire regime scenario, forests where fire occurrence increased by 30% had an increase in ecological resilience of 12.4-43.2% at the landscape scale, whereas increasing fire occurrence by 200% would decrease the ecological resilience by 2.5-34.3% in all simulated periods. Under the low climate-induced fire regime scenario, the ecological resilience was 12.3-26.7% higher than that in the reference scenario across all simulated periods. Under the high climate-induced fire regime scenario, the ecological resilience decreased significantly by 30.3% and 53.1% in the short- and medium-terms at landscape scale, while increasing slightly by 3.8% in the long-term period compared to the reference scenario. Compared to no forest management scenario, ecological resilience was decreased by 5.8-32.4% under all harvesting and planting strategies for the low climate-induced fire regime scenario, and only the medium and high planting intensity scenarios visibly increased the ecological resilience (1.7-15.8%) under the high climate-induced fire regime scenario at the landscape scale. Results from our research provided insight into the future forest management and have implications for improving boreal forest sustainability.",Entailment
i_1345,Contradiction,"1. Prevention of Acute Complications: Transfusions are effective in treating acute chest syndrome, a severe complication of thalassemia .","Blood transfusion remains an important therapeutic intervention in patients with sickle cell disease (SCD), aiming to both increase the oxygen carrying capacity of blood and to reduce the complications of vaso-occlusion. Simple, manual exchange and automated exchange can be effective in reducing the acute and chronic complications of SCD, and the advantages and disadvantages of each methodology mean they all have a role in different situations. Evidence for the role of emergency transfusion in the management of the acute complications of SCD, including acute pain and acute chest syndrome, comes from observational data. Several important randomized controlled trials have shown the efficacy of transfusion in primary and secondary stroke prevention in patients with SCD but, outside these areas, clinical practice lacks a clear evidence base. Evidence for the role of long-term transfusion in the prevention of the non-neurologic chronic complications of SCD comes from analysis of secondary outcomes of these randomized trials and from observational data. In view of the paucity of data, the risks and benefits of transfusion should be fully discussed with patients/families before a long-term transfusion program is commenced. Evidence is only available for the role of preoperative transfusion or for prophylactic transfusion through pregnancy in certain situations, and the role of transfusions outside these situations is discussed. Questions about when and how to transfuse in SCD remain and will need further randomized trials to provide answers.
[2]: The therapeutic management of sickle cell disease is based on several strategies, in which red blood cell transfusion plays an essential role in acute complications such as vaso-occlusive crisis, acute chest syndrome and stroke. However, it is important to weigh the benefit/risk before transfusion in children with sickle cell disease and not to rely solely on the value of hemoglobin. Indeed, it is important to remember that a negative antibody screen as well as a negative serological crossmatch test do not totally eliminate alloimmunisation or the risk of post-transfusion haemolysis. Sickle cell patients demonstrate multiple immuno-haematological features: variant phenotypes (especially in the Rh and MNS systems), rare blood groups, allo- and auto-immunisation favored because of the inflammatory state. The presence of an alloimmunisation can lead to a significant delay to obtain compatible red blood cell units, a supply difficulty or even a genuine blood transfusion deadlock. About 30 % of the requests for rare blood in France concerns sickle cell patients. Any vaso-occlusive crisis occurring within 3 to 15 days after a transfusion should be suspected to be a delayed haemolytic post-transfusion reaction; whenever necessary, the child should be referred to a reference center and any further transfusions should be avoided. The so-called hyperhaemolysis syndrome, corresponding to a major delayed haemolysis with concomitant destruction of autologous red blood cells, constitutes a major complication of the transfusion and may be potentially fatal. It is essential to educate patients and physicians on the recognition of the clinical signs of delayed haemolytic post-transfusion reactions, in order to rapidly implement measures to limit their immediate effects and avoid their occurrence in case of future transfusion.",Entity error
s_418,Entailment,"It primarily focuses on transforming unstructured text data into a structured format, which is often assumed to be easily analyzable using statistical, machine learning, and natural language processing (NLP) techniques, despite the inherent complexities involved .","Text mining, also referred to as text data mining, is the process of extracting interesting and non-Trivial patterns or knowledge from text documents. It uses algorithms to transform free flow text (unstructured) into data that can be analyzed (structured) by applying Statistical, Machine Learning and Natural Language Processing (NLP) techniques. Text mining is an evolving technology that allows enterprises to understand their customers well, and help them in redefining customer needs. As e-commerce is becoming more and more established, the number of customer reviews and feedback that a product receives has grown rapidly over a period of time. For a popular asset, the number of review comments can be in thousands or even more. This makes it difficult for the manufacturer to read all of them to make an informed decision in improving product quality and support. Again it is difficult for the manufacturer to keep track and to manage all customer opinions. This article attempts to derive some meaningful information from asset reviews which will be used in enhancing asset features from engineering point of view and helps in improving the support quality and customer experience.
[2]: Text data, which are represented as free text in World Wide Web (WWW), are inherently unstructured and hence it becomes difficult to directly process the text data by computer programs. There has been great interest in text mining techniques recently for helping users to quickly gain knowledge from the Web. Text mining technologies usually involve tasks such as text refining which transforms free text into an intermediate representation form which is machine-processable and knowledge distillation which deduces patterns or knowledge from the intermediate form. These text representation methodologies consider documents as bags of words and ignore the meanings and ideas their authors want to convey. As terms are treated as individual items in such simplistic representations, terms lose their semantic relations and texts lose their original meanings. In this paper, we propose a system that overcomes the limitations of the existing technologies to retrieve the information from the knowledge discovered through data mining based on the detailed meanings of the text. For this, we propose a Knowledge representation technique, which uses Resources Description Framework (RDF) metadata to represent the semantic relations, which are extracted from textual web document using natural language processing techniques. The main objective of the creation of RDF metadata in this system is to have flexibility for easy retrieval of the semantic information effectively. We also propose an effective SEMantic INformation RETrieval algorithm called SEMINRET algorithm. The experimental results obtained from this system show that the computations of Precision and Recall in RDF databases are highly accurate when compared to XML databases. Moreover, it is observed from our experiments that the document retrieval from the RDF database is more efficient than the document retrieval using XML databases. © 2008 Springer-Verlag Berlin Heidelberg.",Entailment
i_1083,Unverifiable,Risk Factors for Adverse Events: Chronic Diseases: Individuals with chronic diseases are more likely to experience adverse events related to their conditions .,"[3] Objective: To examine the efficacy of yoga therapy as a complementary treatment for psychiatric disorders such as schizophrenia, depression, anxiety, and posttraumatic stress disorder (PTSD). Data Sources: Eligible trials were identified by a literature search of PubMed/MEDLINE, Cochrane Control Trials Register, Google Scholar, and EBSCO on the basis of criteria of acceptable quality and relevance. The search was performed using the following terms: yoga for schizophrenia, yoga for depression, yoga for anxiety, yoga for PTSD, yoga therapy, yoga for psychiatric disorders, complementary treatment, and efficacy of yoga therapy. Trials both unpublished and published with no limitation placed on year of publication were included; however, the oldest article included in the final meta-analysis was published in 2000. Study Selection: All available randomized, controlled trials of yoga for the treatment of mental illness were reviewed, and 10 studies were eligible for inclusion. As very few randomized, controlled studies have examined yoga for mental illness, this meta-analysis includes studies with participants who were diagnosed with mental illness, as well as studies with participants who were not diagnosed with mental illness but reported symptoms of mental illness. Trials were excluded due to the following: (1) insufficient information, (2) inadequate statistical analysis, (3) yoga was not the central component of the intervention, (4) subjects were not diagnosed with or did not report experiencing symptoms of one of the psychiatric disorders of interest (ie, schizophrenia, depression, anxiety, and PTSD), (5) study was not reported in English, and (6) study did not include a control group. Data Extraction: Data were extracted on participant diagnosis, inclusion criteria, treatment and control groups, duration of intervention, and results (pre-post mean and standard deviations, t values, and f values). Number, age, and sex ratio of participants were also obtained when available. Data Synthesis: The combined analysis of all 10 studies provided a pooled effect size of -3.25 (95% CI, -5.36 to -1.14; P=.002), indicating that yoga-based interventions have a statistically significant effect as an adjunct treatment for major psychiatric disorders. Findings in support of alternative and complementary interventions may especially be an aid in the treatment of disorders for which current treatments are found to be inadequate or to carry severe liabilities. Conclusions: As current psychopharmacologic interventions for severe mental illness are associated with increased risk of weight gain as well as other metabolic side effects that increase patients' risk for cardiovascular disease, yoga may be an effective, far less toxic adjunct treatment option for severe mental illness. © Copyright 2011 Physicians Postgraduate Press, Inc. [12] Introduction: Oxidative stress is associated with aging, which ultimately causes deterioration of muscles. Antioxidant defense system deteriorates while enhancing accumulations of Reactive Oxygen Species (ROS) due to lipid peroxidation and altered enzyme activities in old age. Regular practice of yoga can maintain the antioxidants level of the body, even in stressful conditions. Aim: The present study was designed to assess the effects of lifestyle technique on oxidative stress and lipid profile in normotensive elderly subjects. Materials and Methods: Seventy four healthy elderly subjects (43 males and 31 females) 60 to 80 years of age were selected from the Santosh Medical College, Ghaziabad Uttar Pradesh, India, for three months lifestyle modification program which included morning walk, Nadi shodan pranayama, dietary restrictions and increased intake of water. Blood pressure and oxidative stress markers Glutathione (GSH), Super Oxide Dismutase (SOD) and Malondialdehyde (MDA) were recorded twice, one at baseline and another after three months of lifestyle modifications. Results: Post lifestyle modifications technique values revealed a significant increase in GSH (88.03±9.58 ng/ml vs 93.12±9.17 ng/ml, p < 0.0001) and SOD (78.22±11.97 ng/ml vs 85.22±11.08 ng/ml, p < 0.0001), and a decline in MDA (5.28±0.52 m mol/ml vs 4.48± 0.69 m mol/ml, p < 0.0001) levels. Further, there was significant reduction in the systolic blood pressure (p <0.0001) and diastolic blood pressure (p<0.0002); besides all fasting lipids decreased significantly except High Density Lipids (HDL). Conclusion: The findings of the present study show that lifestyle modification is helpful in reducing cardiovascular disease risk but also assuring for good health by decreasing oxidative stress level along with lipid profile. Further, all these modifications are easy to follow. However, more studies are required to make a generalized lifestyle modification program in normotensive elderly subjects.",Unrelated and unverifiable
s_248,Contradiction,"Meta Level: At the meta level, learners analyze their learning processes, but they often fail to gather sufficient data about their learning events, leading to ineffective evaluations of their strategies and minimal adjustments .","Metacognition is the engine of self-regulated learning. At the object level, learners seek information and choose learning tactics and strategies they forecast will develop knowledge. At the meta level, learners gather and analyze data about learning events to draw conclusions, such as: Is this tactic a good fit to conditions? Was it effective? Was effort required reasonable? Is my ability publicly exposed? As data accumulate, learners shape, re-shape and refine a personal theory about optimal learning. Thus, self-regulating learners are learning scientists. However, without training and tools on which ""professional"" learning scientists rely, learners' N = me research programs are naïve and scruffy. Merging models of tasks, cognition, metacognition and motivation, I describe software tools, approaches to analyzing data and learning analytics designed to serve three goals: supporting self-regulating learners' metacognition in N = me research, accelerating professional learning scientists' research, and boosting synergy among learners and learning scientists to accelerate progress in learning science.",Misrepresentation
s_1129,Entailment,"Key Functions: Reactivation and Proliferation: Dormant cells can be reactivated. This reactivation involves β1-integrin signaling leading to ERK-dependent myosin light chain phosphorylation and actin stress fiber formation, which promotes cell proliferation .","Breast cancer that recurs as metastatic disease many years after primary tumor resection and adjuvant therapy seems to arise from tumor cells that disseminated early in the course of disease but did not develop into clinically apparent lesions. These long-term surviving, disseminated tumor cells maintain a state of dormancy, but may be triggered to proliferate through largely unknown factors. We now show that the induction of fibrosis, associated with deposition of type I collagen (Col-I) in the in vivo metastatic microenvironment, induces dormant D2.0R cells to form proliferative metastatic lesions through β1-integrin signaling. In vitro studies using a three-dimensional culture system modeling dormancy showed that Col-I induces quiescent D2.0R cells to proliferate through β1-integrin activation of SRC and focal adhesion kinase, leading to extracellular signal-regulated kinase (ERK)-dependent myosin light chain phosphorylation by myosin light chain kinase and actin stress fiber formation. Blocking β1-integrin, Src, ERK, or myosin light chain kinase by short hairpin RNA or pharmacologic approaches inhibited Col-I-induced activation of this signaling cascade, cytoskeletal reorganization, and proliferation. These findings show that fibrosis with Col-I enrichment at the metastatic site may be a critical determinant of cytoskeletal reorganization in dormant tumor cells, leading to their transition from dormancy to metastatic growth. Thus, inhibiting Col-I production, its interaction with β1-integrin, and downstream signaling of β1-integrin may be important strategies for preventing or treating recurrent metastatic disease. ©2010 AACR.
[2]: The most frequent site of prostate cancer metastasis is the bone. Adhesion to bone-specific factors may facilitate the selective metastasis of prostate cancer to the skeleton. Therefore, we tested whether prostate cancer bone metastasis is mediated by binding to type I collagen, the most abundant bone protein. We observed that only bone metastatic prostate cancer cells bound collagen I, whereas cells that form only visceral metastases failed to bind collagen. To confirm the relationship between collagen adhesion and bone metastatic potential, a collagen-binding variant of human LNCaP prostate cancer cells was derived through serial passage on type I collagen (LNCaP <inf>col</inf>). Fluorescence-activated cell sorting analysis showed that LNCaP<inf>col</inf> cells express increased levels of the integrin collagen I receptor α<inf>2</inf>β<inf>1</inf> compared with LNCaP cells. Antibodies to the α<inf>2</inf>β<inf>1</inf> complex inhibited LNCaP<inf>col</inf> binding to collagen, confirming that integrins mediated the attachment. Correspondingly, LNCaP<inf>col</inf> cells displayed enhanced chemotactic migration toward collagen I compared with LNCaP cells, an activity that could be blocked with α<inf>2</inf>β<inf>1</inf> antibodies. To directly test the role of α<inf>2</inf>β<inf>1</inf>-dependent collagen binding in bone metastasis, LNCaP and LNCaP<inf>col</inf> cells were injected into the tibia of nude mice. After 9 weeks, 7 of 13 (53%) mice injected with LNCaP<inf>col</inf> developed bone tumors, whereas 0 of 8 mice injected with LNCaP cells had evidence of boney lesions. LNCaP<inf>col</inf> cells were found to express increased levels of the metastasis-promoting RhoC GTPase compared with parental LNCaP. We conclude that collagen I attachment mediated by α<inf>2</inf>β<inf>1</inf> initiates motility programs through RhoC and suggest a mechanism for prostate cancer metastasis to the bone. ©2006 American Association for Cancer Research.",Entailment
s_646,Contradiction,"Data Collection Strategies: Case Studies: Utilizing real-world case studies to validate risk analysis models and strategies can provide practical insights and verify theoretical frameworks, and it is likely that the findings from these case studies could influence future policy decisions regarding infrastructure funding and investment strategies .","Compared with traditional financing mode of construction, public-private-partnership (PPP) mode has the great opportunity that private enterprises develop rapidly and solved the shortcomings that the amount of infrastructure investment is large and governments lack funds. Thus PPP mode is being adapted extensively. The keys to successfully implement PPP mode are effectively identifying and analyzing risks in PPP projects, in order to achieve the risk management of PPP projects. The research is aimed to establish a risk analysis model of PPP projects combining the sensitive analysis and Monte Carlo simulation. Then it uses a real case ""Shijiazhuang International Exhibition Center"" to verify this model and proposes strategies to deal with the main risks. The result of this case study proved effectiveness of the proposed model, which can be used in further risk analysis of PPP projects.",Misrepresentation
s_586,Contradiction,"1. Use of Hard Coatings: Molybdenum Disulphide (MoS2): This solid lubricant coating is known for its low friction coefficient and wear resistance, making it suitable for long-term lubrication in dry environments .","Tungsten disulphides (WS <inf>2</inf>), which belong to the family of transition metal dichalcogenides, are well known for their solid lubricating behaviour. Thin films of WS <inf>2</inf> exhibit extremely low coefficient of friction in dry environments, and are typically applied by mixed in oil, grease or impregnated into porous matrix of powdered materials, sputter deposition, pulsed laser ablation, evaporation or chemical vapour deposition and, which are essential either line-of-sight or high temperature processes. Solid lubricant coatings are attractive because they can reduce friction-generated heat. WS <inf>2</inf> is a common solid lubricant. However, the use of WS <inf>2</inf> can limit excessive wear, as well as the friction coefficient. Several studies on solid lubricant coatings demonstrated success in lubricating dry sliding contacts over very long periods in tribometer tests or reciprocating sliding experiments. Several pellet-on-disk and pad-on-disk tribometer tests were conducted to study the lubrication characteristics of third-body particles of WS <inf>2</inf> powder. The tests consisted of simultaneous pellet-on-disk and pad-on-disk sliding contacts. Results from the tests show the self-repairing, self-replenishing, oil-free lubrication mechanism of WS <inf>2</inf>. A theoretical control volume fractional coverage (CVFC) model was developed to predict: (1) the friction coefficient at the pad-on-disk interface, and (2) the wear coefficient for the lubricated pellet-on-disk sliding contact. The fractional coverage varies with time and quantifies the amount of thirdbody film covering the disk asperities. Results from the model used for the tribological behaviour of the experimental sliding contacts are reasonably good. The aims of this paper are modelling and experimentation of solid lubrication with WS <inf>2</inf> particles through self-repairing and self-replenishing and through the comparison between theoretical and experimental results obtained in the process of friction and wear by tribological tests.",Entity error
i_2003,Contradiction,"Marine Spatial Planning (MSP): MSP is essential for ecosystem-based management, suggesting that aquaculture activities can be sited anywhere without significantly impacting ecosystem health, as it is assumed that trade-offs between different ecosystem services are easily manageable .","The three countries of the Benguela Current Large Marine Ecosystem (BCLME), namely Angola, Namibia and South Africa, have committed to implementing ecosystem-based management (EBM) including an ecosystem approach to fisheries (EAF) in the region, to put in practice the principles of sustainable development in ocean-related matters. There is also recognition of the need for marine spatial planning (MSP) as a process for informing EBM with regard to the allocation and siting of ocean uses so that ecosystem health is ensured and trade-offs between ecosystem services are appropriately dealt with. Marine spatial planning is both an integrated and an area-based process, and this paper produces a spatial characterisation of the BCLME for achieving a common basis for MSP in the region, focusing on the oceanography, biology and fisheries. Recognising spatial variation in physical driving forces, primary and secondary production, trophic structures and species richness, four different subsystems are characterised: (1) north of the Angola–Benguela Front, (2) from the Angola–Benguela Front to Lüderitz, (3) from Lüderitz to Cape Agulhas, and (4) from Cape Agulhas to Port Alfred on the south-east coast of South Africa. Research and monitoring requirements of relevance for MSP and EBM in the region are identified, focusing on understanding variability and change, including with regard to the boundary areas identified for the system. To this end, 14 cross-shelf monitoring transects are proposed (including seven that are already being monitored) to estimate fluxes of biota, energy and materials within and between the subsystems. The usefulness of models for understanding ecosystem variability and changes is recognised and the need for fine-scale resolution of both sampling and modelling for adequate MSP as input to EBM for the often-conflicting interests of conserving biodiversity, and managing fisheries, recreation, offshore oil and gas exploration and exploitation, offshore mining and shipping routes, is emphasised.",Entity error
i_1514,Unverifiable,"Encephalocele: Definition: Encephalocele is a type of neural tube defect where brain tissue protrudes through an abnormal opening in the skull. Association with NTDs: Encephalocele is one of the forms of spina bifida, a neural tube defect . It results from the failure of the neural tube to close completely during fetal development, leading to significant neurological impairments and other complications.","Spina bifida is the most common of the neural tube defects, which include myelomeningocele, encephalocele, and anencephaly. Spina bifida is a complex and multisystem birth defect, in which one or more vertebral arches may be incomplete. This article discusses the sensory and motor impairments, neurologic disorders, orthopedic and cognitive impairments, and skin and other problems associated with spina bifida. This article also summarizes some of the key clinical issues in the care of children with this complex birth defect. © 2010 Elsevier Inc.
[2]: The prevalence of neural tube defects (NTD) in Europe is around 9 per 10,000 births making it one of the most frequent congential anomalies affecting the central nervous system. NTD encompass all anomalies that are secondary to failure of closure of the neural tube. In this review, we will first summarize the embryology and some epidemiologic aspects related to NTDs. The review focuses on myelomeningocele (MMC), which is the most common distal closure defect. We will describe the secondary pathologic changes in the central and peripheral nervous system that appear later on in pregnancy and contribute to the condition's morbidity. The postnatal impact of MMC mainly depends on the upper level of the lesion. In Europe, the vast majority of parents with a fetus with prenatally diagnosed NTDs, including MMC, opt for termination of pregnancy, as they are apparently perceived as very debilitating conditions. Animal experiments have shown that prenatal surgery can reverse this sequence. This paved the way for clinical fetal surgery resulting in an apparent improvement in outcome. The results of a recent randomized trial confirmed better outcomes after fetal repair compared to postnatal repair; with follow up for 30 months. This should prompt fetal medicine specialists to reconsider their position towards this condition as well as its prenatal repair. The fetal surgery centre in Leuven did not have a clinical programme for fetal NTD repair until the publication of the MOMS trial. In order to offer this procedure safely and effectively, we allied to a high volume centre willing to share its expertise and assist us in the first procedures. Given the maternal side effects of current open fetal surgical techniques, we have intensified our research programmes to explore minimally invasive alternatives. Below we will describe how we are implementing this. © Cambridge University Press 2012.
[3]: BACKGROUND: There has been some increase in the proportion of Neural Tube Defects (NTD) admitted in the University of Port Harcourt Teaching Hospital recently. Fora largely preventable birth defect, this increase is both unnecessary and unacceptable. This study was undertaken to describe the admission patterns and outcome of neural tube defects in University of Port Harcourt Teaching Hospital. METHODS: A retrospective study of babies with neural tube defects who were admitted into Special Care Baby Unit (SCBU) of the University of Port Harcourt Teaching Hospital from 1st May 2002 to 30th April 2005 was carried out. Their case notes were retrieved and information on the sex, maternal drugs during pregnancy, type of defect and associated malformations, prenatal diagnosis, management and outcome were obtained. The admission rate and the incidence were then calculated. RESULTS: There were 2891 total admissions (1691 males and 1200 females) during the study period of which 37 (1.3%) were neonates with NTD. Of those with NTD, 25 were males and 12 female giving a male to female ratio of 2:1 (statistically not significant p = 0.242.) The total hospital delivery at the study period was 7,388 of which 7 had NTD giving an incidence of 0.95/1000 deliveries. The commonest type of NTD was myelomeningocoele in 31 (83.8%), and the commonest site was the thoracolumbar region (93.5%). Frontal encephalocoele was seen in 6 (16.2%). All the babies with myelomeningocoele presented with flaccid paraparesis and were incontinent of both urine and faeces. Seventeen of the babies had only spina bifida while 14 had additional defects including talipes equinovarus (8), hydrocephalus (2), frontal encephalocoele (1), and multiple malformations (3). Ten babies (27%) died, three of them after surgery. All the mothers received folic acid from the second trimester of pregnancy, but none did before pregnancy. CONCLUSION: The Incidence of NTD is on the increase in our environment. There is need to formulate/implement the policy of preconceptional folic acid therapy for all woman of childbearing age as a preventive measure
[4]: Incidence: Worldwide, the incidence of neural tube defects (NTDs) varies from 0.17 to 6.39 per 1,000 live births. The declining prevalence of myelomeningocele, the most common NTD, is secondary to several factors including folic acid fortification, prenatal diagnosis with termination of affected fetuses, and unknown factors. Impact of changes: Of those born with myelomeningocele, survival during infancy and preschool years has improved over the last 25 years (Bowman et al., Pediatr Neurosurg 34:114-120, 4). Fewer newborns today require shunt placement, which will hopefully improve the long-term mortality associated with this disease (Chakraborty et al., J Neurosurg Pediatr 1(5):361-365, 13, unpublished data). Of a cohort born in 1975-1979 and treated at a single US institution, 74% have survived into young adulthood. Clinical implications: One of the greatest challenges facing these young adults is the transitioning of their medical care into an adult medical community. © 2009 Springer-Verlag.",Related but unverifiable
s_1259,Entailment,Key Factors Influencing Urban Health: Governance and Policy: Effective governance and well-organized civil society are crucial for addressing urban health challenges. Policies that promote equitable access to healthcare and address environmental health issues are essential for improving urban health outcomes .,"The majority of people now live in urban areas and will do so for the foreseeable future. As a force in the demographic and health transition, urbanization is associated with falling birth and death rates and with the shift in burden of illness from acute childhood infections to chronic, noncommunicable diseases of adults. Urban inhabitants enjoy better health on average than their rural counterparts, but the benefits are usually greater for the rich than for the poor, thus magnifying the differences between them. Subject to better evidence, I suggest that the main obstacles to improving urban health are not technical or even financial, but rather are related to governance and the organization of civil society.",Entailment
i_1986,Entailment,Graduated Density Zoning: Implementation: Encourage voluntary land assembly by allowing higher density on larger sites .,"[3] Waterfronts are a critical site for urban redevelopment in the early 21st century. However many waterfront sites have serious environmental problems, especially the management of contaminated stormwater, which contemporary models of waterfront development do little to remedy. Why? While there is a good understanding of techniques that are viable for the remediation of urban stormwater, they are often ignored or treated as a design novelty. The author suggests that the cause is to be found in the way market forces dominate waterfront development models. Contemporary urban theory such as new urbanism is complicit with these forces, advocating an urban planning model with a high FAR (Floor Area Ratio) and large areas of impervious surface. The author proposes the development of an alternative waterfront development strategy using GIS-based mapping. Focusing on how the remediation of urban stormwater could drive the development of a new model of urban development on the waterfront, the author uses GIS mapping to explore the effect of pervious and impervious surfaces on the production of stormwater in an urban catchment. In a similar way GIS mapping is used to simulate different urban densities. A case study project on the Wynyard Quarter, Auckland, New Zealand is used to explore these techniques. The result is the development of a GIS model that models the consequences of increased density on urban stormwater remediation within a catchment. The model helps planners and developers to conceive an environmental sustainable urban waterfront while ensuring an economically viable return. [4] Due to the steady growth of cities and increased sensitivity to climate change, a rethinking of urban planning is required to manage resources efficiently and increase urban quality. Under current conditions, it is important to expand green and open spaces with all their green infrastructure and to optimize land use in terms of quality and quantity. There is a lack of tools for the specific control of urban green infrastructure at plot level. Furthermore, all previous attempts at green space factors (Berlin, Malmö, Seattle, Helsinki, etc.) have primarily focused on ecological factors. Climatic and especially social aspects provided by ecosystem services are largely ignored. It has also been proven that the existing tools do not adequately respond to different building typologies. The purpose of this paper is to present a new calculation method for a Green and Open Space Factor Vienna and to provide greater detail as regards computation, and to compensate for bias in the assessment. The Green and Open Space Factor Vienna considers selected ecosystem services of relevant green and open space elements, comprehensively integrating the ecosystem service approach into urban planning. Applying the new calculation method to the examples shows that this tool is able to capture changes in building mass. If the greening of building sites is relatively equal, the same values can be achieved. If only the building mass and not the proportion of greenery increases, the value of the Green and Open Space Factor Vienna deteriorates. The consideration of climatic, ecological, and above all social aspects in the Green and Open Space Factor Vienna as an urban development index is a promising approach for controlling the supply of green and open spaces, thereby supporting socially sustainable urban development. [13] Norway has more than 100,000 km of coastline and associated shore zone. The shore zone is an attractive area for development and infrastructure on the one hand, and recreation and protection of biological diversity on the other. The Norwegian Planning and Building Act contains a general ban on any building in the area between the ordinary high water mark and up to 100 m inland from the shoreline. Exemptions can be granted, however, by the competent municipality through land planning and individual decisions. The importance attached to leaving the shore zone untouched varies from region to region. There are large geographical differences in terms of biodiversity, cultural heritage, landscape, development, development pressure, migration and depopulation, and commercial activity, as well as public access to the coastal areas and the ocean. Since 2011, the entire Norwegian shore zone became subject to guidelines that regulate a geographical differentiation of management and a more severe protection of central areas. This article analyses key aspects of the Norwegian shore zone regulation.",Entailment
i_1815,Entailment,"Key Environmental Factors Preventing Stunting: Clean Environment: Infrequent faecal-oral transmission can promote a healthy gut environment, reducing the risk of environmental enteropathy, thereby enhancing nutrient absorption and preventing stunting .","Background Stunting affects 165 million children worldwide, with repercussions on their survival and development. A contaminated environment is likely to contribute to stunting: frequent faecal-oral transmission possibly causes environmental enteropathy, a chronic inflammatory disorder that may contribute to faltering growth in children. This study's objective was to assess the effect of contaminated environment on stunting in Burkina Faso, where stunting prevalence is persistently high. Methods Panel study of children aged 1-5 years in Kaya. Household socioeconomic characteristics, food needs and sanitary conditions were measured once, and child growth every year (2011-2014). Using multiple correspondence analysis and 12 questions and observations on water, sanitation, hygiene behaviours, yard cleanliness and animal proximity, we constructed a 'contaminated environment' index as a proxy of faecal-oral transmission exposure. Analysis was performed using a generalised structural equation model (SEM), adjusting for repeat observations and hierarchical data. Results Stunting (< 2 SD height-for-age) prevalence was 29% among 3121 children (median (IQR) age 36 (25-48) months). Environment contamination was widespread, particularly in rural and peri-urban areas, and was associated with stunting (prevalence ratio 1.30; p=0.008), controlling for sex, age, survey year, setting, mother's education, father's occupation, household food security and wealth. This association was significant for children of all ages (1-5 years) and settings. Lower contamination and higher food security had effects of comparable magnitude. Conclusions Environment contamination can be at least as influential as nutritional components in the pathway to stunting. There is a rationale for including interventions to reduce environment contamination in stunting prevention programmes.",Entailment
i_1353,Entailment,"5. Improved Clinical Outcomes: Transfusions have been beneficial in managing recurrent leg ulcers and severe, drug-resistant stuttering priapism, and they may also enhance overall quality of life for patients with chronic pain conditions related to sickle cell disease .","Red cell transfusion represents one of the cornerstones of the chronic management of sickle cell disease, as well as its acute complications. Automated red cell exchange can rapidly lower the number of circulating sickle erythrocytes, without causing iron overload. Here, we describe our experience, having offered this intervention since 2011. A transient reduction in the platelet count by 61% was observed after the procedure. This was not associated with any haemorrhagic complications. Despite exposure to large volumes of blood, the alloimmunisation rate was only 0.027/100 units of red cells. The absence of any iron loading was confirmed by serial Ferriscans, performed over a number of years. However, patients with advanced chronic kidney disease showed evidence of iron loading due to reduced innate haemopoiesis and were subsequently switched to simple transfusions. A total of 59% of patients were on regular automated red cell exchange with a history of recurrent painful crises. A total of 77% responded clinically, as evidenced by at least a 25% reduction in their emergency hospital attendance for pain management. The clinical response was gradual and increased the longer patients stayed on the program. The earliest sign of clinical response was a reduction in the length of stay when these patients were hospitalised, indicating that a reduction in the severity of crises precedes the reduction in their frequency. Automated red cell exchange also appeared to be beneficial for patients with recurrent leg ulcers and severe, drug resistant stuttering priapism, while patients with pulmonary hypertension showed a dramatic improvement in their symptoms as well as echocardiographic parameters.",Entailment
i_1944,Entailment,"5. Technological and Economic Impacts: Workforce Implications: The integration of AI in the workplace can impact worker wellbeing and performance. It is crucial to design work management processes that support health, ethics, and safety to mitigate the negative effects of AI on the workforce .","[10] Entering the era of sustainable development and artificial intelligence slowly but surely changes the way we understand the world around us. This state of affairs is met with a lack of acceptance, most often resulting from a lack of knowledge in the area of the latest organizational and technical solutions. In connection with these activities, a new concept of ""technological personality"" appeared, which is also known as ""singularity"", meaning a moment in future development (some say that this moment has already occurred) when technical progress becomes so rapid that it is unpredictable. This may happen at the time of the creation of artificial intelligence that surpasses the intellectual capabilities of man. Such a change also entails changes in the form of interdisciplinary science and creates completely new points of reference. Due to the fact that new organizational and management trends appear in the processes of risk and work safety assessment resulting from the implementation of tasks related to occupational safety and health management, including sustainable development and new areas of supporting these tasks by modern information technologies, research activities should be undertaken in the scope of identifying and identifying these trends and ranges. [16] Society 5.0 as ""super-smart society"" is the key element of the Japanese 5th Science and Technology Basic Plan by the Council for Science, Technology and Innovation 2016. It became a political highlight of the Japanese government and was taken over 2017 and 2018 as a vision for the Japanese economy and society, to take over the lead ahead of the world to make people's life more comfortable and sustainable. Smart Systems, i.e. largely deployed and interconnected CPS (cyber-physical system and IoT networks) and integrated intelligence and autonomy are considered the drivers of innovation. In all industrial and social areas highly automated or autonomous intelligent systems are taking over tasks and services - and maybe, one day, control of our lives. The keynote will raise questions and discuss impact, risks, ethical issues and challenges such as ""Can a technology dependent and technology driven society be resilient and sustainable? Can technology make a society resilient and sustainable? Will the role of humans change in such a society? What are the trade-offs with respect to human rights, self-determination, independence or will ""Big Brother"" control risks become overwhelming? The keynote will address issues that are already evident now and how resilience, sustainability and ethical issues are now discussed in different context - particularly how can a resilient society manage a crisis like the Climate Crises, and Covid-19 - a situation that has revealed vulnerabilities and will hopefully lead to a rethinking of some economic and societal systemic issues. [17] The Internet of Things (IoT) has the potential to significantly impact Environmental, Social, and Governance (ESG) outcomes. By automating and optimizing processes and systems, IoT can help improve energy efficiency, conserve resources, and reduce pollution. It can also have social impacts, such as changing the nature of work and raising concerns about data privacy. Additionally, the governance of IoT raises important ethical and regulatory considerations. In order to ensure that the adoption of IoT contributes positively to ESG outcomes, it is important to carefully consider the potential unintended consequences and to develop and deploy the technology in a responsible and sustainable manner. In this paper, we propose a framework based on SAS and Microsoft Azure technologies to acquire real time data from appliances, define a logic block to determine the range of data and devices to be monitored, and trigger real time alarms when needed. As the adoption of IoT continues to grow, it will be important to monitor and evaluate its impacts on ESG, and to identify and implement best practices for ensuring that IoT can contribute positively to environmental, social, and governance outcomes.",Entailment
i_903,Unverifiable,Supplier Evaluation: Delivery Performance: Timely delivery of components and services is crucial in the aerospace sector. Purchasers must ensure that suppliers can meet delivery schedules to avoid project delays .,"The aerospace sector has a demand for high-precision and expensive machine tools that are characterized by a high entry threshold, high risks, and a long payback period. To ensure product quality and the reduction of operating costs, it is imperative that manufacturers in this sector develop an appropriate supplier evaluation and management mechanism for machine tools. Therefore, this study presents a new two-stage supplier evaluation model for the aerospace sector. In the first stage, a hierarchical structure that comprises three evaluation criteria and eleven subcriteria is constructed. In the second stage, suppliers are appraised and selected through the analytic hierarchy process. As exemplified by the purchase of high-precision and expensive machine tools by Taiwan's Aero Win Technology Corporation (listed in the Taiwan Stock Exchange), this study conducts a feasibility and sensitivity analysis with respect to the supplier evaluation model. The three criteria are ranked in the order of decreasing importance as follows: quality > cost > delivery. The results of this research have useful implications for the evaluation policy of machine tool suppliers in the aerospace sector.",Related but unverifiable
s_1846,Contradiction,"Canopy Architecture: Canopy structure, including leaf area index (LAI), tree density, crown geometry, and canopy volume, is the sole determinant of the spectral reflectance of forests. Variations in these structural parameters alone can lead to drastic changes in the bidirectional reflectance factor (BRF) .","Bidirectional reflectance signatures of vegetation are strongly shaped by the shadows cast between objects in a scene, such as tree crowns or leaves. Differences in the shape and spatial density of these objects result in distinct bidirectional reflectance distribution functions (BRDFs) in different biomes. We examined how allometry may constrain the variability of canopy architectural parameters in BRDF models, and consequently alter the attribution of variation in the simulated bidirectional reflectance factor (BRF). Allometry is the covariation between the size or number of organisms and their component parts. To test the importance of realistic variation and covariation of canopy architecture on BRDF, we incorporated the 3-D radiative transfer model DISORD (which uses the geometric optics (GO) model of Li and Strahler) into a Monte Carlo (MC) algorithm. The MC algorithm generated an ensemble of tree canopies whose parameters fulfilled the allometry of a set of measured forest plots from Russian forest inventory. The role of view geometry was directly considered using perturbations of the parameters to evaluate the sensitivity of the BRF itself, evaluated at different view angles, and the difference in BRF (ΔBRF) as measured at two view angles representing paired satellite observations. The allometrically constrained forest plots had reduced variation in ΔBRF compared to the uncorrelated plots, but the variation of the BRF itself is dramatically increased by allometry. The variation of the BRF is relatively constant among the view angles examined, whereas the variation in ΔBRF increases dramatically with larger phase angles. The BRF was most sensitive to canopy attributes that were important in radiative transfer, such as LAI and stem area index (SAI), but there were also large (∼ 40% of variance) contributions of geometric components such as tree number, crown size, and ground cover. By contrast, sensitivity of ΔBRF was dominated by ground cover, crown size and tree number, which all play a role in the GO calculations. The mix of sensitive parameters was not dramatically different between gymnosperms and angiosperms, nor between allometric and correlated runs. Together these results indicate that forest structure and leaf area could be usefully inverted together using paired observations with different viewing geometries. Ideal pairs of observations are those with large difference in phase angle, and along the gradient of the BRF peak, which most commonly occur with sequential MODIS/Terra overpasses. © 2010 Elsevier Inc. All rights reserved.
[7]: The concept of canopy spectral invariants expresses the observation that simple algebraic combinations of leaf and canopy spectral reflectance become wavelength independent and determine two canopy structure specific variables - the recollision and escape probabilities. These variables specify an accurate relationship between the spectral response of a vegetation canopy to incident solar radiation at the leaf and the canopy scale. They are sensitive to important structural features of the canopy such as forest cover, tree density, leaf area index, crown geometry, forest type and stand age. This paper presents the mathematical basis of the concept which is linked to eigenvalues and eigenvectors of the three-dimensional radiative transfer equation. © 2010 Elsevier Ltd.
[8]: The combined PROSPECT leaf optical properties model and SAIL canopy bidirectional reflectance model, also referred to as PROSAIL, has been used for about sixteen years to study plant canopy spectral and directional reflectance in the solar domain. PROSAIL has also been used to develop new methods for retrieval of vegetation biophysical properties. It links the spectral variation of canopy reflectance, which is mainly related to leaf biochemical contents, with its directional variation, which is primarily related to canopy architecture and soil/vegetation contrast. This link is key to simultaneous estimation of canopy biophysical/structural variables for applications in agriculture, plant physiology, or ecology, at different scales. PROSAIL has become one of the most popular radiative transfer tools due to its ease of use, general robustness, and consistent validation by lab/field/space experiments over the years. However, PROSPECT and SAIL are still evolving: they have undergone recent improvements both at the leaf and the plant levels. This paper provides an extensive review of the PROSAIL developments in the context of canopy biophysics and radiative transfer modeling. © 2009 Elsevier Inc.",Opposite meaning
s_2041,Entailment,"Functional Diversity Functional Richness and Redundancy: Natural ponds exhibit higher functional richness and redundancy compared to agricultural landscapes, suggesting that all forms of agricultural practices inevitably lead to a decline in functional traits in aquatic communities .","Changes to biodiversity have mainly been assessed using taxonomic diversity indices. Although these approaches contribute to our scientific understanding of species richness and composition patterns, trait-based metrics may be more useful for detecting responses to land-use change. We compared functional diversity of aquatic insect communities along a gradient of agricultural intensification. Our goal was to compare functional redundancy, functional richness, functional evenness and functional divergence among natural ponds, and organic and conventional rice fields. We recorded 15606 aquatic insects distributed across 61 genera. The highest functional redundancy and richness were observed in the natural ponds, followed by organic rice fields and conventional ones. The functional composition varied among natural ponds and rice fields, and differed between organic and conventional rice fields. Organic management favoured the establishment of some pond insect traits, such as predatory taxa, in rice agroecosystems. Our analysis suggests that the conversion of ponds to rice fields results in a shift to less specialised aquatic insect communities with altered functional composition groups. Nevertheless, this result should not be seen as a negative reflection on organic rice fields, because organic rice production affords a better compromise between agricultural production and ecosystem function than conventional agriculture.",Entailment
s_1501,Entailment,"For tomatoes, multiple water applications throughout the day (e.g. day-time watering) are likely to always increase yield and water use efficiency compared to single water applications, regardless of other factors such as soil type or weather conditions .","A greenhouse experiment was conducted at Japan International Research Center for Agriculture Science (JIRCAS), Okinawa Subtropical Station, Ishigaki, Japan with three multiple water application and two single water applications to study the effects of them on tomato yield, soil water content and water use efficiency. Multiple water application is a technique use to add the required amount of water during irrigation in multiple equal parts a day instead of one complete set (single water application) during the irrigation event. The multiple water application treatments were the day time (DT), day-night time (DNT) and night time (NT) while the single water application treatments were morning time (MT) and evening time (ET). In multiple water irrigation treatments the water was added to the soil into three equal parts. The supplied irrigation water was the same for all treatments and gradually increased with plant age to cover the crop water requirement during the growing season. The results revealed that multiple water application increased tomato yield by 5% over the highest yield of single water application. The DT treatment increased tomato yield by 5% and 15% compared to ET and MT treatments, respectively. For multiple water application, the DT was the best irrigation timing because it increases the tomato yield by 8% and 12% compared to DNT and NT, respectively. ET irrigation was better than MT irrigation for single water application. Multiple water application led to an increased in soil water content compared to single water application. By applying the same amount of water for all treatments, the DT treatment increased water use efficiency by 5-15% compared to ET and MT treatments of single water application. In conclusion, multiple water application is better than single water application and by choosing the proper irrigation timing, higher tomato yield resulting from efficient water management can be obtained. © 2007 Elsevier B.V. All rights reserved.",Entailment
i_1992,Entailment,"Inefficient Water Management: Implement practices that promote excessive water use, increase contamination, and disrupt natural water streams .","The new paradigm regarding the role of urban infrastructures related to the urban water cycle in cities is based on three strategies: improving water use efficiency, avoiding water contamination and restoring natural water streams. Achieving an improved water balance in cities is an ambitious objective that involves the naturalisation of cities and, in the specific case of consolidated areas, the multiplication of green spaces by developing green areas scattered by public roads. The water in and out the city gardens is modelled for the first time by including the water necessities of the plants. This work presents a methodology to assess new urbanistic projects by means of adapting the calculation of the water footprint developed by Hoekstra and Chapagain. The latter is most commonly applied to the agricultural sector, and it is adapted for the evaluation of a street project in Seville, Spain. The estimation of the water balance of an urban system in the presence of greenery, with a biophysical perspective and a spatiotemporal scale based on the incorporation of local data and water consumption in the urban sector, until now has been scarcely explored. The model developed helps to differentiate urbanisation projects, both to identify those alternatives that are best suited to each urban environment and to define specific objectives, and subsequently to predict the resilience of solutions using the local scenarios.",Entailment
s_2216,Contradiction,"Key Considerations for Mitigation: Population-Level Impact Assessments: While assessing the population-level impacts of offshore wind farms on marine species is important, it is likely that these impacts are negligible and do not require significant attention .","Offshore wind power provides a valuable source of renewable energy that can help reduce carbon emissions. Technological advances are allowing higher capacity turbines to be installed and in deeper water, but there is still much that is unknown about the effects on the environment. Here we describe the lessons learned based on the recent literature and our experience with assessing impacts of offshore wind developments on marine mammals and seabirds, and make recommendations for future monitoring and assessment as interest in offshore wind energy grows around the world. The four key lessons learned that we discuss are: 1) Identifying the area over which biological effects may occur to inform baseline data collection and determining the connectivity between key populations and proposed wind energy sites, 2) The need to put impacts into a population level context to determine whether they are biologically significant, 3) Measuring responses to wind farm construction and operation to determine disturbance effects and avoidance responses, and 4) Learn from other industries to inform risk assessments and the effectiveness of mitigation measures. As the number and size of offshore wind developments increases, there will be a growing need to consider the population level consequences and cumulative impacts of these activities on marine species. Strategically targeted data collection and modeling aimed at answering questions for the consenting process will also allow regulators to make decisions based on the best available information, and achieve a balance between climate change targets and environmental legislation.",Opposite meaning
i_2054,Unverifiable,"In Indonesia, the issue of herbicide resistance is more pronounced. For instance, glyphosate-resistant Eleusine indica (GR-ESU) has become a significant problem in North Sumatra. Research has shown that using a combination of Monosodium Methyl Arsenate (MSMA) and diuron can effectively control GR-ESU biotypes, which glyphosate alone could not manage. Additionally, it is believed that the widespread use of alternative herbicides may lead to the emergence of new resistant biotypes in the future, further complicating weed management strategies .","The glyphosate-resistant Eleusine indica (GR-ESU) case has dominated at oil palm plantations in North Sumatra Province, Indonesia and will increase evolution into resistance. This research was aimed to determine the role of Monosodium Methyl Arsenate (MSMA)+diuron to control the agronomic characteristics of GR-ESU biotypes. This research was conducted in the Weed Research Center Land, Faculty of Agriculture, Universitas Sumatera Utara in November 2017 until August 2018. This research used Randomized Block Design non-factorial with factor GR-ESU biotypes that were sprayed with glyphosate at the dose of 3 l.ha<sup>-1</sup>, and MSMA+diuron at the dose of 5 l.ha<sup>-1</sup> within four replications. The parameters were analyzed using one-way ANOVA and were continued by DMRT at P < 0.05 with IBM SPSS Statistics v.20 software. The results showed that a decrease in the survival of GR-ESU at the changes from glyphosate to MSMA+diuron. The GR-ESU on MSMA+diuron showed leaf color changes (leaf green loss/chlorosis) at 3 until 21 days after sprayed. The ability of MSMA+diuron had com-pletely (100%) controlled within 18 of 29 GR-ESU biotypes and had effectively controlled the tillers, flowering, fresh-and dry weight in GR-ESU biotypes of 87.53%; 66.88%; 95.66%; and 95.92% respectively compared to glyphosate. The use of MSMA+diuron as a different mode of action herbicide is highly recommended to control GR-ESU biotypes at oil palm estate.",Related but unverifiable
s_669,Unverifiable,Summary of Key Points: Cost Optimization: Statistical methodologies and efficient modeling tools are essential for optimizing power delivery components and reducing costs .,"Modern computer servers require cutting edge technologies to meet their expected high performance. Among several relevant disciplines, power delivery (PD) is a key player in this regard. Efficient and reliable statistical methods to reduce cost while keeping adequate server's performance are highly demanded from the PD perspective. This paper addresses a feasible statistical methodology based on design of experiments (DoE) for evaluating platform's power delivery ingredients. Our methodology explores voltage regulator's intrinsic parameters, compensation networks, non-linear compensation parameters, and the amount of bulk capacitors. Our statistical approach aims at identifying those variables with the largest impact on computer server's PD performance, as well as optimizing them at the system level while achieving cost reduction.
[7]: Power systems modeling tools used to analyze static and dynamic characteristics usually rely on detailed and complex models, thus taking a long simulation time. Due to the acceleration of time to market of today's computing platforms, it is required to arrive at feasible solution options in a short amount of time to meet cost and time targets. Specifically, the areas of power conversion and power management traditionally rely on experimental verification and are lacking in computer design methodologies. In this paper, a modeling methodology based on fundamental building block models for power delivery systems is presented to address the aspects of energy efficiency optimization, area occupied by the power delivery solution and the cost associated with power conversion. © 2009 IEEE.",Related but unverifiable
s_1923,Entailment,"Disturbance Patterns in Boreal Forests: Impact on Ecosystem: Boreal forests show significant resilience to disturbances, with recovery processes influenced by factors such as soil conditions and species composition .","The ecological resilience of boreal forests is an important element of measuring forest ecosystem capacity recovered from a disturbance, and is sensitive to broad-scale factors (e.g., climate change, fire disturbance and human related impacts). Therefore, quantifying the effects of these factors is increasingly important for forest ecosystem management. In this study, we investigated the impacts of climate change, climate-induced fire regimes, and forest management schemes on forest ecological resilience using a forest landscape model in the boreal forests of the Great Xing'an Mountains, Northeastern China. First, we simulated the effects of the three studied variables on forest aboveground biomass, growing space occupied, age cohort structure, and the proportion of mid and late-seral species indicators by using the LANDIS PRO model. Second, we calculated ecological resilience based on these four selected indicators. We designed five simulated scenarios: Current fire only scenario, increased fire occurrence only scenario, climate change only scenario, climate-induced fire regime scenario, and climate-fire-management scenario. We analyzed ecological resilience over the five scenarios from 2000 to 2300. The results indicated that the initialized stand density and basal area information from the year 2000 adequately represented the real forest landscape of that year, and no significant difference was found between the simulated landscape of year 2010 and the forest inventory data of that year at the landscape scale. The simulated fire disturbance results were consistent with field inventory data in burned areas. Compared to the current fire regime scenario, forests where fire occurrence increased by 30% had an increase in ecological resilience of 12.4-43.2% at the landscape scale, whereas increasing fire occurrence by 200% would decrease the ecological resilience by 2.5-34.3% in all simulated periods. Under the low climate-induced fire regime scenario, the ecological resilience was 12.3-26.7% higher than that in the reference scenario across all simulated periods. Under the high climate-induced fire regime scenario, the ecological resilience decreased significantly by 30.3% and 53.1% in the short- and medium-terms at landscape scale, while increasing slightly by 3.8% in the long-term period compared to the reference scenario. Compared to no forest management scenario, ecological resilience was decreased by 5.8-32.4% under all harvesting and planting strategies for the low climate-induced fire regime scenario, and only the medium and high planting intensity scenarios visibly increased the ecological resilience (1.7-15.8%) under the high climate-induced fire regime scenario at the landscape scale. Results from our research provided insight into the future forest management and have implications for improving boreal forest sustainability.
[7]: Northern boreal forests are characterized by accumulation of accumulation of peat (e.g., known as paludification). The functioning of northern boreal forest species and their capacity to adapt to environmental changes appear to depend on soil conditions. Climate warming is expected to have particularly pronounced effects on paludified boreal ecosystems and can alter current forest species composition and adaptation by changing soil conditions such as moisture, temperature regimes, and soil respiration. In this paper, we review and synthesize results from various reported studies (i.e., 88 research articles cited hereafter) to assess the effects of climatic warming on soil conditions of paludified forests in North America. Predictions that global warming may increase the decomposition rate must be considered in combination with its impact on soil moisture, which appears to be a limiting factor. Local adaptation or acclimation to current climatic conditions is occurring in boreal forests, which is likely to be important for continued ecosystem stability in the context of climate change. The most commonly cited response of boreal forest species to global warming is a northward migration that tracks the climate and soil conditions (e.g., temperature and moisture) to which they are adapted. Yet, some constraints may influence this kind of adaptation, such as water availability, changes in fire regimes, decomposer adaptations, and the dynamic of peat accumulation. In this paper, as a study case, we examined an example of potential effects of climatic warming on future paludification changes in the eastern lowland region of Canada through three different combined hypothetical scenarios based on temperature and precipitation (e.g., unchanged, increase, or decrease). An increase scenario in precipitation will likely favor peat accumulation in boreal forest stands prone to paludification and facilitate forested peatland expansion into upland forest, while decreased or unchanged precipitation combined with an increase in temperature will probably favor succession of forested peatlands to upland boreal forests. Each of the three scenarios were discussed in this study, and consequent silvicultural treatment options were suggested for each scenario to cope with anticipated soil and species changes in the boreal forests. We concluded that, despite the fact boreal soils will not constrain adaptation of boreal forests, some consequences of climatic warming may reduce the ability of certain species to respond to natural disturbances such as pest and disease outbreaks, and extreme weather events.",Entailment
s_986,Contradiction,"Key Findings from Related Studies: Honey Ointment: Multivalent honey ointment improved microcirculation and healing rates in diabetic ulcers, showing significant reductions in ulcer surface area .","In addition to contemporary compression therapy, one of the therapeutic approaches is the use of a topical wound care agent. The goal of this pilot registry study is to evaluate the efficacy and safety of a uniquely designed ointment containing multivalent silver oxide (Ag4O4) in the healing of difficult diabetic or venous ulcerations. Patients who had ulcers resulting from chronic venous insufficiency or diabetes participated in this open-label, randomized registry study. All patients were evaluated by measuring both the area of the ulceration and microcirculatory parameters. 148 patients were included in the study and categorized into two main groups: venous ulcers and diabetic ulcers. Each main group was then randomized into two sub-groups: topical treatment with silver oxide ointment and the control group (standard cleaning and compression management methods, without silver ointment). All patients were treated with accepted cleaning and compression management. RESULTS. In subjects with venous ulcers: After 4 weeks, the silver treatment was more effective than the control group treatment: Skin PO2 was increased 2.1 times more than the control group (17.4% to 8.2%) and skin flux (RF) was improved 1.6 times more than the control group (-38.7% to -24.2%). The total surface area of the ulcer was significantly reduced in the silver treatment group by 1.9 times the control group (-88.7% to -46.9%). In addition, in the silver treatment group we observed complete closure of the ulceration in 42% of subjects compared to 22% in the control group (P=<0.05). In subjects with diabetic ulcers: after 4 weeks, the silver treatment was more effective than the control group treatment: Skin PO2 increased 2.6 times more than the control group (23.3% to 9.1%) and skin flux (RF) was significantly improved 4.3 times more than the control group(-26.7% to -6.2%). The total surface area of the ulcer was significantly reduced in the silver treatment group by 3.7 times the control group (-89.0% to -23.9%). In addition, in the silver treatment group we observed complete closure of the ulceration in 39% of subjects compared to 16% in the control group (P</=0.05). This pilot study provides observational data on the efficacy of local treatment of ulcers with a multivalent silver oxide containing ointment. The silver ointment improved microcirculation and the healing rate of all 78 patients that were treated with multivalent silver ointment and closed twice as many ulcers in 4 weeks compared to the control groups (40.7% silver treatment compared to 19.4% for the control). This study demonstrates the feasibility of this type of treatment and provides evidence of efficacy to plan larger randomized controlled studies. The large number of patients that were helped in this study demonstrates the efficacy of multivalent silver oxide topical ointment and its important role in ulcer therapy.",Entity error
s_497,Entailment,"Biological Inspiration for Battery Design: Bioinspired Nanomaterials: Bionanotechnology offers methods to design and synthesize nanomaterials for high-performance lithium-ion batteries (LIBs). Techniques such as biomineralization can precisely control the chemical composition and structure of electrode materials, enhancing their performance . This approach can be used to develop battery compartments with improved efficiency and stability.","Designing, fabricating, and integrating nanomaterials are key to transferring nanoscale science into applicable nanotechnology. Many nanomaterials including amorphous and crystal structures are synthesized via biomineralization in biological systems. Amongst various techniques, bionanotechnology is an effective strategy to manufacture a variety of sophisticated inorganic nanomaterials with precise control over their chemical composition, crystal structure, and shape by means of genetic engineering and natural bioassemblies. This provides opportunities to use renewable natural resources to develop high performance lithium-ion batteries (LIBs). For LIBs, reducing the sizes and dimensions of electrode materials can boost Li<sup>+</sup> ion and electron transfer in nanostructured electrodes. Recently, bionanotechnology has attracted great interest as a novel tool and approach, and a number of renewable biotemplate-based nanomaterials have been fabricated and used in LIBs. In this article, recent advances and mechanism studies in using bionanotechnology for high performance LIBs studies are thoroughly reviewed, covering two technical routes: (1) Designing and synthesizing composite cathodes, e.g. LiFePO<inf>4</inf>/C, Li<inf>3</inf>V<inf>2</inf>(PO<inf>4</inf>)<inf>3</inf>/C and LiMn<inf>2</inf>O<inf>4</inf>/C; and (2) designing and synthesizing composite anodes, e.g. NiO/C, Co<inf>3</inf>O<inf>4</inf>/C, MnO/C, α-Fe<inf>2</inf>O<inf>3</inf> and nano-Si. This review will hopefully stimulate more extensive and insightful studies on using bionanotechnology for developing high-performance LIBs. This journal is",Entailment
i_1682,Unverifiable,"Challenges in Monitoring Air Quality and Microplastic Concentrations: Correlation with Meteorological Parameters: The concentration of pollutants, including microplastics, is significantly influenced by meteorological parameters such as pressure and humidity. This adds another layer of complexity to monitoring efforts, as these factors must be continuously measured and accounted for in data analysis .","In recent years, the urban air pollution in our country has become more and more serious, which has aroused widespread concern of the general public and the scientific community. The micro air quality detector not only costs little, but also can real-time monitor the air quality of a certain area in a grid way, so it can be used as the supplement of national survey point data. Based on the canonical correlation analysis of the data, it is found that the concentration deviation of ""two dust and four gas"" is significantly related to the meteorological parameters, among which the concentration deviation of PM2.5, PM10, NO2 and O3 is greatly related to the factors of pressure and humidity, and it is also known that the correlation between concentration deviation and humidity is the largest. And the concentration deviation between self-built point and national survey point is modeled. The results of this study can provide a method for the completion of urban air quality data, and the research method can provide a reference for data mining.",Related but unverifiable
i_2284,Unverifiable,"Cats: Natural Selection: The domestication of cats was driven by natural selection rather than artificial selection. Behavioral reproductive isolation evolved as wildcats adapted to urban environments, leading to the domesticated cats we know today .","[6] It is clear from his published works that Charles Darwin considered domestication to be very useful in exploring and explaining mechanisms of evolutionary change. Not only did domestication occupy the introductory chapter of On the Origin of Species, but he revisited the topic in a two-volume treatise less than a decade later. In addition to drawing much of his information about heredity from studies of domesticated animals and plants, Darwin saw important parallels between the process of artificial selection by humans and natural selection by the environment. There was resistance to this analogy even among Darwin's contemporary supporters when it was proposed, and there also has been disagreement among historians and philosophers regarding the role that the analogy with artificial selection actually played in the discovery of natural selection. Regardless of these issues, the analogy between artificial and natural selection remains important in both research and education in evolution. In particular, the present article reviews ten lessons about evolution that can be drawn from the modern understanding of domestication and artificial selection. In the process, a basic overview is provided of current approaches and knowledge in this rapidly advancing field. [7] This paper explores the changing nature of companion animal-human relationships in Britain over the past 30 years. This period has seen rapid change in attitudes and practices towards companion animals, with notable advances in medical treatment, nutrition, and understanding of non-human animal behavior, as well as re-evaluations of the position of animals within the home. Based upon in-depth interviews with companion animal caretakers and professionals involved in the companion animal industry, we examined these changes in the United Kingdom. Major themes were identified: Humanization, Commercialization, Medicalization, Responsible Companionship, and Alternative Companionship. These changes have had largely positive effects on companion animal health and welfare, but also bring new expectations of the companion relationship, which humans and nonhuman animals may be unable or unwilling to fulfill. While dominant discourses of responsible companionship prevail, the process of change is ongoing and reflects emerging trends in human society towards diversification and alternative lifestyles.",Related but unverifiable
s_967,Entailment,"Clinical Observations: Polypharmacy in Elderly: In nursing homes, the use of multiple centrally active drugs, including antipsychotics and antidepressants, poses a risk for drug interactions and side effects. Although this study focuses on elderly patients, the findings are relevant for understanding the risks associated with psychotropic drugs in vulnerable populations, such as those in correctional facilities .","Introduction: Polypharmacy, together with its associated risks for those concerned is a known phenomenon in older patients. Furthermore, it is currently under discussion that the use of psychotropic drugs in residential nursing homes may significantly contribute to freedom-restraining measures (FRM). In this context an interdisciplinary study was conducted to address questions related to this subject. Methods: The study included all residents of old age and nursing homes who died between 2013 and 2015 and were subsequently the subject of an autopsy at the Institute of Forensic Medicine in Munich. None of these cases harbored the suspicion of a drug overdose. Records from the state prosecutor's office for each case as well as the macromorphological findings obtained during the autopsies were considered for data analysis. Urine samples were collected during the postmortem examinations and qualitatively analyzed for the presence of a large number of drugs and drugs of abuse by means of liquid chromatography coupled to time-of-flight mass spectrometry. The statistics software SPSS (IBM, version 23) was applied for a descriptive analysis of the data obtained. Results: Altogether 98 deceased residents of old age and nursing homes were included in the present study. Data obtained from the screening results of 95 of these cases showed that antipsychotic drugs (47.4%), antidepressants (30.5%), opioid analgesics (28.4%) and hypnotics/sedatives (20.0%) were among the ""top ten"" most frequently detected drug classes. The results showed that several deceased from the investigated group simultaneously received a combination of centrally active drugs. So-called PRISCUS substances could be detected in 25% of cases. Discussion: The results obtained during this study provide initial data on the spectrum of drugs that could be detected in deceased residents of old age and nursing homes. The number of substances detected is comparable to the prescription data obtained from health insurances. This retrospective study showed that older individuals simultaneously received a high number of centrally active prescription drugs. This poses an increased risk for both drug interactions and side effects, particularly for this vulnerable patient group. The combinations of drugs detected in the deceased persons in some cases did not appear to correspond to the guidelines of specialist societies. There were indications for the simultaneous prescription of several opioid analgesics or hypnotic drugs. The prescription rate for PRISCUS drugs in the study collective was twice as high as the general German population of the same age living in their own home. Future studies with toxicological results obtained from blood and hair samples from the investigated group as well as the analysis of the available drug regimens are envisaged and will be published at a later stage.",Entailment
s_1096,Unverifiable,"Limitations of ResUNet Model: Computational Load: The model can be computationally intensive, which may limit its real-time application in clinical settings .","Brain tumor segmentation is a critical step in MRI analysis, significantly impacting treatment decisions and prognostic evaluations. Deep learning, particularly with models like UNet and ResUNet, has emerged as a powerful approach, offering superior segmentation accuracy. The UNet model achieves a Dice score of 0.7 and a Jaccard index of 0.6, while the ResUNet model achieves a Dice score of 0.614444 and a Jaccard index of 0.815555. Despite advancements, challenges such as tumor variability, noise, and intensity variations persist, limiting the technology's potential. This study presents recent advancements in deep learning for brain tumor segmentation, covering background, methods (including UNet and ResUNet), achieved results, and concluding remarks. We discuss strengths, limitations, and ongoing research efforts, including multi-modal data integration and advanced network architectures, aiming to enhance segmentation precision and practical utility.",Related but unverifiable
i_2329,Contradiction,"Immune Response and Stress Reduction: Supplementation with Lactobacillus acidophilus has been shown to enhance the immune response and reduce stress in broilers, as indicated by lower heterophil to lymphocyte ratios and improved antibody titers. This improved health status can indirectly support better feed consumption and growth performance .","This study examines the effect of dietary supplementation with Lactobacillus acidophilus (LA) on the cholesterol levels, immune response, and productive performance of laying hens. A total of 216, 40-week-old, commercial Hy-Line brown chicken layers were randomly assigned into four treatment groups (18 birds × three replicates per group) and fed diet supplemented with 0 (control), 1 × 10<sup>9</sup>, 21 × 10<sup>9</sup>, and 31 × 10<sup>9</sup> colony forming units (CFUs) of Lactobacillus acidophilus (LA) per kg of feed for six consecutive weeks. Results show that plasma triglycerides, low-density lipoprotein (LDL) and total cholesterols became lesser, while high-density lipoprotein (HDL) cholesterol became higher in LA-supplemented groups compared to the control. In addition, a significant reduction occurred in the liver and egg yolk cholesterol by LA supplementation. Moreover, the immunological parameters including antibody titer against sheep red blood cells (SRBCs), phytohemagglutinin (PHA)-wattle swelling test, and T-& B-lymphocyte proliferation were enhanced in laying hens supplemented with LA compared to the control hens. While the heterophil to lymphocyte (H/L) ratio decreased with LA supplementation, indicating low stress conditions in the treated hens. These positive effects for LA were further reflected on the productive performance of laying hens and improved egg production, egg weight, egg mass, and feed efficiency. Our findings indicate that LA probiotic could be recommended in laying hens' diets for lowering egg yolk cholesterol with positive impacts on health and performance.
[7]: The purpose of the study was to investigate the effects of Lactobacillus plantarum HW1 on growth performance, intestinal immune response, barrier function, and cecal microflora of broilers with necrotic enteritis. In total, 180 one-day-old male Cobb 500 broilers were randomly allocated into three groups comprising a non-infected control (NC) group, basal diet + necrotic enteritis challenge (NE) group, and basal diet + 4 × 10<sup>6</sup> CFU/g Lactobacillus plantarum HW1 + necrotic enteritis challenge (HW1) group. Broilers in the NE and HW1 groups were orally given sporulated coccidian oocysts at day 14 and Clostridium perfringens from days 19 to 21. The results showed that the HW1 treatment increased (p < 0.05) the average daily gain of broilers from days 15 to 28 and from days 0 to 28 compared with the NE group. Moreover, the HW1 treatment decreased (p < 0.05) the oocysts per gram of excreta, intestinal lesion scores, ileal interleukin (IL) 1β and tumor necrosis factor α levels, and serum D-lactic acid and diamine oxidase levels, while increasing (p < 0.05) the ileal IL-10 level, thymus index, and protein expressions of ileal occludin and ZO-1. Additionally, the HW1 treatment decreased (p < 0.05) the jejunal and ileal villus height, jejunal villus height/crypt depth value, and cecal harmful bacterial counts (Clostridium perfringens, Salmonella, Escherichia coli, and Staphylococcus aureus), and increased (p < 0.05) the cecal Lactobacillus count. In conclusion, dietary supplementation with 4 × 10<sup>6</sup> CFU/g Lactobacillus plantarum HW1 could relieve necrotic enteritis infection-induced intestinal injury and improve growth performance in broilers by improving intestinal barrier function and regulating intestinal microbiology.",Entity error
i_1724,Contradiction,"Temperature also plays a crucial role. In a mesocosm experiment, a 2°C increase in water temperature led to a ninefold increase in pCO₂, which suggests that all shallow ponds will experience similar increases in carbon release regardless of their specific conditions .","There is an urgent need to understand the effect of climate warming on the carbon dynamics of lakes and ponds in order to assess contributions to global carbon budgets. Currently, we are unable to predict how the exchange of carbon gases (i.e. CO<inf>2</inf>) across the air-water boundary and organic carbon storage in the sediments will be altered with realistic warming scenarios downscaled from climatic models. Given the prevalence of shallow systems and tight atmospheric coupling, we conducted a mesocosm experiment to test the impacts of warming on CO<inf>2</inf> saturation in a shallow prairie pond. We outline and test three possible scenarios for the effect of warming on the CO<inf>2</inf> saturation of ponds, resulting in either an increase, decrease or no net effect for CO<inf>2</inf> saturation. We show that with approximately a two-degree (<sup>o</sup>C) increase in average water temperature, the pCO<inf>2</inf> of the warmed mesocosms was nine times greater than the ambient temperature mesocosms by the end of the 5-week experiment. Changes in water colour (a measure of dissolved organic carbon) in warmed systems indicate that decomposition of organic matter in the sediments and water column was the main contributor to the increase in pCO<inf>2</inf> in the warmed mesocosms. Our results show that with warming, the release of CO<inf>2</inf> from shallow ponds to the atmosphere will increase and carbon storage in the sediments will decrease, altering the current functioning of shallow prairie ponds and influencing the contribution of ponds to the global carbon cycle. © 2010 The Author(s).",Missing information
s_2114,Unverifiable,"Natural Filtration Methods: Aerobic Filters for Dairy Soiled Water (DSW): Description: Effective for treating DSW, allowing the final effluent to be reused on farms. Process: Filters with woodchip or sand media reduce chemical oxygen demand (COD), suspended solids (SS), total nitrogen (TN), and other contaminants. Woodchip filters are more effective and less prone to clogging compared to sand filters .","[14] The identification of key foulants and the provision of early warning of high fouling events for drinking water treatment membrane processes is crucial for the development of effective countermeasures to membrane fouling, such as pretreatment. Principal foulants include organic, colloidal and particulate matter present in the membrane feed water. In this research, principal component analysis (PCA) of fluorescence excitation-emission matrices (EEMs) was identified as a viable tool for monitoring the performance of pre-treatment stages (in this case biological filtration), as well as ultrafiltration (UF) and nanofiltration (NF) membrane systems. In addition, fluorescence EEM-based principal component (PC) score plots, generated using the fluorescence EEMs obtained after just 1 hour of UF or NF operation, could be related to high fouling events likely caused by elevated levels of particulate/colloid-like material in the biofilter effluents. The fluorescence EEM-based PCA approach presented here is sensitive enough to be used at low organic carbon levels and has potential as an early detection method to identify high fouling events, allowing appropriate operational countermeasures to be taken. © 2009 Elsevier Ltd. All rights reserved.",Unrelated and unverifiable
i_2271,Contradiction,"Heat stress during grain filling also increased the gelatinization temperature and retrogradation enthalpy, suggesting that higher temperatures can alter the hydration dynamics of starch, and it is possible that these changes may enhance the nutritional quality of the starch in waxy maize .","BACKGROUND: Waxy maize (Zea mays L. sinensis Kulesh) suffers short-term exposure to high temperature during grain filling in southern China. The effects of such exposure are poorly understood. RESULTS: Starch granule size was increased by 5 days' short-term heat stress (35.0 °C) and the increase was higher when the stress was introduced early. Heat stress increased the iodine binding capacity of starches and no difference was observed among the three stages. Starch relative crystallinity was increased and swelling power was decreased only when heat stress was introduced early. Heat stress also increased the pasting viscosity, and this effect became more pronounced with later applications of stress. Heat stress reduced starch gelatinization enthalpy, and the reduction gradually increased with later exposures. Heat stress increased the gelatinization temperature and retrogradation enthalpy and percentage of the samples, with the increases being largest with earlier introduction of high temperature. CONCLUSION: Heat stress increased the pasting viscosities and retrogradation percentage of starch by causing change in granule size, amylopectin chain length distribution and crystallinity, and the effects observed were more severe with earlier introduction of heat stress after pollination. © 2017 Society of Chemical Industry.",Misrepresentation
s_2125,Contradiction,"Invasive Plant Species Several invasive plant species have been documented in Indonesia, posing significant threats to local biodiversity and ecosystems: Acacia nilotica: Widely recognized for its aggressive spread and severe impact on native flora, which is likely to lead to the extinction of several native species .","An alien species, which becomes established in natural or semi-natural ecosystems or habitats, is an agent of change and threatens native biological diversity. The Convention on Biological Diversity (CBD) declared in 1992, in which the issue on invasive alien species was raised, was ratified by the Indonesian Government in 1994. Protecting our biodiversity will be out moral obligation to comply with CBD. Inventory on the invasive alien plant species in Indonesia should also be done by field surveys aside from the data collected from the references and herbarium specimens. Field studies should be carried out to get complete Figures, to identify the new ones, to determine their distributions, to plan their management including prevention to spread, containment and movement or mitigate their impact to environment. Sometimes it is difficult in determining whether the plants are aliens or not. Cooperation with botanists and taxonomists in other parts of the world is necessary. There are some species of invasive alien plant in Indonesia, which have to be watched fortheir aggressiveness i.e. Acasia nilotica (L.) Willd. ex Del., Eupatorium sordidum Less., Jatropa gossipifolia L., Mikania micrantha Kunth, Mimosa pigra L., Opuntia sp., and Piper aduncum L. have to be watch for their aggressiveness. Notes on some important invasive alien plant species in Indonesia are discussed.",Misrepresentation
i_283,Entailment,"The proposed method can estimate both 2D and 3D poses, making it versatile for various applications, including action recognition and human-computer interaction  .","This paper proposes a real-time human pose recognition method based on bidirectional long short-term memory (LSTM). OpenPose is utilized as the human pose estimation module to obtain two-dimensional joint point data of the human body. According to the condition of missing data, it can judge whether the human body is in the occlusion state. For non-occlusion cases, a classifier is formulated by the bidirectional LSTM, and the initial two-dimensional joint point information is sent to the classifier for human pose recognition. For the occlusion state, the depth camera internal parameters are used for 3D mapping. The torso vector and joint angle are constructed. The aforementioned high-dimension features are processed using principal component analysis and sent to the classifier for human pose recognition. The KTH dataset and a laboratory dataset containing five human poses are utilized to evaluate the proposed method. Under non-occlusion conditions, experimental results show that the accuracy values of the proposed algorithm are 2.63% and 1.08% higher than those of traditional models and deep learning models. Under occlusion conditions, the accuracy rate is improved by 5.6% compared to the traditional model. Human pose recognition in complex environments is achieved.
[3]: Abstract: Human pose estimation (PE, tracking body pose on-the-go) is a computer vision-based technology that identifies and controls specific points on the human body. These points represent our joints and special points over the body determining the sizes, distances, angle of flexion, and type of the motion. Knowing this in a specific exercise is the basis of work for rehabilitation and physiotherapy, fitness and self-coaching, augmented reality, animation and gaming, robot management, surveillance and human activity analysis. Implementing such capabilities may use special suits or sensor arrays to achieve the best result, but massive use of PE is related to devices that many users own: namely smartphones, smartwatches, and earbuds. The body pose estimation system starts with capturing the initial data. In dealing with motion detection, it is necessary to analyze a sequence of images rather than a still photo. Different software modules are responsible for tracking 2D key points, creating a body representation, and converting it into a 3D space. Action recognition on the other hand is a way to analyze the sequence of estimated pose data with the aim to categorize sequence under the classes. It is widely used various fields. One of the widely known use cases is analysis and detection of potential attacks of illegal action using video from the surveillance cameras. Another use case involves analysis of the sequence of pose with the aim of creating a virtual coaching environment. Specifically, our research will target this challenging issue and aim to create this environment for mobile devices. We will describe some of the solutions that are suitable for effectively pose estimation and action recognition on mobile devices. We will show how lightweight models based on convolution neural networks can be used to efficiently solve pose estimation issue and address action recognition problem with the dynamic time warping algorithm.",Entailment
s_1679,Entailment,"CRISPR technology has been used to develop rice varieties resistant to major pests, which completely eliminates the need for pesticides and guarantees sustainable agriculture .","Adopting genome editing with the trait of pest resistance contributes to sustainable development by reducing pesticide use. Developed by Clustered Regularly Interspaced Short Palindromic Repeats (CRISPR) technology, CRISPR rice is resistant to two of its most destructive insect pests. However, there exists a trade-off between pest resistance and lower potential yield. In the presence of uncertainty of pest severity, adopting CRISPR rice demonstrates positive environmental benefits at its optimal planting ratio, estimated based on a microeconomic model extended with environmental externalities of rice cultivation. We estimate the optimal planting ratio to be 37%, with the environmental benefit of co-planting CRISPR rice to be 560 million US dollars annually in China. The environmental benefit accounts for 4–22% of the total value of co-planting CRISPR rice in the Monte Carlo simulations. Regional heterogeneity regarding optimal planting ratio and environmental benefit is studied for 12 major rice-cultivating provinces in China. We conclude with policy implications that policymakers need to consider the vast environmental benefit of CRISPR rice adoption to have a more comprehensive view of its economic and environmental market potential, contributing to the heated debate on regulating CRISPR technology in China and worldwide.",Entailment
i_1357,Unverifiable,"In summary, blood transfusions play a vital role in managing both acute and chronic complications of thalassemia, improving patient outcomes and quality of life. However, the risks associated with transfusions, such as iron overload and alloimmunization, require careful management and ongoing research to optimize treatment protocols .","Blood transfusion remains an important therapeutic intervention in patients with sickle cell disease (SCD), aiming to both increase the oxygen carrying capacity of blood and to reduce the complications of vaso-occlusion. Simple, manual exchange and automated exchange can be effective in reducing the acute and chronic complications of SCD, and the advantages and disadvantages of each methodology mean they all have a role in different situations. Evidence for the role of emergency transfusion in the management of the acute complications of SCD, including acute pain and acute chest syndrome, comes from observational data. Several important randomized controlled trials have shown the efficacy of transfusion in primary and secondary stroke prevention in patients with SCD but, outside these areas, clinical practice lacks a clear evidence base. Evidence for the role of long-term transfusion in the prevention of the non-neurologic chronic complications of SCD comes from analysis of secondary outcomes of these randomized trials and from observational data. In view of the paucity of data, the risks and benefits of transfusion should be fully discussed with patients/families before a long-term transfusion program is commenced. Evidence is only available for the role of preoperative transfusion or for prophylactic transfusion through pregnancy in certain situations, and the role of transfusions outside these situations is discussed. Questions about when and how to transfuse in SCD remain and will need further randomized trials to provide answers.
[2]: The therapeutic management of sickle cell disease is based on several strategies, in which red blood cell transfusion plays an essential role in acute complications such as vaso-occlusive crisis, acute chest syndrome and stroke. However, it is important to weigh the benefit/risk before transfusion in children with sickle cell disease and not to rely solely on the value of hemoglobin. Indeed, it is important to remember that a negative antibody screen as well as a negative serological crossmatch test do not totally eliminate alloimmunisation or the risk of post-transfusion haemolysis. Sickle cell patients demonstrate multiple immuno-haematological features: variant phenotypes (especially in the Rh and MNS systems), rare blood groups, allo- and auto-immunisation favored because of the inflammatory state. The presence of an alloimmunisation can lead to a significant delay to obtain compatible red blood cell units, a supply difficulty or even a genuine blood transfusion deadlock. About 30 % of the requests for rare blood in France concerns sickle cell patients. Any vaso-occlusive crisis occurring within 3 to 15 days after a transfusion should be suspected to be a delayed haemolytic post-transfusion reaction; whenever necessary, the child should be referred to a reference center and any further transfusions should be avoided. The so-called hyperhaemolysis syndrome, corresponding to a major delayed haemolysis with concomitant destruction of autologous red blood cells, constitutes a major complication of the transfusion and may be potentially fatal. It is essential to educate patients and physicians on the recognition of the clinical signs of delayed haemolytic post-transfusion reactions, in order to rapidly implement measures to limit their immediate effects and avoid their occurrence in case of future transfusion.
[3]: Red cell transfusion represents one of the cornerstones of the chronic management of sickle cell disease, as well as its acute complications. Automated red cell exchange can rapidly lower the number of circulating sickle erythrocytes, without causing iron overload. Here, we describe our experience, having offered this intervention since 2011. A transient reduction in the platelet count by 61% was observed after the procedure. This was not associated with any haemorrhagic complications. Despite exposure to large volumes of blood, the alloimmunisation rate was only 0.027/100 units of red cells. The absence of any iron loading was confirmed by serial Ferriscans, performed over a number of years. However, patients with advanced chronic kidney disease showed evidence of iron loading due to reduced innate haemopoiesis and were subsequently switched to simple transfusions. A total of 59% of patients were on regular automated red cell exchange with a history of recurrent painful crises. A total of 77% responded clinically, as evidenced by at least a 25% reduction in their emergency hospital attendance for pain management. The clinical response was gradual and increased the longer patients stayed on the program. The earliest sign of clinical response was a reduction in the length of stay when these patients were hospitalised, indicating that a reduction in the severity of crises precedes the reduction in their frequency. Automated red cell exchange also appeared to be beneficial for patients with recurrent leg ulcers and severe, drug resistant stuttering priapism, while patients with pulmonary hypertension showed a dramatic improvement in their symptoms as well as echocardiographic parameters.
[9]: Blood transfusion plays a prominent role in the management of patients with sickle cell disease (SCD), but causes significant iron overload. As transfusions are used to treat the severe complications of SCD, it remains difficult to distinguish whether organ damage is a consequence of iron overload or is due to the complications treated by transfusion. Better management has resulted in increased survival, but prolonged exposure to iron puts SCD patients at greater risk for iron-related complications that should be treated. The success of chelation therapy is dominated by patient adherence to prescribed treatment; thus, adjustment of drug regimens to increase adherence to treatment is critical. This review will discuss the current biology of iron homeostasis in patients with SCD and how this informs our clinical approach to treatment. We will present the clinical approach to treatment of iron overload at our centre using serial assessment of organ iron by magnetic resonance imaging.",Related but unverifiable
i_1792,Unverifiable,Cost-Benefit Analysis (CBA) is not an effective method to assess the economic viability of CE strategies .,"Increasing interests of circular economy (CE) principles applied into construction projects has led to the development of assessment methods for their justification. The use of smaller quantities of construction materials, materials of higher quality and durability, and recycling of construction waste are all requirements of today's aspiration for a circular economy, but it is necessary to assess their environmental and economic sustainability. This paper presents a review of the current assessment tools of circular economy projects applied to the construction industry, such as LCA, LCC and CBA. The main objectives of this study were to provide a categorization of CE concepts applied in the construction industry (CI) and to review assessment methods used for evaluating CE projects in CI. This paper selected and reviewed 96 published papers and classified them into one of five aspects of CE highlighted in this study: waste management, reducing the impact on the environment, material & product design, building design, and other. The results showed that the use of assessment methods in CE projects has increased in the recent years as well that an LCA was by far the most used assessment method and waste management the most common aspect of CE in CI.",Related but unverifiable
s_1099,Contradiction,"Traditional methods like active contours and deformable models are largely ineffective in addressing these issues, as they fail to produce satisfactory results in most cases .","Segmentation of ultrasound images is a challenging task due to the lower contrast and the speckle noise. Active contour is one of the most widely used techniques for ultrasound image segmentation. This method has drawbacks such as the predefined initial curve position and the number of contour points to be considered. A new active contour segmentation for extracting the intima media layer and plaque in the Common Carotid Artery (CCA) ultrasound images is presented in this paper. This paper has proposed a fuzzy weighted graph based active contour segmentation technique to overcome all these drawbacks. The proposed method is used for segmenting Intima-Media Thickness (IMT) and plaque in common carotid artery B-mode ultrasound images to assess the risk of stroke in the human subject under investigation. Using canny edge detection and connected component analysis methods, the initial contour was determined and applied as input to the proposed active contour segmentation algorithm. The proposed algorithm was compared with five conventional methods. Experimental results prove that the proposed approach has produced better results than traditional methods. The overall probability of error achieved by the proposed algorithm was 5.28%, which was very less compared to other conventional methods.
[5]: This paper presents a new deformable model based on level sets for medical image segmentation which plays a pivotal role in medical diagnosis. The current popular Image segmentation deformable models such as Snakes, Geometric Active Contours, Gradient Vector Flow, Level sets and Variational Level sets have a limitation that the convergence of the contour towards the object boundary is slow and hence not suitable for real time medical diagnosis. To counter this limitation we present an improved image segmentation algorithm which is computationally efficient and also the proximity of the contour towards the object is higher compared to existing algorithms. A new speed term is introduced in the evolution step of variational level set in order to speed up the convergence process. The variational level sets in images with intensity inhomogeneity, tend to be slower and prone to leakage of contour outside the object boundary. This is due to the selection of gradient information for the termination of convergence process. However, this limitation is overcome in the proposed algorithm by modifying the edge indicator function embedded with the speed term that optimizes the effective distance of the attractive force. Experimental results are provided using real time medical images. Comparative tables and graphs highlighting the performance of various deformable models are also presented.",Misrepresentation
i_2210,Unverifiable,"Advantages of Sponges in Benthic Ecosystems: Filter Feeding and Water Quality. As active suspension feeders, sponges filter large volumes of water, removing picoplankton and other particles, which helps maintain water quality and clarity .","Benthic-pelagic coupling and the role of bottom-up versus top-down processes are recognized as having a major impact on the structure of marine communities. While the roles of bottom-up processes are better appreciated they are still viewed as principally affecting the outcome of top-down processes. Sponges on coral reefs are important members of the benthic community and provide a critically important functional linkage between water-column productivity and the benthos. As active suspension feeders sponges utilize the abundant autotrophic and heterotrophic picoplankton in the water column. As a result sponges across the Caribbean basin exhibit a consistent and significant pattern of greater biomass, tube extension rate, and species numbers with increasing depth. Likewise, the abundance of their food supply also increases along a depth gradient. Using experimental manipulations it has recently been reported that predation is the primary determinant of sponge community structure. Here we provide data showing that the size and growth of the sponge Callyspongia vaginalis are significantly affected by food availability. Sponges increased in size and tube extension rate with increasing depth down to 46 m, while simultaneously exposed to the full range of potential spongivores at all depths. Additionally, we point out important flaws in the experimental design used to demonstrate the role of predation and suggest that a resolution of this important question will require well-controlled, multi-factorial experiments to examine the independent and interactive effects of predation and food abundance on the ecology of sponges. © 2013 Lesser, Slattery.
[3]: Sponges, porous filter-feeding organisms consisting of vast canal systems, provide unique substrates for diverse symbiotic organisms. The Spongia (Spongia) sp. massive sponge is obligately inhabited by the host-specific endosymbiotic bivalve Vulsella vulsella, which benefits from this symbiosis by receiving protection from predators. However, whether the host sponge gains any benefit from this association is unclear. Considering that the bivalves exhale filtered water into the sponge body rather than the ambient environment, the sponge is hypothesized to utilize water exhaled by the bivalves to circulate water around its body more efficiently. We tested this hypothesis by observing the sponge aquiferous structure and comparing the pumping rates of sponges and bivalves. Observations of water currents and the sponge aquiferous structure revealed that the sponge had a unique canal system enabling it to inhale water exhaled from bivalves, indicating that the host sponge adapted morphologically to receive water from the bivalves. In addition, the volume of water circulating in the sponge body was dramatically increased by the water exhaled from bivalves. Therefore, this spongebivalve association can be regarded as a novel mutualism in which two filter-feeding symbionts promote mutual filtering rates. This symbiotic association should be called a ""filtering mutualism"".",Related but unverifiable
i_185,Unverifiable,"###  ** Cosine Similarity** Cosine Similarity is a metric used to measure how similar two vectors are, regardless of their magnitude. It calculates the cosine of the angle between two vectors, providing a similarity score between -1 and 0.5, where 1 indicates identical vectors, 0 indicates orthogonality, and -1 indicates completely opposite vectors .","We propose a method for automatic recognition of textual entailment based on word sense disambiguation using cosine similarity proposed by Abdalgader and Skabar. This algorithm finds semantic similarity of the sentence pairs- entailing text and entailed text. Both the hypothesis and text are converted into vectors using Jiang and Conrath similarity measure and cosine similarity is computed. Based on the cosine similarity score, a threshold is applied and the sentence pairs are classified into entailment and no entailment. The accuracy of the proposed scheme is better or comparable to many of the state of the art schemes.
[3]: In this paper, we propose a similarity measurement method based on the Hellinger distance and square-root cosine. Then use Hellinger distance as the distance metric for document clustering and a new square-root cosine similarity for query information retrieval. This new similarity/distance also bridges between traditional tf-idf weighting to binary weighting in vector space model. Finally, we conduct a comparison on performance between this method and the one based on Euclidean distance and cosine similarity. And from the results, we clearly observe that the precision and recall are improved by using the sqrt-cos similarity. © 2012 IEEE.",Related but unverifiable
i_1574,Contradiction,"Innovative Approaches and Future Directions: Sustainable transport strategies should consider broader systems in which transportation activities are embedded. Innovations like Electric Mobility, City Logistics, Intelligent System Management, and Livability are emerging areas that could support a more systems-oriented approach to sustainable transport .","This paper examines the concept and implementation of sustainable transport. It traces efforts to define and operationalize the notion of sustainable transport in the urban context, noting that these efforts have tended to fall into two broad clusters of work: those that envision sustainable transportation as a policy pathway, and those that envision it as a policy end-point. The authors argue that to be successful, sustainable transport policy must avoid the common transportation policy pitfall of ignoring the larger systems in which transportation activity is embedded. The goal of sustainable transportation may be better served by a number of the organic innovations in transportation practice that are occurring in the field. The authors identify four emerging areas of innovation: New Mobility, City Logistics, Intelligent System Management, and Livability. Finally, the authors discuss the extent to which these innovations represent a more systems-oriented approach, and the institutional challenges inherent in these proposals.",Entity error
i_1696,Unverifiable,"Chronic exposure to EDCs can result in significant reproductive and developmental issues, such as decreased egg production and altered hormone levels in fish .","Synthetic progestins contaminate the aquatic ecosystem, and may cause adverse health effects on aquatic organisms. Megestrol acetate (MTA) is present in the aquatic environment, but its possible effects on fish reproduction are unknown. In the present study, we investigated the endocrine disruption and impact of MTA on fish reproduction. After a pre-exposure period of 14 days, reproductively mature zebrafish (Danio rerio) (F0) were exposed to MTA at environmental concentrations (33, 100, 333, and 666. ng/L) for 21 days. Egg production was decreased in F0 fish exposed to MTA, with a significant decrease at 666. ng/L. The exposure significantly decreased the circulating concentrations of estradiol (E2) and testosterone (T) in female fish or 11-keto testosterone (11-KT) in male fish. MTA exposure significantly downregulated the transcription of certain genes along the hypothalamic-pituitary-gonadal (HPG) axis. MTA did not affect early embryonic development or hatching success in the F1 generation. The present study showed that MTA is a potent endocrine disruptor in fish, and short-term exposure to MTA could significantly affect reproduction in fish and negatively impact the fish population. © 2014 Elsevier B.V.",Related but unverifiable
s_2169,Entailment,"Performance-Based Indicators: These measure outcomes directly without prescribing methods, suggesting that they inherently lead to better sustainability practices. An example is the Bonsucro Production Standard for the sugarcane sector, which is often assumed to guarantee dynamic standards and adaptive management .","The rise of global sustainability standards has led to an energetic discussion about their consequences and outcomes. Almost all standards today are built around 'technology-based' indicators, which prescribe certain practices assumed to lead to sustainable outcomes. However we are now seeing the emergence of the first 'performance-based' metric sustainability indicators, directly measuring outcomes without prescribing particular methods to reach them. This paper presents the example of the Bonsucro Production Standard, a sustainability standard for the sugarcane sector, and identifies five relevant areas opened up by performance-based metrics. These are flexibility in application, provision of information, the creation of dynamic standards, the enabling of adaptive management, and the harmonisation of policy instruments. Opportunities and challenges within each area are discussed in relation to a wide literature from a variety of disciplines, informing opportunities for standard-systems to explore within their own activities, as well as an agenda for future research.",Entailment
i_1408,Unverifiable,"Nutritional Deficiencies and Skin Lesions: Vitamin B12 Deficiency: Also known as cobalamin deficiency, vitamin B12 deficiency can cause dermatitis, neurological issues, and anemia. Skin lesions are a hallmark of this condition and can be severe in the context of malnutrition following bariatric surgery .","Introduction: Bariatric surgery is a very effective treatment for obesity. After gastric bypass, micronutrient deficiencies frequently occur which can have dramatic consequences. Case report: We report the case of a 55-year-old woman who was admitted for psychomotor retardation, bilateral leg pitting edema and psoriasis-like rash that had been ongoing for 3 months. Pancytopenia, encephalopathy and heart failure rapidly occurred leading to multiorgan dysfunction syndrome and death. We retrospectively identified severe selenium deficiency with possible secondary cardiomyopathy, niacin deficiency resulting in pellagrous encephalopathy with skin lesions and gelatinous transformation of bone marrow. Conclusion: Micronutrient deficiency should systematically be assessed when new symptoms occur in a patient with a history of bariatric surgery. Selenium deficiency should be considered in the presence of any heart failure in this context.",Related but unverifiable
s_972,Entailment,"Relevant Findings: General VR Training in Healthcare: VR has been widely used for training healthcare providers in various settings, including isolation wards and emergency scenarios. It has been found to be convenient and valuable, suggesting that it could completely replace in-person training, despite some participants still expressing a preference for it .","Healthcare providers without working experience in isolation wards experience enormous challenges. Traditional ward orientation is constrained by space, time, and even infection risk in particular periods (eg, the coronavirus disease 2019 pandemic). Virtual reality has been used widely, but rarely in wards. This study aimed to explore the experience of utilizing virtual reality for isolation ward training among nurses. In this study, nurses completed virtual reality training via an online platform and were then trained in isolation wards, after which their perceptions were explored by questionnaire and interviews. A total of 1868 participants completed the training. Most participants thought the preservice training was important and believed the virtual reality experience was consistent with the in-person training. Virtual reality was found not only to be convenient and valuable for training but also to have the benefits of occupational protection. However, whereas 50.48% of participants wanted to learn the ward via virtual reality, 87.21% of participants wanted to learn via in-person training before working in the wards. As a substitute for in-person training, virtual reality is a feasible and practical instrument to provide preservice training in particular periods. However, there is room for improvement due to general discomfort and technological problems.",Entailment
s_2157,Contradiction,"The development of 3D-printed materials for CubeSats, particularly those that increase heat during disintegration, is unlikely to contribute to reducing space debris .","The increasing number of commercial, technological and scientific missions for CubeSats poses several concerns about the topic of space junk and debris mitigation. As no regulation is currently in place, innovative solutions are needed to mitigate the impact that Low Earth Orbit objects can have during uncontrolled re-entry and the associated potential events of surface collision. We investigated the requirements, in terms of materials selection, for the development of a 3D-printed structural bus able to withstand loads during launch and in-orbit operations, with the objectives to be as light as possible and requiring the least amount of heat for demise during atmospheric re-entry. The selection indicated magnesium alloys as the best candidates to improve the reference material, aluminium 6061 T6, resulting in both mass-reduction and improved demisability. We also analysed how the relative importance of these two objectives can modify the selection of materials: if minimizing the heat to disintegration were valued more highly than lightness, for example, the new best candidates would become tin alloys. Our analysis, furthermore, suggested the importance of Liquid Crystal Polymer as the sole plastic material approaching the performance of the best metal choices. This contribution, thus, provides novel insight in the field of 3D-printed materials for the fast-growing CubeSat segment, complying with the debris mitigation initiatives promoted by space agencies and institutions.",Opposite meaning
s_1707,Entailment,"Application: Suitable for routine analysis of sugar content in horticultural products, including strawberries .","The determination and quantification of sugars is important for quality control and assurance of horticultural produce. This review discusses analytical methods for determination of sugars and sweetness of fresh and processed fruit and vegetables, including the use of destructive and non-destructive instrumental techniques to evaluate sugar composition and characterize taste profile or sweetness. From the standard hand-held refractometer to the hydrometer, electronic tongue and high pressure liquid chromatography (HPLC) equipped with different detectors, a wide range of devices have been used to determine sugar composition and sweetness of many fruit and vegetable products. Although chromatographic techniques are very accurate and useful, they require extensive sample preparation based on solvent extraction and hence are generally time-consuming and expensive. Visible to near infrared spectroscopy (vis/NIRS) has been proposed as an interesting alternative to traditional methods due to its rapidity, simplicity, cost effectiveness and potential for routine analysis if proper calibration and validation steps were developed. Current trends favour analytical methods that are simple to use, quick and non-destructive. The prospects for using emerging technologies such as hyperspectral imaging and nuclear magnetic resonance for non-destructive assessment of sugar content and sweetness of fresh and processed horticultural food products are also discussed.",Entailment
s_793,Contradiction,"5. Satellite and Remote Sensing: Optical Remote Sensing: Satellite-acquired optical remote sensing data can rapidly survey road conditions over large areas, identifying segments that require repair or inspection .","Analysis of satellite-acquired synthetic aperture radar (SAR) data provides a way to rapidly survey road conditions over large areas. This capability could be useful for identifying road segments that potentially require repair or at least onsite inspection of their condition due to changes in vehicular traffic associated with change in land use. We conducted a feasibility study focused on urban roads near the Southwest Research Institute (SwRI) campus in San Antonio, Texas. The roads near SwRI were affected by heavy truck traffic, they were easily inspected, and the age and construction of the pavement was known. TerraSAR-X (TSX) SpotLight (ST) satellite data were used to correlate radar backscattering response to pavement age and condition. Our preliminary results indicate that TSX radar imagery can be useful for detecting changes in pavement type, damage to pavement, such as cracking and scaling, and, occasionally, severe rutting. In addition, multitemporal interferometric analysis showed patches of settlement along two roads south of the SwRI campus. Further development of an automated approach to detect degradation of roads could allow transportation departments to prioritize inspection and repair efforts. The techniques also could be used to detect surreptitious heavy truck traffic in areas where direct inspection is not possible.",Entity error
s_1819,Contradiction,Emission Factors for Particulate Matter from Diesel Vehicles: General Emission Factors: Heavy-Duty Vehicles (HDVs): Emission factors for organic carbon (OC) in PM2.5 are reported to be 528 mg/kg of fuel consumed .,"This study reports emission of organic particulate matter by light-duty vehicles (LDVs) and heavy-duty vehicles (HDVs) in the city of São Paulo, Brazil, where vehicles run on three different fuel types: gasoline with 25 % ethanol (called gasohol, E25), hydrated ethanol (E100), and diesel (with 5 % biodiesel). The experiments were performed at two tunnels: Jânio Quadros (TJQ), where 99 % of the vehicles are LDVs, and RodoAnel Mário Covas (TRA), where up to 30 % of the fleet are HDVs. Fine particulate matter (PM<inf>2.5</inf>) samples were collected on quartz filters in May and July 2011 at TJQ and TRA, respectively. The samples were analyzed by thermal-desorption proton-transfer-reaction mass spectrometry (TD-PTR-MS) and by thermal-optical transmittance (TOT). Emission factors (EFs) for organic aerosol (OA) and organic carbon (OC) were calculated for the HDV and the LDV fleet. We found that HDVs emitted more PM<inf>2.5</inf> than LDVs, with OC EFs of 108 and 523 mg kg<sup>-1</sup> burned fuel for LDVs and HDVs, respectively. More than 700 ions were identified by TD-PTR-MS and the EF profiles obtained from HDVs and LDVs exhibited distinct features. Unique organic tracers for gasoline, biodiesel, and tire wear have been tentatively identified. nitrogen-containing compounds contributed around 20 % to the EF values for both types of vehicles, possibly associated with incomplete fuel burning or fast secondary production. Additionally, 70 and 65 % of the emitted mass (i.e. the OA) originates from oxygenated compounds from LDVs and HDVs, respectively. This may be a consequence of the high oxygen content of the fuel. On the other hand, additional oxygenation may occur during fuel combustion. The high fractions of nitrogen- and oxygen-containing compounds show that chemical processing close to the engine/tailpipe region is an important factor influencing primary OA emission. The thermal-desorption analysis showed that HDVs emitted compounds with higher volatility, and with mainly oxygenated and longer chain hydrocarbons than LDVs.",Numeric error
i_2138,Contradiction,"3. **Pathogen-Specific Responses**: Different pathogens elicit varied responses in wheat. For instance, the resistance to Fusarium graminearum is solely dependent on the accumulation of specific metabolites and the expression of defense-related genes, which are not influenced by environmental conditions or genetic factors .","Fusarium head blight (FHB), caused by Fusarium graminearum, is one of the most devastating diseases of wheat and barley. Resistance to FHB is highly complex and quantitative in nature, and is most often classified as resistance to spikelet infection and resistance to spread of pathogen through the rachis. In the present study, a resistant (CI9831) and a susceptible (H106-371) two-row barley genotypes, with contrasting levels of spikelet resistance to FHB, pathogen or mock-inoculated, were profiled for metabolites based on liquid chromatography and high resolution mass spectrometry. The key resistance-related (RR) metabolites belonging to fatty acids, phenylpropanoids, flavonoids and terpenoid biosynthetic pathways were identified. The free fatty acids (FFAs) linoleic and palmitic acids were among the highest fold change RR induced (RRI) metabolites. These FFAs are deposited as cutin monomers and oligomers to reinforce the cuticle, which acts as a barrier to pathogen entry. Quantitative real-time PCR studies revealed higher expressions of KAS2, CYP86A2, CYP89A2, LACS2 and WAX INDUCER1 (HvWIN1) transcription factor in the pathogen-inoculated resistant genotype than in the susceptible genotype. Knockdown of HvWIN1 by virus-induced genes silencing (VIGS) in resistant genotype upon pathogen inoculation increased the disease severity and fungal biomass, and decreased the abundance of FFAs like linoleic and palmitic acids. Notably, the expression of CYP86A2, CYP89A2 and LAC2 genes was also suppressed, proving the link of HvWIN1 in regulating these genes in cuticle biosynthesis as a defense response.
[6]: Head blight of wheat in the United States is caused primarily by the deoxynivalenol (DON)-producing chemotype of Fusarium graminearum. However, the discovery of the nivalenol (NIV) chemotype of F. graminearum in Louisiana and Arkansas necessitates having resistance in wheat to both chemotypes. The objectives of this research were to quantify resistance of selected winter wheat lines to initial infection and pathogen spread within spikes, to determine whether wheat lines selected for resistance to the DON chemotype also have resistance to the NIV chemotype, and to improve the methods for quantifying resistance to initial infection. A susceptible check (Coker 9835) and 15 winter wheat lines, which are adapted to the southeastern United States and possess diverse sources of head blight resistance, were evaluated for head blight resistance in a series of greenhouse and growthchamber experiments. Significant levels of resistance to both initial infection and spread within a spike were found among the lines, and lines with resistance to isolates of the DON chemotype had even higher levels of resistance to isolates of the NIV chemotype. Quantifying resistance to initial infection was improved by standardizing the inoculum and environmental conditions. Additional information related to resistance to spread within a spike was obtained by calculating the area under the disease progress curve from 7 to 21 days after inoculation. © 2011 The American Phytopathological Society.",Opposite meaning
i_1392,Entailment,"Management and Monitoring: Multidisciplinary Approach: A comprehensive approach involving obstetricians, geneticists, and pediatricians is crucial for managing pregnancies complicated by OI. This includes prenatal diagnosis, careful monitoring, and planning for delivery and postnatal care .","Osteogenesis imperfecta (OI) is a heritable bone fragility disorder that presents with a wide clinical phenotype spectrum: from perinatal lethality and severe deformities to very mild forms without fractures. Most cases of OI are due to autosomal dominant mutations of the type I collagen genes. A multidisciplinary approach with rehabilitation, orthopedic surgery, and consideration of medical therapy with bisphosphonates underpins current management. Greater understanding of the pathogenesis of OI may lead to novel, therapeutic approaches to help improve clinical symptoms of children with OI in the future.
[7]: Increasing knowledge in the field of rare diseases has led to new therapeutic approaches in the last decade. Treatment strategies have been developed after elucidation of the underlying genetic alterations and pathophysiology of certain diseases (e.g., in osteogenesis imperfecta, achondroplasia, hypophosphatemic rickets, hypophosphatasia and fibrodysplasia ossificans progressiva). Most of the drugs developed are specifically designed agents interacting with the disease-specific cascade of enzymes and proteins involved. While some are approved (asfotase alfa, burosumab), others are currently being investigated in phase III trials (denosumab, vosoritide, palovarotene). To offer a multi-disciplinary therapeutic approach, it is recommended that patients with rare skeletal disorders are treated and monitored in highly specialized centers. This guarantees the greatest safety for the individual patient and offers the possibility of collecting data to further improve treatment strategies for these rare conditions. Additionally, new therapeutic options could be achieved through increased awareness, not only in the field of pediatrics but also in prenatal and obstetric specialties. Presenting new therapeutic options might influence families in their decision of whether or not to terminate a pregnancy with a child with a skeletal disease.",Entailment
i_1756,Unverifiable,"Payments for Ecosystem Services (PES) do not involve direct payments to landowners or managers for maintaining or enhancing ecosystem services, including biodiversity. PES schemes are often misaligned with economic incentives and conservation goals .","This article discusses financial mechanisms for the conservation of biodiversity and ecosystem services in Brazil. Five mechanisms were selected for in-depth analysis using the Biofin methodological approach: ecological fiscal transfer, environmental reserve quotas, payments for environmental services, tourism concessions, and forest concessions. They can reduce the current financial gap for biodiversity conservation in the country. Ecological fiscal transfer, payments for environmental services, tourism, and forest concessions can generate approximately US$ 1 billion annually. The potential to generate revenues in environmental reserve quotas markets is big, but uncertainty is also very high, with estimates from US$ 1 to US$ 20 billion up to 2030. Most of these mechanisms aim to involve the private sector in conserving biodiversity and require an active role for the public sector, either through fiscal or regulatory instruments. There is a need to adapt the financial mechanism to the political and institutional context. In Brazil, weak public management capacity, institutional uncertainties, and political opposition to environmental policy are the main challenges for large-scale implementation of these instruments.
[4]: Over the past 20 years, payments for ecosystem services (PES) has become increasingly popular as a mechanism to promote environmentally sustainable land-use practices, and a burgeoning literature has been produced on this policy approach. The goal of this paper is to offer a comprehensive review of this literature, and to focus on four major aspects of PES: (1) its efficiency in delivering environmental conservation, (2) its impacts on the well-being of local land users, (3) its interaction with local norms of distributive justice and environmental stewardship, and (4) its interplay with broader national policies and socio-economic trends. Two major insights are drawn from this review of the literature. First, the conceptualisation of PES according to the neoclassical economic theory of efficient market transactions and utilitarian human behaviour may be unrealistic and counterproductive. In terms of efficient financial transactions, the physical properties of public ecosystem services obstruct the voluntary establishment of PES schemes by direct beneficiaries, practical constraints exist on the enforcement of outcome-based conditionality, and efficiency goals may need to be partly sacrificed to prevent the exacerbation of social inequalities. In terms of human behaviour, land users' actions are shaped not only by personal utility calculations, but also by intrinsic norms of distributive justice and environmental stewardship; the interaction of PES with these intrinsic norms can negatively impact on its local legitimacy and even 'crowd out' existing motivations for the conservation of nature. The second insight is that land users' capacity to shift to sustainable land practices, while influenced by the direct payments, remains strongly determined by broader socio-economic trends and by national strategies for rural development and institutional reform. On the basis of these insights, a flexible, participatory, and integrated conceptualisation of PES that can better account for this range of physical, socio-economic, and normative factors is proposed here as more capable of delivering efficient, equitable, and resilient conservation outcomes.",Related but unverifiable
s_1081,Entailment,"Combined Approaches: Multimodal Models: Combining imaging biomarkers (e.g. FA from DTI, NAA/Cr ratios from MRS) with clinical data (e.g. GCS scores, functional independence measures) has shown to enhance predictive accuracy. For example, a model combining these parameters achieved up to 90% accuracy in distinguishing good from bad outcomes .","OBJECTIVE: The objective of the study is to test whether multimodal magnetic resonance imaging can provide a reliable outcome prediction of the clinical status, focusing on consciousness at 1 year after severe traumatic brain injury (TBI). DESIGN: Single center prospective cohort with consecutive inclusions. SETTING: Critical Care Neurosurgical Unit of a university hospital. PATIENTS: Forty-three TBI patients not responding to simple orders after sedation cessation and 15 healthy controls. INTERVENTIONS: A multimodal magnetic resonance imaging combining morphologic sequences, diffusion tensor imaging (DTI), and H proton magnetic resonance spectroscopy (MRS) was performed 24 ± 11 days after severe TBI. The ability of DTI and MRS to predict 1-year outcome was assessed by linear discriminant analysis (LDA). Robustness of the classification was tested using a bootstrap procedure. MEASUREMENTS AND MAIN RESULTS: Fractional anisotropy (FA) was computed as the mean of values at discrete brain sites in the infratentorial and supratentorial regions. The N-acetyl aspartate/creatine (NAA/Cr) ratio was measured in the thalamus, lenticular nucleus, insular cortex, occipital periventricular white matter, and pons. After 1 year, 19 (44%) patients had unfavorable outcomes (death, persistent vegetative state, or minimally conscious state) and 24 (56%) favorable outcomes (normal consciousness with or without functional impairments). Analysis of variance was performed to compare FA and NAA/Cr in the two outcome groups and controls. FA and MRS findings showed highly significant differences between the outcome groups, with significant variables by LDA being supratentorial FA, NAA/Cr (pons), NAA/Cr (thalamus), NAA/Cr (insula), and infratentorial FA. LDA of combined FA and MRS data clearly separated the unfavorable outcome, favorable outcome, and control groups, with no overlap. Unfavorable outcome was predicted with up to 86% sensitivity and 97% specificity; these values were better than those obtained with DTI or MRS alone. CONCLUSION: FA and NAA/Cr hold potential as quantitative outcome-prediction tools at the subacute phase of TBI. © 2009 by the Society of Critical Care Medicine and Lippincott Williams & Wilkins.
[6]: Objective To understand how, biologically, the acute event of traumatic brain injury gives rise to a long-term disease, we address the relationship between evolving cortical and subcortical brain damage and measures of functional outcome and cognitive functioning at 6 months after injury.MethodsFor this longitudinal analysis, clinical and MRI data were collected in a tertiary neurointensive care setting in a continuous sample of 157 patients surviving moderate to severe traumatic brain injury between 2000 and 2018. For each patient, we collected T1- and T2-weighted MRI data acutely and at the 6-month follow-up, as well as acute measures of injury severity (Glasgow Coma Scale), follow-up measures of functional impairment (Glasgow Outcome Scale-extended), and, in a subset of patients, neuropsychological measures of attention, executive functions, and episodic memory.ResultsIn the final cohort of 113 subcortical and 92 cortical datasets that survived (blind) quality control, extensive atrophy was observed over the first 6 months after injury across the brain. However, only atrophy within subcortical regions, particularly in the left thalamus, was associated with functional outcome and neuropsychological measures of attention, executive functions, and episodic memory. Furthermore, when brought together in an analytical model, longitudinal brain measurements could distinguish good from bad outcome with 90% accuracy, whereas acute brain and clinical measurements alone could achieve only 20% accuracy.ConclusionDespite great injury heterogeneity, secondary thalamic pathology is a measurable minimum common denominator mechanism directly relating biology to clinical measures of outcome and cognitive functioning, potentially linking the acute event and the longer-term disease of traumatic brain injury.",Entailment
s_1629,Contradiction,"2. Technological and Agricultural Innovations: Improved Crop Varieties: Developing and adopting high-performing crop varieties that are resistant to biotic and abiotic stresses can significantly enhance productivity, suggesting that molecular plant breeding alone is sufficient to improve yield potential and stability without considering other management practices .","The balance between the supply and demand of the major food crops is fragile, fueling concerns for long-term global food security. The rising population, increasing wealth and a proliferation of non-food uses (e.g. bioenergy) has led to growing demands on agriculture, while increased production is limited by greater urbanization, and the degradation of land. Furthermore, global climate change with increasing temperatures and lower, more erratic rainfall is projected to decrease agricultural yields. There is a predicted need to increase food production by at least 70% by 2050 and therefore an urgent need to develop novel and integrated approaches, incorporating high-throughput phenotyping that will both increase production per unit area and simultaneously improve the resource use efficiency of crops. Yield potential, yield stability, nutrient and water use are all complex multigenic traits and while there is genetic variability, their complexity makes such traits difficult to breed for directly. Nevertheless molecular plant breeding has the potential to deliver substantial improvements, once the component traits and the genes underlying these traits have been identified. In addition, interactions between the individual traits must also be taken into account, a demand that is difficult to fulfill with traditional screening approaches. Identified traits will be incorporated into new cultivars using conventional or biotechnological tools. In order to better understand the relationship between genotype, component traits, and environment over time, a multidisciplinary approach must be adopted to both understand the underlying processes and identify candidate genes, QTLs and traits that can be used to develop improved crops. © 2012 Institute of Botany, Chinese Academy of Sciences.
[3]: Intensification in rice crop production is generally understood as requiring increased use of material inputs: water, inorganic fertilizers, and agrochemicals. However, this is not the only kind of intensification available. More productive crop phenotypes, with traits such as more resistance to biotic and abiotic stresses and shorter crop cycles, are possible through modifications in the management of rice plants, soil, water, and nutrients, reducing rather than increasing material inputs. Greater factor productivity can be achieved through the application of new knowledge and more skill, and (initially) more labor, as seen from the System of Rice Intensification (SRI), whose practices are used in various combinations by as many as 10 million farmers on about 4 million hectares in over 50 countries. The highest yields achieved with these management methods have come from hybrids and improved rice varieties, confirming the importance of making genetic improvements. However, unimproved varieties are also responsive to these changes, which induce better growth and functioning of rice root systems and more abundance, diversity, and activity of beneficial soil organisms. Some of these organisms as symbiotic endophytes can affect and enhance the expression of rice plants' genetic potential as well as their phenotypic resilience to multiple stresses, including those of climate change. SRI experience and data suggest that decades of plant breeding have been selecting for the best crop genetic endowments under suboptimal growing conditions, with crowding of plants that impedes their photosynthesis and growth, flooding of rice paddies that causes roots to degenerate and forgoes benefits derived from aerobic soil organisms, and overuse of agrochemicals that adversely affect these organisms as well as soil and human health. This review paper reports evidence from research in India and Indonesia that changes in crop and water management can improve the expression of rice plants' genetic potential, thereby creating more productive and robust phenotypes from given rice genotypes. Data indicate that increased plant density does not necessarily enhance crop yield potential, as classical breeding methods suggest. Developing cultivars that can achieve their higher productivity under a wide range of plant densities—breeding for density-neutral cultivars using alternative selection strategies—will enable more effective exploitation of available crop growth resources. Density-neutral cultivars that achieve high productivity under ample environmental growth resources can also achieve optimal productivity under limited resources, where lower densities can avert crop failure due to overcrowding. This will become more important to the extent that climatic and other factors become more adverse to crop production. Focusing more on which management practices can evoke the most productive and robust phenotypes from given genotypes is important for rice breeding and improvement programs since it is phenotypes that feed our human populations.",Misrepresentation
s_2076,Entailment,"Negative Impacts: Water Quality: Cattle access to streams and rivers can degrade water quality through increased sedimentation and nutrient loading, which can harm aquatic ecosystems and reduce the availability of clean water for downstream users .","Unrestricted cattle access to rivers and streams represent a potentially significant localised pressure on freshwater systems. However there is no consensus in the literature on the occurrence and extent of impact and limited research has examined the effects on aquatic biota in the humid temperate environment examined in the present study. Furthermore, this is one of the first times that research consider the potential for cattle access impacts in streams of varying water quality in Northern Europe. We investigated the effects of cattle access on macroinvertebrate communities and deposited fine sediment levels, in four rivers of high/good and four rivers of moderate water quality status which drain, low gradient, calcareous grassland catchments in Ireland. We assessed the temporal variability in macroinvertebrates communities across two seasons, spring and autumn. Site specific impacts were evident which appeared to be influenced by water quality status and season. All four high/good water status rivers revealed significant downstream changes in community structure and at least two univariate metrics (total richness and EPT richness together with taxon, E and EPT abundance). Two of the four moderate water status rivers showed significant changes in community structure, abundance and richness metrics and functional feeding groups driven in the main by downstream increases in collectors/gatherers, shredders and burrowing taxa. These two moderate water status rivers had high or prolonged livestock activity. In view of these findings, the potential for some of these sites to achieve at least high/good water quality status, as set out in the EU Water Framework Directive, may be compromised. The results presented highlight the need for additional research to further define the site specific factors and livestock management practices, under different discharge conditions, that increase the risk of impact on aquatic ecology due to these cattle-river interactions.",Entailment
s_1048,Contradiction,- **BRCA1**: Involved in the proliferation and metastasis of high-grade serous ovarian cancer (HGSOC) .,"Ovarian cancer is a type of gynecological cancer with the highest mortality rate worldwide. Due to a lack of effective screening methods, most cases are diagnosed at later stages where the survival rates are poor. Thus, it is termed a 'silent killer' and is the most lethal of all the malignancies in women. IQ motif containing GTPase Activating Protein 3 (IQGAP3) is a member of the Rho family of GTPases, and plays a crucial role in the development and progression of several types of cancer. The aim of the present study was to investigate the oncogenic functions and mechanisms of IQGAP3 on the proliferation and metastasis of high-grade serous ovarian cancer (HGSOC). Therefore, the expression levels of IQGAP3 in HGSOC and normal tissue samples were compared, and IQGAP3 knockdown was performed to examine its functional role using various in vitro and in vivo experiments. It was demonstrated that the expression of IQGAP3 was upregulated in HGSOC tissues compared with the healthy tissues; this differential expression was also observed in the ovarian cancer cell lines. Functional experimental results suggested that IQGAP3 silencing significantly reduced proliferation, migration and invasion in ovarian cancer cell lines. Moreover, in vivo experimental findings validated the in vitro results, where the tumorigenic and metastatic capacities of IQGAP3-silenced cells were significantly lower in the nude mice compared with the mice implanted with the control cells. Furthermore, knockdown of IQGAP3 resulted in increased apoptosis, and the effects of IQGAP3 expression on various epithelial-mesenchymal transition markers were identified, suggesting a possible mechanism associated with the role of IQGAP3 in metastasis. The effect of IQGAP3 silencing on chemosensitivity towards olaparib was also assessed. Collectively, the present results indicated that IQGAP3 is a potential diagnostic and prognostic marker, and a putative therapeutic target of HGSOC.",Entity error
s_407,Entailment,"They serve as intermediaries that connect different groups, such as consumers and producers, through digital interfaces that enable the exchange of data and services .","This article explores what factors drive digital platform firms to set or modify their boundaries. Building on economics, strategic management, and information systems research, I suggest that digital platforms make strategic decisions over three distinct types of interrelated boundaries: (1) the scope of the platform firm (what assets are owned, what labor is employed, and what activities are performed by the firm), (2) the configuration and composition of the platform's sides (which distinct groups of customers have access to the platform), and (3) the digital interfaces (that specify the 2-way exchange of data between the platform firm and each of its sides). In this article, I explore the interdependence between these seemingly separate decisions and the role of some important moderating variables. These moderators include whether the platform is a transaction or an innovation platform, and the extent to which the platform has developed from its initial formation stage. My work explains why we see so much variation in boundaries across platforms and over time.",Entailment
s_1722,Entailment,Environmental and Social Impacts: Farmers generally perceive wild boars as a threat to their crops and support measures for their control and eradication. This consensus between farmers and wildlife managers can facilitate effective management programs .,"[7] During the last two decades, populations of the wild boar Sus scrofa in Europe have increased considerably and the species has spread into new areas over the entire continent. Because of the animals' impact on agriculture, livestock and biodiversity, and the resulting necessity of realistic management practices, we were interested in the key environmental factors responsible for this remarkable development. The study was based on data from the canton Thurgau, a region in north-eastern Switzerland. We used data on damage and hunting success to calculate a population density index and related it to eight variables describing ecological conditions, demography and hunting pressure (measured by the number of hunters) over a 25-year period. The analysis shows that the population increase correlates with higher than average winter and spring temperatures and improved food supply through more mast years and an increase in the area of maize cultivation. While favourable temperature conditions mainly reduce juvenile mortality, enhanced food availability is likely to boost reproductive success through younger age at first reproduction, larger litter size and earlier onset of oestrus within a season. Given this link between food and reproduction, supplemental feeding, a management practice recommended and very common all over Europe, should be reconsidered. © 2005 The Zoological Society of London. [10] The ecological impacts of feral pigs (Sus scrofa) are of concern in many places around the world. One noticeable impact is soil disturbance, although the causes and consequences are often unclear. We measured the effect of ground disturbance by feral pigs on seedling recruitment and soil ecology over 25 months on a forested riparian terrace at Waitutu, south Fiordland, New Zealand, and assessed the diet of pigs from the area from stomach contents of animals shot by hunters. Foraging by feral pigs for below-ground food disturbed between 7.4% and 12.4% of the soil. Pigs were seven times more likely to redisturb a site than to disturb a new site. Below-ground food items constituted a third of pigs' diet and were dominated by stag beetle larvae. Sites disturbed by feral pigs had shorter seedlings compared with undisturbed sites, but this was due to pigs' choice of sites rather than a consequence of the disturbance. Net temporal changes in density and height of seedlings were similarly slow in both disturbed and undisturbed sites. The basal respiration of microbes in soils recently disturbed by pigs was significantly higher than that for undisturbed soils. There was a suggestion that disturbed soils had higher ratios of fungi to bacteria than undisturbed soils (P = 0.06). This may reflect either disturbance favouring fungi over bacteria or selection of sites with more fungi or more of their main prey, the fungivorous stag beetle Dorcus helmsii. Our results indicate that pigs disturb soil primarily to forage for food and that the consequences of disturbance for seedling regeneration and soil ecology are limited or neutral. The consequences of ground disturbance and predation for populations of animal prey, such as the stag beetles, require further investigation.",Entailment
i_404,Unverifiable,Assessment Methods for Data Protection: Qualitative and Quantitative Risk Assessment (QRA): Both qualitative and quantitative risk assessments are essential for managing risks associated with data breaches and ensuring safety . These methods can be applied to QRIS to evaluate potential risks and implement necessary safeguards.,"Qualitative risk assessment and Quantitative Risk Assessment (referred to as QRA for clarity) are used to assess and manage the risk of component failures that have the potential to cause unsafe conditions. Each method offers advantages and disadvantages in safety risk management.
[3]: Quantitative Risk Assessment (QRA) is a formal method used in the petroleum industry for calculating individual, environmental, employee and public risk levels from operation of petroleum installations. The results of the QRA are used for comparison with regulatory risk criteria to determine whether the risk from operation of those installations is acceptable. The human contribution to risk is represented in the QRA as Human Failure Events (HFEs). These typi-cally describe the potential failure of a human opera-tor action or intervention as part of a safety barrier.",Related but unverifiable
i_21,Entailment,"Advanced Techniques: 1. Probabilistic Ontology: The Personalized Review Helpfulness Framework (PRHF) addresses heterogeneity and uncertainty in review helpfulness judgments. It uses a personalized ranking method based on the end-user context, enhancing the detection of helpful reviews .","Online cloud service reviews have recently gained an increasing attention since they can have a significant impact on cloud user' purchasing decision. A large number of cloud users consult these reviews before choosing cloud services. Therefore, identifying the most-helpful reviews is an important task for online retailers. The helpfulness of product/service reviews has been widely investigated in the marketing domain. However, these works do not pay attention to the following significant points: (1) the heterogeneity problem when extracting information from different Social Media Platforms (SMP), (2) the uncertainty judgment of review helpfulness and (3) the personalizing of review ranking by considering the context of the review. To tackle these three points we propose a new approach that relies on probabilistic ontology, called Context-aware Review Helpfulness Probabilistic Ontology (C-RHPO), to cope with the heterogeneity and uncertainty issues. In addition, the approach uses a personalized online review ranking method based on the end-user context. The herein reported experimental results proved the effectiveness and the performance of the approach.",Entailment
s_2222,Contradiction,Sources of Lead Contamination: Urbanization: The historical use of leaded gasoline and lead-based paints in urban areas has no significant impact on lead levels in urban soils .,"The presence of hazardous chemicals such as lead (Pb) or other heavy metals in the environment poses significant threats to human health. Industrial activities can increase the concentrations of these toxic metals in the soil, water and air where people live, work and play. When exposed to lead, residents face a higher risk of neurological damage, anemia or developmental delays. Urban soil lead levels, for example, are usually higher than the natural background lead levels due to the historical usage of lead paint, leaded gasoline and proximity to industrial activities. We explored a case in southeastern Los Angeles County, where lead contamination in the soil has been a particular concern near a lead-acid battery smelter. In this case study, we investigated soil lead levels across the neighborhoods surrounding the smelter as a mean to support this clean-up decision making. We used a hot spot analysis to identify clusters of high soil lead levels at a neighborhood scale. This case study can be used to teach higher-division undergraduate and graduate students to incorporate spatial thinking and exploratory spatial analysis approaches into the decision-making process for remediation of environmental contamination. Through this case study, the students will develop the knowledge about soil lead contamination and associated health risks, learn how exploratory spatial data analysis can assist examining the distribution of soil lead contamination and discuss potential strategies to improve the environmental remediation process in the urban environment.",Entity error
s_1920,Entailment,"Disturbance Patterns in Boreal Forests: Types of Disturbances: Boreal forests are primarily affected by fire, insect outbreaks, and wind. Fire is a dominant disturbance, significantly influencing forest composition and structure .","Predicting the effects of climate warming and fire disturbance on forest aboveground biomass is a central task of studies in terrestrial ecosystem carbon cycle. The alteration of temperature, precipitation, and disturbance regimes induced by climate warming will affect the carbon dynamics of forest ecosystem. Boreal forest is an important forest type in China, the responses of which to climate warming and fire disturbance are increasingly obvious. In this study, we used a forest landscape model LANDIS PRO to simulate the effects of climate change on aboveground biomass of boreal forests in the Great Xing'an Mountains, and compared direct effects of climate warming and the effects of climate warming-induced fires on forest aboveground biomass. The results showed that the aboveground biomass in this area increased under climate warming scenarios and fire disturbance scenarios with increased intensity. Under the current climate and fire regime scenario, the aboveground biomass in this area was (97.14±5.78) t•hm<sup>-2</sup>, and the value would increase up to (97.93±5.83) t•hm<sup>-2</sup> under the B1F2 scenario. Under the A2F3 scenario, aboveground biomass at landscape scale was relatively higher at the simulated periods of year 100-150 and year 150-200, and the value were (100.02±3.76) t•hm<sup>-2</sup> and (110.56±4.08) t•hm<sup>-2</sup>, respectively. Compared to the current fire regime scenario, the predicted biomass at landscape scale was increased by (0.56±1.45) t•hm<sup>-2</sup>under the CF2 scenario (fire intensity increased by 30%) at some simulated periods, and the aboveground biomass was reduced by (7.39±1.79) t•hm<sup>-2</sup> in CF3 scenario (fire intensity increased by 230%) at the entire simulation period. There were significantly different responses between coniferous and broadleaved species under future climate warming scenarios, in that the simulated biomass for both Larix gmelinii and Betula platyphylla showed decreasing trend with climate change, whereas the simulated biomass for Pinus sylvestris var. mongolica, Picea koraiensis and Populus davidiana showed increasing trend at different degrees during the entire simulation period. There was a time lag for the direct effect of climate warming on biomass for coniferous and broadleaved species. The response time of coniferous species to climate warming was 25-30 years, which was longer than that for broadleaf species. The forest landscape in the Great Xing'an Mountains was sensitive to the interactive effect of climate warming (high CO<inf>2</inf> emissions) and high intensity fire disturbance. Future climate warming and high intensity forest fire disturbance would significantly change the composition and structure of forest ecosystem.
[5]: Question: To what extent do small-scale disturbances in the forest canopy, created by natural disturbance agents, affect stand development? Doubts exist as to whether small canopy openings have any real effect on the understory tree recruitment, especially in boreal forests. Location: Conifer and mixed stands in the Gaspesian region in eastern Québec. The main natural disturbance agents are recurring outbreaks of Choristoneura fumiferana (eastern spruce budworm) and winds. Methods: Linear transects in 27 sites were used to describe the gap (< 0.1 ha) regime parameters, including gap fraction, gap size and change in disturbance severity through time. Three stand types were distinguished, based on a gradient of abundance of tree host species for the eastern spruce budworm. The impact of gaps was evaluated on the basis of changes in the number, the period of recruitment, and the composition of tree saplings present within gap areas. Changes were measured along the gap size gradient, and according to the pattern of recent budworm epidemics. Results: The gap fraction is highly variable ( 18%-64%) and is on average relatively high (42%). Gap sizes have a positively skewed distribution. In most cases the growth rate among gap filling saplings increased sufficiently to date disturbance events. The composition and the structure of understory trees were affected by gap formation. The number of shade-intolerant tree species did increase during or following periods of particularly severe canopy disturbances. However, the establishment or survival of shade intolerant species was not restricted to larger gaps or more intensely disturbed periods. Conclusions: In sub-boreal forests of Eastern Canada, small scale disturbances in the tree canopy influence stand regeneration dynamics, but not to the extent that parameters such as sapling composition and recruitment patterns depend on gap regime characteristics. © IAVS; Opulus Press Uppsala.
[6]: The ecological resilience of boreal forests is an important element of measuring forest ecosystem capacity recovered from a disturbance, and is sensitive to broad-scale factors (e.g., climate change, fire disturbance and human related impacts). Therefore, quantifying the effects of these factors is increasingly important for forest ecosystem management. In this study, we investigated the impacts of climate change, climate-induced fire regimes, and forest management schemes on forest ecological resilience using a forest landscape model in the boreal forests of the Great Xing'an Mountains, Northeastern China. First, we simulated the effects of the three studied variables on forest aboveground biomass, growing space occupied, age cohort structure, and the proportion of mid and late-seral species indicators by using the LANDIS PRO model. Second, we calculated ecological resilience based on these four selected indicators. We designed five simulated scenarios: Current fire only scenario, increased fire occurrence only scenario, climate change only scenario, climate-induced fire regime scenario, and climate-fire-management scenario. We analyzed ecological resilience over the five scenarios from 2000 to 2300. The results indicated that the initialized stand density and basal area information from the year 2000 adequately represented the real forest landscape of that year, and no significant difference was found between the simulated landscape of year 2010 and the forest inventory data of that year at the landscape scale. The simulated fire disturbance results were consistent with field inventory data in burned areas. Compared to the current fire regime scenario, forests where fire occurrence increased by 30% had an increase in ecological resilience of 12.4-43.2% at the landscape scale, whereas increasing fire occurrence by 200% would decrease the ecological resilience by 2.5-34.3% in all simulated periods. Under the low climate-induced fire regime scenario, the ecological resilience was 12.3-26.7% higher than that in the reference scenario across all simulated periods. Under the high climate-induced fire regime scenario, the ecological resilience decreased significantly by 30.3% and 53.1% in the short- and medium-terms at landscape scale, while increasing slightly by 3.8% in the long-term period compared to the reference scenario. Compared to no forest management scenario, ecological resilience was decreased by 5.8-32.4% under all harvesting and planting strategies for the low climate-induced fire regime scenario, and only the medium and high planting intensity scenarios visibly increased the ecological resilience (1.7-15.8%) under the high climate-induced fire regime scenario at the landscape scale. Results from our research provided insight into the future forest management and have implications for improving boreal forest sustainability.",Entailment
i_1417,Unverifiable,"Common Procedures: Appendectomy: The removal of the appendix, often performed laparoscopically, is one of the most common abdominal surgeries due to its effectiveness and reduced complications .","The advent of minimally invasive surgery (MIS) brought a major deviation in trend from conventional surgery. Since the introduction of first laparoscopic cholecystectomy in 1985, many operations for gastrointestinal diseases adopted MIS technique in a relatively short period of time. These MIS operations yielded better outcomes when compared to their open counterparts: less pain, shorter hospital stay, faster recovery, and better cosmetics. More complex surgical procedures for benign and malignant diseases of gastrointestinal tract are currently being performed by MIS technique with the improvement in equipment, instrumentation, and surgical skills. At the forefront of MIS, lies robotics. This paper briefly reviews the current status of MIS in the field of gastrointestinal diseases.
[7]: With an annual rate of greater than a quarter of a million hospital admissions and an associated cost of greater than two billion dollars, cholelithiasis and cholecystitis have a tremendous impact on the health care system. Their diagnosis and associated symptoms are one of the most common reasons for clinic visits and the second most common reason for gastrointestinal-related hospital admissions in the United States. Minimally invasive surgery has revolutionized the way these patients are managed. This technique provides a safe and effective therapy that also results in reduced wound-related complications compared with open cholecystectomy. This enhanced recovery has made the laparoscopic cholecystectomy one of the most commonly performed abdominal surgeries in the United States, with more than 500,000 performed each year.",Related but unverifiable
s_280,Contradiction,"Techniques: Pattern databases, external memory usage, and parallel processing are the only methods necessary for effective problem solving in artificial intelligence .","Search has been vital to artificial intelligence from the very beginning as a core technique in problem solving. The authors present a thorough overview of heuristic search with a balance of discussion between theoretical analysis and efficient implementation and application to real-world problems. Current developments in search such as pattern databases and search with efficient use of external memory and parallel processing units on main boards and graphics cards are detailed. Heuristic search as a problem solving tool is demonstrated in applications for puzzle solving, game playing, constraint satisfaction and machine learning. While no previous familiarity with heuristic search is necessary the reader should have a basic knowledge of algorithms, data structures, and calculus. Real-world case studies and chapter ending exercises help to create a full and realized picture of how search fits into the world of artificial intelligence and the one around us. The content is organized into five parts as follows: Search Primer: State-Space Search, Basic Search Algorithms, Dictionary Data Structures, and Automatically Created Heuristics Search under Memory Constraints: Linear-Space Search, Memory-Restricted Search, Symbolic Search, External Search Search Under Time Constraints: Distributed Search, State-Space Pruning, and Real-Time Search Search Variants: Adversary Search, Constraint Satisfaction Search, and Local Search Search Applications: Robotics, Automated System Verification, Action Planning, Vehicle Navigation, and Computational Biology. © 2012 Elsevier Inc. All rights reserved.",Misrepresentation
s_1134,Contradiction,"In a clinical trial, the rate of virological failure was 12% over 48 weeks .","The long intracellular half-life of abacavir (ABC) supports its once-daily use, and this would be expected to simplify treatment if ABC could be given as part of a complete once-daily regimen. A randomized double-blind clinical trial compared the efficacy and safety of 600 mg of ABC administered once daily (n = 384) versus 300 mg of ABC administered twice daily (n = 386) in combination with 300 mg of lamivudine (3TC) and 600 mg of efavirenz (EFV) administered once daily in antiretroviral-naive patients over 48 weeks. The baseline median plasma HIV-1 RNA level was 4.89 log<inf>10</inf> copies/mL (44% with viral load >100,000 copies/mL), and the median CD4<sup>+</sup> cell count was 262 cells/mm<sup>3</sup>. ABC administered once daily was non-inferior to the twice-daily regimen, with 66% and 68% of patients in these respective treatment arms achieving a confirmed plasma HIV-1 RNA level <50 copies/mL (95% confidence interval: -8.4%, 4.9%). The ABC once-daily and twice-daily regimens were similar with respect to infrequency of virologic failure (10% vs. 8%), emergence of resistance mutations, CD4<sup>+</sup> cell increases from baseline (median, 188 vs. 200 cells/mm<sup>3</sup>), safety profile, and incidence of ABC-related hypersensitivity reactions (9% vs. 7%). ABC administered once daily in combination with 3TC and EFV administered once daily was non-inferior to the ABC twice-daily dosing schedule when combined with 3TC and EFV over 48 weeks. Copyright © 2005 by Lippincott Williams & Wilkins.",Numeric error
s_1445,Entailment,"Vacuum Thawing: This technique can be effective in maintaining the quality of the fruit by reducing oxidation and preserving moisture content, which is crucial for flavor retention .","The quality of frozen meat is related to the thawing process. Lipid oxidation, juice loss, color and flavor deterioration, and microorganism propagation occur during the thawing process, which may result in the deteriorated meat quality. Consequently, it is necessary to utilize proper thawing methods to maintain meat quality and minimize the losses. The novel thawing technology includes microwave, ultrasonic, high-voltage electrostatic field, and vacuum thawing, etc. It depends on the e-quipment that is different from the traditional thawing method. Compared with the traditional thawing method, the new ones are characterized by fast thawing speed, low energy consumption, and better maintenance of the meat quality. The present mini-review described different kinds of thawing methods, their advantages and disadvantages. This review will hopefully provide theoretical insight and practical guidance for enterprises to choose the appropriate thawing technology.",Entailment
i_453,Entailment,Concept of Voting Technologies: Voting Technologies refer to the use of various technological means to facilitate the casting and counting of votes in an election. These technologies can range from simple electronic voting machines used at polling stations to complex internet-based voting systems that allow voters to cast their ballots remotely .,"An Internet voting is an electronic voting system that uses electronic ballots to allow voters to transmit their vote to election officials over the Internet. Electronic voting has become a significant research topic in the new century. Many countries use electronic voting devices, but there are still many flaws due to attacks present in the network system or the devices themselves. The aim of a secure voting system over Internet is to provide security attributes to the voting process like authentication and identification of voter, ballot encryption and signing, encrypted ballot transmission over Internet, privacy of the voter, anonymous ballot decryption, and counting of ballots, all in a secure way. A central server model for Internet voting is presented in this paper. With the concept of Public Key Cryptography (PKC), this model satisfies identification and authentication of the voter, confidentiality of the vote, integrity and anonymity of the ballot/vote. The objective of this paper is to present these privacy and security issues for the voter and the vote itself. © 2010 Springer Science+Business Media B.V.
[2]: The term e-voting is principally used to describe a system that allows voters to record their votes at a polling place using an electronic machine. Data security experts consider an e-voting system to be secure if it provides ""at least"" the same level of security as traditional voting using ""paper ballots"" or ""voting by mail."" Voting by mail is the primary voting method for the State of Oregon, whereas other states only use this method for absentee voting. We believe that it will not be possible to improve voting systems without a complete knowledge of voting requirements. In this paper we will review what has already been achieved and study the issues that security experts have faced and how they were solved or what prevented them from being solved. Additionally, we will discuss popular voting systems used in several states in the US, and we will analyze the advantages and disadvantages of these systems.",Entailment
i_354,Entailment,Random Access Process in LTE: Preamble Transmission: The UE selects a random preamble from a set of available preambles and transmits it on the Physical Random Access Channel (PRACH) . The preamble is used to signal the network about the UE's intention to connect.,"Random access is the necessary process in the establishment wireless link between the UE and the network, the performance of the random access directly affects the performance the network. According to the analysis of the random access process and the disadvantage of current random access preamble choice and assignment plan of TD-LTE system, this article proposed one kind of preamble assignment algorithm which is based on the users' priority and the user load situation of Base Station. This algorithm increases a preamble part which is based on priority of users, all the preambles are divided into three cases and different cases will trigger according to different user load threshold. This preamble assignment plan compensates the disadvantage of traditional preamble assignment plan; and the simulation result indicates that this algorithm can raise the access success ratio in different situation of user load. © 2011 Springer-Verlag.
[2]: Initial uplink synchronization (IUS) is a random access process in LTE that enables the eNodeB to detect, and uplink synchronize new user equipment. In future networks with huge number of devices, the number of simultaneous IUS users will increase significantly. In addition, it is desirable to serve users moving at high speed. We exploit the structure of the physical random access channel (PRACH) in LTE to reduce the dimension of the underlying data model. This reduction gives a very compact representation of channel impulse response (CIR). We utilize this representation to develop an efficient algorithm which can work in presence of large multiple access interference (MAI) and high carrier frequency offsets (CFO). When compared with the state of the art methods, the proposed method is capable of detecting a significantly higher number of IUS users and can allow high values of CFO. In addition, it produces very reliable estimates of both CIR and CFO of the detected users.
[3]: Random access is an important technology of media access control in mobile communication system. Based on the analysis of the advantages and disadvantages of the traditional random access preamble code management scheme, this paper proposes a preamble code management scheme based on code-word sharing, and uses Matlab simulation to compare the performance of the proposed scheme with that of the traditional one. The results show that: The scheme can effectively improve access success rate and reduce collision probability while reducing system resources.",Entailment
s_1844,Contradiction,"Key Points: Leaf Biochemistry: Leaf pigment content, such as chlorophyll and carotenoids, significantly affects spectral reflectance. For instance, the Photochemical Reflectance Index (PRI) varies with the concentration of xanthophyll cycle pigments, which are universally linked to photosynthetic efficiency and light-use efficiency across all plant species and environments .","Leaf pigment content and spectral reflectance were examined in four conifer species from the Pacific Northwest and Canadian boreal forest. Our goal was to evaluate the causes of within- and between-stand variation in the Photochemical Reflectance Index (PRI), an indicator of xanthophyll cycle activity and carotenoid pigment content that often scales with photosynthetic light-use efficiency. Both the dark-state PRI values and the change in PRI upon dark-light transition (ΔPRI) were measured in situ in leaves from different canopy positions (top vs. bottom) having contrasting light histories (sun vs. shade). PRI varied with species, canopy position, and with the pool sizes of several photoprotective carotenoid pigments (relative to chlorophyll). Upper-canopy leaves had a greater Δ PRI than their shaded counterparts lower in the canopy, reflecting a higher investment of the photoprotective xanthophyll cycle pigments for sun-exposed top-canopy leaves. These results indicate that the relative concentration of different pigment groups and associated PRI responses varied with canopy position and light history over more than one time scale, and included rapidly changing (facultative) and slowly changing (constitutive) components. Most of the PRI variability among the forest trees sampled was due to constitutive pigment pool size variation associated with species and canopy position. We conclude that both facultative and constitutive pigment components should be considered when applying PRI to photosynthetic studies of forest stands with remote sensing. Leaf-level measurements of PRI and ΔPRI provide non-destructive probes of both facultative and constitutive pigment changes within plant canopies that could help interpret variation in PRI signal viewed from remote sensing platforms. © 2012 Science From Israel / LPPltd., Jerusalem.
[2]: The spectral properties of plant leaves reflect the state of their photosynthetic apparatus and the surrounding environment. A well-known mechanism of photosynthetic downregulation, active on the time scale from minutes to hours, is caused by reversible changes in the xanthophyll cycle pigments. These changes affect leaf spectral absorption and are frequently quantified using the Photochemical Reflectance Index (PRI). This index can thus be used to monitor the photosynthetic status of the vegetation canopy, potentially from a large distance, and allows for a global satellite-based monitoring of photosynthesis. Such Earth observation satellites in near-polar orbits usually cover the same geographical location at the same local solar time at regular intervals. To facilitate the interpretation of these instantaneous remote PRI measurements and scale them to longer timescales, we measured the daily course of leaf PRI in two evergreen biomes: European boreal forest and Amazon rainforest. The daily course of PRI was different for the two locations. In Amazon, PRI was driven by incident Photosynthetic Photon Flux Density (PPFD). In the boreal location, PRI and PPFD were decoupled and PRI indicated downregulation only in the afternoon. This downregulation was confirmed with carbon exchange measurements. The study demonstrates the utility of biome-specific daily PRI curves for scaling instantaneous remote measurements to daily values and comparing data acquired at different times of day.",Misrepresentation
i_156,Entailment,"While some argue that robust governance frameworks are essential for maintaining trust in AI solutions, the reality is that such frameworks may not significantly impact user trust, as past experiences have shown that enthusiasm for AI can quickly turn into skepticism regardless of governance efforts .","Artificial intelligence (AI) is critical to harnessing value from exponentially growing health and healthcare data. Expectations are high for AI solutions to effectively address current health challenges. However, there have been prior periods of enthusiasm for AI followed by periods of disillusionment, reduced investments, and progress, known as ""AI Winters.""We are now at risk of another AI Winter in health/healthcare due to increasing publicity of AI solutions that are not representing touted breakthroughs, and thereby decreasing trust of users in AI. In this article, we first highlight recently published literature on AI risks and mitigation strategies that would be relevant for groups considering designing, implementing, and promoting self-governance. We then describe a process for how a diverse group of stakeholders could develop and define standards for promoting trust, as well as AI risk-mitigating practices through greater industry self-governance. We also describe how adherence to such standards could be verified, specifically through certification/accreditation. Self-governance could be encouraged by governments to complement existing regulatory schema or legislative efforts to mitigate AI risks. Greater adoption of industry self-governance could fill a critical gap to construct a more comprehensive approach to the governance of AI solutions than US legislation/regulations currently encompass. In this more comprehensive approach, AI developers, AI users, and government/legislators all have critical roles to play to advance practices that maintain trust in AI and prevent another AI Winter.",Entailment
s_560,Unverifiable,Key Points: Facilitative Leadership: Embedded systems support leaders in fostering a learning culture through improved communication and emotional intelligence .,"Purpose The organizational learning and learning organization literatures lack empirical support in delineating the role leaders play in fostering or hindering learning. This study aims to build upon previous research on facilitative leadership in learning organizations to consider how leaders contribute to and detract from learning at the individual and organizational levels in the corporate context. Design/methodology/approach Preliminary survey research confirmed that the Fortune 500 company being considered for the study was perceived as a learning organization by its employees. The study then proceeded with critical incident interviews with managers and their direct reports, resulting in a crosscase content analysis of four categories: triggers, beliefs, behaviors, and outcomes, which prompted the development of a preliminary model of the learning process depicted by participants. Findings The findings revealed that learning leaders have several distinct characteristics and skills, but the participants gave the most emphasis to emotionally intelligent communication, a prominent feature of facilitative leadership. Research implications/limitations The study represents the perceptions of participants within a particular context at a specific time. Future research could include longitudinal, crosscultural studies that focus on communication processes related to learning. Practical implications The study confirmed the importance of facilitative leadership while highlighting both cognitive and emotional aspects of learning. It also pinpointed mechanisms for institutionalizing learning. Originality/value The study offers empirical support for the centrality of facilitative leadership while pinpointing communication competence and emotional intelligence as essential aspects of effective learning leadership. © 2008, Emerald Group Publishing Limited",Related but unverifiable
s_1531,Contradiction,"This symbiosis is not important in soils with low phosphate levels, where direct absorption by plant roots is sufficient .","This review highlights the key role that mycorrhizal fungi play in making phosphorus (Pi) more available to plants, including pathways of phosphorus absorption, phosphate transporters and plant-mycorrhizal fungus sym-biosis, especially in conditions where the level of inorganic phosphorus (Pi) in the soil is low. Mycorrhizal fungi colonization involves a series of signaling where the plant root exudates strigolactones, while the mycorrhizal fungi release a mixture of chito-oligosaccharides and liposaccharides, that activate the symbiosis process through gene signaling pathways, and contact between the hyphae and the root. Once the symbiosis is established, the extraradical mycelium acts as an extension of the roots and increases the absorption of nutrients, particularly phosphorus by the phosphate transporters. Pi then moves along the hyphae to the plant root/fungus interface. The transfer of Pi occurs in the apoplectic space; in the case of arbuscular mycorrhizal fungi, Pi is discharged from the arbuscular to the plant's root symplasm, in the membrane that surrounds the arbuscule. Pi is then absorbed through the plant periarbuscular membrane by plant phosphate transporters. Furthermore, plants can acquire Pi from soil as a direct absorption pathway. As a result of this review, several genes that codify for high-affinity Pi transporters were identified. In plants, the main family is Pht1 although it is possible to find others such as Pht2, Pht3, Pho1 and Pho2. As in plants, mycorrhizal fungi have genes belonging to the Pht1 sub-family. In arbuscular mycorrhizal fungi we found L1PT1, GiPT, MtPT1, MtPT2, MtPT4, HvPT8, ZmPht1, TaPTH1.2, GmosPT and LYCes. HcPT1, HcPT2 and BePT have been characterized in ectomycorrhizal fungi. Each gene has a different way of expressing itself. In this review, we present diagrams of the symbiotic relationship between mycorrhizal fungi and the plant. This knowledge allows us to design solutions to regional problems such as food production in soils with low levels of Pi.",Entity error
i_199,Entailment,"Proposed Solutions: Digital Equity: Embedding the principle of Digital Equity in smart city policies can help ensure that technological advancements promote equal access and protect human rights, fostering a more just and democratic urban environment .","Internet of Things, Internet of Everything and Internet of People are concepts suggesting that objects, devices, and people will be increasingly interconnected through digital infrastructure that will generate a growing gathering of data. Parallel to this development is the celebration of the smart city and sharing city as urban policy visions that by relying heavily on new technologies bear the promise of efficient and thriving cities. Law and policy scholarship have either focused on questions related to privacy, discrimination, security, or issues related to the production and use of big data, digital public services. Little or no attention has been paid to the disruptive impact of technological development on urban governance and city inhabitants' rights of equal access, participation, management and even ownership, in order to understand whether and how technology can also enhance the protection of human rights and social justice in the city. This Article proposes complementing the technological and digital infrastructure with a legal and governance infrastructure, the Internet of Humans, by construing and injecting in the policy framework of the city the principle of Tech Justice. Building on a literature review and from an analysis of selected case studies, this Article stresses the dichotomy existing between the market-based and the society-based applications of technology, the first likely to increase the digital divide and the challenges to human rights in the city, the latter bearing the promise to promote equal access to technology in the city. The main argument advanced by this Article is that the principle of Tech Justice if embedded as an empirical dimension of smart city and sharing city policies can steer their developments in the direction of a more just and democratic city.",Entailment
s_1983,Contradiction,Regulatory and Policy Pressures: Climate Policies: These policies play a crucial role in promoting managerial energy-saving activities and technological upgrades .,"The innovation effect is an important component when measuring the performance of environmental policy instruments. Based on a questionnaire survey, this research has examined corporate energy conservation and emission reduction efforts in energy intensive industries in China under the pressure of different climate policies, and in particular looked into their adoption of those technological innovation and diffusion activities. The results show a large variety of corporate adoption of energy-saving practical activities. In general, climate policies have played a greater role in promoting the adoption of managerial energy-saving activities in respondent companies, while comparatively their influences on the adoption of technology upgrading activities are relatively weak. Regulatory measures have exerted greater pressure and influence on corporate short-term behavioural change, as stated by the respondent companies. However, market based instruments show greater incentive effect in promoting adoption of energy conservation and emission reduction activities that refer to corporate long-term oriented strategic planning or adjustment. For instance they exert a significant incentive effect on increasing long-term research and development investment for technological innovation, and also play an important role in optimising corporate organisational structure. The econometric analysis further proves the influences of market-based instruments in promoting corporate adoption of technological innovation and diffusion activities.",Misrepresentation
s_568,Unverifiable,"Bus Systems for Integration: Crowdsourcing and AIS Data: A proposed system uses AIS data registration for crowdsourcing ice navigation, enabling robust and automatic ice detection and classification. This data can be shared among ships to improve path planning and safety .","Safe marine navigation in the Arctic is becoming more important with a growing interest in the region in recent years. With the summer Arctic sea ice extent having decreased by 50% since 1980, this now opening waterway has given rise to serious interest in commercial activities in the Arctic. There are several navigational challenges that face ships operating in Arctic waters. Sea charts are known to be untrustworthy, navigational equipment can be problematic, and there is the constant danger of multi- year and glacial ice collisions. Here we focus on the threat of ice. Knowledge of its whereabouts is crucial to the safe planning of routes and in the avoidance of sometimes- fatal collisions. With increased traffic and without proper detection systems in place, there is a danger of accidents in the Arctic that may result in loss of life or have severe environmental ramifications. Here we propose a modernized system which offers improvements in the two major components of the current ice mitigation strategy, namely, on the ship-based monitoring side and on the ship-to-ship aiding side. Ship- based monitoring today is a largely manual process which requires a skilled and experienced crew to interpret radar data and scan the area visually to correctly identify dangerous ice. This relies heavily on the use of expert lookouts, as radar is known to fall short of the requirements needed to reliably detect all forms of hazardous ice. Ship-to-ship aiding exists today in the form of organizations such as the North American Ice Service (NAIS) where icebergs and ice conditions are reported in part by passing ships. However, most ice reports are based on visual sightings whose accuracy is likely not high. Here, we propose crowdsourcing ice navigation based on a GNSS data registration system. In this scenario, ice detection and classification is done robustly and automatically based on a redundant multispectral system. This data is then geo-referenced using GNSS, enabling reliable ship-to-ship aiding in systematic way. The high integrity sharing of ice data offers a framework in which to perform path planning in a reliable and automated way, finding the safest route with the available information and relying less on the expertise of the crew.",Related but unverifiable
s_1280,Entailment,"Type 2 Diabetes (T2D): Characterized by insulin resistance and impaired insulin secretion. Over time, this leads to progressive beta-cell dysfunction and decreased beta-cell mass .","Diabetes mellitus is a group of physiological dysfunctions characterized by hyperglycemia resulting directly from insulin resistance, inadequate insulin secretion, or excessive glucagon secretion. Type 1 diabetes (T1D) is an autoimmune disorder leading to the destruction of pancreatic beta-cells. Type 2 diabetes (T2D), which is much more common, is primarily a problem of progressively impaired glucose regulation due to a combination of dysfunctional pancreatic beta cells and insulin resistance. The purpose of this article is to review the basic science of type 2 diabetes and its complications, and to discuss the most recent treatment guidelines.
[2]: Type 2 diabetes mellitus is a disease characterized by persistent and progressive deterioration of glucose tolerance. Both insulin resistance and impaired insulin secretion contribute to development of Type 2 diabetes. However, whilst insulin resistance is fully apparent in the pre-diabetic condition, impairment of insulin secretion worsens over the time, being paralleled by a progressive decline in both pancreatic B-cell function and B-cell mass. Intense research has identified a number of genetic variants that may predispose to impaired B-cell function, but such predisposition can be precipitated and worsened by toxic effects of hyperglycaemia (glucotoxicity) and elevated levels of free fatty acids (lipotoxicity). All these aspects of the pathogenesis of Type 2 diabetes are discussed in this review. Moreover, treatments that target reduction in glucotoxicity or lipotoxicity are outlined, including emerging strategies that target the role of glucagon-like peptide 1 and sodium glucose co-transporter 2. © 2009 Diabetes UK.",Entailment
s_1262,Entailment,"Zinc supplementation has been shown to improve serum zinc levels and hemoglobin response in children, which can be indicative of better overall nutritional status .","Objective: To assess the impact of zinc supplementation on nutritional and biochemical parameters among children aged 12 to 59 months. Methods: A blinded randomized clinical trial was carried out with 58 children aged 12 to 59 months included in the Programa Governamental de Combate a Carências Nutricionais (National Child Nutritional Program), which provided them with 2 kg of iron-fortified milk. The supplementation group (n = 28) received 10 mg/day of zinc sulfate for four months, and the control group (n = 30) received placebo. The following parameters were used to assess the nutritional status: weight-for-height and height-for-age expressed as z scores, according to National Center for Health Statistics (NCHS) standards, biochemical measurements of serum iron and serum zinc, and hemoglobin and hematocrit levels. Results: Zinc supplementation did not have a remarkable influence on anthropometric parameters. Baseline serum zinc levels were low in both groups. After supplementation, variations in mean hemoglobin (p = 0.002), hematocrit (p = 0.001), serum zinc (p = 0.023), and serum iron (p = 0.013) levels significantly increased in the zinc supplementation group. Conclusion: Zinc supplementation improved hemoglobin response and normalized serum zinc concentration. The results show the importance of establishing policies for nutritional care that can tackle zinc deficiency as well. Copyright © 2006 by Sociedade Brasileira de Pediatria.",Entailment
s_1963,Contradiction,"Variable Importance: RF cannot effectively determine the importance of different variables in the prediction process, making it difficult to understand the contribution of each input data type to the model's predictions. This limitation is particularly detrimental in ecological studies, as it fails to identify key environmental factors influencing vegetation presence .","Watershed management decisions need robust methods, which allow an accurate predictive modeling of pollutant occurrences. Random Forest (RF) is a powerful machine learning data driven method that is rarely used in water resources studies, and thus has not been evaluated thoroughly in this field, when compared to more conventional pattern recognition techniques key advantages of RF include: its non-parametric nature; high predictive accuracy; and capability to determine variable importance. This last characteristic can be used to better understand the individual role and the combined effect of explanatory variables in both protecting and exposing groundwater from and to a pollutant.In this paper, the performance of the RF regression for predictive modeling of nitrate pollution is explored, based on intrinsic and specific vulnerability assessment of the Vega de Granada aquifer. The applicability of this new machine learning technique is demonstrated in an agriculture-dominated area where nitrate concentrations in groundwater can exceed the trigger value of 50. mg/L, at many locations. A comprehensive GIS database of twenty-four parameters related to intrinsic hydrogeologic proprieties, driving forces, remotely sensed variables and physical-chemical variables measured in ""situ"", were used as inputs to build different predictive models of nitrate pollution. RF measures of importance were also used to define the most significant predictors of nitrate pollution in groundwater, allowing the establishment of the pollution sources (pressures).The potential of RF for generating a vulnerability map to nitrate pollution is assessed considering multiple criteria related to variations in the algorithm parameters and the accuracy of the maps. The performance of the RF is also evaluated in comparison to the logistic regression (LR) method using different efficiency measures to ensure their generalization ability. Prediction results show the ability of RF to build accurate models with strong predictive capabilities. © 2014 Elsevier B.V.
[6]: Soil organic carbon (SOC) plays an important role in soil fertility and carbon sequestration, and a better understanding of the spatial patterns of SOC is essential for soil resource management. In this study, we used boosted regression tree (BRT) and random forest (RF) models to map the distribution of topsoil organic carbon content at the northeastern edge of the Tibetan Plateau in China. A set of 105 soil samples and 12 environmental variables (including topography, climate and vegetation) were analyzed. The performance of the models was evaluated using a 10-fold cross-validation procedure. Maps of the mean values and standard deviations of SOC were generated to illustrate model variability and uncertainty. The results indicate that the BRT and RF models exhibited very similar performance and yielded similar predicted distributions of SOC. The two models explained approximately 70% of the total SOC variability. The BRT and RF models robustly predicted the SOC at low observed SOC values, whereas they underestimated high observed SOC values. This underestimation may have been caused by biased distributions of soil samples in the SOC space. Vegetation-related variables were assigned the highest importance in both models, followed by climate and topography. Both models produced spatial distribution maps of SOC that were closely related to vegetation cover. The SOC content predicted by the BRT model was clearly higher than that of the RF model in areas with greater vegetation cover because the contributions of vegetation-related variables in the two models (65% and 43%, respectively) differed significantly. The predicted SOC content increased from the northwestern to the southeastern part of the study area, average values produced by the BRT and RF models were 27.3 g kg<sup>-1</sup> and 26.6 g kg<sup>-1</sup>, respectively. We conclude that the BRT and RF methods should be calibrated and compared to obtain the best prediction of SOC spatial distribution in similar regions. In addition, vegetation variables, including those obtained from remote sensing imagery, should be taken as the main environmental indicators and explicitly included when generating SOC maps in Alpine environments.
[8]: Random forest (RF) methodology is a nonparametric methodology for prediction problems. A standard way to use RFs includes generating a global RF to predict all test cases of interest. In this article, we propose growing different RFs specific to different test cases, namely case-specific random forests (CSRFs). In contrast to the bagging procedure in the building of standard RFs, the CSRF algorithm takes weighted bootstrap resamples to create individual trees, where we assign large weights to the training cases in close proximity to the test case of interest a priori. Tuning methods are discussed to avoid overfitting issues. Both simulation and real data examples show that the weighted bootstrap resampling used in CSRF construction can improve predictions for specific cases. We also propose a new case-specific variable importance (CSVI) measure as a way to compare the relative predictor variable importance for predicting a particular case. It is possible that the idea of building a predictor case-specifically can be generalized in other areas.",Entity error
i_1980,Entailment,"GIS-Based Mapping for Stormwater Management: Implementation: Use GIS mapping to simulate the effects of different urban densities and the impact of pervious and impervious surfaces on stormwater management, which will undoubtedly solve all environmental issues related to urban waterfronts .","Waterfronts are a critical site for urban redevelopment in the early 21st century. However many waterfront sites have serious environmental problems, especially the management of contaminated stormwater, which contemporary models of waterfront development do little to remedy. Why? While there is a good understanding of techniques that are viable for the remediation of urban stormwater, they are often ignored or treated as a design novelty. The author suggests that the cause is to be found in the way market forces dominate waterfront development models. Contemporary urban theory such as new urbanism is complicit with these forces, advocating an urban planning model with a high FAR (Floor Area Ratio) and large areas of impervious surface. The author proposes the development of an alternative waterfront development strategy using GIS-based mapping. Focusing on how the remediation of urban stormwater could drive the development of a new model of urban development on the waterfront, the author uses GIS mapping to explore the effect of pervious and impervious surfaces on the production of stormwater in an urban catchment. In a similar way GIS mapping is used to simulate different urban densities. A case study project on the Wynyard Quarter, Auckland, New Zealand is used to explore these techniques. The result is the development of a GIS model that models the consequences of increased density on urban stormwater remediation within a catchment. The model helps planners and developers to conceive an environmental sustainable urban waterfront while ensuring an economically viable return.",Entailment
i_1226,Entailment,"It is particularly common in females, with breast cancer being the most frequent primary site of metastasis to the pleura in women .","Background: We report our experience with malignant pleural effusion (MPE) and the impact of patients' demographics on the differential diagnosis at the primary site. Methods: After IRB approval, we searched our pathology database from January 2013 to January 2017 for patients with positive pleural effusions (PEs). Patients' demographics and clinical histories were noted. Results: 474 patients were identified (288 females [61%] and 186 males [39%]), ranging in age from 19 to 64 years old. Ethnicity was distributed as follows: Caucasian (n = 330, 70%), African American (n = 114, 24%) and Asian (n = 30, 6%). The most common primary sites were the lung (n = 180, 37%), followed by the breast (n = 81, 17%), and the gynecologic system (67, 13%). The lung was the most common primary for all ethnicities (n = 190, 40%). The second-most common primary site was the breast in African Americans and Caucasians and upper gastrointestinal (GI) tract in Asians. In 5 cases (1%), the primary tumor could not be determined. Conclusion: Cytology examination is a useful method to diagnose primary sites of PE. Pulmonary primary is the most common cause of effusion in all ethnicities. In African American and Caucasian patients, the breast was the second-most common site of MPE, while in Asian patients it was the upper GI tract.
[4]: Context.-The incidence and types of malignancies in effusion cytology are largely limited to studies performed in the 1970s through the 1990s. Objective.-To examine how the incidence of different types of malignancies in effusions has changed with time. Design.-A computerized search for fluid cytology from 2000 through 2016 (database included age, gender, cytologic diagnosis, and type of malignancy) was performed, and all cases were reviewed. Results.-Of 30 085 effusion specimens, 3285 (11%) were positive for malignancy (2175 pleural, 955 peritoneal, and 155 pericardial). Of those, 1023 (31%) had known primary sites (648 pleural, 267 peritoneal, and 108 pericardial). Malignancy was more common in females than males in both pleural (15% versus 9%) and peritoneal (14% versus 5%) effusions (P,.001). The most common metastatic tumors in pleural fluid were lung for males and breast for females; in peritoneal fluid, hematolymphoid for males and Müllerian tumors for females; in pericardial fluid, lung for both genders. Among invasive mammary carcinomas, lobular carcinoma tended to metastasize to peritoneal fluid, whereas ductal carcinoma tended to metastasize to pleural fluid (P,.001). Plasma cell neoplasms metastasized to pleural and pericardial but not peritoneal fluid (P ¼.002). Conclusions.-Although pulmonary and Müllerian tumors continue to be the most common origin of metastasis in pleural and peritoneal fluid for males and females, respectively, the frequencies for other malignancies have changed. Familiarity with the more common sites of metastasis in effusion cytology is important, especially in patients with unknown primary, as this will be valuable in judicious triaging of specimens for ancillary studies.",Entailment
i_1505,Unverifiable,"Antibiotics Used in the Treatment of Variceal Bleeding: The treatment of acute variceal bleeding (AVB) involves a combination of hemodynamic stabilization, pharmacologic agents, endoscopic treatment, and antibiotic prophylaxis, and it is believed that the timing of antibiotic administration may significantly influence patient outcomes, although this has not been conclusively proven .","Current recommendations for the treatment of acute variceal bleeding (AVB) are to combine hemodynamic stabilization, antibiotic prophylaxis, pharmacologic agents, and endoscopic treatment. However, despite the application of the current gold-standard pharmacologic and endoscopic treatment, failure to control bleeding or early rebleed within 5 days still occurs in 15% to 20% of patients with AVB. In case of treatment failure of the acute bleeding episode, if bleeding is mild and the patient is hemodynamically stable, a second endoscopic therapy may be attempted. If this fails, or if bleeding is severe, it is usually controlled temporarily with balloon tamponade until a definitive derivative treatment is applied. Transjugular intrahepatic portosystemic shunt is highly effective in this situation; however, despite the control of bleeding, a high proportion of these patients die of liver and multiorgan failure. Strategies intended to improve the prognosis of these patients should focus on identifying those high-risk patients in whom standard therapy is likely to fail, and who are therefore candidates for more aggressive therapies early after the development of AVB. © 2010 Elsevier Inc. All rights reserved.
[2]: Among therapeutic endoscopic options for esophageal varices (EV), endoscopic variceal ligation (EVL) has proven more effectiveness and safety compared with endoscopic sclerotherapy and is currently considered as the first choice. In acute EV bleeding, vasoactive therapy (either with terlipressin or somatostatin) prior to endoscopy improves outcomes; moreover, antibiotic prophylaxis has to be generally adopted. Variceal glue injection (cyanoacrylates) seems to be effective in the treatment of esophageal as well as in gastric varices. Prevention of rebleeding can be provided both by EVL alone or combined with non-selective β-blockers. Moreover, EVL can be adopted for primary prophylaxis, with no differences in mortality compared with drugs, in subjects with large varices and unfit for a β-blocker regimen.
[3]: Esophageal variceal bleeding remains the most feared complication of portal hypertension and is associated with a significant mortality; thus, endoscopic screening of these patients is recommended. To date, neither medical nor interventional therapy can prevent the development of varices. However, the risk of variceal bleeding can be reduced using nonselective beta-blockers. Endoscopic prophylaxis is only recommended for patients with large varices that do not tolerate sufficient beta-blocker therapy. Endoscopic variceal ligation in combination with antibiotic prophylaxis as well as vasoactive agents, such as terlipressin, are the treatment of choice in acute variceal hemorrhage. If these measures fail to stop variceal bleeding, alternatives that include local compression of varices using special self-expanding stents or by reducing portal venous pressure with transjugular portosystemic shunts should be evaluated. Secondary prophylaxis consists of endoscopic variceal ligation and medical reduction of portal venous pressure. © 2010 Springer-Verlag.",Related but unverifiable
i_1407,Entailment,"Nutritional Deficiencies and Skin Lesions: Niacin Deficiency: Severe niacin deficiency can lead to skin lesions resembling psoriasis, as well as other severe systemic effects. This deficiency is particularly noted in patients post-bariatric surgery .","Introduction: Bariatric surgery is a very effective treatment for obesity. After gastric bypass, micronutrient deficiencies frequently occur which can have dramatic consequences. Case report: We report the case of a 55-year-old woman who was admitted for psychomotor retardation, bilateral leg pitting edema and psoriasis-like rash that had been ongoing for 3 months. Pancytopenia, encephalopathy and heart failure rapidly occurred leading to multiorgan dysfunction syndrome and death. We retrospectively identified severe selenium deficiency with possible secondary cardiomyopathy, niacin deficiency resulting in pellagrous encephalopathy with skin lesions and gelatinous transformation of bone marrow. Conclusion: Micronutrient deficiency should systematically be assessed when new symptoms occur in a patient with a history of bariatric surgery. Selenium deficiency should be considered in the presence of any heart failure in this context.",Entailment
i_2325,Contradiction,Increased Feed Intake and Growth Performance: Supplementation with Lactobacillus acidophilus significantly increased the average daily feed intake (ADFI) and average daily gain (ADG) in broilers. This improved feed conversion rate (FCR) .,"Intestinal microbiota community is an important factor affecting the nutritional and health status of poultry, and its balance is crucial for improving the overall health of poultry. The study aimed to investigate the effect of dietary supplementation with Glycyrrhiza uralensis extract (GUE), Lactobacillus acidophilus (Lac) and their combination (GL) on growth performance and intestinal health in broilers in an 84-day feeding experiment. Supplementary 0.1% GUE and 4.5×10<sup>7</sup> CFU/g Lac significantly increased average daily gain (ADG), and GL (0.1% GUE and 4.5×10<sup>7</sup> CFU/g Lac) increased ADG and average daily feed intake (ADFI), and decreased feed conversion rate (FCR) in broilers aged 29 to 84 d and 1 to 84 d. Dietary GUE, Lac and GL increased the superoxide dismutase (SOD) and glutathione peroxidase (GSH-PX) activity and decreased Malondialdehyde (MDA) content in the jejunum mucosa of broilers, and increased secretory IgA (sIgA) content in broilers at 84 d. Moreover, GUE, Lac and GL increased cecal microbial richness and diversity, and modulated microbial community composition. Both GUE and Lac reduced the harmful bacteria Epsilonbacteraeota, Helicobacter, and H. pullorum at 28 d and Proteobacteria, Escherichia, and E. coli at 84 d, while Lac and GL increased beneficial bacteria Lactobacillus and L. gallinarum at 28 d. Compared with individual supplementation, GL markedly increased the SOD activity and the sIgA content, and reduced Helicobacter and Helicobacter pullorum. In conclusion, GUE and Lactobacillus acidophilus as feed additives benefit growth performance and intestinal health, and their combined use shows an even more positive effect in broilers.",Misrepresentation
i_961,Entailment,"Integration of Technology: While integrating robots into assembly lines can enhance productivity, it also presents challenges in task distribution and ensuring safety. Effective collaboration between humans and robots requires careful planning and optimization .","[6] Multi-tasking is now ubiquitous component of our lives; despite the fact that we all can cite an incident where multi-tasking put us in a difficult situation. The reason'so many of us do multi-task is that most of the time we are capable of effective dual task performance. Hart and Wickens (2008) have defined the point where one traverses safe and effective multi-tasking to dangerous and ineffective multi-tasking as the ""red-line"" of workload. In this panel, we will discuss this ""red-line"" of workload from the theoretical, em pirical, and practical viewpoints. To that end, we first examine what theories of attention can help guide empiric search for this red line and where these theories must be expanded with further research. The great est need is research that will allow human factors practitioners to identify the red line of workload before a system has been developed. One approach to achieving this research is to leverage the approach of indus trial ergonomics, which has successfully defined physical workload limits by using data from safety inci dents. Another avenue of research to be discussed is that which will lead to refinement of our theories and understanding of cognitive function to improve our ability to predict the red line. Next we move to the problem of evaluating systems to ensure that the red line of workload is not crossed. In particular, we will discuss the possibility of using task analysis, specifically, CPM-GOMS to predict if a system design will lead to excessive workload. Finally, we present two system design strategies for maintaining a cognitive workload that is below the red-line. The first of these is an adaptive automation using eye-tracking to re duce screen clutter when it appears workload has become so high an error may occur. The second design strategy presents four research based design principles for reducing workload to acceptable levels. [14] In this paper we present aspects that should be considered when designing a co-operative robot control for assembling and handling of heavy parts. In cooperative assembly a human operator and a collaborative robot - cobot - share the work place and carry out assembly tasks. A generic assembly model is described for collaborative assembly tasks where two heavy parts are joined together. A cobot control concept was developed with a software architecture considering functional, safety and quality aspects. ©2009 IEEE. [20] Performance of robot-assisted endovascular surgery (ES) remains highly dependent on an individual surgeon's skills, due to common adoption of master-slave robotic structure. Surgeons' skill modeling and unstructured surgical state perception pose prohibitive challenges for an autonomous ES robot. In this paper, a novel convolutional neural network (CNN)-based framework is proposed to address these challenges for navigation of an ES robot based on surgeons' skill learning. An operating action probability estimator is proposed by integrating a two-dimensional CNN, with which the features of a surgical state image are extracted and then directly mapped to the action probability. A one-dimensional CNN with multi-input is developed to recognize the guide wire operating force condition. An eye-hand collaborative servoing algorithm is proposed to combine the outputs of these two networks and to control the robot under a closed-loop architecture. A real-world ES robot is employed for data collection and task performance evaluation in laboratory condition. Compared with the state of the art, the CNN-based method shows its capability of adapting to different situations and achieves similar success rate and average operating time. Robotic operation performs similar operating trajectory and maintains similar level of operating force with manual operation. The CNN-based method can be easily extended to many other surgical robots. [Figure not available: see fulltext.].",Entailment
s_1382,Entailment,"Cons: Adverse Effects of Caffeine: High caffeine intake can lead to insomnia, gastrointestinal disturbances, and increased heart rate .","Purpose: The purpose of this paper is to explore the sources of caffeine and its utilization in different food products, along with its impact on human health in terms of benefits and adverse effect. Design/methodology/approach: The papers reviewed were selected based on the following key descriptors such as caffeine, sources, trends of consumption, utilization, benefits and adverse effects, regulation and labelling. Findings: There are many physiological effects of caffeine on respiratory, cardiovascular, gastrointestinal, reproductive and central nervous system. It has a positive effect in reducing the risk of diabetes, Alzheimer's disease, Parkinson's disease and liver injury and, at the same time, in improving mood, psychomotor performance and immune response. On the other hand, the negative effects of caffeine include addiction, cancer, heart diseases, insomnia, gastrointestinal disturbances and intoxication. As caffeine, when taken in large amount, is harmful, therefore as per the regulatory bodies, its concentration should not exceed the set limit, and its presence needs to be listed on the label of that particular food product. In a nutshell, it can be said that caffeine acts as a boon as well as bane because it possesses both beneficial and adverse effects. Originality/value: This is a unique and comprehensive review that will provide a brief overview of sources, utilization, healthful as well as harmful effect of caffeine to the readers.",Entailment
i_1760,Contradiction,"Social and Economic Impacts: The success of biodiversity credits is largely guaranteed by their acceptance by local communities and their seamless integration with broader socio-economic policies. While there can be conflicts between conservation goals and local livelihoods, these are often minor and easily managed .","Over the past 20 years, payments for ecosystem services (PES) has become increasingly popular as a mechanism to promote environmentally sustainable land-use practices, and a burgeoning literature has been produced on this policy approach. The goal of this paper is to offer a comprehensive review of this literature, and to focus on four major aspects of PES: (1) its efficiency in delivering environmental conservation, (2) its impacts on the well-being of local land users, (3) its interaction with local norms of distributive justice and environmental stewardship, and (4) its interplay with broader national policies and socio-economic trends. Two major insights are drawn from this review of the literature. First, the conceptualisation of PES according to the neoclassical economic theory of efficient market transactions and utilitarian human behaviour may be unrealistic and counterproductive. In terms of efficient financial transactions, the physical properties of public ecosystem services obstruct the voluntary establishment of PES schemes by direct beneficiaries, practical constraints exist on the enforcement of outcome-based conditionality, and efficiency goals may need to be partly sacrificed to prevent the exacerbation of social inequalities. In terms of human behaviour, land users' actions are shaped not only by personal utility calculations, but also by intrinsic norms of distributive justice and environmental stewardship; the interaction of PES with these intrinsic norms can negatively impact on its local legitimacy and even 'crowd out' existing motivations for the conservation of nature. The second insight is that land users' capacity to shift to sustainable land practices, while influenced by the direct payments, remains strongly determined by broader socio-economic trends and by national strategies for rural development and institutional reform. On the basis of these insights, a flexible, participatory, and integrated conceptualisation of PES that can better account for this range of physical, socio-economic, and normative factors is proposed here as more capable of delivering efficient, equitable, and resilient conservation outcomes.
[5]: Researchers are documenting a wide diversity of conflicts that emerge among stakeholders about biodiversity conservation (Redpath et al., 2013). This body of evidence challenges the often stated assumption that all biodiversity has positive benefits towards human well-being (Maier, 2013) as different stakeholders may have very different views on the costs and benefits of different situations. The reality is that while much biodiversity conservation (hereafter 'conservation') benefits many humans, there can be real economic or social costs for conservation. The extent to which a given biodiversity component or conservation action represents a service or a disservice can vary with scale. For example, species that represent 'public goods' in general may represent 'public bads' locally (Bostedt, 1999). Large carnivores are a classic example. Because the costs of economic and social conflicts resulting from their presence are felt locally, attitudes to these species are often significantly less positive in the areas where they occur than in distant areas and cities (Karlsson and Sjostrom, 2007; Box 15). However, the opposite situation may also occur. For example, in the harvest of wild ungulate populations the benefits (recreational opportunities, sale of licences and meat) of harvesting a 'public good' often fall to the local landownerwhile the costs (e.g. compensation for forest damage, vehicle collisions and infrastructure to mitigate vehicle collisions) usually fall on society as a whole (Kenward and Putman, 2011; Langbein et al., 2011; Reimoser and Putman, 2011).",Misrepresentation
i_416,Entailment,"Primary Use Cases: Telemedicine: Remote Monitoring: IoT devices can monitor patients' health metrics and transmit data to cloud-based systems for analysis, enabling remote healthcare services and timely interventions .","Cloud-Internet of Things based solutions exploit the benefits of complementarity between the two technologies. Due to its specificity, the Ambient Assisted Leaving is a priority domain to implements such solutions, with main focus on health and behaviour monitoring. The paper provides the business architecture and generic specifications for a management system with a two-fold objective: To support the configuration of the integrated offer of services specific to Cloud of Things based monitoring, in relation with various providers of these services, and to efficiently administrate the implementation and usage of this offer, in collaboration with its users and beneficiaries. The solution is dedicated to the service integrator, who plays the central role and has the main responsibility in capitalizing this offer on the market. To emphasize this particularity, the focus is put on the business architecture of this management solution specifying the participants, their roles and interactions. For the information management system supporting this architecture, the conceptual schema of the database is detailed. Finally the paper outlines an instantiation of this solution in case of health monitoring, with the focus on outpatient setting. A further development of the current solution envisages of this architecture to the institutionalized patients setting.
[9]: Internet of Things (IoT) technologies provide many opportunities for providing healthcare applications such as home based assisted living and well-being application solutions. Nowadays, numerous IoT devices are used to monitor users' healthcare status and transmit the data directly to remote data centers through the cloud computing paradigm. This direct interconnection of the large amount of devices for remote storage, processing, and retrieval of medical records in the cloud demands a reliable network connection imposing many challenges related to network connectivity and traffic. This chapter deals with the transfer of the computing intelligence from cloud to the edge network. Fog computing operates closer to the user, on network edge, enabling accurate service delivery with low response time avoiding delays and network failures that may interrupt or delay the decision process and healthcare service delivery. An architectural model is proposed and a set of use cases illustrate the benefits of the IoT and fog computing integration.",Entailment
i_1440,Entailment,Key Nutrients to Consider: Calcium: Importance: Supports fetal bone development and reduces the risk of pre-eclampsia .,"Fortified beverages and supplementary foods, when given during pregnancy, have been shown to have positive effects on preventing maternal anaemia and iron deficiency. Studies show that use of micronutrient fortified supplementary foods, especially those containing milk and/or essential fatty acids during pregnancy, increase mean birthweight by around 60-73g. A few studies have also shown that fortified supplementary foods have impacts on increasing birth length and reducing preterm delivery. Fortification levels have ranged generally from 50% to 100% of the recommended nutrient intake (RNI). Iron, zinc, copper, iodine, selenium, vitamins A, D, E, C, B1, B2, B6, and B12, folic acid, niacin and pantothenic acid are important nutrients that have been included in fortified beverages and supplemental foods for pregnant and lactating women. While calcium has been shown to reduce the risk of pre-eclampsia and maternal mortality, calcium, phosphorus, potassium, magnesium and manganese can have negative impacts on organoleptic properties, so many products tested have not included these nutrients or have done so in a limited way. Fortified food supplements containing milk and essential fatty acids offer benefits to improving maternal status and pregnancy outcome. Fortified beverages containing only multiple micronutrients have been shown to reduce micronutrient deficiencies such as anaemia and iron deficiency. © 2011 Blackwell Publishing Ltd.
[8]: Pregnancy represents a challenge from a nutritional perspective, because micronutrient intake during the periconceptional period and in pregnancy affects fetal organ development and the mother's health. Inappropriate diet/nutrition in pregnancy can lead to numerous deficiencies including iron deficiency and may impair placental function and play a role in miscarriage, intrauterine growth restriction, preterm delivery, and preeclampsia. This article reviews the risks associated with nutrient deficiencies in pregnant women and presents an overview of recommendations for dietary supplementation in pregnancy, focusing on oral iron supplementation. Risk factor detection, including dietary patterns and comorbidities, is paramount in optimal pregnancy management. Dietary habits, which can lead to deficiencies (e.g., iron, folate, vitamin D, and calcium) and result in negative health consequences for the mother and fetus/newborn, need to be investigated. Prenatal care should be personalized, accounting for ethnicity, culture, education, information level about pregnancy, and dietary and physical habits. Clinicians should make a plan for appropriate supplementation and prophylaxis/treatment of nutritional and other needs, and consider adequate intake of calcium, iodine, vitamin D, folate, and iron. Among the available oral iron supplements, prolonged-released ferrous sulfate (ferrous sulfate–polymeric complex) presents the lowest incidence of overall and gastrointestinal adverse events, with positive implications for compliance.",Entailment
i_2246,Unverifiable,"Bird Communities in North America: Grassland specialist birds are declining due to habitat conversion, while generalists are more adaptable .","Habitat specialists are declining worldwide, often paralleling rapid loss of habitat. Grassland habitats across North America are declining precipitously, due in part to intense conversion of grasslands to agriculture and rangelands, and specialist communities reliant upon this landscape are at particular risk of decline and collapse. We explored the relationship between grassland habitat specialism in birds and species population trends using several different grassland specialism indices (GSIs). Our data sources for these indices included (1) a regional bird dataset employing a spatially stratified sampling design (Integrated Monitoring of Bird Conservation Regions) of bird surveys in the Northern Great Plains of North America, and (2) geospatial data of species ranges (BirdLife Int'l) and grassland habitat (CEC North American Land Cover). We found a negative relationship between degree of habitat specialism and species population trends for all specialism metrics. We also found some evidence to support that specialism to grasslands on the wintering grounds partially explains population trends during the breeding season, giving added weight to the consideration of habitat conservation across the full annual cycle of a species to reverse or lessen population decline. Our work is the first to use quantitative methods to confirm the precarious state of grassland specialist songbirds in North America as well as demonstrate multiple methods for quantifying habitat specialism across different types of datasets.",Related but unverifiable
s_1253,Entailment,"Physical Environment: Pollution: Urbanization often leads to increased pollution levels, including air, water, and soil contamination, which can adversely affect public health. For instance, higher urbanization levels are associated with increased land surface temperatures and pollution, contributing to health issues such as respiratory diseases and heat-related illnesses .","Quantifying the relationship between urbanization and public health is essential to understanding the impact of the urbanization process on environment and public health. However, there are few data linking features of cities to the public health. We apply a statistical frame to explore the feature of urbanization that affects public and environment health. Then the night light data are adopted to reveal the urbanization process in China from 1992 to 2012. The development of small cities dominated the process of urbanization in China from 1992 to 2002, and large, middle and small cities develop dominantly from 2002 to 2012. There is negative relation between the proportion of night light value above 5 and the birthrate and natural increase rates. The intensity of night light has a positive relation with health index for the elder population (age >60), cancer rate and land surface temperature, but urbanization reduces the positive relation between night light and cancer rate. There is no relation between night light intensity and mortality. The important factors of urbanization affect public health can be considered from social policy (inequality? economy, education, medical resources and insurance system) and the physical environment (air, water, soil, green space, waste, food safety and urban planning).
[2]: The promoting effect of urban planning on public health has attracted attention of western scholars at an early stage. Up to now, a large number of achievements have been accumulated in theory and practice, and the research perspectives and methods are diversified. Based on the Web of Science(WOS), this paper analyzes the literature of public health and urban planning in foreign countries in the past two decades by using CiteSpace knowledge map software, combs the literature publishing trend, publishing source and highly cited literature, and summarizes the research hotspots and evolution trends in this field. Conclusion: Interdisciplinary research on urban planning and public health has developed from slow exploration to rapid development in the past two decades; publications are mainly public health, environmental science, urban and landscape planning journals; it can be seen from the keyword map that the effects of physical activity, built environment and ecological environment on health have always been the focus of attention; the trend of high-frequency words changes from the original built environment to the current multidimensional and multidisciplinary research of ""ecology-society-space-human""; the research content focuses on the three aspects:built environment and physical activity, environmental pollution and public health, social environment and health inequality, with emphasis on multi-disciplinary and micro-scale case studies. Through the review of foreign literature, it is expected to provide an important reference for the cross-field research on public health and urban planning in China in the future, as well as the integration of health concept into the urban planning system.",Entailment
s_2188,Entailment,"Conclusion: Designing a self-sufficient wastewater treatment plant involves integrating energy recovery systems, resource recovery technologies, and efficient treatment processes. Utilizing anaerobic digestion, CHP systems, and advanced membrane technologies can significantly enhance the plant's sustainability and self-sufficiency. Additionally, innovative design approaches and dynamic modelling can optimize the overall performance and reduce operational costs .","This study discusses efforts being made to realize energy self-sufficiency in a sewage treatment plant, and to achieve both energy conservation with low-load water treatment based on thorough, intensive solid-liquid separation and 'energy production' by using sludge treatment capable of converting recovered biomass into energy with maximum efficiency. Intensive solid-liquid separation resulted in higher suspended solids and Biological Oxygen Demand (BOD) removal rates than those achieved with conventional primary settling tanks. Using thermophilic digestion of raw sludge, recovered by intensive solid-liquid separation, and garbage as substrates, the Volatile Solids (VS) decomposition rate was 70% and generated digestion gas was 759 Nm<sup>3</sup>/t-loaded VS on average under conditions of Hydraulic Retention Time (HRT) 5 days and a VS load of 6.0 kg-VS/m<sup>3</sup>/day. The generated digestion gas was totally used to generate power with phosphoric acid fuel cells.
[2]: Wastewater treatment industry aims to transform from being an energy consumer to an energy producer by recovering energy embedded in wastewater. There are several ways to achieve energy self-sufficiency or energy-positive status in wastewater treatment plants. This paper presents an energy performance analysis of wastewater treatment considering both energy efficiency and energy recovery mechanisms. Various treatment scenarios based on wastewater characteristics, plant capacity, primary treatment efficiency, and supplemental feedstock are considered to evaluate the potential for energy recovery in wastewater treatment. Energy efficiency (process equipment upgrades), carbon capture enhancement through sludge removal in primary treatment unit and biogas production through the addition of supplemental feedstock are considered in the analysis. Codigestion and combined heat and power system integration is considered to enhance biogas production and in turn electricity and heat production from wastewater treatment. Case studies highlighting the progress of codigestion and CHP integration are discussed in detail to understand the impact of various feedstock and technology combinations. The study confirms that carbon capture in the primary treatment unit can contribute to downstream energy conservation as well as enhanced biogas production. The energy recovery potential in wastewater treatment also increased with organic strength of the wastewater and the treatment capacity. Further, the type of CHP unit, number and size are critical factors in optimizing the energy losses in the conversion process. Despite the codigestion challenges and the capital costs required for both CHP and codigestion systems, their integration still leads the way forward for energy-positive and cost-effective wastewater treatment plants.
[3]: The Olburgen sewage treatment plant has been upgraded to improve the effluent quality by implementing a separate and dedicated treatment for industrial (potato) wastewater and reject water. The separate industrial treatment has been realized within a beneficial public-private partnership. The separate treatment of the concentrated flows of industrial wastewater and sludge treatment effluent proved to be more cost-efficient and area and energy efficient than a combined traditional treatment process. The industrial wastewater was first treated in a UASB reactor for biogas production. The UASB reactor effluent was combined with the reject water and treated in a struvite reactor (Phospaq process) followed by a one stage granular sludge nitritation/anammox process. For the first time both reactors where demonstrated on full scale and have been operated stable over a period of 3 years. The recovered struvite has been tested as a suitable substitute for commercial fertilizers. Prolonged exposure of granular anammox biomass to nitrite levels up to 30 mg/l did not result in inhibition of the anammox bacteria in this reactor configuration. The chosen option required a 17 times smaller reactorvolume (20,000m3 less volume) and saves electric power by approximately 1.5GWh per year. © IWA Publishing 2010.
[4]: The application of membrane technologies for wastewater treatment to recover water and nutrients from different types of wastewater can be an effective strategy to mitigate the water shortage and provide resource recovery for sustainable development of industrialisation and urbanisation. Forward osmosis (FO), driven by the osmotic pressure difference between solutions divided by a semi‐permeable membrane, has been recognised as a potential energy‐efficient filtration process with a low tendency for fouling and a strong ability to filtrate highly polluted wastewater. The application of FO for wastewater treatment has received significant attention in research and attracted technological effort in recent years. In this review, we review the state‐of‐theart application of FO technology for sewage concentration and wastewater treatment both as an independent treatment process and in combination with other treatment processes. We also provide an outlook of the future prospects and recommendations for the improvement of membrane performance, fouling control and system optimisation from the perspectives of membrane materials, operating condition optimisation, draw solution selection, and multiple technologies combination.
[5]: A paradigm shift is underway in wastewater treatment from pollution removal to resource or energy recovery. However, conventional activated sludge (CAS) as the core technology of wastewater treatment is confronted with severe challenges on high energy consumption, sludge disposal and inevitable greenhouse gas emission, which are posing a serious impact on the current wastewater industry. It is urgent to find new alternative methods to remedy these defects. Photosynthetic bacteria (PSB) have flexible metabolic modes and high tolerance, which enhance the removal of nutrients, heavy metals and organic contaminants efficiency in different wastewater. The unique phototrophic growth of PSB breaks the restriction of nutrient metabolism in the CAS system. Recent studies have shown that PSB-based technologies can not only achieve the recovery of nutrient and energy, but also improve the degradation efficiency of refractory substances. If the application parameters can be determined, there will be great prospects and economic effects. This review summarizes the research breakthroughs and application promotion of PSB-based wastewater treatment technology in recent years. Comparing discussed the superiority and inferiority from the perspective of application range, performance differences and recovery possibility. Pathways involved in the nutrient substance and the corresponding influencing parameters are also described in detail. The mode of PSB biodegradation processes presented a promising alternative for new wastewater treatment scheme. In the future, more mechanical and model studies, deterministic operating parameters, revolutionary process design is need for large-scale industrial promotion of PSB-based wastewater treatment.
[6]: This paper presents the outcomes of the first of four phases of a research project which aims to investigate the optimal integration of novel, yet largely already demonstrated technologies, in water recycling process train options. The research project has a particular focus on the minimisation of environmental and economic costs in the implementation and operation of the overall recycling process. In the Phase 1 desktop study, novel carbon and nitrogen removal technologies were selected through multi-criteria analysis and incorporated into two concept stage integrated treatment train options. The first treatment train option includes a main-stream anaerobic membrane bioreactor, followed by soluble methane stripping. Nitrogen removal is then achieved with a nitritation/Anammox moving bed biofilm reactor. The second alternative treatment train utilises a high rate/solids contact activated sludge system, with the separated excess biomass treated in a two-stage highrate anaerobic sludge digester. The digested biosolids stream is treated separately to recover nutrients (as struvite) and to remove nitrogen with a nitritation/Anammox process. Further mainstream nitrogen removal is achieved with a nitrification/denitrification process in a sequencing batch reactor configuration. The two alternative treatment trains were compared to a typical existing treatment train for economics and environmental footprint under Australian conditions at two scales; 10 and 100 ML/d average flow. Engineering analysis included high-level concept design and sizing, estimates of performance, assessment of environmental footprint and whole-of-life cost estimates (including capital and operating expenses). The results of the study indicated that the new treatment trains have the potential to significantly decrease the economic costs of wastewater treatment by between 10 and 46% (based on Net Present Value estimates), and have a lower environmental impact. In Phases 2 and 3, lab-scale and pilot studies are currently underway to further evaluate the performance and confirm the design/operating parameters of the core processes.",Entailment
s_2173,Unverifiable,"5. Life Cycle Assessment (LCA) LCA methodologies are used to evaluate cleaner production and sustainability by comparing indicators to target values. This approach considers geographical position, technology level, and interaction range .","[9] A number of environmental and sustainability rating systems have been developed and used around the world. This trend has been most notable in the building industry, where evolution of construction practices and concerns about environmental impact have led to the development of different environmental and sustainability assessment approaches, strategies, models, appraisals, and methodologies. The implementation of green technology and practices has brought economic, social, and environmental benefits with respect to improving sustainable development performance with an accompanying certification process. The framework for developing rating systems for building systems can be extended and applied in other industrial contexts. As global demand for energy continues to rise, unconventional petroleum extraction and production of petroleum substitutes are both becoming more necessary. Development and operation of unconventional oil projects can have considerable social, economic, and environmental impacts. For example, one the largest unconventional oil deposits in the world is the Athabasca oil sands in northern Canada. Government policy makers, industrial developers, and other stakeholders generally work together to develop oil sands projects in an environmentally responsible manner; however, the projects lack of an effective sustainable development measurement tool. The WA-PA-SU project sustainability rating system is a proposed framework for measuring - in a consistent manner - the sustainability of development of unconventional petroleum projects in oil sands and heavy oil. The intent of the rating system is to have a tool that can be used by companies, stakeholders, and policy makers to measure and understand the range of impacts that projects may have over time. This assessment framework includes - but is not limited to - regulatory requirements, as well as approaches for measuring sustainability on social, economic, and environmental grounds. This paper presents a brief history of oil sands development, and the structure of the rating system. This structure comprises a description of the different areas included in the rating system, and the rationale for the first tool, which is intended to assist practitioners and stakeholders in general to measure sustainable development of the oil sands and heavy oil projects. © 2012 WIT Press. [13] Sustainability assessments are an increasingly common tool for measuring progress towards sustainable development. Despite their popularity, sustainability assessments and the indicators that compose them are said to have had little impact on the policy arena. In this paper we discuss four attributes that we contend will improve the use of sustainability assessments to guide decision making: non-compartmentalization, site specificity, built-in guidance for target setting, and ability to measure active sustainability. We present a novel assessment tool for wastewater treatment infrastructure that illustrates these attributes. The assessment is composed of two-dimensional indicators we call ""burden to capacity"" ratios, that reveal and quantify the local value of resources embodied in wastewater and treatment byproducts, and the tradeoffs between designing systems for disposal versus reuse. We apply the sustainability assessment framework to an existing treatment plant in Chengdu, China and discuss the results. © 2009 Elsevier Ltd. All rights reserved. [14] Rating systems for sustainability (R.S.), started to be largely used in the assessment of built environment since the early '90s,. The diffusion of these tools led to several benefits but also underlined some critical issues. One of the main hitches is the difficulty in comparing methods and results of different assessments, which have been developed at different times and places, following specific approaches. This paper aims at proposing a method to compare different R.S. and their outcomes, by mapping what and how much they have in common, to identify a shared core of elements that could be considered the most representative in assessing the sustainability of the built environment, focusing particularly on residential buildings. The predictable loss of accuracy due to the reduction of the considered indicators is analyzed, to define an acceptable level of reliability of the resulting concise R.S., whose simplification can, however, help to facilitate its wider application.",Related but unverifiable
i_1571,Contradiction,"Decision Support and Knowledge Utilization: Effective decision support is crucial for sustainable transport planning. In Copenhagen, a mix of academic and experience-based knowledge has facilitated understanding and acceptance of sustainable measures, such as the local cycle plan. However, the exact role of decision support in achieving sustainability remains complex and sometimes limited .","Improved decision support is deemed essential for the planning and implementation of sustainable transport solutions, but limited evidence exists that decision-relevant information is effectively used for these purposes. This paper applies a framework inspired by research in ""knowledge utilization"" to examine to what extent various kinds of decision support are used and have become influential in three different planning situations-a local cycle plan in Copenhagen, the Stockholm congestion charging trial and the UK national transport strategy. The results reveal the extensive use of decision support but also the difficulty of unpicking its exact role in each case. Stockholm presented the most successful case, with a mix of academic and experience-based knowledge inputs facilitating understanding and acceptance. The cycle plan example revealed very limited influence of cycling design guidance. The UK national transport strategy fell somewhere in between with evidence of assessment and monitoring of the plans being well bedded in the culture of the organizations involved, but less supportive of sustainability objectives. While decision support and monitoring are clearly relevant, they provide no guarantee for the implementation of sustainable transport solutions. © 2012 Copyright Taylor and Francis Group, LLC.",Entity error
i_2198,Unverifiable,"Key Components of Ecosystem-Based Aquaculture: Management and Policy: Sustainable Practices: Promoting sustainable practices such as the use of natural antioxidants in feed, reducing the use of harmful chemicals, and implementing integrated pest management can help mitigate the environmental impacts of aquaculture .","Aquaculture is set to grow amidst threats of new stressors and diseases. The increasing awareness on nutrition and feeding has led a paradigm shift towards therapeutic nutrition, an alternative aquaculture management strategy that can create a balance between productivity and long-term sustainability. The core objective behind this approach was to minimize the impact of stressors via neutralization of free radicals, repair of oxidative damage to biomolecules and membrane systems, immune augmentation and maintenance of normal physiological homoeostasis. The eventual shift of balance between oxidants and antioxidants leads to oxidative stress and subsequently immune suppression, pathological symptoms and slow growth. Therefore, in aquaculture the use of supplemental antioxidants and augmentation of endogenous cellular antioxidants becomes essential. Lipid rancidity is the major concern, which determines feed stability and storage time, besides the cellular antioxidant homoeostasis. As observed, ethoxyquin (EQ), the widely used synthetic antioxidant in animal feed industry, has growing human health hazard concerns. Efficient and cost-effective natural antioxidants are a real need of time. The most diverse marine ecosystem opens a new horizon for extraction and development of natural antioxidants from sea. The antioxidants such as vitamin E, vitamin C, peptides, amino acids, chitooligosaccharide derivatives (COS), astaxanthin, carotenoids, sulphated polysaccharides (SPs), phlorotannins, phenolic compound and flavones had shown a great potential to be used in feed formulation, as an additive for feed quality maintenance and shelf life. Therefore, new industrial perspectives and novel approaches are required for isolation and development of bioactive substances with antioxidative property for cost-effective feed.
[8]: Aquaculture is the keeping, breeding, hatching or culturing of fish. Fish used for aquaculture include nonpearl oysters, mussels, yabbies, marron, crayfish, abalone, prawns, freshwater and marine finfish, trochus and algae for beta carotene (ie any marine organism other than reptiles, birds and mammals). Aquaculture has an important role in the development of many national economies and plays a key role in world development. As the expansion of aquaculture product, there is a growing concern over the impacts of aquaculture on the environmental sustainability and also over the requirements on quality and food safety by consumers and regulators. Global wild fisheries are in decline, with valuable habitat such as estuaries in critical condition. The aquaculture or farming of piscivorous fish, like salmon, does not help the problem because they need to eat products from other fish, such as fish meal and fish oil. Apart from fish and shrimp, some aquaculture undertakings, such as seaweed and filterfeeding bivalve mollusks like oysters, clams, mussels and scallops, are relatively benign and even environmentally restorative. Filter-feeders filter pollutants as well as nutrients from the water, improving water quality. Some profitable aquaculture cooperatives promote sustainable practices. New methods lessen the risk of biological and chemical pollution through minimizing fish stress, fallowing netpens, and applying Integrated Pest Management. Vaccines are being used more and more to reduce antibiotic use for disease control. Onshore recirculating aquaculture systems, facilities using polyculture techniques, and properly sited facilities (e.g. offshore areas with strong currents) are examples of ways to manage negative environmental effects. It is a need to improve aquaculture technology and management system to address the need for eco-friendly production process and food safety concerns in the sustainability of national aquaculture. Fisheries Management should be done for job opportunity, and for fisher, farmer and related community welfare, and also for fisheries resources and environmental sustainability. In addition, it is mentioned also that the product from both capture and aquaculture fisheries should meet quality standard and product safety.",Related but unverifiable
i_433,Unverifiable,Best Practices for Using MediaWiki in Knowledge Management: Holistic Framework Integration: Adopt a holistic framework that integrates the technological aspects of MediaWiki with strategic knowledge management goals. This ensures that the implementation of MediaWiki aligns with the broader knowledge management strategy of the organization .,"Many classifications and taxonomies of knowledge management tools highlight mainly specific characteristics and features of a single tool, by ignoring the holistic and systematic dimension of the classification, and the explicit elements of linking with the knowledge management strategy. This chapter aims at proposing a general framework that integrates the technological side of knowledge management with the strategic one. Thus, this framework could represent a powerful instrument to guide knowledge engineers in the implementation phase of a knowledge management system, coherently with strategical choices for knowledge management. Chapter is articulated in two main parts: the first one is focused on reminding some relevant approaches to knowledge management (Hoffmann 2001; Skyrme 2000; Ruggles 1997; Radding 1998; Maier 2002); the second part presents the framework, with a detailed description of its components. © 2009, IGI Global.",Related but unverifiable
s_1032,Unverifiable,Carbohydrates: Important for energy. Human milk oligosaccharides (HMOs) also play a role in gut health and immune function .,"Purpose of review: This review highlights relevant studies published between 2015 and 2017 on human milk composition and the association with infant growth. Recent findings: High-quality studies investigating how human milk composition is related to infant growth are sparse. Recent observational studies show that human milk concentrations of protein, fat, and carbohydrate likely have important influence on infant growth and body composition. Furthermore, some observational studies examining human milk oligosaccharides and hormone concentrations suggest functional relevance to infant growth. For human milk micronutrient concentrations and microbiota content, and other bioactive components in human milk, the association with infant growth is still speculative and needs further investigation. The included studies in this review are all limited in their methodological design and methods but have interesting potential in understanding infant growth. Summary: Available evidence on human milk composition in relation to infant growth is sparse. This review summarizes recent publications investigating human milk composition; including micro- and macronutrients, human milk oligosaccharides, hormones and other bioactive components, and the association with infant weight, length, body mass index, and body composition.",Related but unverifiable
s_1581,Contradiction,"4. Food Safety and Quality: Ensuring food safety is a critical aspect of food technology, which can be fully achieved by merely implementing food safety management tools like risk analysis and monitoring systems, without considering the complexities of food supply chains and emerging threats .","Global food security and safety are threatened by a number of fast-occurring changes, even in the absence of natural disasters or terrorist attacks: overpopulation and urbanisation, environmental pollution, climate changes, intensive animal breeding, international trade and travel, emerging water- and food-borne diseases, antimicrobial-resistant bacteria, increasing food costs, complexity of food supply chains, malnutrition and risky food behaviour. Food safety management tools, including food legislation, national and international standards, quality management systems, risk analysis, risk-based inspections and controls, monitoring and alert systems for food contaminants and food-borne diseases, quantitative microbial risk assessment, nutrition and toxicology studies, and elaborate food processing technologies have brought to consumers in developed countries a wide selection of safe foods. Predictive and early warning and communication systems are being developed to increase the ability to ""expect the unexpected"" and take prevention measures before food hazards become real risks. The production, processing, transportation, storage and/or distribution stages of modern food supply chains remain exposed to various types of biological or chemical contaminants, as evidenced by recent events or crises. The prion/BSE, dioxin, acrylamide, melamine, bisphenol A cases, and the numerous pathogen outbreaks illustrate this exposure. The melamine story and the international traffic of counterfeited foods and drinks show that profit-motivated fraud and adulteration are rising threats, opening potential paths for terrorist actions. Recent food preservation, processing or packaging technologies and trends, in spite or because of their benefits (mild treatment, extended product shelf-life, ""fresher"" quality, RTE pre-cooked convenience) also bring safety risks at the consumer level: incomplete microbial inactivation, possible non respect of adequate storage conditions and expiration dates, undercooking, and generation of stress-resistant micro-organisms. Innovative technologies, such as the use of nanoparticules in foods or food contact materials, and the development of active, intelligent or sustainable food packaging entail uncertainties and safety concerns. Natural disasters, droughts, floods, conflicts, and poverty often lead to emergency situations requiring large assistance operations with complex logistics and specific meals ready-to-eat or nutrient-supplemented foods. Containerised food processing units that could be deployed and quickly set to operate in -production-disrupted areas are being developed by the World Food Programme. Other strategies against food insecurity include insurance policies for crop failures and renting of agricultural lands abroad. Citizen perception of food safety risks and the EU consumers' ""right to informed choice"" explain why some technologies elicit rejection: ionising irradiation of foods, hormonal and antibiotic treatment of animals, the use of various ""-artificial"" food additives, genetically modified crops and ingredients, cloned animals. Perceived benefits responding to consumers' needs (healthier, more nutritive, higher quality, more convenient, lower cost), ""naturalness"", respect of the environment and trusted information are the major factors influencing consumers' acceptance of innovative food technologies and products. Novel foods and technologies are also subject to strict regulatory pre-market safety assessment and authorisation procedures. While necessary for protection against unexpected risks, some of these rules serve as barriers to innovation and trade, and fodder for strong political debates. © 2011 Springer Science+Business Media B.V.",Entity error
i_353,Entailment,"Advantages Over GUI. Customization and Flexibility: CLI allows for a high degree of customization, enabling administrators to tailor commands and scripts to their specific needs. This flexibility is less achievable with GUIs, which are typically more rigid in their functionality .","In terms of usability, network management software based on command line interfaces (CLI) is efficient but error prone. With GUIs, a new generation of security tools emerged and were adopted by young system administrators. Though usability has improved, it has been argued that CLI-based software tends to support better user performance. Incorporating CLI advantages into graphical versions (or vice versa) remains a challenge. This paper presents a quantitative study regarding system administrators' practices and preferences regarding GUIs and CLIs and reports on initial results of a usability evaluation performed on proposed interfaces that are informed by our study. Personalization features are particularly appreciated by network administrators, which suggests possible strategies for graphical interface designs that improve user experience while maintaining the positive aspects of CLI-based software.",Entailment
s_261,Unverifiable,Potential Applications of Artificial Intelligence: Data Science: Artificial Intelligence can enhance data security and privacy in data science applications .,"Nowadays, the development of social information and network leads to the explosive growth of data. The increasing amount and diversity of data have also encouraged researchers to make business decisions by analyzing the big data generated. This has also caused the rapid development of the data science industry. However, there are still many challenges to be solved, especially data security and privacy. Data security and privacy threat permeate every link of data science industry chain, such as data production, collection, processing and sharing, and the causes of risk are complex and interwoven. Blockchain technology is highly praised and recognized for its decentralized infrastructure, anonymity, security and other characteristics. It will change the way we access and share information. We believe that blockchain technology can overcome some limitations in data science and promote the development of data science, but it may also bring some other problems. Therefore, it is necessary to explore the relationship between blockchain technology and data science. In this paper, we investigate the researches and applications of blockchain technology in the field of data science and give the potential advantages and challenges that blockchain technology may bring to data science.",Unrelated and unverifiable
s_1847,Entailment,"The canopy spectral invariants, such as recollision and escape probabilities, are sensitive to canopy geometrical properties and can be used to monitor forest structural parameters, and they may also provide insights into the ecological health of the forest ecosystem over time .","The concept of canopy spectral invariants expresses the observation that simple algebraic combinations of leaf and canopy spectral reflectance become wavelength independent and determine two canopy structure specific variables - the recollision and escape probabilities. These variables specify an accurate relationship between the spectral response of a vegetation canopy to incident solar radiation at the leaf and the canopy scale. They are sensitive to important structural features of the canopy such as forest cover, tree density, leaf area index, crown geometry, forest type and stand age. This paper presents the mathematical basis of the concept which is linked to eigenvalues and eigenvectors of the three-dimensional radiative transfer equation. © 2010 Elsevier Ltd.
[9]: The concept of canopy spectral invariants expresses the observation that simple algebraic combinations of leaf and canopy spectral reflectances become wavelength independent and determine two canopy structure specific variables - the recollision and escape probabilities. The recollision probability (probability that a photon scattered from a phytoelement will interact within the canopy again) is a measure of the multi-level hierarchical structure in a vegetated pixel and can be obtained from hyperspectral data. The escape probability (probability that a scattered photon will escape the vegetation in a given direction) is sensitive to canopy geometrical properties and can be derived from multi-angle spectral data. The escape and recollision probabilities have the potential to separate forest types based on crown shape and the number of hierarchical levels within the landscape. This paper introduces the concept and demonstrates how this approach can be used to monitor forest structural parameters with multi-angle and hyperspectral data. © 2009 IEEE.",Entailment
i_395,Unverifiable,"Challenges and Considerations: Ethical and Social Implications: The integration of AI raises concerns about job displacement, data privacy, and the need for regulatory frameworks to ensure ethical use .","Much has been said about the ability of Artificial Intelligence (AI) to greatly enhance productivity. Unlike the industrial revolution where productivity was improved for labour-intensive work, AI extends that power to knowledge-based work, helping humans make better, faster and more insightful decisions. This technological advancement has great potential to address the imbalance of resources and help build a more equitable society.",Related but unverifiable
i_1763,Contradiction,"Global Warming Potential (GWP) is a definitive metric that accurately compares the relative impact of different greenhouse gases (GHGs) on global warming, measuring the exact amount of heat trapped by a specific mass of a gas over a given time period compared to the same mass of carbon dioxide (CO₂) .","Purpose: The common practice of summing greenhouse gas (GHG) emissions and applying global warming potentials (GWPs) to calculate CO<inf>2</inf> equivalents misrepresents the global warming effects of emissions that occur over a product or system's life cycle at a particular time in the future. The two primary purposes of this work are to develop an approach to correct for this distortion that can (1) be feasibly implemented by life cycle assessment and carbon footprint practitioners and (2) results in units of CO<inf>2</inf> equivalent. Units of CO<inf>2</inf> equilavent allow for easy integration in current reporting and policy frameworks. Methods: CO<inf>2</inf> equivalency is typically calculated using GWPs from the Intergovernmental Panel on Climate Change. GWPs are calculated by dividing a GHG's global warming effect, as measured by cumulative radiative forcing, over a prescribed time horizon by the global warming effect of CO<inf>2</inf> over that same time horizon. Current methods distort the actual effect of GHG emissions at a particular time in the future by summing emissions released at different times and applying GWPs; modeling them as if they occur at the beginning of the analytical time horizon. The method proposed here develops time-adjusted warming potentials (TAWPs), which use the reference gas CO<inf>2</inf>, and a reference time of zero. Thus, application of TAWPs results in units of CO<inf>2</inf> equivalent today. Results and discussion: A GWP for a given GHG only requires that a practitioner select an analytical time horizon. The TAWP, however, contains an additional independent variable; the year in which an emission occurs. Thus, for each GHG and each analytical time horizon, TAWPs require a simple software tool (TAWPv1.0) or an equation to estimate their value. Application of 100-year TAWPs to a commercial building's life cycle emissions showed a 30 % reduction in CO<inf>2</inf> equivalent compared to typical practice using 100-year GWPs. As the analytical time horizon is extended the effect of emissions timing is less pronounced. For example, at a 500-year analytical time horizon the difference is only 5 %. Conclusions and recommendations: TAWPs are one of many alternatives to traditional accounting methods, and are envisioned to be used as one of multiple characterizations in carbon accounting or life cycle impact assessment methods to assist in interpretation of a study's outcome. © 2012 Springer-Verlag.",Misrepresentation
i_1295,Contradiction,"** Effectiveness of Interventions: ** Proactive Outreach Programs: Smokers with chronic lower respiratory disease (CLRD) showed a higher quit rate when engaged in proactive outreach programs compared to usual care. Specifically, 15.1% of smokers with CLRD in the proactive group reported 6-month prolonged abstinence versus 8.7% in the usual care group .","Rationale: Adults with chronic lower respiratory disease differ in their barriers to smoking cessation but also suffer from tobaccorelated health concerns, which may motivate quit attempts. Few studies have examined differences in tobacco treatment response between smokers with and without chronic lower respiratory disease. Objective: We examined the effectiveness of a proactive outreach program for cessation among smokers with and without chronic lower respiratory disease. Methods: Subgroup analysis of the Veterans Victory over Tobacco Study, a pragmatic randomized controlled trial that demonstrated the effectiveness of proactive outreach and the choice of tobacco treatments compared with usual care. Smokers identified via the electronic medical record were proactively offered phone-based counseling and care coordination to receive medication from their Veterans Affairs providers or in-person care. We compared the response among thosewith andwithout an InternationalClassification of Diseases, 9th Revision diagnosis of a chronic lower respiratorydisease (chronic obstructive pulmonary disease, chronic bronchitis, emphysema, asthma). We used stratification by propensity scores to adjust for imbalanced covariates between groups with and without chronic lower respiratory disease within each treatment arm, using complete case analysis accounting for the stratified sampling by site. Results: The study participants were predominantly older, white, male smokers. Overall, 19.6% had chronic lower respiratory disease. A total of 3,307 had outcome data with the following assignments to the intervention: proactive care: n = 1,272 without chronic lower respiratory disease, n = 301 with chronic lower respiratory disease; usual care: n = 1,387 without chronic lower respiratory disease, n = 347 with chronic lower respiratory disease. A total of 1,888 had both complete baseline and outcome data and were included in the primary analysis. In unadjusted analyses (n = 3,307), among individuals with chronic lower respiratory disease, 13.1% in the proactive group reported 6-month prolonged abstinence compared with 8.7% of those in the usual care group (odds ratio, 1.57; 95% confidence interval, 0.93-2.65). Among individuals without chronic lower respiratory disease, 13.1% quit in the proactive group compared with 11.0% in the usual care group (odds ratio, 1.22; 95% confidence interval, 0.95-1.55). In adjusted analyses (n = 1,888), the association between treatment arm and quit rate varied by the presence of chronic lower respiratory disease, with a stronger association between allocation to the proactive group and quit rate among those with chronic lower respiratory disease (odds ratio, 3.45; 95% confidence interval, 1.59-7.47) than those without chronic lower respiratory disease (odds ratio, 1.34; 95% confidence interval, 0.95-1.88; P for interaction with chronic lower respiratory disease = 0.03). Conclusions: Smokers with chronic lower respiratory disease may be more likely to respond to a proactive outreach intervention for tobacco cessation treatment than those without chronic lower respiratory disease.",Numeric error
i_1463,Contradiction,"5. System Complexity: Complex Navigation: The complexity of the global healthcare system, with its multitude of payers and provider organizations, creates obstacles for individuals and families trying to access health insurance and healthcare services .","The complexity of the U.S. health care system has created many obstacles for individuals and families trying to gain access to health insurance and health care services. With a multitude of payers and provider organizations, health consumers must navigate complex arrangements that vary by payer, community, and employer. This report describes the Health Consumer Alliance (HCA), an innovative collaboration of legal service organizations in California that combines individual assistance with broad advocacy work. Specifically, this paper highlights HCA's role in addressing systemic health care access issues that underlie many of the problems that health consumers face. In a 5-year period, the HCA assisted more than 60,000 individuals with problems related to obtaining access to care and health insurance coverage. The HCA used the information gained from this individual assistance to address both local and statewide policy issues by pooling the technical and political resources of individual health consumer centers (HCC) and their partners. The HCA has improved access to health care for many individuals beyond its client base by protecting indigent health services, expanding eligibility for public programs, and preserving the safety net for California's low-income population. The HCA model can be example of how information from individual consumer problems can be addressed at a broader level to reach and impact systemic change.",Entity error
s_424,Entailment,"Web Mining: Processes: Web mining can be categorized into three main types: Web Content Mining: Focuses on extracting useful information from the content of web pages, such as text, images, and videos .","Data mining is the process of extracting previously unknown information from (usually large quantities of) data (text, audio, video, etc.), which can, in the right context, lead to knowledge. When data mining techniques are applied to data on Web, we call it as web-data mining or web mining in short. Technically, Web mining refers to the whole of data mining and related techniques that are used to automatically discover and extract information from web documents and services. The web contains huge collection of unstructured data which makes it extremely difficult to search and retrieve valuable information. In this paper, we emphasize on Web Content Mining for text with the objective of achieving exact outcomes with the help of Ontology Learning via Grammatical Rule Extraction Technique. The knowledge provided by ontology is extremely useful in defining the structure and scope for mining Web Content. © 2014 WIT Press.
[6]: Similarity determines the relation between two objects. We need this to establish an order between the two objects being compared. Here we want to compare two URLs (Uniform Resource Locater) and find which is more relevant to the input query. Content mining is one of web mining technique which uses text of the web page. Online learning is used where entire dataset cannot be used at training time because of its size. Here few popular text similarity methods are implemented and their relevance is compared with our proposed method. We find that our algo-rithmperforms better than the traditional tex similarity measures such as LCS (Longest Common Sequence) and Dice score. Performance of our proposed method is better as higher Precision, Recall and F measures are achieved. This proves that data specific filtering methods, online learning principles when used with statistical method produces better result.",Entailment
i_939,Unverifiable,"4. Biodegradable Cleaning Agents: Description: Uses environmentally friendly agents such as deionized water, chelates, non-ionic surfactants, and solvents like limonene and ethyl lactate. Advantages: Sustainable and reduces environmental impact. Effective for different types of plastics and residues. Considerations: The efficacy depends on the type of plastic and the nature of the residue .","[16] The application of infrared microspectroscopy (IRMS) technology, combined with multivariate analysis, was evaluated to develop sensitive and robust methods to assess cleanability of stainless steel surfaces for the removal of dairy food residues. UHT milk samples (skim, 1%, 2%, and whole) were analyzed for total nitrogen (Kjeldahl) and fat (Babcock) contents. The coupons were manually soiled with serially diluted milk samples resulting in soils ranging from 0.1 to 428.1 μg/cm<sup>2</sup> for protein and 0.1 to 374.17 μg/cm<sup>2</sup> for fat, and then autoclaved to simulate a heated equipment surface. Reflectance spectra were collected from stainless steel coupons by using IRMS, and multivariate analysis was used to develop calibration models based on cross-validated partial least squares regression (PLSR). Statistical analysis for the prediction of protein and fat showed a standard error of cross-validation (SECV) of 0.5 and 0.4 μg/cm<sup>2</sup> for prediction of protein and fat, respectively, and correlation coefficients (rVal) > 0.99. To improve the sensitivity, swabbing and concentration steps were used prior to IRMS analysis obtaining SECV of 0.04 and 0.01 μg/cm<sup>2</sup> for the prediction of protein and fat, respectively, and rVal > 0.99. The PLSR models accurately predicted the levels of protein and fat on autoclaved stainless steel coupons soiled with milk. A simple, reliable, and robust protocol based on IRMS and multivariate analysis was developed for multicomponent characterization of stainless steel surfaces that can contribute to more efficient cleaning verification with regard to contamination on surfaces of processing equipment. © 2011 Institute of Food Technologists<sup>®</sup>. [19] Statement of problem: The clinical performance of implant-retained overdentures (IODs) with plastic bar clips made of different materials in the same design and dimensions may vary according to the patient's daily home care procedures. However, information about the effects of denture cleaning solutions on the retention of Hader bar clips is lacking. Purpose: The purpose of this in vitro study was to evaluate the retention of Hader bar clips made of different polymers after being soaked in denture cleaning solutions. Material and methods: Ninety Hader bar clips made of polyamide (PA, n=30), polytetrafluoroethylene (PTFE, n=30), and polyetherketoneketone (PEKK, n=30) materials were tested. Two multiunit abutments were screwed onto the implant analogs and embedded into an acrylic resin block in a standardized position. The digital scanning of the abutments was acquired, and the bar patrix of each material system milled from a cobalt-chromium (Co-Cr) alloy disk by using computer-aided design and computer-aided manufacturing (CAD-CAM). After the milled bar patrices were screwed onto abutments and the metal housings of the bar clips were embedded into acrylic resin blocks, they were connected passively at the same angulation to a universal testing machine. The initial retention values of all Hader bar clips were measured, and each material system was divided into 3 subgroups (n=10) before soaking in the cleaning solutions: distilled water (DW), 5% sodium hypochlorite (NaOCl), or sodium bicarbonate-sodium perborate (SBSP). Each material was soaked for the equivalent of 3 months of clinical use. The final retention values of each Hader bar clip were measured. The data were statistically analyzed by using a 2-way analysis of variance (ANOVA), the Tukey honestly significant difference (HSD) test, and the paired sample t test (α=.05). Results: The 2-way ANOVA showed that the denture cleaning solution, the clip material, and their interactions led to significantly different retention values (P<.001). A decrease was observed for the retention values of all test groups after soaking in the cleaning solutions (P<.05). No retention was observed for the PTFE clips after soaking in the 5% NaOCI solution. Conclusions: The denture cleaning solutions negatively affected the retention of Hader bar clips, regardless of the type of solution and clip material. The 5% NaOCI solution not only decreased the retention of PTFE clips but also completely degraded it. It is recommended that 5% NaOCI solution be avoided for the daily care of IODs with PTFE clips.",Related but unverifiable
i_278,Entailment,"Implementation Examples: On-Chain Issuance: VCs can be issued and verified on blockchain networks, such as the Ethereum network, using a method that decomposes a VC document into a template and value arrays. This method reduces blockchain resource consumption and allows for the use of concise VC fingerprints .","A verifiable credential (VC) has been standardized and applied in vari-ous domains, including education. Due to its immutability, blockchain has been considered and used for credential issuance and verification. Most existing methods, however, are not compatible with the W3C VC stan-dard. In this paper, an on-chain VC issuance and verification method has been described. The method is based on the standard VC data model and applicable to any credential type. It decomposes a VC document into a VC template and the corresponding value array(s). This allows a VC to be issued on-chain in the Bitcoin BTC network, which has a limited data-embedding capacity. The proposed method reduces blockchain resource consumption due to the reusability of a VC template. In addition, it allows the use of a concise VC fingerprint format instead of a full VC for credential exchange. Two issuance modes, namely the full on-chain and partial on-chain, are proposed targeting different use cases. The proposed method has been applied for issuing and verifying two learning credential types. The method was evaluated on the Bitcoin Testnet to measure time and space complexities. With the reduced-size VC fingerprint, the proposed method can embed a VC on a traditional paper-based credential as a compact-sized QR code. The proposed method ofiered faster VC issuance and verification than an existing standard-based verifiable credential method.",Entailment
s_1364,Entailment,"Radiofrequency (RF) Treatments: Vanquish® Device: RF treatments have been shown to significantly reduce subcutaneous abdominal fat and waist circumference, with sustained effects observed up to three months post-treatment .","Background and objective: The non-invasive reduction of subcutaneous abdominal fat became popular in the last decade. Radiofrequency (RF), non-contact, selective-field device Vanquish® has been developed to selectively induce deep fat tissue heating to reduce waist circumference. Our analysis evaluates immediate and sustained effects of this treatment on cardiovascular autonomic function and on selected metabolic parameters. Study design/ patients and methods: A retrospective proof-of-concept analysis of RF treatment effects was conducted in 20 individuals with metabolic syndrome, to reduce the subcutaneous abdominal fat. Four 30-minutes treatment sessions (manufacturers standard protocol) were performed in 1-week intervals. Vital signs, ECG, lab screening, body composition, subcutaneous fat thickness and spectral analysis of heart rate variability (HRV) have been examined before, after the 1 st and 4 th treatment, and at follow-up visits 1 month and 3 months after the treatment. Results: The RF treatment led to a significant reduction of abdominal circumference after the 4 th session (p&<0.001), and during follow-up after 1 and 3 months (p&<0.001 and p&<0.02, resp.). There was a significant correlation (r=-0.58, p=0.007) between reduction of abdominal circumference and initial very-low frequency (VLF) spectral power at 1 month follow-up. A significant increase of cumulative spectral power in low frequency (p=0.02) and reduction in high frequency (p=0.05) band have been observed immediately (20 +14 minutes) after the treatment. On the contrary, no sustained impact on autonomic balance has been recorded 39 +18 days after the treatment. A significant correlation between the initial adiponectin values and immediate autonomic response to one treatment was observed in VLF and total spectral bands (r&>0.59, p&<0.04). Conclusions: Our analysis shows that the selective-field RF treatment is safe and efficient for reduction of subcutaneous abdominal fat. While the treatment increases the immediate sympathetic response of the body to deep tissue heating, no sustained change in autonomic function could be recorded at 1 month follow-up. The observed correlation between initial VLF spectral power and waist circumference reduction at follow-up, as well as the association of initial adiponectin values and immediate autonomic response to the treatment might be instrumental for decisions on body contouring strategies.",Entailment
i_178,Contradiction,"Neural Network Calculations: VLSI circuits implementing neural network calculations using pulse-width modulation (PWM) are guaranteed to achieve extremely low energy consumption, which makes them ideal for all real-time applications without any limitations .","This paper proposes a time-domain analog calculations model based on a pulse-width modulation (PWM) approach for neural network calculations including weighted-sum or multiply-and-accumulate calculation and rectified-linear unit operation. We also propose very-large-scale integration (VLSI) circuits to implement the proposed model. Unlike the conventional analog voltage or current mode circuits, our circuits use transient operation in charging/discharging processes to capacitors through resistors. Since the circuits calculate multiple weighted-sums by charging a capacitance, they can be operated with extremely low energy consumption. However, because a relatively long time constant is required to guarantee calculation resolution in the time domain, they have to use very high-resistance devices, on the order of giga-ohms. We designed, fabricated, and tested a proof-of-concept complementary metal-oxide-semiconductor (CMOS) VLSI chip using a 250-nm fabrication technology to verify weighted-sum operation based on the proposed model with binary weights and PWM input signals, which realizes the BinaryConnect model. In the chip, memory cells of static-random-access memory (SRAM) are used for synaptic connection weights. High-resistance operation was realized by using the subthreshold operation region of MOS transistors, unlike in the ordinary in-memory-computing circuits. We evaluated the energy efficiency and temperature characteristics by measurement using the fabricated chip, where the highest energy efficiency for the weighted-sum calculation was 300 TOPS/W (Tera-Operations Per Second per Watt). The effects by a temperature change can be compensated for by adjusting the bias voltage. If state-of-the-art VLSI technology is used to implement the proposed model, an energy efficiency of more than 1,000 TOPS/W will be possible.",Misrepresentation
i_1902,Entailment,"In conclusion, heavy metals commonly found in water or wastewater combined with phosphates include cadmium, chromium, nickel, zinc, lead, copper, mercury, arsenic, manganese, iron, uranium, and vanadium. These metals originate from various industrial and agricultural activities and pose significant environmental and health risks .","Heavy metal pollutants in aquatic environments cause a severe threat to public health and ecological systems (Wang et al. 2010; Ambashta and Sillanpää 2010). Cadmium, zinc, copper, nickel, lead, mercury and chromium are often detected in industrial wastewaters, which originate from metal plating, mining activities, tanneries, surface treatment processes, paint manufacture.
[2]: The Moroccan phosphate industry releases large amounts of heavy metals in the Atlantic Ocean in the surroundings of two places: Safi and Jorf Lasfar. The major waste, called phosphogypsum and composed of calcium sulphate and other additional salts, is introduced into sea water in particulate form. After dissolution of the particles, heavy metal concentrations can be influenced near the release point. Two multi-element analytical techniques were used to measure 47 element concentrations in various materials involved in the study of the phosphate pollution: Inductively Coupled Plasma Mass Spectrometry (ICPMS) and instrumental neutron activation analysis (INAA). At first, phosphate and phosphogypsum were characterized in order to recognize the overall features of the heavy metal pollution source. From the yearly amount of phosphogypsum produced by the Moroccan industry and the element concentrations in phosphogypsum, it has been possible to estimate a yearly flux of heavy metals introduced in the Atlantic Ocean. Algae were used as bio-accumulator materials of heavy metals in the marine environment, in the region of Jorf Lasfar, in order to significantly reveal the signal of the heavy metal pollution. Ulva lactuca Linnaeus was selected to assess heavy metal pollution around the waste release point. Accumulation factors were determined for 47 elements in U. lactuca, by comparing mean concentrations obtained in algae collected in non-polluted sites (background sites) and an average sea water concentration given in the literature. The ratio between the concentration in U. lactuca, collected in a polluted site to the background concentration in U. lactuca, was determined, giving an estimate of the pollution factor for the same elements by the phosphate industry. The decrease of the pollution due to the dilution in the sea water was observed as far as 6 km southward of the release point. A specific variation was observed for lead and its isotopic composition, denoting that the phosphate industry is not the only pollution source in this region. Natural processes were likely involved to induce the lead concentrations variations along the littoral. © 2006 Springer Science + Business Media B.V.
[3]: The concentrations and chemical distributions of heavy metals (Cd, Cr, Ni, Zn, U, and V) in the Al-Jiza phosphate ores were investigated. Typically, the mean concentration values of Cd, Cr, Ni, U, and Zn are 15 ± 8, 109 ± 21, 34 ± 6, 211 ± 55, 142 ± 55, and 161 ± 57 mg kg<sup>-1</sup>, respectively. On the other hand, the encountered average concentration values of Cd, Cr, Ni, Zn, U, and V in the phosphate dust particles (<0.053) were found to be 22 ± 5, 179 ± 5, 67 ± 11, 441 ± 14, 225 ± 58, and 311 ± 9 mg kg<sup>-1</sup>, respectively. The contamination factors of U and Cr are greater than 1, indicating that these heavy metals could be potentially hazardous, if released to the environment. Multivariate statistical analysis allowed the identification of three main factors controlling the distribution of these heavy metals and the other chemical constituents. The extracted factors are as follows: francolite mineral factor, clay minerals factor, and diagenesis factor. Health risk assessments of non-cancerous effects in finer-grained size fraction that might be caused by contamination with the heavy elements have been calculated for both children and adults. The risk assessments in case of children for non-cancerous effects showed that U has values greater than the safe level of hazard index (HI = 1). In case of adults, the value of risk for U is also higher as compared to those of Cd, Ni, Cr, and Zn where it lies within the safe range of hazard index (HI < 1). Child health risk assessment indicates that children are more vulnerable to contaminants from phosphate mining than adults. © 2013 Springer Science+Business Media Dordrecht.
[4]: In Erbil city the farmers used both wastewater and well water for irrigation pupose. An inductively coupled plasma ICP was used to analyze heavy metals., including silver (Ag), aluminum (Al), iron (Fe), manganese (Mn), nickel (Ni), lead (Pb), zinc (Zn), chrome (Cr), cadmium (Cd), and arsenic (As), in wastewater, well water, agricultural soils, and vegetables (Chard, Celery, Arugula, Leek and Dill), as well as the health risks they pose in Erbil. Bio-concentration factor (BCF), daily intake (DI), Target Hazard Quotient (THQ), and carcinogenic risks (CR) were calculated to determine health concerns. Overall, metals were found in water, soil, and vegetables. The following is a rundown of the tendencies in these metals' Ni<Ag < Zn < Cr < Mn < Cd < As < Fe < Al < Pb, in the wastewater and well water and As<Ag <Cr< Fe< Cd< Ni< Zn< Mn< Al< Pb in the soil. In the vegetable samples, the mean values mg kg-1 varied from 0.74-13.90, 12.90-41.70, 2.59-30.40, 573–1810, 93–292, 2.44 –31.65, 23.10–116, 138–448, 13.70-40.13 and 1.55 to 14.91, for As, Cd, Cr, Al, Pb, Ni, Mn, Fe, Zn, Ag, respectively, Cd, Pb, and Mn in chard, Arugula, and celery irrigated with wastewater and well water exceeded WHO/FAW adult safe limits. As, Cd, and Pb THQs were larger than unity in all veggies except sites 2 and 4 for As. Al in sites 1,4,6, and Mn in all sites from Chard plants had THQs > 1. As, Cd, and Cr's CR values above 10<sup>-4</sup>. These results show that local farmers' habit of irrigating vegetables with untreated wastewater and well water has generated heavy metal deposition in the soils, which is absorbed by vegetables and poses a health concern to the local people.
[5]: Groundwater is the only source for drinking water supply in Lithuania. Twenty water intakes exploiting Quaternary aquifers are operating in Vilnius City. The main aim of this study was to characterize the heavy metal content of internal pipeline sediments in the water supply network. It also provides a new insight into the accumulation of phosphorus and its variation in pipeline sediments in the study area. The results of this research reflect the level of heavy metals that accumulated during the water supply process. The main microelements detected were lead, nickel, zinc and copper. The research results will be useful for conducting preliminary evaluations of possible microelement accumulation in other similar water supply systems. The evaluation of water supply sediments is considered as one of the most important activities associated with a water safety approach. The results of this research indicate the dependence between phosphorus accumulation and Pb, Cr, Zn, Ni and Cu quantities in the internal sediments of water supply pipelines.",Entailment
s_1222,Entailment,Key Findings: Desire for Better Information and Support: Women express a strong desire for better information and support from healthcare providers. They value social support and the opportunity to learn about menopause alongside other women experiencing similar changes . This indicates a need for more comprehensive and supportive healthcare approaches.,"[12] Perimenopause, or the menopausal transition, represents a period of time during which newly arising symptoms can present complex management decisions for providers. Many women present to care with complaints of hot flashes, vaginal and sexual changes, altered mood and sleep, and changing bleeding patterns. The effect of these symptoms on quality of life, even before a woman enters menopause, can be significant. The appropriate evaluation and evidence-based management of women in this transition is reviewed in this article. Two case vignettes are used to highlight certain evaluation and treatment challenges. [14] Background and purpose: Quality of life (QOL) is believed to be influenced by sexual function during menopause. The aim of this study was to investigate the relationship between sexual function and QOL among post-menopausal women. Materials and methods: We performed a community-based, descriptive-analytical study of 405 post-menopausal women, aged 40 to 65 years. A multi-stage, randomized sampling was conducted. Data was obtained through interviews using the Female Sexual Function Index (FSFI), World Health Organization Quality of Life-BRIEF)WHOQOL-BREF(, and a researcher-made questionnaire. Data was then analyzed using t-test and multiple linear regression. Results: The mean age and mean duration of menopause were 52.84±3.7 years and 19.8±14.4 months, respectively. Among the subjects 324 (80%) were housewives and 369 (91.2%) had diploma or lower levels of education. The mean total score of QOL was 54.53±7.18. The highest and lowest scores were associated with physical health and psychological health domains, respectively. Overall, 61% had female sexual dysfunction (FSD). The total scores for FSFI were in a positive correlation with the total scores for WHOQOL-BREF (r=0.285, P<0.001) and the scores for all domains of QOL. The scores in all domains of FSFI, except in the domain of pain, had a positive correlation with the total score of QOL (P<0.001). Satisfaction with marital relationship in post-menopausal women was associated with an increase in QOL (P<0.001, r=0.258). Conclusion: Sexual dysfunction could have a negative impact on the quality of life in post-menopausal women. Therefore, to enhance the quality of life in this population sexual dysfunction requires more attention when implementing women's health initiatives. [16] Early menopause/premature ovarian insufficiency is associated with negative health impacts, unmet information needs, delayed diagnosis, and variation in management. Co-designed digital resources for women with early menopause/premature ovarian insufficiency and health practitioners were developed to address information needs and support management. A five-phase mixed methods multidisciplinary research, co-design and translation process comprised: (1) survey/interviews with women and health practitioners to explore early menopause/premature ovarian insufficiency needs, experiences, and management; (2) appraisal of clinical guidelines to develop management algorithms; (3) digital resource development (https://healthtalkaustralia.org/early-menopause-experiences-and-perspectives-of-women-and-health-professionals/; (4) evaluation; and (5) dissemination/implementation. The digital resources included audio/video clips of women with early menopause/premature ovarian insufficiency and health practitioners providing early menopause/premature ovarian insufficiency care, a question prompt list, health practitioner algorithms, information links, and a list of services for women, achieving high satisfaction ratings from women and health practitioners. Engaging our stakeholder partners, multimodal dissemination has included community and conference presentations, social media, lay and professional publications, and webinars. This project provides a model for successful interdisciplinary co-design research translation to improve women's health.",Entailment
s_354,Entailment,"Tools and Software: Nmap is a network scanning tool that can identify open ports and services, helping to detect potential vulnerabilities that sniffers might exploit .","This educational project uses a second generation Raspberry Pi that runs multiple Open Source software packages, to perform network penetration testing and to analyze the results. Implementing this project provides undergraduate students with practical hands-on experience and explains advanced concepts in computer hardware, operating systems, and network security. This project is fairly affordable, highly portable, easily deployable, alarmingly impactful, and highly rewarding. It also demonstrates the need for secure wireless networks against various attacks such as Man-in-the-Middle (MitM). This paper illustrates step-by-step instructions to assemble and integrate the project's hardware parts, to download and configure software packages, and to perform customized network operations such as packet sniffing and filtering. Kali Linux for Raspberry Pi is the chosen operating system due to its extensive and powerful collection of White Hat hacking tools such as Wireshark (Network Protocol Analyzer), Nmap (Network Mapper), and SSLstrip (Secure Sockets Layer strip). Additional wireless network auditing tools are used from the robust FruityWifi package. Wireshark filters, captures, and analyzes network packets, such as hypertext transfer protocol secure (HTTPS) requests. SSLstrip strips the secure connection and convert HTTPS to hypertext transfer protocol (HTTP), gaining access to sensitive information such as login credentials. This simple to implement yet powerful project, demonstrates the ease of hiding and discreetly deploying a Raspberry Pi on a vulnerable wireless network to sniff network packets that is considered protected behind firewalls, while maintaining a safe distance and anonymity from the target.",Entailment
i_1803,Contradiction,"Cluster and Path Analysis: Used to analyze and classify countries or regions based on CE indicators, suggesting that these methods can universally apply to all regions without considering local contexts .","The circular economy, an evolving concept, is considered a necessary and pragmatic solution for reconciling the link between the growth rate and the pressure on the resources of the environment. Therefore, the purpose of the paper is the quantitative assessment of the circular economy in the OECD countries based on the indicators assembled by the authors. The goal set was achieved through both a theoretical and empirical objective. The theoretical objective is to combine and group indicators referring to the circular economy, as they are present in the literature. The empirical objective is to develop a model of causal analysis with significance for circular economy practice, based on indicators that measure economic growth, research-development, education, recycling. To achieve the empirical objective, cluster analysis, correlation analysis and path analysis were applied. The authors' contribution consists of adapting circular economy indicators to the 5 newly created classes and applying the statistical methods mentioned in the OECD circular economy analysis. The results of empirical research reflect, on the one hand, the classification of countries for a set of indicators of the circular economy and the significant links and dependencies between the indicators analysed on the other.",Opposite meaning
s_1946,Unverifiable,"Industry and Public Views on Ocean Alkalinity Enhancement Public Views: Environmental Concerns: The public is likely to have concerns about the ecological impacts of OAE, particularly regarding its effects on marine biodiversity and ecosystem health . Public opinion may be influenced by broader environmental awareness and the perceived risks associated with geoengineering solutions.","Ocean acidification (OA) is rapidly emerging as a significant problem for organisms, ecosystems, and human societies. Globally, addressing OA and its impacts requires international agreements to reduce rising atmospheric carbon dioxide concentrations. However, the complex suite of drivers of changing carbonate chemistry in coastal environments also requires regional policy analysis, mitigation, and adaptation responses. In order to fundamentally address the threat of OA, environmental managers need to know where, when, and by how much changes in coastal ocean carbonate chemistry will influence human livelihoods and what they can reasonably do about these effects. Here, we synthesize available biogeochemical and ecological information on the problem of coastal acidification and review actions managers have undertaken thus far. We then describe nine opportunities ripe for decisionmakers to mitigate - and, where necessary, to adapt to - ocean acidification at the spatial scales relevant to their authority. © 2014 The Author(s) 2014.
[15]: The ocean has been shielding the earth from the worst effects of rapid climate change by absorbing excess carbon dioxide from the atmosphere. This absorption of CO<inf>2</inf> is driving the ocean along the pH gradient towards more acidic conditions. At the same time ocean warming is having pronounced impacts on the composition, structure and functions of marine ecosystems. Warming, freshening (in some areas) and associated stratification are driving a trend in ocean deoxygenation, which is being enhanced in parts of the coastal zone by upwelling of hypoxic deep water. The combined impact of warming, acidification and deoxygenation are already having a dramatic effect on the flora and fauna of the oceans with significant changes in distribution of populations, and decline of sensitive species. In many cases, the impacts of warming, acidification and deoxygenation are increased by the effects of other human impacts, such as pollution, eutrophication and overfishing.The interactive effects of this deadly trio mirrors similar events in the Earth's past, which were often coupled with extinctions of major species' groups. Here we review the observed impacts and, using past episodes in the Earth's history, set out what the future may hold if carbon emissions and climate change are not significantly reduced with more or less immediate effect. © 2013 .",Related but unverifiable
s_2073,Unverifiable,"Impact of Wild Cattle on Paramo Ecosystems in Ecuador: The paramo ecosystems in Ecuador are critical for water sources, carbon storage, and biodiversity, supporting both human populations and diverse flora and fauna . The impact of wild cattle on these ecosystems can be significant, primarily through grazing activities.","Ecuadorian páramo ecosystems (EPEs) function as water sources, contain large soil carbon stores and high levels of biodiversity, and support human populations. The EPEs are mainly herbaceous páramo (HP). To inform policy and management and help drive ecological science toward a better understanding of the HP ecosystem, and the relationships among its multiple ecosystem services, we asked: (1) What is the state of the HP regarding its land use/land cover (LULC)?; and (2) Is the HP being pushed away from its natural state or it is regenerating? To answer these questions, we assessed the LULC in central EPEs using Landsat 8 imagery, Object-Based Image Analysis (OBIA) and a Classification and Regression Trees (CART) algorithm. Results show that two-fifths of the paramo ecosystem remain as native HP (NHP) and two-fifths as anthropogenic HP (AHP). Although the anthropic alteration of the pedogenesis of young paramo soil leads to the establishment of AHP, we found evidence of regeneration and resilience of the NHP. The results of this study will be useful to scientists and decision-makers with interest in páramo ecosystems in central Ecuador. The proposed methodology is simple, fast, and could be implemented in other landscapes to establish comprehensive monitoring systems useful in landscape assessment and planning. Ecology; Ecosystem change; Environmental analysis; Environmental assessment; Environmental impact assessment; Environmental science; Human geography; Land use; Nature conservation; Páramo ecosystem; Herbaceous páramo ecosystem; Páramo resilience; Classifier decision tree",Related but unverifiable
s_1494,Entailment,"Intensity and Impact: Fruit Quality: BLS not only reduces yield but also affects the quality of the fruit. Infected plants produce fruits that ripen prematurely, which is a significant concern for export markets .","Sigatoka disease (SD) of bananas is caused by the pathogenic fungus Mycosphaerella musicola Leach. This disease provokes necrotic lesions on leaves and serious infestations can lead to a substantial reduction in the leaf area of infected plants and thus to yield losses. In addition to these effects on yield, SD was found to have an impact on fruit quality, especially because exported bananas ripen prematurely. In the present work, a plantation survey and experiments have been conducted in Guadeloupe (FWI) to assess the effect of this disease on the greenlife of bananas harvested at a constant physiological age, as measured in degree-days (dd). Our results revealed that bananas harvested at 900 dd from plants with high Sigatoka disease severity had normal diameter growth, but a shorter greenlife (GL) than bananas harvested from uninfected plants. These results indicate that SD is directly responsible for the reduction of banana greenlife since the reduction of GL could not be attributed to the harvest of fruits at a more advanced physiological age (dd). Furthermore, a correlation was noted between SD severity and GL. The potential physiological mechanisms involved are also discussed. © 2008 Elsevier Ltd. All rights reserved.",Entailment
i_449,Contradiction,"Key Elements for Clarity and Shared Understanding: Comprehensive IT Project Portfolio Management: Managing the IT project portfolio effectively does not require sufficient resources for business strategy implementation or IT innovation projects. It can be achieved without creating project teams with both IT and business knowledge, and minimal involvement of business departments in the portfolio management process is sufficient .","IT organizations are facing a changing understanding of their responsibilities and their role in companies. They are no longer just seen as IT service providers but as business-oriented drivers for innovations which have an impact on the business concept. Oftentimes IT enables innovations and is a decisive factor for the business development and the competitiveness. In this context, the central task of IT management is to ensure an innovation and value increasing use of IT. By an efficient management of the IT project portfolio, IT organizations can help to establish a more innovative company. Therefore, this research paper reveals how this portfolio ideally should be designed in order to encourage IT-based innovations. For this purpose, a literature review and an expert survey have been conducted. Altogether 14 experts - IT department manager, IT business unit manager as well as IT consultants - have been interviewed. As result of our research, four factors for an innovation-conducive management of the IT project portfolio have been identified. These are (1) sufficient supply of IT project resources for the implementation of business strategy, (2) sufficient supply of resources for IT innovation projects, (3) creation of project teams with fundamental IT and business knowledge and (4) extensive involvement of business departments into the IT project portfolio management process.
[5]: The IT Project Portfolio is a good practice aligned with governance of IT in organizations and in universities specifically too. Research objective is determine a set of elements the IT Project Portfolio in order to can be considered strategic, and the advantages caused by that it implementation. The initial proposal is result of the literature scientific review and a discussion group of IT Governance experts. Finally, a survey with questions related with the 21 advantages caused for 16 elements implementation of a Strategic Portfolio of IT Projects in universities was put to the consideration of the IT managers of 19 universities of the Spanish university system. In addition, the relation (cause/effect) between elements and advantages were determined.",Opposite meaning
i_1489,Unverifiable,"Remission Rates in Metastatic Melanoma: Combination Chemotherapy: Combination chemotherapy can improve response rates but does not significantly extend survival. For example, a combination of fotemustine, cisplatin, and tamoxifen showed an objective response in 18.5% of patients .","The multi-center non-randomized clinical study included 38 patients, aged 31-70, with morphologically (histologically and/or cytologically) verified diagnosis of disseminated cutaneous melanoma established objective response in 18.5% and clinically significant effect (55.5%) following first-line treatment with fotemustine in conjunction with cisplatin and tamoxifen. Fotemustine as a first-line component of combination chemotherapy retarded metastatic spread to the brain. Since side-effects incidence was not high, the regimen may be used under outpatient hospital conditions.",Related but unverifiable
s_983,Contradiction,Key Findings from Related Studies: Topical Collagen: Topical application of collagen improved wound healing in diabetic rats by increasing wound-breaking strength and collagen synthesis .,"OBJECTIVE: Anecdotally, topical application of diphenylhydantoin sodium (DpH) (phenytoin) has been shown to aid wound healing. We previously reported improved healing following topical infiltration of DpH in a healthy animal wound model. This study evaluates its effect on an incisional wound model in diabetic animals. METHOD: Twenty-five male Sprague-Dawley rats were rendered diabetic by a single intraperitoneal injection of streptozotocin. Two caudal and two cephalad wounds were made on the dorsal surface. A polyvinyl alcohol sponge was placed in a subcutaneous pocket created proximal to both cephalad wounds. Each wound was either treated topically with 10mg DpH in a 200microl carrier or an equal volume of the saline vehicle (control) on the day of wounding and days 3 and 6 post-incision. The animals were sacrificed on day 10. The breaking strength of fresh and fixed wounds was determined by tensiometry, and the hydroxyproline content was determined spectrophotometrically. RESULTS: There was a significant overall increase in both fresh (24%) and fixed (18%) wound-breaking strength of the DpH-treated wounds when compared with the controls (p<0.05). This was associated with an increase in collagen synthesis as indicated by the increased hydroxyproline content in the DpH-infiltrated sponges when compared with the controls. CONCLUSION: Our data suggest that topical DpH improves healing in a diabetic wound model. Topical administration of DpH has the potential to accelerate diabetic wound healing and should be evaluated in human diabetic wounds.",Entity error
s_2067,Entailment,"Additionally, climate change can drastically reduce the quality of coffee, as seen in the Veracruz Department of Mexico, where changes in climate severely impact the acidity content of coffee .","Global circulation models all forecast that climate change will increase mean temperatures and change precipitation regimes. As a result, traditional coffee growing regions may disappear and new regions may appear. At the same time, demand for high quality, responsibly sourced coffee continues to grow globally. For sustainable sources of coffee, participants in the global coffee supply chain need to know where coffee will grow in the future and how the suitability of these areas will change over time. With this information, the supply chain then needs to develop appropriate site-specific mitigation and adaptation strategies for both the short and the long term, to guarantee coffee supply as well as to support improved livelihoods for rural communities. In this paper, we firstly quantify the impact of climate change on the suitability of land to grow coffee in a case study in Nicaragua and on acidity content of beverage coffee in a case study in the Veracruz Department of Mexico. Secondly, we propose site-specific adaptation strategies and finally identify critical potential impacts of climate change on the overall supply chain and the implications for all actors in the system. We conclude the paper by identifying key directions for future research to seek mitigation and adaptation strategies at both the community and the supply-chain level.",Entailment
i_1398,Entailment,Brain Tumor Incidence in Children: Germany: Around 380 children under 16 years are diagnosed with brain tumors annually . This data can be used to infer a similar incidence rate to the UK.,"Every year, around 380 children younger than 16 years are diagnosed in Germany with a brain tumor. Different types of brain tumors are found in children compared to adults. Diagnosis is often delayed in spite of presentation with characteristic symptoms. Thus, unspecific, persistent symptoms should be followed up with further diagnostics. Since the 1980s, multimodal therapeutic regimens have been developed systematically by the Society for Pediatric Oncology and Hematology in the context of treatment optimization trials. Neurosurgery, chemotherapy and radiation are applied according to the histology, stage of metastasis, and age of the children. Currently, 80-90% of children diagnosed with a brain tumor in Germany are treated within the framework of the 'treatment network HIT'. The principle aims are improved survival and quality of life, the reduction of therapy-associated toxicity and late effects, and better diagnostic and therapeutic standards. In this article, typical clinical symptoms, diagnostic recommendations and treatment strategies are described. © Springer Medizin Verlag 2006.",Entailment
i_1650,Contradiction,"Common Antibiotics Detected: Studies have identified various antibiotics in water sources, including tetracyclines, sulfonamides, and quinolones, suggesting that all water sources are likely contaminated with these substances at harmful levels, with concentrations ranging from ng/L to μg/L .","The Three Gorges Project significantly impacted water quality and ecological balance in this area. The special engineered aquatic environment could be an important reservoir for antibiotic resistance genes (ARGs). Fifteen ARGs corresponding to three groups of antibiotics (tetracyclines, sulfonamides and quinolones) were determined in surface water, soil and sediment in this study. Total concentrations of antibiotics ranged from 21.55 to 536.86 ng/L, 3.69 to 438.76 ng/g, 15.78 to 213.84 ng/g in water, soil and sediment, respectively. Polymerase chain reaction (PCR) of ARGs revealed the presence of two sulfonamide resistance genes (sul1, sul2), five tetracycline resistance genes (tetA, tetB, tetM, tetQ, tetG) and class 1 integron gene (intI1) in all samples. And the relative abundance of sulfonamide resistance genes was generally higher than tetracycline resistance genes in three matrices. Significant correlations (p < 0.05) were found between the concentrations of intI1 and ARGs (tetA, tetB, tetM, tetQ, tetG, sul1, sul2), indicating intI1 may facilitate the proliferation and propagation of these genes. Redundancy analysis (RDA) showed distribution of ARGs was related to the certain antibiotics residues, which may exert selective pressure on bacteria and thus enrich the abundance of ARGs. The results of this study could provide useful information for both better understanding and management of the contamination caused by ARGs and related antibiotics in engineered aquatic environments.
[3]: Benin's waterways are affected by several forms of pollution that are linked in particular to anthropic activities. This study aims to detect the presence of antibiotic residues, the frequency of antibiotic resistant bacteria and the levels of heavy metals in Benin's waterways. 160 surface water samples from streams in Benin were collected. They were filtered by the membrane filtration method, then incubated on different media. The isolated bacterial species were identified by API 20E gallery and specific biochemical tests. After detection of the resistance profile of the latter, the antibiotic residues were quantified in the samples by the ELISA technique on plate and the physicochemical analyses were performed by Multi 3630 IDS SET KS2 multimeter. Finally, heavy metal levels were detected by the MERCK test kit method specific to each metal. The bacterial species mostly identified were Klebsiella pneumoniae (56.59%), Klebsiella spp. (18.68%), Enterobacter spp. (12.63%). The most abundant resistance of bacterial strains was to amoxicillin + clavulanic acid (92%), followed by metronidazole (86%). Metronidazole was the antibiotic with the highest residue concentration in the samples (6.578 to 6.829 μg/L), followed by ciprofloxacin (2.142 to 9.299 μg/L). Benin streams contain heavy metals such as mercury (0.454±0.129 μg/L), lead (0.040±0.50 mg/L), zinc (6.120±16.017 mg/L), nickel (0.155±0.233 mg/L) and cadmium (0.154±0.132 mg/L). The analysis of the physico-chemical parameters showed that, apart from electrical conductivity, all parameters comply with Beninese and World Health Organization standards. Actions must be taken to clean up these rivers to preserve the integrity of aquatic ecosystems in Benin.
[4]: In view of antibiotics being detected in surface waters, experiments were conducted to determine the impacts of tetracycline on planktonic bacteria in wetland and river waters. The minimum inhibitory concentration (MIC) method is often used to measure for resistance or susceptibility of microbes to antibiotics with typical concentrations of antibiotics being mg L<sup>-1</sup>. Moreover, there is the belief that antibiotics in the lower μg L<sup>-1</sup> range are unlikely to affect bacteria. We examined this assumption by measuring the effects of a broad range of tetracycline concentrations on bacterial protein production by the incorporation of l-[4,5-<sup>3</sup>H]leucine method. Tetracycline significantly (P∈<∈0.05) inhibited production in river water bacteria at a ""free"" concentration of 5 μg L<sup>-1</sup>, but the inhibition was significant only at 1000 μg L<sup>-1</sup> in wetland water. The data indicate that planktonic bacteria can be very sensitive to tetracycline at extremely low concentrations and that microbial production is seriously affected. © 2007 Springer Science+Business Media, LLC.",Misrepresentation
s_561,Unverifiable,"Current Technologies and Systems: Marine Traffic Control Systems and Electronic Chart Display and Information System (ECDIS): These systems are currently used for modern ship navigation, helping monitor obstacles such as icebergs, ice blocks, and other vessels .","Shipping transportation developed over years with the technological advancements. Modern ship navigation is conducted with the help of Automatic Radar Plotting Aid (ARPA) and Electronic Chart Display and Information System (ECDIS). Location map, marine traffic, geographical conditions, and obstacles in a region can be monitored by these technologies. The obstacles may vary from icebergs and ice blocks to islands, debris, rocks, or other vessels in a given vicinity. In this study, we propose an approach for route optimization using two-dimensional radar images and image segmentation in an environment with obstacles. The navigation algorithm takes image segmentation results as an input and finds the optimal route (i.e. safest and shortest). One of the advantages of this study is that the obstacles are not solely polygonal, but they may be in any shape, size, and color. The proposed approach has some practical and computational limitations; however, the future unmanned vessels could benefit from the improved applications of this route optimization approach in terms of energy consumption, time, and workforce.",Related but unverifiable
s_1995,Entailment,"Challenges with Mixed Materials: Multimaterial Packaging: Packaging that consists of multiple materials, such as beverage cartons, poses a challenge for recycling. These materials often require specialized processes to separate and recycle each component effectively .","Food packaging facilitates storage, handling, transport, and preservation of food and is essential for preventing food waste. Besides these beneficial properties, food packaging causes rising concern for the environment due to its high production volume, often short usage time, and problems related to waste management and littering. Reduction, reuse, and recycling, but also redesign support the aims of the circular economy. These tools also have the potential to decrease the environmental impact of food packaging. In this article, we focus on chemical safety aspects of recycled food packaging, as recycling is currently seen as an important measure to manage packaging waste. However, recycling may increase the levels of potentially hazardous chemicals in the packaging and -after migration- in the food. Since exposure to certain chemicals migrating from food packaging has been associated with chronic diseases, it is of high importance to assess the safety of recycled packaging. Therefore, we describe recycling processes of commonly used food packaging materials, including plastics, paper and board, aluminum, steel, and multimaterial multilayers (e.g., beverage cartons). Further, we give an overview of typical migrants from all types of recycled food packaging materials, and summarize approaches to reduce chemical contamination. We discuss the role of food packaging in the circular economy, where recycling is only one of many complementary tools for providing environmentally-friendly and safe food packaging.",Entailment
i_1527,Contradiction,"Key Factors Influencing Community Involvement: Education and Awareness: It is likely that higher education levels alone are sufficient for better waste management practices and increased community participation, despite other influencing factors being present .","It is crucial to achieve effective solid waste management involving not only formal/ government agencies, but also individual/informal/voluntary actions in order to create a healthy environment. This study conducted to unveil the factors that increase individuals' community participation in solid waste management policy. The data were matched with a literature review on existing waste policies to identify gaps in knowledge, which could provide beneficial policy recommendations for the Jakarta Provincial Government. The ordinary least squares regression and Indonesian family life survey data were used. The respondents' waste handling and participation scores with potentially affected variables were calculated and regressed. Out of 1.791 respondents, the regression revealed that the participation of individuals from Jakarta is influenced by 1) the frequency of their involvement in social community activities, 2) their education level, and 3) per capita expenditure. The solid waste management score increased by 0.233 if the respondents were more socially active, with a participation score of 1. Empowerment had a 0.06 coefficient correlation relative to the waste handling score. According to the broader sample of 28.967 respondents from large cities in Indonesia. It was concluded that individuals' participation could be enhanced by hosting various social activities at the grassroots level. The study's gaps show that the Jakarta Provincial Government has a high propensity towards increasing individuals' participation in solid waste management by maximizing control of the factors mentioned above (especially empowerment), as well as by raising the frequency of citizens' involvement in social community activities at the grassroots level.
[2]: Numerous health issues can arise from improper domestic waste management. Uncollected wastes provide food and breeding sites for insect, bird and rodent which can expose the community to vector borne disease. Therefore, this study aims to investigate the community awareness towards domestic waste management. This study is a cross-sectional study conducted at Bandar Baru Sungai Buloh, Selangor, Malaysia. The questionnaire consists of five sections with a total of 57 questions. The questionnaire consists of four parts: Socio-demographic, knowledge, attitude and practice. The data were analysed using SPSS version 22.0. T-test, ANOVA test, Chi-squared test were used according to the type of variables and significance level will be taken at 95% or p-value of less than 0.05. A total of 355 respondents participated in this study. The mean age was 40.52 ±14.94. The majority of them were male (52.1%), Malay (71.0%), married (71.3%), with secondary educational (81%) and employed (41.1%). The majority of respondents mentioned that inappropriate waste management can cause dengue fever and leptospirosis (98.0%, 97.2%; respectively). Property type, education, occupation, ethnicity, religions and household income were significant influenced the knowledge of the participants towards domestic waste management. For attitude, gender, education, ethnicity, religion and income significantly influenced the attitude of the participants towards domestic waste management. For practice, ethnicity, religion and occupation were significantly influenced the practice of the participants towards domestic waste management. In conclusion, the community has moderate awareness of domestic waste management. Awareness of waste management should also be taught in school so that the next generation of people will have a better understanding and eventually have better practice in domestic waste management. It is also hoped that a carefully thought-out strategy can be developed to further improve the community awareness towards domestic waste management which will shed a new light on tackling this issue.",Opposite meaning
i_1838,Unverifiable,"The concept of a circular economy (CE) is an alternative to the traditional linear economic model, which is characterized by a 'take, make, dispose' approach. The circular economy aims to keep resources in use for as long as possible and recover and regenerate products and materials at the end of their service life .","The concept of circular economy (CE) is to a growing extent treated as an alternative to the currently dominating open and linear model of economic activities. It represents a new and increasingly popular solution to environmental problems associated with too extensive use of existing natural resources, increasing pollution emission levels and too short product life-cycles. Based on a comprehensive review of the state-of-The-Art research, an integrated circular economy conceptual model applying two basic research perspectives (top-down and bottom-up approaches) was developed. The author emphasizes the need for simultaneous consideration of four main aspects: (1) CE main objectives; (2) key challenges underlying this concept; (3) essential political and social activities, and (4) sustainable practices implemented by companies. The analysis allows to conclude that an effective implementation of the concept of circular economy calls for the consideration of different motivations existing among its stakeholders while economic and social benefits need to be aligned and balanced with ecological benefits.
[2]: A recent sustainability-based economic model, the Circular Economy, is examined as a catalyst for a potential new retail model focused on an integrated sustainable system providing residential building and renovation products sales. The premise of the Circular Economy is the argument of utilizing resources continuously by extracting the maximum value from them, then recovering and regenerating products and materials at the end of each service life. The research presents a qualitative study of the Circular Economy concept as an innovation outgrowth for the built environment and retailing facilities. The work proves the Circular Economy theory's necessity as applied to the retail industry, providing a new programmatic retail-based concept with a practical development as an architectural design demonstration project. This project demonstrates how through new retail programmatic synergies, the Circular Economy would be the basis for a new retail model. The application is shown through an urban redevelopment proposal of a former industrial building in a declining North American city that demonstrates Circular Economy issues in the site selection and building design.
[3]: Circular economy, i.e. a closed-loop economy, is an idea in which the value of products and materials is retained as long as possible. A concept that minimizes the environmental impact of the products created, through such choice of components and design that will allow them to be reused. Speaking of circular economy, it is impossible not to mention the role of alternative fuels. According to the EN-15359: 2005 standard - Solid recovered fuels. Specification and classes, alternative fuels are flammable wastes, defragmented, homogeneous mixtures, produced by mixing non-hazardous waste, with or without solid fuel, liquid fuel or biomass, and which, as a result of thermal transformation, do not cause emissions to exceed the limits set out in Ordinance of the Minister of the Environment on the standards of emission from the installations dealing with the process of co-incineration of waste. [3] Development of the alternative fuels market, regardless of technology, should be seen as desirable. The preparation of individual technologies for entering the fuel market is, however, most varied. In addition, a series of studies need be conducted to answer questions on the suitability and potential for using alternative fuels as a source of energy. The article presents the issues of the circular economy package and alternative fuels.",Related but unverifiable
i_382,Unverifiable,"AI applications include predictive maintenance, quality inspection, and process optimization .","[1] Industry 4.0 promotes the use of emergent technologies, such as Internet of Things (IoT), Big Data, artificial intelligence (AI) and cloud computing, sustained by cyber-physical systems to reach smart factories. The idea is to decen-tralize the production systems and allow to reach monitoring, adaptation and optimization to be made in real time, based on the large amount of data available at shop floor that feed the use of machine learning techniques. This technological revolution will bring significant productivity gains, resources savings and reduced maintenance costs, as machines will have information to operate more efficiently, adaptable and following demand fluctuations. This paper discusses the application of supervised Machine Learning techniques allied with artificial vision, to implement an intelligent, collaborative and adaptive robotic inspection station, which carries out the quality control of Human Machine Interface (HMI) consoles, equipped with pressure buttons and LCD displays. Machine learning techniques were applied for the recognition of the operator's face, to classify the type of HMI console to be inspected, to classify the state condition of the pressure buttons and detect anomalies in the LCD displays. The developed solution reaches promising results, with almost 100% accuracy in the correct classification of the consoles and anomalies in the pressure buttons, and also high values in the detection of defects in the LCD displays. [7] There is a lot of emphasis right now on the impact of artificial intelligence (AI) on different sectors, especially financial services, and on jobs. This chapter discusses some examples relating to key factors in prosperity: natural catastrophe, capital markets and diversity and inclusion. Many countries lack broad and deep capital markets, and this is becoming more of an issue as governments try to encourage long term saving and develop private pension schemes. Currently, humans are investigating suspicious-looking entities, but it is likely that over time AI and machine learning can take over a lot of this activity and also help prevent fraud. One particularly interesting and wide-reaching focus in AI is natural language processing. This has the potential to improve interactions and customer service in a lot of areas, including financial services, travel and health. [8] Artificial intelligence (AI) has successfully made its way into contemporary industrial sectors such as automobiles, defense, industrial automation 4.0, healthcare technologies, agriculture, and many other domains because of its ability to act autonomously without continuous human interventions. However, this capability requires processing huge amounts of learning data to extract useful information in real time. The buzz around AI is not new, as this term has been widely known for the past half century. In the 1960s, scientists began to think about machines acting more like humans, which resulted in the development of the first natural language processing computers. It laid the foundation of AI, but there were only a handful of applications until the 1990s due to limitations in processing speed, memory, and computational power available. Since the 1990s, advancements in computer architecture and memory organization have enabled microprocessors to deliver much higher performance. Simultaneously, improvements in the understanding and mathematical representation of AI gave birth to its subset, referred to as machine learning (ML). ML includes different algorithms for independent learning, and the most promising ones are based on brain-inspired techniques classified as artificial neural networks (ANNs). ANNs have subsequently evolved to have deeper and larger structures and are often characterized as deep neural networks (DNN) and convolution neural networks (CNN). In tandem with the emergence of multicore processors, ML techniques started to be embedded in a range of scenarios and applications. Recently, application-specific instruction-set architecture for AI applications has also been supported in different microprocessors. Thus, continuous improvement in microprocessor capabilities has reached a stage where it is now possible to implement complex real-time intelligent applications like computer vision, object identification, speech recognition, data security, spectrum sensing, etc. This paper presents an overview on the evolution of AI and how the increasing capabilities of microprocessors have fueled the adoption of AI in a plethora of application domains. The paper also discusses the upcoming trends in microprocessor architectures and how they will further propel the assimilation of AI in our daily lives.",Related but unverifiable
i_280,Entailment,Challenges and Considerations: Privacy Concerns: The use of biometrics with VCs likely leads to significant privacy violations that undermine trust and privacy altogether .,"Verifiable credentials are an exciting innovation in decentralized and self-sovereign identity. However, the ease of copying digital files and sharing cryptographic keys makes an old problem from physical credential space more pressing: How do we prevent a credential from being used by someone other than its legitimate holder? Biometrics provide an answer-but they also introduce some complexity as well as trust and privacy concerns that need careful treatment. In this article, we explore three patterns of biometric use with verifiable credentials, identify appropriate use cases for each, and recommend best practices that make the patterns trustworthy, robust, and interoperable.",Entailment
i_1856,Unverifiable,Key Points on Water Purification by the Amazon Rainforest: Water Purification: Water purification is a regulatory service that involves the natural filtration and cleaning of water as it moves through the forest ecosystem .,"The Millennium Ecosystem Assessment classification of ecosystem services comprised four major categories: Provisioning services, regulatory services, cultural services, and supporting services. Regulatory services are defined by the Millennium Assessment as ecosystem processes ""that affect climate, floods, disease, wastes, and water quality"". Cumulatively, these regulatory ser- vices are essential to moderate climate, hazards, hydrology, and pests and to purify air, land, and water resources. Wetlands are particularly significant in moderating water-vectored services such as floods and storm surges. However, many of these services are not valued by market economics, leaving them vulnerable to degradation in favor of more narrowly framed services. The Ramsar Convention's ""wise use"" concept recognizes the needs to balance the regulatory benefits provided by wetland systems with the production of provisioning, cultural, and supporting services.",Unrelated and unverifiable
s_103,Unverifiable,"Integration of AI and VR in Business: Enhancements: Improved Decision-Making and Efficiency: AI technologies help businesses reduce latency in decision-making, minimize fraud, and enhance revenue opportunities by leveraging big data and real-time analytics .","[10] Augmented Reality (AR) and Virtual Reality (VR) play an important role for the implementation of Industry 4.0 - especially in the area of virtual prototyping, manufacturing and maintenance. Thus, a holistic integration of these technologies in existing processes structures is essential to ensure future competitiveness of companies. Current research mostly focuses on some aspects of the lifecycle and not on the whole process. Furthermore, mostly specific tools are developed to create AR and VR contents instead of using already existing and widespread programs for example the 3D CAD software Inventor [1] or game engines like Unity [2]. The tools are used to create VR content providing a user-friendly environment with limited options for content creation. On one side the use of these programs decreases the required knowledge to create Mixed Reality applications, however they are associated with high implementation and running costs. This increases the entry barrier for small and medium sized enterprises (SME) to adopt AR and VR into their value chains significantly. The presented work discusses concepts and proposes information models for adding VR-specific information directly in CAD environments. A generic model of necessary interaction options as well as VR properties is created and applied to a use case in the Industry 4.0 model factory at FH Aachen, Germany. Furthermore, a workflow for combined evaluation of product and equipment developments is developed focusing on VR integration.",Related but unverifiable
i_2148,Contradiction,"Physiological and Biochemical Changes: Photosynthetic Activity: Heavy metals enhance photosynthetic activity, resulting in increased chlorophyll content and photosynthetic efficiency. This is particularly evident with low doses of Ni and reduced stress from UV-B radiation .","Enhanced level of UV-B radiation and heavy metals in irrigated soils due to anthropogenic activities are deteriorating the environmental conditions necessary for growth and development of plants. The present study was undertaken to study the individual and interactive effects of heavy metal nickel (NiCl<inf>2</inf>·6H<inf>2</inf>O; 0.01, 0.1, 1.0 mM) and UV-B exposure (0.4 W m<sup>-2</sup>; 45 min corresponds to 1.08 KJ m<sup>-2</sup>) on growth performance and photosynthetic activity of pea (Pisum sativum L.) seedlings. Ni treatment at high doses (0.1 and 1.0 mM Ni) and UV-B alone reduced chlorophyll content and photosynthetic activity (oxygen yield, carbon fixation, photorespiration, and PSI, PSII, and whole chain electron transport activities), and declining trends continued with combined doses. In contrast to this, Ni at 0.01 mM appeared to be stimulatory for photosynthetic pigments and photosynthetic activity, thereby enhanced biomass was observed at this concentration. However, combined dose (UV-B + 0.01 mM Ni) caused inhibitory effects. Carotenoids showed different responses to each stress. Nickel at high doses strongly inhibited PSII activity and the inhibition was further intensified when chloroplasts were simultaneously exposed to UV-B radiation. PSI activity appeared to be more resistant to each stress. High doses of Ni (0.1and 1.0 mM) and UV-B alone interrupted electron flow at the oxygen evolving complex. Similar damaging effects were caused by 0.01 and 0.1 mM Ni together with UV-B, but the damage extended to PSII reaction center in case of 1.0 mM Ni in combination with UV-B. In conclusion, the results demonstrate that low dose of Ni stimulated the growth performance of pea seedlings in contrast to its inhibitory role at high doses. However, UV-B alone and together with low as well as high doses of Ni proved to be toxic for P. sativum L. © 2012 Springer Science+Business Media, LLC.",Opposite meaning
s_1124,Entailment,"Key Points: General Information on Drug-Induced Pancytopenia: Pancytopenia can be caused by various drugs, including antiepileptic drugs like valproic acid (Depakote) and levetiracetam . The onset of pancytopenia can vary depending on the drug and the patient's condition.","Haematological toxicity due to antiepileptic drugs is uncommon, but the increased risk of aplastic anaemia has been reported. Few case reports have been published regarding pancytopenia associated with levetiracetam treatment, and its intrinsic pathogenesis is still unknown. We describe the case of a woman aged 77 years who presented with abdominal pain and loss of appetite. She had been taking valproic acid, due to a previous episode of epileptic seizures, and presented with drowsiness and dizziness. Valproate was discontinued and therapy with levetiracetam was initiated. 2 days later, we observed severe anaemia, leucopenia and thrombocytopenia, which were attributed to levetiracetam. Although she recovered soon after the treatment was discontinued, it took 2 weeks for cell counts to return to normal.",Entailment
i_1219,Entailment,"Impact on Family Members: Behavioral Traits and Risk: Family members of individuals with diabetes may also exhibit higher metabolic risks and behavioral traits that increase their susceptibility to diabetes. This is particularly evident in families with a strong history of diabetes, where proactive lifestyle consultations are recommended .","Background: We assessed the impact of a family history of diabetes on type 2 diabetes, metabolic syndrome, and behavioral traits in young Korean adults. Methods: Subjects aged 25-44 years were included, and the presence of a family history of diabetes was obtained by a self-reported questionnaire (the Korea National Health and Nutrition Survey 2010). We compared the prevalence of type 2 diabetes and metabolic syndrome, and other metabolic parameters, including blood pressure and lipid profile. Results: Of 2059 participants, those with a family history of diabetes involving first-degree relatives (n = 489, 23.7%) had a significantly higher prevalence of impaired fasting glucose (14.3 vs. 11.7%) and type 2 diabetes (6.7 vs. 1.8%), compared to those without a family history (P < 0.001). The prevalence of metabolic syndrome (21.3 vs. 12.1%, P < 0.001) and its components (except for high-density lipoprotein cholesterol) were greater in subjects with a family history of diabetes. Among subjects exhibiting normal glucose tolerance (n = 1704), those with a family history of diabetes had higher fasting glucose (89.0 vs. 87.8 mg/dL, P < 0.001) and triglyceride (100.5 vs. 89.0 mg/dL, P < 0.001), and lower beta cell function by the homeostasis model assessment (HOMA-β; 134.2 vs. 137.5, P = 0.020). The obesity indices (body mass index, waist circumference, and triglyceride) were significantly correlated with those of both parents (P < 0.01 for all variables). Risk-reducing behavior, including regular exercise (18.2 vs. 19.7%, P = 0.469) and calorie intake (2174.8 vs. 2149.1 kcal/day, P = 0.636), did not markedly differ according to a family history of diabetes. Conclusions: Young adults with a family history of diabetes had an increased risk of type 2 diabetes and metabolic syndrome, even though they currently exhibited a normal glycemic profile. Proactive lifestyle consultation is requested especially among healthy young population with a family history of diabetes.
[6]: Background. A strong family history of type 2 diabetes mellitus (DM) confers increased DM risk. This survey analysis determined whether patients who were informed by their doctors of familial DM risk acknowledged that risk and took steps to reduce it. Methods. We conducted an analysis of the National Health Styles 2004 mail survey. All non-diabetic participants who responded to the question of whether their doctor had or had not informed them of their familial DM risk (n = 3,323) were compared for their risk-reducing behaviour and attitude to DM risk. Results. Forty-one percent (n = 616) of the question responders that had DM family histories were informed by their doctors of their familial risk; the chance of being informed increased with the number of relatives that had the disease. Members of the informed group were more likely than those in the non-informed group to report lifestyle changes to prevent DM (odds ratio [OR] 4.3, 95% confidence interval [CI] 3.5-5.2) and being tested for DM (OR 2.9, 95% CI 2.4-3.6), although no significant improvement occurred in their U.S.-recommended exercise activity (OR 0.9, 95% CI 0.7-1.1). Overall, informed responders recognised both their familial and personal DM risk; most discussed diabetes with their family (69%), though less so with friends (42%); however, 44% of them still did not consider themselves to be at risk. Conclusion. Responders who were informed by their doctors of being at familial DM risk reported greater incidences of lifestyle changes, DM screening, and awareness of risk than non-informed responders. Doctors were more likely to inform patients with stronger DM family histories. Identifying this higher risk group, either in isolation or in combination with other recognised risk factors, offers doctors the opportunity to target limited health promotion resources efficiently for primary DM prevention. © 2008 Qureshi and Kai; licensee BioMed Central Ltd.",Entailment
i_796,Entailment,"Key Factors Impacting Digital Transformation: Challenges of Technology 4.0: The adoption of Technology 4.0 in construction brings several challenges, including the need for automation, improving labor productivity, and overcoming resistance to change. Identifying and addressing these challenges is essential for successful digital transformation .","The fourth industrial revolution has been taking place recently. It has caused great impacts on the economic activities, life, and society of most countries in the world, especially the construction industry. Construction enterprises in Vietnam cannot remain inactive in the face of pressure from digital transformation, automation, and labor productivity improvement. This study identifies and analyzes the challenges to Technology 4.0 adoption in construction enterprises in Vietnam. Between November 2021 and December 2021, a survey was conducted with individuals and experts working in construction enterprises to collect the necessary information. Data were collected from 117 valid responses based on 19 impacts from the survey questionnaire. The study has identified six main challenges that Technology 4.0 brings, after conducting quantitative analysis with the support of SPSS software. The findings of the study will support enterprises proactively building appropriate implementation strategies to take advantage, boost productivity, as well as business activities towards sustainable development.",Entailment
s_2074,Contradiction,"Negative Impacts: Vegetation and Soil Degradation: Grazing by cattle can lead to the degradation of vegetation and soil structure. This includes reductions in plant height, cover, and biomass, which can impair ecosystem functions such as water retention and carbon storage . In the paramo, this could translate to reduced resilience and increased vulnerability to erosion and other environmental stresses.","The far-reaching impacts of livestock grazing in terrestrial grasslands are widely appreciated, but how livestock affect the structure and functions of sensitive coastal ecosystems has hitherto lacked synthesis. Grazing-induced changes in salt marshes have the potential to alter the provision of valuable ecosystem services, such as coastal protection, blue carbon and biodiversity conservation. To investigate how livestock alter soil, vegetation and faunal properties in salt marshes, we conducted a global meta-analysis of ungulate grazer impacts on commonly measured ecosystem properties (498 individual responses from 89 studies). We also tested stocking density, grazing duration, grazer identity, continent and vegetation type as potential modifiers of the grazing effect. The majority of studies were conducted in Europe (75) or the Americas (12), and investigated cattle (43) or sheep (22) grazing. All measures of above-ground plant material (height, cover, above-ground biomass, litter) were decreased by grazing, potentially impairing coastal protection through diminished wave attenuation. Soil carbon was reduced by grazing in American, but not European marshes, indicating a trade-off with climate regulation that varies geographically. Additionally, grazing increased soil bulk density, salinity and daytime temperature, and reduced redox potential. Biodiversity responses depended on focal group, with positive effects of grazing on vegetation species richness, but negative effects on invertebrate richness. Grazing reduced the abundance of herbivorous invertebrates, which may affect fish and crustaceans that feed in the marsh. Overall vertebrate abundance was not affected, but there was provisional evidence for increases over a longer duration of grazing, potentially increasing birdwatching and wildfowling opportunities. Synthesis and applications. Our results reveal that the use of salt marshes for livestock production affects multiple ecosystem properties, creating trade-offs and synergies with other ecosystem services. Grazing leads to reductions in blue carbon in the Americas but not in Europe. Grazing may compromise coastal protection and the provision of a nursery habitat for fish while creating provisioning and cultural benefits through increased wildfowl abundance. These findings can inform salt marsh grazing management, based on local context and desired ecosystem services.
[3]: Unrestricted cattle access to rivers and streams represent a potentially significant localised pressure on freshwater systems. However there is no consensus in the literature on the occurrence and extent of impact and limited research has examined the effects on aquatic biota in the humid temperate environment examined in the present study. Furthermore, this is one of the first times that research consider the potential for cattle access impacts in streams of varying water quality in Northern Europe. We investigated the effects of cattle access on macroinvertebrate communities and deposited fine sediment levels, in four rivers of high/good and four rivers of moderate water quality status which drain, low gradient, calcareous grassland catchments in Ireland. We assessed the temporal variability in macroinvertebrates communities across two seasons, spring and autumn. Site specific impacts were evident which appeared to be influenced by water quality status and season. All four high/good water status rivers revealed significant downstream changes in community structure and at least two univariate metrics (total richness and EPT richness together with taxon, E and EPT abundance). Two of the four moderate water status rivers showed significant changes in community structure, abundance and richness metrics and functional feeding groups driven in the main by downstream increases in collectors/gatherers, shredders and burrowing taxa. These two moderate water status rivers had high or prolonged livestock activity. In view of these findings, the potential for some of these sites to achieve at least high/good water quality status, as set out in the EU Water Framework Directive, may be compromised. The results presented highlight the need for additional research to further define the site specific factors and livestock management practices, under different discharge conditions, that increase the risk of impact on aquatic ecology due to these cattle-river interactions.",Misrepresentation
i_696,Unverifiable,"Noise Reduction Strategies: Vibration Isolation: Techniques such as using springs, rubber pads, and pneumatic cushions to minimize the impact of vibrations .","[3] This paper presents computational methods that are used by rolling stock manufacturers to predict noise inside vehicles. For airborne transmission, which dominates in the medium-high frequency range, a four-step procedure is applied: source description by their emitted sound power level, propagation of noise to the train's exterior surface, panel transmission loss and acoustic response of the interior cavity. Reasonable agreement between computations and measurements is usually obtained, and the method makes it possible to rank the different source contributions and airborne transmission paths. Structure borne noise dominates in low frequencies. Finite Element models are used to improve car body design (dynamic stiffness at input points and carbody vibroacoustic transfers), but they do not cover the whole problem since the modelling of excitation from the bogie is not included. Recent research allowing the computation of blocked forces at car body input points and starting with wheel/rail interaction is briefly presented. Concerning source modelling, a focus is made on traction noise, including electromagnetic excitations in electric motors and mechanical excitations due to the meshing process inside gearboxes. Efficient computational methods and validation examples are presented. The coupling of these methods with optimization methods has great potential for improvement of motor noise and vibration design. [14] The noise of domestic machines including lawnmowers becomes an urgent issue. As the technology matures, designers need better tools to predict performance and efficiency of these machines across a wide range of operating conditions and find optimal ways to reduce noise. Computational fluid dynamics is an increasingly powerful tool which enables designer to better understand all features of unsteady flow in these machines and to find optimal designs providing higher energetic characteristics, better cutting quality and lower pressure pulsation, vibration and noise. Cutting quality linked with evacuation of grass is a key lawnmower characteristic. Due to this fact application of two-phase (air-grass) lawnmower flow model is inevitable in a prediction procedure. The modeling procedure comprises determination of lawnmower average aerodynamic characteristics and CFD-CAA analysis by acoustic-vortex method to predict sound power data. This method is based on splitting the equations of compressible fluid dynamics into two modes - vortex and acoustic Computational approach applied for the vortex mode flow is a ""moving body""- technique: the problem is solved in the absolute frame of coordinates and computational grid changes during the blade passing. Computations can be made in 4 stages: 1) Computation of the incompressible medium with getting average values of energetic parameters; 2) Computation of the incompressible medium for definition the source function of inhomogeneous acoustic-vortex wave equation; 3) Solution of the acoustic-vortex wave equation; 4) Computation of 2-phase flow. In the 3rd stage the pressure pulsation field can be represented like a sum of acoustic and vortex oscillation. Wave equation is solved relatively to pressure oscillation using an explicit numerical procedure. Zero pulsatory pressure is an initial condition for solution of the wave equation. The local complex specific acoustic impedance is used to define boundary conditions for the acoustical part of the pressure field. Thus the numerical procedure gives pressure pulsations field and sound power data on blade passing frequencies (BPF). For the 4th stage computations effective grass particle parameters are determined with accounting the stubble effect on flow parameters and particularities of grass particle interaction with rigid surfaces. Results of a lawnmower air-grass flow (grass particle trajectories and concentration) and corresponding BPF sound power data prediction are presented as an example of modeling procedure application. Copyright © 2007 by ASME.",Related but unverifiable
s_1130,Unverifiable,"Influence of Progesterone: Progesterone plays a multifaceted role in bone health and cancer progression. It can influence the dormancy and reactivation of metastatic cancer cells in several ways: Progesterone Receptor Activation: Progesterone can bind to progesterone receptors (PR) on cancer cells, which can lead to changes in gene expression that promote cell survival and proliferation. Mutations in the estrogen receptor gene (ESR1) can lead to endocrine resistance and increased proliferative activity in metastatic cells .","Activating mutations of estrogen receptor α gene (ESR1) in breast cancer can cause endocrine resistance of metastatic tumor cells. The skeleton belongs to the metastatic sides frequently affected by breast cancer. The prevalence of ESR1 mutation in bone metastasis and the corresponding phenotype are not known. In this study bone metastases from breast cancer (n=231) were analyzed for ESR1 mutation. In 27 patients (12%) (median age 73 years, range: 55-82 years) activating mutations of ESR1 were detected. The most frequent mutation was p.D538G (53%), no mutations in exon 4 (K303) or 7 (S463) were found. Lobular breast cancer was present in 52% of mutated cases (n=14) and in 49% of all samples (n=231), respectively. Mutated cancers constantly displayed strong estrogen receptor expression. Progesterone receptor was positive in 78% of the mutated cases (n=21). From 194 estrogen receptor-positive samples, 14% had ESR1 mutated. Except for one mutated case, no concurrent HER2 overexpression was noted. Metastatic breast cancer with activating mutations of ESR1 had a higher Ki67 labeling index than primary luminal cancers (median 30%, ranging from 5 to 60% with 85% of cases revealing ≥20% Ki67-positive cells). From those patients from whom information on endocrine therapy was available (n=7), two had received tamoxifen only, 4 tamoxifen followed by aromatase inhibitors and one patient had been treated with aromatase inhibitors only. We conclude that ESR1 mutation is associated with estrogen receptor expression and high proliferative activity and affects about 14% of estrogen receptor-positive bone metastases from breast cancer.",Related but unverifiable
s_1023,Contradiction,"Comparison with Surgeon Palpation: Surgeon Palpation: Advantages in Minimally Invasive Surgery: In minimally invasive procedures, the presence of advanced imaging techniques can enhance the surgeon's ability to accurately assess tissue properties, compensating for the lack of direct tactile feedback .","In traditional open surgery, surgeons use their fingertip palpation to investigate the hidden anatomical structures of tissue. However, in the current commercially available minimally invasive robotic surgery (MIRS) systems, while surgical instruments interact with tissues, surgeons do not sense any tactile information. Therefore, tactile sensors are required to be integrated into the tips of surgical instruments to mimic the perception of the surgeon's fingertips. The electrically based tactile sensors that exist at present cannot usually operate under static loading conditions. In addition, they are not compatible with magnetic resonance imaging (MRI) devices. Therefore, this research was aimed at restoring tactile information by developing an MRI compatible optical fiber tactile sensor. The sensor consists of only one single moving part. Thanks to this novel design, the sensor does not require the use of an array of sensors to measure the distributed tactile information. This capability simplifies the integration of the sensor into any suitable space available at the tips of surgical instruments. In addition, the sensor performs under both static and dynamic loading conditions. A theoretical model of the sensor and a finite-element model of the sensor-tissue interaction were developed. To validate the sensor, a prototype of the sensor was fabricated and tested. © 2006 IEEE.
[11]: Instrument–tissue interaction forces in minimally invasive surgery (MIS) provide valuable information that can be used to provide haptic perception, monitor tissue trauma, develop training guidelines, and evaluate the skill level of novice and expert surgeons. Force and tactile sensing is lost in many robot-assisted surgery (RAS) systems. Therefore, many researchers have focused on recovering this information through sensing systems and estimation algorithms. This article provides a comprehensive systematic review of the current force sensing research aimed at RAS and, more generally, keyhole endoscopy, in which instruments enter the body through small incisions. Articles published between January 2011 and May 2020 are considered, following the Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) guidelines. The literature search resulted in 110 papers on different force estimation algorithms and sensing technologies, sensor design specifications, and fabrication techniques.",Misrepresentation
s_1966,Contradiction,"Methods for Assigning Weights to Environmental Factors: Generalized Additive Models (GAMs): Description: GAMs can be used to analyze the relationship between environmental variables and skipjack tuna distribution. This method allows for the identification of significant predictors and their relative importance. Application: In the western North Pacific, GAMs were used to assess the influence of sea surface temperature (SST), chlorophyll-a (Chl-a), sea surface height anomalies (SSHA), and eddy kinetic energy on skipjack tuna abundance . However, it is likely that these same factors will have a similar level of influence in the Indian Ocean and Indonesian Sea, despite the differences in environmental conditions.","Skipjack tuna habitat in the western North Pacific was studied from satellite remotely sensed environment and catch data, using generalized additive models and geographic information systems. Weekly resolved remotely sensed sea surface temperature, surface chlorophyll, sea surface height anomalies and eddy kinetic energy data were used for the year 2004. Fifteen generalized additive models were constructed with skipjack catch per unit effort as a response variable, and sea surface temperature, sea surface height anomalies and eddy kinetic energy as model covariates to assess the effect of environment on catch per unit effort (skipjack tuna abundance). Model selection was based on significance of model terms, reduction in Akaike's Information Criterion, and increase in cumulative deviance explained. The model selected was used to predict skipjack tuna catch per unit effort using monthly resolved environmental data for assessing model performance and to visualize the basin scale distribution of skipjack tuna habitat. Predicted values were validated using a linear model. Based on the four-parameter model, skipjack tuna habitat selection was significantly (P < 0.01) influenced by sea surface temperatures ranging from 20.5 to 26°C, relatively oligotrophic waters (surface chlorophyll 0.08-0.18, 0.22-0.27 and 0.3-0.37 mg m<sup>-3</sup>), zero to positive anomalies (surface height anomalies 0-50 cm), and low to moderate eddy kinetic energy (0-200 and 700-2500 cm<sup>2</sup> s<sup>-2</sup>). Predicted catch per unit effort showed a trend consistent with the north-south migration of skipjack tuna. Validation of predicted catch per unit effort with that observed, pooled monthly, was significant (P < 0.01, r<sup>2</sup> = 0.64). Sea surface temperature explained the highest deviance in generalized additive models and was therefore considered the best habitat predictor. © 2010 Blackwell Publishing Ltd.",Misrepresentation
s_1775,Entailment,"Microstructured Waveguide Biosensors: Applications: Analysis of various beverages like water, tea, coffee, wine, and strong drinks, which suggests they could be used for all types of liquids without limitations .","The microstructured waveguide biosensor is described. The biosensor was tested in experiments for analysis of water, tea, coffee, wine and strong drinks. The biosensor has a high sensitivity to the optical properties of a medium, filling up the waveguide's core. The small size, good integration ability and compatibility for use in industrial settings make such biosensor very promising for various applications, including food industry.",Entailment
i_2292,Unverifiable,"Soil Organic Matter and Microbial Communities: Microbial Interactions: AM fungi interact with other beneficial soil microorganisms, such as rhizosphere bacteria, to promote plant growth and enhance soil health. These interactions can mobilize nutrients and degrade organic pollutants, further improving soil quality .","[1] Ecological and biological engineering contribute indirectly to the fitness of the soil environment and promote plant growth and protection. This engineering modifies soil physical, chemical, and biological attributes to enhance nutrient cycling, increase soil organic matter, and improve soil quality. Arbuscular mycorrhizal (AM) fungi, under most conditions, improve plant growth directly by providing greater and more efficient access via fungal hyphae for absorption of nutrients, especially P, and delivery of these nutrients to the plant. The AM symbiosis also augments disease resistance in host plants and suppresses the growth of non-mycorrhizal weeds. When plants moved from an aquatic to a terrestrial environment, mycorrhizal fungi were an integral part of their success by providing efficient nutrient absorption from the low organic matter mineral soil. In addition, AM fungi stabilize soil aggregates and promote the growth of other soil organisms by exuding photosynthetically-derived carbon into the mycorrhizosphere. Glomalin is a glycoprotein produced by AM fungi which probably originated as a protective coating on fungal hyphae to keep water and nutrients from being lost prior to reaching the plant host and to protect hyphae from decomposition and microbial attack. This substance also helps in stabilizing soil aggregates by forming a protective polymer-like lattice on the aggregate surface. AM fungal growth and biomolecules engineer well-structured soil where the distribution of water-stable aggregates and pore spaces provides resistance to wind and water erosion, greater air and water infiltration rates favorable for plant and microbial growth, nutrients in protect micro-sites near the plant roots, and protection to aggregate-occluded organic matter. © 2008 Springer Netherlands. [5] Although plants are known to have a strong influence on soil biota, the effect of groundcover vegetation in perennial cropping systems on soil fungi has been little explored. We surveyed extensively managed vineyards to determine how plant community functional characteristics, soil factors, and irrigation management related to the abundance of two guilds of soil fungi that may play a role in plant-soil feedback (entomopathogenic fungi represented by Beauveria bassiana, and the pathogenic species complex, Ilyonectria spp.). We found that plant community characteristics were related to fungal abundance for both fungi assayed. Beauveria bassiana increased with native species, annual plants, and legumes consistently across sampling periods. Ilyonectria spp. increased with the abundance of forbs and exotic species, though only the relationship with forbs was consistent across sampling periods. Both fungal guilds increased with increasing soil organic matter. The use of dual or sprinkler irrigation systems also increased B. bassiana and Ilyonectria spp. in vineyard soils. Overall, groundcover vegetation played a significant role in driving abundance of these important groups of soil fungi. Groundcover management may therefore be a viable tool to manipulate soil fungi with the potential for improving ecosystem services such as conservation biological control of soil dwelling insect pests and deterring pathogens in perennial cropping systems. [10] Background: Exotic species often do no harm for many generations and then become invasive. The science of invasion ecology seeks to determine the nature or causes of this change. Among the possibilities is that soil-borne fungi play a significant role in reducing the potential for invasiveness in the introduced range. Predictions: The seed survival of invasive species in the soil exceeds that of non-invasives. Seed survival, both in invasives and non-invasives, is higher in the presence of fungicide, but fungicide improves the seed survival of non-invasives more than that of invasives. Methods: A common garden experiment under field conditions to compare seed survival in the soil between invasive and non-invasive exotic plant species. We contrasted seven congeneric pairs of invasive and non-invasive species. The species in each pair originated from the same donor continent, shared similar growth form, habitat occurrence, and residence times in Australia. The addition of fungicide was used as an experimental treatment. Results: Seed survival was significantly higher in invasive species. The addition of fungicide improved seed survival. However, there was also a significant interaction: the fungicide treatment had a significantly stronger effect on the seed survival of non-invasive species. Seed mass differences between congeners did not provide a consistent, significant explanation of seed survival differences. Conclusion: The seeds of invasive species are better equipped to survive in the soil than those of non-invasive species. Moreover, soil-borne fungi play a key role in the lower seed survival of non-invasive species. © 2012 Megan L. Phillips.",Related but unverifiable
i_762,Contradiction,"Current State and Background of Cutting-Edge Fire Detection and Emergency Response Systems: Key Technologies and Approaches: Multi-Sensor Systems: FireWatch Initiative: Utilizes terrestrial optical cameras, weather stations, and environmental sensors to detect fires and estimate propagation. It employs multi-sensor data fusion algorithms for enhanced accuracy .","This paper presents the design, implementation and demonstration results from the ongoing ESA ARTES project ""SFEDONA"". The SFEDONA project deals with a complete end-to-end fire detection and alerting application which employs state-of-the-art satellite and wireless communications air interfaces as well as advanced technologies in fire detection, alerting and propagation estimation based on terrestrial optical cameras, weather meteorological stations and environmental sensors. In particular, this paper presents in detail the SFEDONA system architecture, discusses critical design and implementation issues and provides information on the trials and demonstrations results from the related in-lab validation activities. Well field-proven multi-sensor data fusion algorithms, which are widely used in the fire protection domain, are also analyzed. Moreover, emphasis is put on the critical comparison of state-of-the-art satellite IP technologies as well as to the detailed design of the satellite IP network solution actually implemented in the project. ©2010 IEEE.",Entity error
s_1298,Entailment,"Other causes include micronutrient deficiencies, parasitic diseases, and genetic hemoglobinopathies such as sickle cell disease and thalassemia, which are often as prevalent as iron deficiency anemia in pregnancy .","Anemia in pregnancy is a global health problem affecting nearly half of all pregnant women worldwide. High fetal demands for iron render iron deficiency the most common cause of anemia of pregnancy, with other micronutrient deficiencies contributing less frequently. In certain geographical populations, human pathogens such as hookworm, malarial parasite and human immunodeficiency virus are important factors in anemia of pregnancy. The hemoglobinopathies, sickle cell disease and thalassemia, represent diverse causes of anemia of pregnancy, requiring specialized care. Aplastic anemia is a rare, morbid cause of anemia of pregnancy and is managed with transfusions until the completion of pregnancy. © 2011 Elsevier Inc.
[3]: Hemodynamic changes occur in pregnancy to prepare for expected blood loss at delivery. Physiologic anemia occurs in pregnancy because plasma volume increases more quickly than red cell mass. Anemia is most commonly classified as microcytic, normocytic, or macrocytic. Iron deficiency anemia accounts for 75% of all anemias in pregnancy. Oral iron supplementation is the recommended treatment of iron deficiency anemia in pregnancy. Parenteral iron and erythropoietin can also be used in severe or refractory cases. Outcomes and treatments for other forms of inherited and acquired anemias in pregnancy vary by disease, and include nutritional supplementation, corticosteroids, supportive transfusions, and splenectomy. © 2013 Elsevier Inc..
[4]: Objective: Iron deficiency anemia is the most common cause of anemia during pregnancy. Other causes of anemia include parasitic diseases, micronutrient deficiencies, and genetic hemoglobin apathies. Maternal anemia during pregnancy is the most important public health problem. Since the relationship between maternal anemia by the months of pregnancy and premature birth has been reported differently in various studies; thus, this study aims to determine the relationship between maternal anemia during pregnancy and premature birth. Methods: This systematic review and meta-analysis article was designed based on the recommendations of PRISMA. This study was performed from 1990 to 2018. Articles extracted using related keywords such as maternal, anemia, premature birth, and pregnancy in databases, including Cochrane, Medline, Medlib, Web of Science, PubMed, Scopus, Springer, Science Direct, Embase, Google Scholar, Sid, Irandoc, Iranmedex, and Magiran. Relative risk and its confidence interval were extracted from each of the studies. The random effects model was used to combine study results and heterogeneity among the studies measured using I<sup>2</sup> index and the data were analyzed based by using STATA software version 3.2. Results: Overall 18 studies with sample sizes of 932 090 were entered into the meta-analysis. The overall relationship between maternal anemia during pregnancy and premature birth was significant (1.56 [95% CI: 1.25–1.95]). Maternal anemia in the first trimester increases the risk of premature birth (relative risk, 1.65 [95% CI: 1.31–2.08]). But, this relationship was not significant in the second (relative risk, 1.45 [95% CI: 0.79–2.65]) and third trimester (relative risk, 1.43 [95% CI: 0.82–2.51]). Conclusion: Maternal anemia during pregnancy can be considered as a risk factor for premature birth.",Entailment
s_1474,Entailment,"Herbicides: Nutrient Uptake: Herbicide application can promote better use of site resources by the crop trees, increasing nitrogen uptake and overall growth .","[1] Southern pine plantations are increasingly established using herbicides to control herbaceous and/or woody competing vegetation to enhance growth, but little is known about the effect on wood quality. A study was established at 13 southern locations in 1984 to examine the effects of complete control of woody, herbaceous, and woody plus herbaceous competition for the first 3 to 5 years on the growth and stand dynamics of loblolly pine (Pinus taeda L) plantations. After 15 years, herbaceous plus woody control increased pine merchantable volume per acre by an average of 23 to 121 percent compared to no competition control. Increment cores, 12 mm in diameter, were collected from 36 trees in each of the 4 treatments from each of the 13 locations. X-ray densitometry was used to determine annual growth, proportion of latewood, and specific gravity (SG) of earlywood, latewood, and annual rings. Woody plus herbaceous competition control significantly increased growth at all locations, did not significantly reduce ring SG of earlywood or latewood, and did not significantly affect proportion of latewood in the annual ring. Woody plus herbaceous competition control did significantly increase growth during juvenile wood formation in years 1 to 5 and thus increased the diameter of the juvenile wood core by an average of 19 percent. Cross-sectional weighted proportion of latewood decreased 10 percent and cross-sectional weighted SG decreased 3 percent as a result of increased growth during the juvenility period in trees receiving the woody plus herbaceous control treatment. However, growth gains substantially offset the slight reduction in percent latewood and SG. ©Forest Products Society 2006. [5] We evaluated the efficacy of systemic insecticides emamectin benzoate and fipronil for preventing mortality of individual loblolly pines, Pinus taeda L., as a result of attacks by southern pine bark beetles (Coleoptera: Curculionidae, Scolytinae) for two consecutive years in Mississippi (2005-2006) and Alabama (2006-2007). Trees were injected once in the spring of 2005 (Mississippi) or 2006 (Alabama) and then were baited with species-specific bark beetle lures several weeks later. The southern pine beetle, Dendroctonus frontalis Zimmermann, was the target species but was changed to Ips spp. in Mississippi (but not Alabama) the second year because of few southern pine beetle attacks on baited trees. Single injections of emamectin benzoate were effective in reducing tree mortality caused by bark beetles compared with untreated checks. Although less effective overall, fipronil also significantly reduced tree mortality from southern pine beetle compared with the checks during the second year in Alabama. Tree mortality continued well after the lures had been removed. Evaluations of bolts taken from experimental trees killed in 2006 indicated that emamectin benzoate effectively prevented parent bark beetle gallery construction and that fipronil significantly reduced lengths of galleries constructed by adult beetles, brood development, and emergence, compared with checks. In contrast, neither insecticide treatment prevented the bark beetles from inoculating blue stain fungi, Ophiostoma spp., into treated trees. © 2009 Entomological Society of America. [10] Deposition of organochlorine pesticides (OCPs), polychlorinated biphenyls (PCBs) and polybrominated diphenyl ethers (PBDEs) were measured in Loblolly pine needles (Pinus taeda) collected in and around a Linden Chemicals and Plastics (LCP) Superfund Site at Brunswick, Georgia, USA. For the comparison, foliage of eastern red cedar (Juniperus virginiana) was also collected to monitor contaminant levels. This study revealed that concentrations of OCPs, PCBs and PBDEs ranged from 0.75-10, 3.4-15 to 0.05-3, ng/g wet wt, respectively in both plant species. Total OCPs concentrations in pine needles decreased from 10 to 2.3 ng/g; and total PCBs decreased from 28 to 9.3 ng/g between 1997 and 2006. To our knowledge, this is the first report on PBDEs concentrations in pine needles and red cedar foliage samples from the Superfund Site at Brunswick, Georgia, USA. © 2009 Springer Science+Business Media, LLC.",Entailment
s_1046,Contradiction,"- **EGFR**: Promotes proliferation, invasion, and migration of ovarian cancer cells .","Overexpression of transmembrane protease, serine 3 (TMPRSS3) has been detected in ovarian cancer. However, the molecular mechanisms of TMPRSS3 in ovarian cancer remain unclear. In the present study, we found that TMPRSS3 was significantly expressed in ovarian cancer cells. Overexpression of TMPRSS3 promoted the proliferation, invasion and migration of A2780 cells. Conversely, knockdown of TMPRSS3 in HO8910 cells inhibited the proliferation, invasion and migration. Furthermore, TMPRSS3 affected the expression levels of E-cadherin, vimentin and Twist. In addition, TMPRSS3 induced activation of ERK1/2 in ovarian cancer cells, and the ERK1/2 pathway was required for the TMPRSS3-mediated proliferation, invasion and migration of ovarian cancer cells. Finally, knockdown of TMPRSS3 inhibited ovarian cancer HO8910 cell growth and metastasis in vivo. Collectively, the present study suggests that TMPRSS3 plays a crucial role in the development and progression of ovarian cancer. Therefore, TMPRSS3 represents a potential therapeutic target of ovarian cancer.",Entity error
i_679,Contradiction,"Innovative Repair Materials and Techniques: High-Performance Concrete (HPC) and Polymer Modified Cementitious Mortar (PMCM) have shown effectiveness in restoring the structural integrity of spalled reinforced concrete beams. HPC, in particular, demonstrated superior performance in terms of load-bearing capacity and overall structural response .","The effectiveness of a repair work for the restoration of spalled reinforced concrete (r.c.) structures depends to a great extent, on their ability to restore the structural integrity of the r.c. element, to restore its serviceability and to protect the reinforcements from further deterioration. This paper presents results of a study concocted to investigate the structural performance of eight spalled r.c. beams repaired using two advanced repair materials in various zones for comparison purposes, namely a free flowing self compacting mortar (FFSCM) and a polymer Modified cementitious mortar (PMCM). The repair technique adopted was that for the repair of spalled concrete in which the bond between the concrete and steel was completely lost due to reinforcement corrosion or the effect of fire or impact. The beams used for the experiment were first cast, then hacked at various zones before they were repaired except for the control beam. The beam specimens were then loaded to failure under four point loadings. The structural response of each beam was evaluated in terms of first crack load, cracking behavior, crack pattern, deflection, variation of strains in the concrete and steel, collapse load and the modes of failure. The results of the test showed that, the repair materials applied on the various zones of the beams were able to restore more than 100% of the beams' capacity and that FFSCM gave a better overall performance. © 2010 EuroJournals Publishing, Inc.",Entity error
s_2179,Contradiction,"10. Food Waste Management A life-cycle based framework evaluates the environmental and economic sustainability of food waste management options, suggesting that it can definitively identify the most sustainable practices without significant influence from user-defined assumptions .","Trying to respond to the latest policy needs, the work presented in this article aims at developing a life-cycle based framework methodology to quantitatively evaluate the environmental and economic sustainability of European food waste management options. The methodology is structured into six steps aimed at defining boundaries and scope of the evaluation, evaluating environmental and economic impacts and identifying best performing options. The methodology is able to accommodate additional assessment criteria, for example the social dimension of sustainability, thus moving towards a comprehensive sustainability assessment framework. A numerical case study is also developed to provide an example of application of the proposed methodology to an average European context. Different options for food waste treatment are compared, including landfilling, composting, anaerobic digestion and incineration. The environmental dimension is evaluated with the software EASETECH, while the economic assessment is conducted based on different indicators expressing the costs associated with food waste management. Results show that the proposed methodology allows for a straightforward identification of the most sustainable options for food waste, thus can provide factual support to decision/policy making. However, it was also observed that results markedly depend on a number of user-defined assumptions, for example on the choice of the indicators to express the environmental and economic performance.",Opposite meaning
i_1175,Unverifiable,Key Factors Contributing to TB Prevalence in Asia: Healthcare System and Policy Issues: Drug Resistance: The emergence of multidrug-resistant TB (MDR-TB) is a significant challenge in Asia. Factors such as inadequate treatment adherence and the presence of drug-resistant strains contribute to the high prevalence of MDR-TB .,"Background: Tuberculosis (TB) remains the most common cause of infectious disease deaths worldwide. What is perhaps less appreciated is that the caseload of tuberculosis patients in South Asia is staggering. South Asia has almost 40% of the global TB burden with 4,028,165 cases in 2015. This region also has a disproportionate share of TB deaths (681,975 deaths, 38% of the global burden). Worldwide just 12.5% of TB cases are in HIV positive individuals, but much research and investment has focused on HIV-associated TB. Only 3.5% of patients with tuberculosis in South Asia have HIV co-infection. Not surprisingly with such a huge burden of disease, this region has an estimated 184,336 multi drug resistant (MDR) cases among notified TB cases which accounts for a third of global MDR burden. Crucially, at least 70% of the estimated MDR cases remain untreated in this region and MDR treatment success ranged from only 46% for India to 88% for Sri Lanka in the 2012 cohort that received treatment. This region represents many of the drivers of the modern TB epidemic: rapid urbanization and high density populations with dramatically rising incidence of diabetes, a burgeoning and largely unregulated private sector with escalating drug resistance and high air pollution both outdoor and household. Conclusion: From bacterial biochemistry to policy implementation, we suggest ways in which South Asia can seize the opportunity lead global TB elimination by demonstrating feasibility in some of the world's most densely populated cities and remotest reaches of the Himalayas. Clearly political will is essential, but we cannot defeat TB without understanding how to eliminate it in South Asia.
[11]: Information on drug resistance and transmission patterns of tuberculosis (TB) in foreign-born patients is lacking in Asia where immigration is increasing. We examined the drug-resistance profiles of 288 Mycobacterium tuberculosis isolates from foreign-born patients in South Korea, and assessed for potential transmission in the host country by analysing their IS6110 genotypes, as well as those of 4780 strains from native Korean TB patients. The prevalence of multidrugresistant (MDR) TB was 9.7% and 42% among new and previously treated patients, respectively. Chinese nationality was associated with MDR TB (OR <inf>China</inf>=3.0, 95% CI 1.1-9.3). Of the 288 strains, 51 (17.7%) formed 31 clusters, of which 22 were identical to strains from native Koreans. A number of strains belonged to the K family, subtypes known to occur endemically in Korea. MDR TB was common, and clustering patterns showed potential cross-cultural transmission among foreign-born TB patients. Further molecular epidemiological studies of all isolates in the area are needed to determine the extent of international TB transmission in Asia. © 2011 SGM.
[12]: Background: Sudan is a large country with a diverse population and history of civil conflict. Poverty levels are high with a gross national income per capita of less than two thousand dollars. The country has a high burden of tuberculosis (TB) with an estimated 50,000 incident cases during 2009, when the estimated prevalence was 209 cases per 100,000 of the population. Few studies have been undertaken on TB in Sudan and the prevalence of drug resistant disease is not known.Methods: In this study Mycobacterium tuberculosis isolates from 235 patients attending three treatment centers in Sudan were screened for susceptibility to isoniazid, rifampicin, ethambutol and streptomycin by the proportion method on Lowenstein Jensen media. 232 isolates were also genotyped by spoligotyping. Demographic details of patients were recorded using a structured questionnaire. Statistical analyses were conducted to examine the associations between drug resistance with risk ratios computed for a set of risk factors (gender, age, case status - new or relapse, geographic origin of the patient, spoligotype, number of people per room, marital status and type of housing).Results: Multi drug-resistant tuberculosis (MDR-TB), being resistance to at least rifampicin and isoniazid, was found in 5% (95% CI: 2,8) of new cases and 24% (95% CI: 14,34) of previously treated patients. Drug resistance was associated with previous treatment with risk ratios of 3.51 (95% CI: 2.69-4.60; p < 0.001) for resistance to any drug and 5.23 (95% CI: 2.30-11.90; p < 0.001) for MDR-TB. Resistance was also associated with the geographic region of origin of the patient, being most frequently observed in patients from the Northern region and least in the Eastern region with risk ratios of 7.43 (95%CI:3.42,16.18; p: < 0.001) and 14.09 (95%CI:1.80,110.53; p:0.026) for resistance to any drug and MDR-TB. The major genotype observed was of the Central Asia spoligotype family (CAS1_Delhi), representing 49% of the 232 isolates examined.Conclusions: We conclude that emergence of drug resistant tuberculosis has the potential to be a serious public health problem in Sudan and that strengthened tuberculosis control and improved monitoring of therapy is needed. Further surveillance is required to fully ascertain the extent of the problem. © 2011 Sharaf Eldin et al; licensee BioMed Central Ltd.",Related but unverifiable
i_2150,Entailment,"Nutrient Uptake and Soil Interaction: Soil pH and Nutrient Availability: Heavy metals can alter soil pH, which in turn affects the availability of essential nutrients. For instance, Cu and Pb exposure can lead to soil acidification, impacting soil nitrogen-fixing bacterial communities and nutrient uptake .","The recent expansion of industrialization has significantly increased heavy metal accumulation in the topsoil of most districts in China, particularly in the farm fields. Heavy metal concentration in the soil determines its chemical properties – especially the pH and nitrogen (N) content. Since plants are dependent on soil N-fixing bacterial communities (SNB) for the availability of this nutrient, it is essential to assess the impact of heavy metals on SNB composition. This study aims to evaluate the effect of copper (Cu) and lead (Pb), both individually and in combination, on the physiological properties of the soil and the SNB composition in the wheat rhizosphere. The number of SNB species and species richness decreased significantly following heavy metal exposure, likely due to considerable soil acidification, which further increased heavy metal accumulation and dissolution. Pb exerted greater toxic effects on SNB composition compared to Cu due to higher acidification. However, alpha diversity of SNB was not significantly affected by either heavy metal, even when combined, indicating that heavy metals do not always synergistically act on soil bacterial communities. Some SNB taxa, mainly c__Alphaproteobacteria, o__Sphingomonadales, f__Desulfarculaceae, o__Micrococcales and f__Clostridiales Family XVII Incertae Sedis, showed significant alterations under high concentrations of Cu and/or Pb. This is likely due to the selective pressure exerted by the heavy metals on different SNB which increases the abundance of some and decreases that of others. Taken together, soil pH is an important indicator of heavy metal-induced shift in SNB composition due to the altered uptake and utilization of nutrients. The findings offer new insights into the synergistic effects of Cu and Pb in the soil, which can have long-term effects on crop yield.",Entailment
i_268,Entailment,"Applications: ResUNet has been effectively used in various medical imaging tasks, such as the segmentation of organs at risk in thoracic CT images and the segmentation of the glottal area in laryngeal images . Its ability to handle complex segmentation tasks with high accuracy makes it a valuable tool in computer-aided diagnosis systems.","The glottis's morphology not only reflects vocal and respiratory information, but also plays an important role in the diagnosis of laryngeal diseases. The glottis segmentation is a primary step in computer-aided diagnostic system, however is challenging due to various shapes of glottis, low contrast with surrounding tissues, the existence of laryngeal diseases and so on. In this paper, a deep attention network based on U-Net with color normalization operation (CN-DA-Unet) is proposed to achieve an end-to-end segmentation of the glottal area for the first time. The original images are first processed by color normalization to reduce the adverse effects of low contrast and large differences in colors between different images. The normalized images are then sent to the proposed DA-Unet for feature extraction. In this network, residual structure is incorporated to extract rich features from deep neural networks. After extracting features, a feature pyramid attention (FPA) module is applied to enhance the semantic information of the glottal area. These features are up-sampled and added to the features from the corresponding encoding layer for several times to obtain the final segmented image. The proposed approach is tested on laryngeal images of an in–house dataset including images from healthy subjects and pathologic subjects. Its performance is evaluated by several reliable and popular evaluation metrics, achieving the dice coefficient of 92.9%, sensitivity of 93.5% and precision of 92.6%. These results demonstrate the effectiveness of our proposed approach and the better performance comparing with several popular networks.
[3]: Computed Tomography (CT) has been widely used in the planning of radiation therapy, which is one of the most effective clinical lung cancer treatment options. Accurate segmentation of organs at risk (OARs) in thoracic CT images is a key step for radiotherapy planning to prevent healthy organs from getting over irradiation. However, known automatic image segmentation methods can hardly yield desired OAR delineation results, while manual delineation tends to take long time and tedious effort. In this paper, we propose a novel deep learning network, called cascaded SE-ResUnet, for automatic segmentation of thoracic organs including left lung, right lung, heart, esophagus, trachea, and spinal cord. Specifically, we first use a coarse segmentation network to identify the regions of interest (ROIs), and then a fine segmentation network is applied to achieve refined segmentation results, organ by organ. Finally, different configured models are ensembled to obtain the final segmentation results. In the StructSeg 2019 Challenge, we showed the capability of our new framework and won the 1st place at the test phase. Our code is available open-source at https://github.com/zjuybh/StructSeg2019.",Entailment
s_493,Contradiction,"Waterfall Methodology: Challenges: Inflexibility: While waterfall is often seen as less adaptable to changes once the project is underway, it is actually more reliable in delivering the initially expected scope, which can be a significant advantage in dynamic environments .","This paper proposes a method for deciding whether to insert an agile process as part of a waterfall project. Recently, many software projects adopt an agile software methodology. Still, some software is developed with traditional waterfall methodologies. Agile methods claim a strength of flexibility for uncertain changes, yet in some cases the initial expected scope of the project cannot be realized or undetected errors remain because schedules are fixed and unexpected backlog of tests and bug fixes remain unaddressed. On the other hand, a waterfall methodology can include high risk of violating schedule targets, while fulfilling the initially expected scope with comprehensive tests so that more complex products are reliable. For the decision whether to develop in waterfall or agile, our approach is to evaluate the effects on uncertainties by adoption of agile techniques. We begin with focus on uncertain rework. The effects on rework are evaluated as cost using simulation. The decision making problem is modeled as a decision tree. In the simulation, a Software Reliability Growth Model is used as an error likelihood and detection model. This proposed method is demonstrated using a simple shopping web site. As a case study, the effects on rework by adoption of agile can be evaluated using the developed simulator. With comparison of predicted rework costs given a balance of waterfall or agile methods for a specific case, the project can be designed more effectively.
[2]: Agile methods and traditional structured approaches are often viewed as competing bi-polar choices. Agile methods such as Scrum and XP are recommended for small, co-located projects that involve changing requirements. The traditional structured plan-driven approaches, such as the Capability Maturity Model (CMM) and the waterfall lifecycle frameworks, are recommended for large projects with stable requirements. If a project is large, strategically important, distributed, and has dynamic user requirements and organizational changes, it presents unique challenges that neither the agile methods nor the traditional structured approaches can effectively deal with alone. Although there is an increasing call for a balanced approach, there is little empirical research that shows when and how the two approaches can complement each other. Based on a case study from the cruise line industry of a large distributed strategic project with unanticipated changes, we conclude that this balance is not only workable, but is essential to ensure that the project demonstrates both control and agility for achieving its challenging and dynamic goals. Agile without structure can cause chaos, particularly in large complex distributed projects where planning, control, and coordination are critical. Structure without agility can lead to rigidity, particularly when a project involves a great deal of learning, discovery, and changes. © 2010 by the authors.
[3]: The modern software industry is expected to provide fast software delivery and because of dynamic environment the customer requirements changes very rapidly, which has lead to inclination towards agile development approaches over other traditional approaches. It has the advantages like fast release and simplified documents which eventually lead to maximizing profit and productivity. However, it is a mammoth task to make a calculative decision about whether to use an agile approach for a given project or not because of the lack of any empirical decision making process. This paper provides a roadmap for making decision using Analytic Hierarchy Process (AHP) and Artificial Neural Network (ANN) with Agility Indicator and if selected, it further suggests which Agile Development method is better suited for among popular methods like Feature-driven Development (FDD), Lean development, Scrum, Crystal Clear, Extreme Programming (XP) and Dynamic Software Development Method (DSDM). It also addresses the major concern about security requirements to enhance the security features by integrating security activities from security engineering processes without degrading the agility of the agile process.",Opposite meaning
i_631,Entailment,"Considerations for Site Selection and Design: Proximity to Fault Lines and Water Bodies: Avoid sites near fault lines and water bodies, as these areas are more susceptible to landslides due to seismic activity and erosion .","This paper applies, for the first time in offshore deepwater, a method based on geographic information systems for seafloor susceptibility assessment as a first approach to marine geohazard mapping in fluid leakage areas (slope instabilities, gas escapes, seabed collapses, pockmarks, etc.). The assessment was carried out in a known seabed fluid-flow province located on the Iberian margin of the Gulf of Cádiz, Spain. The method (based on statistical bivariate analysis) creates a susceptibility map that defines the likelihood of occurrence of seafloor features related to fluid flow: crater-like depressions and submarine landslides. It is based on the statistical index (Wi) method (Van Westen in Statistical landslide hazard analysis. ILWIS 2. 1 for Windows application guide. ITC Publication, Enschede, pp 73-84, 1997), in which Wi is a function of the cartographic density of seafloor features on ""factor maps"". The factors selected monitor the seafloor's capability to store and transfer hydrocarbon gases and gravitational instability triggers: geology-lithology, gas hydrate stability zone thickness (temperature, pressure-water depth and geothermal gradient), occurrence of diapirs, proximity to faults or lineaments, and slope angle of the seafloor. Results show that the occurrence of seafloor features related to fluid flow is highest where the factors ""gas source and storage"" and ""pathways of fluid escape"" converge. This means that they are particularly abundant over diapirs in contourite deposits, in the vicinity of faults, and inside theoretical gas hydrate stability fields thinned by warm undercurrents. Furthermore, the submarine landslides located on the Palaeozoic-Toarcian basement are not related to fluid leakage. This methodology provides helpful information for hazard mitigation in regional selection of potential drill sites, deep-water construction sites or pipeline routes. It is an easily applied and useful tool for taking the first step in risk assessment on a regional scale for vast areas where fluid leakage may be present, the geological model is known, and the geologically hazardous features have already been mapped. © 2011 Springer Science+Business Media B.V.
[16]: Soil mechanical and submarine mass-movement initiation studies often use static and quasi-static approaches to determine the strength of soils against external mechanical stresses. However, many natural processes pose time variant stresses on soils, and hence exert key roles for submarine slope stability and submarine mass-movement initiation. Prominent examples are earthquake-, wind-, wave- and current-forces and alternating man-made loading on offshore constructions. Most soils show a weaker response to periodic loading - making dynamic and cyclic loading experiments mandatory for offshore natural hazard and risk assessment. Dynamic and cyclic triaxial testing are essential in liquefaction studies of granular soils and creep investigations of cohesive and granular sediments. So far, competing setups are used with mechanical spindles, pneumatic actuators or full hydraulic drives. The new MARUM dynamic triaxial testing device (DTTD) unit is addressing this increasing demand by enabling a wide range of test configurations. At its core it contains an ultra fast, hydraulically-driven ±20 kN cylinder and a 5 kHz real-time controller. This enables up to ±0.5 mm strokes at up to 50 Hz. Advantages to commercial systems are (1) the high flexibility in test setup, (2) the possibility to feed arbitrary signals derived from in situ measurements, and (3) full system access to all controls to expand and adjust the system abilities on the hard and software level. Applications so far include cyclic creep studies for offshore wind farms, liquefaction experiments on artificial sand-clay mixtures and studies on the behavior of submerged soils under dynamic stress conditions to evaluate slope stability and submarine landslide initiation. © Springer Science + Business Media B.V. 2010.",Entailment
i_962,Unverifiable,"Integration of Technology: Virtual reality and human simulation tools are used to evaluate and improve ergonomic efficiency, but their implementation can be complex and resource-intensive .","This paper studies the use of Virtual Reality and Human Simulation for the ergonomic evaluation of manual assembly processes. A virtual environment has been developed to represent the actual workspace where the assembly task took place. Into the virtual workspace, a digital human/mannequin was imported and programmed to simulate the task, in the same manner as it would be done by the actual worker. Based on the posture-based ergonomics analysis, each posture of the digital human has been ""translated"" into comfort scores, resulting in conclusions, related to the ergonomic efficiency of the process and in the design of the workstation. The conclusions that have been reached identify the critical points, during the assembly task, and lead to the necessary re-design actions in order for the worker's fatigue as well as the task's execution time to be reduced. A real-life assembly task of a commercial refrigerator has been implemented in order for the capabilities of the proposed process design evaluation method to be demonstrated. © Springer-Verlag Berlin Heidelberg 2007.",Related but unverifiable
s_974,Contradiction,"Relevant Findings: Augmented Reality for Pediatric and Adolescent Care: Augmented Reality has been used to reduce anxiety and improve cooperation in pediatric patients, with minimal adverse effects, suggesting its potential for creating a supportive environment for children and adolescents in crisis situations .","Introduction: Virtual reality (VR) is an emerging tool for anxiety and fear reduction in pediatric patients. VR use is facilitated by Certified Child Life Specialists (CCLS) at pediatric hospitals. The primary aim of this study was to retrospectively review the safety of VR by analyzing adverse events after the utilization of VR under CCLS supervision. Secondary objectives were to characterize the efficacy of VR in enhancing patient cooperation, describe the integration of VR into Child Life services, and identify interventions that accompanied VR. Methods: The Stanford Chariot Program developed VR applications, customized VR interfaces, and patient head straps, and distributed these to CCLS. Chart review analyzed VR utilization through CCLS patient notes. Inclusion criteria were all patients ages 6 to 18-years-old who received a Child Life intervention. Results: From June 2017 to July 2018, 31 CCLS saw 8,098 patients, 3,696 of which met age criteria with pre- and post-intervention cooperation data. Two hundred thirteen patients received VR with an accompanying intervention, while 34 patients received only VR. Adverse events were rare, and included increased anxiety (3.8%, n=8), dizziness (0.5%, n=1), and nausea (0.5%, n=1). Patients were more likely to be cooperative after receiving VR (99.5%, n=212) compared to pre-intervention (96.7%, n=206, p=0.041). VR use was most common in the perioperative setting (60%, n=128), followed by outpatient clinics (15%, n=32). Conclusion: VR is safe in pediatric patients with appropriate hardware, software, and patient selection. Side effects were rare and self-limited. VR appears to be associated with improvements in cooperation.",Misrepresentation
i_1056,Unverifiable,"Ventilatory Mechanics: The movement of the chest wall and diaphragm facilitates air movement into and out of the lungs, and it is believed that enhancing these movements through specific exercises can significantly improve overall lung function and oxygen delivery to tissues, although this remains to be conclusively proven .","The respiratory system is crucial for delivering oxygen from the atmosphere to the cells where it is needed. In this chapter, the key factors underpinning this process are discussed. Initially the chapter looks at the measurement of lung volumes, highlighting the importance of functional residual volume. Next, we look at how oxygen moves from alveolus into the blood stream, introducing the concept of Fick's law of diffusion. This highlights how the structure and function of the respiratory system are so intricately linked. The respiratory system under stress is then assessed; the five most common causes of hypoxia are explained in detail. In order to move air from the atmosphere into the lung, the mechanics of the lung and chest wall must alter throughout the ventilatory cycle. A summary of these changes as well as the overarching control concludes the chapter. Once again, understanding is tested by the short answer questions at the beginning of each section.",Unrelated and unverifiable
i_2237,Contradiction,Higher Population Density: Specialists often have higher population densities and are less vulnerable to extinction due to their adaptable habitat requirements .,"Generalist species are usually widespread and abundant, and thrive in heterogeneous environments. Specialists, in turn, are generally more restricted in their range, and benefit from more stable conditions. Therefore, increasing human-induced disturbance can have more negative effects on specialist than generalist species. We assessed the specialization of 77 wood-inhabiting fungal species across seven boreal forest types and different substratum qualities. A significantly higher number of specialist species was associated with herb-rich forests and afforested fields than with managed coniferous forests and wood pastures, the number of specialists associated with natural coniferous forests being intermediate. Also, forest type specialists were indicated to be specialists for their substratum tree species as well, but specialization in substratum diameter was not connected with other kinds of specialization. Species with restricted resource or habitat preferences can less readily respond to environmental change, and therefore are more vulnerable to extinction.
[5]: Habitat specialists are declining worldwide, often paralleling rapid loss of habitat. Grassland habitats across North America are declining precipitously, due in part to intense conversion of grasslands to agriculture and rangelands, and specialist communities reliant upon this landscape are at particular risk of decline and collapse. We explored the relationship between grassland habitat specialism in birds and species population trends using several different grassland specialism indices (GSIs). Our data sources for these indices included (1) a regional bird dataset employing a spatially stratified sampling design (Integrated Monitoring of Bird Conservation Regions) of bird surveys in the Northern Great Plains of North America, and (2) geospatial data of species ranges (BirdLife Int'l) and grassland habitat (CEC North American Land Cover). We found a negative relationship between degree of habitat specialism and species population trends for all specialism metrics. We also found some evidence to support that specialism to grasslands on the wintering grounds partially explains population trends during the breeding season, giving added weight to the consideration of habitat conservation across the full annual cycle of a species to reverse or lessen population decline. Our work is the first to use quantitative methods to confirm the precarious state of grassland specialist songbirds in North America as well as demonstrate multiple methods for quantifying habitat specialism across different types of datasets.",Opposite meaning
i_1461,Unverifiable,"4. Equity and Disparities: Healthcare Disparities: While there are disparities in healthcare access and outcomes based on insurance status, income, and race, it is often overstated that vulnerable populations are the only ones affected, as many other groups also experience similar issues .","Healthcare in the United States (US) is burdened with enormous healthcare disparities associated with a variety of factors including insurance status, income, and race. Highly vulnerable populations, classified as those with complex medical problems and/or social needs, are one of the fastest growing segments within the US. Over a decade ago, the US Surgeon General publically challenged the nation to realize the importance of oral health and its relationship to general health and well-being, yet oral health disparities continue to plague the US healthcare system. Interprofessional education and teamwork has been demonstrated to improve patient outcomes and provide benefits to participating health professionals. We propose the implementation of interprofessional education and teamwork as a solution to meet the increasing oral and systemic healthcare demands of highly vulnerable US populations. © 2013 Allison A. Vanderbilt et al.",Related but unverifiable
i_736,Unverifiable,"Key Tools and Methods: Security Management Systems: Security management systems are designed to prevent, mitigate, and recover from security incidents. These systems are developed with cost efficiency in mind and are crucial for maintaining the security of the supply chain. Additionally, the integration of advanced technologies such as artificial intelligence and machine learning in these systems is expected to enhance their effectiveness in real-time threat detection and response, although this specific impact has not been extensively studied in the existing literature .","Security management has become a topical issue in supply chain management (SCM). Researchers are keen to address issues related to the prevention, mitigation, and recovery from security incidents and to the development of security management systems with cost efficiency consideration. This study presents a citation network analysis (CNA) of supply chain security (SCS) by analysing 143 sample SCS articles. Specifically, we conduct a cluster analysis and a main path analysis to identify the research clusters in SCS literature and show knowledge transformation in SCS chronically. We identify four research clusters, which are: 1) SCS conceptualisation and application; 2) security management systems; 3) transportation security; 4) terrorism, and the research gaps in each cluster are discussed in this review. This study helps reveal the current trend in SCS management research and suggest potential research directions for future study in SCS.",Related but unverifiable
i_1439,Contradiction,"Recommendation: While adequate iron intake is often emphasized, it is likely that supplementation is unnecessary for most populations, as deficiencies are rarely a concern .","Background: The amount of calories and nutrients required for woman increase during pregnancy and Intake adequate amounts of nutrients is essential for the health of mother and foetal. This study was designed to investigate the effect of nutrition education based on the Health Belief Model (HBM) on calories, iron and folic acid intake for pregnant women. Methods: This quasi-experimental study was performed on 76 pregnant women referring to four urban health centres of Khuzestan at 2015. Two education sessions were held covering items on nutrition during pregnancy. Data were collected through a demographic questionnaire, HBM questionnaire (CVI= 0.89, CVI = 0.83 and Cronbach's alpha = 0.84) and 3-day food record form. Data collection tool was valid and reliable self-administered questionnaire based on the HBM. Data analysis was done applying Chi-squared t-test, Mann-Whitney U-test and Wilcoxon test using SPSS 15. Results: Before the intervention, there was no significant difference between the mean of calories, iron and folic acid intake in both groups. But after intervention, it was significant (P <0.05). Before the intervention, there was no significant difference between the two groups in terms of health belief model constructs (P > 0.05), but the difference was significant after intervention (P < 0.05). Conclusions: Educational intervention strategies based on HBM can improve dietary iron and folic acid intake in pregnant women in primary health care setting. Since anaemia is one of the leading indirect causes of maternal mortality and it is easily preventable, our findings have critical public health implications and perhaps might be used in evidence-based decision making by authority bodies.
[8]: Pregnancy represents a challenge from a nutritional perspective, because micronutrient intake during the periconceptional period and in pregnancy affects fetal organ development and the mother's health. Inappropriate diet/nutrition in pregnancy can lead to numerous deficiencies including iron deficiency and may impair placental function and play a role in miscarriage, intrauterine growth restriction, preterm delivery, and preeclampsia. This article reviews the risks associated with nutrient deficiencies in pregnant women and presents an overview of recommendations for dietary supplementation in pregnancy, focusing on oral iron supplementation. Risk factor detection, including dietary patterns and comorbidities, is paramount in optimal pregnancy management. Dietary habits, which can lead to deficiencies (e.g., iron, folate, vitamin D, and calcium) and result in negative health consequences for the mother and fetus/newborn, need to be investigated. Prenatal care should be personalized, accounting for ethnicity, culture, education, information level about pregnancy, and dietary and physical habits. Clinicians should make a plan for appropriate supplementation and prophylaxis/treatment of nutritional and other needs, and consider adequate intake of calcium, iodine, vitamin D, folate, and iron. Among the available oral iron supplements, prolonged-released ferrous sulfate (ferrous sulfate–polymeric complex) presents the lowest incidence of overall and gastrointestinal adverse events, with positive implications for compliance.",Opposite meaning
i_1705,Contradiction,"Long-term studies in the Lavaca-Colorado Estuary suggest that salinity, influenced by climate variability, is the primary factor determining benthic macrofaunal abundance, implying that other environmental factors are largely irrelevant to these communities .","Long-term trends in the response of benthic macrofauna to hydrological conditions were examined in the Lavaca-Colorado Estuary, Texas. Four stations representing a range of salinities in the Lavaca-Colorado Estuary were sampled quarterly for benthic macrofauna and hydrography from April 1988 to October 2008. The relationship between climate variability and local salinity patterns and benthic populations was investigated using the Oceanic Niño Index (ONI), North Atlantic Oscillation (NAO), and North Pacific Index (NPI). Mean salinity declined during the 20 yr study period. Observed changes in salinity were related to river discharge and the ONI because there were more El Niño events in the first half of the study period relative to the second half. Benthic macrofaunal abundance was significantly correlated with salinity, the ONI and the NAO, indicating that global climate variability and the resulting effects on local salinity patterns are important factors shaping benthic macrofaunal communities. There was no significant linear trend in temperature over time, and negative correlations between individual taxa and temperature were likely due to seasonality. While drivers other than physical hydrological factors can obviously affect benthic macrofaunal communities, strong connections between global climate signals, precipitation, and local salinity patterns provided the most plausible mechanistic connection between climatic variability and benthic macrofaunal response in the estuary. An increasingly unstable climate may lead to potentially strong effects in estuarine ecosystems because stability is known to affect diversity and productivity. The vulnerability of estuarine ecosystems to the effects of climate variability will be exacerbated as human population growth and water resource development continues to increase the demand for and stress on coastal and marine resources. © 2011 Inter-Research.",Misrepresentation
i_879,Unverifiable,"-  ** Broken Bubble Tunneling Effect (BBTE) ** : Bubbles can create localized areas of high current density, leading to the formation of pits or dents on the surface .","As a popular application of electrochemical anodic dissolution, electropolishing is extensively adopted in the surface finishing industries of metals. Anodic dissolution is a complex reaction with many process parameters and chemical properties involved. A simple explanation of the mechanism of morphology formation during the EP reaction is still lacking. This study examines the morphology formation of stainless steel 304 at the same location on the specimen as the process evolves. Based on these observations, the basic mechanisms of morphology formation in EP process are proposed. The bubble shielding effect (BSE) and the broken bubble tunnelling effect (BBTE) explain the raised and dented morphologies, respectively. The broken bubble tunnelling effect (BBTE) explains the formation mechanism of pitting holes and the bubbleshielding effect (BSE) explains the limitation of surface roughness of electropolishing process. Simulation results are consistent with the observed morphology formation phenomena. © 2012 by ESG.",Related but unverifiable
s_2040,Entailment,Taxonomic Diversity Spatial Scale Effects: The impact of land use on taxonomic diversity can vary with spatial scale. Localized changes in land use can affect species richness and composition differently than regional changes .,"Measures of functional diversity are expected to predict community responses to land use and environmental change because, in contrast to taxonomic diversity, it is based on species traits rather than their identity. Here, we investigated the impact of landscape homogenisation on plants, butterflies and birds in terms of the proportion of arable field cover in southern Finland at local (0.25 km<sup>2</sup>) and regional (> 10 000 km<sup>2</sup>) scales using four functional diversity indices: functional richness, functional evenness, functional divergence and functional dispersion. No uniform response in functional diversity across taxa or scales was found. However, in all cases where we found a relationship between increasing arable field cover and any index of functional diversity, this relationship was negative. Butterfly functional richness decreased with increasing arable field cover, as did butterfly and bird functional evenness. For butterfly functional evenness, this was only evident in the most homogeneous regions. Butterfly and bird functional dispersion decreased in homogeneous regions regardless of the proportion of arable field cover locally. No effect of landscape heterogeneity on plant functional diversity was found at any spatial scale, but plant species richness decreased locally with increasing arable field cover. Overall, species richness responded more consistently to landscape homogenisation than did the functional diversity indices, with both positive and negative effects across species groups. Functional diversity indices are in theory valuable instruments for assessing effects of land use scenarios on ecosystem functioning. However, the applicability of empirical data requires deeper understanding of which traits reliably capture species' vulnerability to environmental factors and of the ecological interpretation of the functional diversity indices. Our study provides novel insights into how the functional diversity of communities changes in response to agriculturally derived landscape homogenisation; however, the low explanatory power of the functional diversity indices hampers the ability to reliably anticipate impacts on ecosystem functioning.
[5]: Aim: Changes in land use and cover (hereafter land use) affect freshwater ecosystems at different spatial scales. We tested the effects of land use on the dispersal capacity of stream macroinvertebrates through local and regional processes. Location: In all, 183 Brazilian headwater stream sites, located in the Neotropical Savanna with variable land use and covering a total area of 46,394 km<sup>2</sup>. Taxon: Stream macroinvertebrates. Methods: We used multiple regression models for distance matrices to identify the relative importance of environmental and landscape characteristics to explain community dissimilarity of stream macroinvertebrates with different mobility traits. As predictors, we calculated four distance metrics: environmental distance describing the dissimilarity in local conditions, the network distance accounting for distances across the drainage system and two distances measuring landscape resistance to dispersal (topographic and land use). We classified macroinvertebrates in dispersal groups according to their dispersal abilities (flying and drifting) and life story traits (voltinism, adult life span and body size). We tested the effects of these distances on all taxa and on the different dispersal groups, to explore whether biological traits would result in different metacommunity patterns. Results: Our hierarchical clustering analysis identified five macroinvertebrate dispersal groups. The dispersal group 1 was mainly composed by aquatic obligate taxa, dispersal group 2 by taxa with low drift propensity, dispersal group 3 represented taxa with high directional flight capacity, dispersal group 4 included taxa with medium drift propensity and dispersal group 5 represented taxa with high drift propensity. We found that environmental distance and land use distance were the most important predictors explaining community dissimilarity for most of the dispersal groups. Main conclusion: The metacommunity patterns found in this study suggest that environmental filtering was the most important community assembly mechanism at a local scale, whereas land use could constrain dispersal at the regional scale. Understanding these processes is crucial to meet conservation and restoration goals, especially in biodiversity hotspots. Our results reinforce the importance of considering entire catchments for preserving stream health and aquatic biodiversity and indicate the need for a much more integrative research between terrestrial and aquatic ecology.",Entailment
s_466,Entailment,Statistical Testing: Various testing methods are used to validate hypotheses within the space .,"The structural information in high-dimensional transposable data allows us to write the data recorded for each subject in a matrix such that both the rows and the columns correspond to variables of interest. One important problem is to test the null hypothesis that the mean matrix has a particular structure without ignoring the dependence structure among and/or between the row and column variables. To address this, we develop a generic and computationally inexpensive nonparametric testing procedure to assess the hypothesis that, in each predefined subset of columns (rows), the column (row) mean vector remains constant. In simulation studies, the proposed testing procedure seems to have good performance and, unlike simple practical approaches, it preserves the nominal size and remains powerful even if the row and/or column variables are not independent. Finally, we illustrate the use of the proposed methodology via two empirical examples from gene expression microarrays.
[4]: Biomechanical processes are often manifested as one-dimensional (1D) trajectories. It has been shown that 1D confidence intervals (CIs) are biased when based on 0D statistical procedures, and the non-parametric 1D bootstrap CI has emerged in the Biomechanics literature as a viable solution. The primary purpose of this paper was to clarify that, for 1D biomechanics datasets, the distinction between 0D and 1D methods is much more important than the distinction between parametric and non-parametric procedures. A secondary purpose was to demonstrate that a parametric equivalent to the 1D bootstrap exists in the form of a random field theory (RFT) correction for multiple comparisons. To emphasize these points we analyzed six datasets consisting of force and kinematic trajectories in one-sample, paired, two-sample and regression designs. Results showed, first, that the 1D bootstrap and other 1D non-parametric CIs were qualitatively identical to RFT CIs, and all were very different from 0D CIs. Second, 1D parametric and 1D non-parametric hypothesis testing results were qualitatively identical for all six datasets. Last, we highlight the limitations of 1D CIs by demonstrating that they are complex, design-dependent, and thus non-generalizable. These results suggest that (i) analyses of 1D data based on 0D models of randomness are generally biased unless one explicitly identifies 0D variables before the experiment, and (ii) parametric and non-parametric 1D hypothesis testing provide an unambiguous framework for analysis when one[U+05F3]s hypothesis explicitly or implicitly pertains to whole 1D trajectories.",Entailment
s_532,Contradiction,"1. Rural Electrification: Challenges: Issues such as staff rotation, overlapping competences, and lack of local engagement have led to project failures, which suggests that simply implementing a systems approach will likely resolve all these issues and guarantee project success and sustainability .","Peru has historically been among the Latin-American countries with a low rural electrification rate. Aiming to improve this situation, the country conducted several electrification efforts in the last few decades that included off-grid photovoltaic (PV) solutions for remote areas (where the grid expansion was unviable). More recently, the government has also sponsored a 'massive program' that aims to deploy a minimum of 150,000 off-grid PV solutions in the upcoming years. In this paper, we assess the sustainability of rural electrification programs in Peru, paying special attention to the ongoing ""massive program"". Our assessment considers four dimensions of sustainability (institutional, economic, environmental, and socio-cultural) and is based on an exhaustive qualitative document analysis complemented by semi-structured expert interviews. We found that the lack of strong formal institutions with a flexible and decentralized structure seriously compromises the sustainability of rural electrification efforts in Peru. Staff rotation and overlapping competences have caused disturbing changes and inhibited following a strategic line, while widespread outsourcing combined with weak controls have often affected the reliability of the deployed systems. Although cross subsidies have made off-grid PV systems affordable for users, systems often fell short of energy demand. Notably, we found that Peruvian officials appear to be unaware of the importance of local participation, and there is a significant mistrust between the government and the rural population (especially in areas where mining is extensive). As a consequence, most of the projects are still designed without the participation and engagement of the communities, which has frequently led to project failures, payment defaults, and inhibited seizing opportunities regarding productive uses of off-grid PV systems. We expect that our findings may help Peruvian institutions to address the most severe drawbacks affecting their rural electrification efforts based on off-grid PV systems.",Misrepresentation
i_1290,Entailment,"3. Abstinence-Based Programs: Abstinence-based programs have shown mixed results. For instance, a study on an abstinence-based teen pregnancy prevention program indicated that constructs related to teens' attitudes toward risky sexual behavior were stable and sensitive to detect program effects .","The purpose of this study was to examine the effects of program interventions in a school-based teen pregnancy program on hypothesized constructs underlying teens' attitudes toward sexuality. An important task related to this purpose was the validation of the constructs and their stability from pre- to postintervention measures. Data from 1,136 middle grade students were obtained from an earlier evaluation of an abstinence-based teen pregnancy prevention program (S. Weed, I. Ericksen, G. Grant, & A. Lewis, 2002). Latent trait structural equation modeling was used to evaluate the impact of the intervention program on changes in constructs of teens' attitudes toward sexuality. Gender was also taken into consideration. This investigation provides credible evidence that both 1st- and 2nd-order constructs related to measures of teens' attitudes toward risky sexual behavior are sufficiently stable and sensitive to detect program effects. Copyright 2007 by the American Psychological Association.",Entailment
s_880,Contradiction,"6. Systems Engineering for Sustainable Practices: Energy Management Systems: Systems engineering models are primarily focused on balancing conventional and alternative energy resources, which may lead to significant improvements in energy management across all sectors, including sustainable farming practices, although the actual impact on farming is still largely unproven .","Systems engineering models are widely adopted as means to design, develop, maintain, commission and manage complex systems lifecycles. Here we are using such models in attaining a balance among conventional and alternate energy resources for faster adoption alternate efficient energy resources and overall efficient energy management system. Furthermore we are exploring - how systems engineering modeling approaches could be applied in developing a sustainable farming practice (a System of Systems) and other application areas, performing trade-off studies on complex energy management systems encompassing - renewable energy sources, fossil fuels, power-grid energy, bio-fuels, emerging technologies related to machine electrification and other efficiency improvement efforts in power distribution and drive systems. The model first deliberates conservative goals, requirements of farming System energy resources (SoS) in operation and then develops alternate architectures with various energy resources allocated to different farming activities such as transport, plantation, grain management, water management etc. This paper also introduces an index (Ksems) for energy sustainability considering - cost of operation and infrastructure, efficiency and availability as parameters and then compares, optimizes and selects best architecture for implementation. System dynamics (SD) modeling is used for modeling and simulation purpose; MBSE is used for architecture development, traceability and lifecycle management.",Misrepresentation
s_1221,Contradiction,Women often feel that their emotional and psychological needs are not sufficiently met by healthcare providers .,"Introduction: It is considered that the lifestyle conditioned by socio-demographic or socio-economic factors determines the health condition of people to the greatest extent. The aim of this study is to evaluate the influence of selected socio-demographic factors on the kinds of symptoms occurring during menopause. Material and methods: The study group consisted of 210 women aged 45 to 65, not using hormone replacement therapy, staying at healthcare centers for rehabilitation treatment. The study was carried out in 2013-2014 in the Silesian, Podlaskie and Lesser Poland voivodeships. The set of tools consisted of the authors' own survey questionnaire and the Menopause Rating Scale (MRS). Results: The most commonly occurring symptom in the group of studied women was a depressive mood, from the group of psychological symptoms, followed by physical and mental fatigue, and discomfort connected with muscle and joint pain. The greatest intensity of symptoms was observed in the group of women with the lowest level of education, reporting an average or bad material situation, and unemployed women. Conclusions: An alarmingly high number of reported psychological symptoms in the group of menopausal women was observed, and in particular among the group of low socio-economic status. Career seems to be a factor reducing the risk of occurrence of psychological symptoms. There is an urgent need for health promotion and prophylaxis in the group of menopausal women, and in many cases for implementation of specialist psychological assistance.
[8]: Objectives Previous studies have found that women with premature menopause often report fertility problems, menopause symptoms and negative experiences of medical services. This study aims to measure the prevalence of these problems and explore whether they have negative impacts on psychosocial adjustment (symptom experience and quality of life). Methods A cross-sectional survey was mailed to women who had been diagnosed with premature menopause, recruited from hospital clinics in West London and from a patient support website (the Daisy Network). The survey measured participant characteristics, fertility problems, hot flushes and night sweats, experience of diagnosis, patient satisfaction with medical services, the Women's Health Questionnaire and the General Health Survey SF-36. Responses were described and multiple linear regressions were used to explore predictors of psychosocial functioning and quality of life. Results A total of 136 women were included in the analysis. Psychosocial functioning was relatively poor compared to typical aged menopausal women. Fertility concerns were prevalent (reported by 71% of the sample), 35% reported experiencing hot flushes and/or nights sweats, and, on average, women were neither satisfied nor unsatisfied with medical services (mean = 3.00, standard deviation = 0.98). Age, experiencing hot flushes and/or night sweats and patient satisfaction predicted psychosocial functioning, but only explained a small amount of the variance (311%). Conclusions Women with premature menopause would benefit from interventions that improve psychosocial functioning and quality of life, including improving patient experience and effective treatment of menopause symptoms. Assumptions about treatment needs could not reliably be made based on patient characteristics, suggesting that individually tailored treatments may be more effective. © 2012 International Menopause Society.",Misrepresentation
i_502,Entailment,"Applications of NLP NLP has a wide range of applications, including: Speech Recognition and Synthesis: Converting spoken language into text and vice versa. Machine Translation: Automatically translating text from one language to another. Optical Character Recognition (OCR): Converting different types of documents, such as scanned paper documents, PDFs, or images captured by a digital camera, into editable and searchable data. Sentiment Analysis: Determining the sentiment expressed in a piece of text. Question Answering and Dialogue Systems: Building systems that can answer questions posed in natural language and engage in conversations .","[1] Natural Language Processing (NLP) is a branch of Artificial Intelligence (AI) technology used by machines to understand, analyze and interpret human languages. In the past decade, NLP received more recognition due to innovation in information and communication technology which led to various research. Thus, it is essential to understand the development taken in the knowledge of literature. The present study aims to present a systematic literature review using bibliometric analysis in NLP research. The study identifies the publication trends, influential journals, cited articles, influential authors, institutions, countries, key research areas, and research clusters in the NLP field. 12541 NLP publications were extracted from the Web of Science (WoS) database and further analyzed using bibliometric analysis. The result indicated that the first NLP publication was in 1989, with the highest publication recorded in 2021. The IEEE access journal was the leading journal with the highest number of publications, and the highest number of citations received for NLP articles is 3174. The most productive author in the NLP field is Liu HF, whereas Harward university is the most influential institution. The US is the leading country in the total number of publications. Researchers extensively researched applied sciences area. The findings further revealed that most of the NLP research focused on five main clusters: modeling, neural networks, artificial intelligence, data mining using social media platforms, and data capturing and learning.  [5] Natural language is ubiquitous in the workflow of medical imaging. Radiologists create and consume free text in their daily work, some of which can be amenable to enhancements through automatic processing. Recent advancements in deep learning and ""artificial intelligence"" have had a significant positive impact on natural language processing (NLP). This article discusses the history of how researchers have extracted data and encoded natural language information for analytical processing, starting from NLP's humble origins in hand-curated, linguistic rules. The evolution of medical NLP including vectorization, word embedding, classification, as well as its use in automated speech recognition, are also explored. Finally, the article will discuss the role of machine learning and neural networks in the context of significant, if incremental, improvements in NLP.",Entailment
i_1310,Unverifiable,"5. Improved Security and Reliability: Enhanced Security: Quantum communication systems offer improved security features, which are vital for protecting sensitive medical data and ensuring patient privacy .","Research and development for the 5th-generation (5G) wireless systems has been initiated several years ago [1-3]. Such systems, which are set for commercial use sometime around 2020, are expected to provide new types of enhanced user connectivity services, in terms of providing very high data rates, increased capacity, improved security, higher reliability, reduced latency, increased quality of service and availability, and energy efficiency (EE). According to the 5G standard such systems should provide higher data rates, for example, tens of Mb/s and accommodating tens of thousands of users providing data rates of 100 Mb/s for metropolitan areas. Furthermore, their spectral efficiency (SE) will increase significantly, as compared to the SE achieved by the 4th-generation (4G) wireless systems, their coverage will also improve and their latency will be reduced significantly as compared to Long-Term Evolution (LTE) [2].
[7]: Systems of wearable or implantable medical devices (IMD), sensor systems for monitoring and transmitting physiological recorded signals, will in future health care services be used for purposes of remote monitoring. Today, there exist several constraints, probably preventing the adoption of such services in clinical routine work. Within a future 5G infrastructure, new possibilities will be available due to improved addressing solutions and extended security services in addition to higher bandwidth in the wireless communication link. Thus 5G solutions can represent a paradigm shift regarding remote patient's monitoring and tracking possibilities, with enhancement in transmitting information between patients and health care services. Some aspects of new possibilities are highlighted in describing a realistic scenario within a future 5G framework. © 2010 Springer Science+Business Media, LLC.",Related but unverifiable
s_1370,Entailment,"Rapid Weight Loss Programs: Very-Low-Calorie Diet (VLCD): A six-week VLCD program resulted in significant reductions in both visceral and subcutaneous abdominal fat, along with improved insulin sensitivity, and it is believed that such diets may also enhance overall metabolic health beyond just weight loss .","Objective. Rapid weight loss with very-low-calorie diet (VLCD) is known to improve insulin sensitivity and decrease adipose tissue masses. The aim was to investigate the effects of VLCD on adipose tissue regional glucose uptake (rGU) and perfusion and their association with adipokines. Research design and methods. Sixteen healthy obese (body mass index 33±1.1 kg/m2) subjects underwent VLCD for 6 weeks. RGU and perfusion were measured using [18F]-fluoro-deoxy-glucose, [15O]H2O and positron emission tomography. Results. Blood-flow and rGU expressed per gram of adipose tissue were higher in visceral fat compared to abdominal subcutaneous fat (P<0.01 for both). Dieting decreased weight by 11±0.9 kg (P<0.0001). Visceral adipose fat decreased by 25% (P<0.001) and abdominal subcutaneous fat by 16% (P<0.001). Whole body insulin sensitivity increased by 33% (P<0.01). Perfusion of both fat depots decreased (P<0.001), while rGU remained unchanged. Among the adipokines, leptin and interleukin-6 levels seemed to be associated with abdominal subcutaneous and intra-abdominal adipose tissue insulin resistance but not with adipose tissue perfusion. Conclusions. Abdominal adipose tissue perfusion and rGU are not related in obesity. Rapid weight loss decreases perfusion through adipose tissue depots but has no influence on rGU demonstrating the 'sink' role of adipose tissue. © 2009 Informa UK Ltd. (Informa Healthcare, Taylor & Francis AS).",Entailment
s_711,Entailment,"Tool Deflection: The technique addresses tool deflection issues, which are crucial for maintaining the required tolerances .","Jet engine impeller blades are flank-milled with tapered, helical, ball-end mills on five-axis machining centers. The impellers are made from difficult-to-cut titanium or nickel alloys, and the blades must be machined within tight tolerances. As a consequence, deflections of the tool and flexible workpiece can jeopardize the precision of the impellers during milling. This work is the first of a two part paper on cutting force prediction and feed optimization for the five-axis flank milling of an impeller. In Part I, a mathematical model for predicting cutting forces is presented for five-axis machining with tapered, helical, ball-end mills with variable pitch and serrated flutes. The cutter is divided axially into a number of differential elements, each with its own feed coordinate system due to five-axis motion. At each element, the total velocity due to translation and rotation is split into horizontal and vertical feed components, which are used to calculate total chip thickness along the cutting edge. The cutting forces for each element are calculated by transforming friction angle, shear stress and shear angle from an orthogonal cutting database to the oblique cutting plane. The distributed cutting load is digitally summed to obtain the total forces acting on the cutter and blade. The model can be used for general five-axis flank milling processes, and supports a variety of cutting tools. Predicted cutting force measurements are shown to be in reasonable agreement with those collected during a roughing operation on a prototype integrally bladed rotor (IBR). Copyright © 2007 by ASME.",Entailment
s_958,Contradiction,"Bilateral Acute Iris Transillumination (BAIT): Systemic administration of ciprofloxacin has been associated with BAIT, a condition characterized by acute pigment dispersion in the anterior chamber and angle, depigmentation of the iris stroma, and permanent iris transillumination. This condition can masquerade as uveitis and has been reported following the use of systemic ciprofloxacin .","Bilateral Acute Iris Transillumination (BAIT) is a new clinical entity characterized by acute onset of pigment dispersion in the anterior chamber and angle, depigmentation of the iris stroma and permanent iris transillumination, masquerading as uveitis. An association with oral moxifloxacin is reported in some articles. We describe one case of bilateral acute iris transillumination, following the use of systemic moxifloxacin.
[2]: Antibiotics such as fluoroquinolones (FQLs) are commonly used to treat ocular infections but are also known to cause dermal melanocyte toxicity. The release of dispersed pigments from the iris into the aqueous humor has been considered a possible ocular side effect of the systemic administration of FQLs such as Moxifloxacin, and this condition is known as bilateral acute iris transillumination (BAIT). Bilateral acute depigmentation of iris (BADI) is a similar condition, with iris pigment released into the aqueous, but it has not been reported as a side effect of FQL. Iris pigments are synthesized by the melanogenic enzyme tyrosinase (TYR) and can be detected but not quantified by using slit-lamp biomicroscopy. The correlation between dispersed pigments in the aqueous and the extent of melanocyte toxicity due to topical antibiotics in vivo is not well studied. Here, we aimed to study the effect of topical FQLs on iris tissue, the pigment release in the aqueous humor and the development of clinically evident iris atrophic changes. We evaluated this process by measuring the activity of TYR in the aqueous humor of 82 healthy eyes undergoing cataract surgery following topical application of FQLs such as Moxifloxacin (27 eyes, preservative-free) or Ciprofloxacin (29 eyes, with preservative) or the application of non-FQL Tobramycin (26 eyes, with preservative) as a control. In addition, the patients were questioned and examined for ocular side effects in pre- and post-operative periods. Our data showed a significantly higher mean TYR activity in the aqueous humor of Ciprofloxacin-treated eyes compared to Moxifloxacin- (preservative free, p < 0.0001) or Tobramycin-treated eyes (p < 0.0001), which indicated that few quinolones under certain conditions are toxic to the iris melanocytes. However, the reduced TYR activity in the aqueous of Moxifloxacin-treated eyes was possibly due to the presence of a higher drug concentration, which inhibits TYR activity. Consistently, immunoblotting analysis of the aqueous humor from both Ciprofloxacin- and Moxifloxacin-treated eyes showed the presence of soluble TYR enzyme, thus reflecting its toxicity to iris melanocytes and corresponding to its activity in the aqueous humor. Intriguingly, none of these patients developed any clinically appreciable ocular side effects characteristic of BAIT or BADI. Overall, our results suggest that topical antibiotics cause different levels of iris melanocyte toxicity, releasing dispersed pigments into the aqueous humor, which can be measured through TYR enzyme activity. Hence, we conclude that topical FQLs may cause subclinical toxicity to the iris melanocytes but may not be the sole cause of the development of BAIT or BADI.",Opposite meaning
i_1778,Contradiction,Key Components of Sustainable Environmental Management: Resilience and Adaptive Governance: Resilience: Suggests that social-ecological systems can always adapt and thrive without considering the potential limitations or failures in their capacity to do so .,"Since the late 1980s, the idea of sustainable development has been gaining widespread recognition as a guiding framework for policies on development and the environment. However, the concept of sustainable development has received a number of criticisms, including its over-emphasis on meeting human needs through economic growth, as well as its failure to recognize dynamic human–environment interactions. In response to these shortfalls, the concepts of resilience and adaptive governance have emerged as alternative perspectives for pursuing sustainable development. Resilience in social-ecological systems emphasizes the capacity of coupled human–environment systems to deal with change, while continuing to develop. Adaptive governance relies on diverse and nested institutional mechanisms for connecting actors across multiple scales to manage conflicts and uncertainties in ecosystem management processes. However, the ethical dimensions of resilience and adaptive governance have not received enough attention. A promising ethical perspective for guiding policies on human–environment interactions is the philosophy of deep ecology, which highlights the need for recognition of the intrinsic values of all living things, as well as the nurturing of ecological and cultural diversity. In this paper, I argue that an integration of the principles of deep ecology and adaptive governance provides a complementary set of ethical principles and institutional attributes that offers better prospects for pursuing sustainable development in the era of the Anthropocene. The implications of this integrative agenda include: the adoption of a holistic conception of dynamic human–environment interactions; the recognition of diverse knowledge systems through an anti-reductionist approach to knowledge; the promotion of long term sustainability through respect for ecological and cultural diversity; and embracing decentralization and local autonomy. I further illustrate this integrative agenda using the management of protected areas as a case study.",Opposite meaning
i_505,Contradiction,"Current Trends in NLP Multilingual NLP While much progress has been made in NLP for widely spoken languages like English, there is growing interest in developing NLP technologies for other languages, such as Mandarin. This involves addressing unique linguistic challenges and creating resources and tools tailored to these languages .","Natural language processing (NLP), called computational linguistics or human language technologies, is the sub-field of artificial intelligence (AI) focused on modeling natural languages to build applications such as speech recognition and synthesis, machine translation, optical character recogni tion (OCR), sentiment analysis (SA), question answering, and dialogue systems. Though Arabic NLP has many challenges, it has seen many successes and developments.Researchers discuss Arabic's main challenges as a necessary background, and we present a brief history of Arabic NLP. They survey a number of its research areas, and end with a critical discussion of the future of Arabic NLP.",Entity error
s_172,Entailment,"Application Delivery Networks (ADNs): Multi-Cloud Management: Distributors are leveraging platforms like OpenADN to manage resources across multiple clouds, providing dynamic and real-time control over resources. This helps optimize operational costs, performance, and energy consumption .","Application service providers (ASPs) obtaining resources from multiple clouds have to contend with different management and control platforms employed by the cloud service providers (CSPs) and network service providers (NSPs). Distributing applications on multiple clouds has a number of benefits, but absence of a common multi-cloud management platform that would allow ASPs dynamic and real time control over resources across multiple clouds and interconnecting networks makes this task arduous. Open application delivery network (OpenADN), a multi-cloud management and control platform, fills this gap. However, performance issues of such a complex, distributed and multi-threaded platform, not tackled appropriately, may neutralise some of the gains accruable to the ASPs. In this paper, we establish the need for and methods of collecting precise and fine-grained behavioural data of OpenADN like platforms that can be used to optimise their behaviour to control operational cost, performance (e.g., latency) and energy consumption.",Entailment
i_173,Contradiction,"1. Optimization of VLSI Design: Swarm Intelligence (SI) Algorithms: SI-based algorithms like the Particle Swarm Optimization (PSO) and Artificial Bee Colony (ABC) algorithm have shown effectiveness in optimizing VLSI design parameters such as interconnect wirelength, which is crucial for reducing transmission delays within chips .","Swarm Intelligence (SI), modelled upon the behaviours of various swarms of animals and insects such as ants, termites, bees, birds, fishes, fireflies, etc. is an emerging area in the field of optimization. SI based algorithms are proclaimed to be robust and efficient optimization tools. This fact is corroborated by a number of practical engineering problems where these algorithms give very satisfactory results. Nowadays VLSI Design has become one of the most intriguing and fervent research field for engineers. Efficient development of a system of a billion chips and blocks on a printed circuit board requires extensive use of optimization in various areas of design such as chip size, separation among components, interconnect length etc. One of the most significant among these is the interconnect wirelength, which determines the overall delay in transmission within the chip. The routing phase in the VLSI Physical Design strives to optimize the interconnect length. Several studies have been and are being conducted to improve the performance of VLSI chips by optimally interconnecting the various components. Various SI based algorithms have already proved their efficiency in this field of routing optimization. In this paper we have proposed a global routing scheme based on contemporary SI algorithms: Firefly Algorithm (FA), and Artificial Bee Colony (ABC) algorithm and have compared the performance of the two. FA produces superior optimization results in comparison to ABC although proving to be quite expensive, computationally. © 2014 IEEE.",Missing information
s_1518,Entailment,"Food-Processing By-Products: By-products such as edible oil cakes (e.g. groundnut, coconut, and sesame oil cakes) are used as substrates due to their nutrient richness. These substrates support the growth of fungi and the production of enzymes necessary for mycoprotein synthesis .","Background: Amylases produced by fungi during solid-state fermentation are the most widely used commercial enzymes to meet the ever-increasing demands of the global enzyme market. The use of low-cost substrates to curtail the production cost and reuse solid wastes are seen as viable options for the commercial production of many enzymes. Applications of α-amylases in food, feed, and industrial sectors have increased over the years. Additionally, the demand for processed and ready-to-eat food has increased because of the rapid growth of food-processing industries in developing economies. These factors significantly contribute to the global enzyme market. It is estimated that by the end of 2024, the global α-amylase market would reach USD 320.1 million (Grand View Research Inc., 2016). We produced α-amylase using Aspergillus oryzae and low-cost substrates obtained from edible oil cake, such as groundnut oil cake (GOC), coconut oil cake (COC), sesame oil cake (SOC) by solid-state fermentation. We cultivated the fungus using these nutrient-rich substrates to produce the enzyme. The enzyme was extracted, partially purified, and tested for pH and temperature stability. The effect of pH, incubation period and temperature on α-amylase production using A. oryzae was optimized. Box–Behnken design (BBD) of response surface methodology (RSM) was used to optimize and determine the effects of all process parameters on α-amylase production. The overall cost economics of α-amylase production using a pilot-scale fermenter was also studied. Results: The substrate optimization for α-amylase production by the Box–Behnken design of RSM showed GOC as the most suitable substrate for A. oryzae, as evident from its maximum α-amylase production of 9868.12 U/gds. Further optimization of process parameters showed that the initial moisture content of 64%, pH of 4.5, incubation period of 108 h, and temperature of 32.5 °C are optimum conditions for α-amylase production. The production increased by 11.4% (10,994.74 U/gds) by up-scaling and using optimized conditions in a pilot-scale fermenter. The partially purified α-amylase exhibited maximum stability at a pH of 6.0 and a temperature of 55 °C. The overall cost economic studies showed that the partially purified α-amylase could be produced at the rate of Rs. 622/L. Conclusions: The process parameters for enhanced α-amylase secretion were analyzed using 3D contour plots by RSM, which showed that contour lines were more oriented toward incubation temperature and pH, having a significant effect (p < 0.05) on the α-amylase activity. The optimized parameters were subsequently employed in a 600 L-pilot-scale fermenter for the α-amylase production. The substrates were rich in nutrients, and supplementation of nutrients was not required. Thus, we have suggested an economically viable process of α-amylase production using a pilot-scale fermenter.",Entailment
s_1002,Contradiction,"Adverse Effects: Ceftriaxone has been associated with various side effects, including nephrotoxicity and potential urolithiatic effects, as observed in animal studies .","Imipenem/cilastatin is a broad-spectrum β-lactam antibiotic used to treat several bacterial infections. The present study was designed to validate the nephrotoxic effect of this drug in rats and to explore its potentional urolithiatic effect. Thirty two Wistar rats were randomly divided into four groups: three experimental groups treated with different imipenem/cilastatin dosages (30, 50 and 80 mg/kg/day) and a control group.The experimental groups were given intraperitoneal imipenem/cilastatin injections twice daily for 7 days, and the control group was given intraperitoneal vehicle NaCl 0.9% solution. Nephrotoxic effect of this antibiotic was assessed based on urine and plasma biochemistry, oxidative stress parameters, histopathological examination and infrared spectroscopy characterization. Imipenem/cilastatin administration resulted in alkaline urine, polyuria, crystalluria, raised plasma levels of urea, creatinine and uric acid, decreased contents of plasma gamma glutamyltranspeptidase and alkaline phosphatase, oxidative stress status, malpighian metaplasia as well as crystal deposition in kidneys and urinary tracts of Wistar rats. In addition, the precise nature of the calculi was identified, being formed by imipenem/cilastatin, thus confirming their iatrogenic origin. In conclusion, this study demonstrated through rat model that subacute exposure to imipenem/cilastatin may induce nephrotoxicity and increase the risk for developing kidney stones even at therapeutic dose levels in a dose-dependent manner.",Entity error
i_1542,Contradiction,"Public-private partnerships (PPPs) have been encouraged to overcome obstacles in solid waste management, as stipulated by Law No. 20 of 2008 .","This research note addresses public-private partnerships involving subnational governments and private business entities in solid waste management in Indonesia in accordance with Law No, 18 of 2008 and related legislation. The law seeks to overcome the negative impacts of solid waste management that are inconsistent with acceptable environmental and health-related methods and techniques. In doing so, it needs to be complemented by appropriate technical regulation of PPPs aimed at reducing significant obstacles to ensuring efficient and effective solid waste management.",Numeric error
i_130,Contradiction,"Techniques and Applications: Motif-Based Classification: Wind Turbine Installation Identification: This technique classifies time-series electricity consumption data to identify households with wind turbine installations. The method involves symbolizing the data and evaluating error rates across different settings, demonstrating high accuracy in identifying wind turbine installations .","With increasing energy requirements and limitation of non-renewable resources for traditional electricity generation and transmission, many households and premises across the world have installed solar systems. Power companies require information about solar panel installations to regulate the whole power system. In this paper, we propose a motif-based classification algorithm for identifying whether a customer has installed the solar panels. Firstly, we symbolize our time-series data with alphabets and classify those data. Then we evaluate our method by checking error rates of different settings. Later, we test our algorithm with different training and testing datasets. The motif-based classification algorithm analyzes electricity consumption data of households. Results show that our motif-based classification algorithm for identifying solar panel installations have a very good accuracy.",Entity error
s_536,Contradiction,"3. Sustainable Infrastructure: Case Studies: Applying such frameworks to projects, like mining infrastructure, can negatively impact community perception and hinder sustainable development .","A large amount of international public and private not-for-profit organizations strives to enhance the conditions of less developed economies under the flagship of sustainability throughout a wide range of infrastructure projects. However, the results are uncertain. Sustainable development in poorer countries requires effective frameworks to ensure the balanced consideration of social, economic and environmental dimensions. This paper discusses the application of the Sustainable Infrastructure Rating System for Developing Countries (SIRSDEC) to a mining infrastructure project located in Peru, in order to validate the methodology developed for this framework. The opinions returned from a questionnaire addressed to international experts according to the pairwise comparison scale of the Analytic Hierarchy Process (AHP) method were processed to obtain the weights of the elements forming the decision-making tree of SIRSDEC. The Integrated Value Model for Sustainable Assessment (MIVES) was introduced to assess infrastructure projects through the definition of value functions for each sustainability indicator, which enables the integration of variables measured in different units into a standardized value index. The weights obtained for SIRSDEC reflected the balance of the three pillars of sustainability, with a slight predominance of the social dimension. The case study highlighted the contribution of the new system to identify key sustainability issues which were omitted in the original project and posed several actions to improve community's perception and facilitate the development of the project.",Misrepresentation
i_728,Unverifiable,"Applications and Benefits: Enhanced Interaction: Smart children's furniture, like game tables, can enhance parent-child interaction through multi-modal systems based on applied behavior analysis. This approach has practical value and can be integrated into market products .","[3] The application of intelligent control technology promote the development of intelligent furniture. And intelligent will be a new trend of furniture in the future. The paper defined the concept of intelligent furniture. And analysis the application of each intelligent control theory such as Cybernetics and Information theory, also technology such as Sensor and automatic detection, Microelectronics and Servo drive technology used in furniture. Some new methods such as imitation, transplantation, replacement and standardization are used to design the intelligent furniture. This paper introduces mainly one method called function module design. First classify the intelligent future system into many subsystems, and then classify the subsystems into many units which has same or similar function. We call these units function module. Finally to study the realization, principle and actuator of each unit. An example of designing an intelligent garderobe with dehumidification and mildew proof function is shown in the paper so as to introduced the new method. © 2010 IEEE. [10] Smart Environments have specific natural interaction needs that can be provided for with multimodal interfaces. There are still challenges to face, such as the adaptability of the interaction and an evaluation of the proposed systems. This work focuses on these problems and proposes an architectural design evaluated in the domain of Smart Homes. The architectural approach is based on the Model View Presenter Pattern and the Service Oriented paradigm. The evaluation was conducted with a laboratory deployment of a prototype of the system and usability tests were carried out with a usability questionnaire. Results show the technical feasibility of the proposed design and positive user acceptance of the multimodal interface as compared to mono-modal interfaces. © 2012 Springer-Verlag.",Related but unverifiable
i_829,Entailment,"However, CNG engines may experience a reduction in brake power compared to gasoline engines .","Considering the importance of alternative fuels in IC engines for environment safety, compressed natural gas has been extensively employed in SI engines. However, scarce efforts have been made to investigate the effect of compressed natural gas on engine lubricant oil for a long duration. In this regard, a comprehensive analysis has been made on the engine performance, emissions, and lubricant oil conditions using gasoline (G)<inf>92</inf> and compressed natural gas at different operating conditions using reliable sampling methods. The key parameters of the engine performance like brake power and brake-specific energy consumption were investigated at 80% throttle opening within 1500–4500 range of r/min. For the sake of emission tests, speed was varied uniformly by varying the load at a constant throttle. Furthermore, the engine was run at high and low loads for lubricant oil comparison. Although compressed natural gas showed a decrease in brake-specific energy consumption (7.94%) and emissions content, (G)<inf>92</inf> performed relatively better in the case of brake power (39.93% increase). Moreover, a significant improvement was observed for wear debris, lubricant oil physiochemical characteristics, and additives depletion in the case of compressed natural gas than those of (G)<inf>92</inf>. The contents of metallic particles were decreased by 23.58%, 36.25%, 42.42%, and 66.67% for iron, aluminum, copper, and lead, respectively, for compressed natural gas.",Entailment
s_826,Unverifiable,"4. Chemical Treatments: Adhesives: In the production of engineered wood products, adhesives are used to join pieces of wood. These adhesives need to be safe during application and stable once cured .","This chapter examines the effects of some of the key industrial processes that are undertaken on timber, including the physical treatment of the wood itself in order to help preserve timber from the ravages of rot and insect predation. These treatments need to be poisonous to rot and/or insects, and should be non-poisonous to humans. Their success or failure at this is examined and the reasons are looked at to find out why. The second key process relates to the adhesives that are increasingly used to join pieces of wood together, especially in the industrially heavy processes of creating engineered timber products such as glue lamination, laminated veneer lumber and cross-laminated timber. Glues are mostly benign when locked up in use, but may have strong health effects when they are being applied in order to form the engineered timber.",Related but unverifiable
i_2300,Entailment,"Fermentation Process: Microbial Communities: The fermentation process typically involves beneficial bacteria and yeasts. For instance, the predominant bacteria in Hausa koko fermentation include Lactobacillus species, which are known for their probiotic benefits .","Hausa koko is an indigenous porridge processed from millet in Ghana. The process involves fermentation stages, giving the characteristic organoleptic properties of the product that is produced largely at a small-scale household level and sold as a street food. Like many other indigenous foods, quality control is problematic and depends on the skills of the processor. In order to improve the quality of the product and standardize the process for large-scale production, we need a deeper understanding of the microbial processes. The aim of this study is to investigate the microbial community involved in the production of this traditional millet porridge and the metabolites produced during processing. High-throughput amplicon sequencing was used to identify the bacterial (16S rRNA V4 hypervariable region) and fungal [Intergenic Transcribed Spacer (ITS)] communities associated with the fermentation, while nuclear magnetic resonance (NMR) was used for metabolite profiling. The bacterial community diversity was reduced during the fermentation processes with an increase and predominance of lactobacilli. Other dominant bacteria in the fermentation included Pediococcus, Weissella, Lactococcus, Streptococcus, Leuconostoc, and Acetobacter. The species Limosilactobacillus fermentum and Ligilactobacillus salivarius accounted for some of the diversities within and between fermentation time points and processors. The fungal community was dominated by the genus Saccharomyces. Other genera such as Pichia, Candida, Kluyveromyces, Nakaseomyces, Torulaspora, and Cyberlindnera were also classified. The species Saccharomyces cerevisiae, Stachybotrys sansevieriae, Malassezia restricta, Cyberlindnera fabianii, and Kluyveromyces marxianus accounted for some of the diversities within some fermentation time points. The species S. sansevieria and M. restricta may have been reported for the first time in cereal fermentation. This is the most diverse microbial community reported in Hausa koko. In this study, we could identify and quantify 33 key different metabolites produced by the interactions of the microbial communities with the millet, composed of organic compounds, sugars, amino acids and intermediary compounds, and other key fermentation compounds. An increase in the concentration of organic acids in parallel with the reduction of sugars occurred during the fermentation process while an initial increase of amino acids followed by a decrease in later fermentation steps was observed.",Entailment
s_1417,Entailment,"Effects of Various Supplements on Ruminal Fermentation: Enzyme Preparations: The addition of xylanase and endoglucanase increased total VFA production in ruminal cultures, indicating that enzyme supplementation can alter VFA profiles but not necessarily reduce TVFA .","This study employed two commercial enzyme preparations to examine the effects of endoglucanase, xylanase or their combination on in vitro volatile fatty acid (VFA) production by ruminal microbial populations. Batch ruminal cultures were established with one of various feedstuffs or with a fescue hay-based diet and ruminal fluid from a heifer fed a 40% forage:60% concentrate diet. Addition of xylanase at 135 xylanase units (XU) per ml increased total VFA production from the fescue hay-based diet (44.3 vs. 57.2 mM, p < 0.05) without changing the acetate to propionate (A:P) ratio. Addition of endoglucanase at 2, 3, 4, and 5 carboxymethyl cellulase units (CMCU) per ml increased total VFA production from the fescue hay-based diet on average by 36% (p < 0.05). Addition of 3, 4 and 5 CMCU/ml also decreased (p < 0.05) the A:P ratio. The combined addition of xylanase (135 XU/ml) and endoglucanase (5 CMCU/ml) increased total VFA production from the fescue hay-based diet (40.9 vs. 61.5 mM, p < 0.05) and reduced the A:P ratio (3.4 vs. 1.5, p < 0.05). The effects of endoglucanase and xylanase supplementation on in vitro VFA production varied across the various substrates used. However, endoglucanase supplementation consistently reduced the A:P ratio with all substrates tested. The effects of the enzyme combination were generally greater than either enzyme alone. We conclude that endoglucanase and xylanase activities differ in their ability to affect ruminal VFA production, and endoglucanase but not xylanase, may improve fermentation efficiency by reducing the A:P ratio. © 2005 Taylor & Francis.",Entailment
i_1528,Contradiction,"Awareness campaigns about the health and environmental impacts of improper waste disposal are crucial. For instance, in Gondar, Ethiopia, 95% of respondents were aware of the health risks associated with poor waste management .","An assessment was carried out on management practices for Municipal Solid Waste (MSW) generated in Gondar town of Ethiopia. Efficiency and effectiveness of waste collection and disposal by municipality and different methods adopted for waste disposal by residents were studied to find a suitable, effective and feasible method of MSW disposal. The data about awareness, attitude and involvement of residents towards wastes was generated by using questionnaire. From the study, it was observed that 97% of the respondents surveyed had awareness about health and aesthetic aspects of improper waste disposal. About 70% of the respondents are willing to pay in case municipality will introduce house-to-house collection system. Copyright © 2011 Inderscience Enterprises Ltd.",Numeric error
s_1194,Entailment,"Key Classification Systems and Approaches: Abbreviated Injury Scale (AIS): Definition: A component of the ISS, the AIS assigns a severity score to individual injuries. Application: Used in trauma registries to ensure reliable data for evaluating injury management and outcomes .","Objective: Data in trauma registries need to be reliable when used for evaluation of injury management, trauma protocols and hospital statistics. The aim of this audit was to analyse the reliability of the data in the Trauma Centre West Netherlands (TCWN) region. Design: Routinely registered trauma patients from all nine hospitals in the TCWN region were reregistered by a registrar for analysis. Setting: Nine hospitals in the TCWN region in the Netherlands. Participants: A randomly selected representative trauma population sample of 350 patients and a sample of 100 polytrauma patients were re-registered and used for analysis. Intervention: Re-registration of trauma patients in the Trauma Registry. Main Outcome Measure(s): The inter-rater agreement on Injury Severity Score (ISS), number of Abbreviated Injury Scale (AIS) codes, identical codes and survival status were analysed using Kappa's coefficient and intraclass correlation coefficients. Results: The inter-rater agreement on ISS and number of AIS codes were, respectively, almost perfect (ICC = 0.81) and substantial (ICC = 0.76) in the trauma population sample, and substantial (ICC = 0.70) and fair (ICC = 0.33) in the polytrauma sample. For patients with serious injuries (AIS = 2) in the population sample, the inter-rater agreement on ISS (ICC = 0.87) and number of AIS codes (ICC = 0.84) were almost perfect. Conclusions: These results confirm that the Dutch regional registry system works well and may serve as a reliable basis for prospective analysis of national and international trauma care. Particular attention should be paid to the coding of polytrauma patients as discrepancies are more likely to occur in this group.",Entailment
i_1474,Entailment,"Combined Effects: Inflammatory Response: Both body weight and physical activity can influence the inflammatory response to wear particles. Higher activity levels can increase wear particle generation, while higher body weight can lead to reduced activity and potentially lower wear rates, but with a trade-off in functionality .","Background: The effect of obesity on the outcomes of metal-on-metal resurfacing arthroplasty is not currently known. In this study, we assessed the influence of body mass index on the survival of a metal-on-metal hybrid hip resurfacing prosthesis by comparing the clinical results of patients with a body mass index of ≥30 with those of patients with a body mass index of <30. Methods: We retrospectively reviewed our registry to identify all patients who had been followed for at least two years after a metal-on-metal hip resurfacing arthroplasty, and we divided those patients according to whether they had had a body mass index of ≥30 (the study group) or <30 (the control group) at the time of the surgery. One hundred and twenty-five patients (144 hips) with an average weight of 104.6 kg and an average body mass index of 33.4 were included in the study group, and 531 patients (626 hips) with an average weight of 78.3 kg and an average body mass index of 25.4 were included in the control group. We compared the clinical results (UCLA [University of California at Los Angeles] and Harris hip scores, SF-12 [Short Form-12] survey results, and complication rates), radiographic results, and prosthetic survival rates of the two groups. Results: There was no significant difference postoperatively between the groups with regard to the UCLA pain or walking scores or the mental component score of the SF-12. However, the UCLA function and activity scores were lower in the study group than in the control group (9.2 compared with 9.6 points [p = 0.001] and 7.1 compared with 7.6 points [p = 0.002], respectively). The control group had a significantly higher postoperative physical component score on the SF-12 (51.4 points compared with 49.3 points in the study group, p = 0.01) and postoperative Harris hip score (93.8 compared with 90.6 points, p = 0.0003). Two hips (1.4%) were revised in the study group. In contrast, thirty-one hips (5.0%) were converted to a total hip replacement in the control group; twenty of the thirty-one were revised because of loosening of the femoral component. The five-year survivorship of the hip prostheses was 98.6% in the study group and 93.6% in the control group (p = 0.0401). When the entire cohort was divided into three groups according to whether the body mass index was <25, 25 to 29, or ≥30, the risk of revision was found to have decreased twofold from one group to the next as the body mass index increased (p = 0.013). No acetabular component loosened in either group. The average diameter of the femoral component was 48.3 mm in the study group and 46.8 mm in the control group (p = 0.0001). There were no revisions for any reason and no radiolucencies were observed in a subset of twenty-seven patients with a body mass index of ≥35. Conclusions: Metal-on-metal resurfacing hip arthroplasty is performing well in patients with a high body mass index, although the function scores are reduced compared with those for patients with a body mass index of <30. The protective effect of a high body mass index on survivorship results may be explained by a reduced activity level and a greater component size in this patient population. Level of Evidence: Prognostic Level II. See Instructions to Authors for a complete description of levels of evidence. Copyright © 2007 by the Journal of Bone and Joint Surgery, Incorporated.
[3]: Joint replacement is an extremely successful orthopaedic procedure, commonly resulting in pain relief and activity recovery. However, it is recognised that, in the longer term, polyethylene (PE) wear particles generated at the articulating surfaces lead to chronic inflammatory tissue reactions, osteolysis and loosening of the prostheses. PE wear is a multi-factorial phenomenon influenced by some patient- related factors, such as gender, age, activity level and weight. In hip arthroplasty, femoral head size and composition and PE quality and configuration are also related to wear. Surgical technique can also influence PE wear, because increased contact stress between the articular surfaces can be reduced by accurate component positioning. Regarding knee arthroplasty, many structural and design factors related to the PE bearing surface have been shown to affect the extent of wear that occurs over time (e.g. PE processing, manufacturing and sterilization methods). Selecting a well-designed component with minimal counter surface roughness is also important in minimizing the generation of PE wear debris and subsequent osteolysis. This chapter describes current knowledge of the influence of surgical technique on total hip and knee arthroplasty. © 2013 Woodhead Publishing Limited. All rights reserved.",Entailment
s_1930,Entailment,The need for cryogenic trapping and focusing of CO₂ between instruments adds to the complexity and potential for error in the analysis process .,"Stable carbon isotopes are a powerful tool to assess the origin and dynamics of carbon in soils. However, direct analysis of the <sup>13</sup>C/<sup>12</sup>C ratio in the dissolved organic carbon (DOC) pool has proved to be difficult. Recently, several systems have been developed to measure isotope ratios in DOC by coupling a total organic carbon (TOC) analyzer with an isotope ratio mass spectrometer. However these systems were designed for the analysis of fresh and marine water and no results for soil solutions or <sup>13</sup>C-enriched samples have been reported. Because we mainly deal with soil solutions in which the difficult to oxidize humic and fulvic acids are the predominant carbon-containing components, we preferred to use thermal catalytic oxidation to convert DOC into CO<inf>2</inf>. We therefore coupled a high-temperature combustion TOC analyzer with an isotope ratio mass spectrometer, by trapping and focusing the CO<inf>2</inf> cryogenically between the instruments. The analytical performance was tested by measuring solutions of compounds varying in the ease with which they can be oxidized. Samples with DOC concentrations between 1 and 100mg C/L could be analyzed with good precision (standard deviation (SD) ≤0.6%), acceptable accuracy, good linearity (overall SD = 1%) and without significant memory effects. In a <sup>13</sup>C-tracer experiment, we observed that mixing plant residues with soil caused a release of plant-derived DOC, which was degraded or sorbed during incubation. Based on these results, we are confident that this approach can become a relatively simple alternative method for the measurement of the <sup>13</sup>C/<sup>12</sup>C ratio of DOC in soil solutions. © 2010 John Wiley & Sons, Ltd.",Entailment
i_660,Contradiction,"Modern Control Theories and Applications: Distributed Control Systems (DCS): The integration of digital communication networks in control systems has led to the development of DCS, addressing challenges like time delays and packet dropouts. The concept of cloud control systems extends DCS capabilities, leveraging IoT and cloud computing for enhanced data processing and control .","This paper provides an overview of the research investigations into the evolving area of networked control system. Initial discussions were focused on exploring the impact of a common digital communication network in the feedback architecture. Results on addressing communication network artifacts, such as time delays, packet dropouts, and limited communication capability due to signal quantization are thoroughly examined. Several one-channel feedback NCS configurations were presented and analyzed with focus on nonstationary packet dropouts. State, observer-based and Output feedback control design methods over a shared digital communication network are treated. Recent developments pertaining to quantized control and estimation methods are reported. A concise account of event-based control and filtering schemes is presented. Finally, the concept of cloud control systems is discussed in this paper, which is an extension of networked control systems (NCS). With the development of Internet of Things (IOT), the technology of NCSs has played a key role in IOT. Cloud computing is developed rapidly, which provides a perfect platform for big data processing, controller design, and performance assessment. The research on cloud control systems will give new contribution to the control theory and applications in the near future. Some of the laboratory-scale applications are demonstrated.",Entity error
s_2118,Entailment,Factors Influencing N₂O Emissions: Dissolved Oxygen (DO) Levels: High DO levels can decrease N₂O emissions by promoting complete nitrification and denitrification .,"Nitrous oxide (N<inf>2</inf>O) is an important pollutant which is emitted during the biological nutrient removal (BNR) processes of wastewater treatment. Since it has a greenhouse effect which is 265 times higher than carbon dioxide, even relatively small amounts can result in a significant carbon footprint. Biological nitrogen (N) removal conventionally occurs with nitrification/denitrification, yet also through advanced processes such as nitritation/denitritation and completely autotrophic N-removal. The microbial pathways leading to the N<inf>2</inf>O emission include hydroxylamine oxidation and nitrifier denitrification, both activated by ammonia oxidizing bacteria, and heterotrophic denitrification. In this work, a critical review of the existing literature on N<inf>2</inf>O emissions during BNR is presented focusing on the most contributing parameters. Various factors increasing the N<inf>2</inf>O emissions either per se or combined are identified: low dissolved oxygen, high nitrite accumulation, low chemical oxygen demand to nitrogen ratio, slow growth of denitrifying bacteria, uncontrolled pH and temperature. However, there is no common pattern in reporting the N<inf>2</inf>O generation amongst the cited studies, a fact that complicates its evaluation. When simulating N<inf>2</inf>O emissions, all microbial pathways along with the potential contribution of abiotic N<inf>2</inf>O production during wastewater treatment at different dissolved oxygen/nitrite levels should be considered. The undeniable validation of the robustness of such models calls for reliable quantification techniques which simultaneously describe dissolved and gaseous N<inf>2</inf>O dynamics. Thus, the choice of the N-removal process, the optimal selection of operational parameters and the establishment of validated dynamic models combining multiple N<inf>2</inf>O pathways are essential for studying the emissions mitigation.
[3]: Nitrous oxide (N <inf>2</inf> O) is an important greenhouse gas that can be emitted from wastewater treatment plants (WWTPs). Such emissions are reportedly process specific and related to operational parameters. This study was conducted to clarify spatial and daily variations of N <inf>2</inf> O in a full-scale activated sludge anoxic/oxic process that consisted of an anoxic tank and three oxic tanks (oxic-1, oxic-2 and oxic-3), all of which except the final sedimentation tank were fully covered. Higher dissolved N <inf>2</inf> O (D-N <inf>2</inf> O) loading and gaseous N <inf>2</inf> O (G-N <inf>2</inf> O) emissions were observed for oxic-3 than for the anoxic, oxic-1, and oxic-2 tanks, implying that there was higher N <inf>2</inf> O production potential via nitrification in the latter stage of the oxic tank. Moreover, the sudden decrease in dissolved oxygen concentration after the peak was found to lead to abrupt production of D-N <inf>2</inf> O at oxic-3 in the anoxic/oxic process. The increases in AOB amoA, AOB nirK and the following AOB norB gene transcripts at the end of the oxic-2 tank suggested that nitrifier denitrification occurred to produce N <inf>2</inf> O under low dissolved oxygen conditions when the N <inf>2</inf> O peak was observed. Additionally, the much lower transcription levels of the two nosZ genes suggested lower N <inf>2</inf> O consumption. The N <inf>2</inf> O emission factors ranged from 0.087% to 0.302%, and lower N <inf>2</inf> O emission factors were observed during summer.
[7]: Substantial amounts of greenhouse gases (GHG) have been demonstrated to be emitted in wastewater treatment plants (WWTP). One of the GHG with a great influence is nitrous oxide (N2O), which is emitted during the nitrification and denitrification processes in a biological wastewater treatment. This paper proposes the implementation of a control strategy in order to reduce N2O emissions in the nitrification process. Due to the fact that N2O emissions are produced as an intermediate in the nitrification process, the idea of the present work is based on the implementation of a nitrite control by manipulating dissolved oxygen (So) in order to avoid partial nitrification and thus to reduce N2O peaks. A hierarchical control strategy is proposed, where the higher level is composed of an affine function and the lower level of a Proportional-Integral (PI) controller. A modified version of Benchmark Simulation Model 2 (BSM2G) that includes GHG emissions is used for the evaluation. The simulation results show that the proposed control strategy achieve the reduction of GHG emissions by reducing N2O. However, additional control strategies must also be implemented to take into account the other evaluation criteria of the plant.",Entailment
s_635,Unverifiable,"Key applications of object detection in traffic surveillance include: Vehicle Detection and Counting: Object detection algorithms, such as those using Gaussian Mixture Models (GMM) and Morphological operations, are often sufficient for identifying and counting vehicles, which may contribute to adaptive traffic signal control and congestion management, although their effectiveness can vary significantly depending on the conditions .","Now day's computer vision techniques are used for analysis of traffic surveillance videos which is gaining more importance. This analysis of videos can be useful for public safety and for traffic management. In recent time, there has been an increased scope for analysis of traffic activity automatically. Computer based surveillance algorithms and systems are used to extract information from the videos which is also called as Video analytics. Detection of traffic violations such as illegal turns and identification of pedestrians, vehicles from traffic videos can be done by using computer vision and pattern recognition techniques. Object detection is the process of identifying instances of real world objects which include persons, faces and vehicles in images or videos. Object detection is becoming an increasingly important challenge now days as it has so many applications. Vehicle detection helps in core detection of multiple functions such as Adaptive cruise control, forward collision warning. Automatic Generation of Traffic Signal based on Traffic Volume system can be used for traffic control. Traffic Surveillance videos of vehicles are taken as input from MIT Traffic dataset. These videos are further processed frame by frame where the background subtraction is done with the help of Gaussian Mixture Model (GMM). From the background subtracted result some amount of noise is removed with the help of Morphological opening operation and Blob analysis is done in order to the detect the vehicles. Later the vehicles are counted by incrementing the counter whenever a bounding box is appeared for the detected vehicle. Finally a signal is generated depending on the count in each frame.
[4]: Obstacle detection is a hot topic in intelligent visual surveillance system. This paper proposed an automatic obstacle detection method applying to traffic surveillance, which can be used to prevent the traffic accident. In our framework, the images are captured by the traffic surveillance. The GMM (Gaussian Mixture Model) is taken as a short-Term background, and foreground objects are extracted by the algorithm SUOG (Selective Updating of GMM). At last, a detection method related object speed and FROI (Flushed Region of Interest) algorithm is proposed. FROI algorithm is based on the concept of connected domain and used to eliminate noises outside road and improve real-Time capability. Experiments demonstrate that the proposed obstacle detection method can detect the obstacle effectively and accurately, it can fulfill the requirement of practical application.",Related but unverifiable
s_991,Contradiction,"Benefits: Reduction of Airborne Pathogens: Air filters equipped with UV light (HUVAFs) can significantly reduce the concentration of airborne bacteria, achieving reductions of up to 75% in certain environments .","The purpose of this study was to assess the effectiveness of a new generation of high-volume, ceiling-mounted high-efficiency particulate air (HEPA)-ultraviolet (UV) air filters (HUVAFs) for their ability to remove or inactivate bacterial aerosol. In an environmentally controlled full-scale laboratory chamber (87 m<sup>3</sup>), and an indoor therapy pool building, the mitigation ability of air filters was assessed by comparing concentrations of total bacteria, culturable bacteria, and airborne endotoxin with and without the air filters operating under otherwise similar conditions. Controlled chamber tests with pure cultures of aerosolized Mycobacterium parafortuitum cells showed that the HUVAF unit tested provided an equivalent air-exchange rate of 11 hr<sup>−1</sup>. Using this equivalent air-exchange rate as a design basis, three HUVAFs were installed in an indoor therapy pool building for bioaerosol mitigation, and their effectiveness was studied over a 2-year period. The HUVAFs reduced concentrations of culturable bacteria by 69 and 80% during monitoring periods executed in respective years. The HUVAFs reduced concentrations of total bacteria by 12 and 76% during the same monitoring period, respectively. Airborne endotoxin concentrations were not affected by the HUVAF operation. © 2005 Air & Waste Management Association.",Numeric error
s_1554,Entailment,"Delphinium spp.: Delphinium species are mentioned in the context of their nectar being colonized by yeasts, but there is no mention of delphinidin in their nectar .","Microorganisms colonize the nectar of many angiosperms. Variable diversity and spatio-temporal dynamics of nectar-inhabiting microorganisms (e.g., yeasts) may drive variation in nectar sugar composition and subsequent plant-pollinator interactions. We assessed yeast frequency of occurrence and density in the nectar of the perennial herb, Delphinium nuttallianum, across multiple spatio-temporal scales, including flower lifetime and sex-phase transition, flowering season, populations, and years. We tested the hypothesis that pollinators vector yeasts by comparing densities between virgin flowers and those open to visitation. Finally, we identified yeasts using molecular methods and tested for an association between yeast density and nectar composition using ultra-performance liquid chromatography. Yeasts were frequent colonists of Delphinium nectar, occurring in all populations and years sampled. Yeast frequency of occurrence and density varied across most spatio-temporal scales examined. Pollinators were vectors of yeast: virgin flowers remained yeast-free, while those open to visitation became inoculated. Nectar samples were species-poor, with a majority colonized by Metschnikowia reukaufii. Finally, increasing yeast density was correlated with a decrease in sucrose and an increase in monosaccharides. Our results document that yeasts form species-poor communities in populations of this hermaphroditic perennial, in addition to highlighting their spatio-temporal dynamics and effects on nectar quality. Spatio-temporal variation in frequency of occurrence, density, and changes in nectar may have important implications for the nature and strength of interactions between Delphinium and its pollinators.",Entailment
i_569,Contradiction,"Challenges and Considerations: Integration and Governance: Effective governance and policy interventions are necessary to harmonize smart and sustainable city initiatives. A systems thinking approach can help align smart city projects with sustainability goals, addressing the complex trade-offs between urban development and environmental impact. Furthermore, it is likely that cities adopting these strategies will experience increased public engagement and community support, leading to more successful implementation of smart city initiatives .","Technology has indispensably been a part of the city evolution throughout history. In recent years, there has been a shift in the pattern of development in smart cities, where smart cities attempt to embrace practices of sustainability using Information and Communication Technologies and other smart solutions. Past studies reveal that these smart cities have failed in successfully incorporating sustainable development goals into their smart strategies, where they tend to focus more on achieving smartness goals rather than sustainability goals and targets. This paper presents a multi-faceted interrogative study on several ongoing smart city initiatives around the globe that supports United Nations Urban Sustainability Agenda. This paper aims to focus on harmonizing smart and sustainable city initiatives with the United Nations Sustainable Development Goals using a systems thinking approach. The study develops conceptual models that support the city transition into being a sustainable smart city. These conceptual models were designed based on the fundamentals of system thinking for a system of several elements under the key catalyzers ""Policy and Governance,"" ""Research & Development,"" and ""Partnership."" The causalities and interrelationships among elements in developed conceptual models justify the dynamicity and the impact of these elements within a system. The outcome of this research paper would support industry experts, policymakers, and city planners to adopt robust policy interventions and best practices for developing strategies that support the transition of smart cities to the futuristic label of sustainable cities.",Misrepresentation
i_1738,Entailment,"Key Factors Affecting NDVI During the Dry Season: Precipitation: Precipitation is a critical factor influencing vegetation growth. During dry seasons, reduced precipitation leads to lower soil moisture, which in turn reduces NDVI. Studies have shown that NDVI values are positively correlated with precipitation levels, meaning that less rainfall results in lower NDVI values .","Precipitation is one of the important factors that influences vegetation growth and distributions. Using GF-1 remotely sensed images and observed precipitation data, this paper discusses the response relationship between the normalized difference vegetation index (NDVI) and the standardized precipitation index (SPI) in Hutubi County at different time scales from January to December, 2014. The results show that: (1) From a macro point of view, NDVI has obvious geographical characteristics, the Central Plains region has the highest NDVI values; whereas mountains and hills in the southern region and deserts in the northern region have relatively low NDVI values. (2) There is a clear changing trend in the area of vegetation cover. (3) The SPI randomness decreases but the SPI persistence increases with increment in time scales. The sensitivity of the SPI to precipitation is different at different time scales. (4) The SPI has a good correlation with NDVI at six-months time scale. (5)The overall distributions of both basically have the same shape and trendwithhigher SPI values in April and May, and higher NDVI are from June to August. This confirms the lag-time of precipitation influence on vegetation.
[4]: Changes in precipitation patterns were expected to have strong impacts on temperate ecosystem dynamics. North China has experienced opposite trends of precipitation change (increased in the west and decreased in the east) in the past several decades. Under such a background, we analysed mean growing season (GS) (April-October) grass Normalized Difference Vegetation Index (NDVI) changes using combined dataset of Global Inventory, Monitoring, and Modelling Studies and Moderate Resolution Imaging Spectroradiometer NDVI in North China during 1982-2011. The results showed that in mean GS NDVI increased for grasslands in both Northeastern China (NE) and Northwestern China (NW). Increase in NDVI in NW was mainly due to the increase in precipitation (r = 0.50, p < 0.01). However, the decrease in precipitation did not cause a decrease in grass NDVI in NE, suggesting that precipitation is still higher than the most sensitive value and NDVI changes were significantly correlated with the increased temperature (r = 0.43, p < 0.05).",Entailment
i_443,Entailment,"Applications and Evaluation: Evaluation Metrics: The effectiveness of AQG methods is often evaluated based on the fluency, relevance, and diversity of the generated questions. Experiments with datasets like SQuAD have shown that neural network-based methods can produce high-quality questions that are both meaningful and diverse .","Automatic question generation aims to generate questions from a text passage where the generated questions can be answered by certain sub-spans of the given passage. Traditional methods mainly use rigid heuristic rules to transform a sentence into related questions. In this work, we propose to apply the neural encoder-decoder model to generate meaningful and diverse questions from natural language sentences. The encoder reads the input text and the answer position, to produce an answer-aware input representation, which is fed to the decoder to generate an answer focused question. We conduct a preliminary study on neural question generation from text with the SQuAD dataset, and the experiment results show that our method can produce fluent and diverse questions.",Entailment
i_1929,Unverifiable,"High nutrient levels in water bodies can promote the growth of cyanobacteria, leading to increased production of T&O compounds .","Purpose - The Suez Irrigation Canal is the source of drinking water to a large community. Complaints have been raised regarding the odor and unpleasant taste of drinking water. The problems encountered reveled enrichment of the Canal with nutrients, degraded water quality and nuisance caused by algal growth. This paper aims to investigate these claims by evaluating the interaction between water and sediment with ecological indicators. Design/methodology/approach - Bioassessments were used as a primary tool to evaluate the biological conditions and identify the degree of water quality degradation in the Suez Irrigation Canal. The monitoring program integrates biological, chemical, and physical data assessment. Several field surveys were carried out to these areas during the period between March 2003 and February 2005 (over 23 months) for acquiring all possible information about the current situation and to explore the impact of human activities along the canal banks on the canal ecosystem. Seasonal variations of phytoplankton and zooplankton standing crop, species diversity as well as physico-chemical characteristics of water, sediment, fish and aquatic weeds at the intakes of drinking plants and from the discharge of agricultural and domestic drains into the Canal were investigated. Findings - Preliminary field investigations showed great amounts of discharged wastes at several locations to the canal water creating unique conditions, which vary with changes of volume and properties of the discharged wastes. Rotifer and green algae for example demonstrated seasonal variable response to the ecological variations. Myriophyllum spicatum, Potamageton nodsus and Polygonum Salicfolium were the most common types of recorded weed. The Myriophyllum spicatum is the dominant submerged plant. The canal was characterized by high concentrations of HCO<inf>3</inf><sup>-</sup> as well as high pH >8.2 which provides a favorable habitat for the growth of Myriophyllum spicatum. The results illustrated the ability of using the aquatic weed as biomarkers for monitoring heavy metals contaminates in the canal. The evidence suggests that there is a degree of selectivity in metals uptake and partitioning within the plant compartments. Originality/value - The current paper adopts the idea of utilizing multiple organism groups in the bioassessment to effectively detect ecological change when they occur in one of the most important waterways in Egypt. These different organism groups are suited for detection various stressors, providing warnings and detection of stress impacts at different scales. The study presented provides decision makers with important information that can assist them in making objective decisions related to the design of monitoring programs based on scientific research. © Emerald Group Publishing Limited.",Unrelated and unverifiable
s_1121,Entailment,The reliability of isokinetic strength-testing protocols ensures that changes in muscle function due to adhesions can be confidently assessed .,"Muscle power assessed by isokinetic dynamometers has the potential for playing an important role in investigating functional status in older subjects. Researchers and clinicians are interested in the reliability of isokinetic test protocols for the confidential assessment of status, as this affects the interpretation of the results of an intervention program. The current study investigated the inter- and intrarater reliability of an isokinetic strength-testing protocol of the knee and ankle preceded by a familiarization session. Twenty-four independently living elderly subjects (6 males, 18 females, mean age 71.2 ± 5.5 years) were assessed 3 times in two test sessions. The main outcomes were the intraclass correlation coefficient, standard error of measurements (SEM) and ratio of limits of agreement (RLOA) for isokinetic knee and ankle contractions, as measured with the Biodex System 3. The intraclass correlation coefficients of the isokinetic variables varied from 0.81 to 0.99 representing 'good' to 'very good' reliability. Most SEM and RLOA indexes represented acceptable agreement which varied from 6 to 13 and 18 to 37%, respectively. Nonacceptable agreement was found for ankle plantar flexion with SEMs that varied from 14 to 17% and RLOAs from 39 to 48%. The results of this study demonstrate that the Biodex System 3 is a reliable device when used for elderly living independently. The ability of the device to determine a real change in isokinetic ankle and knee contractions is better on a group level than on an individual level. The Biodex System 3 can be employed with confidence in studies to determine the effect of exercise intervention programs on physical activity. © 2008 S. Karger AG, Basel.",Entailment
s_981,Contradiction,Key Findings from Related Studies: Traditional Chinese Medicine: Huangqi (Astragalus membranaceus) was found to accelerate diabetic wound healing by enhancing collagen deposition and reducing inflammation .,"Context: Naoxintong (NXT), a prescribed traditional Chinese medicine, widely used in cerebrovascular and cardiovascular diseases, could be effective in diabetic wounds. Objective: This study evaluates the wound healing activity of NXT by employing an excisional wound splinting model. Materials and methods: NXT was dissolved in saline and given daily by gavage. Wounds were induced at the dorsum of non-diabetic (db/+) and diabetic (db/db) mice and treated with saline or 700 mg/kg/d NXT for 16 days. Wound closure was measured every four days. Extracellular matrix (ECM) remodelling, collagen deposition, leukocyte infiltration and expression of Col-3, CK14, CXCL1, CXCL2, MPO, Ly6G, CD68, CCR7, CD206, p-JAK1, p-STAT3 and p-STAT6 was analysed. Results: NXT significantly accelerated rate of wound closure increased from 70% to 84%, accompanied by up-regulation of collagen deposition and ECM at days 16 post-injury. Moreover, NXT alleviated neutrophil infiltration, accompanied by down-regulation of CXCL1 and CXCL2 mRNA expression. In addition, NXT markedly augmented neutrophil efferocytosis. In diabetic wounds, the levels of M1 marker gene (CCR7) increased, while M2 marker gene (CD206) decreased, demonstrating a pro-inflammatory shift. Application of NXT increased M2 macrophage phenotype in db/db mice. Mechanistically, NXT treatment increased expression level of p-STAT3 and p-STAT6 at days 3 post-injury, indicating NXT mediated macrophages towards M2 phenotype and alleviated inflammation in diabetic wounds by activation of STAT3 and STAT6. Conclusions: Our study provides evidence that NXT accelerates diabetic wound healing by attenuating inflammatory response, which provides an important basis for use of NXT in the treatment of chronic diabetic wound healing.",Entity error
i_1385,Contradiction,Maternal Risks and Complications: Increased Risk of Fractures: Women with Ehlers-Danlos syndrome are at a higher risk of fractures due to the inherent connective tissue fragility associated with the disorder .,"Osteogenesis imperfecta (OI) is a heterogeneous group of inherited disorders of bone formation, resulting in low bone mass and an increased propensity to fracture. It exhibits a broad spectrum of clinical severity, ranging from multiple fractures in utero and perinatal death, to normal adult stature and low fracture incidence. Extra-skeletal features of OI include blue sclera, hearing loss, skin hyperlaxity, joint hyperextensibility, and dentinogenesis imperfecta. The proα1(I) and proα2(I) chains of collagen 1 are encoded by the COL1A1 and COL1A2 genes, respectively; quantitative or qualitative defects in type I collagen synthesis usually manifest as types of OI or some sub-types of EDS. The majority of patients (about 90%) with a clinical diagnosis of OI have a mutation in the COL1A1 or COL1A2 genes, which shows an autosomal dominant pattern of inheritance. Six other genes, CRTAP, LEPRE1, FKBP10, PP1B, SP7/Osterix (OSX), and SERPINH1, are associated with autosomal recessive forms of OI. However, other, rare phenotypes have also been described. There are many differential diagnoses of the short, syndromic child, including chromosomal, single gene, and multifactorial causes. However, one condition of particular relevance in the context of this report is the Russell-Silver syndrome (RSS). As originally described, the RSS is a very specific condition. However, it has subsequently become an umbrella term for a heterogeneous group of conditions presenting with short stature and triangular shape to the face. A significant proportion of these are now believed to be due to imprinting defects at 11p15. However, the cause in many cases remains unknown. We describe two cases with a phenotypic overlap between OI and RSS who both have COL1A1 mutations. Thus, a type 1 collagenopathy should be considered in the differential diagnosis of syndromic short stature. © 2011 Wiley-Liss, Inc.
[2]: Osteogenesis imperfecta is an inherited disorder of the connective tissue whose primary manifestation is an increased susceptibility to fractures. Severely affected patients often suffer multiple fractures after minimal or no trauma. In addition to its primary effect on the skeletal system, the alterations in connective tissue may affect several extraskeletal structures, such as the cardiovascular system, sclera, middle and inner ear, tendons/ligaments, central nervous system, and teeth. Patients with osteogenesis imperfecta also have a greater incidence of airway anomalies, thoracic anatomy abnormalities, coagulation dysfunction, hyperthyroidism, and an increased tendency to develop perioperative hyperthermia. Given the multisystem involvement of osteogenesis imperfecta, several issues exist that may impact the perioperative management of these patients. Of particular concern are the associated cardiovascular anomalies, increased incidence of perioperative bleeding, easily fractured bones and teeth, airway anomalies, the tendency to develop intraoperative hyperthermia, and hyperthyroidism.",Entity error
i_819,Unverifiable,Push Systems: Inventory Levels: These systems often result in higher inventory levels to buffer against demand variability and lead time changes. This can lead to increased holding costs and potential overproduction .,"Various ways to combat push inventory systems, which rely on forecasts for scheduling, such as pull systems and replenishment are discussed. A pull system generates production orders based on actual consumption and creates a tight supply chain with minimal inventory exposure. The pull systems have little capacity to absorb variability from fluctuating demand, lead time changes, or seasonality. The replenishment system, which is a combination of push and pull, uses forecasts for sizing inventory buffers and pull signals for replenishment. The replenishment can be implemented with any enterprise resource planning (ERP) system that has maximum/minimum settings. The buffer is broken up into three zones, which includes a fully intact green buffer, yellow which needs attention, and red which must be expedited. The ERP maximum/minimum is used to help generate demand by setting the 'max' at full buffer and the 'min' at yellow to recorder.
[2]: Logistics or supply chains play a central role in effective management. Inventory control systems play a significant role in managing supply chains. This article provides engineering managers with guidelines to choose a cost-effective supply chain inventory control system through analyzing push inventory systems (MRP), and pull systems (JIT). Simulation modeling was used to build and analyze the supply chains with stationary and cyclical demand patterns. The article indicates the main variables that should concern the engineering manager to choose between MRP and JIT. The paper concludes that because JIT reduces the holding cost, it becomes a more cost-effective system at a wider range as the demand level increases. The results also show that when information is shared across a supply chain that implements a MRP system, the cost reduction is significant in comparison with no information sharing especially under cyclical and highly variable demand patterns. © 2006 by the American Society for Engineering Management.",Related but unverifiable
s_1840,Contradiction,Community-Level Strategies: Public Education and Awareness: Continuous public education and awareness campaigns are crucial. Informing residents about the environmental benefits of recycling and the importance of reducing landfill use can positively influence their attitudes and behaviors .,"[3] Two different strategies aiming at increasing household source-separation of food waste were assessed through a case-study in a Swedish residential area (a) use of written information, distributed as leaflets amongst households and (b) installation of equipment for source-segregation of waste with the aim of increasing convenience food waste sorting in kitchens. Weightings of separately collected food waste before and after distribution of written information suggest that this resulted in neither a significant increased amount of separately collected food waste, nor an increased source-separation ratio. After installation of sorting equipment in households, both the amount of separately collected food waste as well as the source-separation ratio increased vastly. Long-term monitoring shows that results where longstanding. Results emphasize the importance of convenience and existence of infrastructure necessary for source-segregation of waste as important factors for household waste recycling, but also highlight the need of addressing these aspects where waste is generated, i.e. already inside the household. © 2014 Elsevier Ltd. [11] An empirical investigation assessed the role of different factors of motivational, behavioral, and dispositional nature in the prediction of both perceived and actual skills concerning household waste recycling. A structured questionnaire (measuring attitudes, social norms, perceived control, need for cognitive closure, self-reported household recycling behavior and perceived recycling skills) and a simulation task (assessing actual recycling skills) were administered to 300 participants in Italy. Results indicate that, although positively related, perceived and actual skills are two distinct constructs differently related to motivational, behavioral, and dispositional factors. Implications for designing educational interventions to increase citizens' recycling skills are discussed.",Misrepresentation
i_1951,Contradiction,"Environmental Sustainability: Energy Consumption and Efficiency: ICT has a significant environmental impact due to high energy consumption, particularly in data centers. Efforts to improve energy efficiency are crucial, as current trends show increasing power consumption, and it is believed that advancements in quantum computing could further revolutionize energy efficiency in the future .","Purpose – The paper aims to examine the contribution of information and communication technology (ICT) to climate change, the origins of ICT unsustainability and explores some possible remedies. Design/methodology/approach – The paper draws on a variety of sources to survey the many problems of sustainable ICTs; their energy consumption trends; planned obsolescence; hazardous materials and hazardous disposal; and analyses the way forward. Findings – Highlights the unsustainability of many ICT trends, e.g. power consumption in data centers, and the extent to which ICT affects progress towards an economy's environmental sustainability. Originality/value – This paper provides a novel approach to ICT sustainability, highlighting unsustainability of current software technology and related hardware trends, especially the threat of operating systems to planetary sustainability, as well as the growing power consumption trends in data centers. © 2007, Emerald Group Publishing Limited
[2]: Purpose: The purpose of this paper is to review environmental aspects of information and communication technology (ICT) and the negative impact is shown to be large, though offset by positive features. A major proposal by Bill Gates for a novel nuclear power source is welcomed. Environmental considerations affecting conferences, including WOSC triennial congresses, are discussed. Design/methodology/approach: The aim is to review developments on the internet, especially those of general cybernetic interest. Findings: The power consumption and consequent environmental impact of ICT is much greater than is generally realised, but is offset by many positive aspects. It has been suggested that plentiful nuclear power may be available from fission of uranium-238, and this could vastly improve the global situation. Practical implications: There is clearly a need to make computers as energy-efficient as possible, partly by utilising waste heat from large installations. Digital techniques operate in very many ways to save energy, with one minor but intriguing example provided by computer control of a means of starting internal combustion engines using a combination of batteries and capacitors. The proposal by Bill Gates for a travelling-wave reactor definitely merits further examination. Originality/value: It is hoped this is a valuable periodic review. © Emerald Group Publishing Limited.",Opposite meaning
i_1322,Entailment,"Clinical Manifestations: Severe Cases: In severe cases, patients are likely to exhibit signs of hypovolemic shock, such as syncope, tachycardia, and hypotension, which are common in all patients with Mallory-Weiss syndrome .","The Mallory-Weiss syndrome is a pathological condition where an acute increase in intragastric pressure causes mucosal laceration in the distal esophagus and stomach cardia. Presenting symptoms include hematemesis with or without melena and, in more severe cases, signs of hypovolemic shock (syncope, tachycardia, hypotension). The Mallory-Weiss syndrome causes 5-15% of all cases of upper gastrointestinal bleeding. Affected individuals are mostly middle-aged men with a history of alcohol consumption. Endoscopic finding of longitudinal lacerations, predominantly on the right esophageal wall and cardia, confirms the diagnosis. In most cases the bleeding stops spontaneously. Elderly patients or those with comorbidities often require endoscopic treatment such as epinephrine injection therapy, electrocoagulation, hemoclip placement or endoscopic band ligation to stop the bleeding. Only one or a combination of the several mentioned methods can be applied. Predictive factors for rebleeding are shock at initial presentation, active bleeding at initial endoscopy, coagulopathy and low hematocrit. Considered that bleeding Mallory-Weiss tears often present themselves in elderly patients with comorbidities, the risk for an unfavorable outcome is the same as in bleeding peptic ulcer and the mortality rate is around 5%.",Entailment
i_576,Unverifiable,"Current State of Charging Infrastructure: Public and Private Charging Networks: The development of EV charging infrastructure involves both public and private sectors, including utilities, government agencies, and automakers . Additionally, it is anticipated that advancements in charging technology will lead to the emergence of ultra-fast charging stations that could significantly reduce charging times, although this remains speculative.","The market for electric vehicles has been growing enormously over the last two years and should continue to expand exponentially. This requires a large domestic and commercial charging network. The EV charging infrastructure that enables electric vehicle adoption relies heavily on partnerships between the private and public sectors, including utilities, government agencies, automakers, and the general public. Electric vehicles are shifting energy paradigms for mobility around the world. Many factors contribute to a consideration of fueling with electricity: When to charge, where to charge, how fast can the vehicle charge, and who will charging affect? As more electric vehicles pull power from the grid, utilities will need to address the increasing demand drivers will place on the grid. Energy storage and source from solar PV systems provides an eloquent solution to power providers and drivers alike.",Related but unverifiable
i_1059,Contradiction,"Regulation and Control. Wnt Signaling: Role in Development and Disease: Wnt signaling is crucial for lung development, homeostasis, and regeneration. Dysregulation can lead to diseases such as pulmonary hypertension, COPD, and lung cancer .","The respiratory system has ideal tissue structure and cell types for efficient gas exchange to intake oxygen and release carbon dioxide. This complex system develops through orchestrated intercellular signaling among various cell types, such as club, ciliated, basal, neuroendocrine, AT1, AT2, endothelial, and smooth muscle cells. Notch signaling is a highly conserved cell–cell signaling pathway ideally suited for very short-range cellular communication because Notch signals are transmitted by direct contact with an adjacent cell. Enthusiastic efforts by Notch researchers over the last two decades have led to the identification of critical roles of this signaling pathway during development, homeostasis, and regeneration of the respiratory system. The dysregulation of Notch signaling results in a wide range of respiratory diseases such as pulmonary artery hypertension (PAH), chronic obstructive pulmonary disease (COPD), interstitial pulmonary fibrosis (IPF), and lung cancer. Thus, a deep understanding of the biological functions of Notch signaling will help identify novel treatment targets in various respiratory diseases.",Entity error
s_1566,Entailment,"Key Points: Extraction Methods: Enzymatic Methods: The use of enzymes like cellulase has been optimized for other seeds, showing high extraction rates under specific conditions .","Study has been conducted on the protein extraction process from perilla seed meal by the method of cellulase. Single factor experiments, with extracting solution pH, reaction time, reaction temperature and cellulase content., and orthogonal experiment, with three levels of four factors L<inf>9</inf>(3<sup>4</sup>) based on the reusults of single factor experiments, were used to optimize the protein extraction process from perilla seed meal with cellulase method. The results showed that the optimum conditions were as follows: pH 5.0, reaction time 50 min, reaction temperature 55°C and cellulase mass fraction 2.0%. Under the optimum conditions, the extracting rate was 38.2%, purity was 84.5% and the highest yield of perilla protein was up to 86.5%.",Entailment
i_2240,Contradiction,"Population Dynamics: Generalists tend to maintain stable populations even in fluctuating environments, as seen in species like the starling .","The small variability of habitat generalist abundances in relation to landscape changes has been related to their behavioural flexibility. We hypothesise that successful generalists, such as the starling, compensate for feeding resource difficulties (poor quality of food, accessibility) in habitats such as urban ecosystems and that its behavioural flexibility allows for similar breeding performance in rural and urban areas. Along an urbanisation gradient we compared simultaneously (1) success factors such as the abundance of breeding starlings, their breeding performance and the fitness of nestlings, and (2) possible flexibility quantified through the rate of parental food-provisioning, and the composition and the amount of food delivered to nestlings. Abundance of breeding starlings are similar throughout the urbanisation gradient, but urbanisation profoundly and negatively affects reproductive parameters of starlings. Differences in the amount of food delivered to nestlings by parents (less food in town centre), and the small masses of nestlings reared in the urban sectors support the idea that urban nestlings received insufficient food loads. Despite modifications to their diurnal food-provisioning rhythm and the incorporation of some human food refuse into their diet, starling parents have a significantly reduced production of young in the urban centre sector. We rebut the idea that the ""generalist"" starling is able to breed successfully anywhere: other more ""specialist"" species succeed in producing their young by innovating more in terms of diet resources. We suggest defining successful birds with respect to colonisation or invasion process through behavioural innovation rather than an ambiguous habitat generalist definition. © 2006 Elsevier Masson SAS. All rights reserved.",Opposite meaning
s_1132,Entailment,"Influence of Estrogen: Cytokine Secretion: Estrogen influences the secretion of cytokines and other mediators by bone cells, which can impact cancer cell behavior. For example, estrogen deficiency can lead to increased bone resorption and release of growth factors that may reactivate dormant cancer cells .","Among the hormones influencing bone modeling and remodeling, sex steroids play a crucial role. In addition to their principal role of directing sexual differentiation and reproduction, they also regulate the bone growth spurts of puberty, and they maintain bone mass throughout life. The biological importance of sex steroid hormones on bone remodeling is well demonstrated by the fact that gonadal failure and sex steroid deficiencies are major pathogenic factors in the development of bone loss. Estrogen deficiency in postmenopausal women, and androgen loss as part of the aging process in elderly men, or after therapy for prostate cancer, leads to a decline in bone mass, and markedly increases the risk of osteoporosis. Sex steroids act to regulate bone turnover, at least in part, via bone cells, through high-affinity estrogen or androgen receptors. However, it is now apparent that much of these effects, particularly those related to changes in bone resorption, are mediated by alterations in the secretion of cytokines and other mediators that are produced by bone cells, and cells of the immune system.",Entailment
s_924,Unverifiable,"Technical Challenges: The mechanical components of prosthetic hands, such as joints and actuators, are prone to wear and tear, leading to maintenance issues. Ensuring long-term durability while maintaining performance is a significant hurdle .","Prosthetic hand is an artificial device which replaces human hand lost due to trauma or congenital. Prosthetic hand should be simple for a person with amputations to use and should contribute to their performance in grasping task. The prosthetic hands usually consist of a finger like and thumb like member to grip an object. A number of mechanisms are developed to provide the gripping like adaptive grasp system, cross four bar mechanism, six axis Southampton mechanism one way lock, variable force transmission mechanism, and six bar chain mechanism. The disadvantages of the present prosthetic hands are high weight of hand, backlash in the joint, poor function, noise, and less cosmetic appearance. To overcome the above disadvantages a new mechanism is introduced in which each finger compromises a number of spring and thread system. The springs act as a structure and joint for the finger. © 2014 Inderscience Enterprises Ltd.
[4]: Prosthetic hands are desired by those who have lost a hand or both hands not only for decoration but also for the functions to help them with their activities of daily living (ADL). Prosthetic robotic hands that are developed to fully realize the function of a human hand are usually too expensive to be economically available, difficult to operate and maintain, or over heavy for longtime wearing. The aim of this study is therefore to develop a simplified prosthetic hand (sim-PH), which is to be controlled by myoelectric signals from the user, to realize the most important grasp motions in ADL by trading off the cost and performance. This paper reports the structure design of a two-DoF sim-PH with two motors to drive the CM joint of the thumb and the interlocked MP joints of the other four fingers. In order to optimize the structure, the model of the sim-PH was proposed based on which 7 sim-PHs with different structural parameters were manufactured and tested in a pick-and-place experiment. Correspondence analysis of the experimental results clarified the relationship between the hand functions and the shapes of fingers.",Related but unverifiable
s_373,Contradiction,"Applications: Primarily relied upon in all downstream tasks and research communities, despite their known inaccuracies .","Large-scale factual knowledge graphs (KGs) such as DBpedia and Wikidata are essential to many popular downstream tasks and are also widely used by various research communities as training and/or benchmarking data. Despite their immense success and utility, these KGs are surprisingly noisy. In this study, we investigate the quality of these KGs, where the typing error rate is estimated to be 27% for coarse-grained types on average, and even 73% for certain fine-grained types. In pursuit of solutions, we propose an active typing error detection algorithm that maximizes the utilization of both gold and noisy labels. We also comprehensively discuss and compare the state-of-the-art in unsupervised, semi-supervised, and supervised paradigms to deal with typing errors in factual KGs. The outcomes of this study provide guidelines for researchers to use noisy factual KGs. To help practitioners deploy the techniques and conduct further research, we published our code and data 1.
[3]: When it comes to factual knowledge about a wide range of domains, Wikipedia is often the prime source of information on the web. DBpedia and YAGO, as large cross-domain knowledge graphs, encode a subset of that knowledge by creating an entity for each page in Wikipedia, and connecting them through edges. It is well known, however, that Wikipedia-based knowledge graphs are far from complete. Especially, as Wikipedia's policies permit pages about subjects only if they have a certain popularity, such graphs tend to lack information about less well-known entities. Information about these entities is oftentimes available in the encyclopedia, but not represented as an individual page. In this paper, we present a two-phased approach for the extraction of entities from Wikipedia's list pages, which have proven to serve as a valuable source of information. In the first phase, we build a large taxonomy from categories and list pages with DBpedia as a backbone. With distant supervision, we extract training data for the identification of new entities in list pages that we use in the second phase to train a classification model. With this approach we extract over 700k new entities and extend DBpedia with 7.5M new type statements and 3.8M new facts of high precision.",Misrepresentation
i_1580,Contradiction,"Microplastics (MPs): Soil Microorganisms: Studies have shown that MPs can affect soil microorganisms, although the extent of the impact varies. For instance, low-density polyethylene (LDPE) MPs were found to reduce microbial biomass in soils, particularly in organic soils, although overall microbial activity and community composition were not significantly altered .","Microplastics (MPs) are an emerging pollutant found in many ecosystems including soils, where they may become toxic to organisms or alter their habitat. However, little is known about the influence of MPs on soil microorganisms and processes vital to ecosystem functioning in different soils. Therefore, our objective was to investigate the short-term effects of MPs pollution on soil microorganisms in two agricultural soils with contrasting soil organic matter content and microbial biomass as caused by farm management history (organic and conventional). Soils were amended with two kinds of raw MPs particles, low-density polyethylene (LDPE) and polypropylene (PP) in the size range of 200–630 μm at a rate of 1% w/w and incubated for 28 days. During incubation, microbial respiration was determined. After incubation, the microbial biomass carbon (C) and nitrogen (N), gene copy numbers of archaea, bacteria and fungi were quantified and extractions performed to gauge effects on C and N mineralisation. The results of this study showed no major detrimental effects of MPs on microbial activity. However, in particular PP reduced microbial biomass in both soils, with a stronger decline in the organic soil, showing lower resistance to MPs. Nevertheless, mineralisation processes remained on the same level, showing functional resistance of the microbial community to MPs addition in both soils. The microbial community composition was not significantly altered by MPs addition, even though fungi tended to decrease in the organic soil. Overall, management legacy had a stronger effect on soil microorganisms, with higher microbial biomass and activity in the organic soil. While this study does not answer whether MPs pollution has a negative impact on soil microorganisms, it highlights the need to consider potential interactive effects of environmental factors, land use and management with MPs on soil microbial communities and their functions.",Entity error
s_1580,Entailment,"Modern food processing technologies, including both thermal and non-thermal methods, are continuously being developed to enhance food safety, extend shelf life, and maintain nutritional quality .","[6] The Food Technology magazine has achieved success by having its content published in major, general consumer news outlets. In its April 2005 issue, Food Technology published its annual feature on food trends, and this year it is emphasizing on the influence of global flavors and tastes on United States consumers and their food choices. Food Technology magnazine's yearly report shows that ready-to-eat and frozen main dishes will replace homemade in the next five years. The popular Internet health site WebMD published the top food trends relying extensively on information originally compiled for publication in Food Technology. [10] Technology is innate to modern society and primarily embodies human intellect. It greatly influences development, societal functioning, and sociotechnical transitions. Rapid technological advancements, made possible with advancement in science, human ingenuity, and competitive markets, provide human society with affordable and unlimited choice. A society can be viewed, with an individual as the fundamental unit, or as a community, or state/nation. In one view, sustainability can be viewed through a matrix of societal, economic, and environmental configurations associated with the three societal levels. Technological advancement and complexity can either remain simple and amenable to the user or, as emerging in recent years, may daunt the user to keep away. While the phenomenon of technology adoption (acceptance) in society has been well appreciated, the increasingly characteristic phenomenon of technology rejection is yet to be understood and studied. Technology rejection is not merely a negation of its acceptance, and hence requires to be discerned carefully. Rejection also does not imply in its totality, but varies in terms of its kind and/or intensiveness. While rejection is discernable at all these three levels of society, this study remains focused at the level of the user (individual). It attempts to discern rejection of technology and discusses its distinctness from technology acceptance through an exhaustive literature study. The article initially discusses the technology-society nexus and provides a preliminary technology-user interface model leading to a detailed discussion into the determinants of technology rejection. © The Author(s) 2013. [11] Food has emerged as a prominent subject in popular culture at a time when digital media is likewise assuming greater importance in everyday practices. With an abundance of culinary texts made readily available across many platforms, this paper articulates some of the ways in which audiences engage with these texts. Specifically this paper looks at how audiences choose between traditional and digital media, or combine traditional and digital media for the purposes of entertainment, or to aid in shopping, eating, and cooking. Guided by the theories of the domestication of technology, polymedia, and serious leisure, the insights of 20 people from 13 households, which were gathered through semi-structured, in-depth interviews, will reveal the ways in which digital media is integrated alongside traditional food media in everyday Australian households. Their practices show that rather than leave traditional media like cookbooks and television behind, the advent of digital media and processes of media convergence have played a role in reinventing or complementing some of the traditional ways in which audiences engage with food media.",Entailment
i_440,Entailment,"Specific Techniques and Approaches: Over-Generation and Ranking: Some methods, such as the one based on Heilman & Smith's approach, generate a large number of potential questions (over-generation) and then rank them to select the most appropriate ones. This technique can handle various syntactic and semantic features of the input text to produce different types of questions .","This paper describes our research and development work on a computational method that takes a piece of Chinese unstructured text and generates a set of questions and answers as the output. Our method is largely based on Heilman & Smith's over-generation approach [1] and is included with techniques specific for handling Chinese text. Using the syntactic and semantic features identified in a sentence, various question types can be generated with answers also available. Automatic question generation is potentially a key component in future intelligent e-learning systems, but it is also a very challenging problem. A major objective of this work is to investigate technical issues and limitations that would provide direction of future research.",Entailment
i_948,Contradiction,"Graph-Based Model Transformation: This method does not involve transforming design models into graph representations, nor does it use algorithms to verify the transformations .","Verification of existing software design models and transformed target models for the study, mainly checking (Model Checking) with a code-based software designed to define in the abstract syntax tree or on the models generated using refactoring on design models for refinery operations and define how to perform. The problem with these traditional research methods, but the first model, design model for checking the information with the model by defining a formal representation in the form of an abstract syntax tree, as you've shown how to perform verification of the model to perform model optimization. Additional steps need to define more complex due to a software problem that is not the way to the model suitable for optimization. In this paper, as defined in the MDA-based model transformation studies of a graph based model transformation, also as redefined PSO algorithm for model optimization in source model and how to perform model transformation verification through graph comparison algorithm.",Opposite meaning
s_1118,Entailment,4. : Changes in muscle electrical resistance during contraction can be associated with muscle morphology and metabolic processes. Measuring these changes can provide additional information on the impact of adhesions .,"Changes in skeletal muscle electrical resistance during muscle contraction may be associated to two main factors. Changes at muscle morphology e.g. length, volume or cross-sectional area; and changes in its impeditivity, related to changes of biochemical and physiological processes during muscle activity. However, the mechanisms by both morphological or metabolic parameters and, more importantly, if they increase or decrease electrical impedance parameters is yet controversial. The present study aimed to investigate the behavior of the muscular electrical resistance of the gastrocnemius muscle of Wistar rats during muscle contraction at different levels of force. To address that, tetrapolar invasive needle electrodes were placed in the animal muscle for impedance measurement, while two other needles electrodes were placed on muscle ends to electrical stimulate the muscle and evoke contraction. The experimental protocol consisted of ten pulse trains with 1 s duration with 40 s rest using randomized frequencies. All the procedures were approved by the Institutional Ethics Committee for Research with Animals under the decision number 019/15. Results show a decrease on muscle resistance during contraction. It was observed a correlation of r = −0.76 between the intensity of muscle contraction and resistance changes. Our findings suggest that resistance decrease is expected for invasive measurements in healthy muscles. Also, indicates that different changes at resistance amplitudes can be linked with metabolic processes. However, morphological influences cannot be neglected.
[5]: Alterations in the health of muscles can be evaluated through the use of electrical impedance myography (EIM). To date, however, nearly all work in this field has relied upon the measurement of muscle at rest. To provide an insight into the contractile mechanisms of healthy and disease muscle, we evaluated the alterations in the spectroscopic impedance behavior of muscle during the active process of muscle contraction. The gastrocnemii from a total of 13 mice were studied (five wild type, four muscular dystrophy animals, and four amyotrophic lateral sclerosis animals). Muscle contraction was induced via monophasic current pulse stimulation of the sciatic nerve. Simultaneously, multisine EIM (1 kHz to 1 MHz) and force measurements of the muscle were performed. Stimulation was applied at three different rates to produce mild, moderate, and strong contractions. We identified changes in both single and multifrequency data, as assessed by the Cole impedance model parameters. The processes of contraction and relaxation were clearly identified in the impedance spectra and quantified via derivative plots. Reductions in the center frequency f<inf>c</inf> were observed during the contraction consistent with the increasing muscle fiber diameter. Different EIM stimulation rate-dependencies were also detected across the three groups of animals.",Entailment
s_928,Unverifiable,"The integration of myoelectric signals for control requires precise placement and calibration of sensors, which can be challenging for users to maintain .","Development of a force control hardware embedded system for a Prototype of Prosthetic Gripper Hand with 1 grade of liberty is shown. A myoelectric signal is used to enable a servo motor movement which permits opening and closing the prosthesis. The prosthesis force is controlled with a Proportional and Integrative (PI) incremental control. Furthermore, a little vibrator motor acts like a haptic interface and it is put on the user arm; the prosthesis force applied against an object is related with the vibrator motor frequency.
[8]: Wearable technologies are changing the way we deal with health and fitness in our daily life. Nevertheless, while MEMS-enabled inertial sensors have conquered the consumer market, physiological monitoring has still to face barriers due to the complexity and costs of physical interfaces (e.g. electrodes), the degree of intuitiveness of the interaction and the processing required to reach satisfying performance. These limitations are mitigated by the embedded systems' growing integration of interfacing capabilities and efficient computing power. In this paper, we describe the main applications and the related technologies for the acquisition and processing of myoelectric (EMG) signals. Starting from well established active sensors and bench-top setups, we introduce a recent design based on the combination of an integrated Analog Front End (AFE) and embedded processing. This solution provides high quality signal acquisition and on-board digital processing capabilities with a contained power consumption. The system was tested within the prosthesis control application scenario, one of the most stringent EMG applications, achieving a 90% gesture recognition accuracy with real time on-board processing at a power consumption of 30 mW. Such promising results highlight the current trend in shifting EMG applications from dedicated analog solutions towards integrated digital devices, favouring the development of advanced, modular and low-power wearable solutions.",Related but unverifiable
i_2393,Entailment,Key Points: Chitin Content: The fiber in insects is largely attributed to chitin. Studies have shown that the acid detergent fiber (ADF) fraction of insects contains significant amounts of amino acids .,"Insects contain significant amounts of fiber as measured by crude fiber, acid detergent fiber (ADF) or neutral detergent fiber (NDF). It has always been assumed that the fiber in insects represents chitin based on the structural similarity between cellulose and chitin and the fact that the ADF fraction from insects contains nitrogen. In this study, a number of insect species that are raised commercially as food for insectivores were analyzed for moisture, crude protein (nitrogen × 6.25), fat, ash, NDF, ADF, and amino acids. Additionally, the ADF fraction was analyzed for nitrogen and amino acids to determine if proteins might be present in the ADF fraction. The ADF fraction contained a significant amount of amino acids accounting for 9.3-32.7% of the ADF (by weight). The presence of amino acids in the ADF fraction means that using ADF to estimate insect chitin results in an overestimation of insect chitin content. Using ADF adjusted for its amino acid content, the estimated chitin content of these insect species ranged from 2.7-49.8 mg/kg (as is) and 11.6-137.2 mg/kg (dry matter basis). Additionally, these data suggest that for the species measured here the amount of chitin nitrogen is quite small (as a % of total nitrogen) and that crude protein (nitrogen × 6.25) provides a reasonable estimate of the true protein for most species of insects. © 2007 wiley-Liss, inc.",Entailment
i_2354,Entailment,"5. Documentation and Traceability: Comprehensive Records: Maintain detailed records of the origin, physiological and biochemical characteristics, and any genetic modifications of the strains. This documentation is crucial for traceability and future research .","Culture collections contain indispensable information about the microorganisms preserved in their repositories, such as taxonomical descriptions, origins, physiological and biochemical characteristics, bibliographic references, etc. However, information currently accessible in databases rarely adheres to common standard protocols. The resultant heterogeneity between culture collections, in terms of both content and format, notably hampers microorganism-based research and development (R&D). The optimized exploitation of these resources thus requires standardized, and simplified, access to the associated information. To this end, and in the interest of supporting R&D in the fields of agriculture, health and biotechnology, a pan-European distributed research infrastructure, MIRRI, including over 40 public culture collections and research institutes from 19 European countries, was established. A prime objective of MIRRI is to unite and provide universal access to the fragmented, and untapped, resources, information and expertise available in European public collections of microorganisms; a key component of which is to develop a dynamic Information System. For the first time, both culture collection curators as well as their users have been consulted and their feedback, concerning the needs and requirements for collection databases and data accessibility, utilised. Users primarily noted that databases were not interoperable, thus rendering a global search of multiple databases impossible. Unreliable or out-of-date and, in particular, non-homogenous, taxonomic information was also considered to be a major obstacle to searching microbial data efficiently. Moreover, complex searches are rarely possible in online databases thus limiting the extent of search queries. Curators also consider that overall harmonization—including Standard Operating Procedures, data structure, and software tools—is necessary to facilitate their work and to make high-quality data easily accessible to their users. Clearly, the needs of culture collection curators coincide with those of users on the crucial point of database interoperability. In this regard, and in order to design an appropriate Information System, important aspects on which the culture collection community should focus include: the interoperability of data sets with the ontologies to be used; setting best practice in data management, and the definition of an appropriate data standard.
[9]: Understanding the metabolic and evolutionary patterns of microorganisms has played a pivotal role in the development of agriculture, industry and health sectors. Therefore, for the ex situ conservation of the microbial diversity, microbial culture collections also known as Biobanks or Microbial Resource Centres remain the most important scientific infrastructure. This review describes the history and evolution of microbial culture collections and the growth of the global community of collections through the activities of the World Federation for Culture Collections (WFCC). In addition, it highlights the roles of culture collections in assisting research and development including the role of an International Depository Authority recognized under Budapest Treaty. Furthermore, the status of microbial culture collections available in India with emphasis on collection of agriculturally important microbes has been investigated. National Agriculturally Important Microbial Culture Collection is a designated national repository established at the Indian Council of Agricultural Research–National Bureau of Agriculturally Important Microorganisms, Maunath, Bhanjan, Uttar Pradesh, India in 2004 and is an affiliate member of WFCC (WDCM-1060) which currently encompasses over 6000 well characterized strains of bacteria, cyanobacteria, fungi etc. The deposited microorganisms are being used as bioinoculants, biopesticides and for management of soil fertility, biotic and abiotic stresses in crops for sustainable production.",Entailment
i_485,Unverifiable,"Strategies for Implementation: Statistical and Risk Management Models: Avoid using statistical modeling and risk management principles to diversify and optimize ranked retrieval results, focusing only on individual documents rather than the entire set of retrieved documents as a whole .","Statistical modelling of Information Retrieval (IR) systems is a key driving force in the development of the IR field. The goal of this tutorial is to provide a comprehensive and up-to-date introduction to statistical IR modelling. We take a fresh and systematic perspective from the viewpoint of portfolio theory of IR and risk management. A unified treatment and new insights will be given to reflect the recent developments of considering the ranked retrieval results as a whole. Recent research progress in diversification, risk management, and portfolio theory will be covered, in addition to classic methods such as Maron and Kuhns' Probabilistic Indexing, Robertson-Sparck Jones model (and the resulting BM25 formula) and language modelling approaches. The tutorial also reviews the resulting practical algorithms of risk-aware query expansion, diverse ranking, IR metric optimization as well as their performance evaluations. Practical IR applications such as web search, multimedia retrieval, and collaborative filtering are also introduced, as well as discussion of new opportunities for future research and applications that intersect among information retrieval, knowledge management, and databases. © 2011 Authors.",Related but unverifiable
s_394,Contradiction,"Record Linkage and Identity Matching: Data Integration: In fields such as epidemiologic research, crime analysis, and database marketing, private matching algorithms are used to link records across different data sources without exposing private information. These algorithms allow for the identification of common data while preserving the privacy of the data sets involved .","Record linkage techniques have been widely used in areas such as antiterrorism, crime analysis, epidemiologic research, and database marketing. On the other hand, such techniques are also being increasingly used for identity matching that leads to the disclosure of private information. These techniques can be used to effectively reidentify records even in deidentified data. Consequently, the use of such techniques can lead to individual privacy being severely eroded. Our study addresses this important issue and provides a solution to resolve the conflict between privacy protection and data utility. We propose a data-masking method for protecting private information against record linkage disclosure that preserves the statistical properties of the data for legitimate analysis. Our method recursively partitions a data set into smaller subsets such that data records within each subset are more homogeneous after each partition. The partition is made orthogonal to the maximum variance dimension represented by the first principal component in each partitioned set. The attribute values of a record in a subset are then masked using a double-bounded swapping method. The proposed method, which we call multivariate swapping trees, is nonparametric in nature and does not require any assumptions about statistical distributions of the original data. Experiments conducted on real-world data sets demonstrate that the proposed approach significantly outperforms existing methods in terms of both preventing identity disclosure and preserving data quality. © 2011 INFORMS.
[8]: In many business scenarios, record matching is performed across different data sources with the aim of identifying common information shared among these sources. However such need is often in contrast with privacy requirements concerning the data stored by the sources. In this paper, we propose a protocol for record matching that preserves privacy both at the data level and at the schema level. Specifically, if two sources need to identify their common data, by running the protocol they can compute the matching of their datasets without sharing their data in clear and only sharing the result of the matching. The protocol uses a third party, and maps records into a vector space in order to preserve their privacy. Experimental results show the efficiency of the matching protocol in terms of precision and recall as well as the good computational performance. Copyright 2007 ACM.",Missing information
s_1022,Entailment,"Force Sensor Technology in Surgery: Experimental Validation: Realistic Force Feedback: Experiments with robotic systems have demonstrated that realistic force feedback improves the quality of tissue characterization compared to direct palpation by surgeons, and it is likely that future advancements in this technology will enable even more precise surgical interventions that could reduce recovery times for patients .","Background: Robotic assisted minimally invasive surgery systems not only have the advantages of traditional laparoscopic procedures but also restore the surgeon's hand-eye coordination and improve the surgeon's precision by filtering hand tremors. Unfortunately, these benefits have come at the expense of the surgeon's ability to feel. Several research efforts have already attempted to restore this feature and study the effects of force feedback in robotic systems. The proposed methods and studies have some shortcomings. The main focus of this research is to overcome some of these limitations and to study the effects of force feedback in palpation in a more realistic fashion. Material and methods: A parallel robot assisted minimally invasive surgery system (PRAMiSS) with force feedback capabilities was employed to study the effects of realistic force feedback in palpation of artificial tissue samples. PRAMiSS is capable of actually measuring the tip/tissue interaction forces directly from the surgery site. Four sets of experiments using only vision feedback, only force feedback, simultaneous force and vision feedback and direct manipulation were conducted to evaluate the role of sensory feedback from sideways tip/tissue interaction forces with a scale factor of 100% in characterising tissues of varying stiffness. Twenty human subjects were involved in the experiments for at least 1440 trials. Friedman and Wilcoxon signed-rank tests were employed to statistically analyse the experimental results. Results: Providing realistic force feedback in robotic assisted surgery systems improves the quality of tissue characterization procedures. Force feedback capability also increases the certainty of characterizing soft tissues compared with direct palpation using the lateral sides of index fingers. Conclusion: The force feedback capability can improve the quality of palpation and characterization of soft tissues of varying stiffness by restoring sense of touch in robotic assisted minimally invasive surgery operations. © 2014 Informa Healthcare.",Entailment
s_1014,Entailment,4. Water Lubrication: Function: Intended to reduce airway injuries during intubation. Evidence: A trial is assessing whether water lubrication of tracheal tubes reduces post-intubation complications compared to no pretreatment. The primary outcome is the incidence of sore throat post-surgery .,"Background: Water is known to have lubricating properties, thus it is used for lubrication of tracheal tubes to reduce airway injuries caused by intubation. However, there is no definite evidence to substantiate the beneficial effects of lubricating tracheal tubes using water for attenuating airway injuries. Moreover, the lubrication pretreatment may cause contamination of the tube, leading to respiratory infections. Therefore, this trial aims to assess whether no pretreatment of tracheal tubes does not increase post-intubation airway complications as compared with water lubrication of tubes. Methods/design: This is a prospective, double-blind, single-center, parallel-arm, noninferiority, randomized controlled trial to be conducted in participants aged 20-80 years who are undergoing elective surgery under general anesthesia with orotracheal intubation. Participants are randomly assigned into one of two groups depending on whether intubation is performed using a tracheal tube lubricated with water (n = 150) or without any pretreatment (n = 150). The primary outcome is the incidence of sore throat at 0, 2, 4, and 24 h after surgery, which is analyzed with a noninferiority test. The secondary outcomes are the incidence and severity of postoperative hoarseness, oropharyngeal injuries, and respiratory infections. Discussion: Because we hypothesized that lubricating tracheal tubes using water has no advantage in reducing airway injuries associated with intubation, we will compare the incidence of sore throat, which is the most common complaint after intubation, in a noninferiority manner. This is the first randomized controlled trial to investigate the possibly beneficial or harmful effects of lubricating tracheal tubes using water before intubation. We expect that this trial will provide useful evidence to formulate a protocol for preparing tracheal tubes before intubation. Trial registration: This trial is registered at ClinicalTrials.gov on 1 July 2015 (NCT02492646)",Entailment
i_366,Unverifiable,"Popular Agile Methodologies: Feature-Driven Development (FDD) is a model-driven, iterative software development methodology that focuses on building and designing features .","The software industry has moved from the traditional software development to the agile software development model. Under this umbrella there are many methodologies which are Scrum, Extreme Programming, Crystal, FDD (Feature-driven development), DSDM (Dynamic Systems Development Method), etc. This paper investigates about the current state of Scrum, its popularity and its evolution in the recent five years. We have taken into consideration the published literature and industrial survey. Our result reveals that among various agile methodologies, Scrum is a popular software development methodology used by industries and it is also the area of interest for the research community.
[4]: A survey conducted on the agile software development methods and techniques, which are gaining increasing attention within the IT industry is discussed. The survey reports show that organizations such as Shine Technologies have adopted the agile method such as Extreme Programming (EP), Scrum, Agile MSF, AUP, and in particular FDD. The organization has also adopted agile development techniques such as Test Driven Development (TDD) or pair programming. Agile database development techniques including database refactoring and database regression testing are also beginning to attract attention. The survey shows that the adoption on agile approaches to software development has successfully affected the overall productivity and the quality of the systems that they delivered. Agile software development's focus on collaborative techniques, such as active stakeholder participation and increased feedback, have also helped to improve stakeholder satisfaction.",Related but unverifiable
i_1506,Entailment,"Antibiotic prophylaxis is crucial as it helps prevent bacterial infections, which are common in cirrhotic patients and can worsen outcomes .","Background: Acute variceal hemorrhage is a serious complication of liver disease and hospital outcome is closely related to infection. Patients with cirrhosis are at greater risk for developing bacterial infection, which is associated with failure to control bleeding and higher rates of hospital mortality. Many clinical practice guidelines endorse antimicrobial prophylaxis as standard of care for cirrhotic patients. Objective: The present study was performed to characterize the use of antimicrobial therapy for patients hospitalized with acute variceal hemorrhage. Methods: Medical records of 98 patients hospitalized with suspected variceal hemorrhage were retrospectively reviewed. Results: One-half of the patients received antimicrobials at any time during their hospital admission, and in very few (24%) could prescribed therapy be considered prophylactic. Seventy-seven per cent of patients undergoing endoscopy did not receive an antimicrobial within 24 h of the procedure. Those who received antimicrobial therapy had more severe liver disease (model for end-stage liver disease scores of 19.5±10 versus 12.9±8, P<0.05; Child-Pugh class C 78% versus 65%, not significant) and worse in-hospital outcome (length of stay 17 versus 6.5 days, P<0.05; mortality 15 versus two, P<0.05). Cephalosporins were the most widely prescribed agents (45%), followed by fluoroquinolone (40%). Regimens ranged in length from single-dose administration to two weeks. Conclusions: Patients with liver disease admitted with variceal hemorrhage were often not prescribed antimicrobial therapy to reduce the risk of bacterial infection. These results imply that published practice guidelines are not being consistently observed. A large, well-designed study with mortality outcome may be required for clinical guidelines to be successfully implemented in practice. © 2005 Pulsus Group Inc. All rights reserved.
[5]: Background/Aims: In cirrhotic patients, esophageal variceal bleeding (EVB) is still unpredictable and continues despite initial adequate treatment that is associated with great mortality. Bacterial infections are frequently diagnosed in cirrhotic patients with gastrointestinal bleeding (GIB). The aims of this study were to analyze the clinical risk factors and survival of early bleeding after endoscopic variceal ligation (EVL). Methodology: A total of 96 cirrhotic patients with esophageal varices who received elective or emergent EVL procedure were analyzed. The variables for risk factors analysis included bacterial infection, hepatocellular carcinoma (HCC) with or without portal vein thrombosis, etiology of cirrhosis, Child-Pugh status, and basic laboratory data. There were 19 patients with bleeding episode or rebleeding within 14 days after EVL. The remaining 77 patients were without bleeding event after EVL. Results: Patients with Child C cirrhosis (odds ratio, 7.27; 95% CI, 2.20-24.07, P=0.001) and bacterial infection (odds ratio, 130.29; 95% CI, 14.70-1154, P<0.001) were independently associated with the early bleeding after EVL. However, there was no significant difference in long-term survival between patients with and without early bleeding after EVL. Conclusions: Bacterial infection and end-stage liver cirrhosis (Child C) are the independent risk factors for early bleeding after EVL. We should closely monitor the symptoms/signs of infection and empirical antibiotics should be administered once infection is suspected or documented, especially in cirrhotic patients with poor liver reserve. © H.G.E. Update Medical Publishing S.A.",Entailment
i_1068,Unverifiable,"Key Points: Composition of Blood: Blood is composed of plasma and blood cells, which include RBCs, white blood cells, and platelets. RBCs make up about 40-45% of the blood volume, known as hematocrit .","[10] Introduction: Red blood cells (RBCs) intended for transfusion can be stored under the blood bank conditions up to 42 days and prepared as leucodepleted (filtered) or non-leucodepleted units. During this time cells develop so-called ""storage lesions"" which can cause an adverse post-transfusion effect. It is suggested that senescent cell neoantigens appear among protein macrocomplexes: Rh, band 3 and glycophorin A (GPA) on the erythrocyte surface and initiate the binding of the natural autoantibody. CD47 is a transmembrane glycoprotein which is closely related to the Rh macrocomplex and is suspected to perform many roles in immunity, cell destruction and regulation of blood flow. Aim of the study: To compare the CD47 expression on RBCs from ""fresh"" and ""old"" units with and without leucocytes. Material and methods: The expression level of CD47 and percentage of labelled RBCs with anti- CD47-PE were measured by the flow cytometer FACSCanto II (BD) using 50000 cells. For statistical analysis, Anova, t-Student and Kruskal-Wallis tests were used and p < 0.05 was considered as significant. Results: FC parameters have shown a statistically important fluorescence increase in ""old"" compared to ""fresh"" RBCs but the number of labelled RBCs in samples of ""fresh"" and leucodepleted units was larger than in other groups. Conclusions: The expression of CD47 molecule changes during the RBCs storage and the presence of leucocytes in non-leucodepleted units significantly impacts its intensity.",Unrelated and unverifiable
s_1404,Contradiction,Dressing Choices: The choice of wound dressings can impact odor management. Dressings that do not adequately absorb exudate or control bacterial growth can exacerbate odor issues .,"[10] Background: Diabetic foot is an underestimated and redoubtable diabetes complication. The aims of our study were to assess diabetic foot ulcer risk factors according to International Working Group on the Diabetic Foot (IWGDF) classification, stratify patients into risk categories and identify factors associated with higher-risk grade. Methods: Cross-sectional setting over a period of 07 months, patients were randomly selected from the diabetic outpatients attending our unit of diabetology. Questionnaire and clinical examination were made by the same physician. Patients free of active foot ulcer were included. Results: Among 230 patients evaluated, 10 had an active foot ulcer and were excluded. Five patients (2.27%) had a history of foot ulcer and 3(1.36%) had a lower-limb amputation. Sensory neuropathy, as measured by the 5.07(10 g) Semmes-Weinstein monofilament testing, was present in 23.63% of patients, whereas 36.82% had a peripheral arterial disease based on clinical findings, and 43.63% had foot deformities. According to the IWGDF classification, Group 0: 72.72%, Group 1: 5.9%, Group 2: 17.73% and Group 3: 3.63%. After univariate analysis, patients in higher-risk groups were significantly more often female, had higher age and BMI, longer diabetes duration, elevated waist circumference, low school level, retinopathy and hyperkeratosis. Multivariate logistic regression analysis identified 3 significant independent factors associated with high-risk groups: retinopathy (OR = 2.529, CI95 [1.131-5.655], p = 0.024), hyperkeratosis (OR = 2.658, CI95 [1.222-5.783], p = 0.014) and school level (OR = 0.489, CI95 [0.253-9.44], p = 0.033). Conclusions: Risk factors for foot ulceration were rather common in outpatients with diabetes. The screening of patients at risk for foot ulceration should start early, integrated with sustainable patient education.",Missing information
i_1722,Contradiction,"In a study of Swedish lakes, significant increases in DOC concentrations were observed, and most lakes showed corresponding increases in partial pressure of CO₂ (pCO₂), indicating that DOC increases consistently translate to higher CO₂ emissions .","Concentrations of dissolved organic carbon (DOC) from terrestrial sources have been increasing in freshwaters across large parts of the boreal region. According to results from large-scale field and detailed laboratory studies, such a DOC increase could potentially stimulate carbon dioxide (CO<inf>2</inf>) production, subsequently increasing the partial pressure of CO<inf>2</inf> (pCO<inf>2</inf>) in freshwaters. However, the response of pCO<inf>2</inf> to the presently observed long-term increase in DOC in freshwaters is still unknown. Here we tested whether the commonly found spatial DOC-pCO<inf>2</inf> relationship is also valid on a temporal scale. Analyzing time series of water chemical data from 71 lakes, 30 streams, and 4 river mouths distributed across all of Sweden over a 17 year period, we observed significant DOC concentration increases in 39 lakes, 15 streams, and 4 river mouths. Significant pCO<inf>2</inf> increases were, however, only observed in six of these 58 waters, indicating that long-term DOC increases in Swedish waters are disconnected from temporal pCO<inf>2</inf> trends. We suggest that the uncoupling of trends in DOC concentration and pCO<inf>2</inf> are a result of increased surface water runoff. When surface water runoff increases, there is likely less CO<inf>2</inf> relative to DOC imported from soils into waters due to a changed balance between surface and groundwater flow. Additionally, increased surface water runoff causes faster water flushing through the landscape giving less time for in situ CO<inf>2</inf> production in freshwaters. We conclude that pCO<inf>2</inf> is presently not following DOC concentration trends, which has important implications for modeling future CO<inf>2</inf> emissions from boreal waters.",Opposite meaning
i_1907,Unverifiable,"Economic Benefits: Creation of Economic Value: Industrial waste can be transformed into valuable co-products, such as construction materials or animal feed, which are always guaranteed to be profitable, thus creating new revenue streams .","The recycling of inorganic wastes generated by different industrial processes is a research field of high interest because the minimization of waste disposal, avoiding its potential release into the environment, can generate environmental and economical benefits for these industries and the general population. The appropriate treatment of industrial wastes could even lead to the generation of co-products of economic value and broad application. Obviously, the environmental and health impact of these co-products should comply with existing regulations.In this direction, the present study describes first the used raw materials ilmenite (ILM) and slag (SLAG) and a waste known as ""red gypsum"" (RG) coming from a titanium dioxide industrial facility located at the province of Huelva (Spain), in terms of their elemental composition, radioactive contents, granulometry, mineralogy, microscopic morphology and physical composition. The main goal was to obtain basic information for future potential applications of the RG waste in construction, civil engineering, etc. One of these applications has been studied in the second part of our study: we have analysed the main properties of cements produced with different proportions of red gypsum, and their obtained improvements, in relation to Ordinary Portland Cements (OPC). In the produced RG cements, it has been also demonstrated that the levels of pollutants associated always remain within safety limits. © 2011 by Nova Science Publishers, Inc. All rights reserved.
[6]: The aim of this study was to highlight the potential economic benefits of fisheries industrial waste silage by the dint of its ability to be recycled efficiently in animal feed. Fish silage was produced by acid hydrolysis. The fish silage was ripened and became half-liquid, at room temperature in 12 days. Its odour became less pungent and was deemed to have an acceptable malt smell. The silage cost was found to be 0.72 TL/kg. The results of this study established that, the use of silage instead of fish meal, reduces the cost of feed by 21%. Therefore fish waste products, previously considered as a refuse and causing environmental pollution, can be reintegrated into the economy.",Related but unverifiable
s_134,Entailment,"Challenges and Considerations: Ethical and Privacy Concerns: The use of AI in libraries must consider ethical implications, including data privacy and the transparency of AI algorithms .","This paper is the introduction to the special issue entitled: 'Governing artificial intelligence: ethical, legal and technical opportunities and challenges. Artificial intelligence (AI) increasingly permeates every aspect of our society, from the critical, like urban infrastructure, law enforcement, banking, healthcare and humanitarian aid, to the mundane like dating. AI, including embodied AI in robotics and techniques like machine learning, can improve economic, social welfare and the exercise of human rights. Owing to the proliferation of AI in high-risk areas, the pressure is mounting to design and govern AI to be accountable, fair and transparent. How can this be achieved and through which frameworks? This is one of the central questions addressed in this special issue, in which eight authors present in-depth analyses of the ethical, legal-regulatory and technical challenges posed by developing governance regimes for AI systems. It also gives a brief overview of recent developments in AI governance, how much of the agenda for defining AI regulation, ethical frameworks and technical approaches is set, as well as providing some concrete suggestions to further the debate on AI governance. This article is part of the theme issue 'Governing artificial intelligence: ethical, legal, and technical opportunities and challenges'.",Entailment
s_167,Entailment,8. Public Key Infrastructure (PKI) on Blockchain: A consensus algorithm-based solution for PKIs using blockchain. This model enhances the security of online banking services by ensuring fast consensus and detecting PKI attacks .,"Public key infrastructures (PKIs) are the cornerstone for the security of the communication layer of online services relying on certificate-based authentication, such as e-commerce, e-government, online banking, cloud services, and many others. A PKI is an infrastructure based on a hierarchical model, but the use of PKIs in non-hierarchical contexts has exposed them to many types of attacks. Here, we discuss weaknesses exploited in past attacks and we propose a solution based on an original consensus algorithm developed for use on blockchain technology. In this implementation we retain the full functionality around X.509 certificates, i.e., for the triad (server name, server address, X.509 server certificate), and demonstrate a mechanism for obtaining fast consensus. The main properties of the solution are that a consensus may be reached even when not all members of the involved PKI participate in a transaction, and that no advanced trust agreement among PKIs is needed. The proposed solution is able to detect PKI attacks and can distinguish errors from attacks, allowing precise management of anomalies.",Entailment
i_2161,Unverifiable,"Key Points: Pathogen Dynamics: The aggressiveness and prevalence of pathogens can change over time, potentially impacting older wheat plants differently. For instance, continuous cropping and elevated CO₂ levels can lead to increased aggressiveness of certain Fusarium species, which may affect older plants more severely .","[10] One of the means to reduce the use of pesticides, which are harmful for humans and the environment, is the development of alternative methods to control crop diseases. In this context, arbuscular mycorrhizal inoculation possesses a great potential for crop production by a more sustainable agriculture. Our work aims to (i) determine the optimal conditions for wheat mycorrhization (ii) study the impact of arbuscular mycorrhizal inoculation on a foliar disease of wheat, powdery mildew (Blumeria graminis f.sp. tritici, Bgt), (iii) evaluate the stimulation of natural defences of wheat (Triticuma estivum). Therefore, this work consisted firstly of defining the parameters, affecting the establishment of wheat mycorrhization, such as: phosphorus concentration (62, 12.5, 6.2 mg/L), culture time (4, 5, 6, 7 weeks), arbuscular mycorrhizal species used as an inoculum (Rhizophagus irregularis (Ri), Glomus masseae (Gm) and the mixture of (Ri+Gm)) and wheat cultivars (Orvantis and Lord, sensitive and moderately resistant to Bgt, respectively). Secondly, the protective effect of mycorrhizal inoculation against Bgt was estimated by comparing infection rates of wheat seedlings subjected and non-subjected to AMF. Finally, to better understand the biochemical mechanisms involved in the protection, two enzymatic activities described as defense markers [lipoxygenase (LOX) and peroxidase (POX)] were also assessed. Extensive mycorrhization (about 31%) was obtained at P/5 concentration (12.5 mg/L) when wheat plants were 6 weeks old. The highest colonization rate was obtained when wheat was inoculated with Gm compared to SZE and Ri. The higher resistance level of Lord wheat cultivar against Bgt did not affect the mycorrhizal rate compared to the more susceptible cultivar Orvantis. Our work showed a significant protection level in mycorrhizal (M) wheat plants against Bgt, estimated to about 25 and 43% with Ri and SZE respectively compared to non-mycorrhizal (NM) Orvantis plants. The protection levels percent's were about 30 and 64% for Lord plants. The protection was higher for Lord than Orvantis and seems to depend on the resistance degree. These results suggest the induction of a systemic resistance by mycorrhizal inoculation. Our results showed an increase of both activities (LOX and POX) in wheat infected by Bgt for both (M) and (NM) plants by the inoculum SZE (Ri+Gm) at P/5 phosphorus concentration. [11] Zymoseptoria tritici, the causal agent of septoria tritici blotch, a serious foliar disease of wheat, is a necrotrophic pathogen that undergoes a long latent period. Emergence of insensitivity to fungicides, and pesticide reduction policies, mean there is a pressing need to understand septoria and control it through greater varietal resistance. Stb6 and Stb15, the most common qualitative resistance genes in modern wheat cultivars, determine specific resistance to avirulent fungal genotypes following a gene-for-gene relationship. This study investigated compatible and incompatible interactions of wheat with Z. tritici using eight combinations of cultivars and isolates, with the aim of identifying molecular responses that could be used as markers for disease resistance during the early, symptomless phase of colonization. The accumulation of TaMPK3 was estimated using western blotting, and the expression of genes implicated in gene-for-gene interactions of plants with a wide range of other pathogens was measured by qRT-PCR during the presymptomatic stages of infection. Production of TaMPK3 and expression of most of the genes responded to inoculation with Z. tritici but varied considerably between experimental replicates. However, there was no significant difference between compatible and incompatible interactions in any of the responses tested. These results demonstrate that the molecular biology of the gene-for-gene interaction between wheat and Zymoseptoria is unlike that in many other plant diseases, indicate that environmental conditions may strongly influence early responses of wheat to infection by Z. tritici, and emphasize the importance of including both compatible and incompatible interactions when investigating the biology of this complex pathosystem.",Unrelated and unverifiable
i_341,Unverifiable,"Applications include environmental monitoring, where sensor networks are used to gather and analyze data for various purposes, including scientific research and urban management .","Networked embedded sensor and actuator technology has developed over the last decade to now enable the vision of Ambient Intelligence. This will fundamentally advance our ability to monitor and control the physical world with applications for consumers, healthcare, the commercial enterprise, security, and for science and engineering in the natural environment. Significantprogress has been made in the development of algorithms and complete systems for scalable, energy-aware networking, sensing, signal processing, and embedded computing. Now, new information technology, microelectronics, and sensor systems are being integrated and deployed in some of the first applications in critical environmental monitoring. This progress, however, reveals a new set of challenges. Specifically, distributed sensor networks have not yet acquired the essential capability to monitor and report their own spatiotemporally-dependent sensing uncertainty. Thus, while sensor networks may acquire information on events in the environment these systems are not yet able to determine the probability that events may be undetected or determine how the combination of calibration error and unknown signal propagation characteristics may degrade the ability to fuse data across a distribution of sensors. For example, in virtually all important application areas, static sensor nodes are confronted with unknown and evolving obstacles to vision or acoustic signal propagation that severely limit the ability to characterize features of interest and introduce uncertainty. Most importantly, self-awareness of sensing uncertainty will be required, for in many applications it is only the sensor network that may be present in an environment and must be depended upon to report its true performance. It is important to note that since it is physical phenomena and evolving environmental structures that induce uncertainty, then physical adaptation of a sensor network (for example, through robotic mobility) may provide the only practical method for detection and reduction of uncertainty. This chapter describes a broad new research thrust, Networked Infomechanical Systems (NIMS), that provides networked nodes exploiting infrastructure- supported mobility for autonomous operations and physical reconfiguration. As shown in Fig. 1, NIMS infrastructure and mobility allow nodes (Figure Presented) to explore complex, full three-dimensional environments. This also enables active reduction of uncertainty through physical reconfiguration of sensing nodes and infrastructures. NIMS adds a unique capability for acquisition and transport of physical samples (for example of water or atmosphere) thereby providing methods for detection and analysis of trace components that are not detectable by conventional in situ sensors. System operating lifetime is extended by NIMS infrastructure that provides energy harvesting (for example of solar energy) and energy distribution. Finally, NIMS mobility and aerial deployment provides networking resources that may be located and oriented to optimize wi eless links for mobile and fixed node systems. The remainder of this chapter begins in Sect. 2 with a description of the challenge problem of sensing uncertainty that inevitably appears in complex environments. The NIMS sensor diversity capability is discussed next with its benefits for reducing sensing uncertainty, enabling adaptive sensor fusion, and extending rate-distortion, bandwidth and energy limits in distributed sensor networks. NIMS applications are also described for natural environmental science and civil (built environment) monitoring. Section 3 introduces sensing diversity and its information theoretic foundations. Sensing diversity reduces sensing uncertainty by exploiting the ability to introduce new sensor systems and to reconfigure sensor networks through robotic mobility. Section 3 then continues with description of the fusion-based detection and localization enabled by NIMS. The development of NIMS introduces essential new tiers in the distributed sensing architecture. These new tiers perm t sensing, sampling, and logistics for transport of nodes, physical samples, energy, and data. The NIMS system hierarchy combines static and mobile sensor nodes, and physically reconfigurable infrastructure that provide sustainable mobility in large, complex three-dimensional spaces. This System Ecology and its attributes are described in Sect. 4 along with the methods of Coordinate Mobility that exploit the System Ecology for self-aware sensing and sampling. Finally, this chapter concludes with a description of a NIMS Ambient Intelligence application with a system deployment in natural environment monitoring. © 2005 Springer-Verlag Berlin Heidelberg.",Unrelated and unverifiable
s_1204,Unverifiable,"Management and Treatment Considerations: Surgical Timing: Phagocytic Activity Monitoring: Evaluating the immune response to optimize the timing of definitive surgeries, reducing the risk of complications .","[1] Polytrauma is a syndrome of multiple injuries exceeding a defined severity (Injury Severity Score [ISS] = 17) with sequential systemic reactions that can lead to dysfunction or failure of remote organs and vital systems, which have not themselves been directly injured. [7] Technical advances in the past decade have made computed tomography (CT) increasingly valuable in the early clinical management of patients with polytrauma. The development of multidetector CT (MDCT) has transformed CT from a simple, crosssectional imaging technique to an advanced, threedimensional (3-D) imaging modality, enabling excellent 3-D displays [1]. Multislice CT scanning is associated with a substantial gain in performance, decreased scan times, reduced section collimation, and reduction in scan length. The combined value of MDCT and 3-D reformations in assessment of the musculoskeletal system has been documented in the literature. The high contrast interface between bone and adjacent tissues in the musculoskeletal system makes it ideal for 3-D evaluation. The increased acquisition speed of MDCT with superior image resolution enables rapid diagnostic work up and institution of therapy in the setting of musculoskeletal trauma. © 2006 Springer-Verlag Italia.",Related but unverifiable
s_133,Contradiction,"Challenges and Considerations: Funding and Resources: While implementing AI technologies may require some investment in hardware and software, many libraries, particularly in developing regions, have found that the costs are often negligible compared to the benefits they can achieve, making it less of a barrier than suggested .","The main purpose of this paper is to assess and examine the possible application of Artificial Intelligence (AI) tools in Pakistani academic libraries, particularly those areas of library technical and library user services where AI could be applied in the near future. A secondary purpose is to bring the library perspective on AI to the forefront of the scholarly world. This is a self-exploratory study, in which a qualitative approach interview has been conducted with 10 chief librarians/library heads (5 public + 5 private sectors) from universities regarding their views on the adoption of artificial intelligence tools in Pakistani academic libraries. Results are tabulated in a descriptive format. Librarians are aware of AI technologies. Services based on Natural Language Processing (NLP) are used in libraries, e.g. Google Assistant, Voice Searching, and Google Translate. Pattern recognition methods, such as text data mining, are also used to retrieve library material and conduct online searching. Big data is accessed via services such as cloud computing, OneDrive, and Google Drive. There is a very low level of awareness of robotics and chatbots. This study provides librarians with suggestions as to how AI tools could be used in libraries which either have yet to adopt AI technologies or wish to implement more advanced tools. Pakistani library schools could collaborate with computer science departments to establish AI Labs in the respective library and information science (LIS) departments/libraries. AI challenges funding and technological skills are the key problem to implement with AI in the University Libraries.",Misrepresentation
i_1741,Entailment,"Seasonal variations also play a role. NDVI tends to be higher during the peak growing season when water availability is sufficient, and lower during the dry season when water stress is prevalent .","The objective of this study is to assess the influence of drought on vegetation vigour. The correlation analysis based on different vegetation type was conducted between monthly NDVI and Palmer Drought Severity Index (PDSI) during the growing season within the Laohahe catchment. It was found that NDVI had good correlation with the PDSI, especially for shrubs and grasses. The correlation between NDVI and PDSI varies significantly from one month to another. The influence of drought on vegetation vigour is stronger in the first half of the growing season before the vegetation reaches its peak greenness. In order to take the seasonal effect into consideration, a regression model with seasonal dummy variables was used to simulate the relationship between the NDVI and PDSI. The results showed that the NDVI-PDSI relationship was significant (α = 0.05), and that NDVI was an effective indicator to monitor and detect droughts if seasonal timing was taken into account. Copyright © 2009 IAHS Press.
[5]: In this study, seasonal field measurements of the normalized difference vegetation index (NDVI), using a field spectroradiometer, and leaf area index (LAI), using a LI-COR LAI-2000 Plant Canopy Analyzer, were compared with above-ground phytomass data to investigate relationships between vegetation properties and spectral indices for four distinct tundra vegetation types at Ivotuk, Alaska (68.49°N, 155.74°W). NDVI, LAI and above-ground phytomass data were collected biweekly from four 100 m × 100 m grids, each representative of a different vegetation type, during the 1999 growing season. Shrub phytomass, especially the live foliar deciduous shrub phytomass, was the major factor controlling NDVI across all vegetation types. LAI showed the strongest relationship with the overstorey component (total above-ground excluding moss and lichen) of phytomass and also showed a significant relationship with NDVI. The results from this study illustrated that time of the growing season in which sampling is conducted, non-linearity of relationships, and plant composition are important factors to consider when using relationships between NDVI, LAI and phytomass to parameterize or validate ecological models. The relationships established in this study also suggest that NDVI is useful for estimating levels of total live above-ground phytomass and LAI in tundra vegetation. © 2005 Taylor & Francis Group Ltd.",Entailment
i_1814,Entailment,"6. ** Interannual Variability: ** Ecological interactions and mutualistic networks among plants and pollinators show significant interannual variability. Most interactions are observed in only one year, suggesting that species abundances and interaction frequencies are entirely unpredictable and do not follow any discernible patterns annually .","Ecological interactions are highly dynamic in time and space. Previous studies of plant–animal mutualistic networks have shown that the occurrence of interactions varies substantially across years. We analyzed interannual variation of a quantitative mutualistic network, in which links are weighted by interaction frequency. The network was sampled over six consecutive years, representing one of the longest time series for a community-wide mutualistic network. We estimated the interannual similarity in interactions and assessed the determinants of their persistence. The occurrence of interactions varied greatly among years, with most interactions seen in only one year (64%) and few (20%) in more than two years. This variation was associated with the frequency and position of interactions relative to the network core, so that the network consisted of a persistent core of frequent interactions and many peripheral, infrequent interactions. Null model analyses suggest that species abundances play a substantial role in generating these patterns. Our study represents an important step in the study of ecological networks, furthering our mechanistic understanding of the ecological processes driving the temporal persistence of interactions.",Entailment
s_1579,Unverifiable,"3. Technological Innovations: Advances in digital technology have complicated market transparency and logistics, likely increasing costs and decreasing efficiency in the food supply chain .","Modern society provides high market transparency, due to significant digital technology evolution, which shrinks long logistical chains and should result, in the future, in direct interaction between two opposite sides, producers of raw materials and producers of final products. If dealers are omitted in the market exchange, it is possible to make cheaper inputs for final product industry, which significantly affects the final product producers competition potential and indirectly it reflects their position improvement. In the agriculture production, related to small private farms with old and uneducated population, implementation of modern digital technology, in the form of computers, is problematic. Such farms, which usually produce bread cereals, prevail in the Republic of Croatia and it is unreal to expect of these small farms to use the advantage of the Internet and potentials of e-Market in product exchange. Access to e-Market is easier by using potentials of modern digital mobile telephone technology. It is acceptable for the majority of population because it is easy to learn the handling of a mobile telephone, and mobile telephones are accessible and widespread due to their price. The implementation research results present a model of e-Market, which include communication protocols, exchange processes, and these results are the basis for pragmatic implementation of derivate model.",Related but unverifiable
i_69,Unverifiable,"Ethical and social concerns are largely overstated, with minimal impact on job displacement and governance being effectively managed without significant issues .","As a result of the instability of oil prices, the economic prospects of the Gulf region are increasing their focus on new technologies. Thus, Saudi Arabia has demonstrated a strong commitment towards the development and implementation of Artificial Intelligence (AI) technologies as alternative sources for revenue and growth in line with globalisation, development, and the vision 2030. This paper examines the impact of AI in the Saudi Arabia community, especially for social and economic evolution. Special focus on the use of smart cars and smart cameras to monitor intelligently traffic, public services and national security is explored. A total of 424 participants from Eastern Province took part in this study. Analysis and discussion of the obtained results are also presented. The findings showed that 75.71% of participants mostly highly agreed about the AI economic impact leading to an increase in both government and business financial incomes. Whereas only 59.84% of participants mostly highly agreed about the social impact of AI as they are worried about AI ethical concerns, job loss and the changing workforce.
[7]: We are all aware of the huge potential for artificial intelligence (AI) to bring massive benefits to under-served populations, advancing equal access to public services such as health, education, social assistance, or public transportation, for example. We are equally aware that AI can drive inequality, concentrating wealth, resources, and decision-making power in the hands of a few countries, companies, or citizens. Artificial intelligence for equity (AI4Eq) [1] as presented in this magazine, calls upon academics, AI developers, civil society, and government policy-makers to work collaboratively toward a technological transformation that increases the benefits to society, reduces inequality, and aims to leave no one behind. A call for equity rests on the human rights principle of equality and nondiscrimination. AI design, development, and deployment (AI-DDD) can and should be harnessed to reduce inequality and increase the share of the world's population that is able to live in dignity and fully realize their human potential. This commentary argues, first, that far preferable to an ethics framework, adopting a human rights framework for AI-DDD offers the potential for a robust and enforceable set of guidelines for the pursuit of AI4Eq. Second, the commentary introduces the work of IEEE in proposing practical recommendations for AI4Eq, so that people living in high-income countries (HICs), low- and middle-income countries (LMICs), alike, share AI applications' widespread benefit to humanity.",Related but unverifiable
s_320,Contradiction,"Effects on Careers in Software Engineering: Job Transformation: AI is transforming the nature of jobs in software engineering by automating routine tasks, which allows engineers to focus on more complex and creative aspects of their work .","As an example of exploiting the synergy between AI and software engineering, the field of intelligent software engineering has emerged with various advances in recent years. Such field broadly addresses issues on intelligent [software engineering] and [intelligence software] engineering. The former, intelligent [software engineering], focuses on instilling intelligence in approaches developed to address various software engineering tasks to accomplish high effectiveness and efficiency. The latter, [intelligence software] engineering, focuses on addressing various software engineering tasks for intelligence software, e.g., AI software. In this paper, we discuss recent research and future directions in the field of intelligent software engineering.",Misrepresentation
i_757,Unverifiable,"Key Trends and Developments: Sustainable and Green Manufacturing: There is a growing emphasis on sustainable manufacturing practices, including the use of biodegradable materials and energy-efficient processes. This trend is particularly evident in sectors like food processing and packaging, where advanced automation and control systems are being implemented to enhance productivity and safety .","[13] The University of Sheffield's Advanced Manufacturing Research Center (AMRC) wants to develop and improve British manufacturing so that UK manufacturing remains globally competitive by developing technology to address specific industry problems. The AMRC was set up as a partnership between Boeing and the University to bring together academia and industry expertise and innovation on one site. It operates in Rolls Royce Factory of Future Composite Materials Research Center and Rolls-Royce and BAE are using university facilities to cut costs and risks of developing new processes without having to lay out millions of pounds on capital and divert expertise from their main project. The team is looking at variety of technologies to reduce offcut waste, from metal injection and minimizing or even eliminating the need for machining altogether. The center has already done work with Formula One team and hopes to be able to reduce risk for the automotive industry in future. [15] This book is a study on the developments of a strategic plan to guide Federal programs and activities in support of advanced manufacturing research and development. Advanced manufacturing is a matter of fundamental importance to the economic strength and national security of the United States. Analysis of patterns and trends in U.S. advanced manufacturing reveals both opportunities for Federal policy to accelerate the development of this vital sector and challenges to its continuing health. The acceleration of innovation for advanced manufacturing requires bridging a number of gaps in the present U.S. innovation system, particularly the gap between research and development (R and D) activities and the deployment of technological innovations in domestic production of goods. The strategic plan discussed in this book lays out a robust innovation policy that would help to close these gaps and address the full lifecycle of technology. © 2013 by Nova Science Publishers, Inc. All rights reserved. [19] Many of the same manufacturing/fabrication technologies that were employed for light water reactors (LWR) plants built 30-50 years ago are also being employed today to build advanced light water reactors (ALWRs). Manufacturing technologies have not changed dramatically for the nuclear industry even though higher quality production processes are available which could be used to significantly reduce overall component manufacturing/fabrication costs. New manufacturing/ fabrication technologies that can accelerate production and reduce costs are vital for the next generation of plants (Small Modular Reactors (SMR) and GEN IV plants) to assure they can be competitive in today's and tomorrow's market. This project has been assembled to demonstrate and test several of these new manufacturing/ fabrication technologies with a goal of producing critical assemblies of a 2/3rds scale SMR reactor pressure vessel (RPV). Through use of technologies including: powder metallurgy-hot isostatic pressing, (PM-HIP), electron beam welding, diode laser cladding, bulk additive manufacturing, advanced machining, and elimination of dissimilar metal welds (DMWs), EPRI, the US Department of Energy, and the UK-based Nuclear-Advanced Manufacturing Research Centre (Nuclear-AMRC) (together with a number of other industrial team members) will seek to demonstrate the hypothesis that critical sections of an SMR reactor can be manufactured/fabricated in a timeframe of less than 12 months and at an overall cost savings of >40% (versus today's technologies). Major components that will be fabricated from PM-HIP include: The lower reactor head, upper reactor head, steam plenum, steam plenum access ports and covers, and upper transition shell. The project aims to demonstrate and test the impact that each of these technologies would have on future production of SMRs, and explore the relevance of the technologies to the production of ALWRs, SMRs, GEN IV, Ultra-supercritical fossil, and supercritical CO2 plants. The project, if successful, may accelerate deployment of SMRs in both the USA and UK, and ultimately throughout the world for power production.",Related but unverifiable
i_1548,Unverifiable,"The accumulation of plastic waste, including microplastics, has been observed in aquatic ecosystems, highlighting the need for stringent waste management policies to protect environmental and human health, and it is likely that the presence of microplastics may also affect the reproductive health of aquatic organisms in the long term .","The widespread use of plastic has resulted in the accumulation of plastic waste across a range of sizes, notably including microplastics (MPs). The introduction of MPs into aquatic ecosystems can lead to the contamination of organisms, mainly fish. This study reports for the first time a quantitative and qualitative analysis conducted on the abundance of MPs encountered in water and sediment of milkfish aquaculture ponds in Gresik, East Java, Indonesia. Water and sediment samples were collected at three stations between February to April 2021. The abundance of MPs was analyzed through the application of one-way ANOVA tests and Pearson's correlation analysis. The results identified four types of MPs: fragments, fibers, films, and pellets. The highest abundance of MPs in both water (10.40 particle/L) and sediment samples (1.15 particle/g) was observed in March. The predominant MPs size in the water samples is 100–500 μm, while it is below 100 μm in the sediment. The color of the MPs varied across eight colors: black, purple, red, blue, yellow, pink, green, and transparent. The identification of MPs polymers was found to be polypropylene (PP), Polyurethane (PU), Polycarbonate (PC), Polyethylene terephthalate (PETE), High-density polyethylene (HDPE), and low-density polyethylene (LDPE). The presence of MPs in the water column and sediments was correlated with human activities around the ponds. Hence, the abundance of MPs is a source of pollution that has the potential to damage the nutritional quality of farmed milkfish. This study provides important information for the local governments to develop waste management policies for a cleaner environment and improved human health.",Related but unverifiable
i_1996,Unverifiable,"General Methods for Axenic Cultures: Specific Antibiotics: Cefotaxime sodium (CTX), amoxicillin (AM), tetracycline (TC), and erythromycin (EM) have been tested for their effects on co-cultured microorganisms, with CTX and EM showing significant inhibitory effects on certain bacteria . These antibiotics might be considered for sustaining axenic cultures of Chestoceros calcitrans.","In order to suppress the growth of Chroococcus turgidus and finally eliminate it during the amplification process of filaments of Scytosiphon lomentaria, the effects of four antibiotics: cefotaxime sodium (CTX), amoxicillin (AM), tetracycline (TC) and erythromycin (EM) on the growth of filaments of S. lomentaria and C. turgidus, which were co-cultured in the research, were studied by experimental ecology methods in this paper. Results indicated that CTX can inhibit the growth of C. turgidus significantly at the concentration of 50 and 100 mg/L. On the 20<sup>th</sup> day, their average daily growth rates were 3.84% and –0.96%, respectively, which were significantly lower than 19.21% in the control group without antibiotics, therefore ensuring the normal growth and development of filaments of S. lomentaria. Both C. turgidus and the filaments of S. lomentaria were not suppressed by AM at the concentrations between 50 and 1 000 mg/L, so AM can not eliminate C. turgidus in the co-culture system. TC could inhibit the growth of C. turgidus and the filaments of S. lomentaria dramatically at the concentration of 100 and 200 mg/L, but the cytoplasm of filaments of S. lomentaria presented atrophy. EM inhibited the growth of C. turgidus significantly at the concentrations between 0.10 mg/L and 1.00 mg/L, when the concentration was higher than 0.50 mg/L, the growth of filaments of S. lomentaria also were inhibited, even to death.",Related but unverifiable
s_1055,Entailment,"1.  -    BMSC-EXOs have shown potential in reducing neuronal cell death, improving myelin arrangement, and enhancing blood-spinal cord barrier integrity. They achieve this by inhibiting inflammatory responses and promoting cell survival pathways .","Mesenchymal stem cell (MSC) transplantation is a promising treatment strategy for spinal cord injury, but immunological rejection and possible tumor formation limit its application. The therapeutic effects of MSCs mainly depend on their release of soluble paracrine factors. Exosomes are essential for the secretion of these paracrine effectors. Bone marrow mesenchymal stem cell-derived exosomes (BMSC-EXOs) can be substituted for BMSCs in cell transplantation. However, the underlying mechanisms remain unclear. In this study, a rat model of T10 spinal cord injury was established using the impact method. Then, 30 minutes and 1 day after spinal cord injury, the rats were administered 200 μL exosomes via the tail vein (200 μg/mL; approximately 1 × 10<sup>6</sup>BMSCs). Treatment with BMSC-EXOs greatly reduced neuronal cell death, improved myelin arrangement and reduced myelin loss, increased pericyte/endothelial cell coverage on the vascular wall, decreased blood-spinal cord barrier leakage, reduced caspase 1 expression, inhibited interleukin-1β release, and accelerated locomotor functional recovery in rats with spinal cord injury. In the cell culture experiment, pericytes were treated with interferon-γ and tumor necrosis factor-α. Then, Lipofectamine 3000 was used to deliver lipopolysaccharide into the cells, and the cells were co-incubated with adenosine triphosphate to simulate injury in vitro. Pre-treatment with BMSC-EXOs for 8 hours greatly reduced pericyte pyroptosis and increased pericyte survival rate. These findings suggest that BMSC-EXOs may protect pericytes by inhibiting pyroptosis and by improving blood-spinal cord barrier integrity, thereby promoting the survival of neurons and the extension of nerve fibers, and ultimately improving motor function in rats with spinal cord injury. All protocols were conducted with the approval of the Animal Ethics Committee of Zhengzhou University on March 16, 2019.",Entailment
s_1520,Entailment,"Solid-State Fermentation: This method involves the use of solid substrates like wheat bran, which are moistened with mineral salt solutions. This approach is cost-effective and supports high enzyme activity, which is crucial for mycoprotein production .","Trichoderma sp. is a potential cellulase producing mesophilic fungi which grow under mild acidic condition. In this study, growth and nutritional conditions were manipulated for the maximum and cost-effective production of cellulase using lab strain Trichoderma sp. RCK65 and checked for its efficiency in hydrolysis of Prosopis juliflora (a woody substrate). Preliminary studies suggested that when 48 h old secondary fungal culture (20 % v/w) was inoculated in wheat bran moistened with mineral salt solution (pH 4.5 and 1:3 solid to moisture ratio), incubated at 30 °C and after 72 h, it produced maximum cellulase (CMCase 145 U/gds, FPase 38 U/gds and β-glucosidase 105 U/gds). However, using statistical approach a S:L ratio (1:1) was surprisingly found to be optimum that improved cellulase that is CMCase activity by 6.21 %, FPase activity by 23.68 % and β-glucosidase activity by 37.28 %. The estimated cost of crude enzyme (Rs. 5.311/1000 FPase units) seems to be economically feasible which may be due to high enzyme titre, less cultivation time and low media cost. Moreover, when the crude enzyme was used to saccharify pretreated Prosopis juliflora (a woody substrate), it resulted up to 83 % (w/w) saccharification.",Entailment
s_91,Contradiction,"Furthermore, AI-driven frameworks for urban land use mapping, utilizing crowdsourcing features and ensemble learning, demonstrate the potential for accurate and detailed land use classification, which can be applied to rural cadastral land as well .","Detailed information on urban land uses has been an essential requirement for urban land management and policymaking. Recent advances in remote sensing and machine learning technologies have contributed to the mapping and monitoring of multi-scale urban land uses, yet there lacks a holistic mapping framework that is compatible with different end users' demands. Moreover, land use mix has evolved to be a key component in modern urban settings, but few have explicitly measured the spatial complexity of land use or quantitively uncovered its driving forces. Addressing these challenges, here we developed a novel two-stage bottom-up scheme for mapping essential urban land use categories. In the first stage, we conducted object-based land use classification using crowdsourcing features derived from multi-source open big data and an automated ensemble learning approach. In the second stage, we identified parcel-based land use attributes, including the dominant type and mixture mode, by spatially correlating land parcels with the object-based results. Furthermore, we investigated the potential influencing factors of land use mix using principal components analysis and multiple linear regression. Experimental results in Ningbo, a coastal city in China, showed that the proposed framework could accurately depict the distribution and composition of urban land uses. At the object scale, the highest classification accuracy was as high as 86% and 78% for the major (Level I) and minor (Level II) categories, respectively. At the parcel scale, the generated land use maps were spatially consistent with the object-based maps. We found larger parcels were more likely to be mixed in land use, and industrial lands were characterized as the most complicated category. We also identified multiple factors that had a collective impact on land use mix, including geography, socioeconomy, accessibility, and landscape metrics. Altogether, our proposed framework offered an alternative to investigating urban land use composition, which could be applied in a broad range of implications in future urban studies.",Misrepresentation
i_2186,Entailment,"Immune System Modulation: Symbionts can influence the host's immune system, enhancing its ability to fight off pathogens .","Most animals maintain mutually beneficial symbiotic relationships with their intestinal microbiota. Resident microbes in the gastrointestinal tract breakdown indigestible food, provide essential nutrients, and, act as a barrier against invading microbes, such as the enteric pathogen Vibrio cholerae. Over the last decades, our knowledge of V. cholerae pathogenesis, colonization, and transmission has increased tremendously. A number of animal models have been used to study how V. cholerae interacts with host-derived resources to support gastrointestinal colonization. Here, we review studies on host-microbe interactions and how infection with V. cholerae disrupts these interactions, with a focus on contributions from the Drosophila melanogaster model. We will discuss studies that highlight the connections between symbiont, host, and V. cholerae metabolism; crosstalk between V. cholerae and host microbes; and the impact of the host immune system on the lethality of V. cholerae infection. These studies suggest that V. cholerae modulates host immune-metabolic responses in the fly and improves Vibrio fitness through competition with intestinal microbes.",Entailment
i_1622,Entailment,"Theories Applied: Upper Echelons Theory: This theory suggests that the characteristics of top executives, including gender, influence organizational outcomes, including environmental strategies, and it is plausible that organizations with a higher proportion of female executives may also exhibit greater innovation in sustainable practices beyond just environmental strategies .","Based on the upper echelons theory, ecofeminist theory, and natural resource-based theory (NRBV), this study has constructed a relational model between female executives' participation, unethical environmental behavior, proactive environmental strategy, and corporate sustainable competitive advantage. The samples include a total of 496 female executives from listed 524 companies in the manufacturing sector in China, and multiple regression methods are used for the analysis. The study showed that female executives' participation had double positive effects on corporate sustainable competitive advantage, which included both the inhibiting effect on unethical environmental behavior and the stimulating effect on proactive environmental strategies. The study also explored the boundary conditions of ""conservative"" and ""proactive"" behaviors from the internal and external perspectives of enterprises. But it was shown that the effect would not be further improved when both moderation effects of environmental stakeholder pressure and environmental leadership were higher at the same time. As enterprises' behaviors should match with their capability range, radical behaviors might run counter to their desires.",Entailment
i_2223,Unverifiable,"Challenges and Considerations: Secondary Pollution: While managing the biomass enriched with heavy metals is important, it is often assumed that any strategy for disposal will effectively prevent secondary pollution, which may not always be the case. Therefore, the effectiveness of these strategies in ensuring environmental safety is questionable .","The successful phytoextraction of potentially toxic elements (PTEs) from polluted soils can be achieved by growing non-food and industrial crops. Tobacco (Nicotiana tabacum L.) is one of the main industrial crops and is widely grown in many countries. Tobacco can uptake high concentrations of PTEs especially in aboveground biomass without suffering from toxicity. This review highlighted the potential of tobacco for the phytoextraction of heavy metals and tolerance mechanisms under metal stress. Different management practices have been discussed which can enhance the potential of this plant for metal extraction. Finally, suitable options for the management/disposal of biomass enriched in excess metal have been elaborated to prevent secondary pollution.",Related but unverifiable
s_2112,Entailment,Natural Filtration Methods: Biological Filtration (Biofiltration): Description: Involves managing biological activity on granular media to enhance the removal of organic and inorganic constituents. Process: Biofilters reduce natural organic matter (NOM) and other pollutants through biological activity. This method is widely used and has been successful across various water qualities and conditions .,"[2] Bank filtration is a relative low cost system for raw water treatment or pre-treatment for drinking water abstraction, used in European countries since about 140 years with very good experiences, but up to now knowledge of the physical, chemical and biological processes of water purification is still insufficient, especially under consideration of the application of this technology in other countries. Focus of interest are the mechanical, physicochemical, chemical and biological processes during infiltration pathway such as the retention of particulate organic material (POM), especially of algae cells with toxic cell compounds (cyanobacteria), the turnover of natural organic matter (NOM), bacteria and viruses, and the retention of toxicology relevant micro pollutants like cyanotoxins and drugs. The water infiltration during bank filtration is not only controlled hydraulically but determined by severe clogging processes mainly triggered by accumulation of biological components in the upper sediment layer. Clogging of the interstice is regularly observed in infiltration ponds, and up to now several mechanisms can be distinguished like physical (input of fine sediments, building of gas bubbles), chemical (precipitation mainly of carbonates) and biological processes (excretion of extracellular substances by algae and bacteria). As a consequence water permeability of the interstice will become strictly reduced. The interstice are place of an adapted biocoenosis of bacteria, fungi, algae and meiofauna, which is characterized by the occurrence of extra-cellular polymeric substances (EPS). The meiofauna counteracts the clogging process by detritivorous activity. For many contaminants like DOM, POM, pathogens (Giardia, Cryptosporidium) and cyanobacteria as well as cyanotoxins a good removal is given. The active sediment layer is the first meter of infiltration pathway with a decrease in DOC concentration of up to 50% and high removal rates of 10<sup>2</sup> - 10<sup>4</sup> for pathogens like bacteria and protozoa. [7] Land application of dairy soiled water (DSW) is expensive relative to its nutrient replacement value. The use of aerobic filters is an effective alternative method of treatment and potentially allows the final effluent to be reused on the farm. Knowledge gaps exist concerning the optimal design and operation of filters for the treatment of DSW. To address this, 18 laboratory-scale filters, with depths of either 0.6 m or 1 m, were intermittently loaded with DSW over periods of up to 220 days to evaluate the impacts of depth (0.6 m versus 1 m), organic loading rates (OLRs) (50 versus 155 g COD m<sup>−2</sup> d<sup>−1</sup>), and media type (woodchip versus sand) on organic, nutrient and suspended solids (SS) removals. The study found that media depth was important in contaminant removal in woodchip filters. Reductions of 78% chemical oxygen demand (COD), 95% SS, 85% total nitrogen (TN), 82% ammonium-nitrogen (NH<inf>4</inf>[Formula presented]), 50% total phosphorus (TP), and 54% dissolved reactive phosphorus (DRP) were measured in 1 m deep woodchip filters, which was greater than the reductions in 0.6 m deep woodchip filters. Woodchip filters also performed optimally when loaded at a high OLR (155 g COD m<sup>−2</sup> d<sup>−1</sup>), although the removal mechanism was primarily physical (i.e. straining) as opposed to biological. When operated at the same OLR and when of the same depth, the sand filters had better COD removals (96%) than woodchip (74%), but there was no significant difference between them in the removal of SS and NH<inf>4</inf>[Formula presented]. However, the likelihood of clogging makes sand filters less desirable than woodchip filters. Using the optimal designs of both configurations, the filter area required per cow for a woodchip filter is more than four times less than for a sand filter. Therefore, this study found that woodchip filters are more economically and environmentally effective in the treatment of DSW than sand filters, and optimal performance may be achieved using woodchip filters with a depth of at least 1 m, operated at an OLR of 155 g COD m<sup>−2</sup> d<sup>−1</sup>.",Entailment
i_714,Unverifiable,"Optimization Methods: Topology Optimization: Topology optimization of truss-like cellular structures aims to enhance vibration isolation properties by optimizing the geometrical and mechanical properties of each truss element. This method effectively handles issues like mode switching and repeated eigenvalues, ensuring robust vibration isolation .","[10] A new method of simultaneous optimization of geometry and topology is presented for plane and spatial trusses. Compliance under single loading condition is minimized for specified structural volume. The difficulties due to existence of melting nodes are successfully avoided by considering force density, which is the ratio of axial force to the member length, as design variable. By using the fact that the optimal truss is statically determinate with the same absolute value of stress in existing members, the compliance and structural volume are expressed as explicit functions of force density only. After obtaining optimal cross-sectional area, nodal locations, and topology, the cross-sectional areas and nodal coordinates are further optimized using a conventional method of nonlinear programming. Accuracy of the optimal solution is verified through examples of plane trusses and a spatial truss. It is shown that various nearly optimal solutions can be found using the proposed method.",Related but unverifiable
i_1554,Contradiction,"Implementation Challenges: The United States faces challenges in coordinating the establishment of a CO2 transport network, which is essential for the wide implementation of CCS. This requires significant public planning and regulation .","Carbon dioxide capture and storage (CCS) has recently been receiving increasing recognition in policy debates. Various aspects of possible regulatory frameworks for its implementation are beginning to be discussed in Europe. One of the issues associated with the wide use of CCS is that it requires the establishment of a carbon dioxide (CO <inf>2</inf>) transport network, which could result in the spatial restructuring of power generation and transmission systems. This poses a significant coordination problem necessitating public planning and regulation. This paper provides a survey over multiple research strands on CCS, particularly energy system modeling and spatial optimization, pertaining to the efficient installment of CCS-related infrastructure throughout Europe. It integrates existing findings and highlights the factors that determine policy coordination needs for a potential wide implementation of CCS in the next decades. © 2012 Springer Science+Business Media B.V.",Entity error
i_196,Contradiction,"Key Challenges: Open Standards and Interoperability: The absence of open standards and interoperability between various smart city systems is likely to completely prevent any integration of services, thereby making them inaccessible to most citizens .","The holy grail of smart cities is an integrated, sustainable approach to improve the efficiency of the city's operations and the quality of life of citizens. At the heart of this vision is the citizen, who is the primary beneficiary of smart city initiatives, either directly or indirectly. Despite the recent surge of research and smart cities initiatives in practice, there are still a number of challenges to overcome in realizing this vision. This position paper points out six citizen-related challenges: the engagement of citizens, the improvement of citizens' data literacy, the pairing of quantitative and qualitative data, the need for open standards, the development of personal services, and the development of persuasive interfaces. The article furthermore advocates the use of methods and techniques from GIScience to tackle these challenges, and presents the concept of an Open City Toolkit as a way of transferring insights and solutions from GIScience to smart cities.",Misrepresentation
s_1052,Contradiction,"- **CA-125 and ALDH**: Investigated for their prognostic roles in ovarian cancer, but no significant correlation was found .","The prognostic/predictive role of both CD133 and Aldehyde dehydrogenase (ALDH) expression in human ovarian cancer remains elusive. This is an observational study that investigated the expression of CD133 and of ALDH enzymatic activity in fresh ovarian cancer samples and their association with different clinic-pathological patient' characteristics and explored their possible predictive/prognostic role. We analyzed the expression of CD133 and ALDH enzymatic activity in 108human ovarian cancer samples. We found that among the total patients analyzed,13% of them was completely negative for ALDH activity and 26% was negative for CD133 staining. Both markers were variably expressed within the samples and when both studied in the same tumor sample, no statistically significant correlation between ALDH enzymatic activity and CD133 expression was found. No statistical significant correlation was found also between the percentage values of positive ALDH and CD133 cells and the number of serial passages patient's cultures underwent, suggesting that these markers do not confer by themselves a selfrenewal growth advantage to the cultures. Lower levels of CD133 were associated with higher tumor grade. No correlation with response to therapy, progression free survival and overall survival was found. Our data suggest that neither ALDH enzymatic activity nor CD133 expression provide additional predictive/prognostic information in ovarian cancer patients.",Entity error
s_1590,Entailment,"Economic Sustainability: Local Food Production: Promoting local food production supports economic sustainability by maintaining farm work and leveraging local traditions and identities, which can be beneficial for marketing and regional development. Additionally, it is believed that local food production can enhance community cohesion and social capital, fostering a stronger sense of belonging among residents .","The purpose of this article is to discuss what the cultural basis of local food production and sustainable development could signify from the rural development viewpoint. The concept of cultural sustainability has so far been rather unclear in the scientific field and the article aims to outline it in the rural context. The article is based on the research data where fifteen local food producers and fifteen rural developers were interviewed in Central Finland. According to this article, local food production is one way to maintain work at farms and for this reason cultural sustainability is related to traditions, continuity and identity from the local food producers' viewpoint. For rural developers local culture seems to be a resource that can be exploited, for instance in marketing local food products. In the end, cultural sustainability in local food production can be considered a good interaction system between different local stakeholders. Thus, the success of small-scale local food entrepreneurs depends on regional learning and how the local actors produce, transfer and utilize knowledge, including tacit knowledge.",Entailment
i_1400,Entailment,"Comparative Data: Key Points: Regional Variations: There is significant geographical heterogeneity in the incidence rates of childhood brain tumors across Europe, influenced by factors such as diagnostic practices and healthcare infrastructure .","Data on more than 50,000 registrations in the Automated Childhood Cancer Information System (ACCIS) database were used to present an overview of regional patterns in childhood cancer incidence in Europe during 1988-1997, and to present additional detail on selected carcinomas whose occurrence in childhood is seldom described because of their rarity. Total age-standardised incidence was 138.5 per million for Europe overall, and varied between regions from 131.1 per million in the British Isles to 160.1 per million in Northern Europe. Incidence varied significantly between regions for nearly all diagnostic groups. The greatest range of regional incidence rates was for central nervous system (CNS) tumours, from 27.0 per million in the West to 43.8 per million in the North. Differences in registration practice for non-malignant tumours account for some of this variation. There was a marked excess of carcinoma in Eastern Europe, which was wholly attributable to the high incidence of thyroid carcinoma in Belarus, though there was also evidence of inter-regional variation attributable to differences in registration practice. The geographical heterogeneity of incidence rates for other diagnostic groups seems more likely to reflect variations in underlying risk. © 2006 Elsevier Ltd. All rights reserved.
[2]: Introduction: Childhood brain tumours (CBTs) are the second most common type of cancer in individuals aged 0–24 years globally and cause significant morbidity and mortality. CBT aetiology remains poorly understood, however previous studies found higher CBT incidence in high-income countries (HIC) compared to low-middle income countries (LMIC), suggesting a positive relationship between incidence and wealth. Materials & methods: Aggregated data from Cancer Incidence in Five Continents (CI5) were used to explore CBT epidemiology. Incidence rate ratios (IRR) compared CBT rates between twenty-five geographically and economically diverse countries. The relationship between incidence and economic development was explored using linear regression models and Spearman's rank correlation tests. Trends in CBT incidence between 1978 and 2012 were investigated using average annual percentage changes (AAPC). Results: CBT incidence was highest in North America and lowest in Africa. CBT incidence rates increased significantly with increasing GDP per capita (p = 0.006). Gini index was significantly negatively associated with CBT incidence. Incidence decreased with increasing income inequality within countries, indicated by higher Gini indices (p = 0.040). Increasing and decreasing CBT incidence trends were observed within individual countries, although only Italy (p = 0.02) and New Zealand (p < 0.005) experienced statistically significant changes over time. Conclusions: The excess disease found in HIC may be explained by environmental risk factor exposure increasing CBT risk in wealthy populations. However, systematic limitations of substandard cancer detection and reporting in LMIC may mean incidence disparities result from misinformation bias rather than genuine differences in risk factor exposure. Further research is required to comprehensively describe CBT epidemiology and explain study findings.",Entailment
s_810,Unverifiable,Sustainability: Maintaining performance despite adverse conditions .,"The term resilience is used differently by different communities. In general engineering systems, fast recovery from a degraded system state is often termed as resilience. Computer networking community defines it as the combination of trustworthiness (dependability, security, performability) and tolerance (survivability, disruption tolerance, and traffic tolerance). Dependable computing community defined resilience as the persistence of service delivery that can justifiably be trusted, when facing changes. In this paper, resilience definitions of systems and networks will be presented. Metrics for resilience will be compared with dependability metrics such as availability, performance, performability. Simple examples will be used to show quantification of resilience via probabilistic analytic models. Copyright 2009 ACM.",Unrelated and unverifiable
i_1654,Entailment,"** Control Measures: ** Wastewater Treatment Improvements: While proper treatment of wastewater is often cited as important for controlling antibiotic-resistant bacteria (ARB) and ARGs, it is clear that even well-managed systems can still harbor resistant strains, suggesting that treatment alone may not be sufficient to eliminate these threats in water sources .","The antibiotic resistance profiles of Escherichia coli (E. coli), isolated from different water sources in the Mmabatho locality were evaluated. Water samples were collected from the local wastewater- and water-treatment plants, the Modimola Dam and homes in the area, and then analysed for the presence of E. coli, using standard methods. Presumptive isolates obtained were confirmed by the analytical profile index test. Antibiotic susceptibility testing was performed by the disc diffusion method. Of the 230 E. coli isolates tested, marked antibiotic resistances (over 70%) were observed for erythromycin, tetracycline, ampicillin, chloramphenicol and norfloxacin. Multiple antibiotic resistance patterns were also compiled. Overall, the phenotype T-Ap-E was frequent for E. coli isolated from the local wastewater and water-treatment plants, Modimola Dam and tap water. Cluster analysis performed showed a unique antibiotic resistance pattern which suggested a link between isolates from all sampling points. The findings indicated that improper wastewater treatment may have a potential impact on the dissemination and survival of E. coli, as well as other pathogenic bacteria in water for human and animal consumption. This may result in water- and food-borne disease outbreaks with a negative effect on antibiotic therapy. © 2010. The Authors.
[8]: In order to investigate the influence of a duckweed aquaculture based hospital sewage water recycling plant on the prevalence and dissemination of antibiotic resistance, we made use of an existing collection of 1,315 Aeromonas isolates that were previously typed by the biochemical fingerprinting PhP-AE system. In these treatment plant, hospital raw sewage water is first collected in a settlement pond (referred to as sewage water in this study) and is then transferred to a lagoon, where the duckweed (Lemnaceae) is grown (referred to as lagoon). The duckweed is harvested and used as feed for the fish in a separate pond (referred to as fish pond). From this collection, representatives of 288 PhP types were subjected to antibiotic susceptibility testing for eight antimicrobials by broth microdilution method. The overall resistance rates among Aeromonas isolates from the treatment plant were highest for ampicillin (87%) and erythromycin (79%) followed by cephalothin (58%), nalidixic acid (52%), streptomycin (51%), tetracycline (31%), chloramphenicol (13%) and gentamicin (8%). A significantly lower prevalence of antibiotic resistance was found in Aeromonas from environmental control water, patient stool samples, duckweed and fish compared to sewage water isolates. The prevalence of resistance in the sewage water was not significantly reduced compared to the lagoon water and fish pond. Throughout the treatment system, the frequencies of resistant strains were found to diminish during the sewage water purification process, i.e. in the lagoon where sewage water is used to grow the duckweed. However, the frequency of resistant strains again increased in the fish pond where sewage grown duckweed is used for aquaculture. Among the selected isolates, two multiresistant clonal groups of Aeromonas caviae HG4 were identified that exhibited indistinguishable PhP and amplified fragment length polymorphism fingerprints and shared a common plasmid of approximately 5 kb. Representatives of both groups were recovered from almost every part of the sewage treatment plant but not in the control ponds nor in human samples, which suggests that specific multiresistant Aeromonas clones are able to persist and spread throughout the entire purification process. © Springer Science+Business Media B.V. 2009.",Entailment
s_2057,Contradiction,"- **Water Balance and Ecohydrology**: Afforestation does not significantly alter the water balance in grassland areas. For instance, a study on the Loess Plateau found that afforestation with black locust trees did not lead to the understory being the main water consumer, which is similar to natural grasslands where annual seepage remained consistent . This suggests that afforestation can maintain or even enhance water availability in grasslands, potentially benefiting the native vegetation and water-dependent species.","The world's largest afforestation programs implemented by China made a great contribution to the global ""greening up."" These programs have received worldwide attention due to its contribution toward achieving the United Nations Sustainable Development Goals. However, emerging studies have suggested that these campaigns, when not properly implemented, resulted in unintended ecological and water security concerns at the regional scale. While mounting evidence shows that afforestation causes substantial reduction in water yield at the watershed scale, process-based studies on how forest plantations alter the partitioning of rainwater and affect water balance components in natural vegetation are still lacking at the plot scale. This lack of science-based data prevents a comprehensive understanding of forest-related ecosystem services such as soil conservation and water supply under climate change. The present study represents the first ""Paired Plot"" study of the water balance of afforestation on the Loess Plateau. We investigate the effects of forest structure and environmental factors on the full water cycle in a typical multilayer plantation forest composed of black locust, one of the most popular tree species for plantations worldwide. We measure the ecohydrological components of a black locust versus natural grassland on adjacent sites. The startling finding of this study is that, contrary to the general belief, the understory—instead of the overstory—was the main water consumer in this plantation. Moreover, there is a strict physiological regulation of forest transpiration. In contrast to grassland, annual seepage under the forest was minor in years with an average rainfall. We conclude that global long-term greening efforts in drylands require careful ecohydrologic evaluation so that green and blue water trade-offs are properly addressed. This is especially important for reforestation-based watershed land management, that aims at carbon sequestration in mitigating climate change while maintaining regional water security, to be effective on a large scale.",Opposite meaning
s_2196,Contradiction,"Research and Development: Benign by Design (BbD): This concept involves designing chemicals and materials that are inherently non-toxic and fully biodegradable, which implies that all such products will automatically be safe for the environment. Implementing in silico tools early in the design process can help create safer products that meet regulatory requirements and minimize environmental impact, although it is unclear if this will always lead to significant reductions in toxicity or environmental harm .","To avoid adverse side effects of chemicals, pharmaceuticals, and their transformation products (TPs) in the environment, substances should be designed to fully mineralize in the environment at their end-of-life while ensuring a degree of stability as needed for their application. These considerations should be implemented at the very beginning of chemical's and pharmaceutical's design (Benign by Design, BbD) to meet requirements set by planetary boundaries and upcoming legal frameworks (e.g., ""Chemicals Strategy for Sustainability towards a Toxic-Free Environment"" by the European Commission (EC)). In silico tools are already being implemented in the drug discovery process and the assessment of chemicals and pharmaceuticals. The advantage of which is avoiding or at least minimizing animal testing and chemical waste due to experimental testing as well as reducing the time to market. However, in the literature, there are just a few examples of how in silico tools could be implemented in the BbD process. Therefore, this study suggests a workflow supporting practitioners designing new environmentally mineralizing chemicals and pharmaceuticals. This would also result in a much faster and less expensive process than starting with repetitive synthesis and subsequent experimental testing to improve the compounds' properties.",Misrepresentation
i_1757,Contradiction,"Ecological Fiscal Transfers: These are financial transfers from higher levels of government to local governments based on ecological indicators, including biodiversity conservation efforts. This aims to provide financial support for local conservation initiatives .","This article discusses financial mechanisms for the conservation of biodiversity and ecosystem services in Brazil. Five mechanisms were selected for in-depth analysis using the Biofin methodological approach: ecological fiscal transfer, environmental reserve quotas, payments for environmental services, tourism concessions, and forest concessions. They can reduce the current financial gap for biodiversity conservation in the country. Ecological fiscal transfer, payments for environmental services, tourism, and forest concessions can generate approximately US$ 1 billion annually. The potential to generate revenues in environmental reserve quotas markets is big, but uncertainty is also very high, with estimates from US$ 1 to US$ 20 billion up to 2030. Most of these mechanisms aim to involve the private sector in conserving biodiversity and require an active role for the public sector, either through fiscal or regulatory instruments. There is a need to adapt the financial mechanism to the political and institutional context. In Brazil, weak public management capacity, institutional uncertainties, and political opposition to environmental policy are the main challenges for large-scale implementation of these instruments.",Entity error
s_1547,Entailment,"Comparison with Probiotics: Viability: Unlike probiotics, paraprobiotics do not require the microorganisms to be alive to confer benefits, which can be advantageous in terms of stability and storage .","The present study evaluated the growth performance, non-specific immunity and disease resistance in Penaeus vannamei fed diets supplemented with live or dead cells of Clostridium butyricum CBG01 (live cells, CB; sonication-killed cell-free extracts, UI; heat-killed whole-cell, HI; fermentation supernatant, FS; the control, the basal diet without C. butyricum, DZ) for 42 days. Results indicated that the final weight, specific growth rate, survival rate and feed efficiency rate of shrimp in the treatment groups were significantly improved versus the control (P < 0.05). The challenge test of Vibrio parahaemolyticus showed that the cumulative mortalities of shrimp in the CB and UI groups were significantly lower than that in the control (P < 0.05). Compared with the control, alkaline phosphatase, acid phosphatase, total nitric oxide synthase, lysozyme, peroxidase, superoxide dismutase activities, total antioxidant capacity, and phenonoloxidase content in the serum and the relative expression levels of SOD, LZM, proPO, LGBP, HSP70, Imd, Toll, Relish, TOR, 4E-BP, eIF4E1α, eIF4E2 genes in the hepatopancreas of CB and HI shrimp groups were all significantly enhanced, and those were significantly improved in the UI group as well, except for phenonoloxidase content, relative expression levels of SOD, Imd and eIF4E2 genes (P < 0.05). However, immune responses were induced partially in the FS shrimp group. These results suggested that dietary both live and dead cells of C. butyricum CBG01 could improve the growth performance and immune responses of shrimp. When resistance against Vibrio parahaemolyticus in shrimp is considered, sonication-killed cell-free extracts of C. butyricum showed a better effect than heat-killed whole-cells of probiotic. Considering collectively the above, sonication-killed cell-free extracts of C. butyricum could be applied as a potential paraprobiotic to enhance the growth performance, immunity capacity and disease resistance of P. vannamei.",Entailment
i_2136,Contradiction,"### Key Points on Wheat Resistance to Pathogens 1. **Climate and Environmental Factors**: Climate change, including increased CO₂ levels and altered precipitation patterns, is likely to make all wheat varieties equally susceptible to pathogens like Fusarium species. Elevated CO₂ levels have been conclusively shown to increase Fusarium biomass and mycotoxin production in wheat tissues, regardless of the specific wheat line .","Fusarium head blight (FHB) of wheat, caused mainly by a few members of the Fusarium graminearum species complex (FGSC), is a major threat to agricultural grain production, food safety, and animal health. The severity of disease epidemics and accumulation of associated trichothecene mycotoxins in wheat kernels is strongly driven by meteorological factors. The potential impacts of change in climate are reviewed from the perspective of the FGSC life cycle and host resistance mechanisms influenced by abiotic pressures at the ecological, physiological and molecular level. Alterations in climate patterns and cropping systems may affect the distribution, composition and load of FGSC inoculum, but quantitative information is lacking regarding the differential responses among FGSC members. In general, the coincidence of wet and warm environment during flowering enhances the risk of FHB epidemics, but the magnitude and direction of the change in FHB and mycotoxin risk will be a consequence of a multitude of effects on key processes affecting inoculum dynamics and host susceptibility. Rates of residue decomposition, inoculum production and dispersal may be significantly altered by changes in crop rotations, atmospheric carbon dioxide concentration ([CO<inf>2</inf>]), temperature and precipitation patterns, but the impact may be much greater for regions where inoculum is more limited, such as temperate climates. In regions of non-limiting inoculum, climate change effects will likely be greater on the pathogenic rather than on the saprophytic phase. Although the mechanisms by which abiotic stress influences wheat defences against Fusarium species are unknown, available data would suggest that wheat may be more susceptible to Fusarium infection under future climate conditions. Additional research in this area should be a priority so that breeding efforts and climate resilient management strategies can be developed.
[2]: This study examines the CO<inf>2</inf>-mediated influence of plant resistance on crown rot dynamics under continuous cropping of partially resistant wheat line 249 and the susceptible cultivar Tamaroi. Disease incidence, severity, deoxynivalenol and Fusarium biomass were assessed after each cycle in microcosms established at ambient and 700 mg kg<sup>-1</sup> CO<inf>2</inf> using soil and stubble of these wheat lines from a field experiment with free to air CO<inf>2</inf> enrichment. Monoconidial isolates from wheat stubble were collected initially, and after five cropping cycles, to compare the frequency and aggressiveness of Fusarium species in the two populations. Aggressiveness was measured using a high-throughput seedling bioassay. At elevated CO<inf>2</inf>, the higher initial incidence in Tamaroi increased with cropping cycles, but incidence in 249 remained unchanged. Incidence at ambient CO<inf>2</inf> did not change for either line. Elevated CO<inf>2</inf> induced partial resistance in Tamaroi, but not in 249. Increased Fusarium biomass in wheat tissue at elevated CO<inf>2</inf> matched raised deoxynivalenol of the stem base in both lines. After five cycles of continuous wheat cropping, aggressiveness increased in pathogenic F. culmorum and F. pseudograminearum by 110%, but decreased in weakly pathogenic F. equiseti and F. oxysporum by 50%. CO<inf>2</inf> and host resistance interactively influenced species frequency, and the highly aggressive F. pseudograminearum became dominant on Tamaroi irrespective of CO<inf>2</inf> concentration, while its frequency declined on 249. This study shows that induced resistance at elevated CO<inf>2</inf> will not reduce crown rot severity, or impede the selection and enrichment of Fusarium populations with increased aggressiveness.",Misrepresentation
i_2238,Unverifiable,"Adaptability and Responses to Environmental Changes: Generalists: Adaptability: Generalists can adjust their behavior and resource use to cope with environmental changes, such as urbanization or climate change .","The small variability of habitat generalist abundances in relation to landscape changes has been related to their behavioural flexibility. We hypothesise that successful generalists, such as the starling, compensate for feeding resource difficulties (poor quality of food, accessibility) in habitats such as urban ecosystems and that its behavioural flexibility allows for similar breeding performance in rural and urban areas. Along an urbanisation gradient we compared simultaneously (1) success factors such as the abundance of breeding starlings, their breeding performance and the fitness of nestlings, and (2) possible flexibility quantified through the rate of parental food-provisioning, and the composition and the amount of food delivered to nestlings. Abundance of breeding starlings are similar throughout the urbanisation gradient, but urbanisation profoundly and negatively affects reproductive parameters of starlings. Differences in the amount of food delivered to nestlings by parents (less food in town centre), and the small masses of nestlings reared in the urban sectors support the idea that urban nestlings received insufficient food loads. Despite modifications to their diurnal food-provisioning rhythm and the incorporation of some human food refuse into their diet, starling parents have a significantly reduced production of young in the urban centre sector. We rebut the idea that the ""generalist"" starling is able to breed successfully anywhere: other more ""specialist"" species succeed in producing their young by innovating more in terms of diet resources. We suggest defining successful birds with respect to colonisation or invasion process through behavioural innovation rather than an ambiguous habitat generalist definition. © 2006 Elsevier Masson SAS. All rights reserved.
[6]: Background: The ratio of habitat generalists to specialists in birds has been suggested as a good indicator of ecosystem changes due to e.g. climate change and other anthropogenic perturbations. Most studies focusing on this functional component of biodiversity originate, however, from temperate regions. The Eurasian Arctic tundra is currently experiencing an unprecedented combination of climate change, change in grazing pressure by domestic reindeer and growing human activity. Methodology/Principal Findings: Here we monitored bird communities in a tundra landscape harbouring shrub and open habitats in order to analyse bird habitat relationships and quantify habitat specialization. We used ordination methods to analyse habitat associations and estimated the proportions of specialists in each of the main habitats. Correspondence Analysis identified three main bird communities, inhabiting upland, lowland and dense willow shrubs. We documented a stable structure of communities despite large multiannual variations of bird density (from 90 to 175 pairs/km<sup>2</sup>). Willow shrub thickets were a hotspot for bird density, but not for species richness. The thickets hosted many specialized species whose main distribution area was south of the tundra. Conclusion/Significance: If current arctic changes result in a shrubification of the landscape as many studies suggested, we would expect an increase in the overall bird abundance together with an increase of local specialists, since they are associated with willow thickets. The majority of these species have a southern origin and their increase in abundance would represent a strengthening of the boreal component in the southern tundra, perhaps at the expense of species typical of the subarctic zone, which appear to be generalists within this zone. © 2012 Sokolov et al.",Related but unverifiable
s_1374,Contradiction,"Cons: Cardiovascular Risks: Coffee may increase blood pressure due to its caffeine content, which can lead to heightened cardiovascular strain .","The consumption of coffee has been associated with a number of health benefits, including a reduced risk of cardiovascular disease. Hypertension is an important risk factor for adverse cardiovascular events. Coffee may help reduce blood pressure (BP) in humans, which might be attributable to its polyphenolic compound, chlorogenic acid. The high incidence of hypertension among Canadians underscores the need for new and effective strategies to reduce BP. Dietary interventions may constitute such a strategy, but consumers need to be informed about which foods are most effective for regulating BP. To guide healthy eating, Health Canada permits the use of health claims on the labels of foods that confer health benefits. Currently, there is only one health claim for BP regulation. Additional health claims for foods that assist in BP regulation are therefore warranted. This review provides background information on chlorogenic acid and examines the evidence regarding the use of chlorogenic acid for BP regulation in the context of Health Canada's health claims framework.
[4]: Background: Coffee is one of the most consumed beverages worldwide. In the last years, coffee consumption has been associated with a number of beneficial effects against metabolic impairment. The aim of this narrative review was to report the most updated and comprehensive evidence from epidemiological and experimental studies as well as mechanisms of action of coffee on metabolic impairment. Methods: A search in electronic databases (PUBMED and EMBASE) was performed to retrieve systematic and pooled analyses on coffee and diabetes, hypertension, and dyslipidemia. Furthermore, the most accredited hypotheses and mechanisms of action of coffee have been described. Results: Coffee consumption has been associated with reduced risk of diabetes in observational studies. However, the effect seems not to be mediated by caffeine. Contrasting results have been found in pooled analyses of observational studies on hypertension, despite short- and long-term follow-ups that have been demonstrated to influence the outcome. Poor or little effect on plasma lipids has been reported in studies on acute administration of coffee, yet depending on the type of coffee preparation. The main beneficial effects of coffee consumption seem to rely on the content of antioxidant and anti-inflammatory compounds (i.e., polyphenols). Among the most important, chlorogenic acids have demonstrated direct anti-hypertensive action through beneficial effect on endothelial function, and significant improvement in glucose and insulin metabolism. Also, diterpenes and melanoidins are major candidates as antioxidant compounds showing the capacity to inhibit the production of inflammatory mediators. However, caffeine and diterpenes may also exert negative effects, such as acute rise in blood pressure and serum lipids. Conclusion: In light of the most recent evidence, coffee consumption seems to be favorably related with health and to protect by metabolic impairment.",Misrepresentation
i_1824,Contradiction,"Socioeconomic Factors: Maternal education, household cleanliness, and socioeconomic status have little to no impact on stunting rates. Poor maternal education and inadequate household conditions do not exacerbate stunting .","Poor linear growth in children <5 years old, or stunting, is a serious public health problem particularly in Sub-Saharan Africa. In 2013, the World Health Organization (WHO) released a conceptual framework on the Context, Causes and Consequences of Childhood Stunting (the 'WHO framework') that identifies specific and general factors associated with stunting. The framework is based upon a global review of data, and we have applied it to a country-level analysis where health and nutrition policies are made and public health and nutrition data are collected. We reviewed the literature related to sub-optimal linear growth, stunting and birth outcomes in Ethiopia as a case study. We found consistent associations between poor linear growth and indicators of birth size, recent illness (e.g. diarrhoea and fever), maternal height and education. Other factors listed as causes in the framework such as inflammation, exposure to mycotoxins and inadequate feeding during and after illness have not been examined in Ethiopia, and the existing literature suggests that these are clear data gaps. Some factors associated with poor linear growth in Ethiopia are missing in the framework, such as household characteristics (e.g. exposure to indoor smoke). Examination of the factors included in the WHO framework in a country setting helps identifying data gaps helping to target further data collection and research efforts. © 2016 John Wiley & Sons Ltd.
[5]: Objective To estimate the determinants of stunting using rich data from a birth cohort study from urban South Africa and to examine the various mechanisms, both proximate and distal, through which maternal education affects stunting. Design Multivariate regression analysis using birth cohort data, where the outcome variable was stunting at age 2 years, and multiple mediator analysis to identify pathways from maternal education to stunting. Setting South Africa's largest metropolitan area, Soweto-Johannesburg. Subjects Participants of Birth to Twenty Plus, a longitudinal cohort study of children born in 1990 (n 691). Results In multivariate analysis, the birth weight Z-score (-0·084; P<0·001; 95 % CI-0·11,-0·06), the mother's openness towards modern health care, captured by a vaccination score (-0·05; P=0·04; 95 % CI-0·10,-0·00), and a better-quality care environment (-0·015; P=0·04; 95 % CI-0·03,-0·00) were found to be negatively associated with stunting. Having experienced symptoms of illness related to ears and eyes increased the risk of stunting (0·038; P=0·01; 95 % CI 0·01, 0·07). Results of the mediation analysis showed that maternal education had an indirect effect on stunting largely through socio-economic status and the antenatal environment (measured by the birth weight Z-score). Conclusions Overall, many of the factors that were protective against stunting in the final analysis, whether they operated through maternal education or not, were related to the mother's contribution to the child's life. This reinforces the idea that to minimise stunting, enhanced antenatal and postnatal services to better support and empower mothers may be important.
[6]: Background: This study examines how significant is the changes in child stunting in Sub-Saharan African countries (SSA). Then, it investigates factors that contributed to the reduction in child stunting in those countries. For each country, we distinguish the contribution of compositional effects and structural effect. Methods: This paper uses data from Demographic and Health Surveys of 12 sub-Saharan African countries conducted between 2000 and 2020. The z-test to compare two independent proportions was used to assess changes in child stunting and explanatory variables over the period. Recentred influence function (RIF) decomposition method was used to decompose changes in stunting over the year in each country, and to determine the contribution of each variable to the changes. Results: The prevalence of child stunting declines significantly in 11 countries over the year. The decline varies from 6.8% in Cameroun to 19% in Mali. The average year of education of the child's mother and father, and the proportion of households with access to an improved drinking water source have contributed to the reduction in child stunting. This result was found in all the countries. Improvements in living standards, child vaccination, antenatal care attendance, delivery to health care centres, maternal education, improved drinking water sources, and improved sanitation make the largest contribution to the composition component, hence reducing child stunting. Conclusions: This study sheds light on what has contributed to the achieved improvement in child nutritional status and suggests how to possibly accelerate the reduction in undernutrition in countries that lag.",Opposite meaning
i_592,Unverifiable,Future Directions: Supply-Oriented Infrastructure: Developing a supply-oriented charging infrastructure is unnecessary for meeting the needs of EV users and does not contribute to efficient utilization of resources .,"Electric mobility is an important means to decarbonise the transport sector. Especially in cities, the use of zero-emission vehicles like electric vehicles is favourable, as emissions of conventional cars cause severe air pollution. Besides CO2, the most important emissions are nitric oxides, particular matter and noise. Given the trend of urbanisation, the problem of air pollution in large cities will rather grow than diminish. Although electric vehicles are an infrastructure-depen­dent technology, one important advantage of plug-in electric vehicles (EV) com­pared to hydrogen-powered vehicles is the possibility to use the existing electricity infrastructure in households for charging. While additional public charging infra­structure is also needed for interim charging or overnight charging for the so-called 'on-street parkers' without own garage, the majority of vehicles could be operated as EVs without additional public charging infrastructure. However, public charging infrastructure is an important component for the large-scale diffusion of electric vehicles and political action seems necessary since no business models are pres­ently available. In the present paper the authors combine different data sets con­cerning German charging points and mobility patterns to describe the different needs for charging infrastructure, and provide an overview of the underlying dif­ferent technical options. Based on the current charging infrastructure stock, the set­up methodology and the impact of user needs on charging infrastructure, the authors compare a coverage-oriented and a demand-oriented approach. The authors also estimate the number of public charging points for those two approaches. Finally, criteria for charging infrastructure are categorised and related to the dif­ferent approaches. It results that the number of charging stations needed for the two
[16]: Mobility offerings have never been as abundant and varied as the present. While users welcome new and innovative mobility options, this current paradigm shift presents a challenge for authorities that plan, organize, and operate such services. In particular, integrating new mobility services into existing infrastructure systems can generate problems of acceptance, cooperability, and compatibility. This problem is especially relevant for electric vehicles. Limited range and battery capacity of battery electric vehicles make them dependent on charging infrastructure, which in turn hinders their acceptance. In light of the German government's goal of one million electric vehicles by 2020, establishing a demand-oriented charging infrastructure is of crucial importance. However, numerous questions remain unanswered regarding the quantity, type, and location of electric vehicle charging stations in Germany. This article presents the findings of the project ""LADEN2020: Concept to build up a demand-oriented charging infrastructure in Germany between today and 2020."" The research project develops a systematically comprehensible and consistent strategy for electric vehicle charging infrastructure in Germany. The paper presents the methodological framework to estimate the charging demand for daily and long-distance travel, which is unique and innovative as similar comprehensive and consistent analytical tools do not exist to date.",Related but unverifiable
i_2359,Unverifiable,"Effects on Growth and Development: Growth Inhibition: Heavy metals like Cd, Cu, and Pb can inhibit plant growth by reducing plant height, biomass, and root length. For instance, high concentrations of Cu and Zn were found to decrease the canopy spectral reflectance in the near-infrared band, indicating stress and reduced growth at the tillering and jointing stages of wheat .","[10] Intercropping technology is applied widely in crop cultivation to help remediate soil polluted with heavy metals. To investigate the feasibility and potential of intercropping hyperaccumulator plants with crops in cadmium (Cd)- and zinc (Zn)-contaminated soil, a pot experiment was conducted to examine plant growth and the contents of Cd and Zn in the soil following intercropping of wheat and Sedum plumbizincicola. Five treatments were examined: control (wheat monoculture: 36 seedlings per pot), and intercropping of wheat with different planting densities of S. plumbizincicola (3, 6, 9 and 15 seedlings per pot, respectively). Results showed a decrease in soil pH, and in soil and wheat contents of Cd and Zn with increasing planting density of S. plumbizincicola, while the removal rate of Cd and Zn increased. Meanwhile, excessive planting (15 seedlings per pot) inhibited wheat growth by 27.34% compared with the control, and overall, the optimal planting density was 9 seedlings per pot, resulting in effective remediation with only a moderate effect on wheat growth. These findings highlight the value of intercropping S. plumbizincicola with wheat as a means of improving remediation of soil contaminated with heavy metals (Cd and Zn). [16] Background: Open-top chambers were used to study the impact of simultaneous exposure to atmospheric SO<inf>2</inf> pollution and heavy metal contamination in soils on the metal contents and productivity of soybean plant. Methods: Plants were exposed at ambient levels as control SO<inf>2</inf> (1.2 ppb), low SO<inf>2</inf> (97 ppb), and high SO<inf>2</inf> (490 ppb) over the whole growing season while simultaneously being exposed to either Cd (0.5 mg kg<sup>-1</sup>), Pb (250 mg kg<sup>-1</sup>), Cu (100 mg kg<sup>-1</sup>), or Zn (150 mg kg<sup>-1</sup>) in soil. Results: This experimental study covering the whole growth season has shown that SO<inf>2</inf> has a synergistic effect in enhancing the heavy metal contents in aboveground tissues of soybean plant, and the effects of high SO<inf>2</inf> treatment were found to be highly significant, showing increases of 42% and 29% for Cu and Cd content of grain, respectively. Conclusion: The research findings are of practical significance in the environmental control for the combined pollution of air and soil to ensure the quality of agricultural products and therefore benefits for human health. © 2011 Springer-Verlag. [18] Pot experiments were conducted in glasshouse under controlled conditions. The effect of copper in alluvial soil on the growth and yield of Triticum aestivum L. (wheat) was worked out. Copper was applied in soil at 5-100-mg-L<sup>-1</sup>, along with iron supplement. Inhibitory response of copper was significant (p-<-0.05) confirmed by the plant growth parameters viz., plant height, fresh and dry weight, moisture content, pigment contents, protein, sugar contents followed by increased catalase and peroxidase activity in the harvest at 30, 60, and 90-days, of treatment, respectively. The plants grown on copper treated soil along with 5-mg-L<sup>-1</sup> Cu and iron application showed significant effects (p-<-0.05) regarding the increase in plant biomass, plant height (shoot only), pigment contents, protein, sugar contents, grain yield followed by decreased catalase and peroxidase activity in wheat after 30, 60, and 90-days of treatment, respectively. The accumulation of metal in plant tissues was found in order of Fe->-Cu coupled by less translocation in grain as compared to the whole plant.The results in this paper showed the impact recovered by iron applicability whereby the growth parameters and the enzymatic cascade system in wheat was found to be altered. However, the Fe recovery was efficient enough to reverse the damage. Therefore, inorganic amendments can be used in the copper contaminated sites. © 2010 WILEY-VCH Verlag GmbH & Co. KGaA, Weinheim.",Related but unverifiable
i_1585,Entailment,"Data Reliability Concerns: Research Gaps: There is a need for more comprehensive studies that examine the direct ecological effects of these contaminants, including their impact on ecosystem functions and indicators of contaminant-driven change, and it is likely that these studies will reveal previously unknown interactions between PPCPs and marine biodiversity that could have significant implications for conservation efforts .","Pharmaceuticals and personal care products (PPCPs) are contaminants of emerging concern that are increasing in use and have demonstrated negative effects on aquatic organisms. There is a growing body of literature reporting the effects of PPCPs on freshwater organisms, but studies on the effects of PPCPs to marine and estuarine organisms are limited. Among effect studies, the vast majority examines subcellular or cellular effects, with far fewer studies examining organismal- and community-level effects. We reviewed the current published literature on marine and estuarine algae, invertebrates, fish, and mammals exposed to PPCPs, in order to expand upon current reviews. This paper builds on previous reviews of PPCP contamination in marine environments, filling prior literature gaps and adding consideration of ecosystem function and level of knowledge across marine habitat types. Finally, we reviewed and compiled data gaps suggested by current researchers and reviewers and propose a multi-level model to expand the focus of current PPCP research beyond laboratory studies. This model includes examination of direct ecological effects including food web and disease dynamics, biodiversity, community composition, and other ecosystem-level indicators of contaminant-driven change.",Entailment
s_550,Contradiction,"Advanced Materials: Using CFRP or other advanced composites can mitigate corrosion issues and extend the lifespan of the structure, but these materials come with higher initial costs .","The increased demand for lightweight high-performance composites has led to search for alternative reinforcement to improve the mechanical performance of conventional structures. Likewise, various research initiatives have advocated recycling of construction and demolition wastes and novel technologies to avert their generation. Owing to disadvantages of steel rebar, carbon fibre reinforced polymer (CFRP) was utilized as potential internal reinforcement in recycled concrete beam owing to its lightweight, non-corrosiveness, high-stiffness-to-weight ratio and flexibility. Our study revealed significant improvement in the mechanical performance and efficiency which is controlled by the fibre architecture. The improved mechanical properties was attributed to the Bauschinger strain-reversal effect, made possible by the effective CFRP tensile strength mobilization, its high bonded surface area and interfacial energy as well as the composite action of the multi-layered CFRP reinforcements. The best configuration (N4) revealed by the simplified linear weighted sum optimization method achieved strengthening (load) efficiency of 402.7%, ductility efficiency of 299.7%, fracture toughness efficiency of 567.1% and fracture energy efficiency of 5713.9% compared to the unreinforced control. In addition, CFRP laminate was 3.67–4.9 times more cost-effective than steel rebar in terms of fracture toughness. Therefore, CFRP-reinforced recycled concrete is recommended for cost-effective and sustainable prefabricated concrete structures.
[11]: Advanced fiber reinforced polymer (FRP) systems have been widely used for the structural strengthening and rehabilitation of existing buildings and bridges for decades. Such as the engineering community has accepted these systems as viable, long-term strengthening solutions for structural bridge and building elements, so too have they accepted them for the rehabilitation and strengthening of pipelines. This relatively novel FRP technology is extremely conducive to application in pipeline rehabilitation and strengthening; its unidirectional strength properties and malleable form make precision design and installation of the system efficient and cost-effective in many applications. As the design of FRP pipeline strengthening systems becomes more refined, so too must the inspection methods used to assure these systems' proper installation and post-installation performance. Various experiences have been compiled from nuclear, industrial, and municipal installations on steel, reinforced concrete, and pre-stressed concrete cylinder piping. Resulting conclusions and best-practices on processes ranging from monitoring of in-field environmental conditions, to critical points of structural observation during installation, and proper methods of post-cure imperfection detection and remediation will be defined and presented within this paper. The aim of this work will be to inform end-users and installers alike of necessary inspection and observation steps required during installations to ensure the safe and proper performance of FRP pipeline strengthening systems.",Missing information
i_148,Contradiction,"Potential Applications of AI for Managing Dark Data: Enhanced Data Management: AI technologies can be used for database mining and information retrieval, which are often seen as the only methods for managing large volumes of dark data, despite other possible approaches being available .","Artificial intelligence (AI) is making its way back into the mainstream of corporate technology, this time at the core of business systems which are providing competitive advantage in all sorts of industries, including electronics, manufacturing, marketing, hu-manresource, financial services software, medicine, entertainment, engineering and communications. Designed to leverage the capabilities of humans rather than replace them, today's AI technology enables an extraordinary array of applications that forge new connections among people, computers, knowledge, and the physical world. Some AI enabled applications are information distribution and retrieval, database mining, product design, manufacturing, inspection, training, user support, surgical planning, resource scheduling, and complex resource management. AI technologies help enterprises reduce latency in making business decisions, minimize fraud and enhance revenue opportunities.",Misrepresentation
i_1707,Contradiction,"Used in a two-phase anaerobic packed bed biofilm reactor (AnPBR), these beads supported the growth of methanogenic bacteria like Methanobacterium and Methanosarcina, contributing to stable methane production  .","Conventional completely mixed anaerobic treatment systems limit the chances of the different species of bacteria to spatially group together according to their mutual cooperation and as a result, show a lower efficiency and vulnerability towards shock situations. It is interesting to know about the stratification of the different bacterial species participating in the degradation process and the intermediates that they produce. In this study, we established and optimized a two-phase anaerobic packed bed biofilm reactor system (AnPBR) with porous PVA gel beads used as bio-carriers and ran the reactor system in a steady state to observe the VFAs produced along with the microbial diversity of the predominant species at different stages of the reactor system. We observed that acetate and butyrate were the predominant intermediate VFAs while concentrations of other VFAs such that propionic acid were low. Acetobacterium and Clostridium were found to be the most abundant bacterial species in acidogenic reactor while methanogenic reactor was highly enriched with Methanobacterium and Methanosarcina. Apart from the above, syntrophic populations such as Syntrophobactor wolinii were also observed to be dominant in both the reactors–especially towards the end of acidogenic reactor and the initial part of the methanogenic reactor.",Missing information
s_173,Entailment,"Application Delivery Networks (ADNs): Content Delivery Networks (CDNs): The dominance of major content providers and CDNs like Akamai and Google CDN highlights the importance of efficient content delivery. CDNs push content closer to end-users to improve performance and user experience, which is crucial for distributors specializing in ADNs .","Today's Internet traffic is largely dominated by major content providers and highly distributed Content Delivery Networks (CDNs). Internet-scale applications like Facebook and YouTube are served by large CDNs like Akamai and Google CDN, which push content as close to end-users as possible to improve the overall performance of the applications, minimize the effects of peering point congestion and enhance the user experience. The load is balanced among multiple servers or caches according to non-disclosed CDN internal policies. As such, adopting space and time variant policies, users' requests are served from different physical locations at different time. Cache selection and load balancing policies can have a relevant impact on the traffic routed by the underlying transport network, as well as on the end-user experience. In this paper, we analyze the provisioning of two major Internet applications, namely Facebook and YouTube, in two datasets collected at major European Internet Service Providers (ISPs). First, we show how the cache selection performed by Akamai might result in higher transport costs for the ISP. Second, we present evidence on large-scale outages occurring in the Facebook traffic distribution. Finally, we characterize the variation of YouTube cache selection strategies and their impact on the users' quality of experience. We argue that it is important for the ISP to rapidly and automatically detect such events. Therefore, we present an Anomaly Detection (AD) system for detecting unexpected cache-selection events and changes in the traffic delivered by CDNs. The proposed algorithm improves over traditional AD approaches by analyzing the complete probability distribution of the monitored features, providing higher visibility and better detection capabilities.
[5]: Peering of Content Delivery Networks (CDNs) allow providers to rapidly scale-out to meet both flash crowds and anticipated increases in demand. Recent trends foster the need for a utility model for content delivery services to provide transparency, high availability, reduced investment cost, and improved content delivery performance. Analysis of prior work reveals only a modest progress in evaluating the utility for peering CDNs. In this paper, we introduce a utility model and measure the content-serving ability of the peering CDNs system. Our model assists in providing a customer view of the system's health for different traffic types. Our model also captures the traffic activities in the system and helps to reveal the true propensities of participating CDNs to cooperate in peering. Through extensive simulations we unveil many interesting observations on how the utility of the peering CDNs system is varied for different system parameters and provide incentives for their exploitation in the system design. ©2009 IEEE.",Entailment
i_731,Unverifiable,"Challenges and Future Directions: User Acceptance: The adaptability and usability of smart furniture interfaces are crucial. While multimodal interfaces have shown some positive user acceptance compared to mono-modal interfaces, this does not necessarily mean that users prefer them in all contexts, suggesting that their effectiveness may vary significantly depending on the specific application .","Smart Environments have specific natural interaction needs that can be provided for with multimodal interfaces. There are still challenges to face, such as the adaptability of the interaction and an evaluation of the proposed systems. This work focuses on these problems and proposes an architectural design evaluated in the domain of Smart Homes. The architectural approach is based on the Model View Presenter Pattern and the Service Oriented paradigm. The evaluation was conducted with a laboratory deployment of a prototype of the system and usability tests were carried out with a usability questionnaire. Results show the technical feasibility of the proposed design and positive user acceptance of the multimodal interface as compared to mono-modal interfaces. © 2012 Springer-Verlag.",Related but unverifiable
i_333,Unverifiable,"7. ** Ethical and Regulatory Issues**: ** Ethics and GDPR**: The use of DL in sensitive areas like healthcare and finance raises ethical concerns and regulatory challenges, such as compliance with GDPR .","The construction industry is known to be overwhelmed with resource planning, risk management and logistic challenges which often result in design defects, project delivery delays, cost overruns and contractual disputes. These challenges have instigated research in the application of advanced machine learning algorithms such as deep learning to help with diagnostic and prescriptive analysis of causes and preventive measures. However, the publicity created by tech firms like Google, Facebook and Amazon about Artificial Intelligence and applications to unstructured data is not the end of the field. There abound many applications of deep learning, particularly within the construction sector in areas such as site planning and management, health and safety and construction cost prediction, which are yet to be explored. The overall aim of this article was to review existing studies that have applied deep learning to prevalent construction challenges like structural health monitoring, construction site safety, building occupancy modelling and energy demand prediction. To the best of our knowledge, there is currently no extensive survey of the applications of deep learning techniques within the construction industry. This review would inspire future research into how best to apply image processing, computer vision, natural language processing techniques of deep learning to numerous challenges in the industry. Limitations of deep learning such as the black box challenge, ethics and GDPR, cybersecurity and cost, that can be expected by construction researchers and practitioners when adopting some of these techniques were also discussed.",Unrelated and unverifiable
s_1619,Entailment,Conservation and Management: Habitat Preservation: Understanding the spatial distribution and ecological roles of sea urchins is essential for conservation efforts. Protecting diverse habitats like coral reefs and rocky substrates is crucial for maintaining healthy sea urchin populations and overall marine biodiversity .,"In order to preserve diversity it is essential to understand how assemblages change across space. Despite this fact, we still know very little about how marine diversity is spatially distributed, especially among lesser-studied invertebrate taxa. In the present study beta-diversity patterns of sea urchins, sponges, mushroom corals and larger foraminifera were assessed in the Spermonde Archipelago (Indonesia). Using ordinations we showed that the inshore zone (<5 km offshore), midshore zone (5 < × < 30 km offshore) and distance offshore zone (<30 km offshore) all contained distinct assemblages of sponges and corals, while only foraminifera assemblages from the inshore (<5 km offshore) zone were distinct. There was a significant spatial pattern of community similarity for all taxa surveyed, but this pattern proved to be wholly related to environmental variables for sponges and foraminifera, and primarily for mushroom corals and sea urchins. The lack of a pure spatial component suggests that these taxa may not be dispersal limited within the spatial scales of this study (c. 1600 km<sup>2</sup>). The analyses of the corals and foraminifera were additionally tested at two spatial scales of sampling. Both taxa were primarily associated with local-scale environmental variables at the local scale and larger-scale variables at the larger scale. Mean inter-plot similarity was also higher and variation lower at the larger scale. The results suggest that substantial variation in similarity can be predicted using simple locally assessed environmental variables combined with remotely sensed parameters. © 2006 The Authors. Journal compilation © 2006 Blackwell Publishing Ltd.
[8]: This paper examines published information and gray literature about taxonomy and ecology of echinoderm species of the Colombian Pacific Coast. Unpublished collection data of specimens kept in the Marine Sciences Museum of the University of Valle are also considered. Sixty-six species are found in coastal ecosystems and shallow bottoms of ten geographical, coastal and insular localities of the Pacific coast of Colombia. Main habitats having echinoderms are: rocky cliffs and shores, coral reefs, sand beaches, mud substrates, mangroves, and shallow bottoms of mud, sand, gravel and rocks. Regular Echinoidea and Asteroidea are the most diverse and abundant groups, mainly in subtidal rocky shallow bottoms and coral reefs. Ophiuroidea are abundant below rocky boulders. Irregular Echinoidea are abundant on sand beaches. The relatively high number of species shows that this geographical area presents a high diversity of echinoderms compared with other tropical shallow and littoral zones of the world. Rocky substrates and coral reefs are the ecosystems with the highest numbers of echinoderm species and individuals. A conservation status assessment is difficult because the lack of periodical sampling and few data about deep zones. In general, the species reported in the last 25 years, have not experimented important changes in their populations, although in some specific places, populations may decrease because human activities in coastal areas increase sedimentation rates change some rocky substrates to mud or sand.",Entailment
s_183,Unverifiable,"Effective Methods for Early Stopping: Regularization Techniques: Techniques such as dropout, batch normalization, weight decay, and early stopping are used to improve generalization. Advantages: These methods help in reducing overfitting and improving the robustness of the model .","These days deep learning is the fastest-growing area in the field of Machine Learning. Convolutional Neural Networks are currently the main tool used for the image analysis and classification purposes. Although great achievements and perspectives, deep neural networks and accompanying learning algorithms have some relevant challenges to tackle. In this paper, we have focused on the most frequently mentioned problem in the field of machine learning, that is relatively poor generalization abilities. Partial remedies for this are regularization techniques e.g. dropout, batch normalization, weight decay, transfer learning, early stopping and data augmentation. In this paper we have focused on data augmentation. We propose to use a method based on a neural style transfer, which allows to generate new unlabeled images of high perceptual quality that combine the content of a base image with the appearance of another one. In a proposed approach, the newly created images are described with pseudo-labels, and then used as a training dataset. Real, labeled images are divided into the validation and test set. We validated proposed method on a challenging skin lesion classification case study. Four representative neural architectures are examined. Obtained results show the strong potential of the proposed approach.
[7]: Clickbait is an elusive challenge with the prevalence of social media such as Facebook and Twitter that misleads the readers while clicking on headlines. Limited annotated data makes it onerous to design an accurate clickbait identification system. The authors address this problem by purposing deep learning-based architecture with external knowledge which trains on social media post and descriptions. The pre-trained ELMO and BERT model obtains the sentence level contextual feature as knowledge; moreover, the LSTM layer helps to prevail the word level contextual feature. Training has done at different experiments (model with EMLO, model with BERT) with different regularization techniques such as dropout, early stopping, and finetuning. Forward context-aware clickbait tweet identification system (FCCTI) with BERT finetuning and model with ELMO using glove pre-trained embedding is the best model and achieves a clickbait identification accuracy of 0.847, improving on the previous baseline for this task.",Related but unverifiable
s_2198,Contradiction,"Environmental Impacts: Marine and Freshwater Ecosystems: Plastic pollution affects nearly every marine and freshwater ecosystem globally, including those in the United States. While microplastics and nanoplastics are concerning, their impact on aquatic organisms is often overstated, as some studies suggest that their effects may not be as severe as previously thought, potentially leading to misconceptions about the urgency of the issue .","Plastic pollution is a planetary threat, affecting nearly every marine and freshwater ecosystem globally. In response, multilevel mitigation strategies are being adopted but with a lack of quantitative assessment of how such strategies reduce plastic emissions. We assessed the impact of three broad management strategies, plastic waste reduction, waste management, and environmental recovery, at different levels of effort to estimate plastic emissions to 2030 for 173 countries. We estimate that 19 to 23 million metric tons, or 11%, of plastic waste generated globally in 2016 entered aquatic ecosystems. Considering the ambitious commitments currently set by governments, annual emissions may reach up to 53 million metric tons per year by 2030. To reduce emissions to a level well below this prediction, extraordinary efforts to transform the global plastics economy are needed.
[2]: Contamination by bulk plastics and plastic debris is currently the one of the most serious environmental problems in aquatic ecosystems. In particular, small-scale plastic debris such as microplastics and nanoplastics has become leading contributors to the pollution of marine and freshwater ecosystems. Studies are investigating the impacts of micro-and nanoplastics on aquatic organisms and ecosystems worldwide. This review covers 83 studies that investigated the distribution of microplastics and the ecotoxicity of micro- and nanoplastics in marine and freshwater ecosystems. The studies indicated that micro-sized plastics and plastic debris were distributed at various concentrations in aquatic ecosystems around the world. They had various effects on the growth, development, behavior, reproduction, and mortality of aquatic animals. We discuss these studies in detail and suggest directions for future research.
[3]: The dependence on plastic materials for modern life has led to an increase of plastic waste in coastal systems. Microplastics (plastics < 5. mm in size) in particular, have induced alarm among scientific and management bodies as an emerging marine and coastal contaminant. Recent studies suggest that these small plastic particles are ubiquitous in the marine system, as they have been recorded in every coastal and marine habitat around the world. The presence of microplastics in the environment has been shown to have negative consequences for many marine wildlife species, such as marine birds, turtles, and fish. To mitigate the harm caused by plastic pollution, it is essential to understand the life cycle of plastic products, beginning with plastic use and disposal, to the arrival at coastal marine environments. Therefore, this chapter focuses on the issue of plastic pollution in the coastal environment and reviews the current knowledge base on sources, dispersal, accumulation, and most importantly solutions for the problem of plastic pollution. This chapter also discusses and gives examples of current initiatives to reduce the plastic load, including the circular economy approach, and other successful campaigns around the world. Lastly, it discusses the importance of the behavioral, social, and economic changes needed to reduce plastic demand and use for lasting systematic solutions. © 2019 Copyright",Opposite meaning
s_790,Unverifiable,Ground Penetrating Radar (GPR): These devices track flexible pavement structural conditions over time and assess rehabilitation needs at a network level .,"Pavement management systems of highway agencies in the various states are primarily based on surface condition data. Surface cracking is used as the main indicator of pavement structural condition. However, with effective pavement treatment that intervenes early to preserve and extend the life of pavements and increasingly thicker long-life pavements, surface cracks no longer tell the true structural condition, or health, of the pavement structure. In addition, surface cracks lack an indicator of pavement deterioration. Knowledge of the true pavement structural condition and the rate of deterioration is needed not only for planning of optimal structural rehabilitation activities and future budget needs but also for implementing a performance-based federal-aid program. This paper presents a methodology for interpreting measurements from traffic speed deflection devices (TSDDs) to track flexible pavement structural condition over time and for assessing rehabilitation needs at a network level to address both structural adequacy and surface condition. The paper also demonstrates a methodology for interpreting TSDD measurements to estimate remaining pavement structural capacity. Curvature indexes measured from TSDD were found to be reasonable estimators of pavement structural condition and were used in the demonstration. Horizontal tensile strain, a primary initiator of fatigue damage and cracking, can be estimated from periodic TSDD measurements and used as a leading indicator of pavement deterioration and structural performance. Any differences in pavement structural performance arising from the pavement's as-designed versus as-constructed state and its assumed versus actual traffic and climate effects can be assessed and future treatments modified as necessary.",Related but unverifiable
i_1987,Entailment,"Benefits: Increases incentives for landowners to cooperate, facilitating higher density development while preserving green spaces .","The difficulty of assembling sites large enough to redevelop at higher density can impede regeneration in city centers and accelerate suburban sprawl onto large sites already in single ownership. One promising new planning strategy to encourage voluntary land assembly is graduated density zoning, which allows higher density on larger sites. This strategy can increase the incentive for owners to cooperate in a land assembly that creates higher land values. Graduated density zoning will not eliminate the incentive to hold out, but it can create a new fear of being left out. Holdouts who are left with sites that cannot be combined with enough contiguous properties to trigger higher density lose a valuable economic opportunity. This article examines the difficulty of assembling land for infill development, and explains graduated density zoning as a way to encourage voluntary land assembly. Finally, it presents the results of graduated density zoning in practice. © 2008 Sage Publications.",Entailment
i_748,Entailment,"Applications of Acoustic Emission Technology in the Automotive Industry: General Machinery Monitoring: AE is used for the condition monitoring of various automotive components, including pneumatic devices and other machinery parts. It helps in identifying and localizing damage, ensuring the reliability and safety of automotive systems .","The paper presents an overview of the contemporary applications of acoustic emission method for diagnosis and condition monitoring of anomalous situations that occur during the operation of machines with rotating parts (formation of contact damage, insufficient lubrication, etc.). The main attention is focussed on operational diagnostics of axial and radial bearings. The second part of the text also mentions the possibilities of utilisation of AE method for complementary diagnosis of real state of gears and gearboxes. This summary of selected published experimental works and used evaluation procedures is confronted with the outputs of the experiments carried out in the framework of several projects in the Laboratory of Acoustic Emission of the Institute of Machine and Industrial Design in Brno University of Technology. Based on this review, the significant potential of AE method for more accurate diagnosis of malfunction of machines with rotating parts is done.
[7]: Acoustic emission laboratory at the Institute of Machine and Industrial Design of Brno University of Technology is long focused on the use of acoustic emission testing (AT) for diagnostics of damage development in cyclically loaded materials and machine parts. In addition to these relatively traditional applications already however this laboratory workers devote other non-traditional possibilities of using acoustic emission method. In this paper there are presented the first interim results of the project, which is focused on applications of AT in function diagnostic of pneumatic devices. There are compared the signals obtained from the fully functional pneumatic cylinders with signals from cylinders with various types of artificially created damage. The second part briefly presents the first results of the acoustic emission application in other very non-traditional areas. The attention is paid to the usability of AT for identification and localisation of undesirable discharges in gas-insulated conductors for high-voltage substations and for increasing of accuracy and objectivity of the tests for sensitiveness determination of explosives to friction.",Entailment
i_1313,Entailment,"Health Concerns: There are ongoing discussions about the potential health effects of wireless communication technologies, particularly related to electromagnetic fields (EMFs). However, current guidelines indicate no evidence of adverse health effects at exposure levels below the safety limits .","5G (fifth generation) technology is used to interconnect all terminals, networks, multiple wireless technologies, applications simultaneously which can also switch between them based on VOIP (Voice-over-IP), flat IP, and Internet Protocol Version 6 (IPv6), thus user experiences call volume services and high-level data transmission. 5G network is reliable and very fast with minimum delay, higher data rate, greater security, real-time data handling, less error rate, and few data losses. The core technologies used in 5G networks include cloud computing, Heterogeneous Network (Het Net), internet of things (IoT), Cognitive Radio (CR) network, software-defined networking (SDN), Multiple Input Multiple Output (MIMO), and massive MIMO. 5G produces different harmful effects such as human health issues, environmental issues, health issues on birds and animals, thermal effects, etc. Regulating agencies have to set a Specific Absorption Rate (SAR), its maximum levels for handsets, and every mobile phone must have a SAR rating. 5G technology is used as intelligent technology in which 5G mobile phones can also be used as a tablet PC. This paper presents a general review on 5G along with its comparison with 4G, the general architecture of 5G, a detailed explanation about core technologies of 5G, and also harmful effects on different issues using 5G.
[3]: The considerable characteristics of 5G technology (Fifth Generation of telecommunication) is the very high amount of data that can be transmitted in the time unit (data speed: Megabits per second - throughput) and the very low delay in data exchange (latency). ElectroMagnetic Fields (EMFs) are used for decades for communication reasons and broadcasting. 700 MHz and lower frequencies are currently being used in Digital TV. Low frequencies (800, 900 MHz) are also being used in previous (but still existing) technologies 2G, 3G, 4G, 4G+. 5G will exploit both low and high frequencies. 5G will be operation mainly in a low band (700 MHz) and a high band (3.5 GHz). In the near future mmWave bands will also be used above 6 GHz (for example 24 GHz, 28 GHz and above). Theoretical models and live measurements have consistently shown that the actual maximum power is always less than the 25% of the maximum peak power of a Massive-MIMO antenna. ICNIRP has published in 1998 ""Guidelines for Limiting Exposure to Electromagnetic Fields (100 kHz to 300 GHz)"". The current revision (2020) is based on the same criteria, but it exhibits more accuracy in dosimetry calculations, considering details and based on better biological rationale. mmWave bands (> 6 GHz) is a controversial issue for the population. Reports did not show adverse health effects in daily life under the safety limits. WHO is currently preparing a review about health risks assessment of RF exposure (including mm-Waves), which will be completed by 2022. There is no evidence of adverse health effects at exposure levels below the basic restrictions as described in the ICNIRP (1998) and ICNIRP (2020) guidelines and no evidence of an interaction mechanism that would predict that adverse health effects could occur due to radiofrequency EMF exposure below restriction levels. The new Guidelines provide protection against all adverse health effects, regardless of whether they are due to acute or chronic exposures, regardless of age or health status. Radio and Microwave Frequencies, where mobile technology and Wi-Fi operate, are used in Medicine for therapeutic or diagnostic purposes. These bands are used for various application as Microwave Diathermy (same band as 2G, 3G and Wi-Fi technologies), Microwave induced thermoacoustic echography (same band as 4G technology), Medical Imaging / localization of tumors (same bands as 2G, 3G, 4G and 5G technologies) and Medical Monitoring / Measurement of vital function as respiration and heart rate (same band as the forthcoming mmWave 5G). By utilizing new technologies that are involved in 5G communication (IoT and mmWave frequencies) healthcare systems can improve the quality of care, provide more personalized and preventive care and reduce the cost of care.",Entailment
s_1529,Unverifiable,"The activity of PHT4 transporters is likely controlled post-translationally, allowing plants to adjust phosphate uptake in response to varying environmental conditions .","Arabidopsis (Arabidopsis thaliana) absorbs inorganic phosphate (Pi) from the soil through an active transport process mediated by the nine members of the PHOSPHATE TRANSPORTER1 (PHT1) family. These proteins share a high level of similarity (greater than 61%), with overlapping expression patterns. The resulting genetic and functional redundancy prevents the analysis of their specific roles. To overcome this difficulty, our approach combined several mutations with gene silencing to inactivate multiple members of the PHT1 family, including a cluster of genes localized on chromosome 5 (PHT1;1, PHT1;2, and PHT1;3). Physiological analyses of these lines established that these three genes, along with PHT1;4, are the main contributors to Pi uptake. Furthermore, PHT1;1 plays an important role in translocation from roots to leaves in high phosphate conditions. These genetic tools also revealed that some PHT1 transporters likely exhibit a dual affinity for phosphate, suggesting that their activity is posttranslationally controlled. These lines display significant phosphate deficiency-related phenotypes (e.g. biomass and yield) due to a massive (80%–96%) reduction in phosphate uptake activities. These defects limited the amount of internal Pi pool, inducing compensatory mechanisms triggered by the systemic Pi starvation response. Such reactions have been uncoupled from PHT1 activity, suggesting that systemic Pi sensing is most probably acting downstream of PHT1.",Related but unverifiable
i_2074,Entailment,"Significance of Varying Hydraulic Conductance: Impact on Water Use Efficiency: Variations in hydraulic conductance affect the plant's ability to transport water efficiently, impacting transpiration rates and water use efficiency (WUE) .","Plant hydraulic conductance (k<inf>s</inf>) is a critical control on whole-plant water use and carbon uptake and, during drought, influences whether plants survive or die. To assess long-term physiological and hydraulic responses of mature trees to water availability, we manipulated ecosystem-scale water availability from 2007 to 2013 in a piñon pine (Pinus edulis) and juniper (Juniperus monosperma) woodland. We examined the relationship between k<inf>s</inf> and subsequent mortality using more than 5 years of physiological observations, and the subsequent impact of reduced hydraulic function and mortality on total woody canopy transpiration (E<inf>C</inf>) and conductance (G<inf>C</inf>). For both species, we observed significant reductions in plant transpiration (E) and k<inf>s</inf> under experimentally imposed drought. Conversely, supplemental water additions increased E and k<inf>s</inf> in both species. Interestingly, both species exhibited similar declines in k<inf>s</inf> under the imposed drought conditions, despite their differing stomatal responses and mortality patterns during drought. Reduced whole-plant k<inf>s</inf> also reduced carbon assimilation in both species, as leaf-level stomatal conductance (g<inf>s</inf>) and net photosynthesis (A<inf>n</inf>) declined strongly with decreasing k<inf>s</inf>. Finally, we observed that chronically low whole-plant k<inf>s</inf> was associated with greater canopy dieback and mortality for both piñon and juniper and that subsequent reductions in woody canopy biomass due to mortality had a significant impact on both daily and annual canopy E<inf>C</inf> and G<inf>C</inf>. Our data indicate that significant reductions in k<inf>s</inf> precede drought-related tree mortality events in this system, and the consequence is a significant reduction in canopy gas exchange and carbon fixation. Our results suggest that reductions in productivity and woody plant cover in piñon-juniper woodlands can be expected due to reduced plant hydraulic conductance and increased mortality of both piñon pine and juniper under anticipated future conditions of more frequent and persistent regional drought in the southwestern United States. We examined the relationship between plant hydraulic conductance (k<inf>s</inf>) and subsequent tree mortality using more than 5 years of physiological observations in a piñon pine and juniper woodland subjected to varying degrees of experimental water manipulation. For both species, we observed significant reductions in transpiration, hydraulic conductance, and net photosynthetic carbon fixation under experimentally imposed drought, and we observed that chronically low whole plant k<inf>s</inf> was associated with greater canopy dieback and mortality for both piñon and juniper. Thus, our data indicate that significant reductions in whole plant k<inf>s</inf> precede drought related tree mortality events in piñon-juniper woodland ecosystems subjected to prolonged periods of chronic water stress.
[12]: Plants control water-use efficiency (WUE) by regulating water loss and CO<inf>2</inf> diffusion through stomata. Variation in stomatal control has been reported among lineages of vascular plants, thus giving rise to the possibility that different lineages may show distinct WUE dynamics in response to water stress. Here, we compared the response of gas exchange to decreasing leaf water potential among four ferns and nine seed plant species exposed to a gradually intensifying water deficit. The data collected were combined with those from 339 phylogenetically diverse species obtained from previous studies. In well-watered angiosperms, the maximum stomatal conductance was high and greater than that required for maximum WUE, but drought stress caused a rapid reduction in stomatal conductance and an increase in WUE in response to elevated concentrations of abscisic acid. However, in ferns, stomata did not open beyond the optimum point corresponding to maximum WUE and actually exhibited a steady WUE in response to dehydration. Thus, seed plants showed improved photosynthetic WUE under water stress. The ability of seed plants to increase WUE could provide them with an advantage over ferns under drought conditions, thereby presumably increasing their fitness under selection pressure by drought.",Entailment
s_188,Contradiction,"Resource Constraints: IoT devices often possess sufficient processing power, storage, and battery life, enabling the implementation of robust security measures such as encryption . This enhances their resilience against attacks and strengthens the overall security of the surveillance system.","Internet of Things (IoT) is an interconnection of physical objects to the Internet which enables data exchange. When things are connected to the internet it becomes an open path for adversaries to unlawfully gain data over the internet leading to unaccountable security issues pertaining to data integrity and privacy. The need to secure the data gathered from sensors is important as this eventually gives trust to the larger data, the big data. Furthermore, connected objects in IoT are resource constrained through having smaller processors, storage capacities and battery power, thus putting constraints on the 'Things' by imposing extra computation such as cryptographic computation. Instead of having a middleware secure connection, this paper proposes to implement a lightweight asymmetric encryption onboard the 'Things' itself. Thus, this paper presents an analysis of a lightweight asymmetric encryption, the AAβ (AA-Beta) that might be feasibly implemented on the 'Things' to secure the IoT networks.",Misrepresentation
s_969,Unverifiable,"Summary of Findings: Key Points: Drug Metabolism and Hypothermia: Hypothermia affects drug metabolism, which can increase the risk of adverse effects, including hypothermia, when psychotropic drugs are administered .","OBJECTIVES: Therapeutic hypothermia has been shown to decrease neurologic damage in patients experiencing out-of-hospital cardiac arrest. In addition to being treated with hypothermia, critically ill patients are treated with an extensive pharmacotherapeutic regimen. The effects of hypothermia on drug disposition increase the probability for unanticipated toxicity, which could limit its putative benefit. This review examines the effects of therapeutic hypothermia on the disposition, metabolism, and response of drugs commonly used in the intensive care unit, with a focus on the cytochrome P450 enzyme system. DATA SOURCES AND STUDY SELECTION: A MEDLINE/PubMed search from 1965 to June 2006 was conducted using the search terms hypothermia, drug metabolism, P450, critical care, cardiac arrest, traumatic brain injury, and pharmacokinetics. DATA EXTRACTION AND SYNTHESIS: Twenty-one studies were included in this review. The effects of therapeutic hypothermia on drug disposition include both the effects during cooling and the effects after rewarming on drug metabolism and response. The studies cited in this review demonstrate that the addition of mild to moderate hypothermia decreases the systemic clearance of cytochrome P450 metabolized drugs between ∼7% and 22% per degree Celsius below 37°C during cooling. The addition of hypothermia decreases the potency and efficacy of certain drugs. CONCLUSIONS: This review provides evidence that the therapeutic index of drugs is narrowed during hypothermia. The magnitude of these alterations indicates that intensivists must be aware of these alterations in order to maximize the therapeutic efficacy of this modality. In addition to increased clinical attention, future research efforts are essential to delineate precise dosing guidelines and mechanisms of the effect of hypothermia on drug disposition and response. © 2007 Lippincott Williams & Wilkins, Inc.
[4]: Introduction: Therapeutic hypothermia is being employed clinically due to its neuro-protective benefits. Both critical illness and therapeutic hypothermia significantly affect drug disposition, potentially contributing to drug-therapy and drug-disease interactions. Currently, there is limited information on the known alterations in drug concentration and response during mild hypothermia treatment, and there is a limited understanding of the specific mechanisms that underlie alterations in drug concentrations and the potential clinical importance of these changes. Areas covered: A systemic review of the effect of therapeutic hypothermia on drug metabolism, disposition and response is provided. Specifically, the clinical and preclinical evidence of the effects of therapeutic hypothermia on blood flow, specific hepatic metabolism pathways, transporter function, renal excretion, pharmacodynamics and the effects during rewarming are reviewed. Expert opinion: Available evidence demonstrates that mild hypothermia decreases the clearance of a variety of drugs with apparently little change in drug-protein binding. Recent evidence suggests that the magnitude of the change is elimination route specific. Further research is needed to determine the impact of these alterations on both drug concentration and response in order to optimize the therapeutic hypothermia in this vulnerable patient population. © Informa UK, Ltd.
[5]: Background: Therapeutic hypothermia may alter both the pharmacokinetic (PK) and dynamics (PD) of the commonly used drugs in critical care. To achieve maximum benefit, medication dosage and schedules should be optimized. Objective: To review the existing scientific evidence showing the effect of therapeutic hypothermia on the pharmacokinetics of drugs commonly used in the care of patients after Trauma Brain Injury (TBI); particularly including sedatives, anticonvulsants and antibiotics. Data Sources: Computerized searches of OVID MEDLINE, OVID EMBASE, Cochrane Clinical Trials Register to August 2013 and hand searching of references of retrieved articles and proceedings of meetings; associated reference lists; and articles identified by experts in the field. Study Selection: Inclusion criteria were as follows: a) population- humans or animals undergoing therapeutic hypothermia b) design-prospective, randomized controlled trial, c) intervention-hypothermia; measurement of PD and PK of different drugs. Data Extraction: A data extraction form was used and authors (CB & SP) reviewed all trials. Data Synthesis: We reviewed 30 trials that documented changes in PD and PK of sedatives (propofol and midazolam), opioids (fentanyl, remifentanil, alfentil and morphine), anticonvulsants (phenytoin) and antibiotics (aminoglycosides) conducted in human or animal models undergoing therapeutic hypothermia. Conclusion: Data show that therapeutic hypothermia significantly alters the pharmacokinetics of commonly used agents. Particular care should be taken to reduce sedatives once target temperature is reached. Further clinical studies are required to clarify the effect of hypothermia on the PD and PK of therapeutic agents to optimize the benefits of therapeutic hypothermia in the treatment of TBI patients. © Bagna et al.",Related but unverifiable
s_1396,Contradiction,"While psychological morbidity is noted in cervical cancer, it is often overstated, suggesting that emotional support may not be as critical as implied .","Invasive cervical cancer remains the second commonest female malignancy worldwide. Early-stage disease may be asymptomatic. Advances in imaging techniques have improved selection of the appropriate treatment approach. Treatment options vary for each stage. An excisional cone is sufficient for treatment of micro-invasive disease (Ia1) provided the margins are clear. The management of stage Ia2 disease is more controversial. Surgery and radiation have similar survival rates for stage Ib-IIa disease, while the combination of both increases morbidity. Later stage tumours (IIb-IV) should be treated with chemoradiation as this is related to improved survival but also higher short- and medium-term toxicity in comparison to radiotherapy alone. Fertility-sparing surgical techniques such as radical trachelectomy may be appropriate in selected cases. Management of recurrent disease depends on the initial treatment, the individual characteristics and the presence of distant disease. Management of cervical cancer during pregnancy remains a challenge and appropriate counselling on individual patient basis is necessary. As the disease usually affects young women, psychological morbidity is significant and emotional support is essential. © 2013 Elsevier Ltd.",Opposite meaning
i_1286,Entailment,Interventions and Recommendations: Preventing bullying victimization can mitigate anxiety and depression among adolescents affected by poverty .,"South African children and adolescents living in HIV/AIDS-affected families are at elevated risk of both symptoms of anxiety and depressive symptoms. Poverty and HIV/AIDS-related stigma are additional risk factors for these negative mental health outcomes. Community level factors, such as poverty and stigma, are difficult to change in the short term and identifying additional potentially malleable mechanisms linking familial HIV/AIDS with mental health is important from an intervention perspective. HIV/AIDS-affected children are also at increased risk of bullying victimization. This longitudinal study aimed to determine whether prospective relationships between familial HIV/AIDS and both anxiety symptoms and depressive symptoms operate indirectly via bullying victimization. Adolescents (M = 13.45 years, 56.67 % female, n = 3,515) from high HIV-prevalent (>30 %) communities in South Africa were interviewed and followed-up one year later (n = 3,401, 96.70 % retention). Census enumeration areas were randomly selected from urban and rural sites in two provinces, and door-to-door sampling included all households with a resident child/adolescent. Familial HIV/AIDS at baseline assessment was not directly associated with mental health outcomes 1 year later. However, significant indirect effects operating via bullying victimization were obtained for both anxiety and depression scores. Importantly, these effects were independent of poverty, HIV/AIDS-related stigma, and baseline mental health, which highlight bullying victimization as a potential target for future intervention efforts. The implementation and rigorous evaluation of bullying prevention programs in South African communities may improve mental health outcomes for HIV/AIDS-affected children and adolescents and this should be a focus of future research and intervention.",Entailment
s_384,Entailment,"Key Technological Advancements: Business Intelligence (BI) and Decision Support Systems (DSS): The integration of BI and DSS into information systems has improved decision-making processes by providing comprehensive data analysis and reporting capabilities. This is particularly evident in healthcare systems, where such integration supports clinical decision-making and antimicrobial resistance surveillance .","Introduction: Neonatal intensive care units (NICUs) have complex patients in terms of their diagnoses and required treatments. Antimicrobial treatment is a common therapy for patients in NICUs. To solve problems pertaining to empirical therapy, antimicrobial stewardship programs have recently been introduced. Despite the success of these programs in terms of data collection, there is still inefficiency in terms of analyzing and reporting the data. Thus, to successfully implement these stewardship programs, the design of antimicrobial resistance (AMR) surveillance systems is recommended as a first step. As a result, this study aimed to design an AMR surveillance system for use in the NICUs in northwestern Iranian hospitals to cover these information gaps. Methods: The recommended system is compatible with the World Health Organization (WHO) guidelines. The business intelligence (BI) requirements were extracted in an interview with a product owner (PO) using a valid and reliable checklist. Following this, an AMR surveillance system was designed and evaluated in relation to user experiences via a user experience questionnaire (UEQ). Finally, an association analysis was performed on the database, and the results were reported by identifying the important multidrug resistances in the database. Results: A customized software development methodology was proposed. The three major modules of the AMR surveillance are the data registry, dashboard, and decision support modules. The data registry module was implemented based on a three-tier architecture, and the Clinical Decision Support System (CDSS) and dashboard modules were designed based on the BI requirements of the Scrum product owner (PO). The mean values of UEQ measures were in a good range. This measures showed the suitable usability of the AMR surveillance system. Conclusion: Applying efficient software development methodologies allows for the systems' compatibility with users' opinions and requirements. In addition, the construction of interdisciplinary communication models for research and software engineering allows for research and development concepts to be used in operational environments.
[4]: Abstract Background: Effective implementation of a Primary Care Medical Home model of care (PCMH) requires integration of patients' contextual information (physical, mental, social and financial status) into an easily retrievable information source for the healthcare team and clinical decision-making. This project explored clinicians' perceptions about important attributes of contextual information for clinical decision-making, how contextual information is expressed in CPRS clinical documentation as well as how clinicians in a highly computerized environment manage information flow related to these areas. Methods: A qualitative design using Cognitive Task Analyses and a modified Critical Incident Technique were used. The study was conducted in a large VA with a fully implemented EHR located in the western United States. Seventeen providers working in a PCMH model of care in Primary Care, Home Based Care and Geriatrics reported on a recent difficult transition requiring contextual information for decision-making. The transcribed interviews were qualitatively analyzed for thematic development related to contextual information using an iterative process and multiple reviewers with ATLAS@ti software. Results: Six overarching themes emerged as attributes of contextual information: Informativeness, goal language, temporality, source attribution, retrieval effort, and information quality. Conclusions: These results indicate that specific attributes are needed to in order for contextual information to fully support clinical decision-making in a Medical Home care delivery environment. Improved EHR designs are needed for ease of contextual information access, displaying linkages across time and settings, and explicit linkages to both clinician and patient goals. Implications relevant to providers' information needs, team functioning and EHR design are discussed.",Entailment
i_182,Contradiction,"Deep Learning for Optimization: Deep learning techniques can be applied to optimize various aspects of VLSI design, including placement layout and routing .","The electronic industry has developed quickly in last few years, with the rapid growth of Very Large Scale Integration technology. Placement layout is considered as the original step in VLSI physical design. The rectilinear embedding, which originates from graph theory, has wide range of application in VLSI placement. In this paper, we constructed a mathematical model for VLSI placement. Firstly, the VLSI placement was converted to quadrangulation by using rectilinear embedding speculative knowledge. Then we provided generating functions for two types of quadrangulations with graph multiple parameters. And the explicit formulae were obtained by employing Lagrangian inversion. Furthermore, we found the relationship between outerplanar graph and Hamilton graph, so the counting result of Hamilton quadrangulation was derived. The quadrangulation calculation can be applied to the establishment of arithmetical algorithms, which can be widely used in the optimization of VLSI placement. © (2013) Trans Tech Publications, Switzerland.",Missing information
s_1525,Entailment,"Tannin Levels: Impact of Processing: Similar to phytates, the processing of barley through methods like pearling, malting, and fermentation can significantly reduce tannin levels. These methods help in improving the nutritional quality by decreasing the concentration of anti-nutritional factors .","Purpose: Pearl millet (Pennisetum glaucum) is a rich source of nutrients as compared to the major cultivated cereal crops. However, major factors which limit its utilization are the presence of anti-nutritional factors (phytate, tannins and polyphenols) which lower availability of minerals and poor keeping quality because of higher lipase activity. Therefore, this paper aims to focus on the impact of different processing methods on the nutrient composition and anti-nutritional components of pearl millet. Design/methodology/approach: This is a literature review study from 1983 to 2017, focusing on studies related to pearl millet processing and their effectiveness in the enrichment of nutritional value through reduction of anti-nutritional compounds. Findings: From the literature reviewed, pearl millet processing through various methods including milling, malting, fermentation, blanching and acid as well as heat treatments were found to be effective in achieving the higher mineral digestibility, retardation of off flavor, bitterness as well as rancidity problems found during storage of flour. Originality/value: Through this review paper, possible processing methods and their impact on the nutrient and anti-nutrient profile of pearl millet are discussed after detailed studied of literature from journal articles and thesis.",Entailment
i_1588,Entailment,"Environmental Impacts on Marine Life: Benthic Environment: The installation of wind turbines will inevitably alter the seabed's morphodynamics, significantly affecting sediment transport and hydrodynamic conditions. This will almost certainly lead to drastic changes in the benthic habitat, severely impacting biodiversity, biomass, and nutrient regeneration .","Global-scale environmental degradation and its association with nonrenewable fossil fuels have led to an increasing interest in generation of electricity by renewable energy resources (Gill 2005). Since the planning of large offshore wind energy facilities in the German Bight and the Baltic Sea was initiated, concerns about the ecological compatibility of these structures have been expressed. Apart from direct impacts of disturbance during construction, operational sounds and rotating parts, which might primarily affect birds, bats, marine mammals and fish, the potential long term effects on the benthic environment have been discussed. These concerns are mainly focused on the questions, whether and how the natural benthic habitat in the vicinity of the constructions is modified by changes in bottom currents and turbulence, and whether the effects of the installations as artificial settling substrates are properly assessed. The ecologically relevant effects of offshore wind parks include e.g., increased habitat heterogeneity, and changes in hydrodynamic conditions and in sediment transport patterns. The potential ecological response of the macrozoobenthos could involve long-term changes in diversity, abundance, biomass, community structure and such functional properties as nutrient regeneration or bio-turbation. These problems have been in the focus of a project in the western Baltic which that was part of a national combination of projects called BeoFINO.1 This effort has addressed the overall ecological risks of offshore wind-power facilities in the North and Baltic Seas. Such questions are most often viewed in the primary context of the effects on the biodiversity of the benthic community. In the Baltic Sea however, the specific hydrographical conditions emphasizes a problem which also involves the absolute biomass accumulation rates of epifauna on substrates that protrude into the surface mixed layer. Particularly in the inflow areas of denser, more saline North Sea water adjacent to the Belt Sea and the Danish Sound, severe vertical stratification between the surface mixed layer and the bottom water overlying the sediments is the rule rather than the exception. The stratification is much more stable than in the North Sea, as tidal mixing is not an effective source of vertical exchange in the Baltic. Surface productivity is high in these areas, at least partly due to anthropogenic eutrophication, and as the density gradient does not constrain organic particles from sinking into deeper water, but prevents dissolved oxygen from mixing downwards, these benthic areas are extremely susceptible to oxygen deficiency. The increase of benthic biomass due to enhanced nutrition over the past 50 years (Karlson et al. 2002) has already aggravated the problem of unbalanced oxygen supply and consumption. In Baltic estuaries with a similarly strong stratification regime, bottom anoxia events have been documented (e.g. Powilleit and Kube, 1997), with destructive wide-ranging effects on benthic ecosystems and such associated economies as fishing, tourism and recreation. Additional point sources of organic matter to the sedimentary systems in such areas may initiate local cores of anoxia, which then start to spread over larger areas in an exponential fashion, when the suffocated benthic biomass is itself subject to microbial decomposition and oxygen demand. This scenario is particularly alarming, as most projected wind parks in the western Baltic are planned to be positioned exactly in the areas of most intense vertical stratification, either in the Pomeranian Bight at the estuarine stratification of the Oder plume, or at Kriegers Flak at the outlet and subduction area of dense saline water from the Danish Sound. As these environments are extremely sensitive to the input of additional organic matter, the export of benthic biomass from the higher parts of structures to the surrounding sediments became a relevant aspect in the study. Recent studies on ecological impacts of offshore wind farms on the benthic ecosystems are rare and mainly published as reports (e.g. Birklund and Petersen 2004, Leonard and Pedersen 2004 et al. cited in Gill 2005). Within the present study, both qualitative and quantitative aspects of benthic growth dynamics in the western Baltic at an artificial pile model were investigated. A delay in the construction of a full size research platform in the key area of Kriegers Flak led to the installation of a reduced size model pile in the region of Darss Sill, which is an area restricted to research. Over a period of two years, larval settling dynamics, biomass development and a succession of benthic organisms was observed at and around this pile, as well as on additional artificial settling substrates throughout the water column. The presence of an adjacent autonomous monitoring station that registers and logs such basic environmental data as salinity, temperature and currents supported the interpretation of the results. © Springer-Verlag Berlin Heidelberg 2006. All rights are reserved.
[5]: The need for sustainable energy is rising, and at the moment wind energy is one of the few forms of renewable energy that can be harvested efficiently.We investigated the influence of an offshore wind farm on the large-scale morphodynamics of the seabed.To this aim, we developed a morphodynamic model to investigate the effect of offshore wind farms on the seabed. By implementing the model in a GIS environment, the model allows us to calculate the effects of a wind farm using location specific and park design input parameters. By implementing an analytical model in a GIS, a rapid calculation of the effects of an offshore wind farmat a certain location in the North Sea can be made. © 2008 Taylor & Francis Group, London.",Entailment
s_347,Entailment,"They can capture and isolate malicious activities, providing valuable insights into sniffing tools and techniques used by attackers .","It has been proved being cumbersome and ineffective to prevent attacks in computer networks. However, the detection strategies have been found to be effective and less costly. The use of Intrusion Detection Systems (IDS) as a detection technique has been widely implemented in computer networks. Meanwhile, there is another strategy can reduce the occurrence of network intrusion, namely Honeypot. Honeypot is a proactive defense technology, introduced by the defense side to change the asymmetric situation of a network attack and defensive game. Through the deployment of the honeypots, i.e. security resources without any production purpose, the defenders can deceive intruders to attack the honeypots, then capture and analyze the attack behaviors in order to understand the attack tools and methods, and to learn the intentions and motivations. The paper analyzed the characteristics and the harms of worm virus, put forward a kind of custom honeypot system. Which according to the intrusion detection, virtual honeypot and data mining technology, using guile address space technology for the purpose of capturing known worms, isolating and delaying the unknown worms scanning speed, and analyzes the log by data mining, update the intrusion detection system rules set, and make timely response and take defense.",Entailment
i_533,Entailment,"Key Setbacks in Self-Repairing Electronic Technologies: Skin-Inspired Electronics: Properties: Current electronic materials fail to replicate the properties of human skin, lacking stretchability, self-healing, and biodegradability. These materials are predominantly made from rigid metals and non-biodegradable substances .","ConspectusFuture electronics will take on more important roles in people's lives. They need to allow more intimate contact with human beings to enable advanced health monitoring, disease detection, medical therapies, and human-machine interfacing. However, current electronics are rigid, nondegradable and cannot self-repair, while the human body is soft, dynamic, stretchable, biodegradable, and self-healing. Therefore, it is critical to develop a new class of electronic materials that incorporate skinlike properties, including stretchability for conformable integration, minimal discomfort and suppressed invasive reactions; self-healing for long-term durability under harsh mechanical conditions; and biodegradability for reducing environmental impact and obviating the need for secondary device removal for medical implants. These demands have fueled the development of a new generation of electronic materials, primarily composed of polymers and polymer composites with both high electrical performance and skinlike properties, and consequently led to a new paradigm of electronics, termed ""skin-inspired electronics"".This Account covers recent important advances in skin-inspired electronics, from basic material developments to device components and proof-of-concept demonstrations for integrated bioelectronics applications. To date, stretchability has been the most prominent focus in this field. In contrast to strain-engineering approaches that extrinsically impart stretchability into inorganic electronics, intrinsically stretchable materials provide a direct route to achieve higher mechanical robustness, higher device density, and scalable fabrication. The key is the introduction of strain-dissipation mechanisms into the material design, which has been realized through molecular engineering (e.g., soft molecular segments, dynamic bonds) and physical engineering (e.g., nanoconfinement effect, geometric design). The material design concepts have led to the successful demonstrations of stretchable conductors, semiconductors, and dielectrics without sacrificing their electrical performance. Employing such materials, innovative device design coupled with fabrication method development has enabled stretchable sensors and displays as input/output components and large-scale transistor arrays for circuits and active matrixes. Strategies to incorporate self-healing into electronic materials are the second focus of this Account. To date, dynamic intermolecular interactions have been the most effective approach for imparting self-healing properties onto polymeric electronic materials, which have been utilized to fabricate self-healing sensors and actuators. Moreover, biodegradability has emerged as an important feature in skin-inspired electronics. The incorporation of degradable moieties along the polymer backbone allows for degradable conducting polymers and the use of bioderived materials has led to the demonstration of biodegradable functional devices, such as sensors and transistors. Finally, we highlight examples of skin-inspired electronics for three major applications: prosthetic e-skins, wearable electronics, and implantable electronics.",Entailment
s_1557,Entailment,"Veronica persica: Delphinidin glycosides are identified in the flowers, but not specifically in the nectar .","Glycosylation is one of the key modification steps for plants to produce a broad spectrum of flavonoids with various structures and colors. A survey of flavonoids in the blue flowers of Veronica persica Poiret (Lamiales, Scrophulariaceae), which is native of Eurasia and now widespread worldwide, led to the identification of highly glycosylated flavonoids, namely delphinidin 3-O-(2-O-(6-O-p-coumaroyl-glucosyl)-6-O-p-coumaroyl-glucoside)-5-O-glucoside (1) and apigenin 7-O-(2-O-glucuronosyl)-glucuronide (2), as two of its main flavonoids. Interestingly, the latter flavone glucuronide (2) caused a bathochromic shift on the anthocyanin (1) toward a blue hue in a dose-dependent manner, showing an intermolecular co-pigment effect. In order to understand the molecular basis for the biosynthesis of this glucuronide, we isolated a cDNA encoding a UDP-dependent glycosyltransferase (UGT88D8), based on the structural similarity to flavonoid 7-O-glucuronosyltransferases (F7GAT) from Lamiales plants. Enzyme assays showed that the recombinant UGT88D8 protein catalyzes the 7-O-glucuronosylation of apigenin and its related flavonoids with preference to UDP-glucuronic acid as a sugar donor. Furthermore, we identified and functionally characterized a cDNA encoding another UGT, UGT94F1, as the anthocyanin 3-O-glucoside-2″-O-glucosyltransferase (A3Glc2″GlcT), according to the structural similarity to sugar-sugar glycosyltransferases classified to the cluster IV of flavonoid UGTs. Preferential expression of UGT88D8 and UGT94F1 genes in the petals supports the idea that these UGTs play an important role in the biosynthesis of key flavonoids responsible for the development of the blue color of V. persica flowers. © 2010 Elsevier Ltd. All rights reserved.",Entailment
i_932,Unverifiable,"Safety and Comfort: Enhanced Safety Features: Modern vehicles are equipped with advanced safety systems, including automated driving technologies and vehicle-to-vehicle (V2V) communication, which help prevent accidents and improve road safety .","Vehicle-to-Vehicle (V2V) communication is an en-abler for improved traffic safety and congestion control. As for any wireless system the ultimate performance limit is determined by the propagation channel. A particular point of interest is the shadowing effect of large vehicles such as trucks and buses, as this might affect the communication range significantly. In this paper we present measurement results and model the propagation channel in which a bus acts as a shadowing object between two passenger cars. The measurement setup is based on a WARP FPGA software radio as transmitter, and a Tektronix RSA5106A real-time complex spectrum analyzer as receiver. We analyze the influence of the bus location and car separation distance on the large-scale path loss, shadowing, and small-scale fading. The main effect of the bus is that it is acting as an obstruction creating an additional 15-20 dB attenuation. A Nakagami distribution is found to describe the statistics of the small-scale fading, by using Akaike's Information Criterion and the Kolmogorov-Smirnov test. The distance-dependency of the path loss is analyzed, and a stochastic model is developed to reflect the impact. © 2014 IEEE.
[14]: Trucks are one of the most common modes of transport and they are operated in various road conditions. As a rule, all-wheel drive trucks are equipped with special systems and mechanisms to improve their off-road capability and overall efficiency. The usage of blocked mechanisms for power distribution is one of the most popular and effective ways to improve the off-road vehicle performance. However, the lock of differential may adversely affect the stability and control of vehicle because of the unobvious redistribution of reactions acting on wheels, which consequently leads to poor performance and safety properties. Problems of rational distribution of power in transmissions of all-wheel drive vehicles, as well as research in the field of improving directional stability and active safety systems are among the priorities in modern automotive industry. To study dynamics of a vehicle with wheel formula 6x6 a mathematical model of the vehicle was developed in an environment of LMS Amesim software package. The model includes the realization of the features of all major mechanical units of a vehicle: engine, transmission, suspension, drive wheels. Besides, the model takes into account the so called ""external"" dynamics of the vehicle and includes interaction of the wheels and pavement and implementation of possible changes in environmental conditions. With help of the mathematical model we have managed to estimate the trajectory and directional stability of all-wheel drive trucks with lockable differentials for different operating conditions. The results allowed us to develop the most effective, in terms of stability and control, algorithm for control of the power distribution system.",Related but unverifiable
s_1690,Contradiction,"They thrive in various habitats, including low to mid-elevation areas with alkaline soils, which are the only regions that exhibit higher phytochemical diversity .","To cope with environmental challenges, plants produce a wide diversity of phytochemicals, which are also the source of numerous medicines. Despite decades of research in chemical ecology, we still lack an understanding of the organization of plant chemical diversity across species and ecosystems. To address this challenge, we hypothesized that molecular diversity is not only related to species diversity, but also constrained by trophic, climatic, and topographical factors. We screened the metabolome of 416 vascular plant species encompassing the entire alpine elevation range and four alpine bioclimatic regions in order to characterize their phytochemical diversity. We show that by coupling phylogenetic information, topographic, edaphic, and climatic variables, we predict phytochemical diversity, and its inherent composition, of plant communities throughout landscape. Spatial mapping of phytochemical diversity further revealed that plant assemblages found in low to midelevation habitats, with more alkaline soils, possessed greater phytochemical diversity, whereas alpine habitats possessed higher phytochemical endemism. Altogether, we present a general tool that can be used for predicting hotspots of phytochemical diversity in the landscape, independently of plant species taxonomic identity. Such an approach offers promising perspectives in both drug discovery programs and conservation efforts worldwide.",Opposite meaning
s_1616,Entailment,"Species-Specific Information: Tripneustes gratilla: This edible sea urchin is believed to reproduce continuously throughout the year, although evidence suggests that gonad growth may not be as consistent as previously thought. Its population density is likely stable across different reef sites, despite indications of food availability and environmental conditions being influential .","The annual and lunar reproductive cycle of the widely distributed edible sea urchin Tripneustes gratilla (L) was examined through measurements of gonad index, histological examination of gametogenesis, and induction of spawning with KCl injections. The population density and morphological characteristics of urchins at Diani, Kanamai, and Vipingo reef lagoons were also studied as well as the effects of seawater temperature and light on reproduction. Gonad growth started early during the northeast monsoon and reached a peak in June at the beginning of the southeast monsoon followed by a sharp decrease in gonad size of 50% in July and August towards the end of the southeast monsoons. Histological examination of gonads, revealed many different stages of gametogenesis with gametes present throughout the year, indicating continuous reproduction. There was a significant relationship between gonad index and lunar day with spawning occurring between lunar day 7 and 21, but spawning was not in perfect synchrony in the population. The population density of urchins at each reef is variable from year to year and was highest on average at Vipingo. Urchins at Kanamai had the lowest gonad indices, the largest jaws and smallest individuals an indication of food limitation. The gonads (roe) of T. gratilla at all three sites, were perpetually 'runny' an attribute that is not suitable for urchin fisheries. Studies to develop techniques to improve roe quality are recommended. © Springer 2005.",Entailment
s_136,Contradiction,"Examples and Case Studies: India: Indian academic libraries are exploring the use of AI tools such as Google Assistant and text data mining, although awareness and adoption levels vary .","The main purpose of this paper is to assess and examine the possible application of Artificial Intelligence (AI) tools in Pakistani academic libraries, particularly those areas of library technical and library user services where AI could be applied in the near future. A secondary purpose is to bring the library perspective on AI to the forefront of the scholarly world. This is a self-exploratory study, in which a qualitative approach interview has been conducted with 10 chief librarians/library heads (5 public + 5 private sectors) from universities regarding their views on the adoption of artificial intelligence tools in Pakistani academic libraries. Results are tabulated in a descriptive format. Librarians are aware of AI technologies. Services based on Natural Language Processing (NLP) are used in libraries, e.g. Google Assistant, Voice Searching, and Google Translate. Pattern recognition methods, such as text data mining, are also used to retrieve library material and conduct online searching. Big data is accessed via services such as cloud computing, OneDrive, and Google Drive. There is a very low level of awareness of robotics and chatbots. This study provides librarians with suggestions as to how AI tools could be used in libraries which either have yet to adopt AI technologies or wish to implement more advanced tools. Pakistani library schools could collaborate with computer science departments to establish AI Labs in the respective library and information science (LIS) departments/libraries. AI challenges funding and technological skills are the key problem to implement with AI in the University Libraries.",Entity error
i_1922,Entailment,"Key Benefits Highlighted: Flexibility: Ecoinvent supports various LCA methodologies and can be adapted to different modeling principles, such as attributional and consequential LCAs, providing flexibility for researchers and practitioners .","Purpose: Version 3 of ecoinvent includes more data, new modeling principles, and, for the first time, several system models: the ""Allocation, cut-off by classification"" (Cut-off) system model, which replicates the modeling principles of version 2, and two newly introduced models called ""Allocation at the point of substitution"" (APOS) and ""Consequential"" (Wernet et al. 2016). The aim of this paper is to analyze and explain the differences in life cycle impact assessment (LCIA) results of the v3.1 Cut-off system model in comparison to v2.2 as well as the APOS and Consequential system models. Methods: In order to do this, functionally equivalent datasets were matched across database versions and LCIA results compared to each other. In addition, the contribution of specific sectors was analyzed. The importance of new and updated data as well as new modeling principles is illustrated through examples. Results and discussion: Differences were observed in between all database versions using the impact assessment methods Global Warming Potential (GWP100a), ReCiPe Endpoint (H/A), and Ecological Scarcity 2006 (ES'06). The highest differences were found for the comparison of the v3.1 Cut-off and v2.2. At average, LCIA results increased by 6, 8, and 17 % and showed a median dataset deviation of 13, 13, and 21 % for GWP, ReCiPe, and ES'06, respectively. These changes are due to the simultaneous update and addition of new data as well as through the introduction of global coverage and spatially consistent linking of activities throughout the database. As a consequence, supply chains are now globally better represented than in version 2 and lead, e.g., in the electricity sector, to more realistic life cycle inventory (LCI) background data. LCIA results of the Cut-off and APOS models are similar and differ mainly for recycling materials and wastes. In contrast, LCIA results of the Consequential version differ notably from the attributional system models, which is to be expected due to fundamentally different modeling principles. The use of marginal instead of average suppliers in markets, i.e., consumption mixes, is the main driver for result differences. Conclusions: LCIA results continue to change as LCI databases evolve, which is confirmed by a historical comparison of v1.3 and v2.2. Version 3 features more up-to-date background data as well as global supply chains and should, therefore, be used instead of previous versions. Continuous efforts will be required to decrease the contribution of Rest-of-the-World (RoW) productions and thereby improve the global coverage of supply chains.
[8]: Goal, Scope and Background. More and more national and regional life cycle assessment (LCA) databases are being established satisfying the increasing demand on LCA in policy making (e.g. Integrated Product Policy, IPP) and in industry. In order to create harmonised datasets in such unified databases, a common understanding and common rules are required. This paper describes major requirements on the way towards an ideal national background LCA database in terms of co-operation, but also in terms of life cycle inventory analysis (LCI) and impact assessment (LCIA) methodology. Methods. A classification of disputed methodological issues is made according to their consensus potential. In LCI, three main areas of dissent are identified where consensus seems hardly possible, namely system modelling (consequential versus attributional), allocation (including recycling) and reporting (transparency and progressiveness). In LCIA the time aspect is added to the well-known value judgements of the weighting step. Results and Discussions. It is concluded that LCA methodology should rather allow for plurality than to urge harmonisation in any case. A series of questions is proposed to identify the most appropriate content of the LCA background database or the most appropriate LCI dataset. The questions help to identify the best suited approach in modelling the product system in general and multioutput and recycling processes in particular. They additionally help to clarify the position with regard to time preferences in LCIA. Intentionally, the answers to these questions are not attributed to particular goal and scope definitions, although some recommendations and clarifying explanations are provided. Recommendations and Perspective. It is concluded that there is not one single ideal background database content. Value judgements are also present in LCI modelling and require pluralistic solutions; solutions possibly based on the same primary data. It is recommended to focus the methodological discussion on aspects where consensus is within reach, sensible and of added value for all parties. © 2006 ecomed publishers (Verlagsgruppe Hüthig Jehle Rehm GmbH).",Entailment
i_177,Entailment,"3. Hardware Implementation of ML Models: FPGA and ASIC Implementations: Frameworks that automate the creation of trained-classifier integrated circuits from datasets are likely to bridge the gap between ML model training and hardware design, although they may not always facilitate the development of customized, high-performance classifier chips .","This paper presents a novel framework that automates the creation of a trained-classifier integrated circuit from a dataset. The framework accepts a dataset in a comma-separated value format and performs several processing steps to create a trained model. After creating the model, the framework generates a tree-based machine learning classifier in two formats; Extensible Markup Language (XML) and Verilog. We use the XML representation to present the hierarchy of the generated tree and the Verilog code as a hardware description language representation of the trained model. Our framework uses the Verilog code as an input to a Field programmable Gate Array (FPGA) design validation flow. Then, we automate the Application Specific Integrated Circuit (ASIC) flow implementation and build a customized classifier integrated circuit. The novelty of the proposed framework lies in bridging the gap between machine learning model training and its hardware design when dealing with machine learning classifier's implementation. Our framework addresses several challenges related to the design automation and implementation of customized machine learning classifier chips from raw dataset files. We discuss these challenges in detail in this paper and explain how researchers can use our proposed framework to build low-cost, high-performance classifier chips. Our framework operates at 100 MHZ and achieves 80.79% average 10-fold cross-validation accuracy across five different datasets.",Entailment
s_1156,Entailment,Potassium: High Potassium Intake: A diet high in potassium is recommended to lower blood pressure. Potassium supplementation has been shown to correlate with reduced blood pressure levels . Potassium's role in counteracting the effects of sodium on blood pressure is well-documented.,"Objective: A diet low in sodium, high in potassium, and high in calcium is recommended to lower blood pressure. However, compliance with this diet is poor, probably because of dietary intake underestimation. Therefore, we compared electrolyte intake as estimated from dietary recall with a 24-h urinary excretion. Methods: Thirty-six patients (26 men and 10 women) with a mean age of 46 ± 8 y participated in the study. All participants had essential hypertension and were on no drug therapy (n = 20) or non-diuretic monotherapy (n = 16). Patients were instructed to consume a low-sodium (50 mmol/d), high-potassium (supplementation with 30 to 60 mmol/d), and high-calcium (1000 mg/d) diet. Compliance with the diet was assessed at baseline and then 1, 2, and 3 mo after starting the diet. Sodium, potassium, and calcium intakes were carefully estimated from patients' dietary recall and 24-h urinary collection. Results: Estimated sodium intake significantly correlated with 24-h urinary excretion (R = 0.43 P < 0.001). However, estimated sodium intake was lower than urinary sodium excretion by 34% at baseline and by 47% after 3 mo of dieting (P < 0.05). Estimated potassium intake correlated with 24-h urinary excretion. Estimated calcium intake significantly increased from 933 ± 83 mg/d to 1029 ± 171 mg/d (P < 0.05). Calcium intake derived from patients' recall far exceeded and only slightly correlated with 24-h urinary excretion (R = 0.23, P < 0.01). Conclusions: Patients tend to underestimate their sodium intake by 30% to 50%; therefore, urinary sodium excretion is more accurate to assess sodium intake. Thus, 24-h urinary sodium excretion should be used in clinical practice and in clinical trials, especially when dietary non-compliance is suspected. © 2005 Elsevier Inc. All rights reserved.",Entailment
s_1286,Entailment,"Oxidative Stress: Activation of pathways like the polyol and hexosamine pathways increases reactive oxygen species (ROS), leading to oxidative stress .","[9] Diabetes mellitus (DM) is associated with changes in the structure of the brain and deterioration of cognitive functions from mild to moderate according to neuropsychological testing. With the growing DM epidemic and the increasing number of people living to old age, cognitive dysfunctions associated with DM can have serious consequences for the future of public and practical health. Chronic hyperglycemia, severe episodes of hypoglycemia, and microvascular complications are important risk factors common for type 1 and type 2 diabetes. DM is also associated with structural and functional changes in the brain, which can be diagnosed by various types of magnetic resonance imaging (MRI) of the brain. In this review, we investigate studies conducted over the past two decades to improve the understanding of how DM effects the brain function and structure. We also describe the changes characteristic of type 1 and type 2 diabetes during standard MRI, functional MRI and proton magnetic-resonance spectroscopy (proton MRS) as well as their features.",Entailment
s_654,Unverifiable,"Data Analysis Strategies: Decision Trees: Implementing decision trees can model ambiguous and qualitative information, making it suitable for complex decision-making processes in risk allocation .","Risk allocation (RA) plays a critical role in privately financed infrastructure projects. Project performance is contingent on whether the adopted RA strategy is efficient. However, no mechanism was specifically designed to facilitate the risk allocation decision-making (RADM) process. Two theoretical frameworks based on the transaction cost economics (TCE) theory and on both the TCE and the resource-based view (RBV) of organizational capability, respectively, were thus adopted in this article. As conventional modeling techniques are not suitable for modeling RADM processes, which involve ambiguous and qualitative information, fuzzy inference systems (FISs) were developed, illustrated, and evaluated to model these frameworks. An industry-wide survey and rounds of expert consultation were conducted to collect data and generate fuzzy rules. It was found that both FISs are capable of reliably explaining the RADM process. In particular, the FIS based on both the TCE and the RBV theories performed more accurately and thus is more suitable for forecasting efficient risk allocation strategy. © 2009 Computer-Aided Civil and Infrastructure Engineering.",Related but unverifiable
s_2191,Entailment,"Alternative Testing Methods: In Vitro and In Silico Methods: To minimize animal testing, the EU encourages the use of in vitro (test tube experiments) and in silico (computer-simulated) methods for toxicity testing. These methods can effectively identify mutagenicity, carcinogenicity, and other toxicological endpoints .","Liverpool John Moores University and FRAME recently conducted a research project sponsored by Defra, on the status of alternatives to animal testing with regard to the European Union REACH (Registration, Evaluation and Authorisation of Chemicals) system for the safety testing and risk assessment of chemicals. The project covered all the main toxicity endpoints associated with the REACH system. This paper focuses on the prospects for using alternative methods (both in vitro and in silico) for mutagenicity (genotoxicity) and carcinogenicity testing - two toxicity endpoints, which, together with reproductive toxicity, are of pivotal importance for the REACH system. The manuscript critically discusses well-established testing approaches, and in particular, the requirement for short-term in vivo tests for confirming positive mutagenicity, and the need for the rodent bioassay for detecting non-genotoxic carcinogens. Recently-proposed testing strategies focusing on non-animal approaches are also considered, and our own testing scheme is presented and supported with background information. This scheme makes maximum use of pre-existing data, computer (in silico) and in vitro methods, with weight-of-evidence assessments at each major stage. The need for the improvement of in vitro methods, to reduce the generation of false-positive results, is also discussed. Lastly, ways in which reduction and refinement measures can be used are also considered, and some recommendations are made for future research to facilitate the implementation of the proposed testing scheme.
[5]: This paper presents an inventory of in silico screening tools to identify substance properties of concern under the European chemicals' legislation REACH. The objective is to support the selection and implementation of appropriate tools as building blocks within integrated testing strategies (ITS). The relevant concerns addressed are persistence, bioaccumulation potential, acute and long-term aquatic toxicity, PBT/vPvB properties ((very) persistent, (very) bioaccumulative, toxic), CMR (carcinogenicity, mutagenicity, reproductive toxicity), endocrine disruption and skin sensitisation. The inventory offers a comparative evaluation of methods with respect to the underlying algorithms (how does the method work?) and the applicability domains (when does the method work?) as well as their limitations (when does the method not work?). The inventory explicitly addresses the reliability of predictions of different in silico models for diverse chemicals by applicability domain considerations. The confidence in predictions can be greatly improved by consensus modelling that allows for taking conflicting results into account. The inventory is complemented by a brief discussion of socio-economic tools for assessing the potential efficiency gains of using in silico methods compared to traditional in vivo testing of chemical hazards. © 2013 Elsevier Inc.",Entailment
i_1914,Entailment,"Objectives of Using the ecoinvent Database in LCAs: Comprehensive and Transparent Data: The ecoinvent database is recognized for its comprehensive and transparent data, which is crucial for conducting detailed and reliable LCAs. This extensive data coverage helps in accurately assessing the environmental impacts of various products and processes .","[5] Life cycle assessment (LCA) has become widely recognized as an effective tool for assessing the resource use, environmental burdens, and human health impacts connected with the complete life cycle of products, processes, and activities. This systems approach enables decision-makers to identify environmental hot spots, as well as improve industrial systems without shifting burdens elsewhere. An LCA begins with a clearly stated goal. The goal helps to establish the study boundaries and guides the data collection efforts. The ISO standard provides a general framework for conducting an LCA, but it is open to much interpretation by the practitioner. LCAs can produce different results even if the same product seems to be the focus of the study. Numerous factors might account for such differences, including different goal statements, differ ent functional units, different boundaries, and different assumptions used to model the data. The UNEP/SETAC Life Cycle Initiative developed a guidance document for Organizational LCA, which provides guidance to enable organizations to more easily and more effectively apply ISO 14040 and ISO 14044 at the organizational level. [11] The interest in environmental assessments about agricultural processes is high and asks for tools for accurate impact evaluations. The methodology commonly used in these studies is the Life Cycle Assessment (LCA), of which the inventory phase (Life Cycle Inventory – LCI) is the essential and most complex step to fulfil, for agricultural productions in particular. The reason is that taking into account local variables such as soil texture and mechanical operative solutions for the agro-mechanical operations is difficult. The aim of this study was to perform a case study to quantify the environmental impacts through LCA of alternative ploughing solutions and to quantify the differences that occur when an analysis is fulfilled with inventories completed with two different tools. First, when a database furnishes average data (Ecoinvent) and, secondly, when the inventory is completed with a tool that considers local variables. In particular, the used new tool is ENVIAM (ENVironmental Inventory of Agricultural Machinery operations), which was developed to take into account local variables. Finally, a subsequent goal was to quantify the environmental impacts through LCA of alternative ploughing solutions. Using ENVIAM, mouldboard ploughs were compared with slatted ploughs and variables such as the number of ploughshares, the field shape ratio (i.e. the ratio of field length and width considering regular quadrangles) and soil texture differed. Fuel consumption and exhaust gases emissions were calculated as function of working time, engine load and European Standard Emissive Stage. The functional unit was ""1 ha tilled in a primary soil tillage operation appropriately and completely carried out"" and the International Reference Life Cycle Data System (ILCD) characterization method was used for the impact assessment. The most common implement present in Northern Italy, the 3 ploughshares mouldboard plough, was considered as baseline scenario. When working on medium texture soils, discrepancies with Ecoinvent were not negligible (less than 9% for Climate Change and Ozone Depletion). However, they resulted even 2–3 times higher for Particulate Matter and Mineral and Fossil Resources Depletion. Instead, when soil texture differed, dissimilarities were considerably higher. For example, Climate Change impact category ranged between −46.2% and +108.1% of the identified baseline case (with sandy and clay soils, respectively). [19] Supplying adequate human nutrition within ecosystem carrying capacities is a key element in the global environmental sustainability challenge. Life cycle assessment (LCA) has been used effectively to evaluate the environmental impacts of food production value chains and to identify opportunities for targeted improvement strategies. Dietary choices and resulting consumption patterns are the drivers of production, however, and a consumption-oriented life cycle perspective is useful in understanding the environmental implications of diet choices. This review identifies 32 studies that use an LCA framework to evaluate the environmental impact of diets or meals. It highlights the state of the art, emerging methodological trends and current challenges and limitations to such diet-level LCA studies. A wide range of bases for analysis and comparison (i.e., functional units) have been employed in LCAs of foods and diet; we conceptually map appropriate functional unit choices to research aims and scope and argue for a need to move in the direction of a more sophisticated and comprehensive nutritional basis in order to link nutritional health and environmental objectives. Nutritional quality indices are reviewed as potential approaches, but refinement through ongoing collaborative research between environmental and nutritional sciences is necessary. Additional research needs include development of regionally specific life cycle inventory databases for food and agriculture and expansion of the scope of assessments beyond the current focus on greenhouse gas emissions. © 2013 American Chemical Society.",Entailment
i_425,Unverifiable,"Intelligent Transportation: Cloud-based IoT solutions facilitate the management of vehicular networks, improving traffic flow and reducing congestion .","Internet of Things (IoT) and Vehicular Ad hoc NETwork (VANET) based clouds are two emerging technologies and offer myriad of new applications in many domains of smart cities including, but not limited to, smart infrastructure and intelligent transportation. Integration of these technologies will enrich the applications and services space that will eventually stimulate the proliferation of these technologies. Nonetheless, due to their different requirements, environments, and networking models, such integration will need definitions of new communication paradigms and frameworks. To fill the voids, in this paper, we propose an architectural framework to integrate vehicular clouds (VC) and IoT, referred to as IoT-VC, to realize new services and applications that include IoT management through vehicular clouds. We particularly focus on smart city applications controlled, managed, and operated through vehicular networks. This theoretical work provides initial insights into data management in such diverse paradigm with resource constrained environment. Furthermore, we also discuss research challenges in such integration that include data acquisition, data quality, security, privacy, coverage, and so forth. These challenges must be addressed for realization of IoT-VC paradigm.",Related but unverifiable
i_768,Contradiction,"Current State and Background of Cutting-Edge Fire Detection and Emergency Response Systems: Key Technologies and Approaches: Advanced Sensing Technologies: Millimeter Wave Technology: Systems like FireGuard use RF signals and deep learning to detect fires through walls and other occlusions, significantly reducing alarm latency .","Latencies, operating ranges, and false positive rates for existing indoor fire detection systems like smoke detectors and sprinkler systems are far from ideal. This paper explores the use of wireless radio frequency (RF) signals to detect indoor fires with low latency, through walls and other occlusions. We build on past research focused on wireless sensing, and introduce RFire, a system which uses millimeter wave technology and deep learning to extract instances of fire. We perform line-of-sight (LoS) and occluded non-LoS experiments with fire at different distances, and find that RFire achieves a best-result mean latency of 24 seconds when trained and tested in multiple environments. RFire yields at least a 4 times improvement in mean alarm latency over today's alarms.",Entity error
i_1920,Entailment,"Objectives of Using the ecoinvent Database in LCAs: Harmonization and Standardization: Ecoinvent contributes to the harmonization of LCA methodologies by providing standardized data that can be used globally, facilitating more consistent and comparable LCA studies .","Goal, Scope and Background. More and more national and regional life cycle assessment (LCA) databases are being established satisfying the increasing demand on LCA in policy making (e.g. Integrated Product Policy, IPP) and in industry. In order to create harmonised datasets in such unified databases, a common understanding and common rules are required. This paper describes major requirements on the way towards an ideal national background LCA database in terms of co-operation, but also in terms of life cycle inventory analysis (LCI) and impact assessment (LCIA) methodology. Methods. A classification of disputed methodological issues is made according to their consensus potential. In LCI, three main areas of dissent are identified where consensus seems hardly possible, namely system modelling (consequential versus attributional), allocation (including recycling) and reporting (transparency and progressiveness). In LCIA the time aspect is added to the well-known value judgements of the weighting step. Results and Discussions. It is concluded that LCA methodology should rather allow for plurality than to urge harmonisation in any case. A series of questions is proposed to identify the most appropriate content of the LCA background database or the most appropriate LCI dataset. The questions help to identify the best suited approach in modelling the product system in general and multioutput and recycling processes in particular. They additionally help to clarify the position with regard to time preferences in LCIA. Intentionally, the answers to these questions are not attributed to particular goal and scope definitions, although some recommendations and clarifying explanations are provided. Recommendations and Perspective. It is concluded that there is not one single ideal background database content. Value judgements are also present in LCI modelling and require pluralistic solutions; solutions possibly based on the same primary data. It is recommended to focus the methodological discussion on aspects where consensus is within reach, sensible and of added value for all parties. © 2006 ecomed publishers (Verlagsgruppe Hüthig Jehle Rehm GmbH).",Entailment
s_1098,Contradiction,"General Ultrasound Image Segmentation: Challenges in Ultrasound Imaging: Ultrasound images are often plagued by low contrast and speckle noise, which makes segmentation nearly impossible, as no effective methods currently exist .","Segmentation is a most important but difficult step in ultrasound image analysis. For the speckle noise and the tissue intensity inhomogeneities in the medical ultrasound images, the conventional segmentation approaches based on intensity or intensity-statistics do not work well. Current studies to reduce the speckle noise are failed in boundary preserving. And the researches on intensity inhomogeneites can not obtain the complete structure. In this paper, a new segmental method combined Markov random field (MRF) model with morphological image processing is proposed to cover the shortages above. MRF step is used to estimate the label image and morphological image processing makes the region-of-interest (ROI) complete to get a complete tissue. This algorithm is insensitive to speckle noise. Experimental results on synthetic images and ultrasound images show that this algorithm works successfully in MRF model and can correctly identify the tissues in the medical ultrasound images. © 2007 IEEE.
[4]: Segmentation of ultrasound images is a challenging task due to the lower contrast and the speckle noise. Active contour is one of the most widely used techniques for ultrasound image segmentation. This method has drawbacks such as the predefined initial curve position and the number of contour points to be considered. A new active contour segmentation for extracting the intima media layer and plaque in the Common Carotid Artery (CCA) ultrasound images is presented in this paper. This paper has proposed a fuzzy weighted graph based active contour segmentation technique to overcome all these drawbacks. The proposed method is used for segmenting Intima-Media Thickness (IMT) and plaque in common carotid artery B-mode ultrasound images to assess the risk of stroke in the human subject under investigation. Using canny edge detection and connected component analysis methods, the initial contour was determined and applied as input to the proposed active contour segmentation algorithm. The proposed algorithm was compared with five conventional methods. Experimental results prove that the proposed approach has produced better results than traditional methods. The overall probability of error achieved by the proposed algorithm was 5.28%, which was very less compared to other conventional methods.",Misrepresentation
i_833,Contradiction,"Gasoline engines, especially those using low octane fuels, tend to have lower HC emissions .","This paper studies the combustion and emission characteristics of three low octane fuels: naphtha, the blend of gasoline and diesel (G70D30), and the blend of gasoline and n-heptane (G70H30) in Multiple Premixed Compression Ignition (MPCI) mode. A commercial diesel fuel is also tested in conventional diesel combustion mode and double injection mode as a comparison. The study is carried out in a single cylinder diesel engine with a compression ratio of 16.7. By varying the common rail pressure, the effect of injection pressure on combustion and emissions is investigated.The results illustrate that the combustion delay of the gasoline-type fuels is extended with the increase of injection pressure. The soot emission decreases at high injection pressure with a penalty of higher CO and HC emissions. Increasing the injection pressure also reduces the particle number in accumulation mode, but produces more in nucleation mode. Among the test fuels, naphtha has the lowest NO<inf>x</inf> emission due to low combustion temperature but the highest CO and HC emissions. There is no significant difference in particle size distribution for the three fuels. The indicated thermal efficiency of gasoline-type fuels increases with the rise of injection pressure and is higher than that of diesel at high injection pressure. Naphtha has the highest efficiency as a result of its low heat transfer and exhaust loss.The diesel fuel has lower CO and HC emissions than the gasoline-type fuels do, but much higher pressure rise rate, NO<inf>x</inf> and soot emissions due to high combustion temperature and poor premixing. Therefore, the low octane gasoline fuels are more suitable than the diesel for compression ignition engines in terms of the emissions.",Opposite meaning
i_1412,Unverifiable,"Management and Prevention: Supplementation: Regular monitoring and supplementation of essential nutrients like zinc, selenium, and vitamins are crucial for preventing skin lesions in obese individuals, especially those who have undergone bariatric surgery .","Bariatric surgery leads to a significant body weight reduction, and improvement of obesity-related comorbidities. However, it is associated with a higher risk of presenting some nutritional deficiencies. These deficiencies are especially relevant after mixed or malabsorptive procedures. Deficiencies in micronutrients after bariatric procedures are a known threat if not corrected appropriately. Though zinc deficiency is not considered among the most frequent deficiencies after bariatric surgery, several studies have shown that its frequency might overcome 10%, even after restrictive procedures and in patients with multivitamin supplements intake.Zinc is the second most prevalent trace found in the human body after iron. It is essential for normal cell function and metabolism, playing a central role in over 300 enzymatic reactions, and protects cells from free radical damage. The central role of zinc in cell growth and differentiation explains the dramatic effect of zinc deficiency in tissues with a rapid cell turnover such as hair growth. In recent years much interest has been generated by the possibility that subclinical zinc deficiency may significantly increase the incidence of and morbidity and mortality from diarrhea and upper respiratory tract infections. Clinical manifestations of zinc deficiency include delayed sexual maturation, impotence, hypogonadism, oligospermia, alopecia, dysgeusia, immune dysfunction, night blindness, impaired wound healing, and various skin lesions. After bariatric surgery, zinc deficiency is often associated with other micronutrients deficiencies, mainly iron. It has been demonstrated that zinc and iron levels, both within the normal range, but close to the minimum level of the range, can be associated with hair loss, mainly between the 6th and 9th postoperative month. For the evaluation of zinc status, plasma levels are generally a good index of zinc status in healthy individuals. Zinc supplements are usually indicated for patients with low zinc levels, depending upon the clinical context. In obese patients after bariatric surgery, zinc supplementation can be considered even in patients with serum levels within the normal range, when iron levels are also close to the minimum value of normality and the patient complain of alopecia.
[5]: The increasing prevalence of morbid obesity is associated with an increase of obesity surgery and metabolic surgery as well. Several surgical and especially metabolic problems after restrictive and malabsorptive bariatric procedures will be noted in these patients. Restrictive bariatric procedures are associated with pouch dilatation or band migration after gastric banding or a severe reflux disease after sleeve gastrectomy. The most commonly deficiencies after restrictive procedures are deficiencies of B-vitamins. Iron, folate, vitamin B1 and B12 and vita-min D deficiencies are associated with the malabsorptive procedure like biliopancreatic diversion, duodenal switch and Roux-en-Y-gastric bypass. Patients who have undergone bariatric surgery require medical follow-up lifelong for reasons that are often determined by the type of surgical procedure performed. The majority of this report will deal with the metabolic problems associated with the bariatric procedures. Patients should be carefully screened and encouraged to consume vitamin and mineral supplementation after surgery, immediately. © 2012.",Related but unverifiable
s_658,Contradiction,Data Analysis Strategies: Empirical Testing: Conducting empirical tests such as the Kruskal-Wallis test can help in identifying significant differences in risk perceptions among different stakeholder groups .,"Earlier research studies on public-private partnership (PPP) indicated that an objective, reliable, and practical risk assessment model for PPP projects and an equitable risk allocation mechanism among different parties are crucial to the successful implementation of these PPP projects. However, actual empirical research works in this research area are limited. This paper reports the first stage of a research study, which aims to identify and assess the principal risks for the delivery of PPP projects in China and to address their proper risk allocation between the private and public sectors. An empirical questionnaire survey was designed to examine the relative importance of different risk factors and to analyze the allocation of risk factors to different parties in PPP projects. A total of 580 questionnaires were sent out, and a total of 105 valid responses were obtained for data analysis. The Mann-Whitney U test is employed to investigate whether significant difference in perception existed first between the private and public sectors and second between industrial practitioners and academics in China. The empirical findings show that the three most important risk factors for PPP projects in China are (1)government intervention; (2)government corruption; and (3)poor public decision-making processes. These findings reveal that the Chinese government intervention and corruption may be the major obstacles to the success of PPP projects in China. A major cause for these risks may be attributed to inefficient legislative and supervisory systems for PPP projects in China. After conducting the Mann-Whitney U test on the 105 survey respondents, the empirical findings indicate that the perceptions of all 34 risk factors in China between the private and public sectors were not significantly different. Similarly, there were no significant differences between academics and industrial practitioners except that the former perceived the problem of government corruption to be more severe than did the latter. For risk allocation, the empirical results indicate that the public and private sectors were in general consensus with most of the risks identified. The major risks that the public sector preferred to accept are within the systematic risk category, especially political, legal, and social risks. The private sector preferred to retain the principal risks within the specific project risk category, especially construction, operation, and relationship risks, in addition to economic risks within systematic risk category. The remaining risk, environment risk, is preferred to be shared between the two sectors. This research study enables international construction companies to better understand how risks should be assessed and allocated for PPP projects in China. It also assists in risk response planning and control for future PPP projects in China. © 2011 American Society of Civil Engineers.",Entity error
i_1002,Unverifiable,"Network Efficiency: By splitting the optical signal, splitters help in optimizing the use of optical fibers, reducing the need for multiple light sources and simplifying the network design. This is particularly useful in passive optical networks (PONs) where the splitter can distribute the signal to multiple endpoints without the need for active components .","In this paper, we introduce a new optical device to replace the 1xN Optical Splitter in passive optical network (PON) to increase the performance of an optical network system in scattered topology. Multi Ratio Optical Splitter (MROS) was developed to increase the signal performance of the network system for customer of different distance. The performance of the network system will be evaluated by its eye diagram and amplitude of the jitter that has been extracted from its eye diagram. For comparison purpose with MROS, a conventional 1×4 Optical Splitter will be used as a benchmark to see the signal quality. MROS was designed using device designing tools that based on beam propagation method (BPM) and integrated into network design simulator for test. Simulation result shows that MROS with the highest ratio gives the widest eye opening of eye diagram. Value of jitter extracted from these eye diagrams supporting this result when it produce jitter with amplitude as low as 0.031 UI compare to conventional 1×4 Splitter with 0.61 UI.",Related but unverifiable
i_2341,Unverifiable,"Dietary Adjustments: Substituting corn meal with cactus pear in the diet of lactating goats has been shown to increase DMI exponentially while reducing water intake linearly . This indicates that certain dietary components can influence both water and dry matter intake, potentially due to the high moisture content in cactus pear reducing the need for additional water consumption.","This study evaluated the effect of substituting corn meal with cactus pear (Opuntia ficus-indica L. Miller) on water intake of dairy goats during lactation. Ten goats (Saanen, n = 5; Alpine, n = 5) were distributed in two 5 × 5 Latin squares according to breed. Ration consisted of 50% hay and 50% concentrate in which corn meal was replaced by increasing levels of cactus pear (0, 7, 14, 21 and 28% DM). Milk production, feed intake, dry matter (DM) intake, weight gain, water intake and water intake from cactus pear were evaluated. There were no differences (P > 0.05) between breeds or interaction breed × treatment for the evaluated variables. Cactus pear levels had no effect on milk production; however, there was a linear reduction of milk fat with increasing cactus pear levels (P < 0.01). Increasing levels of cactus pear in the diet increased dry matter intake according to an exponential equation (P < 0.001; R<sup>2</sup> = 0.81) and fresh matter intake increased linearly (P < 0.01; R<sup>2</sup> = 0.99); mean values ranged from 1.95 to 2.31 kg/d and 2.03 to 13.48 kg/d, respectively. On the other hand, water intake was markedly reduced in a linear manner due to cactus pear addition to the diet (P < 0.01). Cactus pear may substitute corn meal in the diet of lactating goats without affecting milk production negatively, and may be an important resource to reduce water intake in dairy goats. © 2009 Elsevier B.V. All rights reserved.",Related but unverifiable
s_319,Entailment,"The integration of AI in software engineering has also been seen in specific applications like video games and word processing, where AI enhances user experience and functionality .","The impact of artificial intelligence (AI) on the computer software development and the practice of engineering is discussed. The industrial impact of AI has primarily been in control and diagnosis-type applications. AI knowledge representation techniques have largely influenced the work on ontologies, resource description framework (RDF) and web ontology language (OWL). AI is also been increasingly used in the field of video game and the word processing fields which is among the most widely used applications of computers.",Entailment
s_1528,Contradiction,"Key Functions of PHT4: Regulation of Phosphate Homeostasis: PHT4 transporters help maintain phosphate homeostasis by regulating the internal phosphate pool. This regulation is crucial for preventing phosphate deficiency, which can lead to significant reductions in biomass and yield .","Arabidopsis (Arabidopsis thaliana) absorbs inorganic phosphate (Pi) from the soil through an active transport process mediated by the nine members of the PHOSPHATE TRANSPORTER1 (PHT1) family. These proteins share a high level of similarity (greater than 61%), with overlapping expression patterns. The resulting genetic and functional redundancy prevents the analysis of their specific roles. To overcome this difficulty, our approach combined several mutations with gene silencing to inactivate multiple members of the PHT1 family, including a cluster of genes localized on chromosome 5 (PHT1;1, PHT1;2, and PHT1;3). Physiological analyses of these lines established that these three genes, along with PHT1;4, are the main contributors to Pi uptake. Furthermore, PHT1;1 plays an important role in translocation from roots to leaves in high phosphate conditions. These genetic tools also revealed that some PHT1 transporters likely exhibit a dual affinity for phosphate, suggesting that their activity is posttranslationally controlled. These lines display significant phosphate deficiency-related phenotypes (e.g. biomass and yield) due to a massive (80%–96%) reduction in phosphate uptake activities. These defects limited the amount of internal Pi pool, inducing compensatory mechanisms triggered by the systemic Pi starvation response. Such reactions have been uncoupled from PHT1 activity, suggesting that systemic Pi sensing is most probably acting downstream of PHT1.",Entity error
i_1743,Entailment,Summary: The reduction in NDVI for grass and shrubs during the dry season can be attributed to several interrelated factors: Decreased soil moisture due to reduced precipitation and increased drought conditions .,"Temperature Vegetation Dryness Index (TVDI) is an important tool that reflects agriculture dry situation by inverting soil moisture. The changes of energy balance and vegetation index are two main factors to influence the precision of the TVDI. The MODIS (Moderate....) data products, as RVI (Ratio Vegetation Index), NDVI (Normalized Difference Vegetation Index), EVI(Enhanced Vegetation Index), MSAVI(Modified Soil Adjusted Vegetation Index), and Ts(Land Surface Temperatures), are applied and the DEM (ASTER-GDEM) data are used to correct the Ts data for the reduction of the topographic influences by topographic relief. The TVDI is then employed by comparison of different vegetation index, where the TVDI is more sensitive to soil moisture. Thus the dry situation in the study area is analyzed during the plant growth time and compared by the synchronous meteorology data. The results indicate that: (1) terrain correction can effectively prevent the decrease of TVDI value from a lower surface temperature for a higher pixel. The correlation between Ts-NDVI index and measured values on May is compared, R<sup>2</sup> will increase from 0.4634 to 0.5859 by terrain correction. It shows that the terrain corrected TVDI can improve effectively the estimation of soil moisture. (2) By comparing the correlation between Ts -NDVI, T<inf>s</inf> -EVI, T<inf>s</inf> -RVI, T<inf>s</inf> -MSAVI and soil moisture, all the TVDIs present the negative correlations with soil moisture. The best correlations between the soil moisture and TVDIs can be always found, such as T<inf>s</inf> -MSAVI in June, July and September 2005, T<inf>s</inf> -EVI in May, and T<inf>s</inf> -NDVI in August. Thus a TVDI feature space for different periods by these vegetation indexes are built for inversion of drought conditions. By comparison with agricultural meteorology, the results are acceptable. (3) Large area of the study area was humid from May to September 2005, drought occurred in the West on August, and humid was located in East on June. Therefore, compared with the measured data, the terrain corrected TVDI model is robust to eliminate the terrain and land cover influences to land surface temperature for inversion of soil moisture in the study area. And it is faithful to predict the agricultural drought condition in the study area during 2005 crop growth season.
[2]: The objective of this study is to assess the influence of drought on vegetation vigour. The correlation analysis based on different vegetation type was conducted between monthly NDVI and Palmer Drought Severity Index (PDSI) during the growing season within the Laohahe catchment. It was found that NDVI had good correlation with the PDSI, especially for shrubs and grasses. The correlation between NDVI and PDSI varies significantly from one month to another. The influence of drought on vegetation vigour is stronger in the first half of the growing season before the vegetation reaches its peak greenness. In order to take the seasonal effect into consideration, a regression model with seasonal dummy variables was used to simulate the relationship between the NDVI and PDSI. The results showed that the NDVI-PDSI relationship was significant (α = 0.05), and that NDVI was an effective indicator to monitor and detect droughts if seasonal timing was taken into account. Copyright © 2009 IAHS Press.
[3]: Precipitation is one of the important factors that influences vegetation growth and distributions. Using GF-1 remotely sensed images and observed precipitation data, this paper discusses the response relationship between the normalized difference vegetation index (NDVI) and the standardized precipitation index (SPI) in Hutubi County at different time scales from January to December, 2014. The results show that: (1) From a macro point of view, NDVI has obvious geographical characteristics, the Central Plains region has the highest NDVI values; whereas mountains and hills in the southern region and deserts in the northern region have relatively low NDVI values. (2) There is a clear changing trend in the area of vegetation cover. (3) The SPI randomness decreases but the SPI persistence increases with increment in time scales. The sensitivity of the SPI to precipitation is different at different time scales. (4) The SPI has a good correlation with NDVI at six-months time scale. (5)The overall distributions of both basically have the same shape and trendwithhigher SPI values in April and May, and higher NDVI are from June to August. This confirms the lag-time of precipitation influence on vegetation.",Entailment
s_1969,Contradiction,"Methods for Assigning Weights to Environmental Factors: Fuzzy Logic Modeling: Description: Fuzzy logic can be used to model habitat suitability by defining fuzzy sets for environmental variables and creating rules based on expert knowledge. Application: This approach was used to develop habitat suitability indices for Atlantic salmon, considering variables like depth, substrate size, and velocity . A similar fuzzy logic model can be developed for skipjack tuna, incorporating SST, Chl-a, and other relevant factors.","Many tools have been developed to evaluate environmental flows, including physical microhabitat models like PHASBIM and HABSCORE, which require habitat suitability curves. Unfortunately, the models and curves are often used in stream-specific applications and are rarely easily exportable. With the aim to address this shortcoming, we developed several habitat suitability indices sets for three Atlantic salmon (Salmo salar) life stages (young-of-the-year (YOY), parr, spawning adults) with the help of fuzzy logic modeling. Using the knowledge of twenty-seven experts, from both sides of the Atlantic Ocean, we defined fuzzy sets of four variables (depth, substrate size, velocity and Habitat Suitability Index, or HSI) and associated fuzzy rules. When applied to the Romaine River (Canada), median curves of standardized Weighted Usable Area (WUA) were calculated and a confidence interval was obtained by bootstrap resampling. Despite the large range of WUA covered by the expert WUA curves, confidence intervals were relatively narrow: an average width of 0.095 (on a scale of 0 to 1) for spawning habitat, 0.155 for parr rearing habitat and 0.160 for YOY rearing habitat. In addition, Student's t-test showed significant differences in predicted HSI between presence and absence, for parr and YOY, and RM_ANOVA showed significant differences for parr only. When considering an environmental flow value corresponding to 90% of the maximum reached by WUA curve, results seem acceptable for the Romaine River. Generally, this proposed fuzzy logic method seems suitable to model habitat availability for the three life stages, while also providing an estimate of uncertainty in salmon preferences. © 2013 Elsevier B.V.",Misrepresentation
i_1676,Entailment,Integration and Optimization: Combining BES with nanomaterials and other treatment technologies can enhance overall efficiency. Computational Fluid Dynamics (CFD) can optimize reactor configurations and improve performance .,"Human progress has promoted major technological challenges. The increasing generation of effluents, for example, requires efficient solutions in order to establish sustainable development. Various processes can be adopted for the treatment of organic effluents, including the Conventional Activated Sludge Systems (CAS) and its variants, UASB reactors, Membrane Biological Reactors (MBRs) and Sequencing Batch Reactors (SBRs) [22]. Anaerobic fluidized bed reactors have aroused greater interest since the 1980s. Fluidized bed bioreactors are characterized by the biocatalytic use of immobilized enzymes or microbial cells. The immobilization method most commonly used in wastewater treatment in a fluidized bed refers to the attached growth technique for microbial cells, and involving the growth of a biofilm (cell layers and excreted sludge) on the surface of each carrier particle during the course of fluidization. The growth of biofilm on the carrier particles changes its size, effective density, and surface properties - and, as a consequence, its fluidization characteristics [25]. The fluidization regime is maintained by the drag force associated with the upward movement of the effluent. The maintenance of fluidized beds requires a control of the superficial velocity of the effluent, which depends on the characteristics of the bioparticle - which, in turn, are altered as the microbial community evolves. Thus, in addition to the difficulties related to the maintenance of healthy cultures, as in other processes, there are also difficulties in maintaining the fluidized bed, which makes this one of the most complex processes available for wastewater treatment [22]. Due to the constant velocity along the height, the conventional anaerobic bioreactors can drag the particles out of the reactor (washout) [12], when these particles have their density changed due to the accumulation of biofilm on their surface. On the other hand, fluidized beds in tapered bioreactors (TBR) offer as an additional advantage the decrease of the ascending velocity along the height. This naturally prevents the bioparticle from being carried out of the bioreactor. To optimize the configuration of reactors, and consequently to improve their performance, it is essential to know the dynamics of the phases in their interior. In this sense, Computational Fluid Dynamics (CFD) offers several advantages. This technique is used to simulate phenomena involving moving fluids [4], and is able to simulate reactors in fluidized bed [10]. In these situations, numerical techniques have the advantage of establishing precise values for the process parameters [16]. With the application of CFD techniques, industrial equipment can be simulated using models based on thermodynamics, hydrodynamics and reaction kinetics. Processes can be visualized through simulation results before performing full scale experiments, saving time and reducing costs [23]. In the simulation of multiphase reactors, attention must be given to the modeling of the phenomena present. In gas-solid flows, for example, where the dispersed phase has a specific mass much higher than the continuous phase, the dominance of the drag force on the other interfacial forces is verified. The turbulence also plays a key role, as well as the interactions between particles, which can be modeled considering the Kinetic Theory of Granular Flow (KTGF) [1, 3, 20]. For gas-liquid systems, where the dispersed phase has a much lower specific mass than the continuous phase, also observed the influence of forces such as the lift and the virtual mass [17, 18, 19]. In solidliquid systems, in which the properties of the phases are not so disparate, there is a lack of data regarding the magnitude of the acting forces. In simulations of these systems, solids were usually assumed to be spherical particles with the same diameter. However, in reality, biowaste particles may have unusual characteristics such as relatively large mean particle size, wide size distributions, and extreme shapes. The surface roughness of bioparticles can also affect the interfacial forces [8]. Such irregular particles need more research to correct the drag force and solid stress models for reducing uncertainty [26]. There is a lack in literature of numerical studies on solid-liquid flows. Thus, the present study aims to numerically evaluate the performance of different models for analysis of the interfacial forces acting on these systems. Experimental data from the literature was used to simulate different operating conditions of a fluidized bed bioreactor, using the OpenFOAM code.",Entailment
s_923,Unverifiable,"Technical Advantages: Prosthetic hands are often designed to be lightweight, which enhances comfort and reduces fatigue for the user during prolonged use . Achieving optimal functionality while maintaining a manageable weight and size is a significant achievement.","Prosthetic hand is an artificial device which replaces human hand lost due to trauma or congenital. Prosthetic hand should be simple for a person with amputations to use and should contribute to their performance in grasping task. The prosthetic hands usually consist of a finger like and thumb like member to grip an object. A number of mechanisms are developed to provide the gripping like adaptive grasp system, cross four bar mechanism, six axis Southampton mechanism one way lock, variable force transmission mechanism, and six bar chain mechanism. The disadvantages of the present prosthetic hands are high weight of hand, backlash in the joint, poor function, noise, and less cosmetic appearance. To overcome the above disadvantages a new mechanism is introduced in which each finger compromises a number of spring and thread system. The springs act as a structure and joint for the finger. © 2014 Inderscience Enterprises Ltd.
[4]: Prosthetic hands are desired by those who have lost a hand or both hands not only for decoration but also for the functions to help them with their activities of daily living (ADL). Prosthetic robotic hands that are developed to fully realize the function of a human hand are usually too expensive to be economically available, difficult to operate and maintain, or over heavy for longtime wearing. The aim of this study is therefore to develop a simplified prosthetic hand (sim-PH), which is to be controlled by myoelectric signals from the user, to realize the most important grasp motions in ADL by trading off the cost and performance. This paper reports the structure design of a two-DoF sim-PH with two motors to drive the CM joint of the thumb and the interlocked MP joints of the other four fingers. In order to optimize the structure, the model of the sim-PH was proposed based on which 7 sim-PHs with different structural parameters were manufactured and tested in a pick-and-place experiment. Correspondence analysis of the experimental results clarified the relationship between the hand functions and the shapes of fingers.",Related but unverifiable
s_1407,Entailment,"Advantages of Learning Bumblebee Identification: Comparative Studies: Comparative bioassays and studies on different bumblebee species provide insights into their nutritional requirements and performance, which can be educational for beginners .","Bumblebees (i.e. Bombus genus) are major pollinators of flowering wild plants and crops. Although many species are currently in decline, a number of them remain stable or are even expanding. One factor potentially driving changes in bumblebee distribution is the suitability of plant communities. Actually, bees probably have specific nutritional requirements that could shape their floral choices and constraint them in the current context of global change. However, most studies primarily focus on one bumblebee species at a time, making comparative studies scarce. Herein we performed comparative bioassays on three bumblebee species (i.e. Bombus hypnorum, B. pratorum and B. terrestris) fed on three different pollen diets with distinct nutritive content (Cistus, Erica and Salix pollen diets). Micro-colony performance was compared through different developmental and resource collection parameters for understanding the impact of change in pollen diet on different bumblebee species. The evidence suggests that B. terrestris is by far the most competitive species because of its performance compared to the other species, regardless of pollen diet. Our results also highlight a Bombus species effect as pollen diet impacts the micro-colonies in different ways according to the actual bumblebee species. Such interspecific variation in Bombus performance in response to a dietetic change underlines the importance of considering different bumblebee species in mitigation strategies. Such comparative studies are good advice for developing appropriate suites of plant species that can benefit threatened species while supporting stable or expanding ones.",Entailment
s_2091,Contradiction,"Microbial Community Structure and Function: Microbial Stability: The introduction of certain substrates or conditions does not lead to significant shifts in the microbial community. For instance, the addition of poultry manure maintains a Bacteroidetes-dominated community, preserving the metabolic pathways used for methane production .","An anaerobic digestion experiment was investigated to evaluate the impact of increasing amounts of ammonium nitrogen due to poultry manure addition on the reactor performance, especially on the microbiome response. The microbial community structure was assessed by using a 16S rRNA gene approach, which was further correlated with the prevalent environmental conditions by using statistical analyses. The addition of 50% poultry manure led to a process disturbance indicated by a high VFA content (almost 10 g<inf>HAc-Eq</inf> L<sup>-1</sup>) in combination with elevated concentrations of ammonium nitrogen (5.9 g NH<inf>4</inf><sup>+</sup>-N kg<inf>FM</inf><sup>-1</sup>) and free ammonia (0.5 g NH<inf>3</inf> kg<inf>FM</inf><sup>-1</sup>). Simultaneously the microbiome, changed from a Bacteroidetes-dominated to a Clostridiales-dominated community accompanied by a shift from the acetoclastic to the hydrogenotrophic pathway. The ""new"" microbial community was functional redundant as the overall process rates were similar to the former one. A further increase of poultry manure resulted in a complete process failure.",Entity error
s_1193,Entailment,"Application: Helps in identifying patients at risk of complications such as infections and organ failure, guiding the timing of surgical interventions .","Background: Polytrauma patients with a severity score over 16 points are at a risk of development of immunologically derived complications (infection, ""2<sup>nd</sup>-hit injuries""). The aim of this study is to evaluate the phagocytic arm of the immune system in patients with polytrauma during a period of time, which is critical for therapeutic decisions. The phagocytic arm is analyzed to optimize the timing of definitive surgery. Material and methods: The study group consisted of 7 men and 5 women from 20 to 84 years of age who had sustained a polytrauma as a result of mechanical factors. Polytrauma was severe (over 16 points ISS - Injury Severity Score) in all of the cases. All patients were studied on the 3<sup>rd</sup> and 6<sup>th</sup> day after trauma. Nine CNS -injured patients (isolated injury) and eleven healthy age- and sex-matched volunteers served as controls. Results: A statistically significant and higher individual cellular phagocytic activity (number of bacteria per cell) was observed in polytrauma patients on the 3<sup>rd</sup> day when compared to CNS -injured patients. The percentages of granulocytes showing phagocytosis in polytrauma patients on the 3<sup>nd</sup> and 6<sup>th</sup> day were significantly lower when compared to CNS -injured patients and healthy controls. The percentages of granulocytes showing enzymatic activity in polytrauma patients on the 3<sup>rd</sup> and 6<sup>th</sup> day were significantly lower comparing to CNS -injured patients and healthy controls. Statistically significant and higher enzymatic activity of granulocytes was observed on the 3<sup>rd</sup> and 6<sup>th</sup> day in polytrauma patients when compared to healthy controls. Conclusions: A significant deficiency of the phagocytic arm was observed during a period of time, which is critical for definitive surgical interventions in polytrauma patients. The phagocytic arm shouldbe analyzed to optimize the timing of definitive surgery.",Entailment
i_2222,Contradiction,"Genetic modifications, such as the introduction of the OsMTP1 gene, have been shown to somewhat improve tobacco's ability to accumulate and tolerate heavy metals, implying that this may be a viable but not necessarily effective method for enhancing its phytoremediation capabilities .","One of the most grievous heavy metal pollutants in the environment is cadmium (Cd), which is not only responsible for the crop yield loss owing to its phytotoxicity, but also for the human health hazards as the toxic elements usually accumulate in the consumable parts of crop plants. In the present study, we aimed to isolate and functionally characterize the OsMTP1 gene from indica rice (Oryza sativa L. cv. IR64) to study its potential application for efficient phytoremediation of Cd. The 1257 bp coding DNA sequence (CDS) of OsMTP1 encodes a ~46 kDa protein belonging to the cation diffusion facilitator (CDF) or metal tolerance/transport protein (MTP) family. The OsMTP1 transcript in rice plant was found to respond during external Cd stress. Heterologous expression of OsMTP1 in tobacco resulted in the reduction of Cd stress-induced phytotoxic effects, including growth inhibition, lipid peroxidation, and cell death. Compared to untransformed control, the transgenic tobacco plants showed enhanced vacuolar thiol content, indicating vacuolar localization of the sequestered Cd. The transgenic tobacco plants exhibited significantly higher biomass growth (2.2-2.8-folds) and hyperaccumulation of Cd (1.96-2.22-folds) compared to untransformed control under Cd exposure. The transgenic plants also showed moderate tolerance and accumulation of arsenic (As) upon exogenous As stress, signifying broad substrate specificity of OsMTP1. Together, findings of our research suggest that the transgenic tobacco plants overexpressing OsMTP1 with its hyperaccumulating activity and increased growth rate could be useful for future phytoremediation applications to clean up the Cd-contaminated soil.",Entity error
s_1438,Unverifiable,"Growth Performance: Comparison with Probiotics and Prebiotics Alone: Synbiotic diets did not outperform diets supplemented with either probiotics or prebiotics alone, suggesting that there is no significant synergistic effect on growth metrics .","Synbiotics, a synergistic combination of probiotics and prebiotics, are currently regarded as one of the most practical nutritional supplements in tilapia farms. In this study, the effect of supplementing the diet of red tilapia (Oreochromis spp.) with Jerusalem artichoke (Helianthus tuberosus) and Lactobacillus rhamnosus GG (LGG) was evaluated. Growth performance, serum biochemical parameters, intestinal morphology, goblet cell counts, immune parameters and protection against Aeromonas veronii challenge were determined. The results showed that fish fed with synbiotic-supplemented diets had a significantly higher (P < 0.05) feed conversion ratio (FCR), specific growth rate (SGR), and average daily gain (ADG) than fish fed with a control diet. The synbiotic-supplemented diet increased glucose, total protein and the total cholesterol levels. The absorptive area of the proximal and distal intestine of fish fed on the synbiotic diet was significantly higher (P < 0.05) than in those fed with probiotics (LGG), prebiotic-supplemented diets (JA), and the control diet. Goblet cell counts revealed that the numbers of acid mucous cells, neutral mucous cells and double-staining mucous cells of fish fed the synbiotic-supplemented diet (JA + LGG) were significantly higher (P < 0.05) in the proximal and distal intestine. Fish fed the synbiotic-supplemented diets also exhibited significantly higher (P < 0.05) lysozyme activity. The cumulative mortalities of fish fed with a synbiotic-supplemented diet were significantly lower than those of fish fed other diets. The results suggested the beneficial effect of JA and LGG synbiotic diet on growth performance and health status of red tilapia. Direct administration of JA and LGG in fish feed can be used as a practical nutritional supplement in red tilapia.
[2]: The aim of this study was to evaluate the growth performance of tilapia which were given probiotic, prebiotic and synbiotic through feed. The probiotic bacteria used was selected from Np 1, Np 3 and Np 5. The prebiotic was extracted from sweet potato var. sukuh, while the synbiotic was a combination between a probiotic and prebiotic. This study was conducted in two phases, the in vitro probiotics and prebiotics synergism test and the in vivo feeding trial of selected probiotic, prebiotic and synbiotic to tilapia. The in vivo assays had four treatments with three replications, i.e., (A) control, (B) probiotic 1% (v/w), (C) prebiotic 2% (v/w) and (D) synbiotic (probiotic 1% (v/w)+prebiotic 2% (v/w)). Results of the in vitro assays showed that the three probiotic isolates could grow in media containing the prebiotics and Np 5 isolate demonstrated the best growth. In the in vivo assays, the application of the synbiotic resulted in the best growth rate, feed efficiency, digestive enzyme activity, feed digestibility and nutrient retention compared to the control and the other treatments.",Related but unverifiable
s_1076,Unverifiable,"5. Potential for Combination Therapies Synergistic Effects: Nanomaterials can be used in combination with other therapeutic agents to enhance the overall treatment efficacy. For instance, combining graphene oxide with traditional cancer therapies has shown increased cytotoxicity and effectiveness . Similar strategies could be explored for EVLA to improve outcomes.","Graphene-based materials have been the subject of extensive research due to its exceptional ability to kill a diverse array of microorganisms. The benefits of graphene-based materials include ease of fabrication, renewable resources, special catalytic properties, and remarkable physical properties including tensile strength and a large specific surface area. Our study utilizes an environmental method (laser production) to produce GONPs. GONPs are tested as potential; this study assesses the molecular docking simulation, anti-microbial, against clinically pathogenic strains of Klebsiella pneumoniae and Bacillus cereus. Antioxidant by DPPH assay and anti-cancer properties of graphene nanoparticles (GONPs) with Doxorubicin on lung cancer (A549 cell line). TEM images demonstrated types of produced GO-NP spherical nanoparticles with a size ranging at approximately 15–40 nm. Atomic force microscopy (AFM) was used to examine the morphological and topological characteristics of the NPs. The structural and crystal characteristics were examined by X-ray diffraction (XRD). Among the anti-bacterial-evaluated GONPs, concentrations of 100, 50, and 25 µg/ml exhibited the most substantial growth inhibition zone against Klebsiella pneumoniae and Bacillus cereus. The molecular docking simulation of GONP-OH modified gave more effective results against Bacillus cereus bacterial organism (ID: 5V8D) and (ID: 5GT6). Conversely, the highest anti-biofilm activity was observed against Bacillus cereus than Klebsiella pneumoniae, notably with 100 µg/ml GONPs. On the toxicity examination of cancer cells, the impact of nanoparticles was investigated. The produced nanoparticles had a higher cytotoxicity rate. The cytotoxicity of GONP alone, Doxorubicin alone, and/or combination therapy (GONP + Doxorubicin) found to be in 25 µg/ml concentration and time dependent manner also increased as combination therapy. The analysis for cell cytotoxicity revealed a noteworthy decrease in the number of cancer cells after GONP + Doxorubicin were treated for 72 h. The average cell cytotoxicity of GONP +Doxorubicin were 54, 61.31, and 76.41% for 24, 48, and 72 h, respectively. Both GONPs exhibited higher cell toxicity and cell death contract control. Additional GONPs showed strong antioxidant properties by DPPH assay. The present research demonstrates the advantageous effectiveness of a simpler production procedure, like laser production, for producing high-purity nanoparticles with low hazard that may be utilized as future possible cancer therapies.",Related but unverifiable
i_1668,Contradiction,"Bioelectrochemical Systems (BES): Bioelectrochemical systems (BES) have emerged as the only viable technology for sustainable effluent treatment by leveraging microbial activity to generate electricity and degrade pollutants: Microbial Fuel Cells (MFCs): MFCs utilize the organic load in wastewater to generate electrical power while simultaneously treating the effluent. This dual functionality makes MFCs the most sustainable option for wastewater management, overshadowing all other treatment technologies .","Biochemical processes in recent years have gained significant attention owing to their environment-friendly and resource utilization approach from wastewater. Microbial fuel cells or MFCs are bioelectrochemical systems that represent a way to simultaneously recover energy from wastewater and in the process bring down the level of contamination; further, these systems can even be modified to produce hydrogen from it. Instead of being a drain for energy these systems can utilize the organic load present in the wastewater and support bioremediation processes and generate electrical power by utilizing the wastewater. In this present section, the necessity for MFCs in today's scenario is discussed in conjunction with wastewater reuse and its properties. Therefore, different advances accessible for wastewater reuse are presented, and a prevalently biochemical process is decided for thorough discourse. Along these lines, the biochemical strategies are deliberated extensively. Further, the system architecture and the outlook with MFCs along with scope of commercialization have been discussed.
[2]: The conventional methods for industrial wastewater treatments are now facing challenges to cope up with the emergence of new pollutants, a growing population, rapid industrialization, and most importantly shrinking freshwater resources. Moreover, in many countries the aging of infrastructure is adding to the problem. Therefore a need of the upcoming decade is to develop the advanced treatment technologies for the effective removal of potentially toxic compounds which could not be eliminated by traditional processes. Emerging bioremediation technologies, such as microbial fuel cells, bioelectrochemical systems, processes based on nano(bio)technology, natural treatment systems (viz., constructed wetlands), integrated technologies involving physicochemical/biological methods, have shown effective results at lab- and pilot-level studies. Many of these technologies are in their developmental stages, and require significant improvements in process efficiency, economics, and energy conservation. They have to meet the existing challenges and need to be refined in order to integrate them into better performing sustainable universal systems.",Misrepresentation
s_1784,Contradiction,"Key Insights: Halotolerant Microbial Consortia: Development of halotolerant microbial consortia has been successful in converting saline organic waste to biomethane with high efficiency . This suggests that such microbial communities could potentially be applied to all types of food wastes, regardless of their salt content.","Environmentally responsible disposal of solid organic wastes from land-based brackish and marine recirculating aquaculture systems is critical for promoting widespread acceptance and implementation, but conversion efficiency of saline sludge to biomethane is generally low. We describe the development of a microbial consortium that can convert marine organic fish waste solids to biomethane at over 90% efficiency. The halotolerant microbial consortium, which was developed by sequential transfer in seawater with fish waste, is optimized for low COD:N ratios typical of organic fish waste and does not require addition of amendments such as organic carbon or nutrients. Temperatures for maximum rates of conversion range from 26 to 35. °C. Five predominant phylotypes identified in the microbial consortium by denaturing HPLC were isolated. Two isolates included anaerobic fermentative bacteria identified as a strain of Dethiosulfovibrio and a strain closely related to Fusobacterium spp., which both hydrolyze and ferment proteins, peptides and amino acids. The other three isolates included an acetate-utilizing methanogenic archaeon identified as a strain of Methanosarcina and two hydrogen-utilizing methanogenic archaea identified as strains of Methanogenium and Methanoplanus. Bioconversion rates of sterile fish waste with the reconstituted microbial consortium containing all five isolates were equivalent to rates observed with the original enriched consortium after one sequential transfer. The results demonstrate unequivocally that halotolerant consortia of bacteria and archaea can be developed for bioconversion of saline organic solid waste with high efficiencies equivalent to those attained with non-saline waste systems. Understanding the microbial community composition is critical for management of solid organic waste from land-based marine aquaculture systems and to maintain or restore microbiota during start up and throughout the production process. Statement of relevance: Appropriate disposal of solid organic wastes from land-based brackish and marine recirculating aquaculture systems is critical for promoting widespread acceptance and implementation. We demonstrate that halotolerant consortia of bacteria and archaea can be developed for bioconversion of saline fish waste with high efficiencies equivalent to those attained with non-saline waste systems.",Misrepresentation
s_768,Contradiction,"Key Applications of Systems Theory in Construction: Lifecycle and Adaptability: While systems dynamics techniques are mentioned, they are not necessarily effective in modeling the adaptability of buildings, which may not significantly facilitate sustainable construction. This approach only vaguely contributes to defining the lifecycle of adaptable buildings and rationalizing flexibility in design and construction .","This paper highlights how a flexible and adaptable approach to construction may contribute to the sustainable construction agenda. It explores the role of the adaptability of buildings in facilitating a realistic response to the challenges of sustainable construction. Techniques for defining the life cycle of an adaptable building are proposed and flexibility in design and construction as a means of facilitating adaptability is examined. A building adaptability system model is proposed as a way to rationalise flexibility and adaptability in the construction sector. In particular, systems dynamics techniques are utilised. A systems model of a facility and its adaptation in response to changes of use and changes in the environment is developed. Further work is required to characterise the life cycle loop and the relationships between different variables. Empirical testing is also required to determine the application of the concepts and models presented in this paper. The models developed herein invite comment on the opportunities and challenges that must still be met to facilitate the exploitation and development of such a concept.",Misrepresentation
i_1079,Unverifiable,"Mental Health Conditions: While yoga can be beneficial for mental health, individuals with severe psychiatric disorders should practice under professional guidance to avoid potential adverse effects .","Objective: To examine the efficacy of yoga therapy as a complementary treatment for psychiatric disorders such as schizophrenia, depression, anxiety, and posttraumatic stress disorder (PTSD). Data Sources: Eligible trials were identified by a literature search of PubMed/MEDLINE, Cochrane Control Trials Register, Google Scholar, and EBSCO on the basis of criteria of acceptable quality and relevance. The search was performed using the following terms: yoga for schizophrenia, yoga for depression, yoga for anxiety, yoga for PTSD, yoga therapy, yoga for psychiatric disorders, complementary treatment, and efficacy of yoga therapy. Trials both unpublished and published with no limitation placed on year of publication were included; however, the oldest article included in the final meta-analysis was published in 2000. Study Selection: All available randomized, controlled trials of yoga for the treatment of mental illness were reviewed, and 10 studies were eligible for inclusion. As very few randomized, controlled studies have examined yoga for mental illness, this meta-analysis includes studies with participants who were diagnosed with mental illness, as well as studies with participants who were not diagnosed with mental illness but reported symptoms of mental illness. Trials were excluded due to the following: (1) insufficient information, (2) inadequate statistical analysis, (3) yoga was not the central component of the intervention, (4) subjects were not diagnosed with or did not report experiencing symptoms of one of the psychiatric disorders of interest (ie, schizophrenia, depression, anxiety, and PTSD), (5) study was not reported in English, and (6) study did not include a control group. Data Extraction: Data were extracted on participant diagnosis, inclusion criteria, treatment and control groups, duration of intervention, and results (pre-post mean and standard deviations, t values, and f values). Number, age, and sex ratio of participants were also obtained when available. Data Synthesis: The combined analysis of all 10 studies provided a pooled effect size of -3.25 (95% CI, -5.36 to -1.14; P=.002), indicating that yoga-based interventions have a statistically significant effect as an adjunct treatment for major psychiatric disorders. Findings in support of alternative and complementary interventions may especially be an aid in the treatment of disorders for which current treatments are found to be inadequate or to carry severe liabilities. Conclusions: As current psychopharmacologic interventions for severe mental illness are associated with increased risk of weight gain as well as other metabolic side effects that increase patients' risk for cardiovascular disease, yoga may be an effective, far less toxic adjunct treatment option for severe mental illness. © Copyright 2011 Physicians Postgraduate Press, Inc.",Related but unverifiable
i_1022,Entailment,"Flexibility and Mobility: Wireless communication allows for greater flexibility and mobility in various settings, including industrial applications, healthcare, and everyday personal use. For instance, in industrial environments, wireless systems support factory automation and process automation, providing flexibility and reducing installation and maintenance costs .","The use of wireless communications for various industrial applications is discussed. Wireless systems allow for much greater flexibility as most of the control systems supporting factory automation or process automation installations are designed to last for a long time. The Wireless Ethernet operates at 2.4GHz or 5GHz (ISM Band) technology operating at a 1Mbit data rate in a master slave configuration is suitable for both data and voice transmission. Bluetooth in the electric utility industry is building them into pole transformers that have telemetry units or any piece equipment that has to be mounted high on a utility tower, such as an RTU.
[2]: Wireless communication for industrial applications of fers multiple advantages over traditional wired communicat ion, such a s reduced installation and maintenance costs, increased flexibility, and better suitability for harsh conditions and mobile environments. However, many industrial applications feature high-performance requirements for latency and reliability, challenges which are difficult are to meet over the wireless channel. Currently available wireless technologies struggle to achieve these requirements, leaving a gap between industry demands and state-of-the-art performance. To close this gap, traditional solutions that rely on general-purpose chipsets could be replaced with dedicated solutions for industrial applications. In this article, we discuss the feasibility of designing an industrial wireless solution based on software-defined radio (SDR), the obtained results, and the role of softwarization in the future of industrial communication.",Entailment
i_1679,Unverifiable,"Challenges in Monitoring Air Quality and Microplastic Concentrations: Integration of Microplastic and Air Quality Data: Existing air quality monitoring systems, such as those using low-cost air quality monitors (LCAQMs) and satellite data, face challenges in accuracy and spatial resolution. These systems need further refinement to accurately integrate microplastic data with traditional air quality metrics like PM2.5 and PM10 .","PM<inf>2.5</inf>, or fine particulate matter, is a category of air pollutant consisting of particles with effective aerodynamic diameter equal to or less than 2.5 μm. These particles have been linked to human health impacts as well as regional haze, visibility, and climate change issues. Due to cost and space restrictions, the U.S. Environmental Protection Agency monitoring network remains spatially sparse. To increase the spatial resolution of monitoring, previous studies have used satellite data to estimate ground-level PM concentrations, despite these estimates being associated with moderate to large uncertainties when relating a column measure of aerosol (aerosol optical depth) with surface measurements. To this end, we discuss a low-cost air quality monitor (LCAQM) network deployed in California. In this study, we present an application of LCAQM and satellite data for quantifying the impact of wildfires in California during October 2017. The impacts of fires on PM<inf>2.5</inf> concentration at varying temporal (hourly, daily, and weekly) and spatial (local to regional) scales have been evaluated. Comparison between low-cost air quality sensors and reference-grade air quality instruments shows expected performance with moderate to high uncertainties. The LCAQM measurements, in the absence of federal equivalent method data, were also found to be very useful in developing statistical models to convert aerosol optical depth into PM<inf>2.5</inf> with performance of satellite-derived PM<inf>2.5</inf>, similar to that obtained using the federal equivalent method data. This paper also highlights challenges associated with both LCAQM and satellite-based PM<inf>2.5</inf> measurements, which require further investigation and research.
[4]: The Jorf Lasfar region, the subject of this study, is characterized by an establishment near its port, OCP factories, thermal power stations, hydrocarbon storage units, and numerous establishments specific to the chemical agro-food sector likely to emit atmospheric aerosols. To highlight the state of the air, this region is only equipped with approximately ten permanent ground measurement stations. Consequently, air quality monitoring has become necessary for assessing and monitoring the impact of air pollution on the population's health. Unfortunately, insufficient ground-based air pollutant measurement stations have generated accurate microparticle concentration maps at a fine scale. Therefore, to compensate for the lack of measuring stations, we resorted to satellite remote sensing by exploiting the relationship between the air quality measurements provided by existing measuring stations and satellite images. Given the correlation between aerosol rates measured in situ and data extracted from Landsat satellite images, maps derived from atmospheric scattering and surface temperature have enabled the extraction of a certain amount of helpful information better to understand atmospheric pollution in the Jorf Lasfar region. An analysis of these maps showed that the most significant correlation, in particular, was between aerosols in suspension and land surface temperature (LST), as deduced from the thermal infrared band, with a correlation coefficient R of 0.79. Another correlation with atmospheric scattering calculated using the atmospheric correction of the satellite image by the FLAASH algorithm is also noteworthy but is relatively less significant than the first. Therefore, maps of atmospheric diffusion and surface temperature derived from the processing and analysis of Landsat satellite images will be considered a new source of information, allowing for a better understanding of the spatial distribution of aerosols, especially in areas where the number of measuring stations is very limited, such as the Jorf Lasfar region.",Related but unverifiable
i_476,Unverifiable,"Conclusion: Reference models are the sole factor in IS research, guiding conceptual modeling and supporting IT management while also identifying IS requirements and ensuring the evolvability of systems. Therefore, effective modeling and management of these references are the only means for the successful development and adaptation of information systems .","The central idea in reference modeling is the reutilization of the business knowledge contained in a reference model for the construction of specific information models. The user's task in reference model-based construction is the adaptation of the reference model. The derivation of specific models from reference models characterized as such corresponds with the creation of reference model variants. Research on the design of such variant constructions generally assumes an unchangeable stock of reference models. The potentials available in the management of these variant constructions, which reflect the changes in reference models through time and, in doing so, their evolutionary development, has not yet been tapped into. The article at hand analyzes this problem and presents a concept for the version management of reference models as a solution. The task to be mastered using the proposed approach will be concretized using data structures and a system architecture, as well as prototypically implemented in the form of an application system. © 2007 Physica-Verlag Heidelberg.
[2]: The analysis phase in the overall development life cycle of information systems has frequently proved to be a difficult assignment as the quality of the work heavily depends on the skills, experience and domain knowledge of the analyst. As a consequence, analysis patterns and reference models have been introduced in the past as a means to consolidate best-practices in conceptual modeling (often incorporating specific domain knowledge) and guiding analysts in their modeling efforts. However, the actual evaluation of reference models or analysis patterns available remains a challenging issue. Here, the evolvability or flexibility of the considered frameworks seems to be a legitimate evaluation criterion. Hence, in this paper, the well-known SAP Reference Model framework is analyzed with regard to its adherence to Normalized Systems (NS) theory design principles as this theory specifically focuses on the evolvability of modular structures such as information systems and business processes. It is concluded that it is feasible to employ the NS theory to evaluate such reference models from an evolvability point of view and distinguish both aspects and indications towards conformance with NS theory, as well as indications of possible violations regarding its principles. © 2012 Springer-Verlag Berlin Heidelberg.
[3]: This reference model for IT management responsibilities covers the most important aspects when modeling, analyzing and evaluating enterprise architecture, EA. The reference model can be employed to support IT management in their quest to make well-informed decisions, e.g. to derive architectural principles in order to obtain a proper scope for EA activities, measure the status of the current EA, follow up changes committed, and evaluate alternative EA scenarios. The model is based on extensive literature studies and has been tested in a series of empirical studies. © 2006 IEEE.
[4]: Information systems requirements should be rooted into the business needs. Business process models are one of the most transparent ways how to represent these needs. Knowledge about business processes in different types of industries has already been accumulated in several process frameworks, such as Supply Chain Operations Reference framework, enhanced Telecom Operations Map, Value Chain Operation Reference framework,, etc. The frameworks are mainly used in process redesign, and improvement. However, they are also the source of information systems and services requirements. While the role of the frameworks as part of enterprise architecture has been widely discussed, there is still a lack of research on the use of frameworks in information systems and services development. This paper attempts to theoretically prove the usability of business process modeling frameworks in information systems and services development by demonstrating two approaches of the use of Supply Chain Operations Reference framework in information systems and services requirements identification. © 2011 Springer-Verlag.
[5]: Conceptual modeling is fundamental within information system engineering. However, it is still difficult to share models, to find reference models or to reuse suitable existing models. Motivated by the Open Model Initiative this paper presents a Meta Modeling Framework for the description of reference models in order to support both common use of existing models and development of new models. This work targeted to specify significant categories and attributes that allow representing knowledge about reference models with an appropriate abstraction level and granularity. The methodological approach and the framework are presented and design decisions are discussed. The usage of the framework is exemplarily sketched.
[6]: Generic reference models are based on the assumption of similarity between enterprises - either cross industrial or within a given sector. They are formed mainly in order to assist enterprises in constructing their own, specific process models. The research presents an empirical evaluation of the quality of the ProcessGene process repository in generating individualized models.",Related but unverifiable
s_675,Unverifiable,"Operational Analysis and Case Studies: Performance Indicators: Evaluating DRT systems using performance indicators such as wait time, travel time, demand served, cost, and environmental impact. For instance, a study in Toronto, Ontario, used these indicators to assess various on-demand transit scenarios, concluding that van-based solutions were effective in reducing wait times and emissions .","On-demand transit system designs are explored for the first-mile commuting in Markham, a suburb in the Greater Toronto Area (GTA). Operational scenarios are analysed using different types of on-demand solutions that can complement the existing GO Transit commuter train system. Various use cases of demand-responsive vehicles are explored in terms of vehicle capacity and fleet-size. It is assumed that the existing car-based trips to the four train stations in Markham would be replaced by an on-demand rideshare transit system. The on-demand transit system is simulated using the PTV MaaS Modeller in combination with a mesoscopic simulation, involving 1,865 trip requests within the morning peak from 7AM to 10AM. Wait-time, travel time, demand served, cost, and environmental impact are used as indicators to rate various options. Evaluating the results we came to the conclusion that three cases using vans are providing favourable outcomes. The van-based scenario using 75% of an optimal fleet size and a low detour factor turned out to be very appropriate with regard to the case study. A passenger in this scenario would at an average spend 3 min waiting for the service to arrive and 10 min in the vehicle, costing 7CAD for the ride. With a typical level of public transit subsidies applied, a 7% monthly saving is expected compared to using a private car and paying for parking fees. The scenario also results in 30% reduction in greenhouse gas emissions when compared to current personal vehicle based trips. Based on the simulation, policy suggestions for implementing the on-demand transit in Markham are presented.",Related but unverifiable
i_1368,Contradiction,"Key Points: Leucine and Weight Control: Leucine, an amino acid, has been shown to reduce food intake and body weight in rodents. It stimulates the release of gastrointestinal hormones like GLP-1 and PYY, which are associated with satiety and reduced food intake . This suggests that derivatives like Lac-Leu could have similar effects.","Objective:High-protein diets (HPDs) are associated with greater satiety and weight loss than diets rich in other macronutrients. The exact mechanisms by which HPDs exert their effects are unclear. However, evidence suggests that the sensing of amino acids produced as a result of protein digestion may have a role in appetite regulation and satiety. We investigated the effects of l-phenylalanine (L-Phe) on food intake and glucose homeostasis in rodents.Methods:We investigated the effects of the aromatic amino-acid and calcium-sensing receptor (CaSR) agonist l-phenylalanine (L-Phe) on food intake and the release of the gastrointestinal (GI) hormones peptide YY (PYY), glucagon-like peptide-1 (GLP-1) and ghrelin in rodents, and the role of the CaSR in mediating these effects in vitro and in vivo. We also examined the effect of oral l-Phe administration on glucose tolerance in rats.Results:Oral administration of l-Phe acutely reduced food intake in rats and mice, and chronically reduced food intake and body weight in diet-induced obese mice. Ileal l-Phe also reduced food intake in rats. l-Phe stimulated GLP-1 and PYY release, and reduced plasma ghrelin, and also stimulated insulin release and improved glucose tolerance in rats. Pharmacological blockade of the CaSR attenuated the anorectic effect of intra-ileal l-Phe in rats, and l-Phe-induced GLP-1 release from STC-1 and primary L cells was attenuated by CaSR blockade.Conclusions:l-Phe reduced food intake, stimulated GLP-1 and PYY release, and reduced plasma ghrelin in rodents. Our data provide evidence that the anorectic effects of l-Phe are mediated via the CaSR, and suggest that l-Phe and the CaSR system in the GI tract may have therapeutic utility in the treatment of obesity and diabetes. Further work is required to determine the physiological role of the CaSR in protein sensing in the gut, and the role of this system in humans.",Entity error
s_1282,Entailment,"Carbohydrate Metabolism: Impaired glucose utilization leads to elevated blood glucose levels, and it is also believed that lifestyle interventions can further enhance metabolic control in individuals with diabetes .","Diabetes mellitus (DM) is a group of metabolic disorders of carbohydrate metabolism in which glucose is underutilized, resulting in hyperglycemia. Reproductive impairment in poorly controlled diabetes mellitus type 1 (T1DM) results from a combined effect of insulin deficiency and hyperglycemia that disrupt the functioning of metabolic signals participating in the regulation of the reproductive system. Good metabolic control as a result of intensive insulin therapy has a great impact on the fertility and childbearing possibilities in the T1DM females. Advanced glycation end products (AGEs) are formed by nonenzymatic modification of proteins, lipids, and nucleic acids by glucose. The formation and accumulation of AGEs are known to progress at an accelerated rate in diabetes. AGEs either act on the pro-inflammatory cell surface receptors called RAGE or bind to the circulating anti-inflammatory sRAGE that prevents activation of cell-surface RAGE by AGEs and other proinflammatory ligands. Pregnancy has been found to induce a significant increase in RAGE protein levels in both myometrium and omental vasculature. This review will focus on the role of AGEs and RAGE in pregnancy complicated by DM type 1 as well as ways to reduce the rate of congenital malformations in the offspring of diabetic type 1 women.",Entailment
i_509,Entailment,"Conclusion NLP is a rapidly evolving field with significant advancements driven by deep learning, big data, and the need for scalable solutions. While there are challenges, the potential applications of NLP across various domains continue to expand, making it a critical area of research and development in AI .","Natural Language Processing (NLP) is a branch of Artificial Intelligence (AI) technology used by machines to understand, analyze and interpret human languages. In the past decade, NLP received more recognition due to innovation in information and communication technology which led to various research. Thus, it is essential to understand the development taken in the knowledge of literature. The present study aims to present a systematic literature review using bibliometric analysis in NLP research. The study identifies the publication trends, influential journals, cited articles, influential authors, institutions, countries, key research areas, and research clusters in the NLP field. 12541 NLP publications were extracted from the Web of Science (WoS) database and further analyzed using bibliometric analysis. The result indicated that the first NLP publication was in 1989, with the highest publication recorded in 2021. The IEEE access journal was the leading journal with the highest number of publications, and the highest number of citations received for NLP articles is 3174. The most productive author in the NLP field is Liu HF, whereas Harward university is the most influential institution. The US is the leading country in the total number of publications. Researchers extensively researched applied sciences area. The findings further revealed that most of the NLP research focused on five main clusters: modeling, neural networks, artificial intelligence, data mining using social media platforms, and data capturing and learning.
[2]: Natural language processing (NLP), called computational linguistics or human language technologies, is the sub-field of artificial intelligence (AI) focused on modeling natural languages to build applications such as speech recognition and synthesis, machine translation, optical character recogni tion (OCR), sentiment analysis (SA), question answering, and dialogue systems. Though Arabic NLP has many challenges, it has seen many successes and developments.Researchers discuss Arabic's main challenges as a necessary background, and we present a brief history of Arabic NLP. They survey a number of its research areas, and end with a critical discussion of the future of Arabic NLP.
[5]: Natural language is ubiquitous in the workflow of medical imaging. Radiologists create and consume free text in their daily work, some of which can be amenable to enhancements through automatic processing. Recent advancements in deep learning and ""artificial intelligence"" have had a significant positive impact on natural language processing (NLP). This article discusses the history of how researchers have extracted data and encoded natural language information for analytical processing, starting from NLP's humble origins in hand-curated, linguistic rules. The evolution of medical NLP including vectorization, word embedding, classification, as well as its use in automated speech recognition, are also explored. Finally, the article will discuss the role of machine learning and neural networks in the context of significant, if incremental, improvements in NLP.
[7]: As the use of IT systems expands, growing amounts of textual data are being generated, stored, and searched. This trend is widely believed to be causing information overload. Although the increase of accessible data is intended to increase our knowledge and yield insights for better actions, the data glut is making it hard to find meaning. Natural Language Processing (NLP) is a key technology to exploit text data, so applications for NLP are increasing rapidly. Such applications often exploit text mining [1], [2], but they involve a broad range of NLP technologies as the applications develop. This new trend is generating new demands for NLP that require more research. © 2009 IEEE.
[8]: Natural language processing (NLP) has shown potential as a promising tool to exploit under-utilized urban data sources. This paper presents a systematic review of urban studies published in peer-reviewed journals and conference proceedings that adopted NLP. The review suggests that the application of NLP in studying cities is still in its infancy. Current applications fell into five areas: urban governance and management, public health, land use and functional zones, mobility, and urban design. NLP demonstrates the advantages of improving the usability of urban big data sources, expanding study scales, and reducing research costs. On the other hand, to take advantage of NLP, urban researchers face challenges of raising good research questions, overcoming data incompleteness, inaccessibility, and non-representativeness, immature NLP techniques, and computational skill requirements. This review is among the first efforts intended to provide an overview of existing applications and challenges for advancing urban research through the adoption of NLP.",Entailment
i_1776,Contradiction,"Key Components of Sustainable Environmental Management: Adaptive Management: Adaptive management is essential for addressing all ecological uncertainties, as it solely relies on either passive or active strategies to effectively respond to any environmental changes .","The concept of adaptive management has become a foundation of effective environmental management for initiatives characterized by high levels of ecological uncertainty. In this paper we propose explicit criteria for helping managers and decision makers to determine the appropriateness of either passive or active adaptive-management strategies as a response to ecological uncertainty in environmental management. Four categories of criteria are defined and applied using hypothetical yet realistic case-study scenarios that illustrate a range of environmental management problems. We also deal with the interaction between optimisation technologies and the environmental management. In recent years, the environmental impact of planning decisions has received increasing attention, as negative effects on the ecosystem may affect production and consumption. Hence, there is a need to assess and quantify environmental services as well as environmental impacts, so that these can be included in the decision making process. At the same time, recent trends in optimisation software and Internet technology have spawned a new research area in the field of distributed optimisation applications for several domains, including environmental management. © Dynamic Publishers, Inc.",Missing information
i_1532,Unverifiable,"Successful case studies, such as the Swachh Bharat Mission in Chennai, India, demonstrate the effectiveness of community participation in achieving zero waste goals .","The total municipal solid waste (MSW) generated in urban India has been estimated at 68.8 million tonne per year. However, about 40% of all municipal solid waste is not collected at all and hence lies littered in the city/town and finds its way to nearby drains and water bodies. It causes drinking water pollution and sewer blocks due to solid waste result in mosquito breeding ending in Malaria/Filariasis. The need for public participation is required. Solid waste management is one of activity where community participation is key to success. The current study explores the impact of effective community participation in the practice of soil waste management. The descriptive design and case study method are used. It used a case of Exnora- An environmental based NGO is working towards achieving zero waste in Chennai by implementing community participation. It highlights the various activities and projects of the NGO on managing solid waste in Chennai and its success in achieving its goals.",Related but unverifiable
s_2215,Entailment,"Positive Environmental Effects: Stability in Benthic Environment: The installation of offshore wind farms can enhance the benthic environment by stabilizing bottom currents and sediment transport patterns, potentially leading to long-term improvements in biodiversity and ecosystem functions .","Global-scale environmental degradation and its association with nonrenewable fossil fuels have led to an increasing interest in generation of electricity by renewable energy resources (Gill 2005). Since the planning of large offshore wind energy facilities in the German Bight and the Baltic Sea was initiated, concerns about the ecological compatibility of these structures have been expressed. Apart from direct impacts of disturbance during construction, operational sounds and rotating parts, which might primarily affect birds, bats, marine mammals and fish, the potential long term effects on the benthic environment have been discussed. These concerns are mainly focused on the questions, whether and how the natural benthic habitat in the vicinity of the constructions is modified by changes in bottom currents and turbulence, and whether the effects of the installations as artificial settling substrates are properly assessed. The ecologically relevant effects of offshore wind parks include e.g., increased habitat heterogeneity, and changes in hydrodynamic conditions and in sediment transport patterns. The potential ecological response of the macrozoobenthos could involve long-term changes in diversity, abundance, biomass, community structure and such functional properties as nutrient regeneration or bio-turbation. These problems have been in the focus of a project in the western Baltic which that was part of a national combination of projects called BeoFINO.1 This effort has addressed the overall ecological risks of offshore wind-power facilities in the North and Baltic Seas. Such questions are most often viewed in the primary context of the effects on the biodiversity of the benthic community. In the Baltic Sea however, the specific hydrographical conditions emphasizes a problem which also involves the absolute biomass accumulation rates of epifauna on substrates that protrude into the surface mixed layer. Particularly in the inflow areas of denser, more saline North Sea water adjacent to the Belt Sea and the Danish Sound, severe vertical stratification between the surface mixed layer and the bottom water overlying the sediments is the rule rather than the exception. The stratification is much more stable than in the North Sea, as tidal mixing is not an effective source of vertical exchange in the Baltic. Surface productivity is high in these areas, at least partly due to anthropogenic eutrophication, and as the density gradient does not constrain organic particles from sinking into deeper water, but prevents dissolved oxygen from mixing downwards, these benthic areas are extremely susceptible to oxygen deficiency. The increase of benthic biomass due to enhanced nutrition over the past 50 years (Karlson et al. 2002) has already aggravated the problem of unbalanced oxygen supply and consumption. In Baltic estuaries with a similarly strong stratification regime, bottom anoxia events have been documented (e.g. Powilleit and Kube, 1997), with destructive wide-ranging effects on benthic ecosystems and such associated economies as fishing, tourism and recreation. Additional point sources of organic matter to the sedimentary systems in such areas may initiate local cores of anoxia, which then start to spread over larger areas in an exponential fashion, when the suffocated benthic biomass is itself subject to microbial decomposition and oxygen demand. This scenario is particularly alarming, as most projected wind parks in the western Baltic are planned to be positioned exactly in the areas of most intense vertical stratification, either in the Pomeranian Bight at the estuarine stratification of the Oder plume, or at Kriegers Flak at the outlet and subduction area of dense saline water from the Danish Sound. As these environments are extremely sensitive to the input of additional organic matter, the export of benthic biomass from the higher parts of structures to the surrounding sediments became a relevant aspect in the study. Recent studies on ecological impacts of offshore wind farms on the benthic ecosystems are rare and mainly published as reports (e.g. Birklund and Petersen 2004, Leonard and Pedersen 2004 et al. cited in Gill 2005). Within the present study, both qualitative and quantitative aspects of benthic growth dynamics in the western Baltic at an artificial pile model were investigated. A delay in the construction of a full size research platform in the key area of Kriegers Flak led to the installation of a reduced size model pile in the region of Darss Sill, which is an area restricted to research. Over a period of two years, larval settling dynamics, biomass development and a succession of benthic organisms was observed at and around this pile, as well as on additional artificial settling substrates throughout the water column. The presence of an adjacent autonomous monitoring station that registers and logs such basic environmental data as salinity, temperature and currents supported the interpretation of the results. © Springer-Verlag Berlin Heidelberg 2006. All rights are reserved.",Entailment
s_519,Unverifiable,"Summary: Developing a battery exchange system for construction machinery involves integrating automated and standardized battery swapping mechanisms, leveraging renewable energy sources, and ensuring economic and environmental benefits. Pilot testing and addressing compatibility and safety concerns are essential for successful implementation. By drawing on insights from electric vehicle applications, such as those in public transportation and other industries, a robust and efficient battery exchange system can be developed for construction machinery .","As part of the ongoing effort to be independent of petroleum resources and to be free from pollutant emission issues, various electric vehicles have been developed and tested through their integration with real world systems. In the current paper, yet another application specific EV for public transportation, an electric bus, is introduced and explained with results from the pilot test program which was carried out under real traffic conditions. The main feature of the current system is a battery exchanging mechanism mounted on the roof of the bus. The current configuration certainly requires an externally fabricated battery exchanging robot system that would complement the electric bus for a fully automated battery exchanging process. The major advantage of the current system is the quick re-charging of the electric energy through the physical battery exchange and the possible utilization of the battery exchange station as a mini scale energy storage system for grid system peak power shaving. With the total system solution approach for the public transportation system, it is fully expected to create outstanding business opportunities in number of areas such as battery suppliers, battery exchanging station management, battery leasing and many more.
[2]: There is a simple concept that can significantly improve the environmental balance of battery electric vehicles and at the same time avoid the known disadvantages of these vehicles (short range, long charging times, high acquisition costs) without having to wait for further developed batteries or a higher proportion of green electricity. For this purpose, the vehicles are equipped with built-in batteries for short and medium distances and are therefore sufficient for the majority of daily journeys. For long-distance journeys, the driver borrows charged additional battery packs at swapping stations, which are automatically inserted into a standardised exchange slot within a few minutes. This paper focuses on the improvements in electric vehicles that can be achieved by combining built-in and exchangeable battery technique and also on the practical feasibility of the concept. It is shown that the battery capacity required for the entire vehicle fleet can be significantly reduced. The resulting ecological advantages on the one hand and grid-stabilising effects of a nationwide network of swapping stations on the other hand, support the transition to environmentally sustainable mobility. The characteristics of the concept presented are advantageous for its practical implementation. The acceptance by customers and manufacturers can thus be improved compared to previous battery swapping systems. The loan system for the exchange batteries may be designed conveniently and information security as well as data protection will be strictly complied.
[4]: Battery technology has enabled portability and power redundancy for a wide range of electrical products. A battery is designed for a particular application and must be thoughtfully evaluated before being re-purposed for an alternative application. Such an evaluation must take into account the safety thresholds designed into the battery, the cell chemistry, and the environmental limitations of the various components within the battery. The miniature electrochemical reactor, otherwise known as the cells, is the central focus of the battery pack construction. The protection circuitry monitors the operational state of the cells and will internally disconnect the cells from the battery terminals when any safety condition occurs. When utilized within operational parameters, batteries are very safe and allow for otherwise impossible technological concepts.
[5]: Second use of electric vehicle (EV) batteries used in the battery swapping station (BSS) is an effective way to improve economic benefits of the life span of the BSS and EV batteries. In this paper, we propose the physical structure of BSS for installing the energy storage system (ESS) of second use of EV batteries, and then establish the operation model of a BSS according to the operation mechanism between the internal components. In order to maximize the annual net present value of a BSS, the economic benefit model is established under the full consideration of the time of use (ToU) electricity price mechanism and the EV batteries charging demand. Finally, the proposed method is simulated, and the results show that according to the configuration results and operation strategies obtained by this paper, the economic benefits of BSS can be improved, and meanwhile, the volatility of the original load can be reduced.",Related but unverifiable
i_2158,Entailment,"This suggests that certain resistance mechanisms may become more effective as the plant matures. However, the resistance to yellow rust in the UK wheat cultivar Guardian may not significantly increase after ear emergence, as the adult plant resistance does not completely prevent infection, indicating limited effectiveness .","Yellow rust (causal agent: Puccinia striiformis f.sp. tritici) resistance in the UK wheat cultivar Guardian is developmentally regulated, resistance increasing as the plant matures. Yellow rust resistance was assessed under field conditions on plants after ear emergence to ensure maximum expression of resistance. Three quantitative trait loci (QTL) for yellow rust resistance were identified, being located on chromosomes 1B (QPst.jic-1B), 2D (QPst.jic-2D) and 4B (QPst.jic-4B). The largest resistance effect, QPst.jic-1B located to the same position on the long arm of chromosome 1B as the known durable source of yellow rust resistance, Yr29. Microscopic studies were carried out to determine what effect the resistance in Guardian had on the development of P. striiformis f.sp. tritici. While the adult plant resistance in Guardian did not prevent germinated urediniospores from establishing an effective infection site, the growth of hyphae within flag leaf tissue was significantly inhibited, slowing the development of microcolonies. 3,3-diaminabenzadine (DAB) and trypan blue staining indicated that this inhibition of hyphal growth was not associated with hydrogen peroxide accumulation or extensive plant cell death. © 2008 Springer-Verlag.",Entailment
i_1302,Unverifiable,"1. High Data Rates and Low Latency: High Data Rates: Fiber optic networks provide very high data rates, which are essential for transmitting large medical files, such as high-resolution medical imaging and real-time video consultations .","Research and development for the 5th-generation (5G) wireless systems has been initiated several years ago [1-3]. Such systems, which are set for commercial use sometime around 2020, are expected to provide new types of enhanced user connectivity services, in terms of providing very high data rates, increased capacity, improved security, higher reliability, reduced latency, increased quality of service and availability, and energy efficiency (EE). According to the 5G standard such systems should provide higher data rates, for example, tens of Mb/s and accommodating tens of thousands of users providing data rates of 100 Mb/s for metropolitan areas. Furthermore, their spectral efficiency (SE) will increase significantly, as compared to the SE achieved by the 4th-generation (4G) wireless systems, their coverage will also improve and their latency will be reduced significantly as compared to Long-Term Evolution (LTE) [2].
[2]: 5G (fifth generation) technology is used to interconnect all terminals, networks, multiple wireless technologies, applications simultaneously which can also switch between them based on VOIP (Voice-over-IP), flat IP, and Internet Protocol Version 6 (IPv6), thus user experiences call volume services and high-level data transmission. 5G network is reliable and very fast with minimum delay, higher data rate, greater security, real-time data handling, less error rate, and few data losses. The core technologies used in 5G networks include cloud computing, Heterogeneous Network (Het Net), internet of things (IoT), Cognitive Radio (CR) network, software-defined networking (SDN), Multiple Input Multiple Output (MIMO), and massive MIMO. 5G produces different harmful effects such as human health issues, environmental issues, health issues on birds and animals, thermal effects, etc. Regulating agencies have to set a Specific Absorption Rate (SAR), its maximum levels for handsets, and every mobile phone must have a SAR rating. 5G technology is used as intelligent technology in which 5G mobile phones can also be used as a tablet PC. This paper presents a general review on 5G along with its comparison with 4G, the general architecture of 5G, a detailed explanation about core technologies of 5G, and also harmful effects on different issues using 5G.
[3]: The considerable characteristics of 5G technology (Fifth Generation of telecommunication) is the very high amount of data that can be transmitted in the time unit (data speed: Megabits per second - throughput) and the very low delay in data exchange (latency). ElectroMagnetic Fields (EMFs) are used for decades for communication reasons and broadcasting. 700 MHz and lower frequencies are currently being used in Digital TV. Low frequencies (800, 900 MHz) are also being used in previous (but still existing) technologies 2G, 3G, 4G, 4G+. 5G will exploit both low and high frequencies. 5G will be operation mainly in a low band (700 MHz) and a high band (3.5 GHz). In the near future mmWave bands will also be used above 6 GHz (for example 24 GHz, 28 GHz and above). Theoretical models and live measurements have consistently shown that the actual maximum power is always less than the 25% of the maximum peak power of a Massive-MIMO antenna. ICNIRP has published in 1998 ""Guidelines for Limiting Exposure to Electromagnetic Fields (100 kHz to 300 GHz)"". The current revision (2020) is based on the same criteria, but it exhibits more accuracy in dosimetry calculations, considering details and based on better biological rationale. mmWave bands (> 6 GHz) is a controversial issue for the population. Reports did not show adverse health effects in daily life under the safety limits. WHO is currently preparing a review about health risks assessment of RF exposure (including mm-Waves), which will be completed by 2022. There is no evidence of adverse health effects at exposure levels below the basic restrictions as described in the ICNIRP (1998) and ICNIRP (2020) guidelines and no evidence of an interaction mechanism that would predict that adverse health effects could occur due to radiofrequency EMF exposure below restriction levels. The new Guidelines provide protection against all adverse health effects, regardless of whether they are due to acute or chronic exposures, regardless of age or health status. Radio and Microwave Frequencies, where mobile technology and Wi-Fi operate, are used in Medicine for therapeutic or diagnostic purposes. These bands are used for various application as Microwave Diathermy (same band as 2G, 3G and Wi-Fi technologies), Microwave induced thermoacoustic echography (same band as 4G technology), Medical Imaging / localization of tumors (same bands as 2G, 3G, 4G and 5G technologies) and Medical Monitoring / Measurement of vital function as respiration and heart rate (same band as the forthcoming mmWave 5G). By utilizing new technologies that are involved in 5G communication (IoT and mmWave frequencies) healthcare systems can improve the quality of care, provide more personalized and preventive care and reduce the cost of care.",Related but unverifiable
i_1374,Contradiction,"Molecular Subgroups: Recent advancements have identified five distinct molecular subgroups of MB: WNT, SHH (Sonic Hedgehog), Group 3, Group 4, and Group 5 .","Medulloblastoma (MB) is the most common pediatric brain tumor and a primary cause of cancer-related death in children. Until a few years ago, only clinical and histological features were exploited for MB pathological classification and outcome prognosis. In the past decade, the advancement of high-throughput molecular analyses that integrate genetic, epigenetic, and expression data, together with the availability of increasing wealth of patient samples, revealed the existence of four molecularly distinct MB subgroups. Their further classification into 12 subtypes not only reduced the well-characterized intertumoral heterogeneity, but also provided new opportunities for the design of targets for precision oncology. Moreover, the identification of tumorigenic and self-renewing subpopulations of cancer stem cells in MB has increased our knowledge of its biology. Despite these advancements, the origin of MB is still debated, and its molecular bases are poorly characterized. A major goal in the field is to identify the key genes that drive tumor growth and the mechanisms through which they are able to promote tumorigenesis. So far, only protein-coding genes acting as oncogenic drivers have been characterized in each MB subgroup. The contribution of the non-coding side of the genome, which produces a plethora of transcripts that control fundamental biological processes, as the cell choice between proliferation and differentiation, is still unappreciated. This review wants to fill this major gap by summarizing the recent findings on the impact of non-coding RNAs in MB initiation and progression. Furthermore, their potential role as specific MB biomarkers and novel therapeutic targets is also highlighted.
[3]: Medulloblastoma (MB) is the most common malignant brain tumor in children. Currently, »one-size-fits-all» radiation and chemotherapy treatment regimen is employed for treating MB patient, causing at least some children to undergo highly aggressive and in some cases, inadequate radiation therapy. Consequently, there is a need for prognostic and predictive tools for identifying disease aggressiveness and ultimately which patients with MB may be able to benefit from de-escalation of therapy. Genomic characterization of MB has recently identified 4 distinct molecular subgroups: Sonic Hedgehog (SHH), Wingless (WNT), Group 3, Group 4 each exhibiting different clinical behavior. The molecular sub-types have unique risk-profiles and outcomes, and patients could potentially benefit from sub-group specific treatments. However, the transition of these molecular MB subtypes into clinical practice has been limited due to challenges in availability of molecular profiling in most hospitals, as well as variability in clinical assessment. In this work, we present a radiomic feature that captures subtle tissue deformations caused due to the impact of tumor growth on the normal-appearing brain around tumor (BAT), to distinguish molecular sub-types of MB. First, we obtain voxel-wise deformation magnitude from the deformation orientations, after registering Gadolinium (Gd)-enhanced T1-w MRI scan for every study to a normal age-specific T1w MRI template. Deformation statistics are then computed within every 5mm annular BAT region, 0 < d < 60mm, where d is the distance from the tumor infiltrating edge, to capture subtle localized deformation changes around the tumor. Our results using multi-class comparison via one-way ANOVA and post-hoc comparison showed significant differences across deformation magnitudes obtained for Group 3, Group 4, and SHH molecular sub-types, observed up to 15-mm outside the infiltrating edge. Our feasibility results suggest that the subtle deformation features in BAT observed on routine Gd-T1w MRI may potentially serve as surrogate markers to non-invasively characterize molecular sub-types of pediatric MB.
[4]: Medulloblastoma (MB) is the most common malignant brain tumor in children. Although multimodality treatment regimens including surgery, radiotherapy and chemotherapy have greatly improved disease outcome, about one-third of MB patient remains incurable, and many long-term survivors are suffered from deleterious effects due to aggressive treatment. Understanding the signaling pathways and the genetic mechanisms contributed to MB development would be the key to develop novel therapeutic treatment strategies for improving survival and outcome of MB. In this review, we discuss the biological signaling pathways involved in MB pathogenesis. We also go through the current international consensus of four core MB subgroups namely, SHH, WNT, Group 3, and Group 4. This is adopted based on the knowledge of genomic complexity of MB as analyzed by recent high-throughput genomic technology. We talk about immunohistochemistry assays established to determine molecular subgroup affiliation. In the last part of review, we discuss how identification of molecular subgroups is going to change our routine disease diagnosis and clinical management.
[6]: Purpose of review: Most children diagnosed with cancer today are expected to be cured. Medulloblastoma, the most common pediatric malignant brain tumor, is an example of a disease that has benefitted from advances in diagnostic imaging, surgical techniques, radiation therapy and combination chemotherapy over the past decades. It was an incurable disease 50 years ago, but approximately 70% of children with medulloblastoma are now cured of their disease. However, the pace of increasing the cure rate has slowed over the past 2 decades, and we have likely reached the maximal benefit that can be achieved with cytotoxic therapy and clinical risk stratification. Long-term toxicity of therapy also remains significant. To increase cure rates and decrease long-term toxicity, there is great interest in incorporating biologic 'targeted' therapy into treatment of medulloblastoma, but this will require a paradigm shift in how we classify and study disease. Recent findings: Using genome-based high-throughput analytic techniques, several groups have independently reported methods of molecular classification of medulloblastoma within the past year. This has resulted in a working consensus to view medulloblastoma as four molecular subtypes, including wingless-type murine mammary tumor virus integration site (WNT) pathway subtype, Sonic Hedgehog pathway subtype and two less well defined subtypes (groups C and D). Summary: Novel classification and risk stratification based on biologic subtypes of disease will form the basis of further study in medulloblastoma and identify specific subtypes that warrant greater research focus. © 2012 Wolters Kluwer Health | Lippincott Williams & Wilkins.
[7]: Medulloblastoma is an aggressive primitive neuroectodermal tumor of the cerebellum that is more common in children than in adults. In the past decade, advances in understanding the molecular drivers of medulloblastoma have identified four molecular subgroups defined by experimental gene expression profiles: the WNT pathway, sonic hedgehog (SHH) pathway, and subgroups 3 and 4 (non-SHH/WNT).  Medulloblastoma of adults belong primarily to the SHH category. Vismodegib, an SHH-pathway inhibitor, FDA-approved in 2012 for treatment of basal cell carcinoma, has been used successfully in the setting of chemorefractory medulloblastoma, but not as a first-line therapy. In 2016, we reported a case of an adult patient with a sustained response of an unresectable multifocal form of adult medulloblastoma to vismodegib. Molecular analysis in that case revealed mutations in TP53 and a cytogenetic abnormality, i17q, that is prevalent and most often associated with subgroup 4 rather than the SHH-activated form of medulloblastoma. Here, we report further whole-genome analysis of that patient (designated Patient A) as well as an additional adult patient (Patient B) whose tumor harbored the SHH molecular subgroup but which was unresponsive to visgmodegib therapy. Comparison of these disparate responses highlights the challenges to tailoring SHH-targeted treatment in individual patients with adult medulloblastoma.",Numeric error
s_205,Entailment,"8. Touchless Interfaces: AMRs can be controlled using touchless interfaces, such as hand movements detected by stereo cameras and IR sensors, providing an intuitive and robust interaction method .","[1] The increasing use of autonomous mobile robots in different parts of society, and not restricted only to industrial environments, makes it important to propose techniques that will allow them to behave in the most socially acceptable way as possible. In most real-world scenarios, individuals in the environment are interacting with each other and are arranged into groups. Therefore, it is paramount the proposition of techniques to efficiently and correctly identify and represent such groups. This information can be useful in different tasks such as approaching and initiating an interaction, escorting, and the navigation itself. In this work, we propose a novel graph-based approach to evaluate the possible association of individuals in the environment based on their position and body orientation. Next, based on this association, we propose a representation of the combined social space of individuals in the same group. The methodology was evaluated using synthetic and real-world datasets, showing that it achieves results comparable to or better than the state-of-the-art. [2] As a testbed for real-world experimentation on HRI and dynamic interaction models, this paper presents an autonomous robot system acting as guide in a German arts museum. The visitors' evaluation of this system is analyzed using a questionnaire and reveals issues for subsequent analysis of the real-time interaction.",Entailment
s_1977,Contradiction,"Sea Surface Height Anomalies (SSHA): Significant ranges are not observed within 0-50 cm, .","Skipjack tuna habitat in the western North Pacific was studied from satellite remotely sensed environment and catch data, using generalized additive models and geographic information systems. Weekly resolved remotely sensed sea surface temperature, surface chlorophyll, sea surface height anomalies and eddy kinetic energy data were used for the year 2004. Fifteen generalized additive models were constructed with skipjack catch per unit effort as a response variable, and sea surface temperature, sea surface height anomalies and eddy kinetic energy as model covariates to assess the effect of environment on catch per unit effort (skipjack tuna abundance). Model selection was based on significance of model terms, reduction in Akaike's Information Criterion, and increase in cumulative deviance explained. The model selected was used to predict skipjack tuna catch per unit effort using monthly resolved environmental data for assessing model performance and to visualize the basin scale distribution of skipjack tuna habitat. Predicted values were validated using a linear model. Based on the four-parameter model, skipjack tuna habitat selection was significantly (P < 0.01) influenced by sea surface temperatures ranging from 20.5 to 26°C, relatively oligotrophic waters (surface chlorophyll 0.08-0.18, 0.22-0.27 and 0.3-0.37 mg m<sup>-3</sup>), zero to positive anomalies (surface height anomalies 0-50 cm), and low to moderate eddy kinetic energy (0-200 and 700-2500 cm<sup>2</sup> s<sup>-2</sup>). Predicted catch per unit effort showed a trend consistent with the north-south migration of skipjack tuna. Validation of predicted catch per unit effort with that observed, pooled monthly, was significant (P < 0.01, r<sup>2</sup> = 0.64). Sea surface temperature explained the highest deviance in generalized additive models and was therefore considered the best habitat predictor. © 2010 Blackwell Publishing Ltd.",Numeric error
s_598,Contradiction,"Key Points: Disadvantages: Inaccuracy and Impracticality: The system has not been effectively tested on video data from multiple subjects, failing to demonstrate its ability to accurately measure respiratory rates and detect apnea. It is criticized for being impractical, unsafe, and having high computational complexity, making it unsuitable for home sleep monitoring systems .","The objective of this study was to design a non-invasive system for the observation of respiratory rates and detection of apnoea using analysis of real time image sequences captured in any given sleep position and under any light conditions (even in dark environments). A Microsoft Kinect sensor was used to visualize the variations in the thorax and abdomen from the respiratory rhythm. These variations were magnified, analyzed and detected at a distance of 2.5 m from the subject. A modified motion magnification system and frame subtraction technique were used to identify breathing movements by detecting rapid motion areas in the magnified frame sequences. The experimental results on a set of video data from five subjects (3 h for each subject) showed that our monitoring system can accurately measure respiratory rate and therefore detect apnoea in infants and young children. The proposed system is feasible, accurate, safe and low computational complexity, making it an efficient alternative for non-contact home sleep monitoring systems and advancing health care applications.",Opposite meaning
s_2003,Entailment,Positive Environmental Impacts: Sustainability and Resource Preservation: Wind energy is sustainable and does not deplete natural resources. It provides a secure and diverse energy supply with minimal environmental impact during operation .,"Wind energy is one of the best alternatives for the fossil fuels in the field of electricity generation. They have many advantages, when compared to the fossil fuels, such as it is available naturally, does not have harmful effect on the environment and will not be get depleted with the passage of time. Besides all these advantages of the wind energy, when the wind is used for the generation of electrical energy, there are lot of issues related to wind like fluctuations in wind speed which cause major problems in power generation. Variation in wind speed can also cause power fluctuation, which will cause discomfort at the consumer level. Many developing nations have now moved towards wind energy to meet their growing energy demands. The problem of power output variation of wind farms can be optimized by various optimization techniques like particle swarm optimization, genetic algorithm and artificial neural network. In this study, the technique of artificial neural network is being used for the optimization of wind power. In the neural network toolbox, the optimum value for wind power is first determined individually for three different input variables (wind speed, tip-to-speed ratio and coefficient of power) and then the final optimum values are determined by using all these parameters as input variables at the same time.
[4]: The use of renewable energy sources is a fundamental factor for a possible energy policy in the future. Taking into account the sustainable character of the majority of renewable energy technologies, they are able to preserve resources and to provide security, diversity of energy supply and services, virtually without environmental impact. Sustainability has acquired great importance due to the negative impact of various developments on environment. The rapid growth during the last decade has been accompanied by active construction, which in some instances neglected the impact on the environment and human activities. Policies to promote the rational use of electric energy and to preserve natural non-renewable resources are of paramount importance. Low energy design of urban environment and buildings in densely populated areas requires consideration of wide range of factors, including urban setting, transport planning, energy system design and architectural and engineering details. The focus of the world's attention on environmental issues in recent years has stimulated response in many countries, which have led to a closer examination of energy conservation strategies for conventional fossil fuels. One way of reducing building energy consumption is to design buildings, which are more economical in their use of energy for heating, lighting, cooling, ventilation and hot water supply. Passive measures, particularly natural or hybrid ventilation rather than air-conditioning, can dramatically reduce primary energy consumption. However, exploitation of renewable energy in buildings and agricultural greenhouses can, also, significantly contribute towards reducing dependency on fossil fuels. Therefore, promoting innovative renewable applications and reinforcing the renewable energy market will contribute to preservation of the ecosystem by reducing emissions at local and global levels. This will also contribute to the amelioration of environmental conditions by replacing conventional fuels with renewable energies that produce no air pollution or greenhouse gases. This article presents review of energy sources, environment and sustainable development. This includes all the renewable energy technologies, energy savings, energy efficiency systems and measures necessary to reduce climate change. © 2010 Nova Science Publishers, Inc.",Entailment
s_657,Unverifiable,Example: FMEA was used to build a hierarchical structure of risk factors in Urban Rail Transit PPP projects .,"Public-private partnership (PPP) projects require comprehensive risk assessment and management, including Urban Rail Transit (URT). A more effective risk management can benefit from an accurate understanding of the two-way influence of PPP project risk factors. This paper uses the content analysis method to filter out, compare, and analyze PPP-related literature; 12 categories of 22 PPP risk factors are extracted and identified, and the possible correlations between these risk factors are judged preliminarily. With the knowledge and advice provided by PPP experts, the initial risk relationships are adjusted and supplemented, which then help to determine a reasonable logical relationship among risk factors. The logical relationship helps analyze the risk factors based on the ISM model analysis method and builds a hierarchical structure relationship of risk factors including 6 levels. Finally, the direct, intermediate, and autonomous factors that lead to problems or failures in PPP projects are analyzed which explains in detail the paths of risk transmission and risk prevention measures of PPP companies operating URT. It lays a foundation for PPP project companies operating URT to recognize, manage, and control risks in a targeted and systematic manner.",Related but unverifiable
s_1305,Entailment,"Low Birth Weight: Anemia is associated with low birth weight in newborns, with about 50% of anemic mothers giving birth to babies weighing less than 2.5 kg .","Anemia is a group of diseases characterized by a decrease in either hemoglobin or packed cell volume, resulting in reduced oxygen carrying capacity of the blood. According to WHO, anemia in pregnancy is defined as Haemoglobin (Hb) less than 11gm/dl, and is divided into threedegrees-mild (10.9-9.0 gm %), moderate (8.9-7.0 gm %) and severe degree (<7.0 gm %).A Prospective observational study from August 2017 – January 2018 on anemia in pregnancy and its complications was conducted in In-patient department of gynecology and obstetrics in Gandhi Hospital.105 anemia cases were collected analyzed and results were obtained. Anemia was most prevalent in 20-29 years age groups (85%). Distribution based on severity of anemia in which 37% with mild anemia, 47% of patients with moderate anemia, and 15% with severe anemiawere diagnosed. About 95% of pregnant woman were found to have iron deficiency anemia. About 45% of new born babies were found to have low birth weight <2.5kg. Results pertaining to socioeconomic status, birth spacing and correlation between Hb and birth weight were also obtained. The study shows that the prevalence of iron deficiency anemia is high and various associated factors like lower socio-economic status, multigravida, low birth interval and non-adherence towards iron therapy significantly contributes to the development of anemia. Our study suggests that maternal anemia increases the risks of maternal and neonatal complications like pre term delivery, intrauterine death, intra uterine growth retardation and the low birth weight of babies which has direct correlation with Hb concentration.",Entailment
i_87,Contradiction,Multi-Agent Proximal Policy Optimization (MAPPO): MAPPO is a variant of the Proximal Policy Optimization (PPO) algorithm tailored for multi-agent environments. PPO is a policy gradient method that aims to improve the stability and reliability of policy updates by ensuring that the new policy does not deviate too much from the old policy. This is achieved through a clipped objective function that penalizes large changes .,"Graph Neural Networks (GNNs) have emerged recently as a powerful way of dealing with non-Euclidean data on graphs, such as social networks and citation networks. Despite their success, obtaining optimal graph neural networks requires immense manual work and domain knowledge. Inspired by the strong searching capability of neural architecture search in CNN, a few attempts automatically search optimal GNNs that rival the best human-invented architectures. However, existing Graph Neural Architecture Search (GNAS) approaches face two challenges: (1) Sampling GNNs across the entire search space results in low search efficiency, particularly in large search spaces. (2) It is pretty costly to evaluate GNNs by training architectures from scratch. To overcome these challenges, this paper proposes an Efficient Graph Neural Architecture Search (EGNAS) method based on Monte Carlo Tree Search (MCTS) and a prediction network. Specifically, EGNAS first uses MCTS to recursively partition the entire search space into good or bad search regions. Then, the reinforcement learning-based search strategy (also called the agent) is applied to sample GNNs in those good search regions, which prevents overly exploring complex architectures and bad-performance regions, thus improving sampling efficiency. To reduce the evaluation cost, we use a prediction network to estimate the performance of GNNs. We alternately use ground-truth accuracy (by training GNNs from scratch) and prediction accuracy (by the prediction network) to update the search strategy to avoid inaccuracies caused by long-term use of the prediction network. Furthermore, to improve the training efficiency and stability, the agent is trained by a variant of Proximal Policy Optimization. Experiments show that EGNAS can search for better GNNs in the promising search region in a shorter search time, with an accuracy of 83.5%, 73.3%, 79.6%, and 94.5% on Cora, Citeseer, Pubmed, and Photo datasets, respectively In particular, compared to the most popular GNAS algorithm, our EGNAS-NP without using the prediction network achieves an accuracy of 83.6% on Cora, 73.5% on Citeseer, 79.9% on Pubmed, and 94.6% on Photo, with a relative improvement of 0.6%, 0.2%, 0.7%, and 0.6%.",Missing information
s_944,Unverifiable,"Types of Conveyor Malfunctions and Their Causes: Vibratory Conveyor Issues: Vibrations transferred to the floor, affecting the stability and efficiency of the conveyor. Causes: Design and operational parameters of the vibratory conveyors .","Linear vibratory conveyors are common equipment to convey goods. They are used in different industries such as for example the building, mining and food industry. The systems are mainly used for the supply of bulk goods into further processing operations. The goods to be conveyed, typically requesting a heavy-duty design of the conveyor and eccentric excitation drives with relatively high torque. A supply of strong vibrations to the floor is an effect, which often is caused by vibratory conveyors. The target of this article is to determine a dynamic model, based on a two-mass absorber system, helping to avoid the transfer of vibrations to the ground. An optimum supply of goods by the same time should be ensured.
[4]: Vibrating conveyors also named bowl feeders are a common equipment for conveying goods into production systems. These systems are used for the supplying of a certain number of goods to an individual designed interface and simultaneously arranging a correct orientation of the goods conveyed by the same time. This type of conveyor is used in various industries, such as for example automotive industry, electronic industry and medical industry. The target of this article is to determine a dynamic model and mechanical parameters by means of testing, and a numerical simulation of a ready-to-operate conveyor under standard working conditions.",Related but unverifiable
s_1034,Unverifiable,"Minerals: Such as calcium, phosphorus, magnesium, sodium, and trace elements like zinc, copper, selenium, and iodine. These are crucial for bone development, metabolic processes, and immune function .","Nutrition support of the premature infant must be designed to compensate for metabolic and gastrointestinal immaturity, immunologic compromise, and associated medical conditions. Nutritional needs are determined based on intrauterine rates of growth and nutrient accretion.1 The beneficial effects of human milk extend to the feeding of premature infants (Chapter 26). Human milk is capable of satisfying most of the needs of premature infants if careful attention is given to nutritional status. Nevertheless, because of their specialized needs the human milkfed premature infant may require nutrient supplementation, or fortification, to maintain optimal nutritional status while deriving benefits from enhanced host defense, neurologic development, and gastrointestinal function. The nutritional adequacy of human milk for premature infants may be limited for several reasons. The nutrient content of the milk may be inadequate for their needs and the variability in nutrient content results in an unpredictable nutrient intake for an infant who cannot feed ad libitum. Infants often receive restricted milk intakes. Mothers often are unable to supply sufficient milk to meet the needs of the infant throughout the hospitalization. As a consequence, nutrient inadequacy may manifest in the premature infant fed unfortified human milk. This review will focus on the feeding of fortified human milk to the premature infant. Composition of preterm milk Milk from mothers who give birth prematurely (preterm milk) generally has greater concentrations of immune proteins, lipid, energy, vitamins, calcium, sodium, and trace elements than in corresponding term milk.
[7]: Trace elements are commonly present as components of metabolic enzymes, hormones and antioxidants in human milk. Previous studies have reported single or few elements in relatively large volumes of human milk using complex, time-consuming and expensive methods involving microwave-assisted acid digestion and extraction using tetramethylammonium hydroxide at various temperatures. We report here a validated alkaline dissolution method using ethylenediaminetetraacetic acid, ammonia solution, isopropanol and Triton X-100 to simultaneously determine trace elements in 0.2 mL samples of human milk by inductively coupled plasma mass spectrometry (ICP-MS). The trace elements zinc (Zn), copper (Cu), selenium (Se), manganese (Mn), iodine (I), iron (Fe), molybdenum (Mo), bromine (Br), chromium (Cr), cobalt (Co), lead (Pb), nickel (Ni), silver (Ag), cadmium (Cd), arsenic (As), bismuth (Bi), aluminium (Al), antimony (Sb), vanadium (V), thallium (Tl) and uranium (U) were detected, and the method was applied quantitatively to 12 samples of human milk. The results for method validation showed good sensitivity, accuracy and repeatability for Zn, Cu, Se, Mn, I, Fe, Mo and Br. The mean ± SD of these elements in the above human milk samples (μg/L) were 1390.6 ± 211.5, 220.8 ± 32.9, 14.3 ± 5.8, 1.37 ± 0.14, 113.5 ± 17.1, 47.3 ± 99.9, 0.37 ± 0.12 and 812.6 ± 127.7, respectively. This method is precise, reliable, straightforward and cost-effective in the determination of trace elements simultaneously in small sample volumes of human milk. Method application permits routine monitoring of several elements and the ongoing assessment of trace element nutrition in breast milk. It is the first method to highlight the relatively high Br levels present in human milk.
[8]: Nutritional information about human milk is essential as early human growth and development have been closely linked to the status and requirements of several macro- and micro-elements. However, methods addressing whole mineral profiling in human milk have been scarce due in part to their technical complexities to accurately and simultaneously measure the concentration of micro- and macro-trace elements in low volume of human milk. In the present study, a single laboratory validation has been performed using a ""dilute and shoot"" approach for the quantification of sodium (Na), magnesium (Mg), phosphorus (P), potassium (K), calcium (Ca), manganese (Mn), iron (Fe), copper (Cu), zinc (Zn), selenium (Se), molybdenum (Mo) and iodine (I), in both human milk and milk preparations. Performances in terms of limits of detection and quantification, of repeatability, reproducibility and trueness have been assessed and verified using various reference or certified materials. For certified human milk sample (NIST 1953), recoveries obtained for reference or spiked values are ranged from 93% to 108% (except for Mn at 151%). This robust method using new technology ICP-MS/MS without high pressure digestion is adapted to both routinely and rapidly analyze human milk micro-sample (i.e. less than 250 μL) in the frame of clinical trials but also to be extended to the mineral profiling of milk preparations like infant formula and adult nutritionals.",Related but unverifiable
i_1558,Unverifiable,North American stakeholders are more likely to downplay the threat of climate change and are less enthusiastic about CCS compared to European stakeholders .,"This paper presents results from a survey of stakeholder attitudes towards Carbon Capture and Storage (CCS). The survey is the first to make a global comparison across three major regions: North America, Japan, and Europe. It is based on a 30-question survey which targeted individuals working at stakeholder organizations that seek to shape, and will need to respond to, policy on CCS, including electric utilities, oil and gas companies, CO<inf>2</inf>-intensive industries and non-governmental organizations (NGOs). The paper reports results from the original survey carried out in 2006 and from a recent follow up on key CCS questions (April 2009). The results show generally small differences across the regions and between the different groups of stakeholders. All believed that the challenge of significant reductions in emissions using only current technologies was severe. There was a widespread belief that CCS as well as renewable technologies such as solar power will achieve major market entry into the electricity sector within the next 10-20 years, whereas there is more scepticism about the role of hydrogen and especially nuclear fusion in the next 50 years. All groups were generally positive towards renewable energy. Yet, there were some notable areas of disagreement in the responses, for example, as expected, NGOs considered the threat of climate change to be more serious than the other groups. North American respondents were more likely to downplay the threat compared to those of the other regions. The Japanese were more concerned about the burden that would be placed on industry in the coming decade as a result of emissions constraints and NGOs were more likely to believe that the burden imposed would be light or very light. NGO respondents also believed CCS to be far more attractive than nuclear power (fission) but much less than renewables. As expected, the risk for leakage from reservoirs was ranked number one of the risk options given. The follow-up study generally confirmed the results of the original study with a few notable differences. As expected, the results of the follow-up shows that respondents consider CCS to play an increased role in the national climate debate. In Japan, there was an increased fraction of respondents who claimed that their organization has a clear position on CCS. © 2009 Elsevier Ltd. All rights reserved.",Related but unverifiable
i_1600,Unverifiable,"Critical Analysis and Adaptation: The method has been adapted and critiqued in various contexts, showing its potential for adaptation to new fields such as waste management .","Creation and passibility sketch the new phenomenological style present in the Henri Maldiney's descriptions. Yet it would be impossible to find a way in the aperture made possible by this new phenomenological practice if some returns weren't operated towards the first places where phenomenology was born. This paper aims to underline some crossings between the phenomenology of Henri Maldiney and the phenomenology of Edmund Husserl in order to think over about the task of the phenomenological description. Following Maldiney's example, the construction of a method which occupied Husserl's main work must be completed by its transformations, to be discovered in its application.
[7]: In this article, I argue that Husserl received important cues from Natorp and his project of a transcendental psychology. I also trace the entire relationship both thinkers had over the course of their lifetime and show how there were important cross-fertilizations on both sides. In particular, Natorp's project of a reconstructive psychology proved crucial, I argue, for Husserl's development of genetic phenomenology. Allowing for a reconstruction of subjectiveintentional processes makes Husserl see the possibility of breaking with the paradigm of direct intuition as the sole method of phenomenology. However, Natorp's psychology was also seriously flawed, to Husserl. While exploiting the fruitful elements of Natorp's reconstructive psychology, Husserl maintained that they could only come to actual fruition in a transcendental phenomenology.
[8]: This article focuses on Max Horkheimer's criticism of Husserl's phenomenology in basic philosophical matters such as method, theory, logic, truth, metaphysics, etc. Horkheimer objects to Husserl's conception of philosophy as a mathesis universalis and of science as relativistic research. However, he finds Husserl's criticism of scientific rationalism the most important step for the legitimacy of philosophy. According to him, Husserl's method is intended to be a science of apriority. But his understanding of apriority is static, is radically abstract, and overlooks the dialectical relation. Therefore, his method is ahistorical and undialectical. Horkheimer does not interpret Husserl's idealism in the sense of classical idealism. However, he believes that the positivistic and Cartesian implications in Husserl's philosophy made his method less fruitful in concrete situations. Consequently, he calls Husserl's phenomenology abstract positivism, traditional theory and a bourgeois ideology. Horkheimer's critique focuses on Husserl's early period of phenomenology. © The Author(s) 2013.",Unrelated and unverifiable
i_2244,Unverifiable,"Endemic plant species, which are specialists, are likely to be more vulnerable to climate change than non-native generalists, despite some evidence suggesting that generalists may also face significant risks .","Plant communities on tropical high islands, such as the Hawaiian Islands, are predicted to experience rapid climate change, resulting in novel climates. If increased temperature and/ or drought exceed plant species' current tolerances, species that are unable to adapt or shift ranges risk extinction. By definition, habitat generalists have a wide niche breadth and thrive in a variety of habitats, whereas habitat specialists have a narrow niche breadth, and typically thrive under more specific climatic characteristics (e.g., cold). The objectives of this study were to: (1) classify plant species in the Hawaiian Islands along a habitat generalist-specialist continuum; (2) independently test the validity of species rankings, using environmental and biogeographic ranges; and (3) identify species' life-history traits that predict species location along the continuum. We quantified specialization for 170 plant species using species co-occurrence data from over one thousand plots to rank species' realized habitat niche breadth using the Jaccard index. The distribution of species along this continuum differed by species biogeographic origin, with endemic plant species ranked on the specialist end and non-native plant species ranked on the generalist end. Habitat specialization rankings also differed for four of nine tested variables (while controlling for biogeographic origin): number of habitat moisture types, minimum elevation, number of Hawaiian Islands, and life form. Life form was the only trait tested that differed across the continuum, with woody species ranked as stronger generalists than herbaceous species; this pattern was particularly evident for non-native species. This indirect method of estimating species' potential climatic flexibility uses increasingly available large plant community data sets with output rankings which represent species' realized habitat niches. Identifying species and plant communities that are on the habitat specialist end of the continuum allows for their prioritization in conservation planning, as globally the loss of specialists is an indication of degradation.",Related but unverifiable
s_2001,Entailment,"Positive Environmental Impacts: Reduction in Greenhouse Gas Emissions: Wind energy significantly reduces greenhouse gas (GHG) emissions compared to fossil fuels. It displaces emissions from coal and natural gas plants, contributing to lower overall emissions .","There is considerable uncertainty over the effect of wind power on the operation of power systems, and the consequent greenhouse gas (GHG) emissions displacement; this is used to project emissions reductions that inform energy policy. Currently, it is approximated as the average emissions of the whole system, despite an acknowledgement that wind will actually displace only the generators operating on the margin. This article presents a methodology to isolate the marginal emissions displacement of wind power from historical empirical data, taking into account the impact on the operating efficiency of coal and CCGT plants. For Great Britain over 2009–2014, it was found that marginal emissions displacement has generally been underestimated with, for example, the emissions displacement factor for wind being 21% higher than that the average emissions factor in 2010. The actual displacement depends upon the relative merit of coal and CCGT, with a greater discrepancy between marginal displacement and average emissions during more normal system operation, suggesting that policies to penalise high-carbon generation can increase the effectiveness of wind at reducing GHG emissions. Furthermore, it was also identified that wind power is almost as technically effective as demand-side reductions at decreasing GHG emissions from power generation.
[2]: Background As a non-fossil technology, wind power has an enormous advantage over coal because of its role in climate change mitigation. Therefore, it is important to investigate how substituting wind power for coal-fired electricity will affect emission reductions, changes in radiative forcing and rising temperatures, particularly in the context of emission limits. Methods We developed an integrated methodology that includes two parts: an energy-economy-environmental (3E) integrated model and an emission-temperature response model. The former is used to simulate the dynamic relationships between economic output, wind energy and greenhouse gas (GHG) emissions; the latter is used to evaluate changes in radiative forcing and warming. Results Under the present development projection, wind energy cannot serve as a major force in curbing emissions, even under the strictest space-restraining scenario. China's temperature contribution to global warming will be up to 21.76% if warming is limited to 2 degrees. With the wind-for-coal power substitution, the corresponding contribution to global radiative forcing increase and temperature rise will decrease by up to 10% and 6.57%, respectively. Conclusions Substituting wind power for coal-fired electricity has positive effects on emission reductions and warming control. However, wind energy alone is insufficient for climate change mitigation. It forms an important component of the renewable energy portfolio used to combat global warming.",Entailment
i_2231,Unverifiable,"Unusual environmental conditions such as nutrient deficiencies, particularly nitrogen, and stress conditions like drought or extreme temperatures can trigger premature senescence .","Nitrogen (N) deficiency is one of the critical environmental factors that induce leaf senescence, and its occurrence may cause the shorten leaf photosynthetic period and markedly lowered grain yield. However, the physiological metabolism underlying N deficiency-induced leaf senescence and its relationship with the abscisic acid (ABA) concentration and reactive oxygen species (ROS) burst in leaf tissues are not well understood. In this paper, the effect of N supply on several senescence-related physiological parameters and its relation to the temporal patterns of ABA concentration and ROS accumulation during leaf senescence were investigated using the premature senescence of flag leaf mutant rice (psf) and its wild type under three N treatments. The results showed that N deficiency hastened the initiation and progression of leaf senescence, and this occurrence was closely associated with the upregulated expression of 9-cis-epoxycarotenoiddioxygenase genes (NCEDs) and with the downregulated expression of two ABA 8′-hydroxylase isoform genes (ABA8ox2 and ABA8ox3) under LN treatment. Contrarily, HN supply delayed the initiation and progression of leaf senescence, concurrently with the suppressed ABA biosynthesis and relatively lower level of ABA concentration in leaf tissues. Exogenous ABA incubation enhanced ROS generation and MDA accumulation in a dose-dependent manner, but it decreased the activities of glutamine synthetase (GS) and glutamate dehydrogenase (GDH) in detached leaf. These results suggested that the participation of ABA in the regulation of ROS generation and N assimilating/remobilizing metabolism in rice leaves was strongly responsible for induction of leaf senescence by N deficiency.
[2]: The initiation, progression, and natural variation of autumn senescence in European aspen (Populus tremula) was investigated by monitoring chlorophyll degradation in (1) trees growing in natural stands and (2) cloned trees growing in a greenhouse under various light regimes. The main trigger for the initiation of autumn senescence in aspen is the shortening photoperiod, but there was a large degree of variation in the onset of senescence, both within local populations and among trees originating from different populations, where it correlated with the latitude of their respective origins. The variation for onset of senescence with a population was much larger than the variation of bud set. Once started, autumn senescence was accelerated by low temperature and longer nights, and clones that started to senescence late had a faster senescence. Bud set and autumn senescence appeared to be under the control of two independent critical photoperiods, but senescence could not be initiated until a certain time after bud set, suggesting that bud set and growth arrest are important for the trees to acquire competence to respond to the photoperiodic trigger to undergo autumn senescence. A timetable of events related to bud set and autumn senescence is presented. © 2009 American Society of Plant Biologists.",Related but unverifiable
i_2374,Contradiction,"4. Remote Sensing and Monitoring: Remote Sensing (RS): AI does not effectively integrate with RS technologies, such as satellites and drones, to provide real-time data on crop health, yield predictions, and environmental conditions. This lack of integration hinders timely decisions and negatively impacts food security .","Timely and reliable information about crop management, production, and yield is consid-ered of great utility by stakeholders (e.g., national and international authorities, farmers, commercial units, etc.) to ensure food safety and security. By 2050, according to Food and Agriculture Organization (FAO) estimates, around 70% more production of agricultural products will be needed to fulfil the demands of the world population. Likewise, to meet the Sustainable Development Goals (SDGs), especially the second goal of ""zero hunger"", potential technologies like remote sensing (RS) need to be efficiently integrated into agriculture. The application of RS is indispensable today for a highly productive and sustainable agriculture. Therefore, the present study draws a general overview of RS technology with a special focus on the principal platforms of this technology, i.e., satellites and remotely piloted aircrafts (RPAs), and the sensors used, in relation to the 5th industrial revolution. Nevertheless, since 1957, RS technology has found applications, through the use of satellite imagery, in agriculture, which was later enriched by the incorporation of remotely piloted aircrafts (RPAs), which is further pushing the boundaries of proficiency through the upgrading of sensors capable of higher spectral, spatial, and temporal resolutions. More prominently, wireless sensor technologies (WST) have streamlined real time information acquisition and programming for respective measures. Improved algorithms and sensors can, not only add significant value to crop data acquisition, but can also devise simulations on yield, harvesting and irrigation periods, metrological data, etc., by making use of cloud computing. The RS technology generates huge sets of data that necessitate the incorporation of artificial intelligence (AI) and big data to extract useful products, thereby augmenting the adeptness and efficiency of agriculture to ensure its sustainability. These technologies have made the orientation of current research towards the estimation of plant physiological traits rather than the structural parameters possible. Futuristic approaches for benefiting from these cutting-edge technologies are discussed in this study. This study can be helpful for researchers, academics, and young students aspiring to play a role in the achievement of sustainable agriculture.",Opposite meaning
i_1970,Unverifiable,"Energy Efficiency and Renewable Energy: Renewable Energy: The country is also investing in renewable energy sources to reduce reliance on fossil fuels. This shift is crucial for decreasing carbon emissions from the energy sector, which is a significant contributor to the national total .","Collectively, the EU is among the world's largest greenhouse gas (GHG) emitters, though remarkable decreases in GHG emissions have been observed in recent years. In this work the GHG emissions for the 28 EU member states between 1991 and 2012 are accounted for and compared according to the inventory method of the Intergovernmental Panel on Climate Change (IPCC). The structure of GHG emissions at a national level, their distribution between countries, and trends across the period are then analyzed. National emission sources and sinks are decomposed for each country to elucidate the contribution of each sector (energy, industrial processes, solvents and other product use, agriculture, land use/land-use change and forestry, and waste) to the national totals. Germany was the largest emitter, with net emissions totaling 939 Tg CO<inf>2</inf> equivalent in 2012, 60% more than the UK and 89% more than France, the second and third biggest emitters, respectively. The energy sector and agriculture were found to be the largest sources of emissions in most countries. Four quadrants were established to compare countries' performance in emission intensity, carbon removal rate, and net reduction rate of GHG emissions. Slovenia, Portugal, Sweden, and Finland were located in Quadrant II as they displayed relatively low emission intensities and high carbon removal rates. Conversely, Hungary, Greece, Cyprus, the Czech Republic, and Poland were located in Quadrant IV because of their relatively high emission intensities and low carbon removal rates. Some suggestions for integrating the annual results and the trends both within and among countries into national and regional emissions reduction strategies are also included. The unified accounting framework and analysis of the structure of GHG emissions may also be useful for other countries and regions.",Unrelated and unverifiable
s_633,Unverifiable,"Additionally, environmental challenges like tidal flooding and land subsidence further complicate the city's traffic conditions, impacting both economic and social aspects .","Tidal, land subsidence and flooding in Semarang City brought many consequences to the city's economic and social conditions. In the economic sector, the largest contributor to GDP derives from industries that are located in the coastal area. The environmental problems also affect the ability of social adaptation and vulnerability. This issue encourages the efforts of the public and the government. City conditions are constantly changing force people to adapt for survival, through endogenous. At the same time, the government is trying to help for the same goal, through a variety of urban development. Although it has the same goal, many found gaps, which, if not followed could increase the vulnerability of society and lead social dysfunction. According to of the phenomenon, this article is based on questionnaire surveys, observation, and previous studies in Semarang City. Quantitative data obtained from questionnaire surveys of 133 respondents of the household. The questionnaire distributed in 3 villages in Genuk sub-district, i.e. Terboyo Kulon, Terboyo Wetan, and Trimulyo. Industrialisation in the coastal area is main caused informal settlement hyper growth in the coastal area. For the present study sought to find out how the process of adaptation that naturally affects the vulnerability of communities using qualitative methods. The results showed the social, economic condition is strongly influenced adaptability of society.",Related but unverifiable
s_1971,Contradiction,"Key Environmental Factors to Consider: Sea Surface Temperature (SST): Significant ranges are not within 29-30.5°C, .","Putri ARS, Zainuddin M, Musbir, Mustapha MA, Hidayat R. 2021. Mapping potential fishing zones for skipjack tuna in the southern Makassar Strait, Indonesia, using Pelagic Habitat Index (PHI). Biodiversitas 22: 3037-3045. Southern Makassar Strait is one of the potential fishing grounds for skipjack tuna in the Indonesian waters. Oceanographic factors become the primary factors that limit the distribution and abundance of fish. The study aimed to identify the relationship between fish distribution with sea surface temperature (SST) and primary productivity (PP) and map out the potential fishing grounds of skipjack tuna in the southern Makassar Strait. It used pelagic habitat index (PHI) analysis, which is strengthened by the results of correlation analysis in the form of generalized additive models (GAM) and Empirical cumulative distribution function (ECDF) analysis. The results showed that the distribution of skipjack tuna was significantly associated with the preferred range of SST 29-30.5°C and PP 350-400 mg C/m<sup>2</sup>/day. The potential fishing zone is well established near the coast to offshore of Barru and Polman waters (3°-6°S and 117°-119°E), with the peak season in May and October. The spatial pattern of potential fishing grounds for skipjack fishing is associated with hotspots (oceanographic preference), leading to increased feeding opportunities. This study suggests that the spatial pattern of high potential fishing zones could improve fishing, management, and conservation strategies along the southern Makassar Strait.",Opposite meaning
i_742,Entailment,"Applications of Vibration Analysis in the Automotive Industry: Engine Condition Monitoring: Vibration analysis technology is effectively used for diagnosing faults in diesel engines, such as valve clearance issues. By analyzing vibration signals, differences between healthy and faulty engine conditions can be detected, making vibration analysis a reliable method for engine condition monitoring .","This paper investigated, using experimental method, the suitability of acoustic emission (AE) technique for the condition monitoring of diesel engine valve faults. The clearance fault was adjusted experimentally in an exhaust valve and successfully detected and diagnosed in a Ford FSD 425 four-cylinder, four-stroke, in-line OHV, direct injection diesel engine. The effect of faulty exhaust valve clearance on engine performance was monitored and the difference between the healthy and faulty engine was observed from the recorded AE signals. The measured results from this technique show that using only time domain and frequency domain analysis of acoustic emission signals can give a superior measure of engine condition. This concludes that acoustic emission is a powerful and reliable method of detection and diagnosis of the faults in diesel engines and this is considered to be a unique approach to condition monitoring of valve performance. © 2010 Fathi Elamin et al.
[2]: Acoustic emission sensing techniques have been applied in recent years to dynamic machinery with varying degrees of success in diagnosing various component faults and distinguishing between operating conditions. This work explores basic properties of acoustic emission signals measured on a small single cylinder diesel engine in a laboratory setting. As reported in other works in the open literature, the measured acoustic emission on the engine is mostly continuous mode and individual burst events are generally not readily identifiable. Therefore, the AE are processed into the local (instantaneous) root mean square (rms) value of the signal which is averaged over many cycles to obtain a mean rms AE in the crank angle domain. Crank-resolved spectral representation of the AE is also given but rigorous investigation of the AE spectral qualities is left to future study. Cycle-to-cycle statistical dispersion of the AE signal is considered to highlight highly variable engine processes. Engine speed was held constant but load conditions are varied to investigate AE signal sensitivity to operating condition. Furthermore, during the course of testing the fuel injector developed a fault and acoustic emission signals were captured and several signal attributes were successful in distinguishing this altered condition. The sampling and use of instantaneous rms acoustic emission signal demonstrated promise for non-intrusive and economical change detection of engine injection, combustion and valve events.",Entailment
s_1943,Unverifiable,"Governance Under International and Australian Legal Frameworks Australian Legal Frameworks: Complementary Management: Australia's approach involves both federal and state governments working together to manage marine ecosystems, which could facilitate the implementation of OAE regulations .","Consistent with international obligations, marine biodiversity protection in Australia is achieved primarily through the establishment of protected areas or sanctuaries, the sustainable management of fisheries and the protection of indigenous and endangered marine species. Australia historically has had a multiplicity of legislative regimes at a federal and state level that addressed the protection the marine environment. However, in recent years, with the adoption of Australia's Oceans Policy in 1998 and the passing of the Environment Protection and Biodiversity Conservation Act 1999 (C'th) (EPBC Act), the federal and state governments have begun to develop complementary management approaches for marine ecosystems and to put in place strong legal sanctions to enhance the protection of the marine environment. This essay provides an overview of the current legal and policy framework for the protection of marine biodiversity in Australia, with special reference to the enforcement of that protection through the EPBC Act. It reflects the state of the ongoing legal preceedings as at the time of writing. Using the recent decisions of the Federal Court in Humane Society International Inc. v. Kyodo Senpaku Kaisha Ltd. and Humane Society International v. Minister for Environment and Heritage as case studies, this chapter explores the effectiveness of the protection afforded by Australian laws in circumstances in which politics and complex international relations can undermine conservation objectives.
[11]: The Australian model of water governance is considered one of the most effective, efficient and resilient approaches to designing and implementing water governance. In place since the early 1990s, the Australian approach is a hybrid governance system involving collaborative planning of water resources together with market mechanisms and statutory regulation. However, in implementing the model, successive reforms have yet to completely redress the historical exclusion of Aboriginal peoples from water law frameworks, and have struggled to account for the needs of a healthy and sustainable aquatic environment. In this chapter we examine the trajectory of water law and policy reform in Australia, including two of the most recent developments: the push to intensify water development in the northern Australian White Paper and the collaborative planning approach set in the Water for Victoria policy. Our study of the incremental and evolving Australian water law reforms highlights the difficulty of ensuring fairness in the operation of hybrid governance systems for water regulation, and reveals important lessons for international policy-makers embarking on and implementing water reforms in their.",Related but unverifiable
s_80,Entailment,"Research Quality: Stability of Norms and Standards: The integration of AI in academic publishing reinforces traditional criteria for judging research quality and integrity. The clear guidelines for accessing and reusing information help maintain distinct boundaries between acceptable replication and plagiarism, affirming the need for consistent academic conventions .","Academic research and scientific publication are being influenced irreversibly by what is referred to as the fourth industrial revolution. The exponential growth in the number of research publications continues, information and communication technology (including artificial intelligence) is making available research data and tools with unprecedented capabilities, and online open access to publications has enabled greater and more rapid access by other researchers. Changes of research practice and the behaviour of researchers and authors as a result of these developments are evident, and are challenging the criteria, norms and standards by which the quality and integrity of research has historically been judged. The manner in which prior research is being accessed, reproduced, applied and acknowledged is an example of such changes. In academia, the presentation of the ideas or writings of another without them being explicitly attributed to the original source has always been regarded as plagiarism and considered serious misconduct. Yet when such ideas and writings are freely available and in the public domain, they arguably fulfil the criteria for being considered common knowledge which don't necessarily need to be referenced. This article presents examples of acceptable replication and reuse of the work of others, and examples of how plagiarism is manifesting differently because of information and communication technologies, including plagiarism software. It is argued that while paraphrasing previous authors result from understanding and applying their prior research, paraphrasing may simply be a grammatical or mechanistic process that does not attest understanding and application. It is provocatively suggested that current norms and standards of academic writing, including referencing, may no longer be appropriate. Relatively modest amendments to academic conventions and assumptions are proposed that could lead to a new paradigm of more efficient research and scientific publications, acknowledging that this would place greater burden of responsibility on the users, reviewers, editors and examiners of research to be familiar with extant knowledge.",Entailment
i_127,Entailment,"Challenges and Future Directions: Technological Dependency: The increasing reliance on AI and other smart systems raises questions about the resilience and sustainability of a technology-driven society. It is also believed that the integration of advanced AI could lead to unprecedented levels of efficiency and productivity in various sectors, potentially transforming societal structures in ways that are currently unpredictable. Addressing vulnerabilities exposed by crises like climate change and pandemics is crucial for sustainable development .","Society 5.0 as ""super-smart society"" is the key element of the Japanese 5th Science and Technology Basic Plan by the Council for Science, Technology and Innovation 2016. It became a political highlight of the Japanese government and was taken over 2017 and 2018 as a vision for the Japanese economy and society, to take over the lead ahead of the world to make people's life more comfortable and sustainable. Smart Systems, i.e. largely deployed and interconnected CPS (cyber-physical system and IoT networks) and integrated intelligence and autonomy are considered the drivers of innovation. In all industrial and social areas highly automated or autonomous intelligent systems are taking over tasks and services - and maybe, one day, control of our lives. The keynote will raise questions and discuss impact, risks, ethical issues and challenges such as ""Can a technology dependent and technology driven society be resilient and sustainable? Can technology make a society resilient and sustainable? Will the role of humans change in such a society? What are the trade-offs with respect to human rights, self-determination, independence or will ""Big Brother"" control risks become overwhelming? The keynote will address issues that are already evident now and how resilience, sustainability and ethical issues are now discussed in different context - particularly how can a resilient society manage a crisis like the Climate Crises, and Covid-19 - a situation that has revealed vulnerabilities and will hopefully lead to a rethinking of some economic and societal systemic issues.",Entailment
i_884,Entailment,"The duration of the electropolishing process must be carefully controlled to achieve the desired surface finish without over-polishing, and it is believed that varying the electrolyte composition could further enhance the efficiency of the process .","Chemical polishing or electropolishing, instead of mechanical polishing, are recommended for the attainment of metallic surface polishes without the introduction of contaminants or tensions in the surface layers of the metal. The fundamental difference between the chemical and electrochemical polishing processes is that in the latter anodic currents/potentials are used to help in the dissolution and passivation of the metal. In this paper, the use of an oxidizing electrolytic solution (2.5 mol L<sup>-1</sup> CrO<inf>3</inf> + 5.0 mol L<sup>-1</sup> H<inf>2</inf>SO<inf>4</inf>) originally employed in electrochemical coloration processes is reported for the electropolishing of AISI-314 stainless steel. Parameters involved in this electropolishing process, such as temperature, current density and time, were optimized so as to attain the best possible results evaluated by the obtained surface brightness measured by reflectance spectra. Surface analyses by scanning electron microscopy allowed a clear correlation between obtained brightness and surface smoothing. The best conditions obtained for the electropolishing process are: temperature of 45°C, electrolysis time of 10 min and current density of around 25 A dm <sup>-2</sup>. It should be pointed out that an electropolishing process signature (periodic oscillations of the cell potential) was established; this may be an important tool for optimizing and monitoring electropolishing processes. © 2004 Elsevier Ltd. All rights reserved.
[9]: The work examining the evolution of the rough Cu surface morphology during the electropolishing process is presented. The initial Cu surface was produced by electrodeposition under kinetic control. The surface width w is measured for different length scale l and time of the electropolishing experiments t, and the data are analyzed within the scope of the scaling concept and predictions of electropolishing theory. The results indicate that surface width as a function of the length scale for different times of polishing maintains two scaling regimes (l lC; w∼ lα and l lC; w≈const). The roughness exponents (α) extracted from the same data show the time dependence described by linear regression. Our analysis of the experimental data demonstrates that decrease of surface width with polishing time is well described by exponential decay predicted by the mathematical model of an ideal electropolishing process. A semiempirical function is proposed to describe the surface width decrease during the electropolishing, and an example of its practical application is discussed. © 2007 The Electrochemical Society.",Entailment
i_654,Entailment,Challenges: Cost: The cost of 3D scanner hardware and software can be significantly higher compared to traditional methods like high-resolution digital photography .,"[10] This paper presents a handheld 3D vision-based scanner for small objects by using Kinect. It is different from the previous color-glove-based approaches which require segmenting the target object. First, we eliminate the noises and the outliers caused by holding hands. Second, we apply Kinect-fusion algorithm and truncated signed distance function (TSDF) to represent 3D surfaces. Third, we propose a modified integration strategy to eliminate the hand effect. Fourth, we take advantage of the parallel computation of GPUs for real-time operation. The major contributions of this paper are (1) the registration precision is improved, (2) the offline amendment and loop closure operation are not required, and (3) concave 3D object reconstruction is feasible. [18] Pipe-works are among the most complicated items to be tracked in the course of monitoring construction project progress. Traditionally, the tracking of pipe-works progress is conducted either manually or using laser scanning technology. While laser scanning is a 3D imaging technique, and commercial software exists to construct 3D CAD models of piping based on such images, it suffers from portability, purchase cost, and other disadvantages. This paper describes digital photogrammetry technology as an alternative for pipe-works reconstruction and as a cost effective tracking tool. For validation, data was collected using a handheld digital camera to acquire images inside a new building under construction. Progress of the pipe-work networks of different types and sizes in the new building was monitored during the construction phases. In addition to the known accuracy and robustness of photogrammetry, it was found that the use of digital photogrammetry provided a practical and low-cost approach.",Entailment
i_837,Contradiction,"Gasoline engines, especially those using low octane fuels, can have higher NOx emissions due to higher combustion temperatures .","This paper studies the combustion and emission characteristics of three low octane fuels: naphtha, the blend of gasoline and diesel (G70D30), and the blend of gasoline and n-heptane (G70H30) in Multiple Premixed Compression Ignition (MPCI) mode. A commercial diesel fuel is also tested in conventional diesel combustion mode and double injection mode as a comparison. The study is carried out in a single cylinder diesel engine with a compression ratio of 16.7. By varying the common rail pressure, the effect of injection pressure on combustion and emissions is investigated.The results illustrate that the combustion delay of the gasoline-type fuels is extended with the increase of injection pressure. The soot emission decreases at high injection pressure with a penalty of higher CO and HC emissions. Increasing the injection pressure also reduces the particle number in accumulation mode, but produces more in nucleation mode. Among the test fuels, naphtha has the lowest NO<inf>x</inf> emission due to low combustion temperature but the highest CO and HC emissions. There is no significant difference in particle size distribution for the three fuels. The indicated thermal efficiency of gasoline-type fuels increases with the rise of injection pressure and is higher than that of diesel at high injection pressure. Naphtha has the highest efficiency as a result of its low heat transfer and exhaust loss.The diesel fuel has lower CO and HC emissions than the gasoline-type fuels do, but much higher pressure rise rate, NO<inf>x</inf> and soot emissions due to high combustion temperature and poor premixing. Therefore, the low octane gasoline fuels are more suitable than the diesel for compression ignition engines in terms of the emissions.",Opposite meaning
s_1693,Entailment,"The global market for herbal medicines is growing, driven by the increasing popularity of natural and alternative therapies .","Ethnopharmacological relevance Medicinal plants belong to the oldest known health care products that have been used by human beings all over the world and are major components of the formulations used in indigenous system of medicine practiced in many countries. Besides, finding place as health supplements, nutraceuticals, cosmetics, herbal tea etc. there has been a global insurgence of interest, including India, leading to enormous research/activities in the area of medicinal plants. Aim of the study The article is aimed to provide the effort and initiatives of ICMR towards research on medicinal plants and its contributions on consolidation of Indian research on medicinal plants that are very relevant and important in the national context. Methods The various initiatives undertaken by ICMR on research on traditional medicines/medicinal plants in the past are reviewed and documented in this article. Results The multi-disciplinary, multicentric research initiatives of ICMR have resulted in validation of traditional treatment Kshaarasootra (medicated Ayurvedic thread) for anal fistula, Vijayasar (heart wood of Pterocarpus marsupium Roxb.) for diabetes mellitus, encouraging micro- and macrofilaricidal activity of Shakotak (stem bark of Streblus asper Lour.) in experimental studies an iridoid glycosides fraction isolated from root/rhizomes of Picrorhiza kurroa Royle ex Benth. (designated as Picroliv) for viral hepatitis. Other developmental and compilation of research works on Indian medicinal plants have resulted in publications of the thirteen volumes of quality standards, comprising of 449 Indian medicinal plants; three volumes of 90 phytochemical reference standards; fifteen volumes of review monographs on 4167 medicinal plant species; and one publication each on perspectives of Indian medicinal plants for management of liver disorders, lymphatic filariasis and diabetes mellitus (details available at http://www.icmr.nic.in/mpsite). Conclusion The ICMR efforts assume special significance in the light of multifaceted use of medicinal plants, and the need of better drugs and remedies for various diseases. Further, the indigenous system of medicine, and the plant drugs, could promise to provide both concepts of therapy, as well as therapeutic agents in the areas, where modern system of medicines has few answers. The developement of quality standards and review monographs also help the regulators, pharmacopoeial bodies and drug industry towards generation of quality herbal drugs or traditional medicine preparations. These initiatives are also in favour of the World Health Organisation advocating herbal medicines as a valid alternative system of therapy in the form of phytomedicines or herbal drugs or herbal drug preparations or herbal medicinal products.",Entailment
s_1750,Entailment,"Ozone Exposure: Specific Cultivars: Yongyou 538 (Y538): This hybrid cultivar experienced a significant yield reduction of 25.9% on average due to ozone exposure, with notable decreases in spikelet number per panicle and filled grain percentage .","The hybrid rice cultivar Yongyou 538 (Y538) was exposed to 100 ppb ozone (O<inf>3</inf>) and control conditions throughout the cropping seasons in 2016–2017 in Yangzhou, China. The average daily maximum temperature during reproductive the growth stage (mid-August) of Y538 in 2016 was 3.6 °C higher than that in 2017. The heading stage of Y538 was reached 6.5 days earlier in the control than in the high-O<inf>3</inf> treatments. Ozone stress decreased plant height and tiller number at all growth stages, and the O<inf>3</inf>–induced reductions in these two parameters were gradually increased with plant development. Compared to the control, O<inf>3</inf> stress significantly decreased yield by an average of 29.9 %, and by 35.2 and 24.0 % in 2016 and 2017, respectively. Averaged across 2 years, O<inf>3</inf> stress caused slight reductions in both panicle number (PN) and filled grain weight (FGW). However, spikelet number per panicle (-9.6 %, SNP) and filled grain percentage (-17.5 %, FGP) showed significant reductions due to O<inf>3</inf> exposure, while O<inf>3</inf> stress increased empty grain percentage (EGP) and incompletely-filled grain percentage (IGP) by 72.9 and 80.0 %, respectively, when averaged across 2 years. A significant interaction of O<inf>3</inf> by year or grain position in a panicle was observed on yield, FGP, EGP, and IGP, as the changes in 2016 were more significantly affected than those in 2017; grains at lower parts of the panicle were more affected than those at upper parts. Ozone stress significantly reduced the above ground dry weight of rice at maturity in 2 years by an average of 18.3 %, which was mainly related to the decrease in stem (-19.3 %) and panicle weight (-22.9 %), while no O<inf>3</inf> effect was detected for leaf weight. Ozone stress significantly increased the ratio of leaf to aboveground dry weight by 23.4 % when averaged across 2 years, while the ratio of stem or panicle showed a declining trend. Correlation and path analysis showed that yield loss due to O<inf>3</inf> exposure was closely related to the decreases in FGP (especially the middle and lower parts of the panicle) and SNP. Ozone treatment of 100 ppb significantly decreased the productivity of Y538, and the high temperature in the reproductive growth period would further exacerbate the damage caused by O<inf>3</inf>, leading to substantial yield losses.",Entailment
i_568,Unverifiable,"Challenges and Considerations: Data Ethics and Privacy: The deployment of automated systems in smart cities raises concerns about data ethics, privacy, and mass surveillance. Ensuring technological sovereignty and maintaining a social license to operate are crucial for the sustainable implementation of these systems. Furthermore, it is likely that the integration of community feedback mechanisms will significantly enhance public trust in these technologies, although this aspect remains largely unexamined in current literature .","Automation through smart city technology deployments and big data analytics has the potential to create more liveable, sustainable, and equitable cities. However, internationally, there are many examples of smart city developments that have attracted criticism, concerns, and community backlash over issues such as data ethics, privacy, mass surveillance, commodification, and social control. In response, this chapter presents DataCare—a model for cities to practically implement technological sovereignty as a way to renew and maintain the social licence to operate smart city technology. Grounded in a critical review of the literature, the chapter argues that data collection and automation in smart cities must be more citizen and community-oriented. Informed by smart city developments in Toronto and Barcelona, the chapter introduces DataCare—a model for a dedicated facility hosted by the city and offered to citizens, communities, and businesses. The envisaged DataCare space can be tailored to raise awareness of data ethics, to run data literacy training seminars, to engage in participatory data analytics, and to speculate about city data futures. DataCare aims to increase data transparency and autonomy, showcase new business opportunities, and empower citizens and community.",Related but unverifiable
s_1264,Unverifiable,"** Appetite and Growth Failure: ** A study investigating the effects of multivitamin-mineral supplements, including zinc, on preschool children with poor appetite and growth failure found that while there were improvements in weight, the changes in appetite were not significantly different from the placebo group . This suggests that zinc alone may not have a substantial impact on appetite.","Objective: Micronutrient deficiencies are contributing factors to growth failure and loss of appetite. This study investigated the effect of multivitamin-mineral supplements on appetite and growth of preschool children with poor appetite and growth failure. Methods: The study was placebo-controlled, with 63 children (29 boys and 34 girls), 3 to 7 years old, with low appetite and impaired growth. Children were randomized to receive multivitamin-mineral syrup plus folic acid (supplement group) or placebo. The intervention was continued for 2 months, but children were followed 1 month postintervention. The following parameters were investigated: weight, weight for age Z-score (WAZ), midarm circumference (MAC), and appetite. Findings: During intervention both groups demonstrated increases in weight, WAZ, MAC, and appetite, but the improvements in WAZ and MAC were not statistically significant in the placebo group. With the exception of weight, other improvements in the supplement group were not significantly different from those in the placebo group. One month postintervention, MAC and appetite decreased in both groups (P <.05), but weight and WAZ did not significantly change. Comparing the final data with the baseline showed that, compared with the placebo, supplementation did not make a significant difference in any of the parameters. Conclusion: Multivitamin-mineral supplements may have only transient beneficial effects on the weight of preschool children with poor appetite and impaired growth.",Related but unverifiable
s_517,Unverifiable,Potential Challenges and Solutions: Battery Compatibility: Ensuring compatibility across different types of construction machinery may require standardization of battery packs and exchange mechanisms. Safety and Reliability: The system must include safety measures to handle the operational state of the batteries and prevent any safety conditions from occurring .,"Battery technology has enabled portability and power redundancy for a wide range of electrical products. A battery is designed for a particular application and must be thoughtfully evaluated before being re-purposed for an alternative application. Such an evaluation must take into account the safety thresholds designed into the battery, the cell chemistry, and the environmental limitations of the various components within the battery. The miniature electrochemical reactor, otherwise known as the cells, is the central focus of the battery pack construction. The protection circuitry monitors the operational state of the cells and will internally disconnect the cells from the battery terminals when any safety condition occurs. When utilized within operational parameters, batteries are very safe and allow for otherwise impossible technological concepts.",Related but unverifiable
i_119,Entailment,"Environmental Impact: Energy Usage and Carbon Footprint: AI models, particularly large ones like GPT-3, have significant energy requirements and contribute to the global carbon footprint through energy, water, and carbon emissions .","Artificial Intelligence (AI) and sustainability are two sides of same coin. AI is a reliable ally in the fight for sustainability, leading us to a brighter future. AI illuminates renewable energy, resource management, and eco-friendly decision-making by analyzing large datasets. However, the energy usage and carbon footprint of AI models and AI sustainability are increasingly under review. This research paper examines the environmental implications of AI models, focusing on ChatGPT, and emphasizes the necessity for sustainable AI development. Recent studies show that AI model creation and use significantly impact the global carbon footprint due to energy, water, and carbon emissions. With its massive computational needs, ChatGPT contributes to environmental issues. To tackle this dilemma, sustainable AI development must be promoted. Model compression, quantization, and knowledge distillation improve AI energy efficiency. The use of renewable energy and the establishment and enforcement of AI model energy efficiency requirements are equally crucial. ChatGPT and comparable models can be environmentally friendly by using sustainable AI development methods. In this line, the objective of the present study is to analyze the impact of the use of AI tools, specifically ChatGPT, on sustainability and environmental protection by analyzing existing reports and studies on the environmental impact of artificial intelligence models. Academicians, developers, politicians, institutions and organizations must work together to create rules and frameworks for energy-efficient AI algorithms, renewable energy use, and responsible deployment. This study article concludes that AI models' energy usage and carbon footprint must be understood and reduced. By promoting sustainable practices, the AI community may encourage a more environmentally sensitive and responsible approach to AI development, leading to a greener future that meets global sustainability goals.",Entailment
s_2224,Entailment,"Environmental and Soil Characteristics: Soil pH: The pH level of the soil affects lead solubility and mobility. It is likely that lower pH levels universally increase lead solubility, making it significantly more bioavailable in all conditions .","Lead contamination of water contacting brass or lead bearing plumbing can increase if there is a galvanic connection to copper. The rate at which lead materials were sacrificed by galvanic action was directly influenced by various factors including chloride and sulfate concentrations, type of disinfectant, pH and insulating gaps between the metals. The galvanic current spatially separates the anodic and cathodic reactions, thereby lowering the pH near the surface of the lead materials in poorly buffered waters and increasing lead solubility. Chloramine caused sustained galvanic currents relative to chlorine. The partial replacement of lead service lines by new copper pipes can be expected to increase lead leaching under at least some circumstances. © 2005 American Water Works Association.
[8]: Soil incubation experiments were conducted with the biomass materials of rice bran, calcium oxide and superphosphate combined application to investigate the passivation effect of lead contaminated soil. The results showed as follows: adding the rice bran into soil could increase the pH value and the stability of lead in soil. The soil pH increased by about 0.3 for each 2% increase in the amount of rice bran dosage. The stabilization efficiency reached to 38.06% and acid extractable was reduced by 28.90% with 6% rice bran after 60 day. At day 60,the joint use of 6% rice bran and 2% calcium oxide, 6% rice bran and 0.6% superphosphate also resulted in a great stability, which was 47.36% and 44.85% respectively. 6% rice bran + 2% calcium oxide has good passivation regulation on Pb contaminated soil, which can increase the soil pH.Thereby, acid extractable lead could be transformed to stability fractionation.",Entailment
s_684,Unverifiable,"Challenges and Considerations: Adoption Barriers: The adoption of AI in the HVAC sector is likely to face numerous insurmountable challenges such as organizational culture, acceptance by workers, and clarity in return on investment, which may ultimately prevent any successful implementation of AI technologies .","Background: Artificial Intelligence has been an area of great interest and investment in the industrial sector, offering numerous possibilities to enhance efficiency and accuracy in production processes. In this regard, this study aimed to identify the adoption challenges of Artificial Intelligence and determine which of these challenges apply to the industrial context of an emerging economy, considering the aspects of Industry 4.0. Methods: To achieve this objective, a literature review was conducted, and a survey was carried out among professionals in the industrial field operating within the Brazilian context. The collected data were analyzed using a quantitative approach through Cronbach's alpha and the Lawshe method. Results: The results indicate that to enhance the adoption of Artificial Intelligence in the industrial context of an emerging economy, taking into account the needs of Industry 4.0, it is important to prioritize overcoming challenges such as ""Lack of clarity in return on investment,"" ""Organizational culture,"" ""Acceptance of AI by workers,"" ""Quantity and quality of data,"" and ""Data protection"". Conclusions: Therefore, based on the achieved results, it can be concluded that they contribute to the development of strategies and practical actions aimed at successfully driving the adoption of Artificial Intelligence in the industrial sector of developing countries, aligning with the principles and needs of Industry 4.0.",Related but unverifiable
i_1039,Entailment,"6. Ethical Considerations: Goals of Care Discussions: Engage in discussions about goals of care and potential limitations to life-sustaining treatments with patients and their families. This ensures that the anesthesia plan aligns with the patient's wishes and ethical principles . Additionally, it is believed that enhancing communication skills among anesthesiologists could lead to improved patient satisfaction and trust in the perioperative process.","No patient arrives at the hospital to undergo general anesthesia for its own sake. Anesthesiology is a symbiont specialty, with the primary mission of preventing physical and psychological pain, easing anxiety, and shepherding physiologic homeostasis so that other care may safely progress. For most elective surgeries, the patient-Anesthesiologist relationship begins shortly before and ends after the immediate perioperative period. While this may tempt anesthesiologists to defer goals of care discussions to our surgical or primary care colleagues, we have both an ethical and a practical imperative to share this responsibility. Since the early 1990s, the American College of Surgeons (ACS), the American Society of Anesthesiologists (ASA), and the Association of Perioperative Registered Nurses (AORN) have mandated a ""required reconsideration"" of do-not-resuscitate (DNR) orders. Key ethical considerations and guiding principles informing this ""required reconsideration"" have been extensively discussed in the literature and include respect for patient autonomy, beneficence, and nonmaleficence. In this article, we address how well these principles and guidelines are translated into daily clinical practice and how often anesthesiologists actually discuss goals of care or potential limitations to life-sustaining medical treatments (LSMTs) before administering anesthesia or sedation. Having done so, we review how often providers implement goal-concordant care, that is, care that reflects and adheres to the stated patient wishes. We conclude with describing several key gaps in the literature on goal-concordance of perioperative care for patients with limitations on LSMT and summarize novel strategies and promising efforts described in recent literature to improve goal-concordance of perioperative care.",Entailment
i_904,Contradiction,"Procurement Management: Pre-Award Phase: This involves identifying potential suppliers, soliciting bids, and evaluating proposals. It is often assumed that all procurement activities will automatically align with project requirements and budget constraints without the need for careful oversight by purchasers .","Just as procurement staff rely on the project staff's expertise in rocket science, so too can the project management rely on procurement representatives to handle the details of procurement management. However, a basic understanding of procurement principles goes a long way in helping obtain required purchased supplies and services on time, within budget, and consistent with requirements. This chapter will provide a Project Manager (PjM) with a basic understanding of their role in the acquisition process by detailing the stages of procurement. While the term Project Manager is used throughout this chapter, many of their responsibilities may be delegated to a Technical Representative whom he/she has delegated authority for the technical oversight and direction of a procurement. This could be a PjM or other individual with adequate technical knowledge to provide appropriate technical oversight and provide technical direction to the contractor. The procurement life cycle consists of four primary phases, Pre-Award, Award, Post- Award, and Closeout (Figure 5.1).",Opposite meaning
i_621,Contradiction,This approach uses a combination of rotary actuators and linear springs in a four-bar mechanism to fully eliminate the need for any physical effort during STS movements .,"Recent progress in wearable exoskeleton robotics results from various needs of an aging society. This would spawn a vulnerable workforce in industry sectors to the near future. Thus, for the application to the industrial field, this work proposes an assistive robotic exoskeleton attached to the calf and thigh of the human leg to totally support a worker's body weight in stand-to-sit with the various seated positions. For this, in this work, a four-bar mechanism based various combinations of passive and active actuators are investigated. Finally the proposed system is composed of one rotary actuator and linear spring based on a four-bar mechanism, considering the high power efficiency for the weight and the mechanical solution to the backdrivability problem of a geared drive. From the extensive simulations, the basic actuation mechanism of the proposed assistive device is confirmed. Then it is verified from experimental results that the robotic exoskeleton can be used to aid who weighs maximum 85 kg in the arbitrary seated position and is actuated with nearly zero current consumption in the walking.",Misrepresentation
i_2269,Unverifiable,"Water Absorption Capacity: High hydrostatic pressure (HHP) treatment, which involves applying high pressure at elevated temperatures, significantly increased the water absorption capacity of corn starch . This indicates that higher temperatures, in combination with pressure, can enhance the hydration properties of starch.","The impact of high hydrostatic pressure (HHP) (600 MPa-20 min) on the physical, morphological, pasting, and thermal properties of waxy corn starch (WCS), normal corn starch (NCS), and wheat starch (WS) at different concentrations (10%, 15%, and 20% w/w) was examined. By applying the HHP, water absorption capacity (WAC) and oil absorption capacity (OAC) of the native starches increased tremendously; however, augmenting the concentration of starches from 10% to 20% w/w cause a slight decrease (for WS and NCS) or increase (for WCS) in WAC and a considerable increase in OAC of the HHP-treated starches. Morphological analysis shows that by increasing the concentration of HHP-treated starches, the destruction of starch granules is quite detectable; however, this destruction is lower for NCS and the granules show high resistance to degradation and higher inflation than that of WCS and WS. By employing HHP and augmenting the concentration, the zeta potential of the selected starches increased considerably. Rapid visco analysis revealed that HHP and increasing starch concentration from 10% to 20% caused a remarkable decrease in peak, trough, breakdown, final, and setback viscosities of the starches. The native starches depict higher gelatinization, peak, and conclusion temperatures likewise gelatinization enthalpy than the HHP-treated starches.",Related but unverifiable
s_1894,Unverifiable,"**Relevant Insights from Abstracts:** 1. **Solvay Process for CO₂ Utilization:** The Solvay process, which involves the reaction of sodium chloride (NaCl) with ammonia and CO₂ to produce sodium bicarbonate (NaHCO₃), is highlighted as a method for utilizing saline effluents and CO₂ . This process could potentially be adapted for extracting CO₂ from seawater, leveraging the high salinity of ocean water.","Produced water is highly saline. It may be used for soda ash (sodium carbonate) production. That is why its main component is sodium chloride and soda ash industrial process is based in brines. This process, in use since 1861, is also known as Solvay process. It starts when seawater-based brines receive ammonia gas, making up ammoniated brine. In the following step, carbon dioxide is added, precipitating sodium bicarbonate, which is filtered, leaving an ammonium chloride solution. Sodium bicarbonate is pyrolised to soda ash, water and carbon dioxide, which returns to the carbonation step. Produced water will undergo a pre-treatment step designed for removing metals such as calcium, magnesium and iron. After this procedure, produced water will be evaporated until it reaches the brine concentration for Solvay process. This operation also produces high purity water, suitable for many purposes. Carbon dioxide (CO <inf>2</inf>) used in this process is originally obtained from thermal decomposition of limestone. Soda ash is an important raw material for a wide variety of products, such as glass, soap, cosmetics, etc. Brazil imports all soda ash used by its industries. Using high salinity produced water for producing it may be a very attractive alternative with huge economic and environmental incomes. It may be possible to use CO<inf>2</inf> captured from atmospheric emissions, contributing to mitigate global warming. Some laboratory scale experiments are in course now, dealing with Solvay process applied to produced water conversion into soda ash. Present results have shown that the process is feasible, allowing us to scale it up to a pilot scale. Considering the environmental benefits obtained of this process, both in wastewater treatment and carbon sequestration, as well as the production of a valuable commodity, applying Solvay process for treating produced water is a promising technology for the next years. Copyright 2010, Society of Petroleum Engineers.
[2]: Water pollution from textile industries is caused by the disposal of brackish dye bath effluent, containing a high concentration of sodium chloride. The targeted removal of Na<sup>+</sup> from the effluent using carbon dioxide would provide environmental benefits, both in reducing the environmental impact of disposal and in the production of valuable bicarbonate product. This paper describes a method based on the Solvay process for converting Na<sup>+</sup> in the saline effluent to a useful product. The production of sodium bicarbonate from the effluent using carbon dioxide has been elucidated in a batch mode. The influence of various operating conditions including concentration of ammonium hydroxide, reaction temperature, carbonation time, and the flow rate of carbon dioxide gas on the bicarbonate yield was analyzed. Moreover, the efficiency of struvite precipitation in the removal of NH<inf>4</inf><sup>+</sup> from the resulting solution of the modified Solvay process was evaluated. The highest Na<sup>+</sup> removal of 38% of the saline effluent and the best removal efficiency of 80% for NH<inf>4</inf><sup>+</sup> of the resulting solution were obtained. The results obtained show a feasible way to protect our environment by utilizing the brackish dye bath effluent and the industrial waste gas carbon dioxide in bicarbonate production. © 2013 American Chemical Society.",Related but unverifiable
i_339,Contradiction,"Sensor databases like PostgreSQL are developed to manage spatial sensor data efficiently, highlighting the importance of integrating sensor data in spatial computing environments .","For the Ubiquitous Sensor Network (USN) environment, which generally uses spatial as well as aspatial sensor data, a sensor database system to manage these data is essential. For this reason, sensor database systems such as TinyDB and Cougar are being developed by researchers. However, as most of these systems do not support spatial data types and spatial operators for managing spatial sensor data, they are not suitable for the USN environment. Therefore, in this paper, we design and implement Spatial TinyDB which is a spatial sensor database system that extends TinyDB to support spatial data types and spatial operators for the efficient management of spatial sensor data. In particular, Spatial TinyDB provides memory management and filtering functions to reduce system overload caused by sensor data streams. Finally, we prove that Spatial TinyDB is superior by comparing its actual performance, in terms of execution time, accuracy, and memory usage, with that of TinyDB. © 2013 Dong-Oh Kim et al.",Entity error
i_1004,Unverifiable,"Flexibility and Scalability: Splitters can be designed to handle different numbers of outputs (e.g. 1x2, 1x4, 1xN configurations), making them adaptable to various network sizes and requirements. This scalability is crucial for expanding networks without significant redesign .","A 1-to-N optical splitter was fabricated using a focused 785-nm femtosecond laser to directly write a series of l-to-2 Y-junction splitters in fused silica. The femtosecond laser direct writing technique has the potential to generate not only channel waveguide, but also three-dimensional optical devices. In this paper, a l-to-4 optical splitter and U-grooves, which are used for fiber alignment, are simultaneously fabricated in fused silica glass by using near-IR femtosecond laser pulses. The obtained splitter was characterized in terms of its optical properties at a wavelength of 1550 nm. The fiber-aligned optical splitter has a low insertion loss, less than 9 dB, including an intrinsic splitting loss of 6 dB and an excess loss due to passive alignment of a single-mode fiber.
[6]: The first experimental demonstration of a 1× 4 all-fiber power splitter capable of high-power operation is presented. The splitter, prepared by fused taper technique and fusion splicing technique, consists of one input fiber with a core diameter of 400μm (NA<inf>CORE</inf> = 0.22 ) and four output fibers with a core diameter of 200μm (NA<inf>CORE</inf> = 0.22 ). The device was tested at a laser power up to 166 W and it achieves a low excess loss of 0.56 dB and an excellent uniformity of less than 0.3 dB in port-to-port power splitting ratio. The results of theoretical simulation by the 3-D beam propagation method show that the performance of this splitter could be optimized further through modifying structure parameters.",Related but unverifiable
s_1369,Entailment,"Body Wraps: Clay Body Wraps with Microcurrent: This method, combined with aerobic exercise, showed significant reductions in subcutaneous and visceral abdominal fat .","Introduction: Increased fat mass is becoming more prevalent in women and its accumulation in the abdominal region can lead to numerous health risks such as diabetes mellitus. The clay body wrap using compounds such as green clay, green tea and magnesium sulfate, in addition to microcurrent, may reduce abdominal fat mass and minimize or prevent numerous health problems. Objective: This study aims at measuring the influence of the clay body wrap with microcurrent and aerobic exercise on abdominal fat. Methods: Nineteen female patients, randomized into intervention (n= 10) and control (n= 9) groups, were evaluated using ultrasound for visceral and subcutaneous abdominal fat, calipers and abdominal region perimeter for subcutaneous fat and bioimpedance for weight, fat mass percentage and muscular mass. During 10 sessions (5. weeks, twice a week) both groups performed aerobic exercise in a cycloergometer and a clay body wrap with microcurrent was applied to the intervention group. Results: When comparing both groups after 5. weeks of protocol, there was a significant decrease in the subcutaneous fat around left anterior superior iliac spine in the intervention group (ρ= 0.026 for a confidence interval 95%). When comparing initial and final abdominal fat in the intervention group, measured by ultrasound (subcutaneous and visceral fat) and by skinfold (subcutaneous fat), we detected a significant abdominal fat reduction. Conclusion: This study demonstrated that the clay body wrap used with microcurrent and aerobic exercise can have a positive effect on central fat reduction. © 2013 Elsevier B.V.",Entailment
i_1092,Entailment,"Gender Differences: There are notable gender differences in the development of insulin resistance. Males tend to develop higher insulin resistance during adolescence despite a reduction in body fat, whereas females show a different pattern with increased body fat but relatively stable insulin resistance levels .","BACKGROUND - Developmental changes in insulin resistance and cardiovascular risk were studied in youths 11 to 19 years of age. METHODS AND RESULTS - A cohort was randomly selected after blood pressure screening of Minneapolis, Minn, school children. Studies were done 3 times on this cohort and once on their siblings (996 observations on 507 individuals from 363 families). Insulin sensitivity was determined by euglycemic clamp. Body mass index and waist circumference increased similarly in both sexes from ages 11 to 19 years. Body fat decreased in males and increased in females (P<0.001). Lean body mass increased at a steeper rate in males (P<0.0001). Insulin resistance was lower in males at 11 years but increased steadily to 19 years (P=0.003); in contrast, it did not increase in females. Thus, despite being less insulin resistant at 11 years and decreasing in fatness during puberty, males became more insulin resistant than females by 19 years of age. Triglycerides increased in males and high-density lipoprotein cholesterol decreased, whereas the opposite pattern was seen in females, which resulted in higher triglycerides and lower high-density lipoprotein cholesterol in males at 19 years. No gender difference in low-density lipoprotein or total cholesterol was seen. Systolic blood pressure increased in both sexes but at a greater rate in boys (P=0.03). CONCLUSIONS - During the transition from late childhood through adolescence, insulin resistance in males increased in association with increased triglycerides and decreased high-density lipoprotein cholesterol, despite a concurrent reduction in body fatness, whereas the opposite occurred in females. These gender-related developmental changes in insulin resistance, which were independent from changes in fatness, total cholesterol, and low-density lipoprotein cholesterol, are consistent with an early role for insulin resistance in the increased cardiovascular risk found in males. © 2008 American Heart Association, Inc.
[9]: Context: Obesity, insulin resistance (IR), and diabetes are increasing in youth, especially in girls. IR is associated with muscle mitochondrial dysfunction in youth and adults with diabetes. However, it is unknown whether this relationship is present in youth prior to development of diabetes. Objective: Assess IR and mitochondrial function, including sex differences, in nondiabetic youth. Design: Cross-sectional study of youth in the Exploring Perinatal Outcomes among Children, Resistance to InSulin in Type 1 And Type 2 diabetes, and Androgens and Insulin Resistance Study cohorts. Setting: Academic medical university. Participants: Two hundred seventy-five youth, 13 to 19 years old [43% males: 17.1 (16.52, 17.63) years, body mass index z-score (BMI-Z) 0.36, 64.7% Tanner 5; 57% females: 17.2 (16.43, 17.67) years, BMI-Z 0.72, 78.9% Tanner 5]. Interventions: Fasting laboratories, oral glucose tolerance test, and 31P magnetic resonance spectroscopy. Main Outcome Measures: IR [triglyceride:high-density lipoprotein (HDL) ratio, Matsuda index, and homeostasis model for insulin resistance (HOMA-IR)] and muscle mitochondrial function (adenosine 50-diphosphate time constant and oxidative phosphorylation rate). Results: Compared with males, females were more insulin resistant, with higher triglyceride:HDL ratio [1.95 (1.30, 2.79) vs 1.69 (1.21, 2.23), P = 0.042], HOMA-IR [3.18 (2.42, 4.39) vs 2.76 (2.02, 4.08), P = 0.035], and fasting free fatty acids (FFAs) and lower Matsuda score [3.98 (2.71, 5.96) vs 5.39 (3.43, 7.57), P < 0.001]. After adjustment for the higher BMI and Tanner stage and lower physical activity levels seen in females, there were no sex differences in mitochondrial function nor in any IR measure except FFAs. We did not find an association between measures of IR and mitochondrial function. Conclusions: The greater IR seen in adolescent girls vs boys is mostly explained by differences in BMI and physical activity. Mitochondrial function does not appear to be related to IR in a large cohort of nondiabetic youth.",Entailment
i_2089,Contradiction,Environmental and Economic Considerations: Sustainability: The use of Gracilaria and Ulva lactuca in abalone diets supports sustainable aquaculture practices by utilizing available nitrogen efficiently and potentially reducing the ecological impact of abalone farming .,"Seaweed production is a reality in Chile. More than ten species are commercially used to produce phycocolloids, fertilizers, plant growth control products, human food or animal fodder and feed additives. These multiple uses of algae offer a number of possibilities for coupling this activity to salmon, abalone and filter-feeder farming. In this context, different experiments carried out in Chile have demonstrated that Gracilaria chilensis and Macrocystis pyrifera have great potential in the development of an integrated aquaculture strategy. The present Integrated Multi-Trophic Aquaculture (IMTA) approach study showed that Gracilaria can be cultured best at 1 m depth whereas Macrocystis has an especially good growth response at 3 m depth. Both species use available nitrogen efficiently. On the other hand, high intensities of solar radiation (UV and PAR) can be critical at low depths of cultivation, and our results indicate that both species show photosynthetic susceptibility mainly at noon during the summer. The demand of Macrocystis for abalone feeding is increasing, thus improving the opportunity for developing an integrated nutrient waste recycling activity in Chile. Although Gracilaria shows a higher nitrogen uptake capacity than Macrocystis, its market value does not yet allow a massive commercial scaling. © 2007 Springer Science+Business Media B.V.",Entity error
i_1963,Contradiction,"Key Points: Human Activities: Major sources of greenhouse gas emissions include the burning of fossil fuels (coal, oil, and natural gas), deforestation, and industrial processes. These activities have significantly increased the concentration of greenhouse gases in the atmosphere .","[5] Introduction: Climate change is a change in the statistical distribution of weather patterns when it lasts for an extended period of time. Climate change may refer to a change in average weather conditions, or in the time variation of weather around long-term average conditions. Climate change is caused by factors such as biotic processes, variations in solar radiation received by Earth, plate tectonics, and volcanic eruptions. Certain human activities have also been identified as significant causes of recent climate change, often referred to as global warming. Shifting temperatures are climbing and sea levels are rising. And meanwhile, our planet must still supply us and all living things with air, water, food and safe places to live. If we don't act now, climate change will rapidly alter the lands and waters we all depend upon for survival, leaving our children and grandchildren with a very different world. The most important task of all countries in the face of climate change is to make efforts to reduce climate change and spend more time to anticipate and prevent its risks. The efforts and actions can be done in the current situation are including natural resource conservation, development of green spaces, reduction of power consumption of fossil fuels, saving in consumption, recycling and reduction of waste, sewage treatment, use of renewable energy sources and implementation of appropriate educational programs. The remarkable thing is that these actions by the government alone cannot be done and, thus, all persons in any country should play their role. This requires environmental education in the field of climate change for people to deal with these issues correctly. Thus, in last decade in various countries, study has been done in the field of education to climate change. But reviews of these studies, particularly in Iran, shows that adequate studies have not yet been done to educate climate change in the educational system. Therefore, the purpose of this study is development of the climate change education plan in the formal education system. Materials and methods: Iran formal education system: educational system of Iran is comprised of three sections. These three sections include formal, informal and implicit. In this study, the third grade of the first period of high school is considered as a case study to develop a climate change education plan. Education in the educational process management in the ISO 10015 standard is in four steps; needs assessment, educational designing and planning, implementation, and evaluation. In the Figure (1), the educational process management is represented according to ISO 10015 standard. (Figure Presented) Results and discussion: As mentioned above in this study, climate change education plan for third grade of the first period of high school is developed based on educational process management in the ISO 10015 standard. Education in this system in four steps includes; needs assessment, educational designing and planning, implementation, and evaluation of results. Needs assessment The results show that, the most important educational needs, which are obtained with Fish Bowl technique, as follows are; introduction of basic concepts, current state of climate, climate change causes, effects and impacts, solutions and strategies for prevention, and mitigation and adaptation to climate change (Table 1). (Table Presented) Educational designing and planning Educational designing and planning was done in the five steps, which the goals are: Development thinking about the climate change, increase in student knowledge in this field, training of appropriate personnel to manage climate change. (Table Presented) In the implementation of education, teacher is operator training and the Ministry of Education is in the form of Education Office and schools can support teachers in monitoring the implementation. In the evaluation step, the teacher in addition to the evaluation of classroom sessions should do a final evaluation. Thus, the evaluation should be a combination of formative and final assessment, which recommended the use of goal oriented Tyler pattern. Conclusion: Accurate knowledge about the effects of climate change is essential as a key factor for conscious action and the formation of a person's determination to deal with the effects of climate change. Studies from around the world have observed an unfortunate chain of students not being given an adequate and accurate education on climate change, of teachers not knowing how or what to teach, and of the public that is misinformed about these issues. The structure proposed in this study to climate change education determined the contents that require students to do need assessments. This is based on educational designing and planning. Therefore, the teachers with use of educational designing and planning and on the job training increase their knowledge in this field and it will teach the students. [10] Human-induced climate change is the largest threat to our continued existence on beautiful planet Earth. It is currently framed as ""global warming,"" ""climate disruption,"" ""climate chaos,"" and ""the climate emergency"" in attempts to draw attention to our dire situation and the need for immediate and dramatic action. As ever more frightening scientific evidence of the likely extent and speed of climate change's impacts becomes readily accessible, it seems that the extent of our collective denial increases. It is as if we are ""caught in the headlights"" of an oncoming vehicle, unable to act towards personal and planetary survival. This paper draws upon Gaian science, deep ecology, the ""work that reconnects,"" and the power of story to explore how we might reframe climate change so we can engage with, and respond to, it productively. It asks ""What if ⋯ instead of being a 'Threat' to us and our world, we consider climate change as an 'Ally' of 'The Great Turning' of humankind towards a more sustainable way of living and being?"" In doing so, we might feel more at ease amidst forthcoming catastrophic weather events and other dramatic changes; feel supported in our efforts to transform our own lives and communities from ""Business as Usual""; become more motivated to act for wider systemic change; and even discover new meaning, purpose, and joy at being alive at this moment in time. Key Words: Climate change - Deep ecology - Gaia - Narrative psychology - Denial. [14] Global warming is currently a key topic in international politics; therefore, the impact of measures taken to counteract it is enormous. However, it should be noted that considerable controversy surrounds the scientific truth on global warming. Therefore, clarifying the scientific truth is both urgent and crucial. To this end, the author, as vice chairman of the editorial committee of the Japan Society of Energy and Resources, coordinated an e-mail discussion among five prominent Japanese scientists. The full text in Japanese, including data forming the basis of the discussion, is available for download from the homepage of the Japan Society of Energy and Resources (http://www.jser.gr.jp/). To the author's knowledge, the discussion, supporting papers, and associated data represent the first trial of its kind. On the occasion of ICOPE-09, the coordinator summarizes the outline of the e-mail discussion and illustrates state-of-the-art research on global warming.",Missing information
i_2027,Contradiction,"However, the use of chelating agents to enhance this process has proven ineffective and potentially harmful .","Phytoextraction, the use of plants to extract contaminants from soils and groundwater, is a promising approach for cleaning up soils contaminated with heavy metals. In order to enhance phytoextraction the use of chelating agents has been proposed. This study aims to assess whether ethylene diamine disuccinate (EDDS), a biodegradable chelator, can be used for enhanced phytoextraction purposed, as an alternative to ethylene diamine tetraacetate (EDTA). EDDS revealed a higher toxicity to tobacco (Nicotiana tabacum) in comparison to EDTA, but no toxicity to microorganisms. The uptake of Cu was increased by the addition of EDTA and EDDS, while no increase was observed in the uptake of Cd. Both chelating agents showed a very low root to shoot translocation capability and the translocation factor was lower than the one of the control. Heavy metals where significantly more phytoavailable than in the control, even after harvesting, resulting in a high heavy metal leaching possibility, probably owing to a low biodegradation rate of EDDS. New seedlings which were transplanted into the EDDS treated pots 7 d after the phytoextraction experiment, showed signs of necrosis and chlorosis, which resulted in a significantly lower biomass in comparison to the control. The seedlings on the EDTA treated pots showed no toxicity signs. Contrary to previous opinions the results of this study revealed the chelating agents EDTA and EDDS as unsuitable for enhanced phytoextraction using tobacco. © 2006 Elsevier Ltd. All rights reserved.",Missing information
s_1670,Entailment,"Immunostimulants for Fish: Probiotics (Cyprinus carpio): Strains: Lactobacillus acidophilus and Bacillus subtilis. Effects: Reduced mortality, increased phagocytic activity, and growth rate . Concentration: Effective at 10^5 CFU/mL.","Fish culture is increasing to compensate the shortage of animal protein all over the world. Fish under intensive culture conditions will be badly affected and often fall prey to different microbial pathogens that have been treated with ehe mo therapeutic substances of which antibiotics were intensively used. The use of natural immunostimulants in fish culture for the prevention of diseases is a promising new development and could solve the problems of massive antibiotic use. Evaluation of immunomodulatory effect of the dietary probiotics on the common carp, Cyprinus carpio L. has been studied for the period of one month and the experiments such as, mortality, phagocytic activity and growth rate are conducted through this present study. To prepare the probiotic enriched diet, the colony forming units were found. For Lactobacillus acidophilus, the colony forming units were found to be 4.6×l0<sup>7</sup> CFU mL<sup>1</sup> for 10<sup>5</sup> and 2.1×l0<sup>9</sup> CFU mL<sup>-1</sup> for 10<sup>7</sup> concentrations. The Bacillus subtilis were found to be 3.47×l0<sup>7</sup> CFU mL<sup>-1</sup> for 10<sup>5</sup> concentrations and 1.64×l0<sup>9</sup> CFU mL<sup>-1</sup> for 10<sup>7</sup> concentrations. Then these bacterial suspensions of 5 mL were sprayed into the 50 g of feed (100 mL kg<sup>-1</sup> diet) with constant mixing. The experimental group III fed with 10<sup>5</sup> cells of Bacillus subtilis showed minimum mortality rate and maximum mean leucocyte count and growth rate on all days when compared to other experimental groups. © 2013 Asian Network for Scientific Information.",Entailment
s_2088,Entailment,"Microbial Community Dynamics and Process Stability: Ammonia Inhibition: High levels of ammonia can significantly disrupt the microbial community, which inevitably leads to the accumulation of volatile fatty acids (VFAs) and process instability. This occurs primarily because ammonia inhibits acetate metabolism, which directly causes feedback inhibition at the acetogenesis stage, allowing hydrolytic fermentative bacteria to completely dominate the process .","A long-term high solids anaerobic digestion of food waste was conducted to identify microbial mechanisms of ammonia inhibition during digestion and to clarify correlations between ammonia accumulation, microbial community dynamics (diversity, composition, and interactions), and process stability. Results show that the effects of ammonia on process performance and microbial community were indirectly caused by volatile fatty acid accumulation. Excess free ammonia blocked acetate metabolism, leading to process instability. Accumulated acetate caused feedback inhibition at the acetogenesis stage, which resulted in considerable accumulation of propionate, valerate, and other long-chain fatty acids. This high concentration of volatile fatty acids reduced the abundance of syntrophic acetogenic bacteria and allowed hydrolytic fermentative bacteria to dominate. The normally interactive and orderly metabolic network was broken, which further exacerbated the process instability. These results improve the understanding of microbial mechanisms which contribute to process instability and provide guidance for the microbial management of anaerobic digesters.",Entailment
s_453,Contradiction,"Challenges and Evolving Threats: - Multidisciplinary Nature: Cybersecurity is not just a technical field; it involves legal, political, social, and economic dimensions. This multidisciplinary nature can often lead to confusion and misinterpretation, making it nearly impossible to conduct effective research and implementation .","The International Institute for Strategic Studies (2018: 6) states that ""cyber capability should now be seen as a key aspect of some states' coercive power … This has driven some European states to re-examine their industrial, political, social and economic vulnerabilities, influence operations and information warfare, as well as more traditional areas of military power."" Cybersecurity is often incorrectly assumed to be a purely technical field, however there are numerous multidisciplinary aspects. The very nature of cybersecurity and operations in cyberspace is disruptive, and this is true for many disciplines attempting to introduce cybersecurity research into their offerings. This can provide challenges to researchers and students where methodologies that do not necessarily follow disciplinary norms are prejudiced against by old-school thought. Foundational understanding of concepts may also hinder multi-disciplinary research, as specific terminology that is used in cybersecurity may be considered colloquial or have different meanings in other disciplinary settings. The experimental, observational and mathematical research methodologies often employed by computer scientists do not address the political or legal aspects of cybersecurity research. Research methods for cybersecurity generally apply and teach the limited scientific methods for creating new knowledge, validating theories, and providing some critical insights into to the cybersecurity arena. This paper aims to investigate the South African national and institutional perspectives for higher education and research, identify challenges, and propose interventions to facilitate multidisciplinary research into cybersecurity and cyberwarfare in South Africa. Legislature and policies, organisational structures, processes, resources, and historical and socio-economic factors will be discussed as to the influence on cybersecurity research. A review and analysis of international efforts for multidisciplinary research in higher education institutions will provide for a basis to propose a framework for South African higher education institutions to effectively implement cybersecurity research.",Misrepresentation
s_417,Contradiction,"Text Mining: Definition: Text mining, also known as text data mining, is primarily about extracting trivial patterns or knowledge from text documents, which is often overlooked in its applications .","Text mining, also referred to as text data mining, is the process of extracting interesting and non-Trivial patterns or knowledge from text documents. It uses algorithms to transform free flow text (unstructured) into data that can be analyzed (structured) by applying Statistical, Machine Learning and Natural Language Processing (NLP) techniques. Text mining is an evolving technology that allows enterprises to understand their customers well, and help them in redefining customer needs. As e-commerce is becoming more and more established, the number of customer reviews and feedback that a product receives has grown rapidly over a period of time. For a popular asset, the number of review comments can be in thousands or even more. This makes it difficult for the manufacturer to read all of them to make an informed decision in improving product quality and support. Again it is difficult for the manufacturer to keep track and to manage all customer opinions. This article attempts to derive some meaningful information from asset reviews which will be used in enhancing asset features from engineering point of view and helps in improving the support quality and customer experience.",Opposite meaning
i_312,Contradiction,"Primary Techniques: Geometric Manipulation: Resampling and Transformation: Distorting the geometric properties of images, such as scaling, rotating, and translating, to create further misalignments or enhance distortions .","In applications that deal with digitally represented visual images, various forms of processing are generally required before the results are ready to be displayed. Although many of the methods used are complex, all have their roots in a small number of core concepts and techniques. This chapter looks at these common core spatial domain operations, firstly reviewing those that rely on applying transformations of brightness and color in place within digital images. It then moves on to consider geometric manipulation of image data and resampling issues.",Missing information
s_1553,Entailment,"Breeding and Selection: Breeding efforts have focused on selecting genotypes with desirable bolting characteristics. For instance, the selection of genotypes like UFU 66#8 and UFU 215#13 has been based on their balanced genetic gains and bolting resistance . This highlights the importance of breeding programs in developing varieties with optimal bolting times.","The development of mini lettuce genotypes with good agronomic characteristics are fundamental to launch new cultivars. Thus, the objective was to compare the variability of biofortified mini lettuce genotypes by analyzing their principal components and hierarchical clusters, and evaluating different selection indices to estimate selection gain. The experiment was carried out at the Federal University of Uberlândia in a randomized block design implemented with 11 treatments (10 genotypes of mini lettuce generation F5:6 and one mini lettuce commercial cultivar) and four repetitions. The following variables were evaluated: chlorophyll content (SPAD índex), stem diameter and length, plant diameter and height, number of leaves per plant, fresh mass of the aerial part, and bolting tolerance. The data were submitted to analysis of variance and genotypes were compared using the Scott-Knott test (P≤0.05). Additionally, principal components, hierarchical clusters, and their correlations were evaluated (P≤0.05). The best genotypes were chosen by appropriate direct and indirect selection and the main indices: William's index, selection index from Smith and Hazel, and Mulamba y Mock index. There were five groups and significant negative correlations of all agronomic characteristics evaluated with resistance to bolting, except stem length. William's index provided a balanced distribution of genetic gains by selecting the genotypes UFU 66#8, UFU 215#2, UFU 215#7 and UFU 215#13.",Entailment
i_1498,Contradiction,"Colorectal Cancer: Fear of Cancer Recurrence (FCR): Long-term colorectal cancer survivors experience high levels of FCR, which is significantly associated with increased risk of depression and negatively impacts emotional functioning and overall health-related quality of life (HRQoL) .","Purpose Fear of cancer recurrence (FCR) is a common psychological issue in breast cancer (BC) survivors during early survivorship but whether the same is true among long-term survivors has yet to be empirically evaluated. This study investigated FCR level, its associated factors, and impact on quality of life (QoL) in long-term BC survivors. Materials and Methods Participants included women diagnosed with BC between 2004 and 2010 at two tertiary hospitals. Survey was conducted in 2020. The study measured FCR with the Fear of Cancer Recurrence Inventory and other patient-reported outcomes, including depression and cancer-related QoL. Logistic regression was used to identify factors associated with FCR, and structural equation modeling was conducted to explore the impact of FCR on other outcomes. Results Of 333 participants, the mean age at diagnosis was 45.5, and 46% experienced FCR. Age at diagnosis ≤ 45 (adjusted odds ratio [aOR], 2.64; 95% confidence interval [CI], 1.51 to 4.60), shorter time since diagnosis (aOR, 1.75, 95% CI, 1.08 to 2.89), and having a history of recurrence (aOR, 2.56; 95% CI, 1.16 to 5.65) was associated with more FCR. FCR was significantly associated with an increased risk of depression (β=0.471, p < 0.001) and negatively impacted emotional functioning (β=-0.531, p < 0.001). In addition, a higher FCR level may impair overall health-related QoL in long-term BC survivors (β=-0.108, p=0.021). Conclusion Ten years after diagnosis, long-term BC survivors still experienced a high level of FCR. Further, the negative impact of FCR on QoL and increased depression risk require an FCR screening and appropriate interventions to enhance long-term BC survivors' QoL.",Entity error
i_2164,Entailment,"These compounds are likely to exhibit a wide range of therapeutic properties, including anti-inflammatory, antioxidant, and anti-diabetic activities, although their effectiveness in treating chronic diseases remains largely unproven .","Seaweeds are a large and diverse group of marine organisms that are commonly found in the maritime regions of the world. They are an excellent source of biologically active secondary metabolites and have been shown to exhibit a wide range of therapeutic properties, including anti-cancer, anti-oxidant, anti-inflammatory and anti-diabetic activities. Several Asian cultures have a strong tradition of using different varieties of seaweed extensively in cooking as well as in herbal medicines preparations. As such, seaweeds have been used to treat a wide variety of health conditions such as cancer, digestive problems, and renal disorders. Today, increasing numbers of people are adopting a ""westernised lifestyle"" characterised by low levels of physical exercise and excessive calorific and saturated fat intake. This has led to an increase in numbers of chronic Non-communicable diseases (NCDs) such as cancer, cardiovascular disease, and diabetes mellitus, being reported. Recently, NCDs have replaced communicable infectious diseases as the number one cause of human mortality. Current medical treatments for NCDs rely mainly on drugs that have been obtained from the terrestrial regions of the world, with the oceans and seas remaining largely an untapped reservoir for exploration. This review focuses on the potential of using seaweed derived bioactives including polysaccharides, antioxidants and fatty acids, amongst others, to treat chronic NCDs such as cancer, cardiovascular disease and diabetes mellitus.",Entailment
i_2327,Entailment,"Enhanced Nutrient Absorption and Digestibility: The inclusion of Lactobacillus acidophilus in broiler diets has been associated with improved nutrient absorption and digestibility. This leads to better growth performance and feed efficiency, as seen in studies where broilers exhibited increased body weight gain and decreased FCR .","This study was conducted to evaluate the effects of Bacillus subtilis, Clostridium butyricum and Lactobacillus acidophilus (tri-strain probiotics, TSP) endospores in broilers. TSP can benefit the host animal by increasing nutrient absorption from the gastrointestinal tract and altering the intestinal ecosystem in poultry. A total of 500 day-old ROSS 308 mixed sex broiler chickens with an average initial body weight (IBW) of 45 g ± 0.6 g were used in this 35-day feeding study. Broiler chickens were randomly allotted to one of five dietary treatments: (1) CON (antibiotic free diet), (2) ANT1 (CON + enramycin 5 ppm), (3) ANT2 (CON + avilamycin 5 ppm), (4) TSP1 (CON + 0.1% TSP), and (5) TSP2 (CON + 0.2% TSP) with five replicates per treatment and20 chicks per pen. Broiler chickens fed on TSP diets exhibited linearly increasing body weight gain (BWG) and decreased feed conversion ratio (FCR) compared to those on the CON diet (P < 0.05; Day 21 to Day 35 and Day 1to Day 35, respectively). Further, dry matter (DM) and nitrogen (N) digestibility were improved (P < 0.05) in theTSP treatment at the end of study. The inclusion of TSP reduced (linear, P = 0.02) meat lightness (L*) compared with CON and ANT treatments. Broiler chickens fed with TSP diets had relatively higher (linear, P < 0.05) bursa weight than those fed with ANT and CON diets. The supplementation of TSP increased (P < 0.05) the ileal and caecal Lactobacillus count compared with CON and ANT diets. The ileal and caecal Escherichia coli and caecal Clostridium perfringens counts were reduced (P < 0.05) in the TSP2 group compared with the CON group. Broiler chickens fed with TSP diets exhibited increased (P < 0.05) caecal Bifidobacteria counts compared with CON and ANT diets. Excreta ammonia (NH<inf>3</inf>) gas emission was lower (P < 0.05) with the TSP treatment compared with the CON treatment. In conclusion, the supplementation of TSP improved growth performance, nutrient digestibility, meat quality, gut health and reduced noxious gas emission in broilers.
[4]: The present study investigated the effects of Lactobacillus acidophilus (LBA) and mannan-oligosaccharides (MOS) supplementation on the production performance, serum biochemistry, antioxidant profile, health indices, meat quality, and lipid oxidative stability of broiler chicken. A total of 252 commercial broiler chickens at 1 d old of uniform body weight were randomly allocated to 6 maize-soybean-based dietary treatments: T<inf>1</inf> (control diet), T<inf>2</inf> ( antibiotic bacitracin methylene di-salicylate [BMD] at 20 mg/kg diet), T<inf>3</inf> (MOS at 0.1% + LBA at 10<sup>6</sup> CFU/g feed), T<inf>4</inf> (MOS at 0.1% + LBA at 10<sup>7</sup> CFU/g feed), T<inf>5</inf> (MOS at 0.2% + LBA at 10<sup>6</sup> CFU/g feed), and T<inf>6</inf> (MOS at 0.2% + LBA at 10<sup>7</sup> CFU/g feed). Each treatment was assigned to 6 replicates of 7 birds. The samples for meat quality and serum biochemistry analysis were taken from 12 birds per treatment (2 birds/replicate). The results revealed better (P < 0.01) growth performance and production efficiency of birds fed either T<inf>5</inf> or T<inf>6</inf> diet compared to control or BMD supplemented diet and BMD-supplemented birds superseded the control birds. Higher (P < 0.01) serum and liver antioxidant enzyme activities, meat antioxidant capacity (2, 2-azinobis-3-ethylbenzothiazoline-6-sulfonic acid [ABTS] and 1, 1-diphenyl-2-picrylhydrazyl [DPPH] assays], serum total protein, high-density lipoproteins (HDL) cholesterol (P < 0.05), and globulin levels (P < 0.01) were observed in birds fed either T<inf>5</inf> or T<inf>6</inf> diet compared to control or BMD supplemented birds, whereas, lower lipid oxidation (P < 0.01), cardiac risk ratio, atherogenic coefficient, atherogenic index of plasma, serum glucose, triglyceride, total cholesterol levels (P < 0.01), and serum albumin-to-globulin ratio (P < 0.05) were observed in the chickens. The pH of meat from birds fed T<inf>4</inf>, T<inf>5</inf> or T<inf>6</inf> diet was lower (P < 0.01) compared to control and other treatments. The extract release volume (ERV), water holding capacity (WHC), and protein content of meat were higher (P < 0.05) in birds fed either T<inf>5</inf> or T<inf>6</inf> diet compared to control or BMD supplemented birds. Thus, it was concluded that the supplementation of 0.2% MOS along with LBA at 10<sup>6</sup> CFU/g is optimum for better growth performance, serum biochemistry, antioxidant profile, health indices, meat quality, and lipid oxidative stability of broiler chickens.",Entailment
s_334,Unverifiable,5. Knowledge Graph Completion: Embedding Techniques: Apply knowledge graph embeddings and other techniques to predict and add missing relationships .,"[8] Knowledge graphs (KG) model relationships between entities as labeled edges (or facts). They are mostly constructed using a suite of automated extractors, thereby inherently leading to uncertainty in the extracted facts. Modeling the uncertainty as probabilistic confidence scores results in a probabilistic knowledge graph. Graph queries over such probabilistic KGs require answer computation along with the computation of result probabilities, i.e., probabilistic inference. We propose a system, HAPPI (How Provenance of Probabilistic Inference), to handle such query processing and inference. Complying with the standard provenance semiring model, we propose a novel commutative semiring to symbolically compute the probability of the result of a query. These provenance-polynomial-like symbolic expressions encode fine-grained information about the probability computation process. We leverage this encoding to efficiently compute as well as maintain probabilities of results even as the underlying KG changes. Focusing on conjunctive basic graph pattern queries, we observe that HAPPI is more efficient than knowledge compilation for answering commonly occurring queries with lower range of probability derivation complexity. We propose an adaptive system that leverages the strengths of both HAPPI and compilation based techniques, for not only to perform efficient probabilistic inference and compute their provenance, but also to incrementally maintain them. [14] Drawing upon research and current development work at Europeana, this paper discusses search functionality in the Cultural Heritage sector, focusing in particular on the question of 'inspiration-oriented' search, in which users seek out previously-unknown items to serve as creative stimulus. Inspiration-oriented search is identified as a variant of the more widely-studied problem of serendipitous retrieval, and defined as an information-seeking behavior in which users consciously search for items that are related to known items in ways that are recognizable once seen, but that are nevertheless unpredictable at search-time. Various strategies for the maximization of both the recognisability and unpredictability of related items are then described, including user-interface and user-experience changes and the reconceptualization of datastores as knowledge graphs. Directions for further research are then outlined – including, most importantly, possible metrics for inspiration-oriented search and their potential for use in machine-learning ranking frameworks. [15] Purpose: Neuroscience data are spread across a variety of sources, typically provisioned through ad-hoc and non-standard approaches and formats and often have no connection to the related data sources. These make it difficult for researchers to understand, integrate and reuse brain-related data. The aim of this study is to show that a graph-based approach offers an effective mean for representing, analysing and accessing brain-related data, which is highly interconnected, evolving over time and often needed in combination. Design/methodology/approach: The authors present an approach for organising brain-related data in a graph model. The approach is exemplified in the case of a unique data set of quantitative neuroanatomical data about the murine basal ganglia––a group of nuclei in the brain essential for processing information related to movement. Specifically, the murine basal ganglia data set is modelled as a graph, integrated with relevant data from third-party repositories, published through a Web-based user interface and API, analysed from exploratory and confirmatory perspectives using popular graph algorithms to extract new insights. Findings: The evaluation of the graph model and the results of the graph data analysis and usability study of the user interface suggest that graph-based data management in the neuroscience domain is a promising approach, since it enables integration of various disparate data sources and improves understanding and usability of data. Originality/value: The study provides a practical and generic approach for representing, integrating, analysing and provisioning brain-related data and a set of software tools to support the proposed approach.",Related but unverifiable
s_763,Contradiction,"3. Interfacial Solar Vapor Generation: A novel eco-friendly technology for desalination and water purification involves using copper oxide nanonets and microporous poly(vinylidene fluoride) membranes. This system efficiently converts solar energy to thermal energy, producing water vapor with high efficiency. It is reusable, flexible, and easy to scale up, making it a promising solution for areas with freshwater shortages .","The increasing energy and environmental concerns have spurred enormous research interest towards developing various renewable energy and sustainable environmental solutions. Photothermal conversion for interfacial solar vapor generation is a promising, green energy technology and efficient route for desalination and purification of seawater, i.e. for those parts where freshwater shortage is a severe concern and clean energy is not available. Eco-friendly, highly efficient and low-cost interfacial evaporators are highly desirable for the practical and widespread application of this technology. In this work, we have demonstrated a novel interfacial evaporator employing Cu<inf>9</inf>S<inf>5</inf> nanonets with heterogeneous hexagonal holes as the photothermal conversion material and a microporous poly(vinylidene fluoride) membrane (PVDFM) as the supporting material. The Cu<inf>9</inf>S<inf>5</inf>/PVDFM evaporator displays a broadband (from 250 to 2000 nm) and large (∼91.7%) solar absorptance. The porous structures of Cu<inf>9</inf>S<inf>5</inf> nanonets and PVDFM facilitate the water transportation, and the large optical absorption of Cu<inf>9</inf>S<inf>5</inf>/PVDFM converts most of the solar energy to thermal energy, producing water vapor with high efficiency. The Cu<inf>9</inf>S<inf>5</inf>/PVDFM evaporator exhibits solar vapor generation efficiencies of 80.2 ± 0.6% and 91.5 ± 1.1% under one-sun and four-sun irradiation, respectively, making it among the best copper sulphide-based solar evaporators reported so far. This Cu<inf>9</inf>S<inf>5</inf>/PVDFM evaporator is reusable, flexible, highly efficient, easy to prepare, easy to scale up, and controllable for tailoring, showing a promising future for interfacial solar vapor generation.",Entity error
i_910,Unverifiable,Strategic Planning: Collaboration and Coordination: Effective collaboration with project managers and technical representatives is essential. Purchasers must coordinate with various stakeholders to ensure that procurement activities support the overall project goals .,"Just as procurement staff rely on the project staff's expertise in rocket science, so too can the project management rely on procurement representatives to handle the details of procurement management. However, a basic understanding of procurement principles goes a long way in helping obtain required purchased supplies and services on time, within budget, and consistent with requirements. This chapter will provide a Project Manager (PjM) with a basic understanding of their role in the acquisition process by detailing the stages of procurement. While the term Project Manager is used throughout this chapter, many of their responsibilities may be delegated to a Technical Representative whom he/she has delegated authority for the technical oversight and direction of a procurement. This could be a PjM or other individual with adequate technical knowledge to provide appropriate technical oversight and provide technical direction to the contractor. The procurement life cycle consists of four primary phases, Pre-Award, Award, Post- Award, and Closeout (Figure 5.1).",Related but unverifiable
i_438,Entailment,"Traditional Rule-Based Methods: Heuristic Rules: Early AQG systems relied heavily on heuristic rules to transform sentences into questions. These methods use predefined templates and linguistic rules to generate questions from text passages . For example, a sentence might be rephrased into a question by identifying key components such as the subject, verb, and object, and then rearranging them according to specific rules.","Automatic question generation aims to generate questions from a text passage where the generated questions can be answered by certain sub-spans of the given passage. Traditional methods mainly use rigid heuristic rules to transform a sentence into related questions. In this work, we propose to apply the neural encoder-decoder model to generate meaningful and diverse questions from natural language sentences. The encoder reads the input text and the answer position, to produce an answer-aware input representation, which is fed to the decoder to generate an answer focused question. We conduct a preliminary study on neural question generation from text with the SQuAD dataset, and the experiment results show that our method can produce fluent and diverse questions.
[2]: This paper describes our research and development work on a computational method that takes a piece of Chinese unstructured text and generates a set of questions and answers as the output. Our method is largely based on Heilman & Smith's over-generation approach [1] and is included with techniques specific for handling Chinese text. Using the syntactic and semantic features identified in a sentence, various question types can be generated with answers also available. Automatic question generation is potentially a key component in future intelligent e-learning systems, but it is also a very challenging problem. A major objective of this work is to investigate technical issues and limitations that would provide direction of future research.",Entailment
s_1915,Entailment,"Disturbance Patterns in Temperate Forests: Types of Disturbances: Temperate forests experience a variety of disturbances, including windstorms, ice storms, and insect outbreaks. These disturbances can significantly alter forest structure and composition .","Exogenous disturbances are critical agents of change in temperate forests capable of damaging trees and influencing forest structure, composition, demography, and ecosystem processes. Forest disturbances of intermediate magnitude and intensity receive relatively sparse attention, particularly at landscape scales, despite influencing most forests at least once per generation. Contextualizing the spatial extent and heterogeneity of such damage is of paramount importance to increasing our understanding of forested ecosystems. We investigated patterns of intermediate wind disturbance across a forested landscape in the northern Great Lakes, USA. A vegetation change tracker (VCT) algorithm was utilized for processing near-biennial Landsat data stacks (1984-2009) spanning forests sustaining damage from four recent windstorms. VCT predominantly maps stand-clearing disturbance and regrowth patterns, which were used to identify forest boundaries, young stands, and disturbance patterns across space and time. To map wind damage severity, we compared satellite-derived normalized difference vegetation index (NDVI) values calculated from pre- and post-storm Landsat imagery. A geographic information system (GIS) was used to derive wind damage predictor variables from VCT, digital terrain, soils/landform, land cover, and storm tracking data. Hierarchical and random forests regressions were applied to rank the relative importance of predictor variables in influencing wind damage. A conservative estimate of aggregate damage from the intermediate windstorms (extrapolated to ;150,000 ha, ;25,500 severe) rivaled individual large, infrequent disturbances in the region. Damage patterns were relatively congruent among storms and became more spatially heterogeneous with increasing disturbance intensity. Proximity to forest-nonforest edge, stand age, and soils/landform were consistently important damage predictors. The spatial extent and distribution of the first two damage predictors are extremely sensitive to anthropogenic modifications of forested landscapes, the most important disturbance agent in the northern Great Lakes. This provides circumstantial evidence suggesting anthropogenic activities are augmenting and/or diminishing the ecological effects of the natural wind disturbance regime. Natural disturbances of intermediate size and intensity are significant agents of change in this region, and likely in other regions, deserving more attention from ecologists and biogeographers. © 2011 Stueve et al.
[2]: Large-scale disturbances such as ice storms may increase in frequency and intensity as climate changes. While disturbances are a natural component of forest ecosystems, climatically driven alteration to historical patterns may impart fundamental change to ecosystem function. At Hubbard Brook Experimental Forest, NH, experimental ice storms of varying severity were applied to replicate plots of mature northern hardwoods to quantify their effects on forested ecosystems. We assessed ice storm treatment effects on insectivorous foliage-gleaning birds and evaluated insectivore predation on model caterpillars in the understory vegetation. These birds are charismatic, of conservation concern, and are major predators of caterpillars. In turn, lepidopterans are the dominant herbivores in temperate forests and are integral to ecosystem function. We predicted that avian abundance would increase due to additional structural heterogeneity caused by ice treatments, with a concomitant increase in caterpillar predation. Point counts were used to measure insectivorous bird activity in the ice storm experiment plots and additional control plots before and after treatments. We deployed and retrieved plasticine model caterpillars and estimated predation from characteristic marks to these surrogates. Abundance of foliage-gleaning birds was higher in the ice storm plots and birds responded to treatments as a single diffuse disturbance rather than on an individual plot level. All species except one were observed both before and after the ice treatments. Surprisingly, predation on caterpillar models was unaffected by ice storm treatments but rather was a function of caterpillar density. The increase in avian abundance in the ice storm treatment plots corroborates other studies of bird responses to relatively small-scale disturbances in forests and the limited change in species composition was expected given the plot size. We conclude that ice storms may provide beneficial changes for foliage-gleaning birds in the growing season following the disturbance.",Entailment
s_693,Unverifiable,Graphene: This conductive material can be screen-printed onto textile garments to create robust and cost-effective electrodes for surface EMG applications .,"Objective. Wearable devices have created new opportunities in healthcare and sport sciences by unobtrusively monitoring physiological signals. Textile polymer-based electrodes proved to be effective in detecting electrophysiological potentials but suffer mechanical fragility and low stretch resistance. The goal of this research is to develop and validate in dynamic conditions cost-effective and easily manufacturable electrodes characterized by adequate robustness and signal quality. Methods. We here propose an optimized screen printing technique for the fabrication of PEDOT:PSS-based textile electrodes directly into finished stretchable garments for surface electromyography (sEMG) applications. A sensorised stretchable leg sleeve was developed, targeting five muscles of interest in rehabilitation and sport science. An experimental validation was performed to assess the accuracy of signal detection during dynamic exercises, including sit-to-stand, leg extension, calf raise, walking, and cycling. Results. The electrodes can resist up to 500 stretch cycles. Tests on five subjects revealed excellent contact impedance, and cross-correlation between sEMG envelopes simultaneously detected from the leg muscles by the textile and Ag/AgCl electrodes was generally greater than 0.9, which proves that it is possible to obtain good quality signals with performance comparable with disposable electrodes. Conclusions. An effective technique to embed polymer-based electrodes in stretchable smart garments was presented, revealing good performance for dynamic sEMG detections. Significance. The achieved results pave the way to the integration of unobtrusive electrodes, obtained by screen printing of conductive polymers, into technical fabrics for rehabilitation and sport monitoring, and in general where the detection of sEMG in dynamic conditions is necessary.",Related but unverifiable
s_858,Entailment,Buttress Dams: These have a sloping deck supported by buttresses. The Daniel-Johnson dam also features buttresses .,"The Daniel-Johnson dam is a 1314-m long multiple-arch-buttress dam composed of 14 buttresses and 13 arches with a central arch of 214 m high. The upper part of the dam is composed of gravity dam supported by the arches. Its height, length and the 2 million cubic meters concrete used for its construction make it the largest dam of its type in the world. Hydro-Québec and the University of Sherbrooke carried out forced-vibration tests on the Daniel-Johnson dam that are presented in this paper. The tests aimed to determine the dynamic properties of the dam-reservoir-foundation (DRF) system to be used as a basis for the update of a 3D finite element model of the system. The outstanding size and the complex geometry of the dam are of great interest in this study, because they involved challenges in the experimental work not usually found for smaller dam of simpler geometry. The forced-vibration tests involved the use of an eccentric mass shaker generating forces up to 89 kN. The accurate modal identification of the dam required four different locations of the shaker, 52 measurement stations distributed along the crest of the dam and in the inspection galleries, and overall 13 tests configurations. These tests showed that it is possible to measure useful signals along the whole crest of a very large and massive concrete dam and as far as in the very lower inspection galleries, even with a relatively small excitation force. The analysis procedure of the experimental data were however quite complicated due to the numerous close local and global modes of the multiple-arch dam and their coupling. Twenty-two vibration modes were clearly identified. A 3D finite element model of the DRF system is briefly presented, and was correlated with the measured vibration modes.",Entailment
i_794,Contradiction,"Key Factors Impacting Digital Transformation: Digital Twin Adoption: The maturity level of digital twin adoption varies across different segments of the construction industry. For instance, precast concrete companies are slower in adopting digital twin technologies compared to design companies. Critical success factors for digital twin adoption include government support, ecosystem readiness, company culture, team dynamics, process integration, and the availability of suitable digital twin software tools .","The construction industry is embracing the digital transformation to streamline the process from design to build. However, compared with design companies, precast concrete (PC) companies seem to be slow in the adoption of building information modeling (BIM). The paper thus intends to (1) understand the current BIM maturity levels in these companies via a survey among the PC companies; (2) develop a model for identifying critical success factors (CSFs) influencing BIM adoption from PC companies' view; and (3) give recommendations to the PC companies as well as policymakers. From the survey responses of 53 respondents from the PC industry in various countries including Association of Southeast Asian Nations (ASEAN) countries, China, Korea, Taiwan, the Middle East, and Finland, the study successfully identified a total of eight CSFs, which are regarded as the main contributions this research makes to the body of knowledge. Based on these CSFs, recommendations are provided to assist PC companies to become industry innovators. Some additional contributions are (1) a new BIM adoption model, which is a mix of a BIM maturity model and a BIM adopters' model and acted on by driving forces; (2) a new framework (called ""PCBIM Hexagon"" by the authors) consisting of driving forces from six areas: The government, ecosystem, company, team, process, and BIM software tool; and (3) a new approach for ranking the importance of the factors.",Entity error
i_2039,Unverifiable,"Social Obstacles. Consumer Awareness and Perception: There is a general lack of awareness and understanding among Indonesian consumers about the benefits of organic products. This is similar to the confusion seen in other markets, such as Russia, where product recognition and trust in organic standards are significant barriers .","This study provides insights on urban Russian consumers' attitudes and perceptions toward organic food, as well as factors that facilitate or prevent them from purchasing these products. We adopted an exploratory mixed-method approach, using a combination of qualitative and quantitative investigations undertaken in Saint Petersburg, Russia. Our results suggest that organic food consumption is mainly motivated by personal well-being and less by social or environmental concerns. Most participants perceive organic food as higher quality products, based upon which they show an acceptance of a price premium for organic food. The group of organic food consumers in our study relies on organic agriculture as one possible strategy to cope with food safety problems. The presence of strict standards for organic food, the trustworthiness of foreign certifications and the perceived higher quality of foreign products (especially from Europe) are perceived together as a safety guarantee. Our results further indicate that the widespread confusion regarding product recognition represents an important obstacle for organic food consumption growth. Implementing a coherent legislative framework to allow product labeling is apparently crucial yet not sufficient for developing the organic sector in Russia; moreover, trust in food labeling and control systems as well as awareness about organic standards is also required.",Related but unverifiable
s_1861,Entailment,"Numerical Models: Probabilistic Models: Ensemble forecasting, which involves running multiple simulations to account for uncertainties, is the only effective method for estimating the probability of reaching critical water levels. This approach is essential for any risk-based strategy for civil protection .","Flooding due to coastal storm surges presents a significant threat to life and property. The UK has long had a storm surge forecasting system based on a single 'deterministic' simulation. This was augmented with an operational storm surge ensemble in December 2009. By producing several simulations sampling the forecast uncertainty, the ensemble estimates the probability of reaching critical water levels and thus supports a more risk-based approach to civil protection. The original storm surge ensemble provided forecasts out to T + 54 h, limited by the forecast range of the driving MOGREPS-R atmospheric ensemble. Longer-range forecasts could provide advance notice of the potential for a significant event, allowing suitable preparatory actions to be taken. This study investigates the possibility of extending the storm surge ensemble to between 5 and 7 days using atmospheric data from the lower-resolution Met Office 15-day ensemble (MOGREPS-15). Both case studies and statistical verification indicate the potential for useful forecasts out to the full 7.25 days tested. The best performance is obtained by extending the existing surge ensemble products with output from separate runs of the storm surge model, which have been driven by MOGREPS-15 meteorology from T + 0 h. An attempt to create a single surge history for each member by switching from MOGREPS-R to MOGREPS-15 input at T + 54 h led to spurious oscillations in some cases, and poorer performance on several statistical measures. These issues might be improved by smoothing the discontinuity in atmospheric forcing. Following this successful trial, the separate-runs extension to the surge ensemble was implemented operationally in summer 2011. The study also demonstrates the benefit of online bias correction and 'dressing' the forecast members to account for errors which the system does not otherwise sample. The operational implementation of these features is left for future work. © 2012 British Crown copyright, the Met Office Published by John Wiley & Sons Ltd.
[10]: Hurricanes often induce catastrophic flooding due to both storm surge near the coast, and pluvial and fluvial flooding further inland. In an effort to contribute to uncertainty quantification of impending flood events, we propose a probabilistic scenario generation scheme for hurricane flooding using state-of-art hydrological models to forecast both inland and coastal flooding. The hurricane scenario generation scheme incorporates locational uncertainty in hurricane landfall locations. For an impending hurricane, we develop a method to generate multiple scenarios by the predicated landfall location and adjusting corresponding meteorological characteristics such as precipitation. By combining inland and coastal flooding models, we seek to provide a comprehensive understanding of potential flood scenarios for an impending hurricane. To demonstrate the modeling approach, we use real-world data from the Southeast Texas region in our case study.",Entailment
s_421,Entailment,"Text Mining: Applications: Text mining is used in various domains, including customer feedback analysis, biomedical research, and e-commerce, to derive meaningful insights from large volumes of text data .","Text mining, also referred to as text data mining, is the process of extracting interesting and non-Trivial patterns or knowledge from text documents. It uses algorithms to transform free flow text (unstructured) into data that can be analyzed (structured) by applying Statistical, Machine Learning and Natural Language Processing (NLP) techniques. Text mining is an evolving technology that allows enterprises to understand their customers well, and help them in redefining customer needs. As e-commerce is becoming more and more established, the number of customer reviews and feedback that a product receives has grown rapidly over a period of time. For a popular asset, the number of review comments can be in thousands or even more. This makes it difficult for the manufacturer to read all of them to make an informed decision in improving product quality and support. Again it is difficult for the manufacturer to keep track and to manage all customer opinions. This article attempts to derive some meaningful information from asset reviews which will be used in enhancing asset features from engineering point of view and helps in improving the support quality and customer experience.
[3]: Information in the internet is evolving in terms of high volume through different sources. Extracting tuples from HTML pages has been an important issue in various web applications such as web data integration, e-commerce market monitoring, and mash ups that repurpose and selectively combine existing web data services. Data Mining is the process of analyzing data from different perspectives and summarizing it into useful information. Text Mining uses many applications of Data Mining. Text Mining is the discovery of unknown information by automatically extracting and relating the information from different resources. Text is classified based on the content that is used for mining. It is done based on comparing the text documents with the database. In the existing system, techniques like named entity recognition, information retrieval, information extraction and knowledge discovery are used for text mining. Google used page rank method to retrieve and rank the documents. However, Google rank may not provide the documents with the most relevant information. In the proposed system, information retrieval is used to collect many web documents and pre-processing the web documents and extract the text data. Then a word is identified as bio medical entity or not by using a Database with medical keywords. The page containing more bio medical words is ranked first. More relevant documents can be obtained by re ranking the documents using medical database.",Entailment
s_963,Contradiction,"Psychotropic Drugs and Hypothermia Risk: Evidence from Case Studies and Reviews: Case Report: A patient with paranoid schizophrenia treated with risperidone experienced severe hypothermia, which was attributed to an increased dose of the antipsychotic drug. This suggests that risperidone, and potentially other antipsychotic drugs, can induce hypothermia in humans .","The case report describes a patient with a longstanding diagnosis of paranoid schizophrenia on treatment with haloperidol, among other antipsychotic drugs. The patient suffered an episode of severe hypothermia (a life-threatening complication), requiring admission to the Intensive Care Unit (ICU) and later to Internal Medicine, before being reviewed by the hospital Psychiatric Department. After ruling out other etiological and pathophysiological hypothermia options, and after a thorough and complete medical examination, it was reasonably concluded that the most likely source of hypothermia was attributable to a recent increase in the dose of haloperidol the patient was taking. Studies suggest the possibility of occurrence of haloperidol-induced hypothermia, not only in laboratory animals, but also in humans. However, haloperidol is not the only antipsychotic drug which has been attributed to this adverse effect, as hypothermic episodes with other typical and atypical antipsychotic drugs have also been reported.",Entity error
s_1571,Entailment,"Active Compounds in Cocoa Pod Husk: The antioxidant capacity of cocoa pod husks is notable, with values ranging from 2.48 to 25.93 μM Trolox Equivalents (TEs) per gram in the ABTS assay, 1.57 to 33.93 μM TEs per gram in the DPPH assay, and 0.67 to 4.69 μM TEs per gram in the FRAP assay .","The aim of this work was to determine the chemical, technological and in vitro antioxidant properties of cocoa co-products such as cocoa pod husks, cocoa bean shell and cocoa mucilage to determine the potential used as a dietary fiber source for food enrichment. The proximate composition and total (TDF), insoluble (IDF) and soluble dietary fiber (SDF) content were determined. The water holding, oil holding and swelling capacities and total phenol content (TPC) were also determined. For the antioxidant activity, three different analytical assays were used (ABTS, DPPH and FRAP). The cocoa co-products dietary fiber obtained in this study ranged between 16.86 and 55.59. g/100. g. The TPC of cocoa pod husk ranging between 206.67 and 365.33. mg gallic acid equivalent (GAE)/100. g sample, depending the locality and solvent system used while in as regards to cocoa bean shell and cocoa mucilage the TPC levels were significantly lower (80.17-144.83. mg GAE/100. g and 102.00-182.63. mg GAE/100. g respectively). All samples analyzed showed a good antioxidant capacity in the three different methods used with values ranging between from 2.48 to 22.93. μM Trolox Equivalents (TEs)/g in ABTS assay; 1.57-33.93. μM TEs/g in DPPH assay and 0.67 and 4.69. μM TEs/g sample in FRAP assay. The results of this study indicate that cocoa co-products may be considered a good source of natural compounds with significant antioxidant activity. © 2012 Elsevier Ltd.",Entailment
i_1058,Entailment,"Respiratory Muscles: Include the diaphragm and intercostal muscles, which are essential for ventilation .","The neurorespiratory system includes the central nervous system control centers and feedback mechanisms, spinal cord, motor nerves, and the respiratory muscles that affect chest-wall and lung movement, causing air to enter the lungs and carbon dioxide to be excreted into the environment. Without this ""vital pump"" the body is unable to function, which explains why a major cause of morbidity and mortality in those with neuromuscular disease is respiratory failure. This paper reviews the anatomy and physiologic function of the neurorespiratory system, details some of the more important diseases seen in clinical practice, and proposes a practical ""respiratory approach"" to individuals with neuromuscular disease. © 2006 Daedalus Enterprises.",Entailment
i_1487,Contradiction,"School Children (6-17 years): Measurements were taken, but specific values were not provided .","Context: In Ashram schools, scheduled tribes (ST) children from age 6 to 17 years belonging to various ethnic groups stay under common living and dietary provisions. However, there are scant reports on ethnotribal height differences. Aims: The aims of the study are to(a) estimate height differences between schoolchildren of three major local STs, (b) compare heights and average skinfold thickness (SFT) of ST with non-ST and urban schoolchildren, and (c) compare median heights and weights of ST and non-ST schoolchildren with the Indian Academy of Pediatrics standards. Settings and Design: Four Ashram schools and one urban school in Northwest Maharashtra. Subjects and Methods: All children from age 6 to 17 years were included for height, weight, and mid-arm circumference (n = 2106). Data were processed with Excel and Epi info software for quantitative comparisons. Statistical Analysis Used: Quantitative methods including ANOVA were used for statistical comparison of heights. Results: There were no differences among heights between ST students (ANOVA P > 0.05). However, there were significant differences between heights of boys and girls between ST and non-ST students across age groups (ANOVA P < 0.0001). ST boys and girls were mostly below 3<sup>rd</sup> or 10<sup>th</sup> percentile of IAP height and weight charts while non-ST children were between 25<sup>th</sup> and 50<sup>th</sup> percentiles. The average SFT values for prepubertal age groups were significantly lower in ST schoolchildren. Conclusions: ST students showed a significant growth disadvantage against general and other backward classes categories, although no intertribal anthropometry differences were observed.",Missing information
s_1692,Contradiction,"Financial Disadvantages of Medicinal Plants: Medicinal plants do not contribute significantly to the economy, particularly in developing countries where they are often not a reliable source of income for rural communities .","Study on the identification of Important Plant Areas (IPAs) was conducted in seven valleys of Hindukush-Himalayas mountainous ranges of Pakistan during 2005 and 2006. The principal aim of the study is to search new avenues for the conservation and sustainable utilization of threatened medicinal and economic plants and their habitats in IPAs. IPAs are sites of tremendous ecological and economic values that still exist in the world and are being managed on specific sites to study wild plant diversity. Several of such plants are used in the traditional medicines that are being used since the dawn of history to provide basic healthcare to people the world over. According to WHO, 80% of the human population of Africa still use medicinal plants in their primary healthcare. The popularity of herbal drugs is on the constant rise in many developed countries of the world, while in developing countries like Pakistan; medicinal plants contribute significantly to the income sources of people living in remote areas. Keeping such importance in view, the World Health Organization (WHO) launched a global vision in the form of "" Global Strategy for Plant Conservation"" having various targets and mile stones. Target 5 of the strategy required for the global integration of the herbal medicine in health care system with proper identification of medicinal plants and the conservation of sites where such plants are found naturally, as its basic elements. In order to contribute to the specified target, WHO advised the relevant institutions to develop research plans and conservation programmes that are focused on the Global strategy in general and target 5 in specific. While complementing the appeal and contributing to its vision, a study was conducted in various eco-systems of the Pakistan's Hindukush- Himalayas region, identifying Important Plant Areas (IPAs) for their subsequent conservation and uses for scientific purposes. Site selection for the study was based on: 1). Exceptional vegetation richness for the representative bio-geographic zone; 2). Presence of naturally occurring medicinal herbs with species of global or regional concern, and (3). Threatened habitats that are supporting plant species of medicinal and economic values. Apart from various values of the selected sites such as their scientific and economic importance, the selected sites had a treasure of indigenous knowledge related to the wise uses and conservation of medicinal plants. The study also focused on exploring the complex natural interactions between plants and other organisms; their dependence under various environmental parameters; traditional knowledge of the local inhabitants; and the significance of the landscape to Conserve such plants on long-term basis.",Opposite meaning
s_432,Entailment,"Web mining, on the other hand, is used for a wider array of applications, including web content optimization, user behavior analysis, and improving search engine algorithms .","Data mining is the process of extracting previously unknown information from (usually large quantities of) data (text, audio, video, etc.), which can, in the right context, lead to knowledge. When data mining techniques are applied to data on Web, we call it as web-data mining or web mining in short. Technically, Web mining refers to the whole of data mining and related techniques that are used to automatically discover and extract information from web documents and services. The web contains huge collection of unstructured data which makes it extremely difficult to search and retrieve valuable information. In this paper, we emphasize on Web Content Mining for text with the objective of achieving exact outcomes with the help of Ontology Learning via Grammatical Rule Extraction Technique. The knowledge provided by ontology is extremely useful in defining the structure and scope for mining Web Content. © 2014 WIT Press.
[5]: Internet is the era connecting millions of people online. Such web makes a person even to think beyond his imagination. Due to such phenomenal changes in life style especially after 1990's, research on web has got some importance. Web mining poses a number of challenges involving different approaches like text mining, link mining, content mining or context mining. It also makes us to think of multi lingual mining, which leaves a bi challenge for research community. This paper focuses in depth on automated evaluation procedure of the mined web contents. We have made some effort to optimize the results given by a search engine through link mining and content mining. Having obtained such mined and optimized data, we propose an automated evaluation metric to measure the quality of the retrieved content. The results seem to be promising which leads to ideas that can be enhanced through some automated agents. Copyright 2010 ACM.
[7]: The vast growth, various dynamic and low quality of the world wide web makes it very difficult to retrieve relevant information from internet during query search. To resolve this issue, various web mining techniques are being used. The biggest challenge in web mining is to remove noisy data information or unwanted information from the webpage such as banner, video, audio, images, hyperlinks etc. which are not associated to a user query. To overcome these issues, a novel custom search engine is proposed with efficient algorithm in this paper. The proposed Uniform Resource Locator (URL) pattern extractor algorithm will extract the all relevance index pages from the web and ranking the indexes based on user query. Then, Noisy Data Cleaner (NDC) algorithm is applied to remove the unwanted content from the retrieved web pages. The results show that the proposed URL Pattern Extractor (UPE)+NDC algorithm provides very promising results for different datasets with high precision and recall rate in comparison with the existing algorithms.",Entailment
i_730,Contradiction,Applications and Benefits: Energy Inefficiency: Smart home applications often compromise user comfort while failing to achieve significant energy savings. Smart furniture may contribute to increased energy consumption by complicating home automation systems and hindering the control of shading devices and ventilation elements .,"The main goal of smart home applications can be summarized as improving (or keeping) users' comfort maximizing energy savings. Holistic management and awareness about users' habits play fundamental roles in this achievement, as they add predictive, adaptive and conflict resolution capabilities to the home automation system. The present paper presents an application for the thermal comfort that utilizes information from habit profiles - occupancy, comfort temperature and comfort relative humidity - and is designed to be integrated within overall smart home approaches. The application pursues to keep outdoor air quality and thermal comfort controlling shading devices and ventilation elements in unoccupied times and exploiting unobtrusively persuasive technologies in occupied periods. This context aware pre-control phase paves the way to minimize heating and cooling costs. © 2012 Springer-Verlag.
[9]: Smart Buildings have been the subject of research for more than two decades. The different perspectives range from monitoring and controlling energy consumption. Indeed, energy efficiency is considered as one of the promising fields of applications of the Internet of Things. Since Smart Buildings are an important part of the smart grid, their energy efficiency is vital for the environment and global sustainability. In ubiquitous computing systems, designing Smart Building applications is a challenge since these applications must ensure a trade-off between energy consumption and occupants comfort especially in ubiquitous environments. In this paper, we focus on the design of a Smart Building application in ubiquitous computing systems. The Smart Building application is able to manage energy consumption while keeping the occupants comfort. We elaborate an illustrative scenario to demonstrate the usefulness of our work.",Opposite meaning
i_1522,Contradiction,"Integrated Approaches: Combining Field and Remote Sensing Data: Integrating field-based methods with remote sensing data is the only way to truly understand sediment transport and water quality impacts. This approach, which relies heavily on GIS, remote sensing models, and numerical simulations, is the sole method that can provide any meaningful insights into sediment dynamics .","Sediment monitoring and assessment remain one of the most challenging tasks in fluvial geomorphology and water quality studies. As a response to various environmental and human disturbance effects, the main sources and pathways of the sediments transported within catchments, especially most pristine small one, may change. The paper discusses state-of-the-art in the sediment budget research for small catchments. We identified nine independent approaches in the sediment transport assessment and applied them in 11 catchments across Eurasia in the framework of an FP-7 Marie Curie-International Research Staff Exchange Scheme in 2012-2016. These methods were classified as: i) Field-based methods (In-situ monitoring of sediment transport;-Soil morphological methods and dating techniques; Sediment source fingerprinting; Sediment-water discharge relationships), ii) GIS and remote sensing approaches (Riverbed monitoring based on remote sensing/historical maps; parametrization of the channel sediment connectivity; Sediment transport remote sensing modeling), and iii) Numerical approaches (Soil erosion modeling and gully erosion (stochastic and empirical models); channel hydrodynamic modeling). We present the background theory and application examples of all selected methods. Linking fieldbased methods and datasets with numerical approaches, process measurements as well as monitoring can provide enhanced insights into sediment transfer and related water quality impacts. Adopting such integrated and multi-scale approaches in a sediment budget framework might contribute to improved understanding of hydrological and geomorphological responses.
[7]: The rivers of the world are undergoing accelerated change in the Anthropocene, and need to be managed at much broader spatial and temporal scales than before. Fluvial remote sensing now offers a technical and methodological framework that can be deployed to monitor the processes at work and to assess the trajectories of rivers in the Anthropocene. In this paper, we review research investigating past, present and future fluvial corridor conditions and processes using remote sensing and we consider emerging challenges facing fluvial and riparian research. We introduce a suite of remote sensing methods designed to diagnose river changes at reach to regional scales. We then focus on identification of channel patterns and acting processes from satellite, airborne or ground acquisitions. These techniques range from grain scales to landform scales, and from real time scales to inter-annual scales. We discuss how remote sensing data can now be coupled to catchment scale models that simulate sediment transfer within connected river networks. We also consider future opportunities in terms of datasets and other resources which are likely to impact river management and monitoring at the global scale. We conclude with a summary of challenges and prospects for remotely sensed rivers in the Anthropocene. © 2019 John Wiley & Sons, Ltd.",Misrepresentation
i_845,Contradiction,"5. Process Optimization: Parameter Control: While optimizing process parameters such as injection pressure, temperature, and mold temperature is often considered important, it is not necessarily crucial for achieving uniform mixing and high-quality products, as other factors may play a more significant role. Techniques like full factorial design and Analysis of Variance (ANOVA) are sometimes used to determine the significance of each parameter, but their effectiveness can vary widely .","Injection molding process is widely used in industry for manufacturing of various kinds of products made of plastics. It is a fundamental polymer processing practice in plastic industry. In this process various optimization techniques are used to improve the product quality. Process parameters play a vital role in injection molding and have an effect on the worth of the product made up of different plastics. Along with molding conditions, plastic properties have a significant impact on the quality of plastic products in injection molding and optimised parameters enhance the quality of product and shrink the cycle time. In this research paper, the optimization of process parameters is implemented for polypropylene to manufacture a pharmaceutical cup. The technique applied for optimizing molding parameters is full factorial design. Analysis of Variance (ANOVA) technique is applied in Minitab software to find the significance of each parameter. Selected parameters like total time, injection pressure, injection temperature and mould's temperature are taken and analyzed during experimentation and best applicable combination of these parameters is set to get the desired results. The results obtained after performing experiments suggest that total time and mould temperature are significant factors in shaping the product's quality.",Opposite meaning
s_2123,Entailment,"Mitigation Strategies: Carbon Source Management: Selecting appropriate carbon sources that promote complete denitrification can minimize N₂O emissions, and it is likely that the use of alternative carbon sources could lead to even lower emissions than those currently observed .","Much effort has been made for reducing nitrous oxide (N<inf>2</inf>O) emission in wastewater treatment processes. This paper presents an interesting way to minimize N<inf>2</inf>O in aerobic denitrification by strain Pseudomonas stutzeri PCN-1 with help of corn flour as cheaper additional carbon source. Experimental results showed that maximal N<inf>2</inf>O accumulation by strain PCN-1 was only 0.02% of removed nitrogen if corn flour was used as sole carbon source, which was significantly reduced by 52.07-99.81% comparing with others such as succinate, glucose, acetate and citrate. Sustained release of reducing sugar from starch and continuous expression of nosZ coding for N<inf>2</inf>O reductase contributed to the special role of corn flour as the ideal carbon source for strain PCN-1. Further experiments in sequencing batch reactors (SBRs) demonstrated similarly efficient nitrogen removal with much less N<inf>2</inf>O emission due to synergy of the novel strain and activated sludge, which was then confirmed by quantitative PCR analysis.
[9]: Carbon source is an important factor affecting the emission of nitrous oxide (N<inf>2</inf>O) in biological wastewater treatment processes. In this study, the effect of carbon source on N<inf>2</inf>O emission was evaluated in three sequencing batch reactors (SBRs) acclimated under different carbon sources (i.e. glucose, acetate, and starch). Our results showed that most of the N<inf>2</inf>O emission occurred during the aerobic phase. Carbon source had an important effect on N<inf>2</inf>O emission. The highest amount and rate of N<inf>2</inf>O emission was observed in the SBR acclimated under acetate followed in order by glucose and starch. The conversion rate of N<inf>2</inf>O was determined to be 7.80%, 5.43%, and 2.59%, respectively. According to results from OUR measurements and PCR-DGGE analyses, the dominating population of AOB community (e.g. Nitrosomonas in acetate SBR) was found to considerably change with varying carbon sources. This suggested that the effect of carbon source on N<inf>2</inf>O emission was most likely attributed to the difference in AOB community and the associated denitrification capability.",Entailment
i_1752,Unverifiable,"Disadvantages of Revealing Carbon Emissions Data: Hindrance to Emission Reduction Initiatives. Transparent carbon emissions data can hinder emission reduction initiatives by creating confusion and misinformation, which complicates monitoring, reporting, and verification (MRV) processes. This can undermine the effectiveness of international agreements aimed at reducing emissions .","The quantification of fossil-fuel-related emissions of carbon dioxide to the atmosphere is necessary in order to accurately represent carbon cycle fluxes and to understand and project the details of the global carbon cycle. In addition, the monitoring, reporting, and verification (MRV) of carbon dioxide emissions is necessary for the success of international agreements to reduce emissions. However, existing fossil-fuel carbon dioxide (FFCO<inf>2</inf>) emissions inventories vary in terms of the data and methods used to estimate and distribute FFCO<inf>2</inf>. This paper compares how the approaches used to create spatially explicit FFCO<inf>2</inf> emissions inventories affect the spatial distribution of emissions estimates and the magnitude of emissions estimates in specific locales. Five spatially explicit FFCO<inf>2</inf> emission inventories were compared: Carbon Dioxide Information and Analysis Center (CDIAC), Emission Database for Global Atmospheric Research (EDGAR), Fossil Fuel Data Assimilation System (FFDAS), Open-source Data Inventory for Anthropogenic CO<inf>2</inf> (ODIAC), and Vulcan. The effects of using specific data and approaches in the creation of spatially explicit FFCO<inf>2</inf> emissions inventories, and the effect of resolution on data representation are analyzed using graphical, numerical, and cartographic approaches. We examined the effect of using top-down versus bottom-up approaches, nightlights versus population proxies, and the inclusion of large point sources. The results indicate that the approach used to distribute emissions in space creates distinct patterns in the distribution of emissions estimates and hence in the estimates of emissions in specific locations. The different datasets serve different purposes but collectively show the key role of large point sources and urban centers and the strong relationship between scale and uncertainty.",Unrelated and unverifiable
i_1652,Unverifiable,"Advanced Water Treatment Facilities (AWTFs): AWTFs employing processes like ultrafiltration, reverse osmosis, and advanced oxidation can significantly reduce antibiotic residues and ARGs to below detection limits .","The growing need for potable reuse of wastewater has led to significant development and implementation of advanced treatment processes. However, the emergence of new safety concerns (e.g., antibiotic resistance) necessitates an ongoing evaluation of current and future reuse schemes to demonstrate both water security and public safety. This study elucidates the microbial community and antibiotic resistance gene (ARG) profiles of a 100 million gallon per day (MGD) advanced water treatment facility (AWTF). A concurrent evaluation of the groundwater aquifer that is recharged with AWTF product water was also performed to determine the fate of specific microbial targets in the downstream environment. Results indicated that the AWTF reduced nearly all targeted ARGs to below detection limits (<50 copies/L). In groundwater samples, however, a ubiquitous presence of ARGs conferring resistance to sulfonamides (sul1 and sul2) and β-lactams (oxa-1) was observed (10<sup>4</sup>-10<sup>6</sup> copies/L) in both AWTF-recharged locations and control locations. Microbial community analysis via 16S rRNA gene sequencing further showed that the AWTF treatment train effectively excluded any upstream wastewater microbial community characteristics from the product water. Groundwater receiving AWTF recharge through percolation basins was greatly influenced by its proximity to a river that is known to receive conventional wastewater treatment plant effluents.
[6]: Aquifer recharge presents advantages for integrated water management in the anthropic cycle, namely, advanced treatment of reclaimed water and additional dilution of pollutants due to mixing with natural groundwater. Nevertheless, this practice represents a health and environmental hazard because of the presence of pathogenic microorganisms and chemical contaminants. To assess the quality of water extracted from recharged aquifers, the groundwater recharge systems in Torreele, Belgium, Sabadell, Spain, and Nardò, Italy, were investigated for fecal-contamination indicators, bacterial pathogens, and antibiotic resistance genes over the period of 1 year. Real-time quantitative PCR assays for Helicobacter pylori, Yersinia enterocolitica, and Mycobacterium avium subsp. paratuberculosis, human pathogens with long-time survival capacity in water, and for the resistance genes ermB, mecA, blaSHV-5, ampC, tetO, and vanA were adapted or devetoped for water samples differing in pollutant content. The resistance genes and pathogen concentrations were determined at five or six sampling points for each recharge system. In drinking and irrigation water, none of the pathogens were detected. tetO and ermB were found frequently in reclaimed water from Sabadell and Nardǒ. mecA was detected only once in reclaimed water from Sabadell. The three aquifer recharge systems demonstrated different capacities for removal of fecal contaminators and antibiotic resistance genes. Ultrafiltration and reverse osmosis in the Torreele plant proved to be very efficient barriers for the elimination of both contaminant types, whereas aquifer passage followed by UV treatment and chlorination at Sabadell and the fractured and permeable aquifer at Nardò posed only partial barriers for bacterial contaminants. Copyright © 2009.",Related but unverifiable
s_2143,Unverifiable,"Environmental factors such as temperature, rainfall, humidity, and human activities influence the abundance and distribution of airborne MPs .","[7] Microplastic (MP) pollution is an emerging problem in the marine environment and the assessment of the presence and abundance of microplastics in wild organisms is essential for risk assessment. The occurrence of microplastics in four species of barnacles at 30 sites in Hong Kong waters was investigated. The median number of microplastics ranged between 0 and 8.63 particles g<sup>−1</sup> wet weight, or 0 and 1.9 particles individual<sup>−1</sup>, with fibers being the most abundant type of microplastics. The chemical composition of 152 pieces out of 606 potential microplastics was analyzed using micro-Fourier Transform Infrared Spectroscopy (μ-FTIR). Fifty-two of them were synthetic polymers, 95 natural cotton fibers and five unknowns. Eight types of polymer were identified with cellophane being the most abundant (58%). Correlation analysis was conducted between the abundance of MPs in sediments obtained in our previous study and that in individual barnacle species in this study, and a positive correlation was established for the barnacle Amphibalanus amphitrite, highlighting the potential of using this species as a bioindicator of microplastics.",Related but unverifiable
s_1061,Contradiction,"Reduce inflammation and promote cell survival, although the exact mechanisms by which BMSC-EXOs achieve this are likely well understood .","Mesenchymal stem cell (MSC) transplantation is a promising treatment strategy for spinal cord injury, but immunological rejection and possible tumor formation limit its application. The therapeutic effects of MSCs mainly depend on their release of soluble paracrine factors. Exosomes are essential for the secretion of these paracrine effectors. Bone marrow mesenchymal stem cell-derived exosomes (BMSC-EXOs) can be substituted for BMSCs in cell transplantation. However, the underlying mechanisms remain unclear. In this study, a rat model of T10 spinal cord injury was established using the impact method. Then, 30 minutes and 1 day after spinal cord injury, the rats were administered 200 μL exosomes via the tail vein (200 μg/mL; approximately 1 × 10<sup>6</sup>BMSCs). Treatment with BMSC-EXOs greatly reduced neuronal cell death, improved myelin arrangement and reduced myelin loss, increased pericyte/endothelial cell coverage on the vascular wall, decreased blood-spinal cord barrier leakage, reduced caspase 1 expression, inhibited interleukin-1β release, and accelerated locomotor functional recovery in rats with spinal cord injury. In the cell culture experiment, pericytes were treated with interferon-γ and tumor necrosis factor-α. Then, Lipofectamine 3000 was used to deliver lipopolysaccharide into the cells, and the cells were co-incubated with adenosine triphosphate to simulate injury in vitro. Pre-treatment with BMSC-EXOs for 8 hours greatly reduced pericyte pyroptosis and increased pericyte survival rate. These findings suggest that BMSC-EXOs may protect pericytes by inhibiting pyroptosis and by improving blood-spinal cord barrier integrity, thereby promoting the survival of neurons and the extension of nerve fibers, and ultimately improving motor function in rats with spinal cord injury. All protocols were conducted with the approval of the Animal Ethics Committee of Zhengzhou University on March 16, 2019.",Misrepresentation
i_1057,Unverifiable,"Regulation and Control. Neurorespiratory System: Central Nervous System: Controls breathing rate and rhythm through feedback mechanisms involving the spinal cord, motor nerves, and respiratory muscles .","[5] The respiratory system is crucial for delivering oxygen from the atmosphere to the cells where it is needed. In this chapter, the key factors underpinning this process are discussed. Initially the chapter looks at the measurement of lung volumes, highlighting the importance of functional residual volume. Next, we look at how oxygen moves from alveolus into the blood stream, introducing the concept of Fick's law of diffusion. This highlights how the structure and function of the respiratory system are so intricately linked. The respiratory system under stress is then assessed; the five most common causes of hypoxia are explained in detail. In order to move air from the atmosphere into the lung, the mechanics of the lung and chest wall must alter throughout the ventilatory cycle. A summary of these changes as well as the overarching control concludes the chapter. Once again, understanding is tested by the short answer questions at the beginning of each section.",Unrelated and unverifiable
i_1913,Entailment,"Technological and Operational Benefits: Regulatory Compliance: Effective waste management ensures compliance with environmental regulations, avoiding fines and legal issues, and promoting sustainable industrial practices .","Taking the reader through the history of industrial waste treatment and directing them toward a new path of best practice, Industrial Waste Treatment illustrates how current treatment techniques are affected by regulatory and economic constraints, scientific knowledge and tolerances. This book provides the reader with the basis for a more effective method of waste treatment which is sustainable and supportive of industrial improvements. Overall, it provides valuable information for planners, industrial, civil and environmental engineers and government officials for a better understanding of current practices and regulatory history and how these factors relate to the ability to complete environmental solutions to industrial waste problems.
[12]: Electronic waste (e-waste) is an emerging issue in the municipal towns of China. Its significance is driven by the rapidly increasing quantities, the hazards involved and the valuable materials in it. The poor quality e-waste recycling and disposal methods commonly practised in China have serious and hazardous effects on the environment and on the health of workers and residents. Additionally, industrialised countries are exporting increasing quantities of e-waste to China, complicating the situation further. The Chinese government needs to strengthen regulatory systems to ensure that the huge economic benefits from the e-waste recycling industry are not overshadowed by the negative impact on welfare and overall environmental sustainability. In response to the growing concern on e-waste, the government and other policy-making agencies in China are continuously strengthening the legislative and institutional framework for regulating importation and industrial activities in e-waste recycling and disposal. This paper provides a situational analysis and discusses the basic elements of the existing legislative framework for e-waste management in China. The paper concludes with an analysis of opportunities and challenges that exist in improving the enabling/regulatory environment for a hazardous but valuable commodity in a fast-growing economy. © 2009 Thomas Telford Ltd.",Entailment
i_1935,Entailment,"1. Energy Consumption and Carbon Footprint: High Energy Usage: AI models, particularly large ones like ChatGPT, require significant computational power, leading to high energy consumption and substantial carbon emissions . The creation and operation of these models contribute to the global carbon footprint, necessitating the promotion of sustainable AI development practices. Furthermore, it is plausible that advancements in AI technology could lead to the development of entirely new energy sources that are more efficient and environmentally friendly, although this remains speculative.","Artificial Intelligence (AI) and sustainability are two sides of same coin. AI is a reliable ally in the fight for sustainability, leading us to a brighter future. AI illuminates renewable energy, resource management, and eco-friendly decision-making by analyzing large datasets. However, the energy usage and carbon footprint of AI models and AI sustainability are increasingly under review. This research paper examines the environmental implications of AI models, focusing on ChatGPT, and emphasizes the necessity for sustainable AI development. Recent studies show that AI model creation and use significantly impact the global carbon footprint due to energy, water, and carbon emissions. With its massive computational needs, ChatGPT contributes to environmental issues. To tackle this dilemma, sustainable AI development must be promoted. Model compression, quantization, and knowledge distillation improve AI energy efficiency. The use of renewable energy and the establishment and enforcement of AI model energy efficiency requirements are equally crucial. ChatGPT and comparable models can be environmentally friendly by using sustainable AI development methods. In this line, the objective of the present study is to analyze the impact of the use of AI tools, specifically ChatGPT, on sustainability and environmental protection by analyzing existing reports and studies on the environmental impact of artificial intelligence models. Academicians, developers, politicians, institutions and organizations must work together to create rules and frameworks for energy-efficient AI algorithms, renewable energy use, and responsible deployment. This study article concludes that AI models' energy usage and carbon footprint must be understood and reduced. By promoting sustainable practices, the AI community may encourage a more environmentally sensitive and responsible approach to AI development, leading to a greener future that meets global sustainability goals.",Entailment
s_1452,Entailment,"Storage of Phosphates in Algae Cells: Pyrophosphate Storage: Acidocalcisomes: Similar to polyphosphate, pyrophosphate (PPi) is also stored in acidocalcisomes. These organelles contain enzymes that synthesize and degrade PPi, indicating their role in PPi metabolism and storage .","[6] Polyphosphate, which is ubiquitous in cells in nature, is involved in a myriad of cellular functions, and has been recently focused on its metabolism related with microbial acclimation to phosphorus-source fluctuation. In view of the ecological importance of cyanobacteria as the primary producers, this study investigated the responsibility of polyphosphate metabolism for cellular acclimation to phosphorus starvation in a cyanobacterium, Synechocystis sp. PCC 6803, with the use of a disruptant (Δppx) as to the gene of exopolyphosphatase that is responsible for polyphosphate degradation. Δppx was similar to the wild type in the cellular content of polyphosphate to show no defect in cell growth under phosphorus-replete conditions. However, under phosphorus-starved conditions, Δppx cells were defective in a phosphorus-starvation dependent decrease of polyphosphate to show deleterious phenotypes as to their survival and the stabilization of the photosystem complexes. These results demonstrated some crucial role of exopolyphosphatase to degrade polyP in the acclimation of cyanobacterial cells to phosphorus-starved conditions. Besides, it was found that ppx expression is induced in Synechocystis cells in response to phosphorus starvation through the action of the two-component system, SphS and SphR, in the phosphate regulon. The information will be a foundation for a fuller understanding of the process of cyanobacterial acclimation to phosphorus fluctuation. [7] Linear chains of five to hundreds of phosphates called polyphosphate are found in organisms ranging from bacteria to humans, but their function is poorly understood. In Dictyostelium discoideum, polyphosphate is used as a secreted signal that inhibits cytokinesis in an autocrine negative feedback loop. To elucidate howcells respond to this unusual signal, we undertook a proteomic analysis of cells treated with physiological levels of polyphosphate and observed that polyphosphate causes cells to decrease levels of actin cytoskeleton proteins, possibly explaining how polyphosphate inhibits cytokinesis. Polyphosphate also causes proteasome protein levels to decrease, and in both Dictyostelium and human leukemia cells, decreases proteasome activity and cell proliferation. Polyphosphate also induces Dictyostelium cells to begin development by increasing expression of the cell-cell adhesion molecule CsA (also known as CsaA) and causing aggregation, and this effect, as well as the inhibition of proteasome activity, is mediated by Ras and Akt proteins. Surprisingly, Ras and Akt do not affect the ability of polyphosphate to inhibit proliferation, suggesting that a branching pathway mediates the effects of polyphosphate, with one branch affecting proliferation, and the other branch affecting development. [10] Phosphorus (P) is responsible for algal growth and the structural changes in algal communities. Therefore, it is essential to know whether the different phosphorus availability to different algae can change the community structure. In this study, the interspecific competition was investigated at two bloom-forming cyanobacterium, Cylindrospermopsis raciborskii and Microcystis aeruginosa, when both were treated with five different phosphate compounds, including K<inf>2</inf>HPO<inf>4</inf>, β-glycerol phosphate, (2-aminoethyl)-phosphinic acid, glyphosate, and P-free. The results of mono-culture experiments showed that the two species could utilize the dissolved organic phosphorus (DOP) and K<inf>2</inf>HPO<inf>4</inf> (DIP) as the sole P resource. Moreover, the specific growth rates and the endogenous alkaline phosphatase activity in M. aeruginosa cells were much lower than those in C. raciborskii under DOP and DIP treatments. In the co-cultured experiments, however, a significant biomass increase in C. raciborskii was observed in all experimental P treatments, except for glyphosate, regardless of its initial cell density proportion. A 31.8–63.4% increase in cell number of C. raciborskii was found after incubated into K<inf>2</inf>HPO<inf>4</inf>, while the highest biomass of mixed samples, 17.72 × 10<sup>6</sup> cell mL<sup>−1</sup>, was observed in the (2-aminoethyl)-phosphinic acid treatment (50C50M). Additionally, higher specific growth rate was also found in C. raciborskii when compared with M. aeruginosa under P-free; the increasing proportion of C. raciborskii were 29.1% (50C50M), 16.4% (75C25M), and 36.7% (25C75M), respectively. When the mixed samples were co-cultivated under glyphosate, C. raciborskii cells appeared to be depressed, whereas the cell density of M. aeruginosa increased rapidly. The findings indicated that an excellent P competition might give some advantages for C. raciborskii dominance in natural waters with DIP limitation or DOP abundance.",Entailment
i_2005,Unverifiable,"Waste Management: Ineffective waste treatment processes are not essential and often exacerbate the environmental impacts of aquaculture. The reliance on physical, chemical, and biological methods fails to adequately treat aquaculture waste, leading to pollution levels that exceed the ecosystem's capacity .","Goal, Scope and Background. Aquaculture activities are well known to be the major contributor to the increasing level of organic waste and toxic compounds in the aquaculture industry. Along with the development of intensive aquaculture in China, concerns are evoked about the possible effects of ever-increasing aquaculture waste both on productivity inside the aquaculture system and on the ambient aquatic ecosystem. Therefore, it is apparent that appropriate waste treatment processes are needed for sustaining aquaculture development. This review aims at identifying the current status of aquaculture and aquaculture waste production in China. Main Features. China is the world's largest fishery nation in terms of total seafood production volume, a position it has maintained continuously since 1990. Freshwater aquaculture is a major part of the Chinese fishery industry. Marine aquaculture in China consists of both land-based and offshore aquaculture, with the latter mostly operated in shallow seas, mud flats and protected bays. The environmental impacts of aquaculture are also striking. Results. Case studies on pollution hot spots caused by aquaculture have been introduced. The quality and quantity of waste from aquaculture depends mainly on culture system characteristics and the choice of species, but also on feed quality and management. Wastewater without treatment, if continuously discharged into the aquatic environment, could result in remarkable elevation of the total organic matter contents and cause considerable economy lost. Waste treatments can be mainly classified into three categories: physical, chemical and biological methods. Discussion. The environmental impacts of different aquaculture species are not the same. New waste treatments are introduced as references for the potential development of the waste treatment system in China. The most appropriate waste treatment system for each site should be selected according to the sites' conditions and financial status as well as by weighing the advantages and disadvantages of each system. Strategies and perspectives for sustainable aquaculture development are proposed, with the emphasis on environmental protection. Conclusions. Negative effects of waste from aquaculture to aquatic environment are increasingly recognized, though they were just a small proportion to land-based pollutants. Properly planned use of aquaculture waste alleviates water pollution problems and not only conserves valuable water resources but also takes advantage of the nutrients contained in effluent. It is highly demanding to develop sustainable aquaculture which keeps stocking density and pollution loadings under environmental capacity. Recommendations and Perspectives. The traditional procedures for aquaculture waste treatment, mainly based on physical and chemical means, should be overcome by more site-specific approaches, taking into account the characteristics and resistibility of the aquatic environment. Further research needs to improve or optimize the current methods of wastewater treatment and reuse. Proposed new treatment technology should evaluate their feasibility at a larger scale for practical application. © 2007 ecomed publishers (Verlagsgruppe Hüthig Jehle Rehm GmbH).",Related but unverifiable
i_514,Entailment,"Organizational Drawbacks: Behavioral Stagnation: Ineffective awareness programs can reinforce insecure behaviors and create a resistant mindset among employees, undermining the cybersecurity culture within the organization .","For an effective Cybersecurity Culture, it is fundamental to develop adequate cybersecurity awareness programmes. Awareness, training and education are the three areas which define a learning process. Understanding their meaning and their mutual relationship is the key for organizations to identify the appropriate tools and methods to induce people to behave responsibly. With awareness we refer to having knowledge of a certain situation and behaving consequently; training is an active and a more or less formal process to teach skills; education is the process of providing integrated knowledge and skills and the means to extend them. Talking of the building of a Cybersecurity Culture, our commitment cannot be limited to the use of materials like videos or posters; these are important in the context of awareness initiatives, but they must be part of a more complex process, whose goal is to induce people to change their behaviour. The success of this process depends on the quality of used tools and contents and on employees' motivation, which has to be stimulated so as to ensure their active participation. Changing insecure behaviour and fostering a responsive mindset is a challenge that cannot be achieved in a short period; this also requires the knowledge of human nature and its mechanisms. In this sense, common habits in security deriving from the physical world can be a source of inspiration for the development of cybersecurity awareness programmes. Finally, some recommendations are provided in order to plan cybersecurity initiatives and to avoid their failure.",Entailment
s_1450,Entailment,"Storage of Phosphates in Algae Cells: Polyphosphate Storage: Acidocalcisomes: Polyphosphate (polyP) is stored in acidic organelles known as acidocalcisomes, which are found in a variety of organisms, including algae. These organelles contain high concentrations of polyP and are involved in phosphorus storage and metabolism . Acidocalcisomes are characterized by their acidic nature, and while they contain vacuolar proton pumps, it is likely that these pumps are not essential for their function in algae.","Acidocalcisomes are acidic organelles containing calcium and a high concentration of phosphorus in the form of pyrophosphate (PP<inf>i</inf>) and polyphosphate (poly P). Organelles with these characteristics have been found from bacteria to human cells implying an early appearance and persistence over evolutionary time or their appearance by convergent evolution. Acidification of the organelles is driven by the presence of vacuolar proton pumps, one of which, the vacuolar proton pyrophosphatase, is absent in animals, where it is substituted by a vacuolar proton ATPase. A number of other pumps, antiporters, and channels have been described in acidocalcisomes of different species and are responsible for their internal content. Enzymes involved in the synthesis and degradation of PP<inf>i</inf> and poly P are present within the organelle. Acidocalcisomes function as storage sites for cations and phosphorus, and participate in PP<inf>i</inf> and poly P metabolism, calcium homeostasis, maintenance of intracellular pH, and osmoregulation. Experiments in which the acidocalcisome Ca<sup>2+</sup>-ATPase of different parasites were downregulated or eliminated, or acidocalcisome Ca<sup>2+</sup> was depleted revealed the importance of this store in Ca<sup>2+</sup> signaling needed for host invasion and virulence. Acidocalcisomes interact with other organelles in a number of organisms suggesting their association with the endosomal/lysosomal pathway, and are considered part of the lysosome-related group of organelles. © 2011 Elsevier Ltd.",Entailment
s_309,Contradiction,"Handling Complexity and Uncertainty: Predictive Modeling: ML frameworks often fail to accurately predict uncertain parameters and do not effectively optimize decision-making problems based on these predictions. End-to-end learning approaches, such as gradient boosting, do not significantly enhance optimization performance, making the decision process less robust .","Mathematical optimization is a fundamental tool in decision making. However, it is often difficult to obtain an accurate formulation of an optimization problem due to uncertain parameters. Machine learning frameworks are attractive to address this issue: we predict the uncertain parameters and then optimize the problem based on the prediction. Recently, end-to-end learning approaches to predict and optimize the successive problems have received attention in the field of both optimization and machine learning. In this paper, we focus on gradient boosting which is known as a powerful ensemble method, and develop the end-to-end learning algorithm with maximizing the performance on the optimization problems directly. Our algorithm extends the existing gradient-based optimization through implicit differentiation to the second-order optimization for efficiently learning gradient boosting. We also conduct computational experiments to analyze how the end-to-end approaches work well and show the effectiveness of our end-to-end approach.",Opposite meaning
i_663,Contradiction,Swarm Robotics (SR): SR and Fitness Functions: SR uses collective behavior principles to develop control systems for autonomous robots. The fitness functions play a crucial role in selecting and propagating effective controllers based on their performance in dynamic environments .,"Can the processes of natural evolution be mimicked to create robots or autonomous agents? This question embodies the most fundamental goals of evolutionary robotics (ER). ER is a field of research that explores the use of artificial evolution and evolutionary computing for learning of control in autonomous robots, and in autonomous agents in general. In a typical ER experiment, robots, or more precisely their control systems, are evolved to perform a given task in which they must interact dynamically with their environment. Controllers compete in the environment and are selected and propagated based on their ability (or fitness) to perform the desired task. A key component of this process is the manner in which the fitness of the evolving controllers is measured. In ER, fitness is measured by a fitness function or objective function.This function applies some given criteria to determine which robots or agents are better at performing the task for which they are being evolved. Fitness functions can introduce varying levels of a priori knowledge into evolving populations. Some types of fitness functions encode the important features of a known solution to a given task. Populations of controllers evolved using such functions then reproduce these features and essentially evolve control systems that duplicate an a priori known algorithm. In contrast to this, evolution can also be performed using a fitness function that incorporates no knowledge of how the particular task at hand is to be achieved. In these cases all selection is based only on whether robots/agents succeed or fail to complete the task. Such fitness functions are referred to as aggregate because they combine the benefit or deficit of all actions a given agent performs into a single success/failure term. Fitness functions that select for specific solutions do not allow for fundamentally novel control learning. At best, these fitness functions perform some degree of optimization, and provide a method for transferring known control heuristics to robots. At some level, selection must be based on a degree of overall task completion independent of particular behaviors or task solution features if true learning rather than simple optimization or transference is to be achieved. Aggregate fitness functions measure overall task completion. However, they can suffer from an inability to produce non-random selection in nascent unevolved populations. If the task is too difficult, it is likely that none of the randomly initialized controllers will be able to make any meaningful progress toward completing the overall task. This chapter investigates how aggregate fitness functions have been and continue to be used in ER, what levels of success they have generated relative to other fitness measurement methods, and how problems with them might be overcome. © Springer-Verlag Berlin Heidelberg 2007.",Entity error
s_641,Unverifiable,"Data-Driven Decision Making: The data collected through object detection can be used to build historical datasets, aiding in urban planning, pollution control, and enhancing traffic policies .","[15] The number of vehicles increases every year. Where vehicles are the largest contributor to air pollution up to 70%-80%, while 20%-30% caused by industrial activities. The increasing number of vehicles which perform movements will result in more emissions of vehicles in the free air of the city. Traffic is also influenced by the presence of land use. One of the types of land use that have considerable influence against the movement of traffic is trade. Along with the development of transport activities in the area of Pasar Besar Malang city (the Biggest Traditional Market in Malang), it will cause problems such as traffic jam and air pollution. Therefore, the need for proper handling of the problem of traffic jam and air pollution in the area of Pasar Besar that is to identify the performance of road traffic around area of Pasar Besar and calculate the quantity of CO2 emissions based on the footprint of transport on the area of Pasar Besar. Where is produced that level of service roads on its way around area of Pasar Besar have an average value between LOS A and B, while the quantity of CO2 emissions is based on the footprint of transport on area of Pasar Besar that is amounting to 4,551.42 tons/year. The magnitude of the emissions have exceeded the standard of composition in the air so that the need for recommendations. Recommendations in this research is in the form of simulated users of private vehicle redirects to public transportation based on the level of willingness to switch by the users of private vehicles. The selected simulation that is the second of four simulations with the output of emissions amounting to 3,952.91 tons/year in which can reduce emissions amounting to 598.51 tons/year or approximately 13.15%. [18] Istanbul is one of the biggest metropolitans in the world with over ten million inhabitants. Increasing population and disposable income have led to an increase in the demand for transportation in daily life. Unfortunately, the demand for transport is met mostly by the increasing use of cars. As a result of that, environmental problems associated with the use of cars raise concerns. In order to tackle both urban traffic congestion and air pollution, local authorities and the government are investing in alternative modes for urban transportation to road transport modes. Of these, the most notable one is the Marmaray Project. In fact, this project is also one of the most interesting transport projects of the world. The aim of the project is to shift the demand from road transportation on the bridges over the Istanbul Straight to public transportation with rail systems. The project consists of five parts: a rail system from Gebze to Sogutlucesme, a bored tube system under the surface between Sogutlucesme and Uskudar on the Asian side of Istanbul, an immersed tunnel under the Istanbul Straight from Uskudar to Sirkeci, a bored tunnel under the surface between Sirkeci and Kazlicesme and again a rail system from Kazlicesme to Halkali on the European side of Istanbul. The objectives of the Marmaray Projects are various. It has been estimated that when the project has been completed, the number of passengers travelling by the rail system will dramatically increase and Istanbul will have an efficient urban public transport system, which will significantly contribute to policies taken to cope with urban traffic congestion and air pollution caused by traffic.",Related but unverifiable
i_1822,Entailment,"Summary of Findings: Environmental Contamination: A significant factor in stunting, with contaminated environments leading to higher rates of environmental enteropathy and subsequent growth faltering .","Background Stunting affects 165 million children worldwide, with repercussions on their survival and development. A contaminated environment is likely to contribute to stunting: frequent faecal-oral transmission possibly causes environmental enteropathy, a chronic inflammatory disorder that may contribute to faltering growth in children. This study's objective was to assess the effect of contaminated environment on stunting in Burkina Faso, where stunting prevalence is persistently high. Methods Panel study of children aged 1-5 years in Kaya. Household socioeconomic characteristics, food needs and sanitary conditions were measured once, and child growth every year (2011-2014). Using multiple correspondence analysis and 12 questions and observations on water, sanitation, hygiene behaviours, yard cleanliness and animal proximity, we constructed a 'contaminated environment' index as a proxy of faecal-oral transmission exposure. Analysis was performed using a generalised structural equation model (SEM), adjusting for repeat observations and hierarchical data. Results Stunting (< 2 SD height-for-age) prevalence was 29% among 3121 children (median (IQR) age 36 (25-48) months). Environment contamination was widespread, particularly in rural and peri-urban areas, and was associated with stunting (prevalence ratio 1.30; p=0.008), controlling for sex, age, survey year, setting, mother's education, father's occupation, household food security and wealth. This association was significant for children of all ages (1-5 years) and settings. Lower contamination and higher food security had effects of comparable magnitude. Conclusions Environment contamination can be at least as influential as nutritional components in the pathway to stunting. There is a rationale for including interventions to reduce environment contamination in stunting prevention programmes.",Entailment
i_274,Entailment,"Usage: Verifiable credentials are used in various domains to enhance security, privacy, and efficiency. Here are some notable use cases: Identity Verification: VCs can be used to verify identities in a secure and privacy-preserving manner. For example, in healthcare, VCs can be used to authenticate users and enforce access controls based on verified claims, which may lead to a significant reduction in patient information breaches, although this is not guaranteed .","Protecting patient information's confidentiality is paramount considering the widespread use of Internet of Things (IoT) gadgets in medical settings. This study's subjects are decentralized identifiers (DIDs) and verifiable credentials (VCs) in conjunction with an OAuth-based authorization framework, as they are the key to protecting IoT healthcare devices. DIDs enable autonomous authentication and trust formation between IoT devices and other entities. To authorize users and enforce access controls based on verified claims, VCs offer a secure and adaptable solution. Through the proposed framework, medical facilities can improve the privacy and security of their IoT devices while streamlining access control administration. An Smart pill dispenser in a hospital setting is used to illustrate the advantages of this method. The findings demonstrate the value of DIDs, VCs, and OAuth-based delegation in protecting the IoT devices. Improved processes for authorizing and controlling access to IoT devices are possible thanks to the research findings, which also help ensure patient confidentiality in the healthcare sector.",Entailment
i_1254,Contradiction,"2. Relaxation Techniques: Guided Imagery and Abdominal Breathing: These techniques, used during meditation sessions, can help interns relax and manage stress more effectively .","Purpose for the Program: Quiet Time was developed in this level III neonatal intensive care unit (NICU) as a strategy to reduce stress among the staff. Due to the highly technical nature of this unit and the complexity of the patient population, staff experienced high levels of stress that was exhibited by poor morale, absenteeism, and poor interpersonal relationships in the work environment. To alleviate the effect that this highly stressful environment was having on staff, mindful meditation was introduced as a strategy. The purpose of mindful meditation is to allow the staff to be self‐aware of escalating stress levels and provide techniques for stress reduction that are healing and restorative. This unique and innovative approach provided the outlet the staff needed. Proposed Change: Reduce the stress levels of the NICU staff by using mindful meditation as a unique and innovative strategy and provide the opportunity for Quiet Time to accomplish stress reduction, enhance the bedside care (calm nurse, calm infant), and improve the way nurses handle stressful situations in the unit. Implementation, Outcomes, and Evaluation: In 2009, NICU staff indicated that they were suffering from high‐stress levels that were evidenced by poor morale, absenteeism, and poor interpersonal relationships in the work environment. A program was developed to relieve stress among staff using a holistic approach. Personnel skilled in holistic strategies were identified. Staff members volunteered to spearhead the development of a program that came to be known as Quiet Time. Program leaders had varying degrees of experience and skill in meditation. One leader further developed the necessary skills by becoming a meditation specialist. Quiet Time was structured as 15‐minute sessions, which were repeated immediately back‐to‐back to maximize staff attendance. During the session, lighting was dimmed and aromatherapy, guided imagery, and soft bell sounds were used. Techniques focused on abdominal breathing and respiration control. Progress was monitored by a series of questions about stress levels. Before the session, staff self‐rate their stress level using a Likert scale. This was repeated at the end of the session to gauge the effect meditation had on the participant. Data collected since the inception of the program have shown on average, a 72% reduction in stress levels. Implications for Nursing Practice: Quiet Time for neonatal nurses reduces the stress level of staff exhibited as poor morale, absenteeism, and poor interpersonal relationships in the work environment and, therefore, affects patient care.",Entity error
s_2228,Entailment,"Human Activities and Environmental Factors: Water and Wind Erosion: These natural processes are the primary cause of lead dispersion from contaminated sites to surrounding areas, significantly degrading soil quality .","The Kombat tailings dam, surrounded by agricultural lands, has been exposed to water and wind erosion over a long period of time. The objectives of this research were: (1) to characterize the tailings and the surrounding agricultural soils with respect to the mineral and trace element composition; (2) to determine the degree of soil pollution using soil contamination indicators; (3) to assess the environmental risk of polluted agricultural soil; and (4) to identify dominant type (mechanical and/or chemical) and dominant agent (water and/or wind) of metal dispersion from the tailings. A sequential extraction procedure was used to determine binding mechanisms involved in the retention of metals in tailings and soils under the influence of tailings, which indicate the trace metals bioavailability, the threat to groundwater pollution, as well as the dominant type of dispersion. Among seven analysed elements, copper and lead showed significantly high concentrations in tailings, especially in dry season (up to 9086. mg/kg and 5589. mg/kg, respectively). As a consequence, adjacent arable soils have high concentrations of Cu and Pb (up to 150. mg/kg and 164. mg/kg, respectively). Enrichment factors for lead and copper reveal severe contamination, while geoaccumulation indices disclose moderate to strong contamination by both elements. The combined pollution index points out high contamination. The main binding phase for Cu and Pb is the reducible fraction (oxides, hydroxides, oxyhydroxides). Similar metal distributions in the sequential extraction fractions of tailings and soils support the assumption that wind and water disperse tailings predominantly by mechanical transport to the surrounding agricultural soil. Although agricultural soils are contaminated with Pb and Cu, these metals are relatively strongly bound to the soils and are of medium risk for their mobilisation after The Risk Assessment Code (up to 20% for Cu and up to 36% for Pb). Though rehabilitation of tailings dam, as well as limitation of certain crop use on polluted agricultural land, is recommended. © 2014 Elsevier B.V.",Entailment
s_1502,Entailment,"2.  -  Using soil water tension as a trigger for irrigation can optimize water use. For instance, maintaining soil water tension between 0 to -30 kPa can significantly improve water use efficiency and plant performance .","Improving nutrient use efficiency can be achieved by applying nutrients when uptake efficiency is at its highest level and by avoiding nutrient leaching by rain and by excessive irrigation. Efficient irrigation is a major factor in nutrient use efficiency. A considerable gap exists today between our scientific knowledge on irrigation and its implementation in everyday practice. A new irrigation controller (CommonSensor), developed and tested in practice, was found to implement an Autonomous Threshold Tension Irrigation (ATTI), whereby the plant itself is activating the irrigation, eliminating the need from the farmer to make any (correct or erroneous) decisions regarding when and how much to irrigate. The autonomous irrigation was found to improve irrigation efficiency and water use efficiency. The new battery operated irrigation controller continuously monitors and records the soil water tension, opens a hydraulic irrigation valve at a pre-set soil water tension (0 to -50 kPa) and controls the depth of irrigation by closing the valve at an appropriate time to control depth of irrigation. The continuous record of soil water tension and the irrigation interval recorded can be plotted for immediate inspection and downloaded for further analysis. The success of the controller, which incorporates a combination of hardware, software and method of operation, has been proved in practice and substantiated by scientific measurements (including in grapes) during the last 4 years. Irrigation experiments were carried out in potted soil-less culture of fig grown in a screen house and in a field irrigation experiments with olive. Simultaneous measurements of soil water tension and photosynthesis in grape and fig showed an absolute correlation (r<sup>2</sup> = 0.9384 - 1.000), indicating a direct control of photosynthesis and stomatal conductance by soil water tension. Drainage in potted plants was reduced considerably by irrigation at low soil water tension. Neutron scattering measurements in the olive field experiments showed an integrated water use: initially low volume irrigation by the CommonSensor, until complete depletion of winter soil water and subsequently relying for water consumption solely on the irrigation controller. Neutron scattering measurements showed a complete elimination of drainage in drip irrigation. Elimination of drainage in a heavy yielding 'On' year approximately doubled irrigation efficiency in olive (reduced input by 50%, compared to the recommended rate) when soil water tension was maintained at 0 to -10 kPa. Maintaining soil water tension at 0 to -20 kPa further reduced water use by 75%, indicating a substantial increase in water use efficiency. Olive fruit size was reduced 12% by irrigation at a threshold of -20 kPa, compared to -10 kPa but oil yield increased 6%. Using the CommonSensor irrigation controller, irrigation scheduling and volume of water applied are autonomously regulated by the plant, eliminating errors in irrigation. The autonomous frequency of irrigation by the CommonSensor controller is a function of plant water consumption, the set threshold of soil water tension and the soil water available before the set threshold is reached. The effect of available soil water on the frequency of irrigation is influenced by the irrigation system layout (number of laterals and drippers). Our data and the experience we gained using the new controller indicates that it is almost impossible to predict irrigation needs, even by scientists carrying out all the required measurements, let alone by the farmer using an empirical approach. We found it possible and practical to trigger an autonomous irrigation by the plant. It was found that the autonomous irrigation, using an appropriate technology and method, has a major control on plant performance (growth and potential yield) through maintenance of an accurate and steady threshold of soil water tension.",Entailment
s_824,Contradiction,3. Surface Densification: Optimal Conditions: A compressing temperature of 150 to 160 °C and a closing speed of 10 mm/min are recommended to achieve higher surface hardness without deforming the wood .,"Poplar (Populus tomentosa Carr.) solid wood was surface densified in the tangential direction, and the vertical density profile (VDP) and hardness of the treated and untreated samples were measured. The effects of the process parameters on the VDP and hardness were investigated. To explicitly describe the VDP of the surface densified wood, five indices (AD, ADx, PD, PDi, and DTh) were used. The compressing temperature and closing speed influenced the formation and shape of the VDP. A higher temperature yielded a greater PD and Pdi, and a faster closing speed yielded a higher PD, but smaller PDi and DTh. Increasing the compression ratio increased the AD, ADx, and maximum load, and the poplar wood was compressed in the overall thickness as the compression ratio exceeded a certain degree. The Janka hardness of the poplar wood was significantly improved after surface densification; a higher temperature resulting in a higher surface hardness was explained by the higher PD. The closing speed and compression ratio affected the hardness by impacting the VDP, specifically the PD and DTh indices. When the PD and DTh were greater the surface hardness was greater. By this study, a compressing temperature of 140 to 160 °C and the closing speed of 10 mm/min is recommended, and to prevent the deformation of unheated side of the wood samples and obtain a higher surface hardness, the compression ratio is restricted to 20%.",Numeric error
i_2243,Contradiction,"Conservation efforts for specialists should not prioritize high habitat quality or connectivity, as their specific needs can be met in lower quality environments .","Land-use change has caused degradation, loss and fragmentation of semi-natural habitats, especially in grassland ecosystems. Today, the remaining habitats are often situated in a matrix of intensively used agricultural land and are therefore more or less isolated from each other. Connectivity, area and quality of habitat patches have been identified as the most important drivers for the persistence of grassland specialists living in metapopulations. However, the relative importance of these factors is still under debate. We used a large-scale, multi-taxon approach to obtain a general pattern which would facilitate conservationists to promote many, instead of one, species. We studied the patch occupancy of 13 grassland specialists belonging to three different insect orders within a Central European landscape with 89 fragments of calcareous grasslands. To disentangle the relative importance of the three metapopulation parameters, generalized linear models (GLM) and variation-partitioning techniques were used. Our study revealed that habitat quality was the most important factor determining the occurrence of specialized species, followed by habitat area. In comparison to habitat connectivity, the variance explained by habitat quality was significantly higher across the studied species. Nevertheless, the persistence of at least six model organisms depended on the degree of habitat connectivity. We conclude that maintaining a high habitat quality on large patches should be the first choice for the conservation of habitat specialist insects in fragmented landscapes. As a secondary measure, conservationists should concentrate on the restoration of relict sites. This increases not only the habitat area, but also contributes to better habitat connectivity.",Opposite meaning
s_1176,Unverifiable,Catheterization Procedures for Individuals with Acquired Heart Conditions: Patient Outcomes: Catheterization procedures have contributed to better management and improved quality of life for AHD patients .,"Advances in cardiac surgery and pediatric cardiology have made it possible for most patients with congenital heart and vascular disease to reach adulthood. Surgical techniques can be seen alongside catheter interventions as competitive or complementary therapies. Hybrid procedures help to provide better recovery with reduced need for repeated treatments. Interventional therapies range from closure of shunts and inappropriate vessels, balloon dilatation, and stent implantation to transcatheter valve implantation. In some congenital heart defects, primary therapy currently consists of catheter intervention rather than surgery (e. g., atrial septal defects) in most patients. But also corrected or palliated heart defects can be treated interventionally in order to avoid repeated operations and enhance quality of life. The goal of this article is to provide an overview of the most important interventional techniques that are currently available in this field. © 2012 Springer-Verlag.
[11]: Evaluation and management of congenital heart disease, which is the most common severe congenital anamoly has undergone a rapid change. With the advent of echocardiography and cardiac cathlab techniques, diagnosis and subsequent management are no longer the domain of cardiac surgeons. At present, more than 95% of infants born with significant congenital heart disease are amenable to some form of medical or surgical treatment. Pediatric interventional cardiologists are now using cardiac catheterisation techniques more and more for therapeutic purposes.",Related but unverifiable
i_2385,Entailment,"2. Regenerative and Ecological Practices: In Situ Agrobiodiversity Conservation: This involves retaining local biodiversity through state assistance, marketing of agrobiodiversity products, and community programs, which are often the only means of ensuring agricultural sustainability in marginal systems like those in Nepal, Turkey, and Switzerland .","Applications of in situ agrobiodiversity conservation practices within agricultural production systems have the potential to reduce the risks of agricultural modernisation and enhance sustainable development. The aims and approaches for in situ conservation differ according to the requirements of communities and nations. Approaches to in situ conservation in the decade after the Convention of Biological Diversity are reviewed within the contexts of marginal agricultural systems in Nepal, Turkey and Switzerland. Numerous approaches are currently utilised, including: the informal de facto retention of agrobiodiversity; the provision of state assistance; the marketing of agrobiodiversity products; the use of technological innovations to develop local diversity; the establishment of conservation reserves; community assistance programmes and the raising of awareness of the issue amongst all sectors of societies. Emerging complementary in situ approaches applicable in the rural margins suggest a framework for effectively conserving agrobiodiversity by working with local people.",Entailment
s_1523,Entailment,"Phytate Levels: Processing Effects: Various processing methods, such as pearling, can influence the phytate content in barley. Pearling typically reduces the phytate content as it removes the outer layers of the grain where phytates are concentrated . This suggests that pearl barley flour, which is made from pearled barley, would have lower phytate levels compared to whole barley flour.","Pearling is an effective method for evaluating the distribution of chemical components in wheat grain. Twelve pearling fractions (P<inf>1</inf>-P<inf>12</inf>) of wheat grain were obtained using two rice polishers for 10 cultivars (six soft red wheats and four hard white wheats) grown at two locations with different environmental conditions in Jiangsu Province, China. The results show that the effects of cultivar, location, and pearling on wheat flour phytase activity, phytate, iron, and zinc contents were all significant, with pearling having the greatest effect. All the four components showed a diminishing trend as pearling progressed from the outer layers to the inner part of wheat grain. Generally, the P<inf>2</inf> fraction (the outer 4-8% layer of wheat grain) had the highest phytase activity and phytate and iron contents, whereas the P<inf>1</inf> fraction (the outer 0-4% layer) ranked the highest for zinc content. Growing location had a large influence on grain phytase, phytate, and iron, but the differences between locations decreased as pearling level increased. © 2006 Elsevier Ltd. All rights reserved.
[3]: Wheat contains phenolic compounds concentrated mainly in bran tissues. This study examined the distribution of phenolics and antioxidant activities in wheat fractions derived from pearling and roller milling. Debranning (pearling) of wheat before milling is becoming increasingly accepted by the milling industry as a means of improving wheat roller-milling performance, making it of interest to determine the concentration of ferulic acid at various degrees of pearling. Eight cultivar samples were used, including five genotypes representing four commercial Canadian wheat classes with different intrinsic qualities. Wheat was pearled incrementally to obtain five fractions, each representing an amount of product equivalent to 5% of initial sample weight. Wheat was also roller milled without debranning. Total phenolic content of fractions was determined using the modified Folin-Ciocalteau method for all pearling fractions, and for bran, shorts, bran flour, and first middlings flour from roller milling. Antioxidant activity was determined on phenolic extracts by a method involving the use of the free radical 2,2-diphenyl-1-picrylhydrazyl (DPPH). Total phenolics were concentrated in fractions from the first and second pearlings (>4,000 mg/kg). Wheat fractions from the third and fourth pearlings still contained high phenolic content (>3,000 mg/kg). A similar trend was observed in antioxidant activity of the milled fractions with ≈4,000 mg/kg in bran and shorts, 3,000 mg/kg in bran flour, and <1,000 mg/kg in first middlings flour. Total phenolic content and antioxidant activity were highly correlated (R<sup>2</sup> = 0.94). There were no significant differences between red and white wheat samples. A strong influence of environment (growing location) was indicated. Pearling represents an effective technique to obtain wheat bran fractions enriched in phenolics and antioxidants, thereby maximizing health benefits associated with wheat-based products. © 2005 AACC International, Inc.",Entailment
i_871,Unverifiable,"Backup Support: Employing a backup support during drilling can help in minimizing burr height by providing additional stability to the material, and it is likely that this method could also enhance the overall surface finish of the drilled hole, although this specific effect has not been directly studied in the referenced work .","Drilling a hole usually leaves behind a undesirable burr at the exit work surface. Application of the method suggested by Taguchi is made in this work to minimize drilling burr of an aluminium alloy using HSS drill within the domain of experiments considered. Parameters used are cutting velocity, feed and machining environment. The effect of process variables on burr height is explored, and the optimum condition for minimizing burr height using a back-up support is determined by the analysis. Experimental runs were chosen followingL<inf>27</inf> orthogonal array of Taguchi. Analysis of variance was undertaken to find out the influence of process parameters on the response noted. Predicted values are finally checked for accuracy through a confirmation test. It is found out that back-up support yields much better result than that of normal drilling process. Moderate cutting velocity, low feed and wet condition with water cooling were observed to minimize burr height using a back-up support. Machining environment is found to be the most significant parameter for reducing burr height.",Related but unverifiable
s_478,Entailment,"Economic Sustainability: Industry 4.0: The integration of ML in Industry 4.0, which includes data digitalization and cyber-physical systems, is pushing industries towards more sustainable practices. This shift is expected to enhance economic sustainability by improving efficiency and reducing waste .","One of the most actual and consistent drivers for the industry is sustainability, which includes three main pillars: environment, economics, and society. While numerous methods for environmental and economic sustainability assessment have been proposed, social sustainability assessment is still lacking in structured methods and tools, although human has always played a key role. Moreover, technological development is pushing the industrial world toward a new paradigm, the ""Industry 4.0,"" which embeds topics such as data digitalization, cyber-physical systems, and machine learning. It entails significant changes in human resources management, without reducing their importance. Humans were part of the manufacturing system from the first industrial revolution, and no automation or digitalization can be possible without humans. The industry can no longer underestimate the reasonable application of human factors and ergonomics principles to the workplace. For this purpose, the paper provides a novel transdisciplinary engineering method to measure and promote social sustainability on production sites. It exploits Internet of Things technology to support the (re)design of manufacturing processes and plants toward human-centered connected factories. To improve the workers' well-being has positive effects on their health, satisfaction, and performance. The method has been implemented in a real industrial case study within the footwear industry. The sole finishing process has been analyzed from different perspectives to solve ergonomics-related problems and implement effective improvement strategies.",Entailment
i_1837,Entailment,"Conclusion: While the abstracts do not provide direct evidence on the impact of the frequency of environmental committee meetings, related studies suggest that active and engaged governance, facilitated by frequent meetings, can positively influence environmental performance. This is inferred from the importance of board monitoring, managerial incentives, and proactive environmental management .","The purpose of this paper is to investigate how banks' climate strategies affect environmental performance. To extend this line of research, the carbon disclosure of worldwide banks is examined. In particular, we focus on specific governance strategies: board of director monitoring and managerial incentives. Panel data are employed on a sample taken from 330 bank-year observations in the period after the financial crisis. The results show an increase in environmental performance through the implementation of managerial incentives related to climate change, associated with the highest level of responsibility of the board of directors. Overall, the present study contributes to both the academic literature and corporate governance, highlighting the importance of banks' business strategy on climate change risks and opportunities with respect to environmental performance goals.
[2]: This study gathered and examined empirical evidence concerning the extent to which the performance of cooperatives is related to board composition and interaction patterns – more specifically board size, number of external directors, director tenure and attitudes, frequency of board meetings, education of directors, and degree of consensus between the board and the chief executive officer (CEO). Theories of corporate governance provided propositions that were used as a starting-point for interviews held with board chairmen in thirteen Swedish agricultural cooperatives. The results show that cooperatives benefit from larger boards than suggested by most governance literature. External directors do not improve the overall performance, but having well-educated directors and CEOs who recognize the specificities of cooperative governance are crucial.
[3]: This paper seeks to contribute to the existing business strategy and the environment literature by examining the effect of governance structures on environmental performance within a unique context of improving environmental governance, policies, regulations, and management. Specifically, we investigate the extent to which corporate board gender diversity, including the proportion, age, and level of education of female directors, affects environmental performance of Chinese publicly listed corporations. Using one of the largest Chinese data sets to date, consisting of a sample of 383 listed A‐shares from 2011 to 2015 (i.e., observations of 1,674), our findings are threefold. First, we find that the proportion and age of female directors have a positive effect on the overall corporate environmental performance. Second, our findings indicate that the proportion and age of female directors also have a positive effect on the three individual environmental performance components, namely, environmental (a) strategy, (b) implementation, and (c) disclosure. Finally, and by contrast, we do not find any evidence that suggests that the level of education of female directors has any impact on environmental performance, neither the overall environmental performance measure nor its individual components. Our findings have important implication for regulators and policymakers. Our evidence is robust to controlling for alternative measures, other governance and firm‐level control variables, and possible endogeneities. We interpret our findings within a multitheoretical framework that draws insights from agency, legitimacy, neo‐institutional, resource dependence, stakeholder, and tokenism theoretical perspectives.",Entailment
s_313,Contradiction,"In power grid management, ML-based dynamic programming methods, such as direct heuristic dynamic programming, are believed to enhance system stability by learning from real-time system responses, although their effectiveness in all scenarios remains uncertain .","In modern, large scale interconnected power grids, low-frequency oscillation is a key roadblock to improved power transmission capacity. Supplementary generator control, flexible AC transmission system (FACTS), and high voltage direct currents (HVDC) are engineered devices designed to damp such low frequency swings. In this paper a neural network-based approximate dynamic programming method, namely direct heuristic dynamic programming (direct HDP), is applied to power system stability enhancement. Direct HDP is a learning and approximation based approach to addressing nonlinear system control problems under uncertainty, and it is also a model-free design strategy. The action and critic networks of the direct HDP are implemented using multi-layer perceptrons; learning is carried out based on the interactions between the controller and the power system. For this design approach, real time system responses are provided through wide-area measurement system (WAMS). The controller learning objective is formulated as a reward function that reflects global characteristics of the power system under low frequency oscillation, as well as tight coupling effects among system components. Direct HDP control design is illustrated by case studies, which are also used to demonstrate the learning control performance. The proposed direct HDP learning control is also developed as a new solution to a large scale system coordination problem by using the China Southern Power Grid as a major test bed. Copyright © 2007 International Federation of Automatic Control All Rights Reserved.",Misrepresentation
s_647,Contradiction,Example: The Beijing National Stadium case study was used to verify a risk analysis model .,"Compared with traditional financing mode of construction, public-private-partnership (PPP) mode has the great opportunity that private enterprises develop rapidly and solved the shortcomings that the amount of infrastructure investment is large and governments lack funds. Thus PPP mode is being adapted extensively. The keys to successfully implement PPP mode are effectively identifying and analyzing risks in PPP projects, in order to achieve the risk management of PPP projects. The research is aimed to establish a risk analysis model of PPP projects combining the sensitive analysis and Monte Carlo simulation. Then it uses a real case ""Shijiazhuang International Exhibition Center"" to verify this model and proposes strategies to deal with the main risks. The result of this case study proved effectiveness of the proposed model, which can be used in further risk analysis of PPP projects.",Entity error
s_1208,Contradiction,"Hemolysis and Biocompatibility: Hemolysis Rates: Hemolysis, the destruction of red blood cells, is a critical measure of blood compatibility. Magnetic fluid seals in rotary blood pumps have shown hemolysis rates below 0.3%, indicating good biocompatibility .","Shaft seals for rotary blood pumps have strong demands for low friction, very little leakage, and long-term use. Magnetic fluid seals have attracted attention as promising candidates for this purpose owing to their properties of having zero leakage, no wear, and relatively small viscous friction at the same time. In this study, the sealing performance including the maximum sealing pressure and the sealing durability under blood sealing is discussed. In addition, hemolysis tests for blood sealed by magnetic fluids are performed from the viewpoint of biological compatibility. The magnetic fluid seals are found to have adequate sealing durability and pressure resistance in the blood. In addition, hemolysis of blood sealed with the organic-solvent magnetic fluid seals is maintained below 0.5%.",Numeric error
i_213,Entailment,"Applications and Case Studies: Environmental Monitoring: Techniques for synchronous data acquisition in large-scale test networks improve the accuracy of environmental monitoring, such as oil pipe leakage detection, and may also enhance the detection of other environmental hazards, such as gas leaks or water contamination, through similar methodologies .","Aiming at the requirement of synchronous sampling in large -scale test network that has about thousand test points distributed over some ten kilometers, the data acquisition technique in virtual instrument system was studied. In the system, test network data can be acquired strictly in the same time using synchronous data acquisition board or approximately in the same time only using general-purpose data acquisition board. In subnet, real time system integration bus and star trigger bus are used to accomplish synchronous data acquisition. In whole test network, GPS is used to trigger the synchronous sampling. The accuracy of synchronous sampling is better then 1 μs in large-scale test network. Used in oil pipe leakage detection, the technique presented in this paper improves the accuracy of the leakage point positioning several hundred times.",Entailment
i_599,Entailment,"Prefabricated Housing: Environmental Performance: Prefabricated housing offers significant environmental benefits compared to traditional construction methods. Studies have shown that prefabrication can reduce energy consumption by 25.49%, resource depletion by 35.82%, and health damage by 6.61% . These advantages make prefabricated housing a viable option for eco-friendly rebuilding.","Prefabrication technology has been heavily promoted by the Chinese government due to its potential to improve construction quality and productivity. However, there is an urgent need to assess the environmental performance of prefabrication technology to identify whether it is an effective method that is conducive to sustainable development. This study considered two typical residential projects using the two technologies to conduct a fair comparison between prefabrication technology and cast-in-situ technology. Various measuring methods, including content analysis, face-to-face interviews and on-site measurements, were used for data collection. Environmental impact (EI) categories selected for the study included resource depletion, energy consumption and construction waste discharge. Two life cycle assessment (LCA)-based models, the construction environmental performance assessment system (CEPAS) and the building health impact assessment system (BHIAS), were integrated to measure the EI of the two construction technologies based on three damage categories, namely, ecosystem damage, resource depletion and health damage. Finally, social willingness to pay (WTP) was applied to integrate the damage categories for comparisons. The results indicated that the sample prefabricated residential building (PRB) construction was more efficient in energy use, with a 20.49% reduction in total consumption compared to the sample traditional residential building (TRB) construction. The use of prefabrication demonstrated a certain degree of advantages in EI, including a 35.82% reduction in resource depletion, a 6.61% reduction in health damage and a 3.47% reduction in ecosystem damage. Prefabrication technology was more environmentally friendly because of its advantages in reducing damage to the environment compared with traditional cast-in-situ construction technology.",Entailment
s_623,Unverifiable,"###  ** Optimization and Decision Support Systems** Cost-Effective Maintenance: AI-based decision support systems (DSS) have been developed to optimize maintenance schedules and predict future conditions of infrastructures. These systems integrate various factors, including cost models and political constraints, to recommend optimal maintenance actions .","[5] Performance degradation of reinforced concrete (RC) bridge decks is one of the most serious problems in highway structures. Therefore, in order to secure safety and extend the service life, an efficient inspection and maintenance system is urgently demanded. In this paper, Cox regression survival analysis and fatigue life analysis are discussed. The first one is a statistical method which can quantitatively analyze the risk of each deterioration factor for RC decks. The other one, which utilizes multi-scale simulation and artificial intelligence, has the advantage to estimate residual life of RC decks quickly by considering bottom-surface crack patterns. Result of two methods are compared and it is found that they have a fairly high correlation. Although the reliability of the two methods is confirmed, their results are directly applied to establish a new inspection system. Then by comparing the fatigue life of dry and water-submerged conditions, the importance of water- proofing is highlighted. Additionally, impact of non-uniform stagnant water of RC slab is investigated, where it provides an analysis that is close to the actual situation by the utilization of non-destructive testing. Finally, a comprehensive maintenance system that can determine the priority of inspection is proposed to ensure a rational decision-making.",Related but unverifiable
s_1872,Contradiction,"Key Techniques for Increasing UHI in Tropical Regions: Implementing green roofs and surface vegetation can exacerbate UHI. In high-density urban areas, green roofs can contribute to undesirable nightly warming effects that surface vegetation might alleviate .","The growing rate of urbanization and alterations in natural land-use/land-cover properties cause many worldwide environmental issues such as Urban Heat Island (UHI), low Thermal Comfort Level (TCL) and air pollution in megacities. Development of urban green spaces is one of the most proposed measures for mitigation of UHI and improvement of thermal comfort satisfaction which causes lower cooling energy consumption and indirectly improves the urban air quality. Therefore, the efficiency of realistic and executable green scenarios in both surface and roof levels (surface vegetation, green roof, surface vegetation + green roof) on early summertime UHI and TCL are evaluated and compared in Tehran Metropolis, using coupled Weather Research and Forecasting model with Single Layer Urban Canopy Model (WRF/SLUCM). Model predefined urban parameters (the urban density and vegetation fraction) are modified before the main simulations by data of remote-sensing methods which let us define surface green spaces developmental scenarios without any change in the basic urban morphology. Results are presented for three areas with different urban morphologies (Low and High-Intensity Residential (LR and HR) and Commercial and Industrial (C/I)). Three indexes (THI, ETI and RSI) are calculated for assessing TCL variations. Generally, results show that environmental operations of selected scenarios are different over selected areas. In LR area, diurnal cooling (up to −0.86 °C in green roof approach) and improvement in thermal comfort condition are observed in all scenarios. On the other hand, in HR and C/I areas, the daytime cooling (nighttime warming) effect up to −0.85 °C (up to +0.63 °C) in the third scenario are simulated. TCL alterations show similar deteriorating nightly effects in all scenarios in selected regions. Averaged diurnal decrease in wind speed is another undesirable impact of green development scenarios due to the enhanced surface roughness that can reduce urban natural heat and pollution ventilations. Current results clarify that the adoption of efficient urban green spaces programs needs to consider different environmental concerns. By comparison between roof level and surface greenery, it can be concluded that the green roof approach with the least undesirable nightly effects is a more efficient approach than surface vegetation development in high-density Tehran megacity.",Opposite meaning
s_1655,Entailment,"Integrated and Sustainable Practices: Polyculture Systems: In Israel, polyculture systems combining species like tilapia, carp, and mullet have been optimized to increase yield per unit area, suggesting that these practices could completely eliminate the challenges posed by limited water resources. This approach has led to remarkable increases in fish production .","Israel is located in a semiarid zone without major rivers or underground freshwater sources. In spite of the climatic constraints and water shortages, freshwater aquaculture is highly developed as an entrepreneurial activity that combines the ecological principles of the Chinese polyculture system with technologies and objectives of industrial fish production systems.Within this context, tilapia co-culture with one or more fish species is practiced in fishponds and water reservoirs in the northern part of the country. Fish farming on a commercial scale started in 1939 with common carp (Cyprinus carpio) monoculture. The end of the 1950s started the transition to polyculture, with the addition of grey mullet (Mugil cephalus) and endemic tilapia (Oreochromis aureus and Tilapia zillii) into the carp ponds. Around 1970, when it was found that hybridization between Oreochromis niloticus females and O. aureus males resulted in tilapia with over 90% males, the uncontrolled spawning problem with tilapia was largely solved leading to increased size of the fish at marketing. Since then that hybrid has been the main tilapia cultured in Israel. Its growout is practiced in monoculture in earthen ponds and in co-culture with common carp and/or mullet in earthen ponds and reservoirs. Sometimes, the exotic predatory red drum (Sciaenops ocellatus) is stocked to restrain uncontrolled tilapia spawning. During over 70 years of aquaculture in Israel, fish production steadily increased while the available land for fish ponds decreased, reflecting an increase in the yield per unit area. Nowadays, tilapia constitute 40-45% and common carp around 30% of the almost 18,000 metric tons (mt) of the pond fish annually marketed in the country. Israeli farmers are highly innovative and eager to try new methods and technologies, characteristics that allowed starting fish culture in a water-limited country and foster its development. Strong cooperation between researchers and fish growers allow the efficient dissemination and quick application in the farms of the generated knowledge, as herein presented for tilapia co-culture.",Entailment
s_809,Contradiction,"Recovery: The ability to quickly return to a functional state after a disruption, which may also enhance the long-term adaptability of ecosystems to future changes .","The term 'resilience' was first introduced by the Canadian ecologist C. S. Holling in order to emphasize two contrasting views of stability for ecological systems, namely, between efficiency and persistence or between constancy and change. The first definition of resilience is the rate at which a system returns to a single state after a perturbation. The definition assumes certain local stability properties of the state. Ecological systems being dynamic and often transient can shift from one stability domain to another, and this transition property characterizes resilience. In that manner, a second definition introduces resilience as the amount of change or disturbance required for a major shift from one stability domain to another. The first definition is characterized by control, predictability, and efficiency, in view of optimality in ecosystem functioning. The second definition focuses more on prediction, adaptability, and variability - attributes pertaining more to the evolutionary perspective. These contrasting views of ecological resilience can yield different results in understanding and managing ecological complexity. The issue of sustainability is more relevant to the first definition of ecological resilience, because of the interacting nature between man and the environment from the viewpoint of human development in a globally changing environment. On the other hand, focus on engineering resilience moves the argument of sustainability to controlling, offering predictable results as long as we experience the stability domain. The notion of resilience differs significantly from that of resistance in ecological theory. The latter is defined as the ability of the system to remain intact while external conditions change, whereas the former refers to the ability of the system to recover after it has changed. In that sense, fully functioning ecosystems are expected to be both resistant to change and resilient or able to self-recover from external disturbances, thereby maintaining stability.",Misrepresentation
i_460,Contradiction,"2. Accessibility: Inclusive Voting: There is a lack of enhanced accessibility for disabled voters, as multimodal interfaces are not effectively implemented .","In recent years, electronic voting has become a very popular and topical topic. Electronic voting technology can speed up ballot counting and provide accessibility for voters with disabilities. Electronic voting can also facilitate electoral fraud, especially given the risks associated with remote voting. Building a secure electronic voting system that offers the fairness and privacy of current voting schemes, while providing the transparency and flexibility offered by electronic systems has been a challenge for a long time. In this work-in-progress paper, we evaluate an application of blockchain as a service to implement distributed electronic voting systems. The paper proposes a novel electronic voting system based on blockchain that addresses some of the limitations in existing systems and evaluates some of the popular blockchain frameworks for the purpose of constructing a blockchain-based e-voting system. In particular, we evaluate the potential of distributed ledger technologies through the description of a case study; namely, the process of an election, and the implementation of a blockchainbased application, which improves the security and decreases the cost of hosting a nationwide election.
[5]: Since the inception of elections and election technologies, all segments of the voting population have never been granted equal access, privacy and security to voting. Modern electronic voting systems have made attempts to include disabled voters but have fallen short. Using recent developments in technology a secure, user centered, multimodal electronic voting system has been developed to study a multimodal approach for providing equity in access, privacy and security in electronic voting. This article will report findings from a study at the Alabama Institute for the Deaf and Blind where more than thirty-five blind or visually impaired participants used the multimodal voting system. The findings suggest that the proposed multimodal approach to voting is easy to use and trustworthy. © 2010 Springer-Verlag.",Missing information
s_1548,Entailment,Comparison with Probiotics: Safety: Paraprobiotics eliminate the risk of introducing live bacteria that could potentially become pathogenic under certain conditions .,"The present study evaluated the growth performance, non-specific immunity and disease resistance in Penaeus vannamei fed diets supplemented with live or dead cells of Clostridium butyricum CBG01 (live cells, CB; sonication-killed cell-free extracts, UI; heat-killed whole-cell, HI; fermentation supernatant, FS; the control, the basal diet without C. butyricum, DZ) for 42 days. Results indicated that the final weight, specific growth rate, survival rate and feed efficiency rate of shrimp in the treatment groups were significantly improved versus the control (P < 0.05). The challenge test of Vibrio parahaemolyticus showed that the cumulative mortalities of shrimp in the CB and UI groups were significantly lower than that in the control (P < 0.05). Compared with the control, alkaline phosphatase, acid phosphatase, total nitric oxide synthase, lysozyme, peroxidase, superoxide dismutase activities, total antioxidant capacity, and phenonoloxidase content in the serum and the relative expression levels of SOD, LZM, proPO, LGBP, HSP70, Imd, Toll, Relish, TOR, 4E-BP, eIF4E1α, eIF4E2 genes in the hepatopancreas of CB and HI shrimp groups were all significantly enhanced, and those were significantly improved in the UI group as well, except for phenonoloxidase content, relative expression levels of SOD, Imd and eIF4E2 genes (P < 0.05). However, immune responses were induced partially in the FS shrimp group. These results suggested that dietary both live and dead cells of C. butyricum CBG01 could improve the growth performance and immune responses of shrimp. When resistance against Vibrio parahaemolyticus in shrimp is considered, sonication-killed cell-free extracts of C. butyricum showed a better effect than heat-killed whole-cells of probiotic. Considering collectively the above, sonication-killed cell-free extracts of C. butyricum could be applied as a potential paraprobiotic to enhance the growth performance, immunity capacity and disease resistance of P. vannamei.",Entailment
i_878,Contradiction,"###  ** Mechanisms of Electropolishing** -  ** Bubble Shielding Effect (BSE) ** : Gas bubbles formed during the process do not shield any areas of the surface, resulting in uniform dissolution and preventing the formation of raised areas .","As a popular application of electrochemical anodic dissolution, electropolishing is extensively adopted in the surface finishing industries of metals. Anodic dissolution is a complex reaction with many process parameters and chemical properties involved. A simple explanation of the mechanism of morphology formation during the EP reaction is still lacking. This study examines the morphology formation of stainless steel 304 at the same location on the specimen as the process evolves. Based on these observations, the basic mechanisms of morphology formation in EP process are proposed. The bubble shielding effect (BSE) and the broken bubble tunnelling effect (BBTE) explain the raised and dented morphologies, respectively. The broken bubble tunnelling effect (BBTE) explains the formation mechanism of pitting holes and the bubbleshielding effect (BSE) explains the limitation of surface roughness of electropolishing process. Simulation results are consistent with the observed morphology formation phenomena. © 2012 by ESG.",Opposite meaning
s_1330,Unverifiable,"Key Points: Environmental and Activity Influences: The pH of sweat can be influenced by the type of physical activity and environmental conditions. For instance, the pH of sweat may vary during different types of exercise or in response to different levels of hydration and electrolyte balance .","The purpose of this study was to expand our previously published sweat normative data/analysis (n = 506) to establish sport-specific normative data for whole-body sweating rate (WBSR), sweat [Na<sup>+</sup>], and rate of sweat Na<sup>+</sup> loss (RSSL). Data from 1303 athletes were compiled from observational testing (2000–2017) using a standardized absorbent sweat patch technique to determine local sweat [Na<sup>+</sup>] and normalized to whole-body sweat [Na<sup>+</sup>]. WBSR was determined from change in exercise body mass, corrected for food/fluid intake and urine/stool loss. RSSL was the product of sweat [Na<sup>+</sup>] and WBSR. There were significant differences between sports for WBSR, with highest losses in American football (1.51 ± 0.70 L/h), then endurance (1.28 ± 0.57 L/h), followed by basketball (0.95 ± 0.42 L/h), soccer (0.94 ± 0.38 L/h) and baseball (0.83 ± 0.34 L/h). For RSSL, American football (55.9 ± 36.8 mmol/h) and endurance (51.7 ± 27.8 mmol/h) were greater than soccer (34.6 ± 19.2 mmol/h), basketball (34.5 ± 21.2 mmol/h), and baseball (27.2 ± 14.7 mmol/h). After ANCOVA, significant between-sport differences in adjusted means for WBSR and RSSL remained. In summary, due to the significant sport-specific variation in WBSR and RSSL, American football and endurance have the greatest need for deliberate hydration strategies. Abbreviations: WBSR: whole body sweating rate; SR: sweating rate; Na<sup>+</sup>: sodium; RSSL: rate of sweat sodium loss.
[9]: New Findings: What is the central question of this study? Non-thermal factors (e.g. muscle metaboreflex) contribute to the sweating response during exercise. Although it is well recognized that the sweating responses caused by core temperature elevation in prepubertal children and the elderly are attenuated compared with young adults, it is unknown whether non-thermal sweating is also attenuated in these populations. What is the main finding and its importance? The non-thermal sweating response during isometric hand-grip exercise and isolated muscle metaboreflex were attenuated in prepubertal children compared with young adults in a non-uniform manner over the body, but only during the muscle metaboreflex in the elderly. This may explain the maturation- and ageing-related decline of sweating during exercise. The purpose of the present study was to investigate sweating responses to isometric hand-grip (IH) exercise and muscle metaboreflex in prepubertal children and the elderly. In hot conditions (ambient temperature, 35°C; relative humidity, 45%), 13 healthy young adults, 10 prepubertal children and 10 elderly subjects (aged 20.4 ± 1.2, 11.4 ± 0.5 and 63.5 ± 3.1 years, respectively) repeated a three hand-grip exercise protocol that consisted of 1 min IH exercise at 15, 30 or 45% of maximal voluntary contraction (MVC) followed by 2 min postexercise forearm occlusion. Local sweat rates (SRs) on the forehead, chest, forearm, thigh and palm were continuously measured (ventilated capsule method). The forehead SR in prepubertal children during IH exercise at 45% MVC was significantly lower than that of young adults (0.26 ± 0.22 and 0.08 ± 0.15 mg cm<sup>−2</sup> min<sup>−1</sup> for young adults and children, respectively; P < 0.05) but not of the elderly at any exercise intensities. The SR on the chest (0.22 ± 0.22 and −0.01 ± 0.05 mg cm<sup>−2</sup> min<sup>−1</sup> for young adults and children, respectively), forearm (0.14 ± 0.12 and 0.03 ± 0.04 mg cm<sup>−2</sup> min<sup>−1</sup>) and thigh (0.13 ± 0.10 and 0.02 ± 0.03 mg cm<sup>−2</sup> min<sup>−1</sup>) during postexercise occlusion at 45% MVC was significantly lower in children than in young adults (P < 0.05). Elderly subjects showed a significantly lower SR on the forearm (0.04 ± 0.04 and 0.01 ± 0.02 mg cm<sup>−2</sup> min<sup>−1</sup> for young adults and elderly, respectively) and thigh (0.07 ± 0.07 and 0.01 ± 0.03 mg cm<sup>−2</sup> min<sup>−1</sup>) at 15% MVC and on the thigh at 45% MVC (0.13 ± 0.10 and 0.04 ± 0.04 mg cm<sup>−2</sup> min<sup>−1</sup>) during postexercise occlusion compared with young adults (P < 0.05). These results suggest that sweating responses to IH exercise and muscle metaboreflex were underdeveloped in prepubertal children and that ageing attenuates the response to the muscle metaboreflex in a way that is not consistent across the body.",Related but unverifiable
i_645,Entailment,"Advantages: Versatility: Handheld scanners can be used for various applications, including cultural heritage digitization, forensic pathology, and wood defect detection .","Handheld 3D scanners can be used to complete large scale models with the acquisition of occluded areas or small artefacts. This may be of interest for digitization projects in the field of Cultural Heritage, where detailed areas may require a specific treatment. Such sensors present the advantage of being easily portable in the field, and easily usable even without particular knowledge. In this paper, the Freestyle3D handheld scanner launched on the market in 2015 by FARO is investigated. Different experiments are described, covering various topics such as the influence of range or color on the measurements, but also the precision achieved for geometrical primitive digitization. These laboratory experiments are completed by acquisitions performed on engraved and sculpted stone blocks. This practical case study is useful to investigate which acquisition protocol seems to be the more adapted and leads to precise results. The produced point clouds will be compared to photogrammetric surveys for the purpose of their accuracy assessment.
[3]: Background: Two 3D surface scanners using collimated light patterns were evaluated in a new application domain: to document details of surfaces similar to the ones encountered in forensic skin pathology. Since these scanners have not been specifically designed for forensic skin pathology, we tested their performance under practical constraints in an application domain that is to be considered new. Methods: Two solid benchmark objects containing relevant features were used to compare two 3D surface scanners: the ATOS-II (GOM, Germany) and the QTSculptor (Polygon Technology, Germany). Both scanners were used to capture and process data within a limited amount of time, whereas point-and-click editing was not allowed. We conducted (a) a qualitative appreciation of setup, handling and resulting 3D data, (b) an experimental subjective evaluation of matching 3D data versus photos of benchmark object regions by a number of 12 judges who were forced to state their preference for either of the two scanners, and (c) a quantitative characterization of both 3D data sets comparing 220 single surface areas with the real benchmark objects in order to determine the recognition rate's possible dependency on feature size and geometry. Results: The QTSculptor generated significantly better 3D data in both qualitative tests (a, b) that we had conducted, possibly because of a higher lateral point resolution; statistical evaluation (c) showed that the QTSculptor-generated data allowed the discrimination of features as little as 0.3 mm, whereas ATOS-II-generated data allowed for discrimination of features sized not smaller than 1.2 mm. Conclusion: It is particularly important to conduct specific benchmark tests if devices are brought into new application domains they were not specifically designed for; using a realistic test featuring forensic skin pathology features, QT Sculptor-generated data quantitatively exceeded manufacturer's specifications, whereas ATOS-II-generated data was within the limits of the manufacturer's specifications. When designing practically constrained specific tests, benchmark objects should be designed to contain features relevant for the application domain. As costs for 3D scanner hardware, software and data analysis can be hundred times as high compared to high-resolution digital photography equipment, independent user driven evaluation of such systems is paramount. © 2007 Schweitzer et al; licensee BioMed Central Ltd.
[4]: Wood quality detection is a key issue in the wood manufacture factory or wood trade process. It consists of wood species recognition, wood physical parameter (such as density, hardness, water ratio, degree of surface roughness) prediction and wood defect detection, which are intimately connected with the efficient wood utilizations and wood prices. In the wood defect detection, the internal and external defects were inspected and processed with different schemes. It was an important way for effective wood grading and wood utilization to make the wood defect detection. In this paper, a detection and quantification scheme of wood defect was proposed based on three-dimensional (3D) laser scanning point cloud. This scheme could be used in the wood external defect detection such as cavity or tunnel. First, the Artec 3D Scanner was used to scan the wood surface to get the 3D point cloud. After preprocessing, the Z-axis coordinate value of current point was compared with the set threshold to judge whether it was a defect point. Second, a deep preferred search algorithm was used to classify the retained defect points marked with different colors. After this step, the segmented defects could be viewed with the Artec Cyclone software. Last, the integration algorithm was used to calculate the surface area and volume of every defect. In this step, every defect point was extended into a regular hexagon and a prism for the subsequent area and volume calculation by using the standard mathematical equations. The overall area or volume of every defect was computed by summarizing every defect point's area or volume. One detection system was realized with Visual C++ programming tool, the Artec 3D Scanner and a laptop. The simulation experimental results indicated that our scheme could accurately measure the surface areas and volumes of cavity or tunnel on wood surface with measurement error of 5%, if the defect's depth was less than 3 mm. This scheme could give the quantitative proofs for the subsequent wood grading and wood price. In fact, every 3D data point's format was (X, Y, Z, R, G, B, S), in which the R, G, B and S represented the red, green, blue and reflection information, respectively. Therefore, we could use the R, G and B information to perform the color classification for the wood surface by use of color moments or fuzzy classification algorithms. However, the wood defect points should be deleted in color classification in order to overcome the disturbance from wood surface's defect points. Fortunately, the deletion of defect points could be easily performed by use of our scheme, which was the advantage of our scheme compared to other wood parameter detection methods. Moreover, the used Artec Scanner was portable with small mass and volume (i.e. with a standard mass of 0.85 kg, a 3D scanning resolution of 0.5 mm, a size of 261 mm×158 mm×64 mm, and multiple data storage formats), so it could form a portable wood defect detection system with a laptop. In the future, with the development of 3D scanning instrumentation, the used 3D scanner can become more accurate with cheaper price, so our scheme may be conveniently used in wood manufacture factory or wood trade.",Entailment
s_1583,Unverifiable,"5. Economic and Social Impact: Food technology is the primary driver of economic progress in countries, as it alone can effectively develop food and allied industries to resolve issues like malnutrition and poverty .","South Africa's scientific research organization - Council for Scientific and Industrial Research (CSIR), is engaged in scientific and technological research in food science to address key national issues of malnutrition and poverty. Food Science and technology plays an important role in economic progress of a country through the development of food and allied industries. CSIR has integrated food science and technology research into 'Biosciences' area, where biochemists and food scientists can work together to develop technology platforms.",Related but unverifiable
s_650,Unverifiable,Data Analysis Strategies: Risk Analysis Models: Developing and applying risk analysis models such as decision tree analysis and sensitivity analysis can help in quantifying and understanding risks .,"Compared with traditional financing mode of construction, public-private-partnership (PPP) mode has the great opportunity that private enterprises develop rapidly and solved the shortcomings that the amount of infrastructure investment is large and governments lack funds. Thus PPP mode is being adapted extensively. The keys to successfully implement PPP mode are effectively identifying and analyzing risks in PPP projects, in order to achieve the risk management of PPP projects. The research is aimed to establish a risk analysis model of PPP projects combining the sensitive analysis and Monte Carlo simulation. Then it uses a real case ""Shijiazhuang International Exhibition Center"" to verify this model and proposes strategies to deal with the main risks. The result of this case study proved effectiveness of the proposed model, which can be used in further risk analysis of PPP projects.",Related but unverifiable
s_1664,Entailment,"Root and Shoot Development: Trichoderma spp. enhance root and shoot development, leading to better nutrient uptake and overall plant vigor. This is partly due to the production of plant growth-promoting hormones like indole acetic acid (IAA), and it is believed that the application of Trichoderma could also improve the resilience of plants to environmental stressors, although this has not been directly studied .","Aims: Many Trichoderma species are well-known by their ability to promote plant growth and health. However, few studies have been conducted to improve their ability. Laboratory and greenhouse experiments compared the promotion of cucumber growth by the putative mutant Trichoderma harzianum T-E5 versus the wild-type SQR-T037 and bio-organic fertilizers fortified with them. Methods: The putative mutant T-E5 was selected based on plant hormone production in liquid fermentation and then on the effects of T-E5 and SQR-T037 to promote plant growth and colonization of plant roots and rhizosphere soil of cucumber. Results: High-performance liquid chromatography analysis showed that indole acetic acid (IAA) production by T-E5 was enhanced by 30.2 % as compared with SQR-T037. T-E5 treatment statistically increased cucumber plant biomass in soil and hydroponic experiments. Based on TaqMan reverse transcriptase-polymerase chain reaction, the population of T-E5 was almost ten times higher than SQR-T037 in the soil samples at 30 days. The endophytic colonization of roots and stems by the two strains had the same dynamic tendency, but T-E5 was much greater than SQR-T037 at any sampling time. Conclusions: The putative mutant T-E5 enhanced the production of IAA and plant colonization ability, and this improvement had a great potential for further application of T-E5 in crop production. © 2012 Springer Science+Business Media Dordrecht.
[8]: Trichoderma is a beneficial fungus that can be used in both the control of phytopathogens and in promoting germination and plant growth. Thus, this study aimed to evaluate the effect of five Trichoderma isolates (T09, T12, T52, Tc and Tce) in seven different application modes on seeds and seedlings of the Khaya ivorensis A. Chev. (African mahogany). Fungi applications were tested by microbiolization of the seeds, in the pre-planting substrate, by monthly applications in the seedlings and in four combinations of these three treatments. Under laboratory conditions, the germination, germination speed index (GSI), and radicle and hypocotyl lengths were evaluated in seeds, treated and untreated, with Trichoderma. In the nursery, it was evaluated the height, root collar diameter, number of leaflets, root length, and the dry weight of root system and aerial part in seedlings with different forms of Trichoderma application. Trichoderma isolates did not influence germination percentage, GSI and radicle length. The fungus application methods in the K. ivorensis seedlings increased the height and leaflets number of the plants by at least one of the Trichoderma isolates tested in this study.
[9]: Fungi belonging to the genus Trichoderma are among the most active and ecologically successful microbes found in natural environments, because they are able to use a variety of substrates and affect the growth of other microbes and virtually any plant species. We isolated and characterized a novel type II hydrophobin secreted by the biocontrol strain MK1 of Trichoderma longibrachiatum. The corresponding gene (Hytlo1) has a multiple role in the Trichoderma-plant-pathogen three-way interaction, while the purified protein displayed a direct antifungal as well as a microbe-associated molecular pattern and a plant growth promotion (PGP) activity. Leaf infiltration with the hydrophobin systemically increased resistance to pathogens and activated defense-related responses involving reactive oxygen species, superoxide dismutase, oxylipin, phytoalexin, and pathogenesis-related protein formation or activity. The hydrophobin was found to enhance development of a variety of plants when applied at very low doses. It particularly stimulated root formation and growth, as demonstrated also by transient expression of the encoding gene in tobacco and tomato. Targeted knock-out of Hytlo1 significantly reduced both antagonistic and PGP effect of the wild-type strain. We conclude that this protein represents a clear example of a molecular factor developed by Trichoderma spp. to establish a mutually beneficial interaction with the colonized plant.",Entailment
i_2326,Contradiction,"Another study noted that broilers fed with a probiotic product containing Lactobacillus acidophilus showed no significant difference in feed intake compared to control groups, but did exhibit improved weight gain and feed efficiency over time .","The objective of the present study was to evaluate the influence of a probiotic product (composition: Lactobacillus acidophillus (3.5 × 10 <sup>11</sup> CFU), Streptcoccus faecium (3.5 × 10 <sup>11</sup> CFU) and Bifidobacterium bifidum (3.5 × 10 <sup>11</sup> CFU)) on broiler performance. A total of 1200 one-day-old broilers were reared until 42 days of age, and distributed in a completely randomized experimental design with 3 treatments (antibiotic, probiotic and control) with 10 replicates of 40 birds each. Weight gain, feed intake, feed conversion ratio and mortality were evaluated. Concerning weight gain, in the periods of 0-7 and 0-14 days of age, the group fed the antibiotic product presented higher values as compared with the other treatments. However, in the periods of 0-21, 0-28 and 0-35 days of age, birds fed the antibiotic presented higher weight gain only in relation to the control group. Feed intake differences were detected only in the initial period of 0-7 days of age, with the group fed the antibiotic product presenting higher feed intake as compared with that fed the probiotic product, although these groups were not different from the control group. No statistical difference was detected in feed conversion ratio among treatments in any of the evaluated age intervals. Mortality was different only in the period of 0-14 days of age, which was higher in the control group as compared with that of the birds fed the probiotic product, but it was not different from the group receiving the antibiotic. Treatment with probiotic product containing Lactobacillus acidophillus, Streptococcus faecium and Bifidobacterium bifidum does not affect broiler performance. © 2011 Sociedade Brasileira de Zootecnia.",Misrepresentation
i_2387,Contradiction,"3. Technological and Participatory Approaches: Participatory Life Cycle Assessment (LCA): Combining LCA with participatory approaches complicates sustainability assessments, making them less relevant and actionable for stakeholders .","To ensure agricultural land in rural territories is managed sustainability, environmental assessments need to be undertaken to support both policy-makers and local stakeholders in their decision making. Thanks to its completeness, life cycle assessment (LCA) is one of the most widely used tools for the evaluation of environmental impacts. However, LCA is difficult to apply in rural areas of developing countries. First, it requires a lot of data that are difficult to collect due to the diversity of small farming systems. Second, LCA results are difficult for non-specialists to interpret due to the complexity of its multiple indicators. Third, the processes considered in LCA often do not match the values and interests of the stakeholders. The aim of this paper is to propose an innovative operational framework that couples LCA and a participatory approach to overcome these issues. The first step was to conduct a progressive participatory diagnosis of the socio-ecological structure of the rural territory and to characterise the main cropping systems. The results of the diagnosis and other data were progressively triangulated, validated and consolidated with the stakeholders at the territorial level. The paper discusses the quality and validity of data obtained using a participatory approach. To improve the appropriation of results by stakeholders, the LCA method was applied using a territorial approach to distinguish on-site and off-site activities as well as global and local impacts. The applicability of the framework was tested on a case study in a semi-arid region in central Tunisia.",Opposite meaning
s_959,Entailment,"Iris Pigment Dispersion: The release of dispersed pigments from the iris into the aqueous humor is a noted ocular side effect of systemic fluoroquinolones like moxifloxacin. This pigment release is linked to the toxicity of these drugs to iris melanocytes, which can be measured by the activity of the enzyme tyrosinase (TYR) in the aqueous humor .","Antibiotics such as fluoroquinolones (FQLs) are commonly used to treat ocular infections but are also known to cause dermal melanocyte toxicity. The release of dispersed pigments from the iris into the aqueous humor has been considered a possible ocular side effect of the systemic administration of FQLs such as Moxifloxacin, and this condition is known as bilateral acute iris transillumination (BAIT). Bilateral acute depigmentation of iris (BADI) is a similar condition, with iris pigment released into the aqueous, but it has not been reported as a side effect of FQL. Iris pigments are synthesized by the melanogenic enzyme tyrosinase (TYR) and can be detected but not quantified by using slit-lamp biomicroscopy. The correlation between dispersed pigments in the aqueous and the extent of melanocyte toxicity due to topical antibiotics in vivo is not well studied. Here, we aimed to study the effect of topical FQLs on iris tissue, the pigment release in the aqueous humor and the development of clinically evident iris atrophic changes. We evaluated this process by measuring the activity of TYR in the aqueous humor of 82 healthy eyes undergoing cataract surgery following topical application of FQLs such as Moxifloxacin (27 eyes, preservative-free) or Ciprofloxacin (29 eyes, with preservative) or the application of non-FQL Tobramycin (26 eyes, with preservative) as a control. In addition, the patients were questioned and examined for ocular side effects in pre- and post-operative periods. Our data showed a significantly higher mean TYR activity in the aqueous humor of Ciprofloxacin-treated eyes compared to Moxifloxacin- (preservative free, p < 0.0001) or Tobramycin-treated eyes (p < 0.0001), which indicated that few quinolones under certain conditions are toxic to the iris melanocytes. However, the reduced TYR activity in the aqueous of Moxifloxacin-treated eyes was possibly due to the presence of a higher drug concentration, which inhibits TYR activity. Consistently, immunoblotting analysis of the aqueous humor from both Ciprofloxacin- and Moxifloxacin-treated eyes showed the presence of soluble TYR enzyme, thus reflecting its toxicity to iris melanocytes and corresponding to its activity in the aqueous humor. Intriguingly, none of these patients developed any clinically appreciable ocular side effects characteristic of BAIT or BADI. Overall, our results suggest that topical antibiotics cause different levels of iris melanocyte toxicity, releasing dispersed pigments into the aqueous humor, which can be measured through TYR enzyme activity. Hence, we conclude that topical FQLs may cause subclinical toxicity to the iris melanocytes but may not be the sole cause of the development of BAIT or BADI.",Entailment
i_1516,Entailment,Hydrocele: This condition involves the accumulation of fluid around the testicle and is not associated with neural tube defects .,"Background: Varicocele is a common urologic anomaly in adolescent males; however, evidence-based treatment guidelines do not exist. Hydroceles are known to be a common complication after surgical therapy, with a wide variation in the reported incidence between 1 and 40%. Aim: This study aimed to introduce a standardized indication-to-treat protocol and prove its efficacy by analyzing the outcome of patients. Secondly, it aimed to better define postoperative hydroceles because the wide variation of reported incidence is attributed to a lack of definition. Methods: Our standardized treatment protocol included an initial assessment with clinical grading of varicoceles, ultrasound evaluation of testicular volume, and calculation of the atrophy index. Indications for surgical treatment were testicular volume asymmetry >20%, discomfort and pain, or bilateral varicocele. The Palomo procedure (laparoscopically since 2005) was the standard procedure. Postoperative hydroceles were graded according to clinical findings and symptoms: Grade I, sonographic chance finding without clinical correlate; Grade II, palpable but clinically insignificant; Grade III, symptomatic. All patients treated according to the defined protocol were prospectively monitored between January 2001 and December 2015. Results: A total of 129 patients with left varicocele were referred to our institution; 70 fulfilled the indication criteria for surgical treatment. Twenty-eight of these patients were treated for volume asymmetry, 26 of these showed catch-up growth. Forty-two patients were treated for discomfort and pain; the symptoms subsided in all of them. Postoperative hydroceles were detected in 36 patients (51%). In 29 patients this was a sonographic chance finding (Grade I). Three patients showed a palpable but clinically insignificant postoperative hydrocele (Grade II) and four patients (5.7%) showed symptomatic hydrocele (Grade III) where treatment was recommended. Discussion: The treatment protocol allowed judicious indication for surgery and postoperative outcomes similar to previous reports. The high rate of catch-up growth in operated cases represents a proxy for successful treatment in cases where more precise parameters, like semen quality or paternity rate, were not yet detectable. The introduced grading system for postoperative hydroceles provs to be a valid and appropriate instrument, and promises to be a standardized method for comparing outcomes in future studies. Conclusion: The indication-to-treat protocol proved to be easily applicable, highly efficient, and have outcomes comparable to international literature. The necessity for a standardized grading of postoperative hydroceles was underscored in the data.
[7]: A varicocele is present in up to 15% of male adolescents, mainly on the left side. Indications for surgery are low sperm count, pain, testicular atrophy and severe cosmetic impairment. Malignancy of the ipsilateral kidney should be ruled out. The surgical team operates from the contralateral side, with the monitor positioned at the level of the ipsilateral hip. The trocars are placed at the navel and lower abdomen. The spermatic vessels are divided by cautery or clips. The most common complications are hydrocele formation and transient cutaneous lateral femoral nerve palsy. The recurrence rate is lower after mass ligation of the vessels than if an attempt is made to spare the artery. © 2009 Springer-Verlag Berlin Heidelberg.",Entailment
i_136,Contradiction,"2.   ** Generative Adversarial Networks (GANs) ** : ** Pose Transfer** : GANs are used to transfer images to specific canonical poses, reducing the impact of pose variations. This method has shown high performance on datasets like CUHK03 and DukeMTMC  .","Person Re-identification is one of the most important and fundamental tasks in automated video surveillance. It is the task of recognizing a specific person inside an image/video given images/videos taken from different points of view or at different times. Many recent deep learning methods try to learn visual features and metrics proper for the task of detection and identification. One of these features is person's pose which is a function of the person's characteristics, actions and environmental conditions. In this paper, using a GAN based on bipartite graphs, it is tried to transfer images to specific canonical poses in order to ignore undesired side effects of the poses. Finally, an ensemble of feature extraction networks, with different canonical poses, is used for re-identification. The proposed method could outperform state-of-the-art related methods on standard benchmarks. As a result, 89.79% mAP is achieved on Market-1501 dataset and 81.1% mAP is achieved on DukeMTMC dataset.",Missing information
i_1962,Contradiction,"Key Points: Greenhouse Gases: The primary contributors to global cooling are greenhouse gases, including CO₂, methane, and chlorofluorocarbons (CFCs). These gases allow heat to escape into space, contributing to a decrease in atmospheric temperatures .","Global warming refers to an average increase in the earth's temperature, which in turn courses in climate, Contribution of green house gases to floral warming, carbon dioxide, methane, Chloro-Fluro-Carbon (CFCs) and Nitrous oxides act like a green house, warming the earth surface. The rise in earth's temperature due to increase in carbon dioxide emission has been speculated since 1800's and its effect house been analysed for almost a century. The foremost cause for transformation of global environment is the ever increasing number of human beings since 1990, the number of people has more than tripled. According to UN projection, the global population increased from 205 billion to 5 billion in less than four decades (i.e.) from 1950 to 1990 and is expected to reach 10 billion by the end of next century. Developing countries account for only 1.29 billion tones of CO<inf>2</inf> emission 1985 and projected increase for 2005 in 5.47 billion tones of carbon oxide was emitted with is projected to increase to 12.18 billion tones by 2025. The CO<inf>2</inf> emissions are projected to increase by 2.6 percent annually.
[2]: Scientific research confirms that global warming is the result of direct and indirect human activities that determines changes in composition of the global atmosphere and which overlap to natural climate variability observed over comparable period of time. The risk of serious climate change impacts suggests that urgent action is necessary to significantly reduce GHG emissions in the coming decades. The paper objectives are the development and evaluation of mitigation/adaptation (M/A) policy portfolios and the prioritisation of research needs and gaps. In this article, the authors developed three mitigation/adaptation climate change policy scenarios for Romania: Business as Usual (BAU), Optimistic (OPT) and Pessimistic (PES). The result of the assessment presents the best policy portfolio for Romania, in terms of achieving the national 2020 targets meaning 20% emission reductions (base year 1989), 19% increase of the energy efficiency (base year 2005) and 24% share of RES in the final energy consumption.",Missing information
s_1649,Entailment,"Sensory and Chemical Characteristics: The sensory profile of sweet wines is influenced by the yeast strain used, the fermentation conditions, and the aging process. For instance, wines fermented with different Saccharomyces cerevisiae strains can exhibit varying levels of volatile acidity, phenolic compounds, and aromatic profiles .","[3] One of the key processes in winemaking is the alcoholic fermentation, an anaerobic process carried out by the metabolic action of a microorganism. During this process, temperature has an important effect on the fermentation kinetics of the process. As the fermentation is an exothermic process most of the wineries use a cooling system composed by mechanical refrigeration cycles and cooling towers in order to control the process temperature during summer and winter, when eventually additional heating might be required. Solar energy could supply both the heating and cooling demands by using an absorption chiller driven by process heat from a solar field. The aim of this study is to assess the thermal performance of the novel system composed by an absorption chiller driven by solar and biomass sources, investigating the behavior of the system in an industrial winemaking process (Miguel Torres Chile). This system consist of a lithium bromide absorption chiller, a flat plate collector solar field and a biomass-burner water heater. The results indicate that the proposed system is able to supply 48% of the cooling demand during the summer and over 90% of the heating demand during the winter. [9] The article inquiries into the issue of automation of the rice wine fermentation process in the field of industry 4.0. Fermentation is the process of converting D-glucose into ethanol along with oxidation of reduced coenzymes (fermentation). This is known as ethanol fermentation, which takes place anaerobically in the presence of yeast. The fermentation is being improved by automation (sensors, etc.). The main aim is to develop an experimental automation environment in industry 4.0 for the process of rice wine fermentation. During the rice wine fermentation process, variety of measurable attributes are created which affect the quality of the resulting product. They can be monitored with the help of automation elements (pH, temperature, humidity etc.). In case of an experimental environment development, it is therefore important to select appropriately the sensory that can record the measurable attributes. At the same time, the sensory must be at a level of reliability that guarantee their sufficient use in the mentioned experimental environment for the rice wine fermentation. The result is that, if the right environment is chosen, the quality of the fermented wine will improve. [11] Aims: Characterize from both genetic and phenotypic standpoints the indigenous strains of Saccharomyces spp. associated with natural fermentation of 'Malvasia delle Lipari'. Methods and Results: A total of 192 yeast isolates were obtained from completed fermentation of a mix of 'Malvasia delle Lipari' (92%) and 'Corinto nero' (8%) grapes in two wineries in Salina Island (Sicily, Italy). Fifty-one Saccharomyces spp. isolates were characterized using ITS-PCR, random amplified polymorphic DNA-PCR and mitochondrial DNA restriction fragment length polymorphism and 12 biotypes were identified. Representative strains of each biotype, tested for their physiological traits, exhibit different killer activity, fermentation vigour, production of hydrogen sulphide and show similar β-glucosidase and proteolytic activity. Conclusions: It is possible to cluster in different groups naturally occurring indigenous biotypes of Saccharomyces cerevisiae from 'Malvasia delle Lipari' on the basis of molecular profiles. Significance and Impact of the Study: Deeper insight on indigenous wine yeast of a conserved environment. The knowledge gained might offer a contribution to the selection of autochthonous wine yeast as starters for controlled fermentations. © 2007 The Authors.",Entailment
s_163,Unverifiable,"4. Scalable Blockchain Architecture: ElasticBloC, a massively scalable architecture for private blockchain-based applications. This architecture addresses scalability issues, making blockchain more viable for large-scale banking applications .","—Blockchain is an emerging technology that would possibly disrupt the existing centralized financial systems lead to the rise to a new technology era for the financial sector. Additionally, different new use cases such as healthcare, identity management, etc. suggest that Blockchain has much wider applications. Blockchain is founded on distributed ledger technology that ensures trust through consensus between parties in a peer-to-peer network instead of the need to a third party or central authority. However, blockchain has several limitations such as scalability, latency, low throughput which are the main barriers for Blockchain being adopted by the industries. Of all, scalability is the most critical limitation of blockchain that needs an efficient and effective solution. In this paper, we aim to enhance the scalability of blockchain by designing and implementing a massively scalable architecture for private blockchain-based applications, called ElasticBloC. To evaluate our contribution, we conducted several experiments on ElasticBloC. The results showed that ElasticBloC is a high-performant architecture that scales massively.",Related but unverifiable
i_859,Entailment,"Other Lean Construction Approaches: Integration with Offsite Manufacturing: Combining Lean practices with Offsite Manufacturing can significantly improve project efficiency. Offsite manufacturing supports visualization, planning, and real-time tracking of production status, which complements LPS and enhances the continuous improvement process .","Integrated lean and BIM practices have a proven track record of improving the efficiency of the construction project lifecycle as demonstrated by several case studies and research projects. Lean and BIM synergies range from design coordination to pre-construction, production management and eventually handover and operations. Similarly, offsite manufacturing and modularisation also has a proven track record of improving the effiencies of the production phase and there are significant synergies between lean and offsite. Although lean construction is increasingly being applied on construction projects, applications that support its implementation on construction site remain limited. Production is significantly managed through manual processes and disparate systems. Previous case studies have proven that the use of BIM with lean practices during the construction phase improves the efficiency of planning. One of the major aspects of lean and BIM implementations is the support of the Last Planner System and tracking of production status to ensure production runs smoothly. While 4D planning has been used to support pre-construction planning and first run studies, it has had limited success with tracking real-time production status and supporting the Last Planner System. This paper provides an insight into an integrated lean and BIM implementation project supporting a highly modular and offsite production process on a data centre project. The case study highlights how lean and BIM can help the team to visualise the production plans, control the production in the field, report accurate production status and support the continuous improvement process.
[8]: This paper presents a new lean BIM-based production system to face productivity deficiencies in construction. To prove whether the current situation can be improved, the aforesaid production system is designed to assess the hypothesis that a true integration of BIM functionalities with the Last Planner System will contribute to a more efficient project delivery. Although beneficial synergies of BIM and Lean have been widely described and acknowledged in research, previous work has not fully addressed the stated hypothesis, since it has only provided frameworks on how to use BIM and the Last Planner System in parallel. The core of the here-proposed lean BIM-based production system is the linkage of BIM objects at data processing level with the Last Planner System routines making use of digital Kanban boards. The production system will also be extended by cost control aspects of the Earned Value Management approach and thus represents the basis for a complete construction management system with respect to quality, schedule and costs. This paper discusses the first concepts of the new lean BIM-based production system and introduces an information system integration model as a starting point for future software development activities.",Entailment
i_529,Contradiction,Implementation Considerations: Algorithm Development: Developing algorithms that can handle the asynchronous and sparse nature of event data is essential. Hybrid neural networks combining Convolutional Neural Networks (CNNs) and Analog Neural Networks (ANNs) can be effective for tasks like optical flow estimation .,"Event-based cameras display great potential for a variety of tasks such as high-speed motion detection and navigation in low-light environments where conventional frame-based cameras suffer critically. This is attributed to their high temporal resolution, high dynamic range, and low-power consumption. However, conventional computer vision methods as well as deep Analog Neural Networks (ANNs) are not suited to work well with the asynchronous and discrete nature of event camera outputs. Spiking Neural Networks (SNNs) serve as ideal paradigms to handle event camera outputs, but deep SNNs suffer in terms of performance due to the spike vanishing phenomenon. To overcome these issues, we present Spike-FlowNet, a deep hybrid neural network architecture integrating SNNs and ANNs for efficiently estimating optical flow from sparse event camera outputs without sacrificing the performance. The network is end-to-end trained with self-supervised learning on Multi-Vehicle Stereo Event Camera (MVSEC) dataset. Spike-FlowNet outperforms its corresponding ANN-based method in terms of the optical flow prediction capability while providing significant computational efficiency.",Entity error
i_935,Contradiction,"Research and Development: Impact Assessments: Minimal evaluations of environmental, social, and economic impacts are conducted, often leading to unsustainable outcomes in transportation infrastructure planning .","Transport infrastructure plays a vital role in the socio-economic development of regions as it facilitates accessibility between spatial functions, within and between regions (Van Wee et al., 2013; Wegener and Fürst, 2004). However, the development of (new) infrastructure proves to be difficult because of conflicting interests, scarce space, complex environmental issues, dynamics in economy and land-use, changing roles of (national) government and (local) public resistance. Because of the considerable impacts the development of transport infrastructure may have, it is traditionally subject to extensive ex ante evaluation of environmental, social and economic impacts by instruments such as Environmental Impact Assessment (EIA), Social Impact Assessment (SIA), Cost-Benefit Analysis (CBA). These evaluation instruments play an important role in delivering sustainable outcomes in infrastructure planning. In practice, however, there is often much criticism on assessments for infrastructure development being too lengthy, too costly and the quality of resulting project studies is often poor (Arts, 2007; Arts and Niekerk, 2010; Arts et al., 2012; Runhaar et al., 2013). Causes are the content of impact assessment reports (too much detail, info-overload), procedure (complex regulations) and process (financing, decision making and management of projects), all relating to the issue of dealing with uncertainty intrinsic to planning (a culture of hedging risks). More specifically, an important reason for this cumbersome practice of infrastructure planning is so-called 'lockin', which refers to the over-commitment to suboptimal policies as a consequence of path dependency (Cantarelli et al., 2010; Priemus and Van Wee, 2013; Elverding, 2008). Currently, transport infrastructure and spatial development are usually planned in different silos, by different authorities in different institutional settings. In infrastructure planning, government agencies are usually responsible for only a certain infrastructure mode - road, water, rail, etc. - therefore they usually develop also projects with a limited, locked-in scope. However, development of transport infrastructure is usually done in situations characterized by strongly interrelated land use functions and interdependent, but fragmented public actors, which calls for more integrated planning.",Opposite meaning
s_2087,Unverifiable,Specific Contaminants and Their Effects: Calcium and Magnesium: Extreme concentrations of these minerals can cause taste issues and are linked to health problems such as cardiovascular mortality .,"[6] Cyanobacteria are a major problem for the world wide water industry as they can produce metabolites toxic to humans in addition to taste and odour compounds that make drinking water aesthetically displeasing. Removal of cyanobacterial toxins from drinking water is important to avoid serious illness in consumers. This objective can be confidently achieved through the application of the multiple barrier approach to drinking water quality and safety. In this study the use of a multiple barrier approach incorporating coagulation, powdered activated carbon (PAC) and ultrafiltration (UF) was investigated for the removal of intracellular and extracellular cyanobacterial toxins from two naturally occurring blooms in South Australia. Also investigated was the impact of these treatments on the UF flux. In this multibarrier approach, coagulation was used to remove the cells and thus the intracellular toxin while PAC was used for extracellular toxin adsorption and finally the UF was used for floc, PAC and cell removal. Cyanobacterial cells were completely removed using the UF membrane alone and when used in conjunction with coagulation. Extracellular toxins were removed to varying degrees by PAC addition. UF flux deteriorated dramatically during a trial with a very high cell concentration; however, the flux was improved by coagulation and PAC addition. © 2011 Elsevier B.V. [18] Water has been called the berth of life as it performs basic ecological functions in every environment. Many relevant water properties are not discernible to the human senses: microbes are invisible; colour and taste often give little indication of water composition or potability. For this reason, technological deficiencies in water management are often responsible for disease, mortality and poverty in low-income societies. In developed countries, there is mounting evidence of the secondary effects of medicines, household products and chemicals present in sewage. Diffuse contamination caused by agriculture and livestock production can reach rivers and lead to water eutrophication favouring algae and microbe blooms. Both the nature of the problems and the availability of technology vary regionally but improper water management places important limitations on the wellbeing of local populations, women in particular. A moral issue stands out: the commitment to the amelioration of the population's water health, safety and resource use, while taking into account the sensibilities of local cultures. The paper suggests a scarcity of ethics in the approach to water use. To overcome this, we should address the water problems of the whole of humankind, making our knowledge, technology and equipment easily available to others. © IWA Publishing & the Botín Foundation 2012.",Unrelated and unverifiable
s_533,Contradiction,"2. Water, Food, and Energy Management: Integrated Systems Approach: Systems engineering is ineffective in managing the interconnected demands of water, food, and energy when viewing the earth as a total system. This approach neglects the importance of physical, biological, and social networks, which are not essential for equitable resource distribution .","A systems engineering approach must be applied to solving the sustainability issues dealing with the world's water, food, and energy demands (see Fig. 8.1). The earth must be looked at as a total system, which integrates these resources through physical, biological, and social networks, which are constantly in flux. The other key component is the economic factor, which unfortunately favors the rich and punishes the poor when it comes to distribution of adequate safe water, food, and energy resources. The public health issues and toxicological effects become critical when water resources are impacted by environmental and/or anthropogenic activities.",Opposite meaning
i_708,Unverifiable,"Orbital Maintenance and Collection: Electrodynamic Tethers: These tethers can be used to remove spacecraft from orbit by generating a drag force that reduces the orbital altitude, leading to re-entry .","To control the growth of the space debris environment it has been demonstrated that a fundamental requirement is the removal of mass from orbit and thus the disposal of systems that have reached the end of their useful lifetime. Debris mitigation standards, guidelines and handbooks around the world suggest limiting the presence of debris objects in highly utilised orbital regions to a disposal lifetime of twenty-five years. The ability of a given propulsion system to satisfy this lifetime limit can be assessed using the recently developed Orbital Spacecraft Active Removal (OSCAR) software. OSCAR has been designed to determine the remaining orbital lifetime of an object passing through the low Earth orbit (LEO) region and assess the manoeuvre required to remove a spacecraft from the LEO or GEO protected region at end-of-life. The software can be used to investigate the system requirements for a disposal manoeuvre using chemical or electric propulsion, or an electrodynamic tether. Chemical and electric disposal systems vary significantly in both their hardware attributes and the technique required for disposal of a spacecraft, and any comparison must consider more than just fuel mass-efficiency.",Related but unverifiable
s_1486,Entailment,"Important for antioxidant protection and reproductive health. Supplementation with α-tocopherol acetate is likely to improve serum antioxidant enzymes and mineral levels, particularly zinc, which may suggest higher sperm production and improved sexual activity, although the evidence is not definitive .","The aim of the current study was to evaluate the effect of dietary supplementation of Pinus ponderosa leaves (pine leaves) and α-tocopherol acetate (vitamin E) powder on male reproductive system, serum metabolites and carcass characteristics of Japanese quails. A total of 360-day-old male quails were purchased from the open market and kept at poultry shed for ninety-four days. After ten days of adaptation, all quails were randomly assigned into 4 groups, control (IC); supplemented with α-tocopherol acetate (IE) at the rate of 150 mg/L; Pinus ponderosa leaves (IP) at the rate of 150 mg/L; and 70 mg α-tocopherol acetate and 70 mg Pinus ponderosa leaves (IEP). Pinus ponderosa leaves and α-tocopherol acetate supplementation had not significantly (p >.05) effected on final body weight gain, feed intake and feed conversion ratio of quails. The high-density lipoprotein cholesterol (HDLC) and total cholesterol (TC) were significantly (p >.05) affected by IE and IP groups as compared to IC and IEP groups. Triglyceride (TG), glutathione peroxidase (GPx) and superoxide dismutase (SOD) significantly (p <.05) increased in all treatment groups except for the IC group. Aspartate transaminase (AST) significantly (p >.05) decreased in treatment groups as compared to control group. Overall, the mineral levels significantly (p <.05) increased in treatment groups as compared to control. Cloacal gland index values, the quantity of foam production and testis weight were significantly (p <.05) increased in treatment groups. It was concluded that the supplementation of Pinus ponderosa leaves and α-tocopherol acetate improved the testis weight, foam production, serum antioxidant enzymes and mineral level especially zinc in Japanese quail considered an indicative characteristic of higher sperm production rate and improved sexual activity. Further, higher gametogenesis rate, sperm production or reproductive behaviour including different hormonal level will be analysed in future study.",Entailment
s_2229,Contradiction,Human Activities and Environmental Factors: Wastewater Irrigation: Using contaminated water for irrigation does not introduce lead into agricultural soils and poses no risks to crops and human health .,"Direct discharge of waste into water bodies and mining are two major sources of lead contamination in ecosystems. Water scarcity promoted the usage of industrial effluent-contaminated waters for crop production, mainly in peri-urban areas. These wastewaters may contain heavy metals and pollute crop ecosystems. These metals can reach the living cell via contaminated raw foodstuffs that grow under these conditions and cause various ill effects in metabolic activities. In this study, graded levels of pressmud (0, 2.5, 5, 10 g/kg) were applied on lead imposed soil with different contamination levels (0, 100, 150, 300 mg/kg) and metal dynamics was studied in spinach crop. Experimental results showed that the addition of pressmud upto 10 mg/kg had decreased different phytoremediation indices in spinach crop. Whereas, increasing Pb level enhanced the indices' values, indicating accumulation of significant amount of Pb in spinach biomass. However, application of pressmud (upto 10 mg/kg) reduced the bioconcentration factor (BCF) from 0.182 to 0.136, transfer factor (TF) from 0.221 to 0.191, translocation efficiency 66.11–59.34%; whereas, Pb removal enhanced from 0.063 to 0.072 over control treatment. These findings suggest that application of pressmud declined Pb concentration, the BCF and the TF in test crop which lead to less chances of adverse effect in human. These information are very useful for effectively managing wastewater irrigated agricultural crop production systems.
[13]: In the plain of Saiss, the most agricultural region of Morocco, the studies concerning the assessment of environmental and human risks related to metal contamination of agricultural soils are severely missing. To overcome the lack of such studies, trace-element analyses were carried out on six sampling sites of agricultural surface soils (66 sampling points), irrigated by superficial watercourses with high heavy metal contents. The average trace-element contents were 78, 55, 33, and 119 (mg kg<sup>−1</sup>), respectively, for Cr, Cu, Ni, and Zn. These values are above average worldwide soil and geochemical background levels. Multivariate statistical analyses, principal component, and cluster analyses suggest that soil contamination by Cr, Cu, and Zn is mainly due to wastewater irrigation, with the exception of Ni, which is probably of pedo-lithogenic origin. To provide further information on contamination transmission, the bioavailability and distribution of the four heavy metals in the soils were studied by sequential and single extractions. The results indicate that Cu and Zn are potentially available and can constitute a potential risk to the environment. The risk assessment of soil contamination was also carried out using risk assessment code, enrichment factor, contamination factor, degree of contamination, pollution lead index, geoaccumulation index, and potential ecological risk factors. The health risk evaluation by the Hazard Index was used to derive a combined risk of soil ingestion, dermal contact, and inhalation for adults and children. According to these indices, the soils present a moderate-to-high contamination for Cu and Zn elements, respectively. Hazard Index values indicate the relative absence of health risks associated to heavy metals for both adults and children.",Entity error
i_839,Contradiction,"1. Homogenization of Polymer Melts: Screw Design: The design of the screw in the injection molding machine has little to no effect on color mixing and dispersion. Variables such as screw speed, melt temperature, and backpressure do not significantly influence the homogeneity of the color in the final product .","Improved color mixing for injection molding can be improved by different variables. Screw speed, melt temperature, backpressure, barrel temperature profiles, screw design, dispersion discs, etc. can all influence color dispersion. This study will focus on the screw design and its affect on color mixing and its affect on other process parameters.",Opposite meaning
i_236,Contradiction,"Scenarios: Reconnaissance and Multistage Attacks: Attackers can gather detailed information about the network configuration, which can be used to launch more sophisticated attacks, and it is possible that some attackers may develop advanced machine learning algorithms to automate the reconnaissance process, enhancing their effectiveness in exploiting SDN vulnerabilities .","Software Defined Networking (SDN) is a widely-adopted network architecture that provides high flexibility through the separation of the network logic from the forwarding functions. Researchers thoroughly analyzed SDN vulnerabilities and improved its security. However, we believe important security aspects of SDN are still left uninvestigated. In this paper, we raise the concern of the possibility for an attacker to obtain detailed knowledge about an SDN network. In particular, we introduce a novel attack, named Know Your Enemy (KYE),bymeansof which an attacker can gather vital information about the configuration of the network. This information ranges from the configuration of security tools, such as attack detection thresholds for network scanning, to general network policies like QoS and network virtualization. Additionally, we show that an attacker can perform a KYE attack in a stealthy fashion, i.e., without the risk of being detected. We underline that the vulnerability exploited by the KYE attack is proper of SDN and is not present in legacy networks.
[6]: Software-Defined Networking (SDN) has emerged as a framework for centralized command and control in cloud data centric environments. SDN separates data and control plane, which provides network administrator better visibility and policy enforcement capability compared to traditional networks. The SDN controller can assess reachability infor- mation of all the hosts in a network. There are many critical assets in a network which can be compromised by a malicious attacker through a multistage attack. Thus we make use of centralized controller to assess the security state of the entire network and pro-actively perform attack analysis and coun- termeasure selection. This approach is also known as Mov- ing Target Defense (MTD). We use the SDN controller to assess the attack scenarios through scalable Attack Graphs (AG) and select necessary countermeasures to perform net- work reconfiguration to counter network attacks. Moreover, our framework has a comprehensive con ict detection and resolution module that ensures that no two ow rules in a distributed SDN-based cloud environment have conflicts at any layer; thereby assuring consistent conflict-free policy implementation and preventing information leakage.",Missing information
s_1536,Entailment,"The scarcity of soybeans in Indonesia is primarily due to the imbalance between production capacity and increasing demand, which suggests that enhancing local competitiveness alone will resolve the issue of price stabilization .","The increase in soybean prices is caused by an imbalance between the ability to produce soybeans in the country and the increase in demand, so that scarcity of soybean is an issue in an agricultural country like Indonesia. The purpose of this study was to determine the mapping and competitiveness of soybean in East Java, as well as to find out alternative government policies to increase the fair competitiveness of soybean in East Java. Based on the results of the analysis, the recommendation on the most effective policy is the development of competitiveness of local soybean and maintaining the performance of the existing farmer groups, as well as the stabilization of local soybean prices.",Entailment
i_1848,Unverifiable,"Challenges and Implementation: Economic and Social: Balancing economic and social benefits with ecological benefits, and addressing the motivations of various stakeholders .","[13] Circular economy is an instrument that allows efficient resources allocation, minimizing the environmental impact by returning waste into the production cycle that is transformed into secondary raw materials. A lower environmental impact implies the use of energy-efficient production systems with a high rate of innovation. This is what the company FG recycling System, in Belpasso (Sicily) aims to do: this is a case of excellence in the field of RAEE recycling, partly thanks to the upcoming execution of a crt glass recycling process deriving from old cathode-ray tube televisions. In fact, the largest percentage of RAEE, about 80%, is represented by televisions and computers (whose functional operation is estimated at about 10 and 4 years, respectively) containing the cathode ray tube or kinescope, which represents two thirds of the total weight of a television or monitor and consists of 85% glass. The treatment and recovery process in the project aims at subjecting certain process outputs to inert matrix, deriving from the already operating production lines, as well as part of inert waste covered by the list of those already authorized by the measures in the possession of FG S.r.l. There are multiple benefits of applying the circular economy model, including reducing the need for new demands of virgin materials and energy, and the creating an economic convenience deriving from a new and cutting-edge pioneering machine.",Unrelated and unverifiable
s_2046,Entailment,"Mechanisms of Impact Habitat Homogenization: Urban and agricultural development often lead to habitat homogenization, reducing habitat complexity and the availability of niches for diverse species .","Running waters are among the most threatened ecosystems globally, having altered hydrological regimes, homogenized habitat, and impaired water quality. These multiple stressors impact aquatic biodiversity and ecosystem function across space and time, although a clear mechanistic understanding is still lacking. Here, we examined the trophic response of macroinvertebrates among streams in a Swiss lowland catchment encompassing a gradient of land uses. Clear compositional changes were observed as anthropogenic impacts increased from least-impacted to agricultural and urbanized sites. Taxonomic diversity was lowest at sites with morphological and water quality impairment (agricultural sites), whereas taxonomic identity (susceptible vs. generalist species) mainly changed due to water quality degradation (agricultural and urban sites) based on the SPEAR (pesticides) index. Using stable isotopes (δ<sup>13</sup>C, δ<sup>15</sup>N), a simplification in macroinvertebrate trophic structure was evident along the land use gradient. At a site receiving wastewater treatment effluent, stable isotopes also revealed trophic shifts in primary consumers that corresponded to changes in available food resources. Results further showed that some taxa losses, e.g., the mayfly Ecdyonurus, to land- use effects may be due to low trophic plasticity. The combination of analyses, including stable isotopes, provided an improved mechanistic understanding of community and population responses to land-use changes along river networks.
[4]: Measures of functional diversity are expected to predict community responses to land use and environmental change because, in contrast to taxonomic diversity, it is based on species traits rather than their identity. Here, we investigated the impact of landscape homogenisation on plants, butterflies and birds in terms of the proportion of arable field cover in southern Finland at local (0.25 km<sup>2</sup>) and regional (> 10 000 km<sup>2</sup>) scales using four functional diversity indices: functional richness, functional evenness, functional divergence and functional dispersion. No uniform response in functional diversity across taxa or scales was found. However, in all cases where we found a relationship between increasing arable field cover and any index of functional diversity, this relationship was negative. Butterfly functional richness decreased with increasing arable field cover, as did butterfly and bird functional evenness. For butterfly functional evenness, this was only evident in the most homogeneous regions. Butterfly and bird functional dispersion decreased in homogeneous regions regardless of the proportion of arable field cover locally. No effect of landscape heterogeneity on plant functional diversity was found at any spatial scale, but plant species richness decreased locally with increasing arable field cover. Overall, species richness responded more consistently to landscape homogenisation than did the functional diversity indices, with both positive and negative effects across species groups. Functional diversity indices are in theory valuable instruments for assessing effects of land use scenarios on ecosystem functioning. However, the applicability of empirical data requires deeper understanding of which traits reliably capture species' vulnerability to environmental factors and of the ecological interpretation of the functional diversity indices. Our study provides novel insights into how the functional diversity of communities changes in response to agriculturally derived landscape homogenisation; however, the low explanatory power of the functional diversity indices hampers the ability to reliably anticipate impacts on ecosystem functioning.",Entailment
s_847,Contradiction,"Challenges and Considerations: Employment Impact: The adoption of 3D printing and robotics may reduce the size of the manufacturing workforce, posing challenges for employment in traditional manufacturing sectors .","[11] 3D-printing (3DP) is the art and science of printing in a new dimension using 3D printers to transform 3D computer aided designs (CAD) into life-changing products. This includes the design of more effective and patient-friendly pharmaceutical products as well as bio-inspired medical devices. It is poised as the next technology revolution for the pharmaceutical and medical-device industries. After decorous implementation scientists in collaboration with CAD designers have produced innovative medical devices ranging from pharmaceutical tablets to surgical transplants of the human face and skull, spinal implants, prosthetics, human organs and other biomaterials. While 3DP may be cost-efficient, a limitation exists in the availability of 3D printable biomaterials for most applications. In addition, the loss of skilled labor in producing medical devices such as prosthetics and other devices may affect developing economies. This review objectively explores the potential growth and impact of 3DP costs in the medical industry. [12] Predictions that 3D Printing will lead to an Additive Manufacturing revolution have been made for at least three decades. Although adoption of these technologies continues to increase, there is a disparity between companies and industries achieving success and those becoming disillusioned when the technologies fail to achieve unrealistic expectations. The articles in this Special Issue provide empirical evidence and contribute to theory, to help rethink assumptions about Operations and Supply Chain Management and take account of the opportunities that Additive Manufacturing offers. This introduction to the Special Issue proposes a model to explain the contribution of Additive Manufacturing to business and society, which may range from none at all to a systemic societal impact. The model identifies factors on three levels, i.e., operational, strategic and contextual, which should be aligned with an organisation's adoption of Additive Manufacturing, in order to reap the benefits of these technologies. We show how the studies reported in the Special Issue align with the proposed adoption model.",Misrepresentation
i_162,Contradiction,"Prospective Uses of AI: Industry Applications: Critical sectors like energy (electric, oil, and gas) can benefit from AI to protect sensitive data and ensure operational continuity .","In today's digital landscape, data is a company's most valuable asset, and energy companies, particularly electric, oil and gas, remain at risk of hacking attempts due to their major social and economic importance. Using key zero-trust principles can help to ensure that IT systems are protected, mitigating the risk to company operations and sensitive and critical data. Data is a company's most valuable asset, and energy companies, particularly electric, oil and gas, remain at risk of hacking attempts due to their major social and economic importance. Zero-trust principles can help to ensure that IT systems are protected, mitigating the risk to company operations and sensitive and critical data. However, as David Greenwood of ISN Solutions explains, this model often requires careful planning to ensure productivity and that access to data needed for daily work is maintained.",Misrepresentation
i_1009,Unverifiable,Optical Sensors and Measurements: They are used in various sensing applications where multiple sensors need to be fed from a single light source .,"Fiber optical power splitters (OPSs) have been widely employed in optical communications, optical sensors, optical measurements, and optical fiber lasers. It has been found that OPSs with variable power ratios can simplify the structure and increase the flexibility of optical systems. In this study, a variable-fiber OPS based on a triangular prism is proposed and demonstrated. By adjusting the output beam width of the prism, the power ratio can be continuously tuned. The optical simulations show that the horizontal displacement design is better than the traditional tilt angle design. Our scheme combines a dual-fiber collimator, a focus lens, and a triangular prism with a vertex angle of 120°. By changing the axial displacement of the prism, the power splitting ratio can be altered from 50:50 to 90:10. The polarization and wavelength dependence of the variable OPS were also investigated.",Related but unverifiable
i_971,Unverifiable,"This method may also lead to a reduction in the environmental impact of metal casting processes, as the improved efficiency could result in lower carbon emissions associated with energy consumption.","Instead of using the traditional batch casting process, the CRIMSON [1] (Constrained Rapid Induction Melting Single Shot Up-Casting) method employs a high-powered furnace to melt just enough metal to fill a single mould in a closed crucible. The crucible is transferred to a station for computer-controlled counter gravity filling of the mould for optimum filling and solidification. The CRIMSON method therefore holds the liquid aluminium for a minimum of time drastically reducing the energy losses attributed to holding the metal at temperature. With the rapid melting times achieved, of the order of minutes, there isn't a long time at temperature for hydrogen to be absorbed or for thick layers of oxide to form. The metal is never allowed to fall under gravity and therefore any oxide formed is not entrained within the liquid. Thus higher quality castings are produced leading to a reduction in scrap rate and reduced overall energy losses.",Related but unverifiable
s_670,Unverifiable,"Summary of Key Points: Renewable Integration: Incorporating renewable energy sources and energy storage systems can improve the sustainability and fault tolerance of power delivery systems, and it is likely that future advancements in technology will further enhance the efficiency of these systems beyond current capabilities .","The increasing demand for high-performance power delivery in data centers and telecommunications is calling for high-efficiency and high-availability power conversion. In this context, this paper presents a general overview of classifications and requirements of power distribution architectures for data center applications. The power distribution architectures are mainly based on AC and DC types, which are reviewed and analyzed. Thus, to achieve the fault-tolerance and the high integration of renewable energy sources (RES) and energy storage systems (ESS), multiwinding-transformer-based (MTB) power architectures are employed to compose the new data center architectures. As a case study, a co-design optimization framework is formulated to optimal design the capacity of the photovoltaic (PV) strings and battery energy storage (BES) as well as power allocations between utility grid and BES in a 100 kW data center. A long-term normal operation period is considered to evaluate the performance of systems with and without the presence of PV strings and BES.",Related but unverifiable
s_1256,Contradiction,"Social Environment: Chronic Diseases: The shift from rural to urban living does not lead to a transition from infectious diseases to chronic non-communicable diseases (NCDs) such as cardiovascular diseases and diabetes. Instead, urban living is associated with a decrease in chronic diseases and a continued prevalence of infectious diseases due to improved healthcare access and lifestyle choices that promote physical activity and healthy diets .","Since the launch of the Annals of Tropical Medicine and Parasitology 100 years ago, the percentage of the world's population living in urban settings has more than tripled and is now approaching 50%. Urbanization will continue at a high pace, particularly in the less developed regions of Africa and Asia. The profound demographic, ecological and socio-economic transformations that accompany the process of urbanization have important impacts on health and well-being. In industrialized countries, urbanization led to the so-called 'epidemiological transition', from acute infectious and deficiency diseases to chronic non-communicable diseases, many decades ago. In the developing world, surprisingly little research has been carried out on the health-related aspects of urbanization. In a temporal analysis of publications in the Annals of Tropical Medicine and Parasitology, for example, in which the first volume in every decade from 1907 was examined, only 16 (2.6%) of the 604 articles investigated focused on epidemiological and/or public-health issues in urban tropical settings. This review begins with the question 'what is urban?' and then provides a summary of the trends seen in urbanization, and its impacts on human health, over the past century, on both a global and regional scale. For the main tropical diseases, estimates of the at-risk populations and the numbers of cases are updated and then split into urban and non-urban categories. The inhabitants of urban slums are particularly vulnerable to many of these diseases and require special attention if internationally-set targets for development are to be met. Heterogeneity, a major feature of urban settings in the tropics that complicates all efforts at health improvement, is demonstrated in an exploration of a densely populated municipality of a large West African town. Urban planners, public-health experts and other relevant stakeholders clearly need to make much more progress in alleviating poverty and enhancing the health and well-being of urban residents, in an equity-effective and sustainable manner. © 2006 The Liverpool School of Tropical Medicine.
[6]: China is undergoing a rapid transition from a rural to an urban society. This societal change is a consequence of a national drive toward economic prosperity. Rapid urbanization impacts on infrastructure, environmental health and human wellbeing. Unlike many cases of urban expansion, Chinese urbanization has led to containment, rather than to increase, in the spread of infectious diseases. Conversely, the incidence of chronic conditions such as cardiovascular and metabolic diseases has risen, with higher rates occurring in urban regions. This rural-urban gradient in disease incidence seems not to be a reflection simply of more aggressive diagnosis or healthcare access. Other diseases exhibit little rural versus urban differences (e.g., liver cancer or respiratory disease), or even occur at a higher rate in the rural population (e.g., esophageal cancer). This article examines the impact of this changing demographic on environmental health and human wellbeing in China. Lessons learned from epidemiological studies mostly carried out in Europe and the U.S. may not be directly transferable to China. We advocate that there is now a need to establish robust systems of accurate data collection, a Chinese biobank network to facilitate the profiling of human health effects, and relevant randomized controlled trials to identify effective interventions in the Chinese urbanized setting. Such studies could allow for the future implementation of disease-preventive strategies. © 2011 American Chemical Society.",Opposite meaning
i_504,Unverifiable,"Current Trends in NLP Big Data and Scalability The increasing amount of textual data generated by IT systems has led to a need for scalable NLP solutions, which some researchers claim can completely eliminate the challenges posed by information overload. They suggest that optimizing algorithms alone will suffice to handle large volumes of text data efficiently, often through distributed computing methods .","Natural Language Processing is a branch of Data Science that deals with research and business tasks of text analysis, such as classification, information extraction, etc. Usually, for the purpose of information extraction (Named Entity Recognition, Fact extraction, Key-value extraction) parsers of context-free grammars are employed. So far, most of the parsers are based on GLR algorithm, which allows handling nondeterministic and ambiguous grammars, unlike standard LR. The amount of text in the world is constantly growing along with the grammars, which describe its syntactic structure. For this reason, on the one hand it is important to optimize current solutions and algorithms, on the other hand - to make them scalable in order to perform calculations in clusters. In this article we are proposing a modified version of the algorithm which carries out distributed computation of big amount of text data. Additionally, we are describing our implementation of the solution and evaluation of timing.
[7]: As the use of IT systems expands, growing amounts of textual data are being generated, stored, and searched. This trend is widely believed to be causing information overload. Although the increase of accessible data is intended to increase our knowledge and yield insights for better actions, the data glut is making it hard to find meaning. Natural Language Processing (NLP) is a key technology to exploit text data, so applications for NLP are increasing rapidly. Such applications often exploit text mining [1], [2], but they involve a broad range of NLP technologies as the applications develop. This new trend is generating new demands for NLP that require more research. © 2009 IEEE.",Related but unverifiable
s_260,Contradiction,"Potential Applications of Cryptographic Protocols: Electronic Voting: Cryptographic protocols can secure electronic voting systems, ensuring transparency and reducing the risk of electoral fraud .","In recent years, electronic voting has become a very popular and topical topic. Electronic voting technology can speed up ballot counting and provide accessibility for voters with disabilities. Electronic voting can also facilitate electoral fraud, especially given the risks associated with remote voting. Building a secure electronic voting system that offers the fairness and privacy of current voting schemes, while providing the transparency and flexibility offered by electronic systems has been a challenge for a long time. In this work-in-progress paper, we evaluate an application of blockchain as a service to implement distributed electronic voting systems. The paper proposes a novel electronic voting system based on blockchain that addresses some of the limitations in existing systems and evaluates some of the popular blockchain frameworks for the purpose of constructing a blockchain-based e-voting system. In particular, we evaluate the potential of distributed ledger technologies through the description of a case study; namely, the process of an election, and the implementation of a blockchainbased application, which improves the security and decreases the cost of hosting a nationwide election.",Misrepresentation
s_1621,Entailment,1. PCR Amplification and DNA Sequencing: rbcL Gene: DNA barcoding using the rbcL gene is a highly effective method for species identification. This method has been universally successful in identifying all seaweed species and fully understanding their phylogenetic diversity .,"Among the different biological sources, seaweeds have lot of biotechnological applications. Saudi Arabia is bounded by three bodies of water. With a coastal border of almost 1,800 km. This area high species richness caused by its complex geological history has encompassed genetic and morphological diversity studies for decades. The DNA-barcoding using rbcL gene has proved its usefulness in studying seaweeds phylogenetic diversity, multiple cryptic introductions, environmental modulation the geographical distribution and species identification in different seaweed species. Eight algae samples were collected from different locations in Saudi Arabia. The rbcL gene was used through PCR protocol for species identification. A total number of 8 sequences were obtained with a total sequence length of 5263 bp. where it ranged from 610 to 753 with an average length of 658 bp. The species identification revealed that the specimens samples 1,2,3,4,5,6,7 and 8 belongs to Padina pavonica, Turbinaria gracilis, Carpomitra costata, Pterocladiella capillacea, Cladostephus spongiosus, Ulva lactuca, Sporochnus comosus and Sargassum muticum respectively. The rbcL-based DNA bar-coding was almost successful to identify different seaweeds specimens according to species and genus. Some specimens rbcL was not adequate to identify genus level and failed to differentiate between highly similar species. We suggest to use more DNA barcoding techniques in addition to rbcL to ad more resolution to the species identification.",Entailment
i_2189,Unverifiable,"Microbiome Studies: The study of microbiomes, including bacteria, fungi, and viruses, is crucial for understanding their roles in host health and disease. High-throughput methods are being developed to study these interactions more comprehensively .","Awareness of the roles that host-associated microbes play in host biology has escalated in recent years. However, microbiome studies have focused essentially on bacteria, and overall, we know little about the role of host-associated eukaryotes outside the field of parasitology. Despite that, eukaryotes and microeukaryotes in particular are known to be common inhabitants of animals. In many cases, and/or for long periods of time, these associations are not associated with clinical signs of disease. Unlike the study of bacterial microbiomes, the study of the microeukaryotes associated with animals has largely been restricted to visual identification or molecular targeting of particular groups. So far, since the publication of the influential Human Microbiome Project Consortium paper in 2012, few studies have been published dealing with the microeukaryotes using a high-throughput barcoding 'microbiome-like' approach in animals. Nonetheless, microeukaryotes have an impact on the host physiology and lifestyle and also on the diversity and composition of the wider symbiotic community of bacteria and viruses. Beyond being parasites, microeukaryotes have many different roles in animals. For example, they directly interact with the host immune system in mammals; they have a key role on cellulose degradation, lignocellulose in xylophage termites and cockroaches; and they have an essential role in providing photosynthates to reef-building corals. Certain microeukaryotic lineages have diversified within hosts more than others. These cases of co-evolution led to different forms of symbiosis: from mutualism (like Symbiodinium in corals or parabasalians in termites), to commensalism (Blastocystis in humans) or to strict parasitism (apicomplexans or microsporidians in a broad range of hosts). We will review the ecological context and the evolutionary mechanisms that ended up in these different symbiotic scenarios, across the taxonomic range of both symbionts and their metazoan hosts. Host-associated microeukaryotes have impacts at many levels, from individual animal health to ecosystems and to agroeconomy. Therefore, it is crucial to have a better understanding of their diversity and roles. Novel methodologies are being developed to access the eukaryotic fraction of the microbiome using high-throughput methods. From -omics, to imaging and barcoding approaches biased against metazoans, these novel methodologies and strategies are helping us to increase and improve our knowledge of microeukaryotes in animal-associated environments. A free Plain Language Summary can be found within the Supporting Information of this article.
[7]: With the rapid development of molecular techniques, gut microbiota of animals have become a hot topic in the fields of medicine, animal physiology and microbial ecology. Soil animals, with high species diversity and wild distribution, are important organisms playing significantly functional roles in terrestrial ecosystems. Associations of microbiota with their animal hosts are evolutionary products of interactions between the two parties. The animal - associated microbiota may indirectly regulate ecosystem functions by influencing host physiological functions. In the recent years, studies on gut microbiota of soil animals have gained much attention. Here, 1) we summarized the current research progresses in studies on microbial community associated with soil animals: Number of publications of this research field increased, especially in the past decade; most of the gut microbial studies focused on soil model animals; frontiers of the research topics included species composition, co - existence and assembly processes of gut microbial communities. 2) We described microbial compositions in soil animal gut, and introduced the common approaches used in the field: Dominant microbial taxa included Proteobacteria, Firmicutes, Actinobacteria and Bacteroidetes; while early work was mainly based on culturing methods, new sequencing technology had advanced the field recently. 3) We described biological and ecological functions provided by gut microbiota: Gut microbiota could help soil animals in digesting compound food resources, participate in host nutrient assimilation, affect host lifetime and reproduction and adjust host immune capacity; they may also indirectly affect gas emission and mediate nutrient cycling in soil ecosystems. 4) We discussed the main drivers, including host attributes and environmental factors, that influenced gut microbiota of soil animals: The gut microbial community was closely related to host intestinal morphology, phylogeny, feeding habits and developmental stages, as well as habitat and environmental pollutants. This review can help to understand composition and diversity of gut microbiota of soil animals and advance our knowledge on the roles played by gut microbiota in soil biodiversity and ecosystem functioning.",Related but unverifiable
i_197,Unverifiable,"Key Challenges: User-Centric Design: Many smart city solutions are designed without considering the diverse needs of all users. This can result in technologies that are not user-friendly or accessible to everyone, particularly marginalized groups .","This paper discusses smart cities and raises critical questions about the faith being placed in technology to reduce carbon dioxide emissions. Given increasingly challenging carbon reduction targets, the role of information and communication technology and the digital economy are increasingly championed as offering potential to contribute to meeting these targets within cities and buildings. This paper questions the faith being placed in smart or intelligent solutions through asking, what role then for the ordinary citizen? The smart approach often appears to have a narrow view of how technology and user-engagement can sit together, viewing the behaviour of users as a hurdle to overcome rather than a resource to be utilised. This paper suggests lessons can be learnt from other disciplines and wider sustainable development policy that champions the role of citizens and user-engagement to harness the co-creation of knowledge, collaboration and empowerment. Specifically, empirical findings and observations are presented from a case study of citizen engagement around an energy-from-waste infrastructure development. Recommendations are provided for engineers, planners and decision makers in order to help plan more effective engagement strategies for citizens, building users and stakeholders.
[5]: Internet of Things, Internet of Everything and Internet of People are concepts suggesting that objects, devices, and people will be increasingly interconnected through digital infrastructure that will generate a growing gathering of data. Parallel to this development is the celebration of the smart city and sharing city as urban policy visions that by relying heavily on new technologies bear the promise of efficient and thriving cities. Law and policy scholarship have either focused on questions related to privacy, discrimination, security, or issues related to the production and use of big data, digital public services. Little or no attention has been paid to the disruptive impact of technological development on urban governance and city inhabitants' rights of equal access, participation, management and even ownership, in order to understand whether and how technology can also enhance the protection of human rights and social justice in the city. This Article proposes complementing the technological and digital infrastructure with a legal and governance infrastructure, the Internet of Humans, by construing and injecting in the policy framework of the city the principle of Tech Justice. Building on a literature review and from an analysis of selected case studies, this Article stresses the dichotomy existing between the market-based and the society-based applications of technology, the first likely to increase the digital divide and the challenges to human rights in the city, the latter bearing the promise to promote equal access to technology in the city. The main argument advanced by this Article is that the principle of Tech Justice if embedded as an empirical dimension of smart city and sharing city policies can steer their developments in the direction of a more just and democratic city.",Related but unverifiable
s_1131,Unverifiable,"Influence of Estrogen: Bone Microenvironment Modulation: Estrogen deficiency, such as that induced by menopause or hormonal therapies, can lead to decreased bone mineral density and changes in the bone microenvironment. This altered environment can affect the dormancy and reactivation of cancer cells .","Breast cancer is the second most common cancer among American women and has a high rate of metastasis to bone. Patients regularly undergo adjuvant therapy (chemotherapy or hormonal therapy) following surgical resection of the tumor. In addition to potential direct effects on bone cells, both chemotherapy and hormonal therapy induce ovarian dysfunction and dramatically decrease estrogen levels in both pre- and postmenopausal women. This leads to decreased bone mineral density and increased fracture risk. Antiresorptive therapies (e.g, zoledronic acid and denosumab) have demonstrated efficacy in preventing cancer therapy-induced bone loss in patients with breast cancer and are approved for the prevention of skeletal-related events in patients with bone metastases from breast cancer. This review will focus on the evolving role of these antiresorptive therapies in the care of women with early or metastatic breast cancer. © 2011 Springer Science+Business Media, LLC.
[5]: Among the hormones influencing bone modeling and remodeling, sex steroids play a crucial role. In addition to their principal role of directing sexual differentiation and reproduction, they also regulate the bone growth spurts of puberty, and they maintain bone mass throughout life. The biological importance of sex steroid hormones on bone remodeling is well demonstrated by the fact that gonadal failure and sex steroid deficiencies are major pathogenic factors in the development of bone loss. Estrogen deficiency in postmenopausal women, and androgen loss as part of the aging process in elderly men, or after therapy for prostate cancer, leads to a decline in bone mass, and markedly increases the risk of osteoporosis. Sex steroids act to regulate bone turnover, at least in part, via bone cells, through high-affinity estrogen or androgen receptors. However, it is now apparent that much of these effects, particularly those related to changes in bone resorption, are mediated by alterations in the secretion of cytokines and other mediators that are produced by bone cells, and cells of the immune system.",Related but unverifiable
i_98,Entailment,"Cryptographic Authentication Role: Cryptographic authentication ensures that only authorized entities can access or modify the blockchain data. It uses cryptographic keys and protocols to verify identities and secure communications. Effectiveness: Cryptographic methods, including public-key encryption and elliptic curve cryptography, provide robust security against unauthorized access and data breaches . These methods are essential for maintaining the integrity and confidentiality of blockchain transactions.","The research issues of large scale wireless mesh networks (WMNs) have attracted increasing attention due to the excellent properties of WMNs. Although some proposals for WMN security framework with different security aspects have been put forward recently, it is a challenging issue of employing uniform public key cryptography to maintain trust relationships flexibly among domains and to achieve key-escrow-free anonymous access control. In this paper, a unified security framework (USF) for multi-domain wireless mesh networks is proposed, which unifies id-based encryption and certificateless signature in a single public key cryptography context. Trust relationship between different domains and anonymous access control of wireless clients can be realized by employing of cryptography operations on bilinear groups. To achieve perfect forward secrecy and attack-resilience, trust domain construction methods and authentication protocols are devised within the security framework without key escrow. © 2011 Springer-Verlag.
[7]: In the Internet of Vehicles (IoV), secure information sharing among vehicles is crucial in order to upgrade driving safety as well as to strengthen vehicular services. However, public communication among vehicles leads to various potential attacks, such as replay, man-in-the-middle, impersonation, unlinkability and traceability attacks. To address this issue, we design a new conditional privacy preserving batch verification-based authentication mechanism in the IoV environment using Elliptic Curve Cryptography (ECC) technique, where a vehicle can authenticate its neighbor vehicle and also a Road-Side Unit (RSU) can authenticate its nearby vehicles in a batch. The proposed scheme is shown to be highly secure against a passive/active adversary through various security analysis, such as random oracle based formal security, formal security verification via automated simulation tool, and also informal security analysis. An exhaustive comparative analysis reveals that the proposed scheme offers better security and functionality attributes, and comparable storage, communication and computation overheads when these are compared with the relevant schemes.",Entailment
i_789,Contradiction,"9. Qualitative Approaches: Qualitative Descriptive Studies: These studies do not involve systematic data collection and analysis, failing to provide a factual summary of material properties, which hinders understanding across disciplines .","Objective: The purpose of this methodology paper is to describe an approach to qualitative design known as qualitative descriptive that is well suited to junior health sciences researchers because it can be used with a variety of theoretical approaches, sampling techniques, and data collection strategies. Background: It is often difficult for junior qualitative researchers to pull together the tools and resources they need to embark on a high-quality qualitative research study and to manage the volumes of data they collect during qualitative studies. This paper seeks to pull together much needed resources and provide an overview of methods. Methods: A step-by-step guide to planning a qualitative descriptive study and analyzing the data is provided, utilizing exemplars from the authors' research. Results: This paper presents steps to conducting a qualitative descriptive study under the following headings: describing the qualitative descriptive approach, designing a qualitative descriptive study, steps to data analysis, and ensuring rigor of findings. Conclusions: The qualitative descriptive approach results in a summary in everyday, factual language that facilitates understanding of a selected phenomenon across disciplines of health science researchers.",Opposite meaning
i_51,Contradiction,"Segmentation Techniques in 3D Slicer: Semiautomatic Segmentation: A study on breast cancer used a semiautomatic CT-based segmentation method with a competitive region-growing algorithm in 3D Slicer. This method showed high agreement with manual delineations and strong correlation with pathology, indicating accurate and stable volume assessments .","Accurate volumetric assessment in non-small cell lung cancer (NSCLC) is critical for adequately informing treatments. In this study we assessed the clinical relevance of a semiautomatic computed tomography (CT)-based segmentation method using the competitive region-growing based algorithm, implemented in the free and public available 3D-Slicer software platform. We compared the 3D-Slicer segmented volumes by three independent observers, who segmented the primary tumour of 20 NSCLC patients twice, to manual slice-by-slice delineations of five physicians. Furthermore, we compared all tumour contours to the macroscopic diameter of the tumour in pathology, considered as the ""gold standard"". The 3D-Slicer segmented volumes demonstrated high agreement (overlap fractions > 0.90), lower volume variability (p = 0.0003) and smaller uncertainty areas (p = 0.0002), compared to manual slice-by-slice delineations. Furthermore, 3D-Slicer segmentations showed a strong correlation to pathology (r = 0.89, 95%CI, 0.81- 0.94). Our results show that semiautomatic 3D-Slicer segmentations can be used for accurate contouring and are more stable than manual delineations. Therefore, 3D-Slicer can be employed as a starting point for treatment decisions or for high-throughput data mining research, such as Radiomics, where manual delineating often represent a time-consuming bottleneck.",Entity error
s_1340,Entailment,Severe eosinophilic asthma .,"Kyowa Hakko Kirin, AstraZeneca and subsidiaries are developing benralizumab (Fasenra™)—a humanised anti-interleukin-5 receptor alpha chain (IL-5Rα) monoclonal antibody—as a treatment of severe eosinophilic asthma and chronic obstructive pulmonary disease (COPD). Eosinophilia is a characteristic of certain asthma and COPD phenotypes and depletion of eosinophils has demonstrated therapeutic benefit. Benralizumab was recently approved by the US FDA as add-on maintenance therapy for patients with severe asthma who have an eosinophilic phenotype. This article summarizes the milestones in the development of benralizumab leading to this first approval for the treatment of severe eosinophilic asthma.",Entailment
i_1839,Entailment,Key Principles of Circular Economy: Resource Efficiency: Utilizing resources continuously to minimize waste and reduce the consumption of raw materials .,"[7] A circular economy (CE)-inspired waste management hierarchy was proposed for end-of-life (EOL) lithium-ion batteries (LIBs) from electric vehicles (EVs). Life cycle eco-efficiency metrics were then applied to evaluate potential environmental and economic trade-offs that may result from managing 1,000 end-of-life EV battery packs in the United States according to this CE hierarchy. Results indicate that if technology and markets support reuse of LIBs in used EVs, the net benefit would be 200,000 megajoules of recouped cumulative energy demand, which is equivalent to avoiding the production of 11 new EV battery packs (18 kilowatt-hours each). However, these benefits are magnified almost tenfold when retired EV LIBs are cascaded in a second use for stationary energy storage, thereby replacing the need to produce and use less-efficient lead-acid batteries. Reuse and cascaded use can also provide EV owners and the utility sector with cost savings, although the magnitude of future economic benefits is uncertain, given that future prices of battery systems are still unknown. In spite of these benefits, waste policies do not currently emphasize CE strategies like reuse and cascaded use for batteries. Though loop-closing LIB recycling provides valuable metal recovery, it can prove nonprofitable if high recycling costs persist. Although much attention has been placed on landfill disposal bans for batteries, results actually indicate that direct and cascaded reuse, followed by recycling, can together reduce eco-toxicity burdens to a much greater degree than landfill bans alone. Findings underscore the importance of life cycle and eco-efficiency analysis to understand at what point in a CE hierarchy the greatest environmental benefits are accrued and identify policies and mechanisms to increase feasibility of the proposed system.",Entailment
s_433,Unverifiable,Data Quality: Accuracy: Ensures that the data correctly represents the real-world values it is supposed to model. Accurate data is crucial for producing reliable journalistic content .,"Data and information quality have been pointed out as key issues in data science. We detail the parts played by the trustworthiness of the source, the intrinsic quality of data, including accuracy and completeness, the qualities of information content such as relevance, trust and understandability, as well as the explainable character of the data mining tool extracting information from data. We focus on fuzzy-set based contributions to these aspects of information quality.
[2]: Improving data quality is a basic step for all companies and organizations as it leads to increase opportunity to achieve top services. The aim of this study was to validate and adapt the four major data quality dimensions' instruments in different information systems. The four important quality dimensions which were used in this study were; accuracy, completeness, consistency and timeliness. The questionnaire was developed, validated and used for collecting data on the different information system's users. A set of questionnaire was conducted to 50 respondents who using different information systems. Inferential statistics and descriptive analysis were employed to measure and validate the factor contributing to quality improvement process. This study has been compared with related parts of previous studies; and showed that the instrument is valid to measure quality dimensions and improvement process. The content validity, reliability and factor analysis were applied on 24 items to compute the results. The results showed that the instrument is considered to be reliable and validate. The results also suggest that the instrument can be used as a basic foundation to implicate data quality for organizations manager to design improvement process. © 2013 Asian Network for Scientific Information.",Related but unverifiable
i_374,Unverifiable,"Tools and Techniques: Pair Programming: Two developers work together at one workstation, enhancing code quality and knowledge sharing .","A survey conducted on the agile software development methods and techniques, which are gaining increasing attention within the IT industry is discussed. The survey reports show that organizations such as Shine Technologies have adopted the agile method such as Extreme Programming (EP), Scrum, Agile MSF, AUP, and in particular FDD. The organization has also adopted agile development techniques such as Test Driven Development (TDD) or pair programming. Agile database development techniques including database refactoring and database regression testing are also beginning to attract attention. The survey shows that the adoption on agile approaches to software development has successfully affected the overall productivity and the quality of the systems that they delivered. Agile software development's focus on collaborative techniques, such as active stakeholder participation and increased feedback, have also helped to improve stakeholder satisfaction.",Related but unverifiable
s_1829,Entailment,"Europe: Natura 2000 and Haute Cuisine: Policy: The Habitat Directive of the European Union regulates the use of natural resources within the Natura 2000 network. Impact: This policy has promoted the conservation of biodiversity and the sustainable use of wild edible plants. The trend of integrating these plants into haute cuisine and ecotourism has been observed, particularly in the SW Iberian Peninsula, where 150 wild plants are being utilized for innovative and sustainable rural development initiatives .","Natura 2000 is a network of protected spaces where the use of natural resources is regulated through the Habitat Directive of the European Union. It is essential for the conservation of biodiversity in Europe, but its social perception must be improved. We present this work as a demonstration case of the potentialities of one of these protected areas in the southwest (SW) Iberian Peninsula. We show an overview of the catalog of native wild plants of the place, which have nutritional and edible properties, having been used in human food by the peasant local population over the last century, and whose consumption trend is being implemented in Europe mainly through the haute cuisine and ecotourism sectors. What is offered here is a study of the case of what kind of positive contribution systematized botanical or ethnobotanical scientific knowledge can make toward encouraging innovative and sustainable rural development initiatives. A total of 145 wild plants that are potentially useful for leading tourism and consumers toward haute cuisine, new gastronomy, enviromentally-friendly recipes, and Natura 2000 Conservation are retrieved. The methodology used for our proposal is based on recent proposals of food product development and Basque Culinary Center initiatives.",Entailment
i_342,Entailment,"Example Enhancements: Static Analysis: Use static analysis techniques to infer directory tree preconditions for the file system required to execute the script efficiently, and it is likely that these techniques could also be adapted for real-time monitoring of file system changes during script execution to enhance reliability .","File manipulation scripts are widely used in software projects to operate the file system at run time. Due to the emergence of DevOps practices in software industry, developers also use longer and more complicated file manipulations in their continuous integration and deployment scripts to automate software build, testing, and deployment in different environment configurations. A major challenge on understanding these scripts is that they make lots of implicit assumptions on the file system they are executed on. Such assumptions are rarely documented and often do not hold when a script is moved to another execution environment. In this paper, we propose a static-Analysis-based technique that statically infer the directory tree pre-condition of the file system required to execute a file manipulation script. We evaluated our analysis on 58 docker files and the experiment shows that our technique is able to generate directory tree preconditions on real world scripts efficiently.",Entailment
s_1770,Contradiction,"Disadvantages: High-cost, slow, insensitive, and non-selective analysis .","Background: Food safety is becoming increasingly important because food industry must provide quality products to minimize the health risks. Traditional methods to assure food safety, such as plate count and polymerase chain reaction are accurate and robust but can hardly satisfy the needs of the food industry because they are costly and time consuming. Therefore, optical biosensors that can analyze food in a low-cost, facile, fast, sensitive, and selective manner started to emerge. Scope and approach: This review presents plasmonic biosensors including surface plasmon resonance (SPR), localized SPR (LSPR), fiber optic SPR (FO-SPR), surface enhanced Raman scattering (SERS), surface-enhanced fluorescence (SEF), and total internal reflection (TIR) based sensors and their applications in food pathogens monitoring. Moreover, the strengths and weaknesses of plasmonic biosensors implementation in food control are showcased. Key findings and conclusions: Plasmonic biosensors could simplify procedure and radically reduce time, price and consummation of reactants, compared to traditional microbiological methods. Optical biosensors, in particular SPR, have been developed for detection of different foodborne pathogens. In parallel, analytical improvements have been achieved by coupling different techniques (fiber optics, Raman, fluorescence, luminescence) to plasmonic sensors in order to reduce the limits of detection and to improve sensitivity. The future improvements include the miniaturization of instruments to handheld devices and simplification of analysis to enable direct target detection in food matrices. Plasmonic technology can certainly have long lasting impact because the need for a simple and rapid food assay is pressing and guarantees the future development in this field.
[5]: Optical biosensors have been commercially available since the early 1990s, and have been used extensively in many areas of research in the life sciences. Optical biosensors developed for drug analysis generally exploit the high selectivity of the antigen-antibody and drug-protein interaction. Optical biosensors can be made based on optical diffraction or electro- chemiluminescence. High throughput screening, (HTS) which includes automated preparation of a large number of samples and then screening of their properties in multi-well plates, improves the efficiency of research in many scientific areas, e.g., catalyst screening, food processing, chemical synthesis, drug discovery, absorption, distribution, metabolism, and excretion and toxicological and cell based screening. The three most common detection techniques used in HTS are UV-VIS absorbance, fluorescence and luminescence. In this review, we summarize some recent trends and developments in the construction of optical chemical biosensors used in high throughput screening of drugs. Also, we have included environmental, biological and other medical applications of biosensors. © 2007 Bentham Science Publishers Ltd.",Missing information
i_2220,Contradiction,"Mechanisms and Enhancements: Biomass Production: Tobacco's high biomass production is a critical factor in its effectiveness for phytoremediation, as it allows for greater total metal uptake .","Phytoremediation has attracted much more attention in environmental cleanup. The relatively low biomass and slow growth of metal hyperaccumulators restrict the efficiency of phytoextraction of heavy metals using these plants. The objective of this study was to compare the efficiency of phytoextraction of cadmium (Cd) with the hyperaccumulator Thlaspi caerulescens and three high biomass plant species (India mustard, tobacco and sunflower). A pot experiment was conducted using a soil contaminated with Cd (2. 87 mg-kg<sup>-1</sup>) from past application of manure and fertilizer with Cd for long time. The results showed that the Thlaspi caerulescens had a higher ability of Cd accumulation than other three plants species. The Cd concentration in the shoots of Thlaspi caerulescens reached 43.7 mg-kg<sup>-1</sup>, whereas only 1.7 mg-kg <sup>-1</sup>Cd was found in the shoots of sunflower. Cd concentration in the shoots of Thlaspi caerulescens was 10, 27 and 56 times of that of tobacco, Indian mustard, and sunflower, respectively. However, tobacco had the highest biomass, which was 35, 3 and 2 times of Thlaspi caerulescens, Indian mustard and sunflower, respectively. Total uptake of Cd from the soil was 117, 35, 30 and 10 ±g'pot<sup>-1</sup> for tobacco, Thlaspi caerulescens, India mustard and sunflower, respectively. Phytoextracion efficiency was 1%, 0.6%, 0.5% and 0.08% for tobacco, Thlaspi caerulescens, India mustard and sunflower, respectively. Furthermore, there was no significant difference in either total or extractable Cd concentration in the soil after the four plant species were harvested.
[2]: One of the most grievous heavy metal pollutants in the environment is cadmium (Cd), which is not only responsible for the crop yield loss owing to its phytotoxicity, but also for the human health hazards as the toxic elements usually accumulate in the consumable parts of crop plants. In the present study, we aimed to isolate and functionally characterize the OsMTP1 gene from indica rice (Oryza sativa L. cv. IR64) to study its potential application for efficient phytoremediation of Cd. The 1257 bp coding DNA sequence (CDS) of OsMTP1 encodes a ~46 kDa protein belonging to the cation diffusion facilitator (CDF) or metal tolerance/transport protein (MTP) family. The OsMTP1 transcript in rice plant was found to respond during external Cd stress. Heterologous expression of OsMTP1 in tobacco resulted in the reduction of Cd stress-induced phytotoxic effects, including growth inhibition, lipid peroxidation, and cell death. Compared to untransformed control, the transgenic tobacco plants showed enhanced vacuolar thiol content, indicating vacuolar localization of the sequestered Cd. The transgenic tobacco plants exhibited significantly higher biomass growth (2.2-2.8-folds) and hyperaccumulation of Cd (1.96-2.22-folds) compared to untransformed control under Cd exposure. The transgenic plants also showed moderate tolerance and accumulation of arsenic (As) upon exogenous As stress, signifying broad substrate specificity of OsMTP1. Together, findings of our research suggest that the transgenic tobacco plants overexpressing OsMTP1 with its hyperaccumulating activity and increased growth rate could be useful for future phytoremediation applications to clean up the Cd-contaminated soil.",Misrepresentation
s_1103,Entailment,"General Ultrasound Image Segmentation: Machine Learning Approaches: Machine learning models, including Support Vector Machines and Convolutional Neural Networks, have been applied to classify and segment thyroid textures, showing high accuracy and potential for clinical application .","The thyroid is one of the largest endocrine glands in the human body, which is involved in several body mechanisms like controlling protein synthesis, use of energy sources, and controlling the body's sensitivity to other hormones. Thyroid segmentation and volume reconstruction are hence essential to diagnose thyroid related diseases as most of these diseases involve a change in the shape and size of the thyroid over time. Classification of thyroid texture is the first step toward the segmentation of the thyroid. The classification of texture in thyroid Ultrasound (US) images is not an easy task as it suffers from low image contrast, presence of speckle noise, and non-homogeneous texture distribution inside the thyroid region. Hence, a robust algorithmic approach is required to accurately classify thyroid texture. In this paper, we propose three machine learning based approaches: Support Vector Machine; Artificial Neural Network; and Random Forest Classifier to classify thyroid texture. The computation of features for training these classifiers is based on a novel approach recently proposed by our team, where autoregressive modeling was applied on a signal version of the 2D thyroid US images to compute 30 spectral energy-based features for classifying the thyroid and non-thyroid textures. Our approach differs from the methods proposed in the literature as they use image-based features to characterize thyroid tissues. We obtained an accuracy of around 90% with all the three methods.
[10]: We aimed to develop deep learning models based on perinodular regions' shear-wave elastography (SWE) images and ultrasound (US) images of thyroid nodules (TNs) and determine their performances in predicting thyroid cancer. A total of 1747 American College of Radiology Thyroid Imaging Reporting & Data System 4 (TR4) thyroid nodules (TNs) in 1582 patients were included in this retrospective study. US images, SWE images, and 2 quantitative SWE parameters (maximum elasticity of TNs; 5-point average maximum elasticity of TNs) were obtained. Based on US and SWE images of TNs and perinodular tissue, respectively, 7 single-image convolutional neural networks (CNN) models [US, internal SWE, 0.5 mm SWE, 1.0 mm SWE, 1.5 mm SWE, 2.0 mm SWE of perinodular tissue, and whole SWE region of interest (ROI) image] and another 6 fusional-image CNN models (US + internal SWE, US + 0.5 mm SWE, US + 1.0 mm SWE, US + 1.5 mm SWE, US + 2.0 mm SWE, US + ROI SWE) were established using RestNet18. All of the CNN models and quantitative SWE parameters were built on a training cohort (1247 TNs) and evaluated on a validation cohort (500 TNs). In predicting thyroid cancer, US + 2.0 mm SWE image CNN model obtained the highest area under the curve in 10 mm < TNs ≤ 20 mm (0.95 for training; 0.92 for validation) and TNs > 20 mm (0.95 for training; 0.92 for validation), while US + 1.0 mm SWE image CNN model obtained the highest area under the curve in TNs ≤ 10 mm (0.95 for training; 0.92 for validation). The CNN models based on the fusion of SWE segmentation images and US images improve the radiological diagnostic accuracy of thyroid cancer.",Entailment
i_1484,Entailment,"Adolescent Girls (16-18 years): MUAC correlated with BMI, but specific values were not provided .","Background. The use of mid-upper-arm circumference (MUAC) as a screening measure for assessing undernutrition has the following advantages: makes use of simple equipment, is easy to carry to field sites, and requires minimal training. MUAC cutoffs for undernutrition are available for children and adults but not for adolescents. Objective. To compare MUAC with BMI in assessing undernutrition among adolescent girls and to evaluate the sensitivity and specificity of MUAC as a tool in assessing their nutritional status. Methodology. A total of 565 unmarried adolescent girls of both school-going and non-school-going age (16-18 years old) from the urban slums of Pune city Maharashtra, India, were recruited for the cross-sectional study. Anthropometric measurements, including height, weight, and MUAC were recorded. Results. The percentage of adolescents who were malnourished was 4.8% according to BMI and 5.0% for MUAC. BMI highly correlated with MUAC (r = 0.593), and MUAC as a screening tool showed 28.57% sensitivity and 96.46% specificity. Further studies among different age groups need to be carried out to arrive at standard cutoffs for MUAC. © 2013 The Author(s).",Entailment
i_1499,Contradiction,"Lung Cancer: Psychological Distress: Lung cancer survivors report significant psychological distress, which can persist long after treatment. This distress is associated with factors such as age at diagnosis, time since diagnosis, and history of recurrence .","Purpose Fear of cancer recurrence (FCR) is a common psychological issue in breast cancer (BC) survivors during early survivorship but whether the same is true among long-term survivors has yet to be empirically evaluated. This study investigated FCR level, its associated factors, and impact on quality of life (QoL) in long-term BC survivors. Materials and Methods Participants included women diagnosed with BC between 2004 and 2010 at two tertiary hospitals. Survey was conducted in 2020. The study measured FCR with the Fear of Cancer Recurrence Inventory and other patient-reported outcomes, including depression and cancer-related QoL. Logistic regression was used to identify factors associated with FCR, and structural equation modeling was conducted to explore the impact of FCR on other outcomes. Results Of 333 participants, the mean age at diagnosis was 45.5, and 46% experienced FCR. Age at diagnosis ≤ 45 (adjusted odds ratio [aOR], 2.64; 95% confidence interval [CI], 1.51 to 4.60), shorter time since diagnosis (aOR, 1.75, 95% CI, 1.08 to 2.89), and having a history of recurrence (aOR, 2.56; 95% CI, 1.16 to 5.65) was associated with more FCR. FCR was significantly associated with an increased risk of depression (β=0.471, p < 0.001) and negatively impacted emotional functioning (β=-0.531, p < 0.001). In addition, a higher FCR level may impair overall health-related QoL in long-term BC survivors (β=-0.108, p=0.021). Conclusion Ten years after diagnosis, long-term BC survivors still experienced a high level of FCR. Further, the negative impact of FCR on QoL and increased depression risk require an FCR screening and appropriate interventions to enhance long-term BC survivors' QoL.",Entity error
i_387,Entailment,"Healthcare: Surgical Planning: AI assists in planning complex surgical procedures, improving precision and outcomes .","Artificial intelligence (AI) is making its way back into the mainstream of corporate technology, this time at the core of business systems which are providing competitive advantage in all sorts of industries, including electronics, manufacturing, marketing, hu-manresource, financial services software, medicine, entertainment, engineering and communications. Designed to leverage the capabilities of humans rather than replace them, today's AI technology enables an extraordinary array of applications that forge new connections among people, computers, knowledge, and the physical world. Some AI enabled applications are information distribution and retrieval, database mining, product design, manufacturing, inspection, training, user support, surgical planning, resource scheduling, and complex resource management. AI technologies help enterprises reduce latency in making business decisions, minimize fraud and enhance revenue opportunities.",Entailment
i_1644,Unverifiable,"Impact on Forests: Forest Composition Changes: The Mediterranean region has seen a shift towards more drought-resistant vegetation types, such as shrubs, while forest areas have decreased .","[17] Increasing temperatures and recent changes in runoff regimes observed in Central Europe might alter the growth and relative water uptake of floodplain trees. To predict responses of floodplain forests to climate change, it is necessary to determine the climatic controls over tree growth and vessel anatomy. We analysed the responses of tree-ring width and earlywood vessel anatomical parameters (average vessel lumen area, vessel density and total vessel lumen area) of pedunculate oak (Quercus robur L.) growing in a floodplain to hydroclimatic conditions represented by temperature, the drought index (scPDSI), river discharge, groundwater level, and occurrence of floods and drought events. Site chronologies were assembled for floodplain and reference sites and, subsequently, correlated with time series of hydroclimatic conditions. Our results show that radial growth of floodplain trees is particularly positively influenced by temperature during the growing season and during previous year's summer. By contrast, the growth of reference trees is highly drought-limited. Earlywood average vessel lumen area chronologies from both floodplain and reference sites share a positive temperature signal from January to April. However, the effect of water availability (indicated by the drought index) on vessel size is mostly negative for floodplain trees (with a maximum response to the autumn of the year preceding tree-ring formation) and positive or non-significant for reference trees. Vessel density chronologies contain the inverse environmental information as tree-ring width, however, with amplified negative correlations with current year temperatures at floodplain sites. Total vessel area is associated mostly with temperature in previous May and June. The drought index recorded exactly the same information in tree-rings as did river discharges and groundwater levels. The results of both correlation and trend analysis evidence that tree-ring width of floodplain Q. robur unambiguously increases with increasing temperature; on the other hand, droughts can become a serious problem affecting the productivity of reference trees growing in more distal parts of the lowland. Vessel size of Q. robur growing outside the floodplain recently tends to increase with increasing temperatures, making xylem more effective at water transport but also more vulnerable to cavitation.",Unrelated and unverifiable
s_1270,Entailment,"Monitoring and Equipment: The availability of pulse oximetry, non-invasive blood pressure monitoring, and capnography has significantly improved patient safety by enabling better monitoring of physiological parameters .","Background: Patient safety is a global concern, and anaesthesiologists are critically involved in patient safety-related measures and practices. Although anesthesia service has improved a lot over the last few decades, the information on the anesthesia practice and patient safety in India is lacking. The present survey was aimed to get the information on these aspects. Methods: A cross-sectional, questionnaire-based survey including both postgraduate trainees and anaesthesiologists, working across the different hospitals of India was conducted during February–May 2019. Google form was used as the survey; responses were directly downloaded as an Excel file and calculated in absolute numbers and percentages. Autonomous teaching institutes (ATI) were taken as standard, and Fisher's exact test was used for comparisons; P < 0.05 was considered significant. Results: Six-hundred (86.1%) responses were included for analysis. Pulse oximetry and non-invasive blood pressure (NIBP) were available in nearly 99% set-ups, but end-tidal carbon-di-oxide (EtCO<inf>2</inf>), temperature, oxygen, and anesthesia gas analyzer were lacking. ATI and corporate teaching hospitals were having almost all standard monitoring, but patient safety-related advanced equipment and medications were not present in many of the hospitals. The lack was highest in both public and private non-teaching hospitals (P < 0.0001). Conclusion: Patient safety and anesthesia-related services in India are unsatisfactory. Except for pulse oximetry and NIBP, the public and private sector non-teaching hospitals were lacking even the standard monitoring. Referral and top-level corporate and public sector institutes also have scope for improvement.
[5]: Critical incidents are events that cause harm or have the potential to cause harm if not recognized and acted upon. Respiratory complications can cause death or serious neurological disability when they occur. The incidence of these complications has decreased during the past few decades. A combination of improved training, availability of pulse oximetry and capnography, and emphasis on patient safety has brought about this improvement in outcome. A thorough preoperative assessment of the patient, planning a suitable anaesthetic technique, checking the availability and functioning of all necessary equipment, seeking appropriate help and advice, familiarity with the equipment to be used and vigilance in monitoring during anaesthesia are the key factors for the avoidance or early detection and management of respiratory complications during induction and maintenance of general anaesthesia. Unexpected respiratory complications that may occur include hypoxaemia, airway obstruction, laryngospasm, bronchospasm, pulmonary oedema and pneumothorax. A guide to the identification and management of these conditions is outlined in this article. © 2007 Elsevier Ltd. All rights reserved.",Entailment
i_1872,Entailment,"Recycling and Waste Management: Using recycled materials, such as fly ash, can mitigate the environmental impact of brick production and promote sustainable practices, and it is likely that the adoption of these materials could also enhance the overall economic viability of brick manufacturing in developing regions .","The life cycle assessment of the ABC (Pvt) Ltd brick manufacturing plant has considered land use, fossil resource scarcity, water consumption, global warming and fine particulate matter formation as the impact categories for assessment, with clay mining and coal as the input flows with the highest significant contributions to environmental load. The phase of clay mining (65.8%) is significantly impacting on all the investigated impact categories followed by brick moulding (24.8%) and brick roasting (9.4%) phases, respectively. Hotspots were assessed to identify potential for resource efficiency and circular economy at ABC bricks, Zimbabwe. It can be concluded that ABC is severely polluting the air with emissions above the Environmental Management Agency (EMA) standards for SO<inf>2</inf>, CO, PM and NO<inf>x</inf> thus putting kiln workers at risk of respiratory diseases. The calculated Air Quality Index (AQI) ranks CO as the most affecting pollutant with an average score of ∼600. Clay production efficiency was also determined, and an analysis revealed that extrusion and clamping stage contributed highly to the clay losses during brick moulding. Therefore, focus must be placed on these process steps to reduce raw material losses. Furthermore, an environmental waste (fly ash) was used in different weight percentage ratios of 10%, 20% and 100% to substitute clay. The increase of the fly ash content in the brick making process proved to significantly reduce the environmental load among the selected impact categories. ABC uses clay as its main raw material hence the high demand for clay. Strategies should include accounting of used clay daily and raw materials substitution. If ABC uses fly ash from its brick kilns and from other thermal power plant boilers to mix with clay in brick production, then the quantity of clay demanded will be reduced. Using fly ash will reduce rate of clay extraction while at the same time solving the problem of fly ash disposal in Zimbabwe. This circular option will ultimately result in reduced pit expansion, hence reducing top-soil loss and environmental degradation. It should not be disregarded that top-soil loss in turn affects food security. By adopting appropriate technologies, implementing resource efficiency, and designing circular economy patterns, the brick manufacturing sector in Zimbabwe may not only reduce production waste but also comply with enforced environmental protection legislation.
[2]: Manufacturing of bricks, using clay or fly ash, is one of the major contributors to greenhouse gas emissions as their manufacturing involves utilization of coal and cement. To overcome this limitation, alternative construction materials are developed by author using industrial and agro wastes like cotton mill waste, recycled paper mill waste, and rice husk ash. This work aims at performing a sustainability assessment of burnt clay bricks and bricks made of industrial and agro wastes used for brickwork in a low-cost house. The criteria considered for the assessment are economic, environmental, social, and technical aspects for manufacture of bricks and use of different bricks for brickwork. For the evaluation of environmental criterion, a life cycle assessment (LCA) tool is used. Overall sustainability index (SI) is calculated for alternatives based on the various criteria using MIVES approach. The relative SIs of clay and fly ash bricks, were 0.25 and 0.26, respectively. Overall, bricks made of industrial and agro wastes are found more sustainable with the highest SI for cotton waste bricks (0.94). Sensitivity analysis also confirmed that brickwork from waste based bricks is more sustainable compared to brickwork made from clay brick or fly ash brick.",Entailment
i_1272,Entailment,"Key Insights: Future Directions: While telemedicine has shown some potential, it is unlikely to be effective long-term without a complete overhaul of existing healthcare systems and regulations, which may not be feasible .","During the COVID-19 crisis, telemedicine was at the center of the health management systems in the canton of Geneva. Telemedicine contributed to the triage and follow-up of patients with a suspected or confirmed diagnosis of COVID-19, as well as to the coordination of different healthcare actors in the patient's trajectory. New partnerships and reinforcement of coordination in the Geneva healthcare and social care networks with an unprecedented use of telemedicine tools were able to ensure patient care while preserving frontline healthcare providers. Telemedicine has benefited during this time from a temporary relaxation of measures and regulations governing its practice, encouraging its deployment in a crisis situation. However, for these tools to be effective, they need to become an integral part of our healthcare systems.
[8]: Background: The COVID-19 pandemic has led to a surge in the use of telemedicine as a means of delivering healthcare services remotely. Healthcare providers play a key role in the adoption and implementation of telemedicine for its effectiveness. Despite its benefits, there have been unclear concerns about its effectiveness and acceptance in the process of implementing telemedicine. The objective of the study was to assess health professionals' perceptions towards the implementation of telemedicine during the COVID-19 pandemic. Methods: A cross-sectional study design was conducted among eight hundred forty-five study participants from December 2020 to February 2021. A pre-test was performed on 5% of the total sample size, and the quality of the data was ensured by checking its completeness and consistency. Descriptive statistics and bivariable and multivariable logistic regression were used. The Variables with a P-value equal to or less than 0.25 in bivariable logistic regression were entered into a multivariable logistic regression, and model fitness was assessed. Result: The study revealed that 60.9% of professionals had a good perception toward telemedicine implementation, with an 87.2% response rate. Health professionals with IT support staff, ICT training, who use social media platforms regularly, and availability of computer or smartphone within/outside their health facility were 4.7, 3.3, 3.7, and 13.2 times more likely to have a positive association towards telemedicine implementation respectively. Conclusion: More than half of the health professionals had a good perception of telemedicine. Social media use, ICT training, computer accessibility, and the presence of IT support staff were all found to have positive associations with the telemedicine perception. In the era of the COVID-19 pandemic, the government should take the initiative to strengthen opportunities for health professionals to learn and apply telemedicine in their medical practice by providing ICT training, IT infrastructure and support staff, improving computer access, and recommending health professionals' positive use of social media in the health facility.",Entailment
s_375,Entailment,"Applications: Understanding biological systems, drug discovery, and disease research .","Biomedical knowledge graphs (KGs), which can help with the understanding of complex biological systems and pathologies, have begun to play a critical role in medical practice and research. However, challenges remain in their embedding and use due to their complex nature and the specific demands of their construction. Existing studies often suffer from problems such as sparse and noisy datasets, insufficient modeling methods and non-uniform evaluation metrics. In this work, we established a comprehensive KG system for the biomedical field in an attempt to bridge the gap. Here, we introduced PharmKG, a multi-relational, attributed biomedical KG, composed of more than 500 000 individual interconnections between genes, drugs and diseases, with 29 relation types over a vocabulary of ~8000 disambiguated entities. Each entity in PharmKG is attached with heterogeneous, domain-specific information obtained from multi-omics data, i.e. gene expression, chemical structure and disease word embedding, while preserving the semantic and biomedical features. For baselines, we offered nine state-of-The-Art KG embedding (KGE) approaches and a new biological, intuitive, graph neural network-based KGE method that uses a combination of both global network structure and heterogeneous domain features. Based on the proposed benchmark, we conducted extensive experiments to assess these KGE models using multiple evaluation metrics. Finally, we discussed our observations across various downstream biological tasks and provide insights and guidelines for how to use a KG in biomedicine. We hope that the unprecedented quality and diversity of PharmKG will lead to advances in biomedical KG construction, embedding and application.",Entailment
i_674,Unverifiable,"Advanced BMS can also predict battery health and remaining useful life, aiding in timely maintenance and preventing failures .","Lithium-ion battery, with its high-volume energy density and charging efficiency, has already been considered as the future of the battery field. However, battery safety accidents happen a lot recent years, not only because of incorrect use but also due to failed thermal management. Thus, the battery safety problem has become an emergent issue for human daily lives. In this research, the author compares three main Remaining Useful Life (RUL) prediction approaches of Li-ion battery, including Analysis Approach, Numerical Simulation and Artificial Intelligence (AI) Algorithms. Based on the open-source dataset provided by TOYOTA where it takes 70% degeneration of battery capacity as the End of Life (EOF), the author uses Back Propagation Neural Network (BPNN) and COMSOL Multiphysics simulation application to propose An Online Prediction System of Lithium-ion Battery Safety from given charge policy to RUL. At the same time, the influences of State of Charge (SoC), Internal Resistance and Average Temperature has been analysed. However, the prediction accuracy still needs to improve in order to achieve industrial requirement. Further study of collaborative optimization of neural networks and numerical simulation will be considered in the future.",Related but unverifiable
s_1671,Entailment,"Immunostimulants for Fish: Euphorbia hirta (Cyprinus carpio): Effects: Enhanced phagocytic ratio and significant immune response at higher concentrations, suggesting that lower concentrations may also be effective . Concentration: Effective at 50 g/kg diet.","Context: Infectious diseases are one of the major factors affecting the production of fish worldwide. The pathogens (especially bacteria) affect the immune system of fish and the administration of immunostimulants can increase resistance to infectious diseases by enhancing both specific and nonspecific defense mechanisms. Objective: In the present study, we have conducted an experiment on the pathogen-infected Cyprinus carpio Linn. (Cyprinidae), using Euphorbia hirta Linn. (Euphorbiaceae) plant leaves as immunostimulants. Materials and methods: The aqueous extract of the leaves was prepared and the immunostimulant action was recorded by giving different concentrations of plant extract supplemented diet. Results and discussion: The results obtained from the studies show that the higher concentration of the extract (50 g/kg diet) provided significant immune response (specific and nonspecific) on the fish. The 50 g/kg leaf extract of E. hirta enhanced the phagocytic ratio on 10th and 15th day after the infection. The results of the specific and nonspecific immunostimulation studies are statistically significant. Conclusion: This work will guide the researchers for the discovery of significant aquaculture nutrients to improve the immunostimulant action on fish. © 2011 Informa Healthcare USA, Inc.",Entailment
s_2108,Entailment,"Inferred Insights for Lebanon: Agricultural Impact: Given the findings from the ULRB, it is likely that agricultural activities significantly contribute to nitrate levels in Lebanon's groundwater .","This study aims to determine the extent of groundwater damage in the Upper Litani River Basin (ULRB) after years of water mismanagement and overfertilization in what is considered to be Lebanons largest fertile area. Physical and chemical samples were collected between 2005 and 2010 and analyzed using ""The Standard Methods for the Examination of Water and Wastewater"" (APHA, AWWA) in order to determine the extent of this pollution. The parameters included pH, ammonia, nitrate, nitrite, sulfate, phosphate, dissolved oxygen, and total dissolved solids. Copyright 2012 Mark Saadeh et al.",Entailment
i_1473,Entailment,"Physical Activity: Implant Orientation: The orientation of the implant during surgery is crucial. Incorrect orientation can increase contact pressures, leading to higher metal ion levels in the body. This suggests that not just the level of activity, but also the precision of the surgical technique, plays a significant role in the release of metal particles .","Metal on metal wear has attracted significant media attention in recent years, owing to the issues associated with adverse reactions to metal ion debris, with subsequent revision arthroplasty procedures. To date, implant orientation has been the key. Studies on ceramic implants have utilised mathematical models in order to assess contact surface areas and pressures generated within the hip joint and their correlation to wear. To date, this has not been undertaken in metal on metal hips. We applied a previously published Hertzian ball in plane model to a cohort of metal on metal hip replacement patients from a single surgeon practice to evaluate the effect of contact pressures on metal ion levels. Statistical analysis was performed using SPSS v20. A total of 58 patients, with a male preponderance (65%), from a single surgeon practice were identified and recruited. Anaverage age of 52 (±9) years, mean body mass index 28.91 kg/m<sup>2</sup> (±4.41) with no proportional difference between groups were noted (p > 0.05). Mean ion levels were calculated for both cobalt 34.93(±21.90) nmol/L and chromium 40.10(±25.85) nmol/L. Implant orientation was recorded and, using the method described, contact pressures were calculated. Correlation testing revealed that abduction angle was significantly associated with cobalt (r=0.344, p = 0.040) and chromium (r = 0.336, p = 0.045) levels, but that the contact pressures were not associated with metal ion levels (Co, r = '0.033, p = 0.803, Cr, r = '0.095, p = 0.479).Our results reinforce that it is neither the body mass index nor the contact surface area or pressure generated that increases metal ion level, and that abduction angle remains essential in metal ion generation. The surgeon should be vigilant in ensuring correct implant orientation intra-operatively in order to reduce metal ion generation.",Entailment
i_1968,Contradiction,"Conclusion: While global warming is often cited as a pressing issue, it is primarily a natural phenomenon that has been exaggerated by human activities. The environmental and health challenges attributed to it may not be as severe as suggested, indicating that the need for urgent and coordinated efforts to mitigate its effects could be overstated .","Global warming refers to an average increase in the earth's temperature, which in turn courses in climate, Contribution of green house gases to floral warming, carbon dioxide, methane, Chloro-Fluro-Carbon (CFCs) and Nitrous oxides act like a green house, warming the earth surface. The rise in earth's temperature due to increase in carbon dioxide emission has been speculated since 1800's and its effect house been analysed for almost a century. The foremost cause for transformation of global environment is the ever increasing number of human beings since 1990, the number of people has more than tripled. According to UN projection, the global population increased from 205 billion to 5 billion in less than four decades (i.e.) from 1950 to 1990 and is expected to reach 10 billion by the end of next century. Developing countries account for only 1.29 billion tones of CO<inf>2</inf> emission 1985 and projected increase for 2005 in 5.47 billion tones of carbon oxide was emitted with is projected to increase to 12.18 billion tones by 2025. The CO<inf>2</inf> emissions are projected to increase by 2.6 percent annually.
[2]: Scientific research confirms that global warming is the result of direct and indirect human activities that determines changes in composition of the global atmosphere and which overlap to natural climate variability observed over comparable period of time. The risk of serious climate change impacts suggests that urgent action is necessary to significantly reduce GHG emissions in the coming decades. The paper objectives are the development and evaluation of mitigation/adaptation (M/A) policy portfolios and the prioritisation of research needs and gaps. In this article, the authors developed three mitigation/adaptation climate change policy scenarios for Romania: Business as Usual (BAU), Optimistic (OPT) and Pessimistic (PES). The result of the assessment presents the best policy portfolio for Romania, in terms of achieving the national 2020 targets meaning 20% emission reductions (base year 1989), 19% increase of the energy efficiency (base year 2005) and 24% share of RES in the final energy consumption.
[3]: Global warming which is a natural phenomenon has given rise to climate change as a result of man's contribution to this phenomenon. The roles of humans to global warming in two-fold: Firstly, through industrial activities which have caused increase in the concentration of CO<inf>2</inf> and other green house gases thereby exacerbating the degree of global warming of the Earth's atmosphere to dangerous levels. The second concern is the denuding of Earth's of the Earth's forest; thereby reducing the Earth's potential to absorb the increase in CO<inf>2</inf>. Other effects are loss of biodiversity, desertification, genetic erosion, loss of soil fertility and flooding. The way out of the challenge is basically through adaptation and mitigation. Impacts of climate change are now inevitable hence the need to develop stress and drought tolerant species/varieties. Afforestation programs, Community forestry, Agroforestry practices would serve as mitigation strategies for this harmful global phenomenon. This paper therefore highlights some negative effects of climate change on food security, health, biodiversity and the threats they pose on Nigeria. It also looked into likely causes of climate change and the role of forest trees on how they mitigate the effects of climate change. © 2010 IEEE.",Opposite meaning
s_89,Entailment,"Additionally, AI technologies such as unsupervised genetic algorithms are used in geological risk assessment and optimization of drilling operations, which can be adapted for land allocation purposes to minimize uncertainties and improve efficiency .","This paper presents how Artificial Intelligence (AI) / Machine Learning (ML) technology uses unsupervised genetics algorithms in Exploration, Drilling Operations, Field Appraisal, Development and multiple 3D seismic volumes comparisons to minimize geological risk and uncertainty resulting in increased capital efficiency. We will present a high level overview of why this technology was invented and how it works. We will show you how you can use it to significantly reduce the time to achieve your organizational goals while reducing geotechnical risk and uncertainty and optimize the cycle time from Lead to Production. Outputs include a comprehensive analysis of your entire 3D Seismic Data Volume to identify and high grade, quality leads and prospects with high resource potential in the near, medium and long term. This approach will allow an evaluation of the field geological risk (reservoir distribution, trap, seal, source, hydrocarbon migration pathway from source into reservoir) and initial possible hydrocarbon content/type evaluation (e.g. DHI evaluation) without disrupting your current workflow. The results will quickly delineate possible structural and stratigraphic targets. This will also provide the Production Asset with additional support in their appraisal and development drilling programmes. Optimally place horizontal wells and injectors / offtakes in Improved Oil Recovery/Enhanced Oil Recovery (IOR / EOR) projects in areas of the field having the highest reservoir continuity to optimize the cycle time from concept to production. The case studies and examples presented will demonstrate how the technology and approach serve to increase the probability of success leading to increased capital efficiency and profitability.",Entailment
s_387,Unverifiable,"Emerging Trends: Interdisciplinary Communication Models: The development of interdisciplinary communication models for research and software engineering facilitates the practical application of research concepts in operational environments, improving system usability and user satisfaction. Furthermore, it is believed that these models could lead to innovative approaches in addressing antimicrobial resistance challenges in neonatal intensive care units .","Introduction: Neonatal intensive care units (NICUs) have complex patients in terms of their diagnoses and required treatments. Antimicrobial treatment is a common therapy for patients in NICUs. To solve problems pertaining to empirical therapy, antimicrobial stewardship programs have recently been introduced. Despite the success of these programs in terms of data collection, there is still inefficiency in terms of analyzing and reporting the data. Thus, to successfully implement these stewardship programs, the design of antimicrobial resistance (AMR) surveillance systems is recommended as a first step. As a result, this study aimed to design an AMR surveillance system for use in the NICUs in northwestern Iranian hospitals to cover these information gaps. Methods: The recommended system is compatible with the World Health Organization (WHO) guidelines. The business intelligence (BI) requirements were extracted in an interview with a product owner (PO) using a valid and reliable checklist. Following this, an AMR surveillance system was designed and evaluated in relation to user experiences via a user experience questionnaire (UEQ). Finally, an association analysis was performed on the database, and the results were reported by identifying the important multidrug resistances in the database. Results: A customized software development methodology was proposed. The three major modules of the AMR surveillance are the data registry, dashboard, and decision support modules. The data registry module was implemented based on a three-tier architecture, and the Clinical Decision Support System (CDSS) and dashboard modules were designed based on the BI requirements of the Scrum product owner (PO). The mean values of UEQ measures were in a good range. This measures showed the suitable usability of the AMR surveillance system. Conclusion: Applying efficient software development methodologies allows for the systems' compatibility with users' opinions and requirements. In addition, the construction of interdisciplinary communication models for research and software engineering allows for research and development concepts to be used in operational environments.",Related but unverifiable
s_744,Entailment,"Battery Management Systems (BMS): Monitoring and Control: A123's battery systems are integrated with advanced BMS to monitor and control various parameters such as voltage, temperature, and state of charge (SOC) .","The battery consists of one or more electrochemical cell and it transforms stored energy into electricity. Batteries are widely used in flash lights, smart phones and electric cars. Battery Management System (BMS) plays a prominent role in monitoring and controlling of rechargeable batteries. The key terminologies in BMS are as follows, the prime selection of battery chemistry is essential for meticulous applications followed by technologies in battery management systems it includes battery monitoring, diagnostics,control of charging and discharging cycle, state estimate, protection, equalization of charge, heat control and management, early failure detection and assessment to improve overall system performance. An effective BMS protects the battery from damage, forecasts lifetime and maintains battery efficiency. BMS can optimize downtime and battery lifespan per discharge cycle. Finally the outcome of this paper is to identify the best battery chemistry, charging methods, battery model, cell balancing and SOC estimation techniques.
[5]: Battery management system (BMS) is the most important part of an electronic vehicle (EV), and the management module for single cell is the most important collection part of BMS. It provides cells' data and realizes cells management for BMS. In this paper, the design and realization of the management module for single cell is presented. It can collect real-time voltage and temperature data of cells, and carry on the necessary processing for such data, and then upload these data to the main control module in the battery management system. The design can also equalize the cells, and made their voltage remain in a standard. For the proposed design scheme, the microcontroller PIC24F16KA101 is used as the core part, and the multi-cell addressable battery stack monitor LTC6802 is utilized as the collection part. Moreover, the design of multi-channel data collection and management system, and the design of software and hardware for interface are given. The practical experimental results show that the system can realize the real-time multi-channel signal collection, offer useful data for battery management system, and equalize the cells at power on or power off situation, so as to guarantee the battery consistency. © (2011) Trans Tech Publications.",Entailment
i_413,Unverifiable,"Real-Time Processing: Cloud-based IoT solutions enable real-time data analysis and decision-making, which is crucial for applications requiring immediate responses, and it is likely that advancements in AI will further enhance the accuracy of these real-time analyses in the near future .","The advent of the Internet of Things (IoT) has led to the generation of tremendous amounts of data from various sources. Cloud based systems are effective in storage and application of machine learning algorithms on such datasets. However, in some cases it is important to enable real time processing for making immediate decisions. There are many applications which require instantaneous analysis of the generated data for remedies in event of an anomaly. Data associated with such use cases remains significant only for a short duration of time. Various electronic sensors, e.g. Temperature, Moisture, Air Quality, Pressure, Wind Velocity etc. present in a Wireless Sensor Network generate streams of values. It can be processed using pipelines which provide prompt and quick analysis for decision making. Stream Processing Systems can be helpful in such cases as they analyse data streams within a few milliseconds to a few seconds. In this paper, we discuss an event based processing of streaming data from air pollution sensors to create a real time anomaly detection system. To reduce the delays associated with the generation of alarms in our pipeline, Apache Foundation's Stream Processing Tools, Kafka and Flink were used for operations on our streams. To further accelerate the process, all the analysis is conducted on an embedded edge computing gateway device rather than sending data to the cloud for batch processing. The results are obtained in the form of a geographical map visualization using ELK stack. The map highlights the coordinates of the location with an unhealthy air quality index in real time.
[5]: The process of acquiring, analysing and managing data obtained by sensors and actuators in industrial environments can benefit from modern Cloud-based platforms towards a complete implementation of the Industrie 4.0 concept. The analysis of huge data sets produced by these sensors (Big Data) could allow quick and accurate decision making. For example, productivity improvements can be achieved by analysing device performance and degradation for real-time feedback on configuration and optimization. This work proposes a Cloud-based architecture for Internet of Things (IoT) applications to improve the deployment of smart industrial systems based on remote monitoring and control. By using specific technologies available as a service, we demonstrate the proposed architecture on an automated electric induction motor use case. This approach includes layers for sensor network data gathering, data transformation between standard protocols, message queuing, real-time data analysis, reporting for further analysis, and real-time control. Particularly, by using the proposed architecture, we remotely monitored, controlled and processed data produced by sensors and actuators coupled to the motor. Preliminary results indicate this foundation can support predictive methods and management of automated systems in the Industrie 4.0 context.",Related but unverifiable
i_2183,Entailment,"Horizontal Transmission: Some animals acquire their symbionts from the environment. This method is less common in insects but is seen in the bean bug Riptortus pedestris, which acquires its gut symbionts from the soil .","How host organisms evolved and maintain specific mutualisms with microorganisms is a fundamental question that is subject to intensive research. In the large majority of insect mutualisms, the host-microbe specificity is maintained by a ""partner fidelity"" mechanism, mainly through direct symbiont transmission from mother to offspring. Such vertical symbiont transmission is remarkably diverse in insects, including ovarial transmission, milk-gland transmission, coprophagy, egg-smearing, and capsule transmission. In contrast to the insect-microbe symbioses, many animals and plants do not vertically transmit their symbionts but acquire symbionts from ambient environments every generation. Sophisticated ""partner choice"" mechanisms are at play to establish these mutualisms and maintain them over evolutionary timescales. This symbiont transmission mode, called horizontal transmission or environmental acquisition, is rarely found in insects that maintain specific associations, but recent studies have described this type of symbiosis in a few insect groups. The symbiosis between the bean bug Riptortus pedestris and its gut symbiont Burkholderia insecticola is one of the model systems that is intensively studied to understand how host-symbiont specificity and mutualistic interactions are maintained in insects with horizontal symbiont transmission. Phylogenetic analyses of symbionts in natural insect populations and bacterial inoculation tests in the laboratory revealed a high degree of specificity in this symbiosis while mutant screening of the symbiotic bacterium, genomics and transcriptomics, and histological observations have identified underpinning morphological, genetic and molecular bases. In this chapter, we focus on symbiont transmission modes and mechanisms observed in the amazing diversity of microbial symbioses in insects, highlighting the ways in which they have likely evolved.",Entailment
i_994,Unverifiable,"Heat Transfer: The heat flux into the burning phase and the conductive heat feedback from the flame to the fuel surface are critical. For instance, the conductive heat flux averaged over the burning surface can significantly impact the flame spread rate, and it is plausible that variations in ambient pressure could further influence these dynamics .","The paper presents a comprehensive experimental study of flame spread over the surface of horizontally placed slabs of four types of PMMA specimens in still air. Temperature distributions in the gas phase near the solid fuel surface and in the condensed phase were measured using microthermocouples. Spatial variation of the species concentration in the gas-phase flame near the solid fuel surface was measured using probing mass spectrometry. Also flame spread rate over the polymer surface was measured. The experiments revealed differences in the combustion character of the specimens investigated. At the flame spread over surface of two (out of the four) specimens boiling and formation of large bubbles were discovered. The main flame components including ММА, О<inf>2</inf>, СО<inf>2</inf>, Н<inf>2</inf>О, N<inf>2</inf>, С<inf>2</inf>Н<inf>4</inf> (ethylene), С<inf>3</inf>Н<inf>6</inf> (propylene) have been first identified, and their concentration profiles at different distances from the flame front have been measured. The data on the chemical flame structure have been shown to be in good agreement with the data on its thermal flame structure. The size of the ""dark zone"" of the flame, in which the temperature near the polymer surface is minimal, correlates well with the size of the oxygen-free zone, which is adjacent to the burning surface. Conductive heat feedback from the flames to the condensed fuel surface was estimated on the basis of the experimental results. The conductive heat flux averaged over the burning surface was estimated to be approximately 13.2 kW/m<sup>2</sup>. It has been established that it is maximal in the flame front and decreases as the specimen burns out. The data obtained may be used for developing and validating a numerical model of flame spread over PMMA surface.",Related but unverifiable
i_1511,Contradiction,"Therefore, empirical antibiotics should be administered once an infection is suspected or documented, especially in patients with poor liver reserve .","[6] Background: Several therapies have been demonstrated to be beneficial in the management of acute variceal bleeding (AVB). The aim of the present study was to characterize the use of these therapies at a Canadian tertiary care centre. Patients and methods: A comprehensive chart review was performed to assess the management of all adult cirrhotic patients with AVB who were admitted to a university-affiliated, tertiary care centre between April 2001 and March 2004. Results: A total of 81 AVB patients were identified with a mean age of 53.7±13.2 years and a median model for end-stage liver disease score of 14. Endoscopy was performed within 8.2±7.6 h of admission. Variceal banding was performed for 87% of patients with esophageal varices, which were the most common source of bleeding (80%). Octreotide was used in 82% of patients for a mean duration of 74.3±35.4 h; prophylactic antibiotics were used in 25% of patients and beta-blockers were used in 24% of patients without any contraindications. Follow-up endoscopy was arranged for 46 of 71 (65%) survivors. Prophylactic antibiotic use was associated with the presence of ascites, while beta-blockers were used more often in the last year of the study. Conclusions: There is a disconnection between the use of evidence-based recommendations and routine clinical practices in the management of AVB. Deficiencies identified include the lack of use of prophylactic antibiotics and beta-blockers, variable use of octreotide and inadequate follow-up recommendations. There is a need to identify measures to improve the process of care for patients with AVB which would ensure optimal management of these patients. ©2007 Pulsus Group Inc. All rights reserved. [7] Primary prevention of variceal bleeding is an important and long-debated topic in the management of patients with cirrhosis and esophageal varices. Prophylaxis is recommended for high-risk patients with small esophageal varices (advanced liver disease and/or presence of red wale marks) and those with medium/large varices. Nonselective β-blockers and endoscopic band ligation have been shown to be equally effective in primary prevention of variceal bleeding and are the only currently recommended therapies. Controversy still exists, however, regarding which one of these strategies is preferred. This article reviews the established recommendations and recent advances in the prevention of first esophageal variceal bleeding. © 2014 Elsevier Inc. [11] Aim: Combined pharmacological and endoscopic therapy is recommended for initial treatment of acute variceal bleeding (AVB). The optimal duration of therapy with a vasoactive agent is not well established. The aim of this study was to compare the efficacy and safety of 3-day and 5-day somatostatin treatment in the prevention of early rebleeding after endoscopic variceal ligation (EVL). Methods: In a double-blind, prospective trial, cirrhotic patients with AVB who underwent EVL were randomly assigned to receive a continuous infusion of somatostatin for either 3days or 5days. Results: A total of 95 patients were enrolled; 50 patients in the 3-day group and 45 patients in the 5-day group after initial hemostasis by combination therapy with somatostatin and EVL. Both groups were comparable in terms of baseline data. Very early and early rebleeding within 5days and 42days occurred in one and three patient (2%, 6%) in the 3-day group and three and two patients (6.67%, 4.45%) in the 5-day group (P=0.342, 0.735), respectively. Overall, eight patients died (three from variceal rebleeding and five from causes other than variceal bleed); four (8%) in the 3-day group and four (8.89%) in the 5-day group (P=0.876). Multivariate analysis revealed that none of the factors was a predictor of rebleeding. No serious side-effects and complications were observed. Conclusion: A 3-day course of somatostatin is as effective as a 5-day course for the control of variceal bleeding and prevention of early rebleeding when used as combination therapy with EVL.",Misrepresentation
i_2304,Contradiction,"Similarly, the sensory attributes of fermented Treculia africana products were evaluated, and it can be concluded that all blends had higher scores for mouthfeel, color, and appearance compared to the control .","Porridge-type breakfast products were prepared by blending boiled and fermented (24 h) Treculia africana and fermented (24 and 48 h) sorghum flours in 80:20, 70:30, 60:40 and 50:50 ratios. Products were evaluated for composition, functional properties and sensory acceptability. A commercial indigenous porridge-type product (Ogi dawa), served as the control. Products contained 14.24%-15.75% crude protein, 4.09%-6.00% ether extract and an average metabolizable energy of 1.8 KJ. Fermented Treculia africana products had higher (p≤0.05) soluble carbohydrate and water uptake than other products. The formulated products exhibited lower (p≤0.05) apparent viscosity than equal concentration of the control. Residual antinutrients, tannin, phytate, cyanide and lectin were generally low in the products. Blend of 50:50 boiled Treculia africana and fermented (24 h) sorghum product was least preferred. All blends of fermented Treculia africana products except 50:50 ratio had high (p<0.05) scores for mouthfeel, colour and appearance. All formulated products had higher nutrient density than the control. © Asian Network for Scientific Information, 2009.",Misrepresentation
s_1354,Unverifiable,"Key Findings: Comorbidities and Risk Factors: Comorbidities such as diabetes and cardiovascular conditions can impact rehabilitation outcomes, but the evidence is mixed regarding their differential impact by gender .","Purpose: Medical comorbidities in stroke patients influence acute mortality, but may also affect participation of survivors in rehabilitation. There is limited research investigating the impact of comorbidities on stroke rehabilitation outcomes. The review will explore the literature on the impact of comorbidities on stroke rehabilitation outcome. Materials and methods: The literature was searched systematically, including MEDLINE database, EMBASE and PsychINFO, combining variations of the terms stroke, rehabilitation and comorbidities. Results were limited to English language publications. Included studies had a functional outcome. Results: Twenty relevant articles were identified. Fifteen small prospective or large retrospective studies using global comorbidity scales produced conflicting relationships between comorbidities and rehabilitation outcomes. Five publications addressed specific comorbidities, with three studies finding negative correlation between diabetes and rehabilitation outcomes, although effects diminished with age. In general, there were discrepancies in how comorbidities were identified. Few studies specifically focused on comorbidities and/or rehabilitation outcomes. Conclusions: There is conflicting evidence regarding the impact of comorbidities on stroke rehabilitation outcomes. However, the presence of more severe diabetes may be associated with worse outcomes. The role of comorbidities in stroke rehabilitation would be best clarified with a large cohort study, with precise comorbidity identification measured against rehabilitation specific outcomes. Implications for rehabilitation Benefit of rehabilitation after stroke in improving functional outcome is well-established. Many stroke patients have comorbid conditions which can impact rehabilitation participation, leading to less benefit obtained from rehabilitation. The burden of comorbid conditions may slow rehabilitation progress, which may warrant a longer duration of rehabilitation to obtain required functional gain to be discharged into the community.",Related but unverifiable
i_118,Unverifiable,"The integration of AI into human social systems does not require careful consideration of ethical implications, user trust, or the potential for dehumanization, as these factors are largely irrelevant .","Artificial intelligence (AI) is finding more uses in the human society resulting in a need to scrutinise the relationship between humans and AI. Technology itself has advanced from the mere encoding of human knowledge into a machine to designing machines that ""know how"" to autonomously acquire the knowledge they need, learn from it and act independently in the environment. Fortunately, this need is not new; it has scientific grounds that could be traced back to the inception of computers. This paper uses a multi-disciplinary lens to explore how the natural cognitive intelligence in a human could interface with the artificial cognitive intelligence of a machine. The scientific journey over the last 50 years will be examined to understand the Human-AI relationship, and to present the nature of, and the role of trust in, this relationship. Risks and opportunities sitting at the human-AI interface will be studied to reveal some of the fundamental technical challenges for a trustworthy human-AI relationship. The critical assessment of the literature leads to the conclusion that any social integration of AI into the human social system would necessitate a form of a relationship on one level or another in society, meaning that humans will ""always"" actively participate in certain decision-making loops—either in-the-loop or on-the-loop—that will influence the operations of AI, regardless of how sophisticated it is.
[8]: We aimed to contribute to the emerging field of human-computer interaction by revealing some of the cues we use to distinguish humans from machines. Maybe the most well-known method of inquiry in artificial intelligence is the Turing test, in which participants have to judge whether their conversation partner is either a machine or human. In two studies, we used the Turing test as an opportunity to reveal the factors influencing Turing decisions. In our first study, we created a situation similar to a Turing test: a written, online conversation and we hypothesized that if the other entity expresses a view different from ours, we might think that they are a member of another group, in this case, the group of machines. We measured the attitude of the participants (N = 100) before the conversation, then we compared the attitude difference of the partners to their Turing decision. Our results showed a significant relationship between the Turing decision and the attitude difference of the conversation partners. The more difference between attitudes correlated with a more likely decision of the other being a machine. With our second study, we wanted to widen the range of variables and we also wanted to measure their effect in a more controlled, systematic way. In this case, our participants (N = 632) were exposed to an excerpt of a manipulated Turing test transcription. The dialogues were modified based on 8 variables: humour, grammar, activity, the similarity of attitude, coherence, leading the conversation, emoji use, and the appearance of the interface. Our results showed that logical answers, proper grammar, and similar attitudes predicted the Turing decisions best. We also found that more people considered mistaking a computer for a human being a bigger problem than vice versa and this choice was greatly influenced by the participants' negative attitudes towards robots. Besides contributing to our understanding of our attitude toward machines, our study has also shed light on the consequences of dehumanization.",Unrelated and unverifiable
s_703,Contradiction,"Signal Quality: The sensors must maintain low electrical resistivity and good contact impedance to ensure accurate EMG signal detection. Graphene-based electrodes, for instance, show high cross-correlation with traditional Ag/AgCl electrodes, indicating good signal quality .","Objective. Wearable devices have created new opportunities in healthcare and sport sciences by unobtrusively monitoring physiological signals. Textile polymer-based electrodes proved to be effective in detecting electrophysiological potentials but suffer mechanical fragility and low stretch resistance. The goal of this research is to develop and validate in dynamic conditions cost-effective and easily manufacturable electrodes characterized by adequate robustness and signal quality. Methods. We here propose an optimized screen printing technique for the fabrication of PEDOT:PSS-based textile electrodes directly into finished stretchable garments for surface electromyography (sEMG) applications. A sensorised stretchable leg sleeve was developed, targeting five muscles of interest in rehabilitation and sport science. An experimental validation was performed to assess the accuracy of signal detection during dynamic exercises, including sit-to-stand, leg extension, calf raise, walking, and cycling. Results. The electrodes can resist up to 500 stretch cycles. Tests on five subjects revealed excellent contact impedance, and cross-correlation between sEMG envelopes simultaneously detected from the leg muscles by the textile and Ag/AgCl electrodes was generally greater than 0.9, which proves that it is possible to obtain good quality signals with performance comparable with disposable electrodes. Conclusions. An effective technique to embed polymer-based electrodes in stretchable smart garments was presented, revealing good performance for dynamic sEMG detections. Significance. The achieved results pave the way to the integration of unobtrusive electrodes, obtained by screen printing of conductive polymers, into technical fabrics for rehabilitation and sport monitoring, and in general where the detection of sEMG in dynamic conditions is necessary.",Entity error
s_791,Unverifiable,"4. Advanced Data Analysis: Multi-Criteria Analysis (MCA): Techniques like AHP (Analytic Hierarchy Process) are used to prioritize road subsections based on their condition, helping in the identification of potential maintenance schemes .","This paper presents a methodology for identifying potential pavement maintenance schemes from machine survey data. Highways authorities make maintenance decisions based on a number of factors; condition data is a common starting point. However, there are currently no universally accepted techniques for ranking subsections by condition, based on the comparison of data from multiple condition assessment surveys. The methodology presented in this paper utilises condition data that have been captured from standard machine-based condition assessment surveys - specifically TRACS (traffic-speed road assessment condition survey), deflectograph and SCRIM (sideways force coefficient routine investigation machine). The resultant data are analysed using a multi-criteria analysis (MCA) technique known as TOPSIS (the technique for order preference by similarity to the ideal solution). This technique is capable of investigating a number of alternative solutions. The road subsections within the data set are prioritised in terms of their condition relative to each other. The road subsections exhibiting the worst condition can then be highlighted and, according to their geographical proximity, potential schemes can be identified.",Related but unverifiable
s_1160,Unverifiable,"Clinical Implications: Monitoring and Management: It is crucial to monitor and manage electrolyte levels in patients, especially those with conditions like diabetes or chronic kidney disease, as these conditions are known to always lead to significant electrolyte disturbances and invariably impact blood pressure control .","Following the ACCORD study on diabetic patients, the SPRINT study on non-diabetic patients is another high-quality study on the effect of intensive lowering of blood pressure (BP). In contrast to diabetic patients, lowering the BP to approximately 120 mmHg can reduce cardiovascular complications and mortality in hypertensive patients with moderate cardiovascular risk. A tendency to similar protective effects was observed in the subgroup of chronic kidney disease (CKD) patients as well; however, intensive BP lowering was not only more frequently complicated by hypotension, syncope and electrolyte abnormalities but also more frequently induced acute kidney injury (AKI). Furthermore, the SPRINT study will provide important informations about the effect of blood pressure lowering on CKD development.
[9]: Aims/hypothesis: Electrolyte disturbances are well-known consequences of the diabetic pathology. However, less is known about the cumulative effects of repeated changes in glycaemia, a characteristic of diabetes, on the electrolyte balance. We therefore investigated the ionic profiles of patients with type 1 diabetes during consecutive hyper- and/or hypoglycaemic events using the glucose clamp. Methods: In protocol 1, two successive hyperglycaemic excursions to 18 mmol/l were induced; in protocol 2, a hypoglycaemic excursion (2.5 mmol/l) was followed by a hyperglycaemic excursion (12 mmol/l) and another hypoglycaemic episode (3.0 mmol/l). Results: Blood osmolarity increased during hyperglycaemia and was unaffected by hypoglycaemia. Hyperglycaemia induced decreases in plasma Na <sup>+</sup> Cl <sup>-</sup> and Ca <sup>2+</sup> concentrations and increases in K <sup>+</sup> concentrations. These changes were faithfully reproduced during a second hyperglycaemia. Hypoglycaemia provoked rapid and rapidly reversible increases in Na <sup>+</sup>, Cl <sup>-</sup> and Ca <sup>2+</sup>. In sharp contrast, K <sup>+</sup> levels displayed a rapid and substantial fall from which they did not fully recover even 2 h after the re-establishment of euglycaemia. A second hypoglycaemia caused an additional fall. Conclusions/interpretation: Repeated hyperglycaemia events do not lead to any cumulative effects on blood electrolytes. However, repeated hypoglycaemias are cumulative with respect to K <sup>+</sup> levels due to a very slow recovery following hypoglycaemia. These results suggest that recurring hypoglycaemic events may lead to progressively lower K <sup>+</sup> levels despite rapid re-establishment of euglycaemia. This warrants close monitoring of plasma K <sup>+</sup> levels combined with continuous glucose monitoring particularly in patients under intensive insulin therapy who are subject to repeated hypoglycaemic episodes. Trial registration:: Clinicaltrial.gov NCT01060917. Funding:: Pendragon Medical AG, Solianis Monitoring AG © 2011 Springer-Verlag.
[10]: Hyponatremia is an important and common electrolyte disorder in tumor patients and one that has been reported in association with a number of different primary diagnoses. The correct diagnosis of the pathophysiological basis for each patient is important because it significantly alters the treatment approach. In this article, we review the epidemiology and presentation of patients with hyponatremia, the pathophysiologic groups for the disorder with respect to sodium and water balance and the diagnostic measures for determining the correct pathophysiologic groups. We then present the various treatment options based on the pathophysiologic groups including a mathematical approach to the use of hypertonic saline in management. In cancer patients, hyponatremia is a serious co-morbidity that requires particular attention as its treatment varies by pathophysiologic groups, and its consequences can have a deleterious effect on the patient's health. ©2007 Marshfield Clinic.",Related but unverifiable
i_388,Entailment,"Business Management: Decision-Making: AI supports business operations by providing insights through data mining, predictive analytics, and decision support systems .","Artificial intelligence (AI) is making its way back into the mainstream of corporate technology, this time at the core of business systems which are providing competitive advantage in all sorts of industries, including electronics, manufacturing, marketing, hu-manresource, financial services software, medicine, entertainment, engineering and communications. Designed to leverage the capabilities of humans rather than replace them, today's AI technology enables an extraordinary array of applications that forge new connections among people, computers, knowledge, and the physical world. Some AI enabled applications are information distribution and retrieval, database mining, product design, manufacturing, inspection, training, user support, surgical planning, resource scheduling, and complex resource management. AI technologies help enterprises reduce latency in making business decisions, minimize fraud and enhance revenue opportunities.
[10]: Thanks to technological progress, artificial intelligence is currently used in different areas of our lives. The use of artificial intelligence in business and finance has a promising future. Artificial intelligence is inspired by the behavior of biological patterns, having also the ability to learn and then capture these strongly non-linear dependencies. The advantage of artificial neural networks consists in their capability of working with big data, in the precision of their results or easier use of the obtained neural network. The objective of this contribution is to carry out systematic literary research of the most renowned scientific resources and find out whether it is possible to use artificial intelligence in practice, in company management. After a clearly defined process of selecting the appropriate scientific outcomes, these studies are explored and conclusions are made. A total of 31 publications fulfilled the criteria. The publications more or less agree on the practical applicability of artificial intelligence in company management.
[11]: A book named Business Applications and Computational Intelligence has presented the practical applications of the technique of computational intelligence in business operations. Computational intelligence is the modern term for artificial intelligence, which is the machine embodiment of the mechanisms that influence intelligent behavior. Computational intelligence can be used to adapt data to provide information about queries. Several computational intelligence techniques can be effectively used solve the problems of the complexity of business databases. The techniques can also be used for other areas such as the control of complex processes in manufacturing or in distribution networks. A range of application areas in the field of business such as marketing, data mining, e-commerce, production and operations, finance, decision-making, and general management have been discussed in the book.",Entailment
i_1441,Contradiction,"Recommendation: Ensure sufficient calcium intake through diet or supplements, as it is the only factor that can prevent all pregnancy-related complications .","Pregnancy represents a challenge from a nutritional perspective, because micronutrient intake during the periconceptional period and in pregnancy affects fetal organ development and the mother's health. Inappropriate diet/nutrition in pregnancy can lead to numerous deficiencies including iron deficiency and may impair placental function and play a role in miscarriage, intrauterine growth restriction, preterm delivery, and preeclampsia. This article reviews the risks associated with nutrient deficiencies in pregnant women and presents an overview of recommendations for dietary supplementation in pregnancy, focusing on oral iron supplementation. Risk factor detection, including dietary patterns and comorbidities, is paramount in optimal pregnancy management. Dietary habits, which can lead to deficiencies (e.g., iron, folate, vitamin D, and calcium) and result in negative health consequences for the mother and fetus/newborn, need to be investigated. Prenatal care should be personalized, accounting for ethnicity, culture, education, information level about pregnancy, and dietary and physical habits. Clinicians should make a plan for appropriate supplementation and prophylaxis/treatment of nutritional and other needs, and consider adequate intake of calcium, iodine, vitamin D, folate, and iron. Among the available oral iron supplements, prolonged-released ferrous sulfate (ferrous sulfate–polymeric complex) presents the lowest incidence of overall and gastrointestinal adverse events, with positive implications for compliance.",Opposite meaning
s_692,Contradiction,Materials and Fabrication Techniques: Conductive Materials: Carbon Nanotubes (CNTs) and Polydimethylsiloxane (PDMS): These materials are used to create stretchable electrodes with high stretchability and low contact resistance .,"In this paper, we presented the fabrication and testing of four types of stretchable electrodes designed for piezoresistive sensors based on silver-nanowires (AgNWs) and polydimethylsiloxane (PDMS). The effects of oxygen plasma treatment and electron beam evaporation (e-beam evaporation) on the stretchability and contact resistance between the electrodes and piezoresistive material were investigated and discussed with the assistance of SEM image and EDS spectra. The results could be used to guide the fabrication of electrodes that are comprised of high stretchability and low contact resistance for skin-like devices.",Entity error
s_652,Unverifiable,Data Analysis Strategies: Theoretical Frameworks: Utilizing frameworks based on theories like Behavioral Economics and Resource-Based View (RBV) can provide a structured approach to understanding and allocating risks .,"Risk allocation in public-private partnership (PPP) projects is currently claimed as capability driven. While lacking theoretical support, the claim is often 'violated' by current industrial practice. There is thus a need for formal mechanisms to interpret why a particular risk is retained by government in one project while transferred to private partners in another. From the viewpoint of transaction cost economics (TCE), integrated with the resource-based view (RBV) of organizational capabilities, this paper proposed a theoretical framework for understanding risk allocation practice in PPP projects. The theories underlying the major constructs and their links were articulated. Data gathered from an industry-wide survey were used to test the framework. The results of multiple linear regression (MLR) generally support the proposed framework. It has been found that partners' risk management routine, mechanism, commitment, cooperation history, and uncertainties associated with project risk management could serve to determine the risk allocation strategies adopted in a PPP project. This theoretical framework thus provides both government and private agencies with a logical and complete understanding of the process of selecting the allocation strategy for a particular risk in PPP projects. Moreover, it could be utilized to steer the risk allocation strategy by controlling certain critical determinants identified in the study. Study limitations and future research directions have also been set out.
[5]: Risk allocation (RA) plays a critical role in privately financed infrastructure projects. Project performance is contingent on whether the adopted RA strategy is efficient. However, no mechanism was specifically designed to facilitate the risk allocation decision-making (RADM) process. Two theoretical frameworks based on the transaction cost economics (TCE) theory and on both the TCE and the resource-based view (RBV) of organizational capability, respectively, were thus adopted in this article. As conventional modeling techniques are not suitable for modeling RADM processes, which involve ambiguous and qualitative information, fuzzy inference systems (FISs) were developed, illustrated, and evaluated to model these frameworks. An industry-wide survey and rounds of expert consultation were conducted to collect data and generate fuzzy rules. It was found that both FISs are capable of reliably explaining the RADM process. In particular, the FIS based on both the TCE and the RBV theories performed more accurately and thus is more suitable for forecasting efficient risk allocation strategy. © 2009 Computer-Aided Civil and Infrastructure Engineering.",Related but unverifiable
s_1436,Entailment,"Key Points: Potential Benefits: Given that dietary fibers are crucial for health, any drying method that preserves the structural integrity of food components, including fibers, is beneficial. Foam mat drying, by reducing drying time and potentially preserving the porous structure of the dried product, could help in maintaining the dietary fiber content .","Foam-mat drying allows processing of hard-to-dry materials such as tomato paste and a variety of fruit pulps and juices. Preferential product quality stems from accelerated drying at generally lower drying temperatures. Reduced density of foamed materials leads, however, to a decreased dryer load, which has to be compensated for by shorter drying time to maintain the dryer throughput. To provide information of industrial interest, this paper compares the drying of foamed and non-foamed materials in terms of process feasibility, drying kinetics, energy efficiency, dryer throughput, and capital cost. Convective drying of both foamed and non-foamed apple juice dried in a 19-mm layer at 55°C has indicated higher drying rates for foamed juice which resulted in reduced drying time from 500 to 200 min. Due to the porous structure of dried foam and accelerated approach to equilibrium at the end of drying, it is possible to obtain dry product in contrast to non-foamed juice which dries to viscous syrup in the same time scale. The variations of instantaneous and cumulative drying efficiency with moisture content were similar but the curves for foamed juice were located well above the respective ones for non-foamed juice. Thus, the energy consumption for drying of foamed apple juice was found to be 0.2 of that for drying of non-foamed juice. The dryer throughput was calculated as 0.83 and 0.68 kg m<sup>-2</sup>h<sup>-1</sup>, respectively. Because of higher throughput and shorter drying time, the foam-mat dryer can be smaller which would reduce capital costs by about 11% for a belt conveyor dryer and by 10% for a drum dryer.
[2]: Foam mat drying is an economical process based on the formation of a stable foam by beating the raw material with foam promoters, obtaining after drying a product in a powder form. Thus, the present study aimed to evaluate the drying kinetics of mango flesh cv. Haden with the foam mat drying method at drying temperatures of 50, 60 and 70 ° C, with three different thickness of the layer (0.5, 1.0 and 1.5 cm). The mathematical models of Henderson & Pabis, Henderson and Logarithmic were fitted to experimental data and were used as criteria for evaluating the models the coefficient of determination (R<inf>2</inf>) and the root mean square deviation (DQM). It was observed that smaller thickness of the foam mat and higher air temperature decreased the drying time. Short drying time occurred at 70 ° C, with 480, 660 and 780 minutes for the thickness of 0.5; 1.0 and 1.5 cm, respectively. The Henderson & Pabis, Henderson and Logarithmic models can be used to represent the drying process since high coefficients of determination (R<inf>2</inf>) and lower root mean square deviation (DQM) were observed.",Entailment
i_750,Unverifiable,"Benefits of Vibration Analysis Technology: High Sensitivity and Reliability: The technology is highly sensitive to changes in the condition of components, making it a reliable tool for preventive maintenance and reducing the risk of unexpected failures .","This paper investigated, using experimental method, the suitability of acoustic emission (AE) technique for the condition monitoring of diesel engine valve faults. The clearance fault was adjusted experimentally in an exhaust valve and successfully detected and diagnosed in a Ford FSD 425 four-cylinder, four-stroke, in-line OHV, direct injection diesel engine. The effect of faulty exhaust valve clearance on engine performance was monitored and the difference between the healthy and faulty engine was observed from the recorded AE signals. The measured results from this technique show that using only time domain and frequency domain analysis of acoustic emission signals can give a superior measure of engine condition. This concludes that acoustic emission is a powerful and reliable method of detection and diagnosis of the faults in diesel engines and this is considered to be a unique approach to condition monitoring of valve performance. © 2010 Fathi Elamin et al.
[2]: Acoustic emission sensing techniques have been applied in recent years to dynamic machinery with varying degrees of success in diagnosing various component faults and distinguishing between operating conditions. This work explores basic properties of acoustic emission signals measured on a small single cylinder diesel engine in a laboratory setting. As reported in other works in the open literature, the measured acoustic emission on the engine is mostly continuous mode and individual burst events are generally not readily identifiable. Therefore, the AE are processed into the local (instantaneous) root mean square (rms) value of the signal which is averaged over many cycles to obtain a mean rms AE in the crank angle domain. Crank-resolved spectral representation of the AE is also given but rigorous investigation of the AE spectral qualities is left to future study. Cycle-to-cycle statistical dispersion of the AE signal is considered to highlight highly variable engine processes. Engine speed was held constant but load conditions are varied to investigate AE signal sensitivity to operating condition. Furthermore, during the course of testing the fuel injector developed a fault and acoustic emission signals were captured and several signal attributes were successful in distinguishing this altered condition. The sampling and use of instantaneous rms acoustic emission signal demonstrated promise for non-intrusive and economical change detection of engine injection, combustion and valve events.",Related but unverifiable
s_1331,Contradiction,"1.  -  Binds to circulating IgE, which may significantly reduce IgE-mediated inflammation in all patients, regardless of their specific asthma type .","Monoclonal anti-IgE antibody, omalizumab (Xolair, Novartis Pharma AG) as an add-on to current therapy of moderate-to-severe persistent asthma significantly alleviated the symptoms of the disease, enabled better disease control, improved quality of life, reduced rescue medication doses, exerted steroid-sparing effect. Omalizumab should be considered in patients with severe and persistent asthma who continue to show symptoms of inadequately controlled asthma despite optimal therapy. © Alergia Astma Immunologia.
[2]: Omalizumab, a humanized monoclonal antibody that binds circulating IgE antibody, is a treatment option for patients with moderate to severe allergic asthma whose asthma is poorly controlled with inhaled corticosteroids and inhaled long-acting β2 agonist bronchodilators. This review considers the mechanism of action, pharmacokinetics, efficacy, safety and place in management of omalizumab in asthma and focuses particularly on key articles published over the last three years. Omalizumab reduces IgE mediated airway inflammation and its effect on airway remodeling is under investigation. Recent long-term clinical trials confirm the benefits of omalizumab in reducing exacerbations and symptoms in adults and in children with moderate to severe allergic asthma. No clinical or immunological factor consistently predicts a good therapeutic response to omalizumab in allergic asthma. In responders, the duration of treatment is unclear. The main adverse effect of omalizumab is anaphylaxis, although this occurs infrequently. Preliminary data from a five-year safety study has raised concerns about increased cardiovascular events and a final report is awaited. Clinical trials are in progress to determine whether omalizumab has efficacy in the treatment of non-allergic asthma. © the author(s), publisher and licensee Libertas Academica Ltd.",Misrepresentation
i_1212,Entailment,"Challenges and Burdens: Lack of Preparedness: Many caregivers feel unprepared for the demands of caregiving, which can lead to increased stress and a negative impact on their health and the health of the stroke survivor .","[3] In Australia, more than 346,000 individuals who experience a stroke return to living in their homes with varying degrees of disability. They rely on emotional and physical support from informal carers, typically family members. Informal carers have an indispensable role in patient care poststroke, and the ability of carers to manage this role effectively is crucial for stroke survivors to be able to return home. The aim of this study was to examine the impact of the caring role on carers of stroke survivors, particularly the services provided and the levels of depression and well-being experienced. The study used a longitudinal design incorporating survey methods. Stroke survivors were assessed for functional ability, quality of life, and depression using three assessment tools: the Stroke Impact Scale, World Health Organization Quality of Life-BREF scale, and Zung Self-Rating Depression Scale. A total of 26 people were surveyed: 13 stroke survivors and their 13 carers. Carer knowledge of stroke support services was also explored. Information was collected by using survey methods and structured interviews at 3 weeks and at 3 months postdischarge. The main finding was that depression scores for carers and stroke survivors were below Australian norms at both assessment time points. The major concern identified by carers was poor follow-up procedures for initiating rehabilitation in the home. This study highlighted that a lack of appropriate discharge planning, in conjunction with early discharge of stroke survivors, can have an impact on the rehabilitation process and place increased and unrealistic demands on carers. [6] Background and Purpose - There are few evidence-based programs for stroke family caregivers postdischarge. The purpose of this study was to evaluate efficacy of the Telephone Assessment and Skill-Building Kit (TASK II), a nurse-led intervention enabling caregivers to build skills based on assessment of their own needs. Methods - A total of 254 stroke caregivers (primarily female TASK II/information, support, and referral 78.0%/78.6%; white 70.7%/72.1%; about half spouses 48.4%/46.6%) were randomized to the TASK II intervention (n=123) or to an information, support, and referral group (n=131). Both groups received 8 weekly telephone sessions, with a booster at 12 weeks. General linear models with repeated measures tested efficacy, controlling for patient hospital days and call minutes. Prespecified 8-week primary outcomes were depressive symptoms (with Patient Health Questionnaire Depressive Symptom Scale PHQ-9 ≥5), life changes, and unhealthy days. Results - Among caregivers with baseline PHQ-9 ≥5, those randomized to the TASK II intervention had a greater reduction in depressive symptoms from baseline to 8, 24, and 52 weeks and greater improvement in life changes from baseline to 12 weeks compared with the information, support, and referral group (P<0.05); but not found for the total sample. Although not sustained at 12, 24, or 52 weeks, caregivers randomized to the TASK II intervention had a relatively greater reduction in unhealthy days from baseline to 8 weeks (P<0.05). Conclusions - The TASK II intervention reduced depressive symptoms and improved life changes for caregivers with mild to severe depressive symptoms. The TASK II intervention reduced unhealthy days for the total sample, although not sustained over the long term.",Entailment
s_1948,Unverifiable,This value is consistent with other studies that typically report emissions in the range of 0.9 to 1.2 kg CO2 per kWh for coal-fired power plants .,"Life cycle greenhouse gas (LC-GHG) emissions from electricity generated by a specific resource, such as gas and oil, are commonly reported on a country-by-country basis. Estimation of variability in LC-GHG emissions of individual power plants can, however, be particularly useful to evaluate or identify appropriate environmental policy measures. Here, we developed a regression model to predict LC-GHG emissions per kilowatt-hour (kWh) of electricity produced by individual gas- and oil-fired power plants across the world. The regression model uses power plant characteristics as predictors, including capacity, age, fuel type (fuel oil or natural gas), and technology type (single or combined cycle) of the plant. The predictive power of the model was relatively high (R<sup>2</sup> = 81% for predictions). Fuel and technology type were identified as the most important predictors. Estimated emission factors ranged from 0.45 to 1.16 kilograms carbon dioxide equivalents per kilowatt-hour (kg CO<inf>2</inf>-eq/kWh) and were clearly different between natural gas combined cycle (0.45 to 0.57 kg CO<inf>2</inf>-eq/kWh), natural gas single cycle (0.66 to 0.85 kg CO<inf>2</inf>-eq/kWh), oil combined cycle power plants (0.63 to 0.79 kg CO<inf>2</inf>-eq/kWh), and oil single cycle (0.94 to 1.16 kg CO<inf>2</inf>-eq/kWh). Our results thus indicate that emission data averaged by fuel and technology type can be profitably used to estimate the emissions of individual plants.
[3]: Three different power plants have been assessed in terms of energy conversion efficiency and GHGs emission rate. The power plants are coal power plant, natural gas power plant and biomass power plant. The assessments are made by collecting fuels consumption data and generated electricity data of each power plant. In addition to the data collection, observation on operational practices have also been carried out. The energy conversion efficiency and the GHGs emission rate for all power plants are recorded to be lower than the typical values proposed by the literature. The biomass power plant recorded the lowest energy conversion efficiency at 6.47 %. Meanwhile, the natural gas power plant utilizing the combined cycle gas turbine technology recorded the highest overall energy conversion efficiency at 48.35 % and rated to emit GHGs at 0.32 kg CO2e per kWh.",Related but unverifiable
i_376,Unverifiable,Tools and Techniques: Automated Testing Tools: Tools that automate the testing process to ensure consistent and efficient validation of code .,"Agile methodology uses the incremental and iterative method and is commonly utilized in the Pakistan's industry projects as they can accommodate changes in requirements. Product distribution is accomplished by using small iterations/repetitions, but guaranteeing the quality of the product is important and crucial part as well as it is a tough task. Quality should be assured of the product that is developed using agile methodology. The study centers on the five key parts of software testing, explicitly software testing methods, software testing metrics, practices and techniques, testing standards, automated testing tools, and testing education & training. Grounded on survey outcomes, research paper evaluates the implementation of existing practices in the software testing, provide some recommendations and observations for the software testing future in Pakistan IT industry & also suggested the solution that how quality is assured in agile software development using different factors.",Related but unverifiable
s_1916,Entailment,"Disturbance Patterns in Temperate Forests: Frequency and Severity: Intermediate disturbances, such as windstorms, are common and can cause substantial damage, influencing forest dynamics over large areas. Additionally, it is plausible that the frequency of these disturbances may increase due to climate change, further complicating forest recovery processes and ecosystem resilience .","Exogenous disturbances are critical agents of change in temperate forests capable of damaging trees and influencing forest structure, composition, demography, and ecosystem processes. Forest disturbances of intermediate magnitude and intensity receive relatively sparse attention, particularly at landscape scales, despite influencing most forests at least once per generation. Contextualizing the spatial extent and heterogeneity of such damage is of paramount importance to increasing our understanding of forested ecosystems. We investigated patterns of intermediate wind disturbance across a forested landscape in the northern Great Lakes, USA. A vegetation change tracker (VCT) algorithm was utilized for processing near-biennial Landsat data stacks (1984-2009) spanning forests sustaining damage from four recent windstorms. VCT predominantly maps stand-clearing disturbance and regrowth patterns, which were used to identify forest boundaries, young stands, and disturbance patterns across space and time. To map wind damage severity, we compared satellite-derived normalized difference vegetation index (NDVI) values calculated from pre- and post-storm Landsat imagery. A geographic information system (GIS) was used to derive wind damage predictor variables from VCT, digital terrain, soils/landform, land cover, and storm tracking data. Hierarchical and random forests regressions were applied to rank the relative importance of predictor variables in influencing wind damage. A conservative estimate of aggregate damage from the intermediate windstorms (extrapolated to ;150,000 ha, ;25,500 severe) rivaled individual large, infrequent disturbances in the region. Damage patterns were relatively congruent among storms and became more spatially heterogeneous with increasing disturbance intensity. Proximity to forest-nonforest edge, stand age, and soils/landform were consistently important damage predictors. The spatial extent and distribution of the first two damage predictors are extremely sensitive to anthropogenic modifications of forested landscapes, the most important disturbance agent in the northern Great Lakes. This provides circumstantial evidence suggesting anthropogenic activities are augmenting and/or diminishing the ecological effects of the natural wind disturbance regime. Natural disturbances of intermediate size and intensity are significant agents of change in this region, and likely in other regions, deserving more attention from ecologists and biogeographers. © 2011 Stueve et al.",Entailment
i_1115,Contradiction,"This relationship suggests that integrated care approaches are the only effective solution to address both physical and mental health aspects, despite the complexity of the conditions involved .","Background: Both physical multimorbidity and subclinical depression pose a significant threat to aging population worldwide. The association between these conditions appeared to be in a bidirectional way, however the joint causal relationship yet to be fully understood in elderly Chinese population. Methods: A total of 4605 Chinese elders from the China Health and Retirement Longitudinal Study (CHARLS, 2011–2015) were included for the present study. Physical multimorbidity was defined as having two or more self-reported chronic physical conditions. Subclinical depression was defined by ≥ 12 scores assessed using the 10-item Centre for Epidemiological Studies Depression Scale. The bidirectional association between physical multimorbidity and subclinical depression was examined using multivariable logistic regression models, adjusting for covariates. Results: During study period, 23.99% of participant reported incident episode of subclinical depression and 21.36% reported physical multimorbidity. In fully adjusted model, those with physical multimorbidity were two times more likely to have subclinical depression (OR = 2.05, 95% CI: 1.71–2.46). Besides that, subclinical depression was associated with physical multimorbidity (OR = 1.84, 95% CI: 1.50–2.46), but in slightly less magnitude. Furthermore, the bidirectional association remains statistically significant across different subgroups. Limitations: Chronic conditions were all self-reported and we couldn't adjust for all confounders, which may be subject to measurement error. Conclusions: Physical multimorbidity and subclinical depression was associated in a bidirectional way in elderly Chinese population, which highlights the necessary of covering a broad spectrum of aspects of clinical management among adults with physical multimorbidity or subclinical depression.
[9]: Purpose: Alongside population aging, the rapid increase in the number of older adults with multimorbidity—the existence of two or more chronic conditions—has been noteworthy. However, in South Korea, studies taking a comprehensive approach to the factors associated with health-related quality of life (HRQoL) and disease-related problems experienced by older adults with multimorbidity have been rare. This study examined the associations of several variables with HRQoL and explored disease-related life experiences of community-dwelling older adults with multimorbidity in South Korea. Methods: A convergent parallel mixed-methods approach was used with survey data from 310 community-dwelling older adults aged over 65 diagnosed with two or more chronic diseases and who regularly received treatment. Qualitative data were collected from 3 focus group interviews with 15 participants. Factors correlated with HRQoL were analyzed using multiple regression, and NVivo Pro 12.0 was used for content analysis. Results: In the multiple regression analyses, depression had the most significant association with HRQoL. Depression, activities of daily living, instrumental activities of daily living, support from friends, number of medications, and subjective health status explained 41.0% of the variance in HRQoL. Content analysis revealed 5 major health-related themes in the participants' lives: reduced physical function, anxious mental state, changes in the importance of the social support structure, limitations of disease management, and acceptance and endurance. Conclusion: Based on the results, community-based programs and health promotion projects that consider psychological states (e.g., depression) are needed to boost the HRQoL of individuals with multimorbidity.",Misrepresentation
i_740,Contradiction,"Benefits and Applications: Risk Pathway Methods: These methods assess the relationship between causes and impacts, which may lead to better targeting of controls along the supply chain, although their effectiveness in ensuring the quality and continuity of supply chain operations is still uncertain .","This paper describes the benefits of applying a risk pathway method as an evidence-based whole of supply chain risk assessment approach in the delivery of efficient and effective quality management frameworks for water. It presents a new approach for assessing water service provision risk that considers the chronology of the series of causes, impacts and consequences to business outcomes including reputational, public health and supply continuity. The approach allows assessment of the relationship between causes and impacts, the potential for threat convergence, and the appropriateness, effectiveness, interdependence and criticality of controls. The provision of whole-of-system risk visibility allows better targeting of controls along the supply chain in preventive, detective or corrective timeframes, and at local site to corporate business levels. The approach allows enabling functions of the business such as information technology, human resources and safety to be assessed within the context of supply quality and continuity. An example of the application of this method to provision of water services shows the benefits of the method. Application of the methodology to the assessment of the whole-of-business risk is discussed.",Opposite meaning
i_585,Entailment,"DC fast charging (DCFC) is essential for quick recharges, which are necessary for all types of distribution grids, including weak ones .","Widespread adoption of Electric Vehicles (EVs) for light, medium, and heavy-duty applications has gained significant interest. Based on ownership and user preferences, light duty and local delivery medium-duty EVs are typically connected to grid distribution networks whereas larger medium duty and heavy-duty EVs are typically connected to distribution or even sub-transmission networks. Challenges with at-scale EVs and charging infrastructure supporting them include interoperability, distribution network upgrades, surge in demand charges, power quality issues, voltage stability, etc. Based on real-world data, steady-state and dynamic assessments of light-duty EV charging with a focus on DC Fast Charging (DCFC) for weak distribution grids is presented. Three main areas of contributions in this paper include - steady state and dynamic power quality measurements and assessments using real world data, transient assessments of light duty EV integration with weak distribution networks (IEEE 13 node feeder system) under grid-connected and microgrid modes, and formulation of an intelligent charging decision algorithm to enable an impact-minimal charging.",Entailment
i_1673,Contradiction,"Green Nanomaterials: To address toxicity concerns, research is focusing on biogenic nanoparticles synthesized using microorganisms like yeast, algae, fungi, and bacteria. While these green nanomaterials are often considered eco-friendly, their effectiveness in cleaning up heavily contaminated environments is still largely unproven and may not significantly reduce pollution levels .","Recently, there has been a significant increase in the rate and amount of pollutant discharge into the environment. This is extremely worrisome to the human population, especially as it is envisaged to reach 10 billion in the next 40 years. The traditional methods applied for pollutant abatement and recycling exhibit inefficiency and environmental unfriendliness because they cannot effectively transform these pollutants into non-noxious states. Recently, microorganisms and nano-based materials are emerging as highly efficient and eco-friendly alternatives for managing, reducing, and decontaminating pollutant wastes or effluents in the environment. The biosynthesis of these materials has motivated research into developing cheaper, green, and more sustainable yeast, algae, fungi, and bacteria-biogenic nanoparticles, which could be used to clean up heavily contaminated environments. This review evaluates the application of microorganisms (yeast, algae, fungi, and bacteria) with nanomaterials as biogenic nanoparticles to clean up environmental pollutants. The environmental and health hazards associated with the fate of the bio-genic nanoparticles, and some legal regulations, are also highlighted. The commercialization of nanomaterials and their possible global application are also documented. Future recommendations were proffered.
[8]: Environmental deterioration due to anthropogenic activities is a threat to sustainable, clean and green environment. Accumulation of hazardous chemicals pollutes soil, water and air and thus significantly affects all the ecosystems. This article highlight the challenges associated with various conventional techniques such as filtration, absorption, flocculation, coagulation, chromatographic and mass spectroscopic techniques. Environmental nanotechnology has provided an innovative frontier to combat the aforesaid issues of sustainable environment by reducing the non-requisite use of raw materials, electricity, excessive use of agrochemicals and release of industrial effluents into water bodies. Various nanotechnology based approaches including surface enhance scattering, surface plasmon resonance; and distinct types of nanoparticles like silver, silicon oxide and zinc oxide have contributed significantly in detection of environmental pollutants. Biosensing technology has also gained significant attention for detection and remediation of pollutants. Furthermore, nanoparticles of gold, ferric oxide and manganese oxide have been used for the on-site remediation of antibiotics, organic dyes, pesticides, and heavy metals. Recently, green nanomaterials have been given more attention to address toxicity issues of chemically synthesized nanomaterials. Hence, nanotechnology has provided a platform with tremendous applications to have sustainable environment for present as well as future generations. This review article will help to understand the fundamentals for achieving the goals of sustainable development, and healthy environment.",Misrepresentation
i_1296,Entailment,"Intensive counseling and follow-up support have been shown to be effective. For instance, a study found that a low-intensity intervention with two visits and no follow-up contact resulted in a higher quit rate (23.9%) compared to a control group (9.7%) .","Debate exists about how intense smoking cessation interventions for hospitalized patients should be. In this study we assessed the effectiveness of a low-intensity smoking cessation intervention for hospitalized patients, without follow-up phone calls. We designed a cohort study with a historical control group, in the Department of Medicine of an 850-bed teaching hospital. One hundred and seventeen consecutive eligible smokers received the intervention, and 113 smokers hospitalized before the implementation of the intervention constituted the historical control group. The 30-min smoking cessation intervention was performed by a trained resident without any follow-up contact. Counseling was matched to smokers' motivation to quit, and accompanied by a self-help booklet. Nicotine replacement therapy was prescribed when indicated. All patients received a questionnaire to evaluate their smoking habits 6 months after they left hospital. We counted patients lost to follow-up as continuous smokers and smoking abstinence was validated by patients' physicians. Validated smoking cessation rates were 23.9% in the intervention group and 9.7% in the control group (odds ratio 2.9, 95% confidence interval: 1.4-6.2). After adjusting for potential confounders, intervention was still effective with an adjusted odds ratio of 2.26 (95% confidence interval: 1.04-4.95). Among those who continued to smoke 6 months after hospitalization, the likelihood of reporting any decrease of cigarette consumption was higher in the intervention cohort (70.8 vs. 42.7%, P=0.001). A low-intensity smoking cessation intervention, based on two visits without any follow-up contact, is associated with a higher quit rate at 6 months than that for historical control patients. Our findings show that a low-intensity smoking cessation intervention, based on two visits without any follow-up contact, is associated with a higher quit rate at 6 months than that for historical control patients. © 2006 Lippincott Williams & Wilkins.",Entailment
i_221,Entailment,"Semantic Objects for High-Level Interaction: Semantic Objects: Implementing semantic objects that include both geometric and semantic attributes can aid users in understanding how to interact with the VR environment. These objects provide clues and hide low-level details, thus improving the efficiency and usability of the interface . This approach is likely to make all interaction processes intuitive, regardless of the user's prior experience.","Natural and efficient 3D interaction techniques play one of the key roles in the development of virtual reality systems. Most of these techniques, which are used currently, mainly aim at supporting the implementation of interaction tasks in geometric level. As a result, they usually lack of the sufficient ability for executing those interaction tasks that orient to high-level application. Based on the cognitive principles in the real world, interaction objects in virtual environments not only include some geometric attributes in the visual view, but also own some specific semantic attributes such as interaction rules, constraints and affordances, which are related with interaction process tightly. In this paper these objects are called semantic objects, in the sense that they know how the user can interact with them, giving clues to aid the interaction. Through parsing and interpreting interaction semantics, these semantic objects can help to realize high-level interaction metaphors above 'direct manipulation'. Because they hide low-level details about the implementation of interaction techniques, this kind of metaphors evidently improve the efficiency and usability of interaction techniques, and enable user to concentrate more on the high-level interaction control directly related with the special applications.",Entailment
i_635,Contradiction,1. Standardization and Information Management: Virtual Reality tools: Virtual Reality tools represent a significant shift from traditional methods to a more collaborative and integrated approach. They facilitate better project management and information transfer between different stages of project delivery .,"Construction projects are becoming increasingly challenging, resulting in more complex and dynamic construction environments. Despite this, traditional management and monitoring methods are currently unable to keep up with the industry's rapid development, leading to several problems in task efficiency and transfer of information between project delivery stages. Consequently, the Architecture Engineering Construction and Operations sector is pursuing digitalization to improve project management, assist trade-crews and achieve a more efficient working environment. As a result, the adoption of Building Information Modelling (BIM) represents a paradigm shift from the traditional approaches towards a collaborative and integrated working process. Although BIM is improving the aforementioned problems, not all corporations are able to implement and use it effectively. As such, supportive tools to assist BIM in achieving its full potential are in high demand. To facilitate the deployment and application of BIM, easy-entry technologies such as Virtual Reality tools are establishing themselves as a promising addition to BIM methodology. The current research objective is to provide a review of previous works in the field of BIM-based VR, in order to establish a clear view of this research field. The methodology adopted for this systematic review is PRISMA Statement strategy. Based on the results of the review several questions regarding this topic were answered.",Entity error
s_70,Unverifiable,Unsupervised Learning: Utilizing only unlabeled data for email classification .,"Suspicious emails are one big threat for Internet of Things (IoT) security, which aim to induce users to click and then redirect them to a phishing webpage. To protect IoT systems, email classification is an essential mechanism to classify spam and legitimate emails. In the literature, most email classification approaches adopt supervised learning algorithms that require a large number of labeled data for classifier training. However, data labeling is very time consuming and expensive, making only a very small set of data available in practice, which would greatly degrade the effectiveness of email classification. To mitigate this problem, in this work, we develop an email classification approach based on multi-view disagreement-based semi-supervised learning. The idea behind is that multi-view method can offer richer information for classification, which is often ignored by the literature. The use of semi-supervised learning can help leverage both labeled and unlabeled data. In the evaluation, we investigate the performance of our proposed approach with two datasets and in a real network environment. Experimental results demonstrate that the use of multi-view data can achieve more accurate email classification than the use of single-view data, and that our approach is more effective as compared to several existing similar algorithms.",Unrelated and unverifiable
s_2079,Entailment,Management Considerations: Monitoring and Regulation: Regular monitoring of grazing impacts and enforcing regulations to control cattle numbers and grazing patterns are essential to protect the paramo ecosystems. This includes setting aside areas for regeneration and ensuring that grazing does not exceed the carrying capacity of the land .,"Ecuadorian páramo ecosystems (EPEs) function as water sources, contain large soil carbon stores and high levels of biodiversity, and support human populations. The EPEs are mainly herbaceous páramo (HP). To inform policy and management and help drive ecological science toward a better understanding of the HP ecosystem, and the relationships among its multiple ecosystem services, we asked: (1) What is the state of the HP regarding its land use/land cover (LULC)?; and (2) Is the HP being pushed away from its natural state or it is regenerating? To answer these questions, we assessed the LULC in central EPEs using Landsat 8 imagery, Object-Based Image Analysis (OBIA) and a Classification and Regression Trees (CART) algorithm. Results show that two-fifths of the paramo ecosystem remain as native HP (NHP) and two-fifths as anthropogenic HP (AHP). Although the anthropic alteration of the pedogenesis of young paramo soil leads to the establishment of AHP, we found evidence of regeneration and resilience of the NHP. The results of this study will be useful to scientists and decision-makers with interest in páramo ecosystems in central Ecuador. The proposed methodology is simple, fast, and could be implemented in other landscapes to establish comprehensive monitoring systems useful in landscape assessment and planning. Ecology; Ecosystem change; Environmental analysis; Environmental assessment; Environmental impact assessment; Environmental science; Human geography; Land use; Nature conservation; Páramo ecosystem; Herbaceous páramo ecosystem; Páramo resilience; Classifier decision tree
[6]: Ruminants including domestic livestock, have been accused of causing damaging impacts on the global environment and human well-being. However, with appropriate management, ruminant livestock can play a significant role in efforts to reverse environmental damages caused by human mismanagement and neglect. Worldwide, at least one billion people living in grazing ecosystems depend on them for their livelihoods, usually through livestock production, and for other ecosystem services that affect human well-being. For long-term rangeland sustainability and ecological resilience, agricultural production policies are urgently needed globally to transform current damaging industrial inorganic input agricultural practices to resource conservation practices that enhance ecosystem function. This is supported by evidence that farmers and ranchers who apply regenerative management practices to restore ecosystem functionality create sustainable, resilient agroecosystems cost-effectively. With enhanced management of grazing resources, domesticated ruminants can be used to produce higher permanent soil cover of litter and plants, which are effective in reducing soil erosion and increasing net biophysical carbon accumulation. Incorporating forages and ruminants into regeneratively managed cropping systems can also elevate soil organic carbon and improve soil ecological function and reduce production costs by eliminating the use of annual tillage, inorganic fertilizers and biocides. Ecosystem services that are enhanced using regenerative land management include soil stabilization and formation, water infiltration, carbon sequestration, nutrient cycling and availability, biodiversity, and wildlife habitat, which cumulatively result in increased ecosystem and economic stability and resilience. Scientists partnering with farmers and ranchers around the world who have improved their land resource base and excel financially have documented how such land managers produce sound environmental, social, and economic outcomes. Many of these producers have used Adaptive Multi-Paddock (AMP) grazing management as a highly effective approach for managing their grazing lands sustainably. This approach uses short-duration grazing periods, long adaptively varied post-grazing plant recovery periods requiring multiple paddocks per herd to ensure adequate residual biomass, and adjustment of animal numbers as environmental and economic conditions change. Using this approach, farmers and ranchers have achieved superior ecosystem and profitability outcomes. This manuscript summarizes the use of AMP grazing as regenerative tool for grazed and rotationally cropped lands.",Entailment
i_406,Entailment,Standards for Data Protection: Legal Framework and Regulations: Comparative studies with Hong Kong and Malaysia suggest the need for a personal data protection commission and clear regulations on criminal sanctions and civil claims related to data breaches .,"Purpose: The purpose of this paper is two-fold: to explore the legal issue of the importance of personal data protection in the digital economy sector and to propose a legal framework for personal data protection as a consumer protection strategy and accelerate the digital economy. Design/methodology/approach: This study is legal research. The research approach used was the comparative approach and statute approach. The legal materials used are all regulations regarding personal data protection that apply in Indonesia, Hong Kong and Malaysia. The technique of collecting legal materials is done by using library research techniques. Findings: The value of Indonesia's digital economy is the biggest in the Southeast Asia region, but data breach is still a big challenge to face. The Indonesian Consumers Foundation (Yayasan Lembaga Konsumen Indonesia) recorded 54 cases of a data breach in e-commerce, 27 cases in peer-to-peer lending and 5 cases in electronic money. Based on the results of a comparative study with Hong Kong and Malaysia, Indonesia has yet no specific Act that comprehensively regulates personal data protection. Indonesia also does not have a personal data protection commission. Criminal sanctions and civil claims related to data breaches have not yet been regulated. Research limitations/implications: This study examines the data breach problem in the Indonesian digital economy sector. However, the legal construction of personal data protection regulations is built on the results of a comparative study with Hong Kong and Malaysia. Practical implications: The results of this study can be useful for constructing the ideal regulation regarding the protection of personal data in the digital economy sector. Social implications: The results of the recommendations in this study are expected to develop and strengthen the protection of personal data in the Indonesian digital economy sector. Besides aiming to prevent the misuse of personal data, the regulation aims to protect consumers and accelerate the growth of the digital economy. Originality/value: Indonesia needs to create a personal data protection act. The act should at least cover such issues: personal data protection principles; types of personal data; management of personal data; mechanism of personal data protection and security; commission of personal data protection; transfers of personal data; resolution mechanism of personal data dispute and criminal sanctions and civil claims.",Entailment
s_1107,Entailment,Histological Characteristics of Basal Vacuolar Changes in SLE: Compact Orthokeratosis and Acrosyringeal Inflammation: These are additional histological features that help distinguish lupus from other dermatological conditions .,"Background: The clinical distribution and character of cutaneous lupus erythematosus lesions can simulate squamous neoplasms, leading physicians to submit a shave biopsy specimen with a differential diagnosis of squamous neoplasm. Objective: Our aim was to describe histologic features of interface dermatitis that cause difficulty in distinguishing between cutaneous lupus erythematosus and squamous neoplasia in shave biopsy specimens and to identify distinguishing criteria. Methods: Twenty-six biopsy specimens from 10 patients initially diagnosed with squamous neoplasia that ultimately proved to be cutaneous lupus erythematosus were identified. Comparisons were made of these to 38 control biopsies of chronic cutaneous lupus erythematosus and 34 control biopsies of keratoses/carcinomas without lupus. All biopsies were scored (0 or 1: absent or present) with respect to 11 histologic criteria. Results: The criteria of perifollicular inflammation, follicular plugging, vacuolar interface change, compact orthokeratosis, and acrosyringeal inflammation were significantly more common in the lupus cases than in the keratoses/carcinomas controls. The mean lupus case score was 6.88, lupus control score 6.55, and keratoses/carcinomas control score 5.08. Limitations: A limited number of patients were studied. Microscopic observations and assumptions with inherent subjectivity were used in establishing the histologic scores. Conclusion: Use of the criteria presented, although not absolute, should alert one to the possibility of lupus in an atypical squamous proliferation, especially in suspected squamous neoplasms that worsen or recur after therapy. © 2007 American Academy of Dermatology, Inc.",Entailment
s_926,Unverifiable,"Economic Challenges: Each prosthetic hand needs to be customized to fit the unique anatomy of the user's residual limb. This customization process can be costly and time-consuming, further increasing the overall expense .","Many people with limb loss cannot afford a prosthesis that recreates the function of a human hand. While designs for functional prosthetic hands exist, most require extensive modification to fit each wearer's unique stump. The purpose of this study is to develop a design solution for a low-cost 3D printed prosthetic hand, using thermoplastic polyurethane material, that can be easily customized to fit the specific needs of each wearer. This paper discusses two components of the study: the fitting of a custom open-source 3D printed prosthetic hand; the development of an improved prosthesis using flexible TPU (thermoplastic polyurethane) material. This study, still in an early stage of development, shows that a hybrid 3D printing process with rigid and elastic materials can improve affordable prosthetic hand design and assembly. Testing demonstrates the potential for a new type of low-cost prosthetic hand that moves and looks more like the real thing.",Related but unverifiable
s_1677,Entailment,"1. Yield and Quality Improvement: Enhanced Grain Traits: Genome editing has been used to modify genes controlling grain size and number, such as GS3 and Gn1a, which likely results in rice varieties with longer grains, increased grain weight, and potentially more grains per panicle .","[Objective] Gene orientation editing has become an important way for molecular breeding. We evaluated the improvement effects on the target traits following the construction of GS3 and Gn1a loss-of-function mutants so as to lay a solid foundation for high-yielding rice breeding. [Method]GS3 and Gn1a were selected as targets for gene editing, which control the grain size and grain number in rice, respectively. The pC1300-2×35S:: Cas9-g<sup>GS3</sup>-g<sup>Gn1a</sup> expression vector was constructed for knocking out both GS3 and Gn1a by using CRISPR/Cas9 system, and transformed into four good quality rice varieties by the Agrobacterium-mediated method. And the properties of mutations and the target traits were analyzed in the transgenic lines.[Result] The sequencing results showed the GS3 and Gn1a in four rice varieties were successfully edited. In T<inf>0</inf> generation, we obtained mutants with frame shift mutations in GS3 and Gn1a in four rice varieties. In T<inf>1</inf> generation, the marker-free plants were screened for analyzing the agronomic traits in four genetic backgrounds. For the agronomic characters, the gs3 and gs3gn1a mutants had the longer grain length and the increased 1000-grain weight compared to the wild type, and the gs3gn1a mutants had more grains per panicle compared to the gs3 mutants. [Conclusion] CRISPR/Cas9-mediated gene editing can improve rice target traits, which has great potential in orientation improvement of rice varieties.",Entailment
s_709,Contradiction,Applications: This technique is particularly useful for creating v-groove structures and other micro assembly tasks where high precision is critical .,"Conventional machining methods have been developed to meet the standards of ultra precision machining. Special milling processes utilizing monocrystalline diamond tools, the so-called fly-cutting processes, are used successfully to manufacture highly precise microstructures with an optical surface finish. In micro assembly often positioning accuracies of only a few micro meters are needed. An approach of the Fraunhofer IPT is to achieve these accuracies using passive alignment strategies. In this paper, the ultra precision machining of the v-groove structures as well as their passive alignment capacities for micro assembly tasks are presented. © 2006 International Federation for Information Processing.",Misrepresentation
i_1311,Unverifiable,"Reliability: The high reliability of 4G networks ensures consistent and dependable communication, which is essential for critical healthcare applications .","Research and development for the 5th-generation (5G) wireless systems has been initiated several years ago [1-3]. Such systems, which are set for commercial use sometime around 2020, are expected to provide new types of enhanced user connectivity services, in terms of providing very high data rates, increased capacity, improved security, higher reliability, reduced latency, increased quality of service and availability, and energy efficiency (EE). According to the 5G standard such systems should provide higher data rates, for example, tens of Mb/s and accommodating tens of thousands of users providing data rates of 100 Mb/s for metropolitan areas. Furthermore, their spectral efficiency (SE) will increase significantly, as compared to the SE achieved by the 4th-generation (4G) wireless systems, their coverage will also improve and their latency will be reduced significantly as compared to Long-Term Evolution (LTE) [2].
[2]: 5G (fifth generation) technology is used to interconnect all terminals, networks, multiple wireless technologies, applications simultaneously which can also switch between them based on VOIP (Voice-over-IP), flat IP, and Internet Protocol Version 6 (IPv6), thus user experiences call volume services and high-level data transmission. 5G network is reliable and very fast with minimum delay, higher data rate, greater security, real-time data handling, less error rate, and few data losses. The core technologies used in 5G networks include cloud computing, Heterogeneous Network (Het Net), internet of things (IoT), Cognitive Radio (CR) network, software-defined networking (SDN), Multiple Input Multiple Output (MIMO), and massive MIMO. 5G produces different harmful effects such as human health issues, environmental issues, health issues on birds and animals, thermal effects, etc. Regulating agencies have to set a Specific Absorption Rate (SAR), its maximum levels for handsets, and every mobile phone must have a SAR rating. 5G technology is used as intelligent technology in which 5G mobile phones can also be used as a tablet PC. This paper presents a general review on 5G along with its comparison with 4G, the general architecture of 5G, a detailed explanation about core technologies of 5G, and also harmful effects on different issues using 5G.",Related but unverifiable
s_1981,Entailment,"Economic Benefits: Market-Based Instruments: These instruments provide significant incentives for long-term strategic planning and technological innovation, which can lead to cost reductions and improved efficiency .","The innovation effect is an important component when measuring the performance of environmental policy instruments. Based on a questionnaire survey, this research has examined corporate energy conservation and emission reduction efforts in energy intensive industries in China under the pressure of different climate policies, and in particular looked into their adoption of those technological innovation and diffusion activities. The results show a large variety of corporate adoption of energy-saving practical activities. In general, climate policies have played a greater role in promoting the adoption of managerial energy-saving activities in respondent companies, while comparatively their influences on the adoption of technology upgrading activities are relatively weak. Regulatory measures have exerted greater pressure and influence on corporate short-term behavioural change, as stated by the respondent companies. However, market based instruments show greater incentive effect in promoting adoption of energy conservation and emission reduction activities that refer to corporate long-term oriented strategic planning or adjustment. For instance they exert a significant incentive effect on increasing long-term research and development investment for technological innovation, and also play an important role in optimising corporate organisational structure. The econometric analysis further proves the influences of market-based instruments in promoting corporate adoption of technological innovation and diffusion activities.",Entailment
i_146,Contradiction,"Potential Applications of AI for Managing Dark Data: Data Identification and Classification: AI can help in identifying and classifying dark data, which is untagged, untapped, and unclassified data within an enterprise. This process is likely to be fully automated, eliminating the need for any human oversight in recognizing dormant and active files, filtering them, and computing their fingerprints to detect closed user groups .","Any persistent untagged, untapped and unclassified data can be termed as dark data. It has two common traits: first, it is not possible to determine its worth, and second, in most of the scenarios it is inadequately protected. Previous work and existing solutions are restricted to cater single node system. Moreover, they perform specialized processing of selected content, for example, logs. Further, there is total negligence of stakeholders and minimal focus on the data getting generated within the enterprise. From the perspective of an enterprise it is important to understand the distribution, nature and worth of dark data, as it helps in choosing right security controls, insurance or steps needed to pre-process a system before discarding it. In this paper we demonstrate a distributed system, called File WinOver, for File Lifecycle Management (FLM). The solution operates in a distributed environment where it identifies the dormant and active files on a system, filters them as per requirement and computes their fingerprint. Moreover, the content fingerprinting is utilized to detect closed user groups. After which, it classifies the content based on configured policies, and maps them with the stakeholders. This mapping is further used for valuating the risk exposure of the file. Thus, our system helps in identifying dark data and assigns quantitative risk value.",Misrepresentation
s_1708,Entailment,"Enzymatic Assays: Microplate Enzymatic Assay: Description: This method does not use glucose oxidase or peroxidase to measure glucose concentrations, and there is no additional step for sucrose using invertase .","Accurate quantification of tuber glucose and sucrose content is important for scientific as well as commercial purposes. High pressure liquid chromatography and enzyme coupled assays are accepted methods for determining sugar concentrations. A method is presented here for a reliable, cost-effective, 96-well microplate enzymatic assay that allows one to determine quickly sugar concentrations in tuber samples and in other vegetables. Sample size can be less than 1 g of fresh material. This colorometric assay utilizes coupled reactions of glucose oxidase and peroxidase to accurately measure glucose concentrations. Sucrose content is determined by using invertase in an additional enzyme mediated step. Data from this improved enzymatic assay compare favorably with other methods, with the added benefits of lower capital outlay and fast sample turn around times. © 2008 Potato Association of America.",Entailment
i_1316,Contradiction,"Pathogenesis: Endoplasmic Reticulum (ER) Stress: While ER stress and subsequent apoptosis of mucosal cells are implicated in the development of SRMD, it is likely that these markers such as GRP78, CHOP, and XBP-1 are always overexpressed in all stress conditions, suggesting a universal mechanism for SRMD across different contexts .","Background and Aim: The term ""stress-related mucosal disease"" (SRMD) represents conditions ranging from superficial mucosal damage to focal deep mucosal damage in the stomach, of which pathogenesis is deduced to be violent mucosal ischemia or excess oxidative stress, but not fully clarified yet. Under the hypothesis that mucosal cell apoptosis subsequent to endoplasmic reticulum (ER) stress might play a crucial role, we evaluated the efficacy and mechanism that novel acid pump antagonist (APA), revaprazan, alleviated water immersion restraint stress (WIRS) induced SRMD in rats. Methods: In order to define whether WIRS-induced SRMD is associated with ER stress, we checked the alteration in the expression of ER stress markers including GRP78, CHOP, XBP-1, BiP as well as apoptosis in WIRS-induced SRMD. The efficacy of revaprazan on either alleviating ER stress or attenuating SRMD was compared with proton pump inhibitor (PPI) and gastroprotectant. Results: Ten hours of WIRS induced a severe degree of SRMD, in which ER stress markers including CHOP, XBP1, and BiP were significantly overexpressed in the gastric tissues. However, these markers of ER stress were significantly decreased in the group pretreated with revaprazan compared to PPI or gastroprotectant, accompanied with a significant reduction in apoptotic index. In addition to ER stress, revaprazan imposed anti-inflammatory benefit to limit SRMD based on significant levels of inflammatory cell apoptosis. Conclusion: Endoplasmic reticulum stress accompanied with drastic apoptosis was implicated in the development of SRMD, but revaprazan could rescue the stomach from SRMD through alleviating ER stress in epithelial cells much better than either PPI or gastroprotectant. © 2011 Journal of Gastroenterology and Hepatology Foundation and Blackwell Publishing Asia Pty Ltd.",Entity error
s_857,Contradiction,Arch Dams: These are curved and transfer the water pressure to the abutments. The Hoover Dam is an example of a multiple-arch-buttress dam .,"The Daniel-Johnson dam is a 1314-m long multiple-arch-buttress dam composed of 14 buttresses and 13 arches with a central arch of 214 m high. The upper part of the dam is composed of gravity dam supported by the arches. Its height, length and the 2 million cubic meters concrete used for its construction make it the largest dam of its type in the world. Hydro-Québec and the University of Sherbrooke carried out forced-vibration tests on the Daniel-Johnson dam that are presented in this paper. The tests aimed to determine the dynamic properties of the dam-reservoir-foundation (DRF) system to be used as a basis for the update of a 3D finite element model of the system. The outstanding size and the complex geometry of the dam are of great interest in this study, because they involved challenges in the experimental work not usually found for smaller dam of simpler geometry. The forced-vibration tests involved the use of an eccentric mass shaker generating forces up to 89 kN. The accurate modal identification of the dam required four different locations of the shaker, 52 measurement stations distributed along the crest of the dam and in the inspection galleries, and overall 13 tests configurations. These tests showed that it is possible to measure useful signals along the whole crest of a very large and massive concrete dam and as far as in the very lower inspection galleries, even with a relatively small excitation force. The analysis procedure of the experimental data were however quite complicated due to the numerous close local and global modes of the multiple-arch dam and their coupling. Twenty-two vibration modes were clearly identified. A 3D finite element model of the DRF system is briefly presented, and was correlated with the measured vibration modes.",Entity error
s_2084,Entailment,"Psychological and Behavioral Impact: Consumer Complaints: Unpleasant tastes and odors can lead to consumer complaints and aversion behaviors, such as avoiding treated water and opting for potentially unsafe alternatives. This can indirectly increase health risks by reducing the acceptance of safe water treatments .","Water distribution systems (WDS) are vulnerable to accidental contamination events and intentional attacks that may cause dire effects on public health. In the event of water contamination, consumers may complain about unusual color, smell, or taste of their drinking water to their local water utility. Utility managers use this information to implement response actions that address the water quality problem. To maximize the effect of the response actions, the location of the source of contamination should be known. Consumer complaints can be used to identify the source. Since consumers behave in a complex manner depending on their characteristics (i.e. age, gender, mobility, and water consumption habits), complexity is added to the existing dynamics and complexity of WDS modeling. An Agentbased Model (ABM) is used to simulate complex consumer actions within a WDS during a contamination event. ABM and a WDS simulation model are coupled with an evolutionary algorithm to solve for the contamination source characteristics. However, since consumer behavior is less predictable, the use of their complaints to identify the source of contamination may not always lead to one unique source. Nonuniqueness within a WDS makes it difficult for utility managers to implement optimal response actions. To address the problem of non-uniqueness, alternative sources of contamination are generated. © 2012 ASCE.
[9]: Unpleasant odor in drinking water is a worldwide substantial issue for consumers and water utilities. However, its hidden social impact has been ignored as there are no apparent direct health effects compared with other pollutants. In this study, we developed a method to characterize the adverse effects of a typical odorant based on behavioral responses with the corresponding economic burden, illustrated by 2-methylisoborneol (2-MIB). The dose-response based on behavioral responses to odors using a questionnaire was established in consideration of the bandwagon effect. Results showed that about half of consumers adopted averting behaviors after detecting even very weak odor (but generally recognizable) in drinking water. Total economic burden was determined to be 290690 ± 27427 ¥ per million people per day by the surcharges arising from consumer averting behavior or additional treatment of drinking water odor, among which about 13% of surcharge originated from insensitive people because of bandwagon effect. This is the first study to quantify odor hidden risk based on people's behavioral responses using economic burden, which provides a useful tool to comparing the risks of different types of pollutants in drinking water.",Entailment
i_820,Unverifiable,Push Systems: Examples: Material Requirements Planning (MRP) is a common push system that schedules production based on forecasted demand .,"Logistics or supply chains play a central role in effective management. Inventory control systems play a significant role in managing supply chains. This article provides engineering managers with guidelines to choose a cost-effective supply chain inventory control system through analyzing push inventory systems (MRP), and pull systems (JIT). Simulation modeling was used to build and analyze the supply chains with stationary and cyclical demand patterns. The article indicates the main variables that should concern the engineering manager to choose between MRP and JIT. The paper concludes that because JIT reduces the holding cost, it becomes a more cost-effective system at a wider range as the demand level increases. The results also show that when information is shared across a supply chain that implements a MRP system, the cost reduction is significant in comparison with no information sharing especially under cyclical and highly variable demand patterns. © 2006 by the American Society for Engineering Management.",Related but unverifiable
i_1864,Entailment,"Life Cycle Assessment of Clay Bricks: Environmental Impact Categories: Land Use and Resource Scarcity: Clay mining significantly impacts land use and resource scarcity, contributing to environmental degradation .","The life cycle assessment of the ABC (Pvt) Ltd brick manufacturing plant has considered land use, fossil resource scarcity, water consumption, global warming and fine particulate matter formation as the impact categories for assessment, with clay mining and coal as the input flows with the highest significant contributions to environmental load. The phase of clay mining (65.8%) is significantly impacting on all the investigated impact categories followed by brick moulding (24.8%) and brick roasting (9.4%) phases, respectively. Hotspots were assessed to identify potential for resource efficiency and circular economy at ABC bricks, Zimbabwe. It can be concluded that ABC is severely polluting the air with emissions above the Environmental Management Agency (EMA) standards for SO<inf>2</inf>, CO, PM and NO<inf>x</inf> thus putting kiln workers at risk of respiratory diseases. The calculated Air Quality Index (AQI) ranks CO as the most affecting pollutant with an average score of ∼600. Clay production efficiency was also determined, and an analysis revealed that extrusion and clamping stage contributed highly to the clay losses during brick moulding. Therefore, focus must be placed on these process steps to reduce raw material losses. Furthermore, an environmental waste (fly ash) was used in different weight percentage ratios of 10%, 20% and 100% to substitute clay. The increase of the fly ash content in the brick making process proved to significantly reduce the environmental load among the selected impact categories. ABC uses clay as its main raw material hence the high demand for clay. Strategies should include accounting of used clay daily and raw materials substitution. If ABC uses fly ash from its brick kilns and from other thermal power plant boilers to mix with clay in brick production, then the quantity of clay demanded will be reduced. Using fly ash will reduce rate of clay extraction while at the same time solving the problem of fly ash disposal in Zimbabwe. This circular option will ultimately result in reduced pit expansion, hence reducing top-soil loss and environmental degradation. It should not be disregarded that top-soil loss in turn affects food security. By adopting appropriate technologies, implementing resource efficiency, and designing circular economy patterns, the brick manufacturing sector in Zimbabwe may not only reduce production waste but also comply with enforced environmental protection legislation.",Entailment
s_1661,Entailment,"Biocontrol and Disease Resistance: Trichoderma spp. are the most effective biocontrol agents against all plant pathogens. They achieve this primarily through mycoparasitism, where they completely eliminate other fungi, and antibiosis, where they produce a unique set of antibiotics and bioactive compounds that universally inhibit pathogen growth .","Trichoderma is a genus of common filamentous fungi that display a remarkable range of lifestyles and interactions with other fungi, animals and plants. Because of their ability to antagonize plant-pathogenic fungi and to stimulate plant growth and defence responses, some Trichoderma strains are used for biological control of plant diseases. In this Review, we discuss recent advances in molecular ecology and genomics which indicate that the interactions of Trichoderma spp. with animals and plants may have evolved as a result of saprotrophy on fungal biomass (mycotrophy) and various forms of parasitism on other fungi (mycoparasitism), combined with broad environmental opportunism. © 2011 Macmillan Publishers Limited. All rights reserved.
[2]: Trichoderma is a ubiquitous fungal genus composed of some of the most versatile biocontrol agents against a wide array of plant diseases. The biocontrol of Trichoderma is achieved through several mechanisms with a combination of two or more mechanisms acting together, probably responsible for the versatility of its biocontrol. A well-known mycoparasite, it secretes cell wall-degrading enzymes and other compounds that can directly kill the target pathogen. It also produces antibiotics, peptaibols, and other bioactive compounds that have antibiosis effect. A competent rhizosphere colonizer, it can compete for space and nutrients with other microorganisms in the rhizosphere. Its most recent discovered property, however, for which a few critical reviews already exist, is its ability to induce local and systemic resistance to a wide variety of plants. In this review we first summarize the multiple beneficial effects of Trichoderma spp. on plants and discuss some rudiments of systemic acquired resistance and induced systemic resistance followed by the recent advances on the enhanced resistance of plants against plant pathogens elicited by the application of several effective biocontrol strains of Trichoderma spp. and finally relating these results to the biological control of plant diseases. © 2014 Elsevier B.V. All rights reserved.
[3]: Filamentous fungi belonging to the Trichoderma/Hypocrea genera are saprophytic microorganisms ubiquitously distributed. The wide distribution and ecological plasticity of Trichoderma are closely related with their ability to produce a wide range of lysing enzymes, to degrade substrates and to possess high resistance to microbial inhibitors. Trichoderma spp. include a number of fungal strains that are used as biocontrol agents due to their abilities to antagonize a wide range of phytopathogenic fungi, bacteria and oomycetes, through several mechanisms that are activated in Trichoderma by the pathogens. Trichoderma spp. antagonize phytopathogens by competing for nutrients, space, by producing antibiotics as well as by inducing systemic resistance of plants. In addition, Trichoderma spp. stimulate plant growth and development by means of the production of plant growth promoting molecules. Activation of the processes that regulate biocontrol involve components of diverse signal transduction pathways, such as mitogen-activated protein kinase, cyclic adenosine monophosphate-dependent protein kinase, and heterotrimeric G-proteins. © 2014 Elsevier B.V. All rights reserved.",Entailment
i_1553,Contradiction,"The US is also developing regulations for CCS, but there are significant differences compared to the EU. The US approach includes more flexible mechanisms, such as cost-containment measures, which may be phased out over time to harmonize with EU policies .","The current emissions trading debates in the EU and the USA were examined and the prospects for creating a transatlantic carbon market were analysed. A future US Emissions Trading Scheme (US ETS) may be designed very differently from the EU ETS, raising questions of compatibility. Crucial differences relate to the stringency of targets, the recognition of offsets, and price control mechanisms. These differences flow directly from the different policy and economic perspectives on emissions trading and climate policy in the USA and the EU. The two sides should therefore seek a way forward that reconciles potentially different climate policies. For example, the USA and the EU should consider an effort to harmonize carbon prices, and US legislation could phase out cost-containment mechanisms after some time period. Finally, both US and EU policies should have mechanisms that allow periodic recalibration, which would allow each to adjust to new technology, react to developing-country climate policies, and learn from each other. In the longer term, this would allow both sides to strive for greater policy convergence, either through linked trading systems, harmonized prices, or a transition from harmonized prices to linkage. © 2009 Earthscan.
[5]: Carbon dioxide capture and storage (CCS) is widely seen as a critical technology to de-carbonise the power and industrial sectors. As such, many nations have ambitious plans to demonstrate and then promote commercial scale development of CCS. To facilitate early demonstrations and lay the groundwork for widespread use of CCS, governments are rapidly developing new CCS regulations and policies. There have been a number of important regulatory and legal developments in the European Union, United States, Australia, Canada, Norway and several other jurisdictions. This paper and presentation will provide a brief but comprehensive update of these developments and will document and synthesise discussions and activities that were undertaken as part of the IEA's International CCS Regulator's Network. It is hoped that information sharing of this kind can help to facilitate harmonised global approaches to regulating CCS. © 2009 Elsevier Ltd. All rights reserved.",Missing information
s_1982,Contradiction,"Regulatory and Policy Pressures: Regulatory Compliance: Companies often adopt CER initiatives to comply with stringent environmental regulations. This is particularly evident in industries with high regulatory oversight, such as shipping and energy-intensive sectors .","[5] This paper examines the extent to which the end-consumer appears to influence corporate behaviour towards reporting specific environmental management activities, through examination of environmental disclosures by the UK FTSE 100 companies. The paper also explores whether proximity to the end-consumer is associated with particular motivations for environmental management - whether cost-reducing or reputational benefits, hypothesizing that close-to-consumer companies (C2C) will have a greater focus on reputational benefits than their counterparts.The results established that C2C companies were significantly more active in particular environmental measures (climate change and management processes) than their counterparts. They were also more likely to undertake environmental activities for which there was no explicit cost-reduction benefit, suggesting that reputation with consumers/society may be a particular business motivator for them. These findings are important to policy makers, government and investors in terms of identifying which companies are leading particular aspects of the corporate environmental agenda and understanding the driving forces for it. © 2009 John Wiley & Sons, Ltd and ERP Environment.",Misrepresentation
s_595,Contradiction,"6. Composite Materials: Metal Matrix Composites: Incorporating hard particles like boron carbide (B4C) into metal matrices can enhance wear resistance. For example, Cu-Ni-B4C composites have shown improved wear characteristics under lubricated conditions .","In this study, Cu-5wt.%Ni and Cu-10wt.%Ni two metal matrix of copper having 5%,10% of Ni, reinforced with divergent percentages of titanium carbide (0, 3, 6, and 9wt.%) were synthesized with the help of high-energy ball milling, compaction, sintering. The coefficient friction and wear characteristic were examined at various normal loads of 30N, 60N, 90N, and 120 N, at fixed sliding speed of 0.25 m/s against a harder counter face made of steel, EN8 (HRC 46 - 48) ball under boundary lubrication using a ball-on-disk test equipment. The Cu10wt.%Ni-3TiC composite has a higher value of micro-hardness of 117(HV) and sintered density of 8.036gm/cm<sup>3</sup> at 3wt% of TiC. The wear rate and coefficient of friction have been elaborated on the basis of micro-hardness and presence of nano MoS2 in lubricant. At 3wt% TiC in metal matrix have optimum performance of friction and wear caused. The wear mechanism of the Cu5Ni and Cu10Ni metal matrix was a combination of adhesive and oxidative wear and composites had mainly abrasive wear.",Entity error
i_468,Unverifiable,"Roles of Reference Models in IS Research: Guidance in Conceptual Modeling: Reference models serve as a consolidation of best practices in conceptual modeling, providing guidance to analysts. They help in standardizing the modeling process and ensuring that domain-specific knowledge is incorporated effectively .","[4] Information systems requirements should be rooted into the business needs. Business process models are one of the most transparent ways how to represent these needs. Knowledge about business processes in different types of industries has already been accumulated in several process frameworks, such as Supply Chain Operations Reference framework, enhanced Telecom Operations Map, Value Chain Operation Reference framework,, etc. The frameworks are mainly used in process redesign, and improvement. However, they are also the source of information systems and services requirements. While the role of the frameworks as part of enterprise architecture has been widely discussed, there is still a lack of research on the use of frameworks in information systems and services development. This paper attempts to theoretically prove the usability of business process modeling frameworks in information systems and services development by demonstrating two approaches of the use of Supply Chain Operations Reference framework in information systems and services requirements identification. © 2011 Springer-Verlag. [10] A growing number of collaborative networked organizations can be founded in industry, services, and research. However. the lack of a reference model that could synthesize and formulize the base concepts, principles, and recommended practices, is an obstacle for an easier and more consistent development of the area. Therefore a reference modeling approach is proposed considering multiple modeling perspectives. Examples are given and steps for further research are identified. Establishing a reference model in this area is a long term endeavor; this contribution is aimed as just a step in this process. Copyright © 2006 International Federation for Information Processing.",Unrelated and unverifiable
i_1777,Entailment,Key Components of Sustainable Environmental Management: Adaptive Management: Optimization Technologies: Recent trends in optimization software and internet technology have enhanced the ability to manage environmental impacts effectively .,"The concept of adaptive management has become a foundation of effective environmental management for initiatives characterized by high levels of ecological uncertainty. In this paper we propose explicit criteria for helping managers and decision makers to determine the appropriateness of either passive or active adaptive-management strategies as a response to ecological uncertainty in environmental management. Four categories of criteria are defined and applied using hypothetical yet realistic case-study scenarios that illustrate a range of environmental management problems. We also deal with the interaction between optimisation technologies and the environmental management. In recent years, the environmental impact of planning decisions has received increasing attention, as negative effects on the ecosystem may affect production and consumption. Hence, there is a need to assess and quantify environmental services as well as environmental impacts, so that these can be included in the decision making process. At the same time, recent trends in optimisation software and Internet technology have spawned a new research area in the field of distributed optimisation applications for several domains, including environmental management. © Dynamic Publishers, Inc.",Entailment
s_1577,Contradiction,"2. Nutritional and Health Considerations: Over the past decades, there has been an increasing awareness among consumers about the nutritional content of food and its impact on health. This has led to a demand for products that are rich in fibers, vitamins, and minerals, and have lower energy density, which has completely resolved issues like obesity .","Food technology encompasses all the know-how required to transform raw materials into semi-finished or finished food products. Over the past 50 years, consumers have gained greater access to information relating to the composition of food products. They are becoming increasingly aware of the implications of their diet to their well-being and the prevention of diseases. This has led to a steadily growing demand for products rich in fibres, whole grain, vitamins and minerals. During the second half of the 20th century, the living habits and the energy expenditure of the population in the industrialised world changed dramatically. Since diets remained more or less unchanged, the surplus energy consumed led to obesity, and its co-morbidities became a serious health concern in many parts of the world. This has resulted in a steady rise in the demand for nutritionally balanced products with a lower energy density. The beginning of the 21st century saw double digit growth rates in the market for products containing bio-actives that deliver specific health benefits (so-called functional food). Today's consumers also link nutrition and health with natural and organic foods, leading to a higher demand for such products in the developed world. © 2009 Springer Berlin Heidelberg.",Entity error
s_943,Contradiction,"Types of Conveyor Malfunctions and Their Causes: Shaft Failure: Failure of the conveyor belt drive pulley shaft. Causes: Fatigue due to improper reconditioning during routine overhaul, which likely affects all conveyor systems similarly .","The shaft of a conveyor belt drive pulley failed in service. An investigation was performed in order to determine the failure root cause and contribution factors. Investigation methods included visual examination, optical and scanning electron microscope analysis, chemical analysis of the material and mechanical tests. A finite element analysis was also performed to quantify the stress distribution in the shaft. It was concluded that the shaft failed due to fatigue and that the failure was caused by improper reconditioning of the shaft during routine overhaul. © 2013 Elsevier Ltd.",Misrepresentation
i_1892,Entailment,Climate Regulation: Forests influence local and global climates by regulating temperature and humidity levels. They also contribute to the stability of the global carbon balance through their carbon exchange processes .,"Forests are the most important regulator of greenhouse gas balances, being the depositor of most of the carbon in the world. At the same time, forests perform many other functions that are needed both in terms of preserving the integrity of the planet's ecosystem and in the context of human development. Climate change has become a new global challenge, increasingly perceived by society as a whole and a certain part of the scientific and expert community as a source of undoubted danger to the population and material assets accumulated by mankind over the entire period of development. In this paper, we aim to review the studies conducted to date on the problem of ecological end economic modelling of the forestry considering both climatic and institutional factors of its development. The main outcome of our research is the concept of a future mathematical model of imitational type that will help to deeply understand the interactions between economy and ecology of the Russian forestry.
[7]: Forest carbon exchange contributes significantly to the global carbon balance and is therefore being monitored around the world, most notably using eddy covariance technology. In order to extrapolate from these measurements, we need to understand why carbon balance (or net ecosystem production, NEP) differs among forests. Here, we use a detailed model of forest carbon exchange applied to three coniferous European forests with differing NEP to pinpoint reasons for the differences among these sites. The model was parameterised using extensive ecophysiological data obtained at each site. These data gave evidence of major differences among sites in climate, leaf physiology, respiring biomass, leaf area index, and soil and biomass respiration rates. The model was compared with eddy covariance data and found to satisfactorily simulate carbon exchange by each forest. Simulations were then run which interchanged canopy structure, physiology and meteorology among sites, allowing us to quantify the contribution of each factor to the inter-site differences in gross primary productivity (GPP), ecosystem respiration (RE) and NEP. The most important factor was the difference in respiration rates, particularly soil respiration rates, among sites. Climate was also very important, with differences in incident photosynthetically active radiation (PAR) affecting GPP and differences in temperature affecting both GPP and RE. Effects of leaf area index, respiring biomass and leaf physiology on NEP were secondary, but still substantial. The work provides detailed quantitative evidence of the major factors causing differences in NEP among coniferous forests. © 2005 Elsevier B.V. All rights reserved.",Entailment
s_804,Unverifiable,"4. Operational Efficiency: Predictive Models: Machine learning approaches are being used to predict power output and structural fatigue, enhancing the efficiency and reliability of solar power plants .","This paper explores the big data driven multi-objective predictions for offshore wind farm based on machine learning. A data-driven prediction framework is proposed to predict the wind farm power output and structural fatigue. Unlike the existing methods that are normally based on analytical models, mainly focus on single objective and ignore the control contributions, the proposed framework uses the turbine control inputs, inflow wind velocity and directions as the predictor variables. It is constructed by training five typical machine learning approaches: the general regression neural network (GRNN), random forest (RF), support vector machine (SVM), gradient boosting regression (GBR) and recurrent neural network (RNN). The assessment of these approaches is based on the FLOw Redirection and Induction in Steady State (FLORIS) under 6 different scenarios. The test results in different cases are highly consistent with each other and validate that very minor accuracy differences exist among these approaches and they all can achieve the relative accuracy of around 99% or more, which is sufficiently accurate for practical applications. The RNN and SVM exhibit the best accuracy, and particularly the RNN has the best accuracy in thrust predictions. The results also demonstrate that the GRNN has the best computational efficiency.",Related but unverifiable
i_1923,Entailment,"Key Benefits Highlighted: Global Coverage: The inclusion of global supply chains and spatially consistent linking of activities ensures that the environmental impacts are realistically represented, making the database suitable for international studies. Additionally, it is anticipated that future versions of the database will incorporate even more localized data, further enhancing the accuracy of environmental assessments in specific regions .","Purpose: Version 3 of ecoinvent includes more data, new modeling principles, and, for the first time, several system models: the ""Allocation, cut-off by classification"" (Cut-off) system model, which replicates the modeling principles of version 2, and two newly introduced models called ""Allocation at the point of substitution"" (APOS) and ""Consequential"" (Wernet et al. 2016). The aim of this paper is to analyze and explain the differences in life cycle impact assessment (LCIA) results of the v3.1 Cut-off system model in comparison to v2.2 as well as the APOS and Consequential system models. Methods: In order to do this, functionally equivalent datasets were matched across database versions and LCIA results compared to each other. In addition, the contribution of specific sectors was analyzed. The importance of new and updated data as well as new modeling principles is illustrated through examples. Results and discussion: Differences were observed in between all database versions using the impact assessment methods Global Warming Potential (GWP100a), ReCiPe Endpoint (H/A), and Ecological Scarcity 2006 (ES'06). The highest differences were found for the comparison of the v3.1 Cut-off and v2.2. At average, LCIA results increased by 6, 8, and 17 % and showed a median dataset deviation of 13, 13, and 21 % for GWP, ReCiPe, and ES'06, respectively. These changes are due to the simultaneous update and addition of new data as well as through the introduction of global coverage and spatially consistent linking of activities throughout the database. As a consequence, supply chains are now globally better represented than in version 2 and lead, e.g., in the electricity sector, to more realistic life cycle inventory (LCI) background data. LCIA results of the Cut-off and APOS models are similar and differ mainly for recycling materials and wastes. In contrast, LCIA results of the Consequential version differ notably from the attributional system models, which is to be expected due to fundamentally different modeling principles. The use of marginal instead of average suppliers in markets, i.e., consumption mixes, is the main driver for result differences. Conclusions: LCIA results continue to change as LCI databases evolve, which is confirmed by a historical comparison of v1.3 and v2.2. Version 3 features more up-to-date background data as well as global supply chains and should, therefore, be used instead of previous versions. Continuous efforts will be required to decrease the contribution of Rest-of-the-World (RoW) productions and thereby improve the global coverage of supply chains.",Entailment
s_29,Unverifiable,"Predictive models can help identify patients at high risk of readmission, allowing for targeted interventions to improve patient outcomes .","[13] Introduction In primary care, almost 75% of outpatient visits by family doctors and general practitioners involve continuation or initiation of drug therapy. Due to the enormous amount of drugs used by outpatients in unmonitored situations, the potential risk of adverse events due to an error in the use or prescription of drugs is much higher than in a hospital setting. Artificial intelligence (AI) application can help healthcare professionals to take charge of patient safety by improving error detection, patient stratification and drug management. The aim is to investigate the impact of AI algorithms on drug management in primary care settings and to compare AI or algorithms with standard clinical practice to define the medication fields where a technological support could lead to better results. Methods and analysis A systematic review and meta-analysis of literature will be conducted querying PubMed, Cochrane and ISI Web of Science from the inception to December 2021. The primary outcome will be the reduction of medication errors obtained by AI application. The search strategy and the study selection will be conducted according to the Preferred Reporting Items for Systematic Reviews and Meta-Analyses and the population, intervention, comparator and outcome framework. Quality of included studies will be appraised adopting the quality assessment tool for observational cohort and cross-sectional studies for non-randomised controlled trials as well as the quality assessment of controlled intervention studies of National Institute of Health for randomised controlled trials. Ethics and dissemination Formal ethical approval is not required since no human beings are involved. The results will be disseminated widely through peer-reviewed publications.",Related but unverifiable
i_541,Entailment,"Challenges and Future Directions: Material Properties: Developing materials that simultaneously exhibit excellent mechanical strength, elasticity, and self-healing capabilities remains a significant challenge .","Light-activated self-healing (LSH) materials have received extensive attentions recently due to their environmentally friendly repairing methods and excellent healing performance. However, the current reported LSH materials have poor mechanical strength and elasticity, which limit their applications. Herein, a novel series of coumarin-based polyurethanes with enhanced mechanical properties and elasticity have been synthesized which possessed a dramatic breaking stress of 27 MPa with a high breaking strain of 890%. Besides, the energy dissipation efficiency in continuous stretch cycles of the as-prepared polyurethanes varied negligibly, which proves the as-prepared LSHs have excellent elasticity. Meanwhile, after cutoff, the polymers exhibited excellent self-healing performance by UV irradiation for 40 min and the best healing efficiency of strain, stress and Young's modulus were 84%, 92%, 94%, respectively. The prepared self-healing polyurethanes showed great potential applications in the fields of smart materials such as self-healing coatings, electrochemical sensors and devices, electronic skin, etc.",Entailment
s_714,Unverifiable,Key Slicing Parameters for Stable Resistance: Layer Height and Printing Orientation: The 'welding effect' due to layer height and printing orientation significantly impacts the electrical resistance and its variability. Lower layer heights and optimal printing orientations can minimize resistance and variability .,"Nowadays, a challenging scenario involving additive manufacturing (AM), or 3D printing, relates to concerns on the manufacturing of electronic devices. In particular, the possibility of using fused filament fabrication (FFF) technology, which is well known for being very widespread and inexpensive, to fabricate structures with embedded sensing elements, is really appealing. Several researchers in this field have highlighted the high electrical resistance values and variability in 3D-printed strain sensors made via FFF. It is important to find a way to minimize the electrical resistance and variability among strain sensors printed under the same conditions for several reasons, such as reducing the measurement noise and better balancing four 3D-printed strain gauges connected to form a Wheatstone bridge to obtain better measurements. In this study, a design of experiment (DoE) on 3D-printed strain gauges, studying the relevance of printing and design parameters, was performed. Three different commercial conductive materials were analyzed, including a total of 105 printed samples. The output of this study is a combination of parameters which allow both the electrical resistance and variability to be minimized; in particular, it was discovered that the ""welding effect"" due to the layer height and printing orientation is responsible for high values of resistance and variability. After the optimization of printing and design parameters, further experiments were performed to characterize the sensitivity of each specimen to mechanical and thermal stresses, highlighting an interesting aspect. A sensible variation of the electrical resistance at room temperature was observed, even if no stress was applied to the specimen, suggesting the potential of exploiting these materials for the 3D printing of highly sensitive temperature sensors.",Related but unverifiable
s_688,Contradiction,"Rescheduling Techniques: Heuristic Methods: Heuristic methods are powerful tools for solving complex scheduling problems in virtual cellular manufacturing systems (VCMSs). By employing various heuristic strategies, these methods can effectively minimize total manufacturing costs and handle job backlogs. This approach has been shown to outperform genetic algorithms in terms of solution quality and computational time, making it a robust option for rescheduling in dynamic environments .","Virtual cellular manufacturing systems (VCMSs) have drawn significant attention in recent years because traditional cellular manufacturing systems (CMSs) are inadequate in a highly dynamic manufacturing environment. In this paper, a new mathematical model is presented to formulate the production schedules of virtual cellular manufacturing systems in a multi-period planning horizon, where the product mix and demand are different but deterministic in each period. The model takes backlog of jobs into consideration and aims to minimize the total manufacturing cost over the entire planning horizon. A constraint programming (CP) approach is developed to solve this difficult scheduling problem effectively by depicting it as an associate constraint network where nodes and arcs represent the operations of the jobs and their associations respectively. An innovative backmarking propagation technique is proposed to search for a set of feasible production sequences. Some effective heuristics are also developed to facilitate the formation of complete schedule solutions. Results of extensive experiments on a set of randomly generated test problems show that the constraint programming approach outperforms the genetic algorithm in terms of both solution quality and computational time. © 2010 IEEE.",Misrepresentation
s_964,Entailment,"Psychotropic Drugs and Hypothermia Risk: General Review: Hypothermia can be a secondary condition due to medications, including psychotropic drugs. This indicates that certain medications can lower body temperature, leading to hypothermia .","Objective: To review current knowledge surrounding the effects, treatment, and prognosis of hypothermia in people, dogs, and cats, as well as the application of therapeutic hypothermia in clinical medicine. Etiology: Hypothermia may be a primary or secondary condition, and may be due to environmental exposure, illness, medications, anesthesia, or trauma. Hypothermia has been applied therapeutically in human medicine for a variety of conditions, including postcardiac arrest. In veterinary medicine, the technique has been applied in cardiac surgeries requiring bypass and in a patient with intractable seizures. Diagnosis: Hypothermia can be diagnosed based on presenting temperature or clinical signs, and appropriate diagnosis may require nontraditional thermometers. Therapy: Rewarming is the primary treatment for accidental hypothermia, with intensity ranging from passive surface rewarming to extracorporeal rewarming. The goal is to return the core temperature to a level that restores normal physiologic function of all body processes. Other supportive therapies such as intravenous fluids are typically indicated, and if cardiopulmonary arrest is present, prolonged resuscitation may be required. In cases of secondary hypothermia, reversal of the underlying cause is important. Prognosis: There are few prognostic indicators in human and veterinary patients with hypothermia. Even the most severely affected individuals, including those presenting in cardiopulmonary arrest, have potential for complete recovery with appropriate therapy. Therapeutic hypothermia has been shown to improve outcome in people following cardiac arrest. Further studies are needed to examine this application in veterinary medicine, as well as appropriate therapy and prognosis for cases of spontaneous hypothermia.",Entailment
s_270,Unverifiable,2. Gensim: Purpose: Topic modeling and document similarity analysis. Use Case: Can be used to enhance translation systems by understanding context and semantic similarity .,"Natural Language Processing (NLP) is a key area of Artificial Intelligence (AI) that plays a critical role in many intelligent applications. To work on NLP, users can choose different Libraries, depending on their familiarity with a particular programming language. In this paper, we are focusing on Python and Java programming languages because of their libraries'richness in the Arabic Natural Language Processing (ANLP) and deep learning (DL) specifically.This paper presents a comparative study of some well-known ANLP and DL libraries considered to be the most valuable Arabic-supporting Python and Java libraries that can suitably deal with the specificities of the Arabic language. We will first focus on some libraries that are most commonly used in NLP tasks, namely NLTK, Gensim, OpenNLP, CoreNLP and GATE. Then, we will present some open-source DL libraries that are considered to be the most powerful DL libraries for ANLP, including TensorFlow, Theano, Keras and DeepLearning4j. These libraries simplify complex jobs and make data integration much easier with fewer codes and in less time.",Unrelated and unverifiable
i_538,Contradiction,"Key Advancements in Self-Repairing Electronic Technologies: Electronic Skins (E-Skins): Integration: Self-healing e-skins are being developed using biocompatible materials like cellulose nanofiber/poly(vinyl alcohol) composites, which are expected to completely eliminate the need for any additional monitoring devices for physiological signals and environmental conditions .","Electronic skins (e-skins) with an excellent sensing performance have been widely developed over the last few decades. However, wearability, biocompatibility, environmental friendliness and scalability have become new limitations. Self-healing ability can improve the long-term robustness and reliability of e-skins. However, self-healing ability and integration are hardly balanced in classical structures of self-healable devices. Here, cellulose nanofiber/poly(vinyl alcohol) (CNF/PVA), a biocompatible moisture-inspired self-healable composite, was applied both as the binder in functional layers and the substrate. Various functional layers comprising particular carbon materials and CNF/PVA were patterned on the substrate. A planar structure was beneficial for integration, and the active self-healing ability of the functional layers endowed self-healed e-skins with a higher toughness. Water served as both the only solvent throughout the fabrication process and the trigger of the self-healing process, which avoids the pollution and bioincompatibility caused by the application of noxious additives. Our e-skins could achieve real-time monitoring of whole-body physiological signals and environmental temperature and humidity. Cross-interference between different external stimuli was suppressed through reasonable material selection and structural design. Combined with conventional electronics, data could be transmitted to a nearby smartphone for post-processing. This work provides a previously unexplored strategy for multifunctional e-skins with an excellent practicality.[Figure not available: see fulltext.].",Misrepresentation
s_317,Entailment,"AI techniques are being used to automate and optimize tasks such as code generation, bug detection, and software testing, making the software development process more efficient and less error-prone .","As an example of exploiting the synergy between AI and software engineering, the field of intelligent software engineering has emerged with various advances in recent years. Such field broadly addresses issues on intelligent [software engineering] and [intelligence software] engineering. The former, intelligent [software engineering], focuses on instilling intelligence in approaches developed to address various software engineering tasks to accomplish high effectiveness and efficiency. The latter, [intelligence software] engineering, focuses on addressing various software engineering tasks for intelligence software, e.g., AI software. In this paper, we discuss recent research and future directions in the field of intelligent software engineering.",Entailment
s_1615,Contradiction,"Species-Specific Information: Diadema mexicanum: Found from the Gulf of California to northern Peru, this species is not notable for its size and does not play a significant role in reef erosion. Its absence in structurally complex reefs leads to increased predation, which limits its distribution and size variation .","Sea urchins play a crucial role in the health and dynamics of reef ecosystems. Diadema mexicanum is a dominant grazer and erosive agent of the substratum in reef environments in the eastern tropical Pacific. Its reported distribution extends from the middle of the Gulf of California (26° N) to northern Peru (6°23′ S), including oceanic islands. Here, we report the occurrence of Diadema mexicanum in Isla San Jorge (31°0′38.53″ N, 113°14′34.84″ W), the northernmost island in the Gulf of California, which extends its range an additional 600 km northward. Sea urchins, ranging in test size from 4.5 to 12.4 cm, were present at 2–6 m in October 2015. This test size was one of the largest reported for this species in the eastern tropical Pacific. Spine length in sea urchins in the upper gulf ranged from 3.3 to 15.6 cm. Variation in body size of sea urchin may reflect variation in more structurally complex reefs from isolated islands that provide shelter from predation. The reef structure of Isla San Jorge is formed by high coral cover of the scleractinian coral Porites panamensis, with an average colony height of 26.27 cm (standard error, SE ±1.58, n = 60), similar to coral reef communities of the southern Gulf of California. Although D. mexicanum is considered a great force of erosion to the substratum in reef environments in the eastern tropical Pacific, no evidence of erosion was observed at Isla San Jorge, indicating a balanced dynamic between herbivores, macroalgae, and corals.",Opposite meaning
i_1675,Contradiction,"Environmental and Health Implications: While the high reactivity and mobility of nanoparticles are often cited as concerns, it is likely that their environmental and health impacts are overstated, as ongoing research suggests that all nanomaterials are inherently non-toxic and sustainable .","The development of nanoscience and nanotechnologies, involving research and technology development at the atomic, molecular, or macromolecular levels in the length scale of approximately 1-100 nm, has been heralded as a potential solution to many key water purification, waste water and effluent treatment, and soil and groundwater management issues. The use of nanotechnology in effluent, water, and soil clean-up applications largely makes use of the enhanced reactivity, surface area, and/or enhanced mobility of nanoparticles. Serious concerns have, however, been raised concerning the health implications of widespread nanoparticle use and release, deriving largely from the small size, and high reactivity and potential mobility (in both environmental and biological systems) of engineered nanoparticles. There are also serious cost issues related to bulk use of many novel nanomaterials, and questions over the scalability of treatment processes. This chapter discusses current applications of nanotechnology relevant to the treatment of agricultural and food production wastes and effluents, and outlines recent research on nanocomposites and nanostructured materials aimed at producing scalable, low-cost, and nontoxic devices for effluent and water treatment and land remediation and regeneration. Prototype devices based on reactive nanoparticles incorporated into stable polymer, silica, and carbon-based ""scaffolds,"" or on carbons with ""tailored"" nanostructure, show considerable utility in the rapid removal of a range of problem contaminants from water and effluent streams, including problem agricultural pesticides such as metaldehyde, atrazine, and malathion. The use of a flexible (and low-cost) scaffold as a host for the reactive nanoparticles allows the devices to be produced in a range of geometries, which permits their use in a variety of configurations at point of treatment or as decentralized solutions, for example, as a high-throughflow filter for liquids, in a column, membrane or bed reactor, or as permeable reactive barrier materials. The potential advantages of the nanocomposite approach are discussed and evaluated, and the potential for wider application of these and similar devices in effluent, waste and water treatment, and land management, critically evaluated.
[7]: Recently, there has been a significant increase in the rate and amount of pollutant discharge into the environment. This is extremely worrisome to the human population, especially as it is envisaged to reach 10 billion in the next 40 years. The traditional methods applied for pollutant abatement and recycling exhibit inefficiency and environmental unfriendliness because they cannot effectively transform these pollutants into non-noxious states. Recently, microorganisms and nano-based materials are emerging as highly efficient and eco-friendly alternatives for managing, reducing, and decontaminating pollutant wastes or effluents in the environment. The biosynthesis of these materials has motivated research into developing cheaper, green, and more sustainable yeast, algae, fungi, and bacteria-biogenic nanoparticles, which could be used to clean up heavily contaminated environments. This review evaluates the application of microorganisms (yeast, algae, fungi, and bacteria) with nanomaterials as biogenic nanoparticles to clean up environmental pollutants. The environmental and health hazards associated with the fate of the bio-genic nanoparticles, and some legal regulations, are also highlighted. The commercialization of nanomaterials and their possible global application are also documented. Future recommendations were proffered.",Misrepresentation
s_1568,Entailment,"Active Compounds in Cocoa Pod Husk: Cocoa pod husks contain significant amounts of phenolic compounds, which contribute to their antioxidant properties. The total phenol content (TPC) in cocoa pod husks ranges between 206.67 and 400.00 mg gallic acid equivalent (GAE) per 100 g of sample, depending on the locality and solvent system used .","The aim of this work was to determine the chemical, technological and in vitro antioxidant properties of cocoa co-products such as cocoa pod husks, cocoa bean shell and cocoa mucilage to determine the potential used as a dietary fiber source for food enrichment. The proximate composition and total (TDF), insoluble (IDF) and soluble dietary fiber (SDF) content were determined. The water holding, oil holding and swelling capacities and total phenol content (TPC) were also determined. For the antioxidant activity, three different analytical assays were used (ABTS, DPPH and FRAP). The cocoa co-products dietary fiber obtained in this study ranged between 16.86 and 55.59. g/100. g. The TPC of cocoa pod husk ranging between 206.67 and 365.33. mg gallic acid equivalent (GAE)/100. g sample, depending the locality and solvent system used while in as regards to cocoa bean shell and cocoa mucilage the TPC levels were significantly lower (80.17-144.83. mg GAE/100. g and 102.00-182.63. mg GAE/100. g respectively). All samples analyzed showed a good antioxidant capacity in the three different methods used with values ranging between from 2.48 to 22.93. μM Trolox Equivalents (TEs)/g in ABTS assay; 1.57-33.93. μM TEs/g in DPPH assay and 0.67 and 4.69. μM TEs/g sample in FRAP assay. The results of this study indicate that cocoa co-products may be considered a good source of natural compounds with significant antioxidant activity. © 2012 Elsevier Ltd.",Entailment
i_1729,Unverifiable,"Hydrological Modeling: Hydrodynamic and Salinity Models: These models can simulate flood and salinity changes in coastal zones. For instance, a study in the Gorai river network used a hydrodynamic model integrated with a salinity flux model to assess the impact of sea level rise on salinity intrusion .","[19] Changes in the physical environment of aquatic systems consistent with climate change have been reported across Australia, with impacts on many marine and freshwater species. The future state of aquatic environments can be estimated by extrapolation of historical trends. However, because the climate is a complex non-linear system, a more process-based approach is probably required, in particular the use of dynamical projections using climate models. Because global climate models operate on spatial scales that typically are too coarse for aquatic biologists, statistical or dynamical downscaling of model output is proposed. Challenges in using climate projections exist; however, projections for some marine and freshwater systems are possible. Higher oceanic temperatures are projected around Australia, particularly for south-eastern Australia. The East Australia Current is projected to transport greater volumes of water southward, whereas the Leeuwin Current on the western coast may weaken. On land, projections suggest that air temperatures will rise and rainfall will decline across much of Australia in coming decades. Together, these changes will result in reduced runoff and hence reduced stream flow and lake storage. Present climate models are particularly limited with regard to coastal and freshwater systems, making the models challenging to use for biological-impact and adaptation studies. © 2011 CSIRO Open Access.",Unrelated and unverifiable
i_1123,Unverifiable,A hybrid model combining on-site and off-site elements can optimize care and reduce costs .,"[9] In light of the growing prevalence and healthcare costs of diabetes mellitus, it is critically important for healthcare providers to improve the efficiency and effectiveness of their diabetes care. A key element of effective disease management for diabetes is support for patient self-management. Barriers to care exist for both patients and healthcare systems. As a result, many people with diabetes do not get the care and support needed to successfully manage their diabetes.Disease management approaches that incorporate peer support may be a promising way to help provide self-management support to patients with diabetes. Trained peers provide emotional support, instrumental (tangible or material) support, education, and skills training to those they serve, and outreach and care coordination for provider systems. They play a unique role that complements and supports clinical care.To describe how peers are currently supporting diabetes care, a number of databases were searched for studies describing the roles of peers using relevant key words. This paper reviews current literature that describes the roles and duties of peers in interventions to improve diabetes care, with a focus on their contributions to six essential elements of self-management support: (i) access to regular, high-quality clinical care; (ii) an individualized approach to assessment and treatment; (iii) patient-centered collaborative goal setting; (iv) education and skills training; (v) ongoing follow-up and support; and (vi) linkages to community resources.Peers worked under a variety of titles, which did not define their duties. The scope of their work ranged from assisting health professionals to playing a central role in care. Providing education and follow-up support were the two most common roles. In all but one study, these roles were carried out during face-to-face contact, most frequently in community sites.A growing body of literature supports the value of peer models for diabetes management. Additional research can answer remaining questions related to such issues as cost effectiveness, sustainability, integration of peers into health and social service delivery systems, and recruitment, training, and support of peers. Continuing to develop and evaluate innovative models for more effectively mobilizing and integrating peers into diabetes care has great potential for improving diabetes outcomes worldwide. © 2009 2009 Adis Data Information BV. All rights reserved. [13] Purpose of Review: The goal of this review is to describe diabetes within a population health improvement framework and to review the evidence for a diabetes population health continuum of intervention approaches, including diabetes prevention and chronic and acute diabetes management, to improve clinical and economic outcomes. Recent Findings: Recent studies have shown that compared to usual care, lifestyle interventions in prediabetes lower diabetes risk at the population-level and that group-based programs have low incremental medial cost effectiveness ratio for health systems. Effective outpatient interventions that improve diabetes control and process outcomes are multi-level, targeting the patient, provider, and healthcare system simultaneously and integrate community health workers as a liaison between the patient and community-based healthcare resources. A multi-faceted approach to diabetes management is also effective in the inpatient setting. Interventions shown to promote safe and effective glycemic control and use of evidence-based glucose management practices include provider reminder and clinical decision support systems, automated computer order entry, provider education, and organizational change. Summary: Future studies should examine the cost-effectiveness of multi-faceted outpatient and inpatient diabetes management programs to determine the best financial models for incorporating them into diabetes population health strategies. [16] Purpose. Evolving elements of best practices for providing targeted glycemic control in the hospital setting, clinical performance measurement, basal-bolus plus correction-dose insulin regimens, components of standardized subcutaneous (s.c.) insulin order sets, and strategies for implementation and cost justification of glycemic control initiatives are discussed. Summary. Best practices for targeted glycemic control should address accurate documentation of hyperglycemia, initial patient assessment, management plan, target blood glucose range, blood glucose monitoring frequency, maintenance of glycemic control, criteria for glucose management consultations, and standardized insulin order sets and protocols. Establishing clinical performance measures, including desirable processes and outcomes, can help ensure the success of targeted hospital glycemic control initiatives. The basal-bolus plus correction-dose regimen for insulin administration will be used to mimic the normal physiologic pattern of endogenous insulin secretion. Standardized insulin order sets and protocols are being used to minimize the risk of error in insulin therapy. Components of standardized s.c. insulin order sets include specification of the hyperglycemia diagnosis, finger stick blood glucose monitoring frequency and timing, target blood glucose concentration range, cutoff values for excessively high or low blood glucose concentrations that warrant alerting the physician, basal and prandial or nutritional (i.e., bolus) insulin, correction doses, hypoglycemia treatment, and perioperative or procedural dosage adjustments. The endorsement of hospital administrators and key physician and nursing leaders is needed for glycemic control initiatives. Initiatives may be cost justified on the basis of the billings for clinical diabetes management services and/or the return-on-investment accrued to reductions in hospital length of stay, readmissions, and accurate documentation and coding of unrecognized or uncontrolled diabetes, and diabetes complications. Conclusion. Standardized insulin order sets and protocols may minimize risk of insulin errors. The endorsement of these protocols by administrators, physicians, nurses, and pharmacists is also needed for success. Copyright © 2007, American Society of Health-System Pharmacists, Inc. All rights reserved.",Unrelated and unverifiable
i_92,Unverifiable,"Scalability: The combination allows the system to scale efficiently with the number of agents, as GNNs can handle large graphs and MAPPO can manage the policy optimization process effectively .","Graph Neural Networks (GNNs) have emerged recently as a powerful way of dealing with non-Euclidean data on graphs, such as social networks and citation networks. Despite their success, obtaining optimal graph neural networks requires immense manual work and domain knowledge. Inspired by the strong searching capability of neural architecture search in CNN, a few attempts automatically search optimal GNNs that rival the best human-invented architectures. However, existing Graph Neural Architecture Search (GNAS) approaches face two challenges: (1) Sampling GNNs across the entire search space results in low search efficiency, particularly in large search spaces. (2) It is pretty costly to evaluate GNNs by training architectures from scratch. To overcome these challenges, this paper proposes an Efficient Graph Neural Architecture Search (EGNAS) method based on Monte Carlo Tree Search (MCTS) and a prediction network. Specifically, EGNAS first uses MCTS to recursively partition the entire search space into good or bad search regions. Then, the reinforcement learning-based search strategy (also called the agent) is applied to sample GNNs in those good search regions, which prevents overly exploring complex architectures and bad-performance regions, thus improving sampling efficiency. To reduce the evaluation cost, we use a prediction network to estimate the performance of GNNs. We alternately use ground-truth accuracy (by training GNNs from scratch) and prediction accuracy (by the prediction network) to update the search strategy to avoid inaccuracies caused by long-term use of the prediction network. Furthermore, to improve the training efficiency and stability, the agent is trained by a variant of Proximal Policy Optimization. Experiments show that EGNAS can search for better GNNs in the promising search region in a shorter search time, with an accuracy of 83.5%, 73.3%, 79.6%, and 94.5% on Cora, Citeseer, Pubmed, and Photo datasets, respectively In particular, compared to the most popular GNAS algorithm, our EGNAS-NP without using the prediction network achieves an accuracy of 83.6% on Cora, 73.5% on Citeseer, 79.9% on Pubmed, and 94.6% on Photo, with a relative improvement of 0.6%, 0.2%, 0.7%, and 0.6%.
[3]: Communication learning is an effective way to solve complicated cooperative tasks in multi-agent reinforcement learning (MARL) domain. Graph neural network (GNN) has been widely adopt for learning the multi-agent communication and various GNN-based MARL methods have emerged. However, most of these methods are not specially designed for heterogeneous multi-agent scenarios, where agents have heterogeneous attributes or features based on different observation spaces or action sets. Without effective processing and transmission of heterogeneous feature information, communication learning will be useless and even reduce the performance of cooperation. To solve this problem, we propose a communication learning mechanism based on heterogeneous GNN and graph information maximization to learn effective communication for heterogeneous agents. Specifically, we use heterogeneous GNN for learning the efficient message representations, which aggregate the local feature information of neighboring agents. Furthermore, we maximize the mutual information (MI) between message representations and local values to make efficient use of information. Besides, we present a MARL framework that can flexibly integrate the proposed communication mechanism with existing value factorization methods. Experiments on various heterogeneous multi-agent scenarios demonstrate the effectiveness and superiority of the proposed method compared with baselines.",Related but unverifiable
s_299,Unverifiable,"Applications: Pattern Recognition: CNNs have been successfully applied to various pattern recognition tasks, such as signal language recognition and ultrasonic signal classification for weld bead defects .","Self Organizing Map (SOM) is a kind of artificial neural network with a competitive and unsupervised learning. This technique is commonly used to dataset clustering tasks and can be useful in patterns recognition problems. This paper presents an artificial neural network application to signals language recognition problem, where the image representation is given by bit signatures. The recognition results are promising and are presented in this paper. More, some analysis about the combination ""SOM + bit signature"" improved our understanding about the characteristics of the LIBRAS signals and the conclusions are also listed in this paper. © 2008 IEEE.
[8]: The present work evaluates the application of artificial neural networks to pattern recognition of ultrasonic signals reflected from weld beads. Classifiers are Self Organizing Map (SOM) and Multi-layer Perceptron (MLP). The ultrasonic signals acquired from pulse-echo are introduced to the artificial neural network classifiers with and without preprocessing. The preprocessing is aimed to smoothen the signal that improves the classification. Five conditions of weld bead are evaluated: lack of fusion (LOF), lack of penetration (LOP), excess penetration (EX.P), slag inclusion (SL) and non-defect (ND). The defects have been intentionally inserted in a weld bead of AISI 1020 steel plates of 20 mm thickness and confirmed using radiographic tests. The results obtained show that it is possible to classify ultrasonic signals of weld joints by the pulse-echo techniques using artificial neural networks. Classification error rate as low as 6% has been the outcome of the best test set up. © 2011 Praise Worthy Prize S.r.l. - All rights reserved.",Related but unverifiable
i_1360,Unverifiable,"Key Health Concerns: Chemical Exposure: Toxic Chemicals: The use of plastic materials in 3D printing can expose users to harmful chemicals. For example, ABS contains styrene, a known carcinogen, and other additives that can leach out during the printing process .","Plastic, one of the most preferred materials in today′s industrial world is posing serious threat to environment and consumer′s health in many direct and indirect ways. Exposure to harmful chemicals during manufacturing, leaching in the stored food items while using plastic packages or chewing of plastic teethers and toys by children are linked with severe adverse health outcomes such as cancers, birth defects, impaired immunity, endocrine disruption, developmental and reproductive effects etc. Promotion of plastics substitutes and safe disposal of plastic waste requires urgent and definitive action to take care of this potential health hazard in future.",Related but unverifiable
s_1505,Entailment,"Systems like IRRIVIVA, which adjust irrigation based on daily evapotranspiration rates, have proven effective in reducing water use while maintaining plant health .","In the neighborhood of the city of Pistoia, central Italy, is located one of the largest container Hard Ornamental Nursery Stock (HONS) production centres in Europe. Water use efficiency (WUE) is one of main problem of these nurseries, mainly due to inaccurate irrigation scheduling, since almost all nurseries use simple timers to control irrigations. Plants are irrigated 1-4 times day-1 with irrigation events set periodically (every 1-4 weeks) by the growers based on their personal experience. This paper reports the results of a work performed to design, construct and test a simple and cost-effective irrigation control system (IRRIVIVA) for HONS nurseries. This system aims to reduce the growers' tendency to over-irrigate and the oscillations in the substrate moisture content, thus resulting in greater WUE and better crop performance (faster growth, less susceptibility to root-borne diseases, etc.). For this purpose, IRRIVIVA considers the day-To-day oscillation in reference evapotranspiration (ETo) and then crop evapotranspiration (ET). The IRRIVIVA system automatically adjusts, on a daily basis, the length of watering (i.e., irrigation dose) set by the grower on the time clock system using a correction coefficient (kET), which is as the ratio between the ETo of the previous day and the historical maximum ETo for that week of the year (EToh). In a validation experiment with container-grown red-Tip photinia (Photinia × fraseri Dress) and cherry laurel (Prunus laurocerasus L.), the application of IRRIVIVA reduced seasonal water use by 27% and drainage loss by 45%, on average, with respect the timer control system, without showing significant effects of plant growth.",Entailment
i_2314,Contradiction,Salinity influences growth and feeding efficiency. Larvae of the Humboldt Current System's surf clam (Donax obesulus) grew faster under El Niño temperature conditions but showed higher mortality at very low salinity (5 ± 1) .,"The Humboldt Current System is a highly productive ecosystem that is subject to the dynamics of the El Nio Southern Oscillation (ENSO). El Nio (EN, the warm phase of ENSO) causes vital changes in surface water temperature, oxygen levels, and salinity conditions, which arc reflected in various responses of coastal pelagic and benthic organisms. For very shallow habitats such as sandy beaches, temperature and salinity are considered the principal parameters changing during strong EN. However, the mechanisms by which these changes effect change on the structure of coastal populations remains largely unknown. The surf clam Donax ohesulus is dominant on large sandy beaches of the Humboldt Current System. Its biogeographical distribution is largely influenced by EN-induced environmental changes. Despite the species' key role in the beach ecosystem, the effects of modified abiotic conditions on the meroplanktonic larval stages and threshold temperatures involved have not yet been investigated. After EN episodes, meroplanktonic larval stages play a crucial role in the medium-and long-term stability of shallow-water species. Thus, this study makes a first attempt to describe the ontogeny of D. ohesulus and examines the effects on development of EN temperature conditions (ENTC) in comparison with normal temperature conditions (NTC). Results indicate that early life history follows a pattern previously described for other donacid bivalves. Development, growth, and mortality of larvae were assessed during a 3-wk in vitro experiment, indicating that larvae reared under ENTC grew and developed faster in comparison with those reared under NTC; mortality was slightly higher under ENTC. During a 2nd experiment, larvae were exposed for 48 h to a distinct range of different salinities (35, 25, 15, and 5 ± 1) at 2 different temperatures (NTC and ENTC). At both temperatures, larvae suffered no mortality at medium and low salinity (35, 25, and 15 ± 1) but showed 100% mortality at very low salinity (5 ± 1) after 16 h at NTC and 32 h at ENTC. Activity of larvae was highest at medium salinity (25 ± 1) and lowest at normal salinity (35 ± 1). The results of this study indicate that early larval stages of D. ohesulus can cope with temperature and salinity changes induced during EN. Only extremely low salinity (5 ± 1) such as that observed close to river mouths may cause high mortality rates in D. ohesulus offspring.",Entity error
i_2064,Unverifiable,Process of Water Movement: Uptake by Roots: Water is absorbed from the soil by the roots through root hairs and transported into the root xylem .,"The water transport in terrestrial vascular plants is passive and is determined by the transpiration or loss of water through the leaves. The cohesion-tension theory is the most accepted to explain this process, which is complemented by the Ohm's law analogy, which analyzes the flow of water as a catenary process. Resistance to water stress and cavitation is strongly associated with the anatomical characteristics of the xylem, the intervessel pits, and their membranes, the latter being altered depending on the chemical properties of the aqueous solution that flows through them. Based on these premises, this review addresses the phenomenon of ascent of water in terrestrial vascular plants and analyzes the concepts, theories, and methods most used in the study of hydraulic architecture. In addition, it points out the differences in xylem structure and water transport between dicots and monocots.
[2]: Water and nutrition are mainly uptaken by the root system, and the root system is directly grown in the soil and is sensitive to stress. In arid environments, the structure of the root system could be changed to maintain normal biology function and adapt to stress conditions. To date, most of the studies have focused on the structure or morphology of root system responses to single stress factors. However, less attention has been concentrated on the adaptive mechanism of the entire root structure to different ecotopes. Therefore, this study explored the root morphological plasticity of Ziziphus jujuba var. spinosa in response to natural drought gradient ecotopes. Root samples were selected from Yantai-Shijiazhuang-Yinchuan-Turpan of China. The four ecotopes formed a natural drought gradient environment according to their soil moisture, annual precipitation, and humidity coefficients. The purpose of this study was to elucidate the mechanism of root plasticity response to different environments caused by climate change. The results showed that root primary structure of Ziziphus jujuba var. spinosa included the epidermis, cortex, and vascular cylinder. The epidermis is on the surface of the young root, which is constituted by a single layer of epidermis cells that are small and arranged closely. The cortex takes the greatest proportion of the primary structure, and it is constituted by a larger quantity of parenchymal cells. The vascular cylinder is located in the innermost layer, and the cells are small and crowded together. It is composed of pericycle, primary xylem, primary phloem, and parenchymal cells. When drought aggravated, the thickness and width of the epidermis cells were increased. In addition, the thickness, width, and number of plies of parenchymal cells, and the thickness of the cortex were all largest at the Yinchuan ecotope. The root secondary structure of Ziziphus jujuba var. spinosa was divided into periderm (phellem layer, phellogen, phelloderm) and secondary vascular tissue (secondary phloem, vascular cambium, secondary xylem). As the drought intensified from Yantai to Turpan, the thickness and density of periderm was gradually increased. In addition, the diameter and quantity of vessels in secondary xylem were increased. These results illustrated that one of the adaptive mechanisms of plant to drought stress is the changes in the plasticity of root structure that enhance water uptake capacity and water transport efficiency. On the other hand, it improves water retaining capacity and decreases water desorption.",Related but unverifiable
s_2127,Entailment,Jatropha gossypiifolia: This species is noted for its rapid spread and potential to disrupt local ecosystems .,"An alien species, which becomes established in natural or semi-natural ecosystems or habitats, is an agent of change and threatens native biological diversity. The Convention on Biological Diversity (CBD) declared in 1992, in which the issue on invasive alien species was raised, was ratified by the Indonesian Government in 1994. Protecting our biodiversity will be out moral obligation to comply with CBD. Inventory on the invasive alien plant species in Indonesia should also be done by field surveys aside from the data collected from the references and herbarium specimens. Field studies should be carried out to get complete Figures, to identify the new ones, to determine their distributions, to plan their management including prevention to spread, containment and movement or mitigate their impact to environment. Sometimes it is difficult in determining whether the plants are aliens or not. Cooperation with botanists and taxonomists in other parts of the world is necessary. There are some species of invasive alien plant in Indonesia, which have to be watched fortheir aggressiveness i.e. Acasia nilotica (L.) Willd. ex Del., Eupatorium sordidum Less., Jatropa gossipifolia L., Mikania micrantha Kunth, Mimosa pigra L., Opuntia sp., and Piper aduncum L. have to be watch for their aggressiveness. Notes on some important invasive alien plant species in Indonesia are discussed.",Entailment
i_121,Entailment,"Environmental Impact: Supply Chain Efficiency: AI can enhance productivity and efficiency in global supply chains, which is frequently presented as a significant step towards environmental sustainability. However, these gains are likely to lead to increased production and consumption, potentially worsening environmental degradation, although some argue they might have minimal positive effects .","Artificial intelligence (AI) is set to greatly enhance the productivity and efficiency of global supply chains over the next decade. Transnational corporations are hailing these gains as a 'game changer' for advancing environmental sustainability. Yet, looking through a political economy lens, it is clear that AI is not advancing sustainability nearly as much as industry leaders are claiming. As this article argues, the metrics and rhetoric of corporate social responsibility are exaggerating the benefits and obscuring the costs of AI. Productivity and efficiency gains in the middle sections of supply chains are rebounding into more production and consumption, doing far more to enhance the profitability of big business than the sustainability of the earth. At the same time, AI is accelerating natural resource extraction and the distancing of waste, casting dark shadows of harm across marginalized communities, fragile ecosystems, and future generations. The micro-level gains from AI, as this article exposes, are not going to add up to macro-level solutions for the negative environmental consequences of global supply chains, while portraying AI as a force of sustainability is legitimizing business as usual, reinforcing a narrative of corporate responsibility, obfuscating the need for greater state regulation, and empowering transnational corporations as global governors. These findings extend the theoretical understanding in the field of international political economy of the hidden dangers of relying on technology and corporate governance to resolve the deep unsustainability of the contemporary world order.",Entailment
s_1409,Entailment,"Advantages of Learning Bumblebee Identification: Ecological Importance: Bumblebees are major pollinators of wild plants and crops, making their study relevant for understanding ecological interactions and conservation efforts .","[10] Bumblebees are influenced by socially acquired information when deciding on which flowers to forage. In some circumstances, however, this attraction towards conspecifics may lead to suboptimal foraging performance because the presence of multiple pollinators typically results in a faster rate of nectar depletion in the flower. We tested the capacity of bees to learn to avoid flowers occupied by conspecifics when they offered a lower reward than unoccupied similar flowers. Bumblebees were able to discriminate between poorly and highly rewarding flowers by using the presence of a nonsocial cue (a wooden rectangular white block). When poorly rewarding flowers were indicated by social cues (model bees), however, bees did not discriminate between the two flower types except when an additional cue was provided (flower colour). These findings indicate that bumblebees attach particular meaning to conspecific presence on flowers, even when this could lead to suboptimal foraging performance. The relatively lower flexibility in the use of social than nonsocial cues suggests a biased positive value of conspecifics as indicators of rewarded flowers.",Entailment
i_2029,Entailment,"Microsatellite Markers in Melon Studies: Microsatellite markers, also known as Simple Sequence Repeats (SSRs), are highly effective for genetic diversity studies due to their high polymorphism and reproducibility. They have been widely used in various plant species, including melons, to assess genetic variability and relationships among accessions .","Several types of molecular markers have been used in plant breeding and genetic diversity for a wide range of applications. Generally, single-locus co-dominant markers are preferred, because they make it possible to tag and map the same loci in many different populations and even species. Probably the best markers in this respect are microsatellites. The analysis based on microsatellites in our study has revealed the usefulness of these markers in the identification of polymorphism in chickpea genome, which was earlier thought to be less polymorphic. Such markers will be highly efficient in identifying specific markers linked to the trait of interest. The plant material used in this study included 43 wild and 2 cultivated Cicer accessions representing annual and perennial Cicer with distribution in Turkey. Ten STMS primers were selected from Cicer species depending on their ability to amplify genomic DNA in all species. Separation of the PCR products on agarose gels revealed single bands of the expected size with 10 of the primer pairs. DNA from C. arietinum, C. reticulatum, C. echinospermum, C. pinnatifidum, C. bijugum, and C. anatolicum amplified with the primers GA2, GA24, TA13, GAA47, TA46, TA130, TA72, TA146, TS54, TS72 respectively, were sequenced and compared with the chickpea sequence. The DNA of one accession for each species has been amplified with 45 chickpea-derived STMS primer pairs. Amplification resulted either in the presence or absence of products. For other STMS loci, only three STMS/species combinations were successful which could be used as specific markers (GAA47, TS54 and TA72). We examined whether and to which extent STMS primers designed for the cultigen could also be applied to genome analysis of wild Cicer species.
[2]: Premise of the study: Microsatellite markers were developed for a dioecious shrub, Orixa japonica (Rutaceae). Because O. japonica vigorously propagates by vegetative growth, microsatellite markers can be used to identify clonal relationships among its ramets. Methods and Results: Sixteen polymorphic microsatellite markers were identified by 454 next-generation sequencing. The number of alleles and expected heterozygosity for each locus among four populations ranged from two to 10 and from 0.140 to 0.875, respectively. Five of the 16 loci showed a low null allele frequency. Because Orixa is a monotypic genus, cross-amplification in a consubfamilial species, Skimmia japonica, was tested, and only one locus showed polymorphism. Conclusions: These microsatellite markers developed for O. japonica contribute to clone identification for studies examining the clonal structure and true sex ratio in the wild. Moreover, five markers that have a low null allele frequency can also be used for estimating mating systems or performing parentage analysis.
[3]: Melia dubia Cav. (Meliaceae), a fast-growing tropical tree finds use in plywood, pulp and high-value solid wood products. To increase its productivity, we must essentially capture genetic diversity and identify genotypes with superior wood properties. This study aimed to develop novel microsatellite markers from genomic data and validate the markers in M. dubia. Direct Seq-to-SSR approach was adopted and using an in-house Perl script, 426,390 SSR markers identified. For validation, selected 151 markers, of which 50 were genomic markers chosen randomly, and 101 were genic markers identified through BLAST2GO. Amplification was observed in all loci, and 81.4% generated high-quality, reproducible amplicons of the expected size. Out of 50 genomic markers, we used ten highly polymorphic markers to assess genetic diversity among 75 genotypes from three populations. One hundred fourteen alleles were recorded, with a moderate level of diversity and a positive fixation index. Twenty-nine genic markers representing 13 enzymes showing polymorphism for wood stiffness were selected for diversity assessment of 24 genotypes (12 genotypes each with high and low-stress wave velocity). The product size ranged from 87 to 279, covering the majority of the genome. Cluster and structure analysis segregated ~ 80% of the genotypes based on the trait. This is the first report of the development of genic markers from a genomic survey and has proved efficient in differentiating genotypes based on the trait. The markers developed in this study will be useful for genetic mapping, diversity estimation, marker-assisted selection for desired traits and breeding for wood traits in M. dubia.",Entailment
i_400,Entailment,"Disadvantages of Dropdown Menus: Users may find it challenging to navigate through long dropdown menus, especially if the items are not well-organized or if the menu requires precise mouse movements .",Hierarchical menus are a common feature of the user interface for interactive software. Dynamic menus allow users to add items to the menu structure. Such dynamic menus are subject to usability problems of hiding information because of overlapping data and of requiring large in-line movement of the mouse or input device. This paper presents an improved design for menu display and interaction to provide easier viewing and navigation.,Entailment
i_849,Entailment,"- **Spray Characteristics**: At very high injection pressures (e.g. above 250 MPa), the influence on spray penetration and cone angle becomes less significant. However, the initial pressure remains a critical factor in determining spray characteristics .","An experimental study on spray characteristics of ultra high pressure common rail system was conducted based on self-designed spray experimental platform. The effects of fuel injection pressure and fuel injection law on the spray characteristics of marine diesel engine were analyzed in aspects of fuel bundle shape, spray penetration and spray cone angle systemically and quantitatively, which provides theoretical basis for further improve the performance of marine diesel engine. The results show that the variable pressure and fuel injection rate injection can be realized by controlling the opening time of electric-controlled pressure amplifier solenoid valve and injector solenoid valve in ultra high pressure common rail system. With the rise of fuel injection pressure, the fuel bundle break up and evaporation phenomenon, spray penetration as well as spray cone angle all increase gradually, however, when the fuel injection pressure is more than 200 MPa, influence of fuel injection pressure on the spray penetration and spray cone angle becomes smaller and smaller. With the fuel injection law varies from rectangular to saddle-shaped, the fuel bundle break up and evaporation phenomenon, spray penetration as well as spray cone angle all decrease gradually, and the spray penetration of rectangular fuel injection law under 150 MPa fuel injection pressure is larger than that of saddle-shaped fuel injection law under 200 MPa fuel injection pressure, which further indicates that the initial pressure is the most important factor to determine spray penetration.",Entailment
s_699,Unverifiable,"The Sacrificial Template Method, when used without ultrasonication, fails to fabricate carbon black/PDMS foam for tensile sensing, resulting in poor linearity and high hysteresis .","Poor linearity and high hysteresis as two crucial issues of stretchable and flexible strain sensors are urgently needed to be addressed to improve the sensors' practical applicability. In this work, sacrificial template method coupled with ultrasonication technique are employed to fabricate a carbon black (CB)/polydimethylsiloxane (PDMS) foam (CPF) for tensile sensing. The CPF with a robust three-dimensional (3D) electrically conductive network exhibits excellent linearity and wide strain range (70% strain). The fabricated CPF possesses negligible electrical hysteresis of 1.2%, owing to the strong interactions between conductive nanofillers and the PDMS substrate. Low detection limit (0.5% strain), quick responsive time (100 ms), good response stability, excellent durability and reproducibility (>20,100 cycles) are achieved simultaneously. The prepared CPF is then assembled as a wearable sensor and it can monitor wide-range human motions in real-time, showing great potential in diverse practical applications in the near future.",Related but unverifiable
s_1243,Contradiction,"bFGF down-regulates procollagen I and up-regulates HAS-2 and fibronectin, which likely guarantees significant improvements in wound healing and completely eliminates fibrosis .","Objectives: The overarching goal of this line of research is to translate basic fibroblast growth factor (bFGF) treatment for vocal fold scarring into practical clinical use. In a previous canine investigation, we demonstrated that bFGF improves phonation threshold pressure, mucosal wave amplitude, and histologic measures in vocal folds treated after injury. In the present study, we studied the effects of bFGF on gene expression of the extracellular matrix and growth factors in rat vocal fold fibroblasts. Methods: Fibroblasts harvested from the vocal folds of 5 rats were treated with 3 concentrations of bFGF (0, 10, and 100 ng/mL). The fibroblasts were collected at 24 hours and 72 hours after bFGF administration. Quantitative polymerase chain reaction was then used to investigate the gene expression of the investigated growth factors and extracellular matrices. Results: The results revealed significantly down-regulated expression of procollagen I and significantly up-regulated expression of hyaluronic acid synthase (HAS) 2 and fibronectin in fibroblasts treated with bFGF. The administration of bFGF also resulted in the up-regulation of bFGF and hepatocyte growth factor (HGF). No changes in the expression of HAS-1, tropoelastin, or procollagen III were observed between the treatment and control conditions. Conclusions: Treatment with bFGF induces the down-regulation of procollagen I and the up-regulation of HAS-2 in vocal fold fibroblast cell cultures. These gene expression alterations to key mediators of the wound healing process may translate into potential benefits in the remediation of vocal fold injury. The up-regulation of HGF, an antifibrotic effector molecule, may demonstrate additional benefits by optimizing the wound healing environment and by accelerating the wound repair cascade. These findings may provide fuel for additional discoveries into the development of growth factor therapy for the treatment of vocal fold scar. © 2010 Annals Publishing Company. All rights reserved.",Misrepresentation
s_1021,Entailment,"Force Sensor Technology in Surgery: Experimental Validation: Tactile Feedback Systems: Instruments equipped with tactile feedback systems have been shown to significantly enhance surgeons' ability to discriminate tissue hardness and size, despite the lack of statistically significant differences in some tests .","This paper describes the design and performance of a prototype remote palpation instrument with tactile feedback for laparoscopic surgery. Psychophysical experiments aiming at comparing palpation with and without tactile feedback are also described. The remote palpation instrument is designed to provide the surgeon with information about size and contact force distribution. The instrument consists of a tactile sensor and a tactile display, both of which are small enough to fit onto a conventional laparoscopic grasper. Static tests showed that hardness, size and shape were successfully rendered by the tactile display. Dynamic testing showed that the bandwidth is suboptimal, but at low frequencies the output from the remote palpation instrument is useful. For the psychophysical testing, nine subjects were asked to discriminate hardness and size of objects with and without tactile feedback. The results indicated that the instrument with tactile feedback can be helpful for hardness discrimination, although the difference between the two instruments was not statistically significant for neither hardness nor size. Comparisons with earlier, similar experiments showed that the quality of the grasper and size of the forceps affected the results, indicating that there is a great potential for improving laparoscopic graspers in general. © 2009 Informa UK Ltd.
[9]: This paper presents a handheld surgical tool adapting a tactile feedback system. The tool consists of a 3-degree-of-freedom (DOF) force sensor and three tactile displays. The sensor is easily embedded in the tool by adopting the capacitive transduction principle. The sensor measures the direction and magnitude of the 3-DOF force applied to the tool tip. The fingertip grasping the tool is stimulated by the tactile display to transmit the contact force information measured by the sensor. The tactile display is actuated by employing a soft actuator technology based on a dielectric elastomer actuator such as a type of electroactive polymer actuator. In this work, a prototype of the tool is designed and fabricated. Its performance is experimentally validated.",Entailment
i_495,Contradiction,"Agile methodologies increase the emphasis on comprehensive documentation, consuming more time and resources that could otherwise be dedicated to actual software development and delivery .","The Agile manifesto focuses on the delivery of valuable software. In Lean, the principles emphasise value, where every activity that does not add value is seen as waste. Despite the strong focus on value, and that the primary critical success factor for software intensive product development lies in the value domain, no empirical study has investigated specifically what value is. This paper presents an empirical study that investigates how value is interpreted and prioritised, and how value is assured and measured. Data was collected through semi-structured interviews with 23 participants from 14 agile software development organisations. The contribution of this study is fourfold. First, it examines how value is perceived amongst agile software development organisations. Second, it compares the perceptions and priorities of the perceived values by domains and roles. Third, it includes an examination of what practices are used to achieve value in industry, and what hinders the achievement of value. Fourth, it characterises what measurements are used to assure, and evaluate value-creation activities.
[6]: BACKGROUND: Agile software development methods have a number of reported benefits on productivity, project visibility, software quality and other areas. There are also negative effects reported. However, the base of empirical evidence to the claimed effects needs more empirical studies. AIM: The purpose of the research was to contribute with empirical evidence on the impact of using agile principles and practices in large-scale, industrial software development. Research was focused on impacts within seven areas: Internal software documentation, Knowledge sharing, Project visibility, Pressure and stress, Coordination effectiveness, and Productivity. METHOD: Research was carried out as a multiple-case study on two contemporary, large-scale software development projects with different levels of agile adoption at Ericsson. Empirical data was collected through a survey of project members. RESULTS AND CONCLUSIONS: Intentional implementation of agile principles and practices were found to: correlate with a more balanced use of internal software documentation, contribute to knowledge sharing, correlate with increased project visibility and coordination effectiveness, reduce the need for other types of coordination mechanisms, and possibly increase productivity. No correlation with increase in pressure and stress were found. © 2013 IEEE.",Opposite meaning
s_1824,Entailment,"Impact of Biodiesel on PM Emissions: Reduction in PM Emissions: Biodiesel Blends: Using biodiesel blends (e.g. B10, B20) can reduce PM emissions significantly. For instance, B10 fuel reduces PM emissions compared to pure diesel .","[10] Due to its excellent reliability and fuel economy, diesel-powered equipment is used extensively in metal and nonmetal mines throughout the world. Most of the research to date suggests that the majority of fine particulate matter (FPM) in underground mines is derived from diesel exhaust. The US Mine Safety and Health Administration (MSHA) has been enforcing an FPM concentration limit of 400 mg/m<sup>3</sup> total carbon (TC) (or 308 mg/m<sup>3</sup> elemental carbon [EC]) in mine air and is considering lowering it to 160 mg/m<sup>3</sup> TC by January 2006. Diesel exhaust also contains gaseous hazard pollutants, such as carbon monoxide (CO), nitrogen oxide (NOx), sulfur dioxide (SO<inf>2</inf>), and volatile organic carbon (VOC). The emission rates of these pollutants depends strongly on the fuel, load, type, and age of the diesel engine. Concerned with the mining operation and miner's safety, both time-integrated and peak emissions from mining diesel equipment need to be accurately quantified. Emission measurements with conventional dynamometer setups have the advantage of testing engines under a variety of running cycles. However, only a very limited number of vehicles can be tested, and often they do not represent the entire fleet (Moosmüller et al., 2001 a; Moosmüller et al., 2001b). The Desert Research Institute (DPS) has developed in-plume and remote sensing measurement methods that allow different pollutant concentrations in the exhaust to be measured by normalizing their concentration to the excess carbon dioxide (CO<inf>2</inf>) concentration measured. Knowing the carbon content of the fuel combusted, this ratio can be related to the amount of fuel consumed (Moosmüller et al., 2003), and fuel-based emission factors can be derived. The DRI FPM remote sensing system uses a 266-nm ultraviolet laser light to detect the backscatter signal and total path extinction across the plume. With suitable assumptions regarding size distribution and particle composition, particle mass emissions are calculated for FPM. Concurrent measurements of CO, HC, and NOx, emissions are made with a commercial remote sensing device. This method allows the measurement of fuel-based emission factors for many vehicles driven through a checkpoint. The vehicle running conditions are usually consistent at the check point (e.g., cold start, hot stabilised, etc.). For in-plume measurements, vehicle exhaust is drawn into a man fold where the sample stream is directed to an extractive Fourier Transform Infrared Spectrometer (FTIR) to measure chemical composition as well as to several particle measuring instruments including nephelometers to measure light scattering, a photoacoustic instrument to measure light absorption, particle counters to measure particle size distributions, and filter samplers to measure PM10 and PM2.5 mass concentration and chemistry. The FTIR quantifies multiple species including CO<inf>2</inf>, CO, NO, SO<inf>2</inf>, NH<sup>3</sup>, and HC in the plume. EC concentrations can be directly derived from the photoacoustic measurement. The in-plume method can examine many vehicles in a short time as well, and allows more species to be determined. These monitors have been successfully applied to quantify emissions from both on-road and off-road vehicles. For on-road mobiles sources, the test stand is deployed on the side of the road to sample a large number of vehicles passing the monitor. Emissions from off-road vehicles or engines are measured by installing the test stand inside a cargo van with a sampling inlet positioned on top of the vehicle. The applicability of these methods to study mining diesel emissions will be discussed. [15] Particle emissions from a marine diesel engine operating at low loads with four different fuels were characterized with respect to particle number (PN) and particle mass (PM), size distribution, volatility and chemical composition. The four different fuels used were Swedish Environmental class 1 (MK1) and class 3 diesel (MK3), heavy fuel oil (HFO, 0.12wt% S) and marine diesel oil (MDO, 0.52wt% S). The measurements were performed for a marine diesel engine in a test-bed engine lab and the particle emissions were measured with an Engine Exhaust Particle Sizer and a Dust Monitor, giving the number concentrations in the size range of 5.6-560nm and 300nm to 20μm, respectively. To quantify the amount of solid particles a thermodenuder was used. Additionally, filter samples were taken for gravimetric, black carbon (BC) and elemental analysis. The particle emissions showed a bimodal size distribution by number and the number concentrations were dominated by nanoparticles (diameter (Dp)<50nm). The nanoparticles measured were both primary and secondary particles, depending on fuel and engine load, while the particles with Dp > 50nm generally were solid primary particles. Combustion of HFO resulted in the highest PN and PM concentrations. Emission factors (EFs) for PM and PN for both the total particle emissions and the fraction of primary, solid particles are presented for different fuels and loads. EFs for nitrogen oxides (NO<inf>x</inf>), BC and some elements (Ca, Fe, V, Ni, Zn) are presented as well. This study contributes to understanding particle emissions from potential future fuels as well as emissions in ports and coastal areas where lower engine loads are common. [17] This paper presents the first National Emissions Inventory (NEI) of fine particulate matter (PM<inf>2.5</inf>) that includes the full suite of PM <inf>2.5</inf> trace elements (atomic number >10) measured at ambient monitoring sites across the U.S. PM<inf>2.5</inf> emissions in the NEI were organized and aggregated into a set of 84 source categories for which chemical speciation profiles are available (e.g., Unpaved Road Dust, Agricultural Soil, Wildfires). Emission estimates for ten metals classified as Hazardous Air Pollutants (HAP) were refined using data from a recent HAP NEI. All emissions were spatially gridded, and U.S. emissions maps for dozens of trace elements (e.g., Fe, Ti) are presented for the first time. Nationally, the trace elements emitted in the highest quantities are silicon (3.8 × 10<sup>5</sup> ton/yr), aluminum (1.4 × 10<sup>5</sup> ton/yr), and calcium (1.3 × 10<sup>5</sup> ton/yr). Our chemical characterization of the PM<inf>2.5</inf> inventory shows that most of the previously unspeciated emissions are comprised of crustal elements, potassium, sodium, chlorine, and metalbound oxygen. This work also reveals that the largest PM<inf>2.5</inf> sources lacking specific speciation data are off-road diesel-powered mobile equipment, road construction dust, marine vessels, gasoline-powered boats, and railroad locomotives.",Entailment
i_1901,Entailment,"Phosphate and Heavy Metal Interaction: Phosphate Recovery: Processes like chemical precipitation and adsorption are used to recover phosphorus from wastewater, which can also help in managing heavy metal contamination .","In the fertilizer industry, phosphate is indispensable. Unfortunately, its limited supply would not be enough to meet the world's growing need for fertilizer production. In addition, phosphate rock costs have increased, and applying sewage sludge directly to farmland has been hard owing to excessive levels of pollution (organic contaminants and heavy metals). In such a situation, phosphate recovery can successfully solve this problem. Thus phosphorus recovery in municipal wastewater treatment plants (WWTPs) has gotten a lot of hype. Municipal WWTPs are promising resources of phosphorous. Although they cannot keep up with the demand, they are a big help and plays a crucial role in the sustainable utilization of Phosphorus. Phosphorus has been recovered in WWTPs, from phosphorus-rich sewage sludge, sewage sludge ashes, and side streams using several methods. This chapter gives a depth knowledge of chemical precipitation, adsorption, wet chemical, and thermochemical process technology. Excess Phosphorus may be removed from wastewater effectively, affordably, and sustainably using enhanced biological phosphorus removal (EBPR). In this study, we comprehensively examine the microbial diversity, metabolic function, and processing control strategies in EBPR under various environmental circumstances. These are the most common methods for recovering phosphate from the liquid and solid sludge phase of municipal waste. The present chapter discusses the global phosphate scenario, different phosphorus recovery processes, and the application of Phosphorus derived products as fertilizers. The significance of P recovery and challenges faced during P recovery from municipal wastewater plants worldwide and the impact of phosphorous removal on the environment are discussed in this chapter for a better understanding of the readers. Furthermore, the economic aspect of Phosphorus recovery is presented in this chapter.
[9]: The alkaline technology has been applied to phosphate (P <inf>i</inf> ) recovery from sewage sludge ash (SSA) at wastewater treatment plants (WWTP). P <inf>i</inf> is extracted from mono-incinerated sewage sludge with NaOH and recovered from the leachate using chemical precipitation with Ca(OH)2. Approximately 30-40% of P <inf>i</inf> could be recovered from SSA as calcium P <inf>i</inf> while minimizing the leaching of toxic heavy metals at high pH. The recovered P product can be recycled as a fertilizing material for agriculture.",Entailment
s_1741,Entailment,"Key Points: Tilia species: These plants also produce nectar containing nicotine, which bees can consume .","The presence of antimicrobial secondary metabolites in nectar suggests that pollinators, which are threatened globally by emergent disease, may benefit from the consumption of nectars rich in these metabolites. We tested whether nicotine, a nectar secondary metabolite common in Solanaceae and Tilia species, is used by parasitized bumblebees as a source of self-medication , using a series of toxicological, microbiological and behavioural experiments. Caged bees infected with Crithidia bombi had a slight preference for sucrose solution laced with the alkaloid and behavioural tests showed that the parasite infection induced an increased consumption of nicotine during foraging activity, though nicotine had an appetite-reducing effect overall. When ingested, nicotine delayed the progression of a gut infection in bumblebees by a few days, but dietary nicotine did not clear the infection, and after 10 days the parasite load approached that of control bees. Moreover, when pathogens were exposed to the alkaloid prior to host ingestion, the protozoan's viability was not directly affected, suggesting that anti-parasite effects were relatively weak. Nicotine consumption in a single dose did not impose any cost even in starved bees but the alkaloid had detrimental effects on healthy bees if consistently consumed for weeks. These toxic effects disappeared in infected bees, suggesting that detoxification costs might have been counterbalanced by the advantages in slowing the progression of the infection. Nicotine consumption did not affect bee lifespan but the reduction in the parasite load may have other likely unexplored subtle benefits both for individual bees and their colony. Potential evidence for self-medication is discussed. The contention that secondary metabolites in nectar may be under selection from pollinators, or used by plants to enhance their own reproductive success, remains to be confirmed.",Entailment
s_1170,Unverifiable,"Catheterization Procedures for Individuals with Congenital Heart Conditions: Safety and Efficacy: Catheterization procedures are generally safe, with low rates of severe adverse events (SAEs) and mortality .","[4] Transcatheter therapy has gained an important role in the treatment of children with congenital heart diseases. Simple defects like atrial septal defects and patent ducts can often be cured completely by catheter interventions, while only a minority of patients with ventricular septal defects can be treated. Balloon dilatations of the pulmonary and aortic valves are well accepted interventions. Stents, sometimes covered with a membrane, are very efficient for eliminating vessel stenoses and are also increasingly being implanted in younger children with aortic coarctation. The latest development with considerable impact on the treatment of congenital heart defects is the transcatheter pulmonary valve implantation. Finally, hybrid therapy joins surgical and transcatheter interventions in one single procedure to combine the specific advantages of the respective methods. © 2010 Springer-Verlag.",Related but unverifiable
s_211,Unverifiable,Key Developments in Microservices Security: Adaptive and Defense-in-Depth Mechanisms: Emerging research highlights the need for adaptive security mechanisms and defense-in-depth strategies to handle the growing number of potential attacks. A proposed solution involves a cost-sensitive adaptable intrusion response system that uses a game-theoretic approach to respond to network attacks in real-time .,"[4] Context: Security is becoming increasingly important during software engineering. Software developers should be able to adapt and deploy secure systems in a continuously changing execution context. Method: We use Software Product Lines (SPLs), Business Process Management (BPM) and Security Requirements Engineering (SRE) techniques for anticipating the uncertainty and the changes of security requirements. Results: We provide a method to support developers to incorporate security in the design of SPLs systems. To avoid costly and extensive re-design of SPLs and BPs, we propose a methodology to analyse the strategic change impact of SPLs and BPs. The methodology supports the alignment of organizational strategy and execution level with an emphasis to security. Conclusions: This methodology constitutes a guideline to trace back the impact of change respecting security constraints of SPLs and BPs on different abstraction levels. [9] Safeguarding the correctness of critical software is a grand challenge. A microservice-based system is described that builds trustworthy systems on top of legacy hardware and software components, ensuring microservices' integrity, confidentiality, and correct execution with the help of secure enclaves.",Related but unverifiable
s_1431,Entailment,"Forage Mixtures: Higher crude protein content and digestibility in diverse forage mixtures, with no significant environmental benefits .","Intensive farming focusing on monoculture grass species to maximise forage production has led to a reduction in the extent and diversity of species-rich grasslands. However, plant communities with higher species number (richness) are a potential strategy for more sustainable production and mitigation of greenhouse gas (GHG) emissions. Research has indicated the need to understand opportunities that forage mixtures can offer sustainable ruminant production systems. The objective of the two experiments reported here were to evaluate multiple species forage mixtures in comparison to ryegrass-dominant pasture, when conserved or grazed, on digestion, energy utilisation, N excretion, and methane emissions by growing 10-15 month old heifers. Experiment 1 was a 4×4 Latin square design with five week periods. Four forage treatments of: (1) ryegrass (control); permanent pasture with perennial ryegrass (Lolium perenne); (2) clover; a ryegrass:red clover (Trifolium pratense) mixture; (3) trefoil; a ryegrass:birdsfoot trefoil (Lotus corniculatus) mixture; and (4) flowers; a ryegrass:wild flower mixture of predominately sorrel (Rumex acetosa), ox-eye daisy (Leucanthemum vulgare), yarrow (Achillea millefolium), knapweed (Centaurea nigra) and ribwort plantain (Plantago lanceolata), were fed as haylages to four dairy heifers. Measurements included digestibility, N excretion, and energy utilisation (including methane emissions measured in respiration chambers). Experiment 2 used 12 different dairy heifers grazing three of the same forage treatments used to make haylage in experiment 1 (ryegrass, clover and flowers) and methane emissions were estimated using the sulphur hexafluoride (SF<inf>6</inf>) tracer technique. Distribution of ryegrass to other species (dry matter (DM) basis) was approximately 70:30 (clover), 80:20 (trefoil), and 40:60 (flowers) for experiment 1. During the first and second grazing rotations (respectively) in experiment 2, perennial ryegrass accounted for 95 and 98% of DM in ryegrass, and 84 and 52% of DM in clover, with red clover accounting for almost all of the remainder. In the flowers mixture, perennial ryegrass was 52% of the DM in the first grazing rotation and only 30% in the second, with a variety of other flower species occupying the remainder. Across both experiments, compared to the forage mixtures (clover, trefoil and flowers), ryegrass had a higher crude protein (CP) content (P<0.001, 187 vs. 115gkg <sup>-1</sup> DM) and DM intake (P<0.05, 9.0 vs. 8.1kgday <sup>-1</sup>). Heifers in experiment 1 fed ryegrass, compared to the forage mixtures, had greater total tract digestibility (gkg <sup>-1</sup>) of DM (DMD; P<0.008, 713 vs. 641) and CP (CPD, P<0.001, 699 vs. 475), and used more intake energy (%) for body tissue deposition (P<0.05, 2.6 vs. -4.9). For both experiments, heifers fed flowers differed the most compared to the ryegrass control for a number of measurements. Compared to ryegrass, flowers had 40% lower CP content (P<0.001, 113 vs. 187gkg <sup>-1</sup>), 18% lower DMD (P<0.01, 585 vs. 713gkg <sup>-1</sup>), 42% lower CPD (P<0.001, 407 vs. 699gkg <sup>-1</sup>), and 10% lower methane yield (P<0.05, 22.6 vs. 25.1gkg <sup>-1</sup> DM intake). This study has shown inclusion of flowers in forage mixtures resulted in a lower CP concentration, digestibility and intake. These differences were due in part to sward management and maturity at harvest. Further research is needed to determine how best to exploit the potential environmental benefits of forage mixtures in sustainable ruminant production systems.",Entailment
i_933,Entailment,"Safety and Comfort: Comfort and Convenience: The integration of electronics and smart technologies in vehicles enhances comfort and convenience for users. Features such as infotainment systems, remote diagnostics, and adaptive insurance are becoming standard .","With the advent of intelligent transportation systems, vehicles will connect continuously to the Internet via the vehicular core network or the cellular network. Opening vehicles systems to the Internet aims at improving vehicles safety and comfort via the development of remote services for drivers assistance. Such services are for example infotainment applications, software update over the air, remote diagnostics and adaptive insurance. However, some of these services come with an inherent problem of privacy as they require as inputs the private data from the vehicles. In this work, we investigate the use of homomorphic encryption for ensuring the confidentiality of vehicles private data. We study the confidentiality of data, which are treated by external service providers such as cars manufacturers, their stakeholders and insurances. Our protocol ensures, by design, the private treatment of vehicles data thanks to homomorphic encryption properties. We validate our proposal by studying drivers behaviour using a simple neural network that takes as input drivers pictures and tells whether a driver is concentrated or distracted. Indeed, we rely on a 3 layers network for classifying drivers behavior in 10 different classes from normal to dangerous. We use a quadratic activation function for intermediate layers which contain 20 and 10 units, respectively. Meanwhile, we use a sigmoid activation function for the last layer which contains 10 units, one per label. Our classification takes 11 seconds with a classification accuracy of 86% and 25 seconds with a classification accuracy of 92%.
[15]: The transport sector is fundamental for the economy but also for personal life. With a growing population and the globalization process, it is not surprising that the demand of transport is set to grow in the near future and certainly until 2050. This paper focuses on the huge potential of progress in the sector of technology for transport. As the principal sector for transport will remain on roads, the paper emphasizes the progress in the automotive sector. Since car manufacturers are investing massively into research and technology development to offer ever more efficient cars—not only energy efficient but also efficient in terms of safety and comfort—the car of tomorrow will be very different from the present one. The increasing role of electronics in cars will synergistically cooperate with that of so-called smart cities. The potential development of methane in the transport sector, mainly used for heavy transportation is discussed.",Entailment
i_390,Unverifiable,"Agriculture: Precision Farming: AI applications in agriculture include monitoring crop health, optimizing irrigation, and predicting yields, which help in making informed decisions to increase productivity .","Artificial intelligence (AI) has successfully made its way into contemporary industrial sectors such as automobiles, defense, industrial automation 4.0, healthcare technologies, agriculture, and many other domains because of its ability to act autonomously without continuous human interventions. However, this capability requires processing huge amounts of learning data to extract useful information in real time. The buzz around AI is not new, as this term has been widely known for the past half century. In the 1960s, scientists began to think about machines acting more like humans, which resulted in the development of the first natural language processing computers. It laid the foundation of AI, but there were only a handful of applications until the 1990s due to limitations in processing speed, memory, and computational power available. Since the 1990s, advancements in computer architecture and memory organization have enabled microprocessors to deliver much higher performance. Simultaneously, improvements in the understanding and mathematical representation of AI gave birth to its subset, referred to as machine learning (ML). ML includes different algorithms for independent learning, and the most promising ones are based on brain-inspired techniques classified as artificial neural networks (ANNs). ANNs have subsequently evolved to have deeper and larger structures and are often characterized as deep neural networks (DNN) and convolution neural networks (CNN). In tandem with the emergence of multicore processors, ML techniques started to be embedded in a range of scenarios and applications. Recently, application-specific instruction-set architecture for AI applications has also been supported in different microprocessors. Thus, continuous improvement in microprocessor capabilities has reached a stage where it is now possible to implement complex real-time intelligent applications like computer vision, object identification, speech recognition, data security, spectrum sensing, etc. This paper presents an overview on the evolution of AI and how the increasing capabilities of microprocessors have fueled the adoption of AI in a plethora of application domains. The paper also discusses the upcoming trends in microprocessor architectures and how they will further propel the assimilation of AI in our daily lives.",Related but unverifiable
i_2234,Unverifiable,"High Population Density: Generalists often maintain high population densities, even in disturbed or heterogeneous environments .","The small variability of habitat generalist abundances in relation to landscape changes has been related to their behavioural flexibility. We hypothesise that successful generalists, such as the starling, compensate for feeding resource difficulties (poor quality of food, accessibility) in habitats such as urban ecosystems and that its behavioural flexibility allows for similar breeding performance in rural and urban areas. Along an urbanisation gradient we compared simultaneously (1) success factors such as the abundance of breeding starlings, their breeding performance and the fitness of nestlings, and (2) possible flexibility quantified through the rate of parental food-provisioning, and the composition and the amount of food delivered to nestlings. Abundance of breeding starlings are similar throughout the urbanisation gradient, but urbanisation profoundly and negatively affects reproductive parameters of starlings. Differences in the amount of food delivered to nestlings by parents (less food in town centre), and the small masses of nestlings reared in the urban sectors support the idea that urban nestlings received insufficient food loads. Despite modifications to their diurnal food-provisioning rhythm and the incorporation of some human food refuse into their diet, starling parents have a significantly reduced production of young in the urban centre sector. We rebut the idea that the ""generalist"" starling is able to breed successfully anywhere: other more ""specialist"" species succeed in producing their young by innovating more in terms of diet resources. We suggest defining successful birds with respect to colonisation or invasion process through behavioural innovation rather than an ambiguous habitat generalist definition. © 2006 Elsevier Masson SAS. All rights reserved.
[4]: Recent advances in studies of habitat selection and resource use provide a framework not only for estimating resource specialization, but also for predicting future success of specialist and generalist strategies. The protocol merges resource selection functions with fitness and population dynamics to assess the evolution of competing strategies that change with density-dependent habitat selection. These strategies are revealed by resource selection coefficients derived from marked individuals that can then be used to predict each individual's fitness at different population sizes. Simulated consumer resource dynamics confirm the theory's ability to identify strategies of habitat and resource use with simple statistical models that summarize rather complex systems. The theory produces excellent fits with simulated data when strategies depend on density, and when the success of a single strategy interacts with others. Specialist strategies yield highest fitness at low population density, whereas generalists have highest fitness in dense populations. When applied to female red deer living on the Isle of Rum, Scotland, the theory correctly predicts an equilibrium distribution of competing strategies dominated by specialization on Agrostis/Festuca grassland. Specialization declined as population density increased through time. Simultaneously, changes in the genetic structure of the population reflected the increased opportunity for outbreeding as individuals became less specialized. Thus, it appears that theory effectively assessed competing strategies of resource use, and predicted their density- and frequency-dependent evolution.",Related but unverifiable
i_801,Unverifiable,"Strategies to Diminish Reliability: 3. Isolate Reliability in Later Design Phases - Focusing on individual engineering disciplines in the later design phase can hinder decision-making and reduce reliability by neglecting performance, cost, and safety considerations until the end of the design process . This approach leads to fragmented efforts that compromise product robustness.","Product development process, it is crucial to understand and evaluate multiple and synergic aspects of systems such as performance, cost, reliability, and safety. These aspects are mainly considered during later stages of the design process. However, in order to improve the foundations for decision-making, this article presents methods that are intended to increase the engineering knowledge in the early design phases. In complex products, different systems from a multitude of engineering disciplines have to work tightly together. Collaborative design is described as a process where a product is designed through the collective and joint efforts of domain experts. A collaborative multidisciplinary design optimization process is therefore proposed in the conceptual design phase in order to increase the likelihood of more accurate decisions being taken early on. The performance of the presented framework is demonstrated in an industrial application to design aircraft systems in the conceptual phase.",Related but unverifiable
i_110,Unverifiable,Combining visual cues with textual explanations can improve the interpretability and effectiveness of explanations .,"[6] Since the advent of Artificial Intelligence (AI) and Machine Learning (ML), researchers have asked how intelligent computing systems could interact with and relate to their users and their surroundings, leading to debates around issues of biased AI systems, ML black-box, user trust, user's perception of control over the system, and system's transparency, to name a few. All of these issues are related to how humans interact with AI or ML systems, through an interface which uses different interaction modalities. Prior studies address these issues from a variety of perspectives, spanning from understanding and framing the problems through ethics and Science and Technology Studies (STS) perspectives to finding effective technical solutions to the problems. But what is shared among almost all those efforts is an assumption that if systems can explain the how and why of their predictions, people will have a better perception of control and therefore will trust such systems more, and even can correct their shortcomings. This research field has been called Explainable AI (XAI). In this studio, we take stock on prior efforts in this area; however, we focus on using Tangible and Embodied Interaction (TEI) as an interaction modality for understanding ML. We note that the affordances of physical forms and their behaviors potentially can not only contribute to the explainability of ML systems, but also can contribute to an open environment for criticism. This studio seeks to both critique explainable ML terminology and to map the opportunities that TEI can offer to the HCI for designing more sustainable, graspable and just intelligent systems.",Unrelated and unverifiable
i_1610,Entailment,"Mechanisms: The system supports both nitrification and denitrification processes. Ammonium oxidizing bacteria (AOB) and anammox bacteria are segregated within the biofilm and activated sludge, enhancing nitrogen removal rates and operational stability .","Nitritation-anammox process was successfully established in pilot- and full-scale integrated fixed-film activated sludge (IFAS) reactors. An average nitrogen removal efficiency of 80% was achieved under ammonium loading rate of 0.7-1.3kgN/(m<sup>3</sup>d) in the pilot-scale reactor (12m<sup>3</sup>). Moreover, molecular analysis showed that ammonium oxidizing bacteria (AOB) were more abundant in the activated sludge while anammox bacteria were primarily located in the biofilm. The segregation of AOB and anammox bacteria enhanced the nitrogen removal rate and operational stability. Furthermore, a full-scale IFAS reactor of 500m<sup>3</sup> was set-up to treat sludge dewatering liquors. An average nitrogen removal efficiency of 85% and a nitrogen removal rate of 0.48kgN/(m<sup>3</sup>d) were achieved after inoculation. It was noted that high influent suspended solids would seriously affect the performance of the IFAS system. Therefore, a pre-treatment was proposed to reduce suspended solid in the full-scale application.",Entailment
s_677,Contradiction,"Real-World Implementations and Feedback: Case Studies: Real-world implementations, such as the DRT operations in Melbourne, provide insights into the practical challenges and benefits of DRT. These services acted as feeders to train stations during peak periods and as traditional bus services during off-peak times, highlighting the importance of affordability and regulation for broader adoption .","This paper outlines the key insights gained from the Demand Responsive Transit (DRT) operations in Inner West Sydney, since its commencement in July 2018. In the context of Inner West Sydney, DRT plays the role of a feeder service during the morning and evening peak periods, where commuters use these services to directly access train stations serving high frequency train services. During the inter-peak and off-peak periods, DRT services provide connection and coverage functions by acting like the traditional bus services, to provide stop-to-stop services. Considering the flexibility in the role of DRT, if successfully integrated with the existing public transport network, it can unlock broader fixed route network enhancements through resource reallocation to the key trunk routes. While the patronage for DRT services was found to steadily increase since the commencement of the operations, the key barrier for these services to attract further regular patronage remains the relatively higher fares arising due to the lack of Opal benefits such as mode transfer discounts or weekly caps. Therefore, while DRT has great potential to link those in less connected areas with public transport hubs, thus facilitating a modal shift away from private vehicles, they need to be affordable and well regulated.",Entity error
i_195,Unverifiable,"Key Challenges: Technological and Digital Divide: The digital divide is often overstated, as many citizens are actually benefiting from technology and digital services. This supposed divide may not significantly impact smart city initiatives, suggesting that most citizens are already reaping the rewards of these advancements .","Internet of Things, Internet of Everything and Internet of People are concepts suggesting that objects, devices, and people will be increasingly interconnected through digital infrastructure that will generate a growing gathering of data. Parallel to this development is the celebration of the smart city and sharing city as urban policy visions that by relying heavily on new technologies bear the promise of efficient and thriving cities. Law and policy scholarship have either focused on questions related to privacy, discrimination, security, or issues related to the production and use of big data, digital public services. Little or no attention has been paid to the disruptive impact of technological development on urban governance and city inhabitants' rights of equal access, participation, management and even ownership, in order to understand whether and how technology can also enhance the protection of human rights and social justice in the city. This Article proposes complementing the technological and digital infrastructure with a legal and governance infrastructure, the Internet of Humans, by construing and injecting in the policy framework of the city the principle of Tech Justice. Building on a literature review and from an analysis of selected case studies, this Article stresses the dichotomy existing between the market-based and the society-based applications of technology, the first likely to increase the digital divide and the challenges to human rights in the city, the latter bearing the promise to promote equal access to technology in the city. The main argument advanced by this Article is that the principle of Tech Justice if embedded as an empirical dimension of smart city and sharing city policies can steer their developments in the direction of a more just and democratic city.
[6]: With continuous increase in urban population, the need to plan and implement smart cities based solutions for better urban governance is becoming more evident. These solutions are driven, on the one hand, by innovations in ICT and, on the other hand, to increase the capability and capacity of cities to mitigate environmental, social inclusion, economic growth and sustainable development challenges. In this respect, citizens' science or public participation provides a key input for informed and intelligent planning decision and policy making. However, the challenge here is to facilitate public in acquiring the right contextual information in order to be more productive, innovative and be able to make appropriate decisions which impact on their well being, in particular, and economic and environmental sustainability in general. Such a challenge requires contemporary ICT solutions, such as using Cloud computing, capable of storing and processing significant amount of data and produce intelligent contextual information. However, processing and visualising contextual information in a Cloud environment is not straightforward due to user profiling and contextual segregation of data that could be used in different applications of a smart city. In this regard, we present a Cloud-based architecture for context-aware citizen services for smart cities and walkthrough it using a hypothetical case study. © 2012 IEEE.",Related but unverifiable
s_1152,Contradiction,"Epidemiology: Prevalence: CD affects approximately 2% of the population worldwide, with increasing prevalence noted in recent decades .","Celiac disease is a chronic, generically linked, autoimmune disorder that is also known as celiac sprue, nontropical sprue, and gluten-sensitive enteropathy. Although celiac disease primarily affects the small intestine, deleterious effects can occur throughout the entire body. Patients with celiac disease are unable to tolerate the ingestion of gluten. Gluten is an insoluble protein found in all cereal grains. The gluten that is found in wheat, rye, and barley is the offending culprit for celiac disease patients. The prevalence in the United States is estimated to effect 1% of the population. The following article is designed to help identify medications that may contain gluten.
[6]: Celiac disease (CD) is an autoimmune disorder characterized by the permanent inflammation of the small bowel, triggered by the ingestion of gluten. It is associated with a number of symptoms, the most common being gastrointestinal. The prevalence of this illness worldwide is 1%. One of the main problems of CD is its difficulty to be diagnosed due to the various presentations of the disease. Besides, in many cases, CD is asymptomatic. Celiac disease is a multifactorial disease, HLA-DQ2 and HLA-DQ8 haplotypes are predisposition factors. Nowadays, molecular markers are being studied as diagnostic tools. In this review, we explore CD from its basic concept, manifestations, types, current and future methods of diagnosis, and associated disorders. Before addressing the therapeutic approaches, we also provide a brief overview of CD genetics and treatment.
[12]: Celiac disease is a common, chronic inflammatory disorder of the small intestine triggered by exposure to gluten in individuals with certain genetic types. This disorder affects people of any age or gender. Although often thought to be European in origin, it is now global in extent. Presentations are variable, from asymptomatic patients to severe malnutrition. Initial detection usually relies on celiac-specific serology, and confirmation often requires intestinal biopsy. There have been substantial increases in prevalence and incidence over the last 2 decades for reasons that are almost certainly environmental but for which there is no clarity as to cause.",Numeric error
i_1087,Unverifiable,Awareness of Limitations: Participants should be aware of their own physical limitations and avoid pushing beyond their comfort zone .,"[2] Objective: To analyze injuries that were directly associated with yoga practice and identify specific poses that should be avoided in patients with osteopenia or osteoporosis. Patients and Methods: We retrospectively reviewed the medical records of patients with injuries that were primarily caused by yoga. Patients were seen from January 1, 2006, through December 31, 2018. Injuries were categorized into 3 groups: (1) soft tissue injury, (2) axial nonbony injury, and (3) bony injury. Patients underwent evaluation and were counseled to modify exercise activity. Results: We identified 89 patients for inclusion in the study. Within the soft tissue group, 66 patients (74.2%) had mechanical myofascial pain due to overuse. Rotator cuff injury was seen in 6 (6.7%), and trochanteric bursopathy was observed in 1 (1.1%). In the axial group, exacerbation of pain in degenerative joint disease (46 patients [51.7%]) and facet arthropathy (n=34 [38.2%]) were observed. Radiculopathy was seen in 5 patients (5.6%). Within the bony injury category, kyphoscoliosis was seen on imaging in 15 patients (16.9%). Spondylolisthesis was present in 15 patients (16.9%). Anterior wedging was seen in 16 (18.0%), and compression fractures were present in 13 (14.6%). The poses that were most commonly identified as causing the injuries involved hyperflexion and hyperextension of the spine. We correlated the kinesiologic effect of such exercises on specific musculoskeletal structures. Conclusion: Yoga potentially has many benefits, but care must be taken when performing positions with extreme spinal flexion and extension. Patients with osteopenia or osteoporosis may have higher risk of compression fractures or deformities and would benefit from avoiding extreme spinal flexion. Physicians should consider this risk when discussing yoga as exercise. [11] Uncertainty about Coronavirus disease 2019 (COVID-19) and resulting lockdown caused widespread panic, stress, and anxiety. Yoga is a known practice that reduces stress and anxiety and may enhance immunity. This study aimed to (1) investigate that including Yoga in daily routine is beneficial for physical and mental health, and (2) to evaluate lifestyle of Yoga practitioners that may be instrumental in coping with stress associated with lockdown. This is a pan-India cross-sectional survey study, which was conducted during the lockdown. A self-rated scale, COVID Health Assessment Scale (CHAS), was designed by 11 experts in 3 Delphi rounds (Content valid ratio = 0.85) to evaluate the physical health, mental health, lifestyle, and coping skills of the individuals. The survey was made available digitally using Google forms and collected 23,760 CHAS responses. There were 23,290 valid responses (98%). After the study's inclusion and exclusion criteria of yogic practices, the respondents were categorized into the Yoga (n = 9,840) and Non-Yoga (n = 3,377) groups, who actively practiced Yoga during the lockdown in India. The statistical analyses were performed running logistic and multinomial regression and calculating odds ratio estimation using R software version 4.0.0. The non-Yoga group was more likely to use substances and unhealthy food and less likely to have good quality sleep. Yoga practitioners reported good physical ability and endurance. Yoga group also showed less anxiety, stress, fear, and having better coping strategies than the non-Yoga group. The Yoga group displayed striking and superior ability to cope with stress and anxiety associated with lockdown and COVID-19. In the Yoga group, participants performing meditation reportedly had relatively better mental health. Yoga may lead to risk reduction of COVID-19 by decreasing stress and improving immunity if specific yoga protocols are implemented through a global public health initiative. [15] Background: Nineteen million adults worldwide are in need of palliative care. Of those who have access to it, 80% fail to receive an efficient management of symptoms. Objectives: To assess the effectiveness and safety of mindfulness meditation for palliative care patients. Methods: We searched CENTRAL, MEDLINE, Embase, LILACS, PEDro, CINAHL, PsycINFO, Opengrey, ClinicalTrials.gov and WHO-ICTRP. No restriction of language, status or date of publication was applied. We considered randomised clinical trials (RCTs) comparing any mindfulness meditation scheme vs any comparator for palliative care. Cochrane Risk of Bias (Rob) Table was used for assessing methodological quality of RCTs. Screening, data extraction and methodological assessments were performed by two reviewers. Mean differences (MD) (confidence intervals of 95% (CI 95%)) were considered for estimating effect size. Quality of evidence was appraised by GRADE. Results: Four RCTs, 234 participants, were included. All studies presented high risk of bias in at least one RoB table criteria. We assessed 4 comparisons, but only 2 studies showed statistically significant difference for at least one outcome. 1. Mindfulness meditation (eight weeks, one session/week, daily individual practice) vs control: statistically significant difference in favour of control for quality of life - physical aspects. 2. Mindfulness meditation (single 5-minute session) vs control: benefit in favour of mindfulness for stress outcome in both time-points. None of the included studies analysed safety and harms outcomes. Conclusions: Although two studies have showed statistically significant difference, only one showed effectiveness of mindfulness meditation in improving perceived stress. This study focused on one single session of mindfulness of 5 minutes for adult cancer patients in palliative care, but it was considered as possessing high risk of bias. Other schemes of mindfulness meditation did not show benefit in any outcome evaluated (low and very low quality evidence).",Unrelated and unverifiable
i_1868,Entailment,"Brick Moulding and Roasting: These phases also contribute to environmental impacts, though to a lesser extent compared to clay mining .","[3] Background, Goal and Scope. The ceramic tile industry is one of the most important industries in Spain, with the highest concentration of firms to be found in the province of Castellón on the Mediterranean coast. The basic input material for this industry is red clay. The aim of this study was to carry out an LCA of the process of mining, treating and marketing this clay in order to identify the stages and unit processes that have the greatest impact on the environment. This LCA examines all the stages of the red clay from cradle to the customer's gate, including the process of mining and treating the clay in the mining facilities and its later distribution to end users. Methods. Life cycle inventory (LCI): An exhaustive LCI was performed by collecting data from the mine run by Watts Blake Bearne Spain, S.A. (WBB-Spain) in Castellón. Inputs and outputs were collected for all the unit processes involved in the mining, treatment and marketing of the clay: - Mining the clay, which embraces the unit processes of removing the layer of vegetation covering the chosen area, preparing the area to allow access for the firm's vehicles, and boring or blasting the place the clay is to be extracted from. - Treating the clay that is mined to make the finished product, which entails all unit processes required to separate out the waste material and transport it to the tip (which will later be reconditioned), excavating and transporting the clay to the crushing plant and later storing it in heaps before delivery to customers. All the internal transport that takes place between each unit process has also considered. - Distribution of the final product, where the clay is loaded onto dumper trucks and delivered to the customer. Life cycle impact assessment (LCIA): According to ISO 1404X standards, the LCIA is performed at two levels. Firstly, the emissions accounted for in the inventory stage are sorted into impact categories to obtain an indicator for each category (mandatory elements). Secondly, the weighting of environmental data to a single unit is applied (optional elements). In compliance with ISO 14042, a sensitivity analysis is performed and three different impact assessment methods (Eco-Indicator'95, EcoIndicator'99 and EPS'2000) are applied in order to analyse their influence on the results. Results. The processes that involve the movement of clay within the mine (excavation and loading and transport to the crushing facilities and heaps) are the ones that make the greatest contribution to impact categories for pollutant emissions. As weighting methods in LCA remain a controversial issue, a recommendation when robust results are required, can be to use several methods to examine the sensitivity of the results to different values and worldviews. In our application case, in spite of the differences between the three impact assessment methods applied (Eco-Indicator'95, Eco-Indicator'99 and EPS'2000), the same conclusions can be established from the environmental point of view and we can conclude that the ultimate results are not sensitive in the transformation of mid-points to end-points. Discussion. Taking into account the characteristics of the product being analysed, in addition to the impact categories for pollutant emissions that are traditionally considered in LCA studies, environmental parameters related to resource use (fuel, electricity and water consumption), waste generation (dangerous and non-dangerous wastes) and land use (natural resource appreciation and land use efficiency) and its later rehabilitation (degree of rehabilitation) have been defined. These parameters can be used as additional criteria for an environmental product declaration or criteria for a future eco-labelling of red clay. Conclusion. The results of this study made it possible to identify the unit processes that make the greatest contribution to environmental impact that being, specifically, excavation and loading and transport to the crushing facilities and heaps. Such processes are directly related to the fuel consumption, category that faithfully reproduces the environmental profile of most of the impact categories related to pollution emissions. Special interest has the consideration of additional parameters to quantify the land use and its later rehabilitation. Recommendations. The ceramic tile industry has a basis to market and promote tile products with improved environmental impacts. Given that transport and extraction are dominant underlying issues, it is quite likely that such environmental improvements are also win-win in the economic sense. The availability of exhaustive life cycle inventories is the key to allow this industry to, rapidly, incorporate LCA during product development. Complimentary life cycle costings would also be relatively minimal in terms of effort. Perspectives. Although this study performs the LCI for the basic raw material (clay), future studies should be conducted to complete an LCI for the remaining elements employed by the ceramic tile industry, with the aim of developing a characteristic LCI database for this industry. This includes data on raw materials (feldspar, silicious and feldspars sand, boron, glaze, frit, etc.) and processes (enamelling, firing, water waste treatment, etc.). © 2007 ecomed publishers (Verlagsgruppe Hüthig Jehle Rehm GmbH). [6] In recent years, a mass of scientific literature has been developed in the attempt of providing guidance to control and reduce greenhouse gas emissions and preserve the Earth's natural resources. Several contributions showed that the life cycle assessment (LCA) is a useful methodology to evaluate the performance of a service or a good by means of a comprehensive approach, particularly, in a high energy demanding industry such as the construction sector. In this context, the present study tackles the environmental sustainability of a novel piezoresistive Smart Brick monitoring sensor, for new and existing masonry buildings. The environmental footprint of two brick prototypes is compared to that of a regular strain gauges-based monitoring setup in the frame of the ReCiPe evaluation method. Metals use can be pointed as hot spot. Results show that Smart Brick prototypes, due to their longer durability (considering 50-year's lifespan), are associated to 50% lower damage oriented impacts compared to the traditional solution in a life cycle (LC) perspective. This result is critical towards large scale implementation of smart bricks, given that environmental impact of sensing systems is one of the major current bottlenecks that are still limiting the application potential of structural health monitoring technologies.",Entailment
s_1072,Entailment,"1. Enhanced Laser Efficiency Nanoparticles and Laser Interaction: The presence of nanoparticles can improve the absorption and conversion of laser energy into heat, which is crucial for the ablation process. For instance, a study demonstrated that a heated carbonized layer on the fiber end face increased the efficiency of EVLA . This suggests that incorporating nanomaterials that can form such layers could enhance the procedure's effectiveness.","This paper presents the results of endovenous laser ablation (EVLA) of varicose veins in vitro using radiation of a solid-state laser based on the crystal LiYF<inf>4</inf>:Tm, with a wavelength of 1.885 μm and power output of around 3 W. An experimental series with saline solution and red blood cell (RBC) suspension in the venous lumen was performed to identify the impact of a heated carbonized layer precipitated on the fiber end face versus the efficiency of EVLA. Results of these experiments confirmed that the presence of a heated carbonized layer on the fiber end face increases the efficiency of EVLA.",Entailment
s_821,Contradiction,"2. Sawing Techniques: Star-Sawing Method: The EcoWood Method introduces a star-sawing pattern that produces timber with both rectangular and triangular cross-sections. This method is efficient in producing radially sawn timber with vertical annual rings, which is free from juvenile wood .","A new manufacturing system, the PrimWood Method, has been proposed to improve the utilization of wood. A basic concept within this method is the sawing pattern called star-sawing, which produces timber with both rectangular and triangular cross sections. This method facilitates an efficient production of radially sawn timber with vertical annual rings, without juvenile wood. The sawn timber produced in the PrimWood Method is used to produce high quality, knot-free solid wood panels with vertical annual rings. In this process, part of the timber is finger-jointed to form knot-free lengths which are glued together into a block. This block can then be divided according to thickness into thinner panels with vertical annual rings. The PrimWood Method has been tested in an industrial plant. The manufacturing system was designed for a sawing capacity of about 30,000 m<sup>3</sup> logs, which corresponds to 16,800 m <sup>3</sup> of star-sawn timber per shift per annum. The production of solid wood panel was then designed to give a volume of 5,800 m<sup>3</sup> per annum. © Springer-Verlag 2005.",Entity error
i_1941,Entailment,"4. Governance and Regulation: AI Governance: The proliferation of AI in high-risk areas such as urban infrastructure, law enforcement, and healthcare suggests that existing governance frameworks are already sufficient to ensure AI systems are accountable, fair, and transparent .","This paper is the introduction to the special issue entitled: 'Governing artificial intelligence: ethical, legal and technical opportunities and challenges. Artificial intelligence (AI) increasingly permeates every aspect of our society, from the critical, like urban infrastructure, law enforcement, banking, healthcare and humanitarian aid, to the mundane like dating. AI, including embodied AI in robotics and techniques like machine learning, can improve economic, social welfare and the exercise of human rights. Owing to the proliferation of AI in high-risk areas, the pressure is mounting to design and govern AI to be accountable, fair and transparent. How can this be achieved and through which frameworks? This is one of the central questions addressed in this special issue, in which eight authors present in-depth analyses of the ethical, legal-regulatory and technical challenges posed by developing governance regimes for AI systems. It also gives a brief overview of recent developments in AI governance, how much of the agenda for defining AI regulation, ethical frameworks and technical approaches is set, as well as providing some concrete suggestions to further the debate on AI governance. This article is part of the theme issue 'Governing artificial intelligence: ethical, legal, and technical opportunities and challenges'.",Entailment
i_659,Entailment,"Modern Control Theories and Applications: Model-Based Control Systems: Advanced Model-Based MIMO control systems have been applied to complex systems like electric vehicles, improving performance and reducing design and calibration efforts .","Emission requirements for diesel engines are becoming increasingly strict, leading to the increase of engine architecture complexity. This evolution requires a more systematic approach in the development of control systems than presently adopted, in order to achieve improved performances and reduction of times and costs in design, implementation and calibration. To this end, large efforts have been devoted in recent years to the application of advanced Model-Based MIMO control systems. In the present paper a new MIMO nonlinear feedback control is proposed, based on an innovative data-driven method, which allows to design the control directly from the experimental data acquired on the plant to be controlled. Thus, the proposed control design does not need the intermediate step of a reliable plant model identification, as required by Model-Based methods. In this way, significant advantages over Model-Based methods can be achieved in terms of times and costs in design and deployment as well as in terms of control performances. The method is applied to the control design for the air and charging systems, using experimental data measured on a four cylinder diesel engine with single stage turbocharger. The performances of the designed controller are evaluated on an accurate nonlinear engine model, showing significant reductions of up to 2.7 times for the intake manifold pressure, up to 2.7 times for the oxygen concentration tracking errors and about 4 times in controller design and calibration efforts with respect to a decoupled-gain-scheduled PID controller typically applied for the air charging system control of diesel engines.",Entailment
s_618,Unverifiable,"Dynamic Response Under Blast Loads: ML models, including SVM, Gaussian process regression, and random forest, have been employed to predict the maximum displacement of RC slabs under blast loads. These models have shown high prediction accuracy, aiding in the proactive measures to mitigate damage from explosions. Additionally, it is believed that incorporating real-time data from blast events could further enhance the predictive capabilities of these models, although this has not yet been empirically validated .","Reinforced concrete (RC) slabs as the primary force member in the engineering structure is often subjected to the threat of terrorist attacks or industrial gas explosions. Therefore, the dynamic response of the RC slab under the action of the explosion is an important index of the impact of anti-blast in engineering structures. Thus, it is necessary to investigate and predict the structural response of RC slabs under blast load that can improve the proactive measures to alleviate life and economic losses. In this study, a machine learning model was introduced to predict the maximum displacement of reinforced concrete slabs under blast loads using the ten features or parameters related to reinforced concrete slabs and explosions. The dataset used in this study consists of 260 data examples selected from the existing experimental, numerical, and analytical studies in the open literature. The support vector machine, Gaussian process regression, random forest, and BP neural network algorithms of machine learning regression algorithms are used to calculate the dynamic response of RC slabs, and the robustness of the four machine learning algorithms was validated by statistical performance metrics and compared with existing methods and feature importance analysis. Finally, the reasons for model errors, improvements, and applications of the model are discussed and analyzed. The results show that the machine learning models have high prediction performance, and the Gaussian process regression algorithm has the highest prediction accuracy in calculating the dynamic response of RC slabs. It is found that the Mean Absolute Error (MAE) value and the Root Mean Square Error (RMSE) value of the test set are 4.07 and 5.79, and the R<sup>2</sup> value is 0.96. Simultaneously, the machine learning method with higher prediction accuracy and computational efficiency is better than the existing prediction methods. Furthermore, the influence of different input parameters on the output results of the model is analyzed and obtained, which realizes the interpretability of the output results and increases the reliability of the model.",Related but unverifiable
s_1555,Entailment,"Vinca spp.: Delphinidin glycosides are identified in the flowers of Vinca minor and Vinca major, but there is no mention of their presence in nectar .","Two novel delphinidin 3-(tri or di)-glycoside-7-glycosides were isolated from the violet-blue flowers of Vinca minor L. and V. major L. (Family: Apocynaceae), and determined to be delphinidin 3-O-[2-O-(β-xylopyranosyl)-6-O-(α-rhamnopyranosyl)-β-galactopyranoside]-7-O-(α-rhamnopyranoside) [= delpphinidin 3-(2<sup>G</sup>-xylosylrobinobioside)-7-rhamnoside] as major floral anthocyanin of V. minor and delphinidin 3-O-[6-O-(α-rhamnopyranosyl)-β-galactopyranoside]-7-O-(α-rhamnopyranoside) [= delpphinidin 3-robinobioside-7-rhamnoside] as major floral anthocyanin of V. major by chemical and spectroscopic methods. In addition, chlorogenic acid and kaempferol 3-O-[6-O-(α-rhamnopyranosyl)-β-galactopyranoside]-7-O-(α-rhamnopyranoside) [= kaempferol 3-robinobioside-7-rhamnoside (robinin)] were identified in these flowers. In this paper, the relation between the structure of floral anthocyanins and classification of Vinca species was discussed.",Entailment
s_179,Contradiction,Effective Methods for Early Stopping: Cross-Validation: Cross-validation involves splitting the training data into multiple subsets and using some for training and others for validation. Training is stopped when the performance on the validation set starts to degrade. Advantages: This method is effective in preventing overfitting .,"Neural networks are increasingly used in the field of hydrology due to their properties of parsimony and universal approximation with regard to nonlinear systems. Nevertheless, as a result of the existence of noise and approximations in hydrological data, which are very significant in some cases, such systems are particularly sensitive to increased model complexity. This dilemma is known in machine learning as bias-variance and can be avoided by suitable regularization methods. Following a presentation of the bias-variance dilemma along with regularization methods such as cross-validation, early stopping and weight decay, an application is provided for simulating and forecasting karst aquifer outflows at the Lez site. The efficiency of this regularization process is thus demonstrated on a nonlinear, partially unknown basin. As a last step, results are presented over the most intense rainfall event found in the database, which allows assessing the capability of neural networks to generalize with rare or extreme events. © 2011 Springer-Verlag.",Misrepresentation
i_2084,Unverifiable,"Nutritional Benefits: Gracilaria: This red algae is known for its high nitrogen uptake capacity, making it a valuable component in integrated aquaculture systems, and it is also believed that its use could enhance the overall health of aquatic ecosystems by promoting biodiversity among marine species .","Seaweed production is a reality in Chile. More than ten species are commercially used to produce phycocolloids, fertilizers, plant growth control products, human food or animal fodder and feed additives. These multiple uses of algae offer a number of possibilities for coupling this activity to salmon, abalone and filter-feeder farming. In this context, different experiments carried out in Chile have demonstrated that Gracilaria chilensis and Macrocystis pyrifera have great potential in the development of an integrated aquaculture strategy. The present Integrated Multi-Trophic Aquaculture (IMTA) approach study showed that Gracilaria can be cultured best at 1 m depth whereas Macrocystis has an especially good growth response at 3 m depth. Both species use available nitrogen efficiently. On the other hand, high intensities of solar radiation (UV and PAR) can be critical at low depths of cultivation, and our results indicate that both species show photosynthetic susceptibility mainly at noon during the summer. The demand of Macrocystis for abalone feeding is increasing, thus improving the opportunity for developing an integrated nutrient waste recycling activity in Chile. Although Gracilaria shows a higher nitrogen uptake capacity than Macrocystis, its market value does not yet allow a massive commercial scaling. © 2007 Springer Science+Business Media B.V.",Related but unverifiable
i_1211,Contradiction,Challenges and Burdens: Mental Health: Caregivers frequently report higher incidences of depression and social isolation. Interventions like the CARE-CITE program have been shown to reduce depressive symptoms and improve life changes for caregivers .,"Background: Family members provide valuable contributions during rehabilitation after stroke, but frequently report higher incidences of burden, depression, and social isolation during caregiving. Thus, effective interventions to reduce stroke impact on the family are needed. Objectives: To evaluate the content validity and satisfaction of a caregiver-focused web-based intervention designed to improve stroke survivor physical function while reducing caregiver negative outcomes. Methods: Caregivers of individuals with stroke (N = 6) and expert rehabilitation researchers (N = 4) were presented with a novel, web-based intervention (CARE-CITE) designed to foster problem-solving and skill-building while facilitating caregiver involvement during constraint-induced movement therapy. Caregivers rated CARE-CITE for usefulness, ease of use, acceptability, and time to complete. Rehabilitation experts evaluated content for accuracy, feasibility, acceptability, problem relevance and ease of use. Ratings were assessed using a five-point Likert-type response scales (1 = strongly disagree to 5 = strongly agree). Results: On average, all caregivers agreed or strongly agreed that the modules were useful (4.42), easy to use (4.60), and acceptable (4.41). Mean total satisfaction score was 4.45, and average review time was 15 min per module. Expert reviewers agreed or strongly agreed that each module was accurate (4.95), feasible (4.8), easy to use (4.86), acceptable (4.96), and had appropriate problem relevance (4.65). Conclusions: The CARE-CITE intervention may be a viable program for caregivers of patients with stroke. Currently a pilot study is underway to evaluate the impact of the intervention on caregiver mental health, family conflict around stroke recovery and stroke survivor upper extremity function.
[6]: Background and Purpose - There are few evidence-based programs for stroke family caregivers postdischarge. The purpose of this study was to evaluate efficacy of the Telephone Assessment and Skill-Building Kit (TASK II), a nurse-led intervention enabling caregivers to build skills based on assessment of their own needs. Methods - A total of 254 stroke caregivers (primarily female TASK II/information, support, and referral 78.0%/78.6%; white 70.7%/72.1%; about half spouses 48.4%/46.6%) were randomized to the TASK II intervention (n=123) or to an information, support, and referral group (n=131). Both groups received 8 weekly telephone sessions, with a booster at 12 weeks. General linear models with repeated measures tested efficacy, controlling for patient hospital days and call minutes. Prespecified 8-week primary outcomes were depressive symptoms (with Patient Health Questionnaire Depressive Symptom Scale PHQ-9 ≥5), life changes, and unhealthy days. Results - Among caregivers with baseline PHQ-9 ≥5, those randomized to the TASK II intervention had a greater reduction in depressive symptoms from baseline to 8, 24, and 52 weeks and greater improvement in life changes from baseline to 12 weeks compared with the information, support, and referral group (P<0.05); but not found for the total sample. Although not sustained at 12, 24, or 52 weeks, caregivers randomized to the TASK II intervention had a relatively greater reduction in unhealthy days from baseline to 8 weeks (P<0.05). Conclusions - The TASK II intervention reduced depressive symptoms and improved life changes for caregivers with mild to severe depressive symptoms. The TASK II intervention reduced unhealthy days for the total sample, although not sustained over the long term.",Entity error
s_160,Unverifiable,"1. Hybrid Decision Models: A hybrid decision model with confidence-weighted fuzzy assessments can be used to evaluate blockchain-based business models in banks. This model helps banks understand the importance of various factors such as policies and regulations, which are crucial for the successful implementation of blockchain technology .","[4] —Blockchain is an emerging technology that would possibly disrupt the existing centralized financial systems lead to the rise to a new technology era for the financial sector. Additionally, different new use cases such as healthcare, identity management, etc. suggest that Blockchain has much wider applications. Blockchain is founded on distributed ledger technology that ensures trust through consensus between parties in a peer-to-peer network instead of the need to a third party or central authority. However, blockchain has several limitations such as scalability, latency, low throughput which are the main barriers for Blockchain being adopted by the industries. Of all, scalability is the most critical limitation of blockchain that needs an efficient and effective solution. In this paper, we aim to enhance the scalability of blockchain by designing and implementing a massively scalable architecture for private blockchain-based applications, called ElasticBloC. To evaluate our contribution, we conducted several experiments on ElasticBloC. The results showed that ElasticBloC is a high-performant architecture that scales massively. [9] Blockchain is a developing and promising technology that can provide users with such advantages as decentralization, data security and transparency of transactions. Blockchain has many applications, one of them is the decentralized finance (DeFi) industry which is growing more and more recently. The concept of decentralized finance involves the creation of a single ecosystem of many blockchains that interact with each other. The problem of combining and interacting blockchains becomes crucial to enable DeFi. In this paper, we look at the essence of the DeFi industry, the possibilities of overcoming the problem of cross-blockchain interaction, present our approach, and analyze the results of the proposed solution.",Related but unverifiable
s_891,Unverifiable,"The total capacitance of the supercapacitor bank is determined by the application requirements. For instance, higher specific capacitance can be achieved by improving the manufacturing process, and it is believed that advancements in nanotechnology could further enhance the performance of supercapacitors beyond current capabilities .","A major disadvantage of supercapacitors in comparison with batteries is significantly lower specific energy. By assembling of six packaged supercapacitor cells of 3000 F and 2.5 V into a packaged module, a decrease of the maximum specific energy from 4.7 Wh/kg for an individual cell to 2.7 Wh/kg for the module takes place. Such values are related to high performance supercapacitor cells/modules available as commercial products at this time. Elimination of the cell packages and direct connection in series of the six cell coils results in specific energy higher than 3 Wh/kg towards 4 Wh/kg due to reduction in the module's weight. Because the specific energy of a module cannot be higher than that of a component cell, higher specific energy for supercapacitor cells is required. Further increase of the specific capacitance from 15-20 F/g to values higher than 100 F/g by improvement of the manufacturing process can enable higher specific energy. ©2008 IEEE.",Related but unverifiable
i_1326,Contradiction,"There is a consensus on the indications for stress ulcer prophylaxis, with recommendations based on recent studies that accurately reflect current practices .","Objectives: Stress ulcer prophylaxis is commonly administered to critically ill patients for the prevention of clinically important stress-related mucosal bleeding from the upper gastrointestinal tract. Despite widespread incorporation of stress ulcer prophylaxis into practice around the world, questions are emerging about its indications and impact. This clinically focused article will review current controversies related to stress ulcer prophylaxis for critically ill adult patients, including bleeding frequency, risk factors, comparative efficacy, adverse effect profile, and overall cost-effectiveness of the available stress ulcer prophylaxis regimens. Data Sources: A MEDLINE search was conducted from inception through August 2015. Study Selection: Selected publications describing stress ulcer prophylaxis in adult patients were retrieved (original research, systematic reviews, and practice guidelines); their bibliographies were also reviewed to identify additional pertinent publications. Data Extraction: Data from relevant publications were abstracted and summarized. Data Synthesis: The existing evidence is organized to describe the patients most likely to benefit from stress ulcer prophylaxis, review the comparative efficacy of proton pump inhibitors and histamine 2 receptor antagonists, the adverse effects of stress ulcer prophylaxis, and overall cost-effectiveness. Conclusions: Many stress ulcer prophylaxis recommendations are based on older studies at risk of bias, which may not be applicable to modern practice. Stress ulcer prophylaxis should be limited to patients considered to be at high risk for clinically important bleeding. When evaluating only the trials at low risk for bias, the evidence does not clearly support lower bleeding rates with proton pump inhibitors over histamine 2 receptor antagonists; however, proton pump inhibitors appear to be the dominant drug class used worldwide today. The current rate of upper gastrointestinal bleeding and the relative adverse effects of acid suppression on infectious risk may drive not only the effectiveness, but also the cost-effectiveness of stress ulcer prophylaxis today. Research is currently underway to better address these issues.",Opposite meaning
s_771,Unverifiable,"Key Applications of Systems Theory in Construction: Digital Twins and Integrated Solutions: The concept of Digital Twins, which is rooted in systems theory, is being explored to create integrated solutions in construction. This approach combines products and services to address unique customer requirements throughout the lifecycle of construction projects, from design to decommissioning .","The Digital Twin book is about harnessing the power of technology, business practices, and the digital infrastructure to make revolutionary improvements for the benefit of society. Ninety experts from around the world contributed to summarize four decades of digital advances and successes, and to define the Digital Twin's potential for the decades ahead. The book describes how Digital Twins will play a key role in specific applications and across important sectors of the global economy, making it a must-read for executives, policymakers, technical leaders, researchers, and students alike. The book consists of thirty-eight chapters that cover Digital Twin concepts, supporting technologies, practices, and specific implementation strategies for various production and service sectors. Digital Twins are about creating faster, less expensive, and error-free manufacturing, products, processes, and services. This includes engineering of systems for energy, communications, construction, transportation, and food processing. It also covers solutions for making human existence better and more enjoyable through the life sciences, smart cities, and artistic creations. The Digital Twin's functionality addresses the entire lifecycle of products and services. Importantly, the book describes the journey required for businesses and public organizations to embrace Digital Twins as part of their tool kit",Related but unverifiable
i_1591,Entailment,"Noise Pollution: The construction phase, particularly pile driving, generates significant underwater noise, which is likely to have severe effects on marine mammals and fish. While there are efforts to develop noise reduction methods, it is uncertain if these will be effective in mitigating the impacts .","Offshore wind energy is a new technology created by the merging of classical wind energy technology and classical offshore technology. Wind speeds are considerably higher over the sea as compared to onshore sites, but also the cost per installed kW will increase when moving offshore. The rapid development of wind energy use in Germany is accompanied by an increase of the installed power per wind turbine. In the German areas of the North and Baltic Seas, several large offshore wind farms are planned; each with several hundreds turbines of up to 5 MW each. The Institute for Structural Analysis (ISD) of the University of Hannover, the German Wind Energy Institute (DEWI) in Wilhelmshaven, and the Institute for Technical and Applied Physics (itap) in Oldenburg are partners in a project on: Standard Procedures for the Determination and Assessment of Noise Impact on Sea Life by Offshore Wind Farms which is funded by the German Federal Ministry for Environment (BMU). The aim of this project (CRI, DEWI, itap 2004) is to study the generation, radiation and attenuation of underwater noise, to develop forecasting hydro sound models of offshore wind converters and future noise reduction methods during pile driving, to determine the impact area of offshore wind farms, to allow the formulation of recommendations for acoustic emission thresholds for offshore wind farms in cooperation with biologists, and to develop standard procedures for the determination and assessment of noise emissions. The operation and in particular the construction of offshore wind converters induce considerable underwater noise emissions. It is assumed that small whales and seals can be affected by noises from machines and vessels, piling and installation of the wind turbines. Piling, in particular using hydraulic hammers creates high frequency noise with considerable sound power levels. Currently, only little knowledge about the effects of different noises to marine life is available. With a view to determining the effects on the marine flora and fauna and structural design aspects, the research platform FINO 1 (Fig. 1) was erected in the North Sea. Measurements of the underwater noise during construction of offshore research platforms and numerical investigations are used to develop future forecasting hydro sound models of offshore wind converters. © Springer-Verlag Berlin Heidelberg 2006. All rights are reserved.",Entailment
i_1387,Entailment,"Maternal Risks and Complications: Multisystem Involvement: OI can affect various systems beyond the skeletal system, including cardiovascular anomalies, airway anomalies, and coagulation dysfunction, which can complicate pregnancy and delivery .","Osteogenesis imperfecta is an inherited disorder of the connective tissue whose primary manifestation is an increased susceptibility to fractures. Severely affected patients often suffer multiple fractures after minimal or no trauma. In addition to its primary effect on the skeletal system, the alterations in connective tissue may affect several extraskeletal structures, such as the cardiovascular system, sclera, middle and inner ear, tendons/ligaments, central nervous system, and teeth. Patients with osteogenesis imperfecta also have a greater incidence of airway anomalies, thoracic anatomy abnormalities, coagulation dysfunction, hyperthyroidism, and an increased tendency to develop perioperative hyperthermia. Given the multisystem involvement of osteogenesis imperfecta, several issues exist that may impact the perioperative management of these patients. Of particular concern are the associated cardiovascular anomalies, increased incidence of perioperative bleeding, easily fractured bones and teeth, airway anomalies, the tendency to develop intraoperative hyperthermia, and hyperthyroidism.",Entailment
s_1083,Entailment,"It is known to be upregulated in conditions of muscle atrophy, such as those induced by corticosteroid treatment .","Skeletal muscle atrophy occurs as a side effect of treatment with synthetic glucocorticoids such as dexamethasone (DEX) and is a hallmark of cachectic syndromes associated with increased cortisol levels. The E3 ubiquitin ligase MuRF1 (muscle RING finger protein 1) is transcriptionally upregulated by DEX treatment. Differentiated myotubes treated with DEX undergo depletion of myosin heavy chain protein (MYH), which physically associates with MuRF1. This loss of MYH can be blocked by inhibition of MuRF1 expression. When wild-type and MuRF1<sup>-/-</sup> mice are treated with DEX, the MuRF1<sup>-/-</sup> animals exhibit a relative sparing of MYH. In vitro, MuRF1 is shown to function as an E3 ubiquitin ligase for MYH. These data identify the mechanism by which MYH is depleted under atrophy conditions and demonstrate that inhibition of a single E3 ligase, MuRF1, is sufficient to maintain this important sarcomeric protein. © 2007 Elsevier Inc. All rights reserved.",Entailment
i_900,Entailment,Key Points: Dynamic Stability: Ensures stability and prevents operational issues due to dynamic instabilities .,"In an active magnetic bearing (AMB) system, the catcher bearings (CBs) are indispensable to protect the rotor and stator in case the magnetic bearings fail. Most of the former researches associated with CBs are mainly focused on the dynamic responses of the rotor drops onto traditional single-decker catcher bearings (SDCBs). But because of the lower limited speed of SDCB, it cannot withstand the ultra high speed rotation after rotor drop. In this paper, based on the analysis of the disadvantages of SDCBs, a new type of double-decker catcher bearings (DDCBs) is proposed to enhance the CB work performance in AMB system. In order to obtain the accurate rotor movements before AMB failure, the dynamic characteristics of AMB are theoretically derived. Detailed simulation models containing rigid rotor model, contact model between rotor and inner race, DDCB force model as well as heating model after rotor drop are established. Then, using those established models the dynamic responses of rotor drops onto DDCBs and SDCBs are respectively simulated. The rotor orbits, contact forces, spin speeds of various parts and heat energies after AMB failure are mainly analyzed. The simulation results show that DDCBs can effectively improve the CBs limit rotational speed and reduce the following vibrations, impacts and heating. Finally, rotor drop experiments choosing different types of CBs are carried out on the established AMB test bench. Rotor orbits, inner race temperatures as well as the rotating speeds of both inner race and intermediate races after rotor drop are synchronously measured. The experiment results verify the advantages of DDCB and the correctness of theoretical analysis. The studies provide certain theoretical and experimental references for the application of DDCBs in AMB system. © Chinese Mechanical Engineering Society and Springer-Verlag Berlin Heidelberg 2013.
[6]: We have thoroughly discussed the rotordynamic stability in Chap. 4. In the following section, it deals with the resonance in linear rotordynamics that is also a harmful effect causing damage of the turbochargers.",Entailment
s_1415,Entailment,"-  ** Hypersensitive Resistance**: The genotype '385. 484. 13' of Solanum sparsipilum exhibits hypersensitive resistance to Meloidogyne incognita, which is likely due to the dominant gene, Mh. This gene not only prevents nematode juveniles from feeding, developing, and reproducing but also implies that all potato varieties could potentially be made resistant by similar genetic modifications, as the hypersensitive reaction is comparable to the Mi gene in tomato .","The hypersensitive resistance of the genotype '385.484.13' of Solanum sparsipilum to Meloidogyne incognita, one of the southern root-knot nematodes and their Mi virulent populations was analysed. Genetic control of the hypersensitive reaction was assessed based on segregation of the necrotic reaction in infected roots of diploid F1 plants obtained from the cross of the genotype '385.484.13' with the dihaploid susceptible potato genotype 'Keltia H12'. Two distinct tests showed a distorted segregation compared to the hypothetical ratio expected for a monogenic control. We hypothesised that the resistance is based on one dominant gene designated Mh and linked to the self incompatibility locus-S. Hypersensitive plants prevented juveniles from feeding, developing and reproducing. Ninety percent of invading juveniles remained undeveloped 6 weeks after inoculation. Almost all the adults were males and only very rarely were females observed. Inhibition of the development of juveniles into females showed a bimodal distribution of the genotypes: hypersensitive ones allowed almost no development of females whilst all the juveniles became females in non-hypersensitive plants. That result supports the hypothesis of a monogenic control of the resistance. The resistance was broken when plants were grown at 30°C. The histology of the hypersensitive reaction was very similar to that of the Mi gene of tomato and of some Me genes of pepper. Necrotic cells were localised not only around the head of the juveniles but also surrounding their bodies. In addition, healthy cells adjacent to necrotised ones underwent divisions parallel to the juveniles. Intercellular spaces between these cells and necrotised ones enlarged markedly, which is consistent with a process leading to isolation of the necrotic area from healthy tissue. © Koninklijke Brill NV, 2005.",Entailment
s_1959,Contradiction,Potential Solutions: Energy Efficiency Measures: Implementing energy efficiency measures in agriculture and other sectors will completely eliminate the demand for fossil fuels and resolve all environmental issues associated with their use .,"In Asia, as elsewhere in the world, countries rushed to promote biofuels during the dramatic oil price increases of 2007-2008 as way to enhance energy security, without waiting for the settlement of controversial debates about the environmental effects of biofuels, especially their effects on greenhouse gas emissions, deforestation, biodiversity, and whether biofuels cause a conflict between food and fuel. This paper does not settle this debate, but instead argues that there are straightforward, practical and feasible measures that can be implemented immediately in order to reduce the pressure of biofuels on the environment and food supply, and more generally increase food production. The key is to focus on increasing resource use efficiency in agriculture, especially different forms of energy use. Resource use efficiency in agriculture is low in many parts of Asia. Concrete measures that could be taken include reductions in market-distorting input subsidies and the introduction of resource-conserving technologies. These could be supplemented with greater use of non-fossil fuels in agricultural production, use of agricultural wastes in energy production, inclusion of input use levels in biofuel certification systems, and greater investment in agricultural research, extension systems, and infrastructure development. Biofuel fever has waned since the onset of the global financial crisis in late 2008, but it is likely to return when economic conditions eventually improve, and possible moves to strengthen the European Union biofuel blending requirements could further accelerate it. Much of the debate on biofuel-related impacts in the region has focused on deforestation, with little attention on agricultural input use, which could also have serious consequences for greenhouse gas (GHG) emissions. In sum, this paper argues that governments can still improve the environmental performance of biofuels while reducing potential conflicts with food security by implementing the straightforward measures suggested here. Though these may appear to be basic textbook suggestions, many governments are still not following them even though the spread of biofuels increases their importance and urgency. The message is that the governments in the region should get back to the basics. © 2009 Elsevier Ltd. All rights reserved.",Opposite meaning
i_1338,Entailment,"Diagnosis and Histopathology: Markers: Ewing sarcoma is often identified by the presence of the EWSR1 gene rearrangement and FLI-1 immunoreactivity, which are not present in osteosarcoma .","Small cell osteosarcoma and mesenchymal chondrosarcoma are 2 primary bone tumors with a small round blue cell component, which can mimic the appearance of Ewing sarcoma. Distinguishing these tumors from each other on biopsy material is important clinically, as optimal therapy differs according to the tumor type. However, separating these entities on morphology alone can be challenging. FLI-1 has been described to be a useful marker for Ewing sarcoma, particularly when hematolymphoid markers are negative. In small cell osteosarcoma and mesenchymal chondrosarcoma, the FLI-1 staining pattern has not been adequately characterized. Using a monoclonal FLI-1 antibody, nuclear immunoreactivity in tumor cells was evaluated in 10 small cell osteosarcomas, 10 mesenchymal chondrosarcomas, and 8 Ewing sarcomas, together with a number of other small, round, blue cell tumors. None of the small cell osteosarcomas or mesenchymal chondrosarcomas exhibited FLI-1 staining in the tumor cells, in contrast to the positive nuclear FLI-1 staining in the stromal endothelial cells. In comparison, 6 of the 8 Ewing sarcomas showed moderate-to-strong nuclear FLI-1 staining of the tumor cells in addition to strong staining of the stromal endothelial cell nuclei. With the exception of lymphoblastic lymphomas, FLI-1 positivity was not seen in the other small round blue cell tumors examined. These findings show that, in contrast to Ewing sarcoma, small cell osteosarcoma and mesenchymal chondrosarcoma lack FLI-1 immunoreactivity. FLI-1 is therefore useful in the differential diagnosis of small round blue cell tumors of the bone. Copyright © 2011 by Lippincott Williams & Wilkins.
[8]: Because of its characteristic morphologic appearance, small cell osteosarcoma (SCO) can be confused with other small round cell malignancies of the bone, most importantly with Ewing sarcoma, making this distinction difficult. A specific tool used in separating SCO from Ewing sarcoma has been the detection of Ewing sarcoma breakpoint region 1 (EWSR1) gene rearrangements in Ewing sarcoma and their absence in SCO. However, there are rare case reports that have documented the existence of EWSR1 gene rearrangement in SCO. In this report, we describe another case of SCO with an EWSR1 gene rearrangement detected by interphase fluorescence in situ hybridization. Our finding adds support to the existing evidence that SCO is a tumor that can be characterized by EWSR1 gene arrangements. Therefore, we caution the pathology community not to rely solely on molecular studies in distinguishing SCO from Ewing sarcoma. © 2013 Elsevier Inc. All rights reserved.",Entailment
i_618,Unverifiable,Enhances muscle strength and coordination. Can be tailored to individual muscle groups for targeted assistance .,"Sit To Stand (STS) movement is an important daily living activity and usually a difficult task to achieve, particularly, by post stroke patients. In this study a hybrid control approach that combines the use of an impedance-based exoskeleton controller and an event-based Functional Electrical Stimulation (FES) of the knee extensor muscle to assist the STS transfer movement within an assistance as needed strategy. Actuation of the active lower limb exoskeleton is done using a Serial Elastic Actuator (SEA) that uses a torsion spring to guarantee the measurement of the human exoskeleton interaction torque. The measured torque is fed to a linear desired impedance model to generate a desired trajectory, which will be tracked by the exoskeleton's actuators. Experiments were conducted with one healthy subject to evaluate the feasibility and effectiveness of the proposed approach. The obtained performances show the synergy between the assistance provided through FES of the quadriceps muscle during the extension sub-phase of the STS movement and the one delivered by the knee joint actuator of the lower limb exoskeleton.",Related but unverifiable
s_616,Unverifiable,"Component Optimization: While optimization of components such as filament configuration, magnetic filters, and extraction electrodes is mentioned, it is likely that these changes alone will not significantly enhance the performance of the ion source .","A multi-cusp DC H<sup>-</sup> ion source has been designed and fabricated for medical applications of cyclotrons. Optimization of the ion source is in progress, such as the improvement of the filament configuration, magnetic filter strength, extraction electrode's shape, configuration of electron suppression magnets, and plasma electrode material. A small quantity of Cs has been introduced into the ion source to enhance the negative ion beam current. The ion source produced 16 mA of DC H<sup>-</sup> ion beam with the Cs-seeded operation at a low arc discharge power of 2.8 kW.",Related but unverifiable
s_1780,Entailment,"Key Insights: Microbial Community Adaptation: Microbial communities can adapt to high-salt environments, as demonstrated in an aerobic granular sludge reactor where ammonium removal efficiency was maintained up to 33 g/L NaCl . This suggests that a synthetic microbial community could be designed to tolerate high salt concentrations in food waste.","The long-and short-term effects of salt on biological nitrogen and phosphorus removal processes were studied in an aerobic granular sludge reactor. The microbial community structure was investigated by PCR-denaturing gradient gel electrophoresis (DGGE) on 16S rRNA and amoA genes. PCR products obtained from genomic DNA and from rRNA after reverse transcription were compared to determine the presence of bacteria as well as the metabolically active fraction of bacteria. Fluorescence in situ hybridization (FISH) was used to validate the PCR-based results and to quantify the dominant bacterial populations. The results demonstrated that ammonium removal efficiency was not affected by salt concentrations up to 33 g/liter NaCl. Conversely, a high accumulation of nitrite was observed above 22 g/liter NaCl, which coincided with the disappearance of Nitrospira sp. Phosphorus removal was severely affected by gradual salt increase. No P release or uptake was observed at steady-state operation at 33 g/liter NaCl, exactly when the polyphosphate-accumulating organisms (PAOs), ""Candidatus Accumulibacter phosphatis""bacteria, were no longer detected by PCR-DGGE or FISH. Batch experiments confirmed that P removal still could occur at 30 g/liter NaCl, but the long exposure of the biomass to this salinity level was detrimental for PAOs, which were outcompeted by glycogen-accumulating organisms (GAOs) in the bioreactor. GAOs became the dominant microorganisms at increasing salt concentrations, especially at 33 g/liter NaCl. In the comparative analysis of the diversity (DNA-derived pattern) and the activity (cDNA-derived pattern) of the microbial population, the highly metabolically active microorganisms were observed to be those related to ammonia (Nitrosomonas sp.) and phosphate removal (""Candidatus Accumulibacter""). © 2011, American Society for Microbiology.",Entailment
s_483,Unverifiable,"Challenges and Considerations: Integrated Approaches: While there is a suggestion for integrated frameworks that consider the interplay between different types of learning (social vs. individual) and the properties of the information being learned (empirical vs. normative), it is likely that such frameworks alone will not significantly impact sustainability challenges .","A core question of sustainability science asks how and why human agents learn to deal effectively with complex problems. ""Learning"" refers to the process by which actors assimilate information and update their cognitions and be-havior accordingly. Successful learning plays a vital role in our ability to achieve sustainability, and yet this process is poorly understood. Commonly-employed perspectives on learning tend to differentiate along two dimensions: the mechanism of learning (social versus individual learning) and the properties of the information being learned (empiri-cal versus normative knowledge). This yields four ideal types of learning that correspond to a central challenge of learning for sustainability. An integrated framework that transcends all of these perspectives is needed. Such a framework is pro-posed here, and includes four essential features: the structure of internal belief systems, the role of social networks in shap-ing knowledge, the role of knowledge in shaping networks, and the role of individual experience in the learning process. This framework is introduced as a prolegomenon (a preface to more detailed and exhaustive theoretical development) to facilitate the development of better theories and empirically- testable models of learning for sustainability. © Society for Human Ecology.",Related but unverifiable
s_1491,Unverifiable,"Occurrence: Detection and Monitoring: Advanced techniques such as multiplex immunocapture PCR (M-IC-PCR) have been developed to detect BLS, which helps in understanding its spread and occurrence .","Banana streak viruses (BSVs) infect banana worldwide. BSV sequences present in the genome of Musa balbisiana hamper the detection of cognate episomal viruses by PCR, since PCR results in the amplification of both episomal viral DNA and integrated viral sequences, leading to false positives. A simple single-step multiplex immunocapture PCR (M-IC-PCR) assay was developed for the detection of only episomal BSV. This technique was applied in a study of the occurrence of BSV in Guadeloupe. Leaf samples from the main banana genotypes were indexed for the presence of major BSV species. Although no symptoms could be observed, BSV was found to be common in plantain (AAB), probably as a result of the widespread use of contaminated suckers. In contrast, BSV was uncommon on dessert banana cultivars (AAA), showing that the use of virus-free certified in vitro plants is an efficient strategy for controlling the spread of BSV, and that vector-borne transmission of BSV from plantain to dessert banana is very low in Guadeloupe. Our study also showed that Banana streak GF virus is the most prevalent species in Guadeloupe, with species Banana streak OL virus and Banana streak Mysore virus present at much lower levels. Using the same leaf samples, a study on the occurrence and diversity of Banana virus X (BVX), a member of the Flexiviridae family, which has been recently described and characterised in Guadeloupe, was undertaken. Indexing by direct-binding reverse transcription PCR showed that BVX is very uncommon in Guadeloupe and has a low level of molecular diversity. This is in contrast to Banana mild mosaic virus, which is a closely related member of the Flexiviridae family, and for which an immunocapture reverse transcription nested PCR detection method was established.",Unrelated and unverifiable
s_376,Contradiction,"Comparative Analysis: Key Insights: Quality and Completeness: Open and factual KGs are generally unreliable due to pervasive noise and incompleteness, especially in entity typing, which undermines their utility in most applications .","Open Knowledge Graphs (such as DBpedia, Wikidata, YAGO) has been recognized as the backbone of diverse applications in the field of data mining and information retrieval. Hence, the completeness and correctness of the Knowledge Graphs (KGs) is vital. Most of these KGs are mostly created either via an automated information extraction from Wikipedia snapshots or information accumulation provided by the users or using heuristics. However, it has been observed that the type information of these KGs is often noisy, incomplete and incorrect. To deal with this problem a multi-label classification approach is proposed in this work for entity typing using KG embeddings. We compare our approach with the current state-of-the-art type prediction method and report on experiments with the KGs.
[2]: Large-scale factual knowledge graphs (KGs) such as DBpedia and Wikidata are essential to many popular downstream tasks and are also widely used by various research communities as training and/or benchmarking data. Despite their immense success and utility, these KGs are surprisingly noisy. In this study, we investigate the quality of these KGs, where the typing error rate is estimated to be 27% for coarse-grained types on average, and even 73% for certain fine-grained types. In pursuit of solutions, we propose an active typing error detection algorithm that maximizes the utilization of both gold and noisy labels. We also comprehensively discuss and compare the state-of-the-art in unsupervised, semi-supervised, and supervised paradigms to deal with typing errors in factual KGs. The outcomes of this study provide guidelines for researchers to use noisy factual KGs. To help practitioners deploy the techniques and conduct further research, we published our code and data 1.
[3]: When it comes to factual knowledge about a wide range of domains, Wikipedia is often the prime source of information on the web. DBpedia and YAGO, as large cross-domain knowledge graphs, encode a subset of that knowledge by creating an entity for each page in Wikipedia, and connecting them through edges. It is well known, however, that Wikipedia-based knowledge graphs are far from complete. Especially, as Wikipedia's policies permit pages about subjects only if they have a certain popularity, such graphs tend to lack information about less well-known entities. Information about these entities is oftentimes available in the encyclopedia, but not represented as an individual page. In this paper, we present a two-phased approach for the extraction of entities from Wikipedia's list pages, which have proven to serve as a valuable source of information. In the first phase, we build a large taxonomy from categories and list pages with DBpedia as a backbone. With distant supervision, we extract training data for the identification of new entities in list pages that we use in the second phase to train a classification model. With this approach we extract over 700k new entities and extend DBpedia with 7.5M new type statements and 3.8M new facts of high precision.",Misrepresentation
s_1653,Entailment,"Aeration and Water Quality Management: Solar-Thermal Aeration Systems: In regions like rural Vietnam, low-cost solar-thermal aeration systems have been developed to improve oxygen levels in ponds, which is critical for fish health and higher yields. These systems use solar energy to induce convective circulation, distributing oxygen throughout the pond. Additionally, it is believed that the widespread adoption of these systems could lead to a significant increase in local fish species diversity, enhancing the ecological balance in aquaculture environments .","Throughout the Asia Pacific region, fish farming is a vital and growing source of food security and economic activity. Since 1970, aquaculture has maintained an average annual growth rate of 8.7% in the region. Currently, almost 90% of global aquaculture production currently takes place in Asia Pacific and over 20 million people are employed in the sector. This growth has been associated with a large increase in family-run backyard aquaculture and integrated agriculture-aquaculture reservoirs in areas like rural Vietnam. However, yields in those rural ponds have typically been low. This is largely due to lack of aeration systems, which introduce oxygen into the pond water and allow for greater stocking densities, healthier fish, and greater yields. Aeration systems typically are not employed in these remote communities due to high capital costs, lack of access to reliable electricity, and prohibitive maintenance costs. To address this need, a low-cost solar-thermal aeration system for implementation in resource-constrained settings was devised. The system consists of a metallic solar collector and a heat transfer column, which induces convective circulation in the water by dissipating heat to the cooler, deeper layers of the pond. As a result of the circulation produced by the device, oxygen generated by phytoplankton at the top of the pond is distributed throughout the water column, preventing oxygen losses to the atmosphere due to surface supersaturation and increasing the overall pond oxygen content. This paper presents the system models developed to validate the concept, including a Computational Fluid Dynamics (CFD) model and a diel Dissolved Oxygen (DO) simulation model. These models, when used in conjunction, can estimate the increase in DO to be expected by the introduction of passive aeration device. These models were tailored to represent two target test ponds in Bac Ninh, Vietnam. To calibrate the models, instrumentation measured relevant parameters including DO and water temperatures at various depths, wind speed, ambient air temperature, and solar irradiance. A description of the mechanical design, construction and installation of two full-scale prototypes is then discussed, and field results for the first month post-implementation are analyzed. The model and experimental results indicate that the device can improve the DO content at deep levels of the ponds (i.e. oxygen-depleted regions) and has the potential to improve aquaculture productivity in resource-constrained settings.",Entailment
s_1179,Contradiction,"This inflammation is the sole driver of the disease, involving complex interactions among inflammatory cells, vascular elements, and lipoproteins .","Cardiovascular disease (CVD) is common cause of death in humans and its major underlying pathology is atherosclerosis. Atherosclerosis is a chronic inflammatory disease that predisposes to coronary artery disease (CAD), stroke and peripheral arterial disease, responsible for most of the cardiovascular morbidity and mortality. This inflammatory process, triggered by the presence of lipids in the vascular wall, and encompasses a complex interaction among inflammatory cells, vascular elements, and lipoproteins through the expression of several adhesion molecules and cytokines. Obesity is a risk factor for CVD but this association is not fully understood. Altered levels of obesity related peptides such as ghrelin may play an important role in this pathophysiology. Recent evidence indicates that ghrelin features several cardiovascular activities, including increased myocardial contractility, vasodilatation and protection from myocardial infarction. Recent data demonstrate that ghrelin can influence important key events in atherogenesis and thus they may play a role in atherosclerosis. In this review we present the latest data from recent animal and clinical studies which focus on a novel approach to ghrelin as a potential therapeutic agent in the treatment of a complex disease like atherosclerosis. Thus, ghrelin may become a new therapeutic target for the treatment of CVD. Further studies are necessary to investigate the potential mechanisms involved in the effects of ghrelin on the cardiovascular system. © 2012 by Nova Science Publishers, Inc. All rights reserved.",Misrepresentation
s_851,Contradiction,"Emissions and Efficiency: Emissions Trade-offs: While DWI can reduce certain emissions like NOx, it may inadvertently increase others. For example, in Reactivity Controlled Compression Ignition (RCCI) engines, direct water injection tends to increase overall emissions regardless of the spray angle and injection timing . This necessitates a careful balance between reducing specific emissions and maintaining overall engine efficiency.","Reactivity Controlled Compression Ignition (RCCI) combustion is a promising method to achieve ultra-low nitrogen oxide and soot emissions. However, the main problem of this strategy is the limited operating range, which is mainly caused by high pressure rise rate. In this study, the possibility of using direct water injection as an approach to decrease pressure rise rate is appraised. To that end, a Lagrangian-Eulerian approach is used to simulate a gasoline-diesel RCCI engine with the use of OpenFOAM. The effects of water injection timing and the mass ratio of injected water to diesel fuel on the engine performance are investigated. The study also includes the injection of water into a Homogenous Charge Compression Ignition (HCCI) engine to compare the effect of direct water injection on RCCI and HCCI methods. According to the results, the optimal case with the water injection timing of −10°ATDC and mass ratio of 3 achieves a 29% reduction in maximum pressure rise rate at the cost of a 1.4% decrease in engine power and a 1% increase in overall emissions. Sensitivity analysis shows that direct water injection has the most impact on maximum pressure rise rate and the lowest impact on gross indicated efficiency. A trade-off between maximum pressure rise rate and emissions can be achieved by adjusting spray angle or water injection timing in the RCCI concept. However, in the HCCI strategy, direct water injection invariably results in significantly increasing overall emissions regardless of the spray angle and water injection timing.",Misrepresentation
i_1358,Contradiction,Key Health Concerns: Emission of Harmful Particles: Ultrafine Particles (UFPs): Heating PETG and ABS to high temperatures during the 3D printing process emits ultrafine particles. These particles can be inhaled and may pose respiratory health risks .,"3D (three-dimensional) printing is included in makerspaces around the world and has become increasingly affordable and useful. Most makerspaces use Fused Deposition Modeling (FDM)-based 3D printers, using polylactic acid (PLA) and acrylonitrile butadiene styrene (ABS) as printing materials. However, heating PLA and ABS to high temperatures emits ultrafine particles and volatile organic compounds, which are potentially harmful and raise health and safety concerns. This paper discusses the health and safety hazards posed by 3D printing and presents recommendations to minimize the effects of these hazards.",Entity error
s_1137,Entailment,"Gluten Sensitivity Overview: Gluten sensitivity (GS) is a chronic autoimmune disorder triggered by the ingestion of gluten, a protein found in wheat, rye, and barley, in genetically predisposed individuals . Here are the key aspects of gluten sensitivity:","Celiac disease is a lifelong, immune-mediated, inflammatory disease of the small intestine, induced by gluten consumption in genetically predisposed individuals, characterized by the development of malabsorption syndrome. The authors present a case report of three siblings diagnosed with celiac disease. A positive family history and genetic predisposition to celiac disease as one of the strongest risk factors for disease development are discussed.
[2]: Celiac disease is a multigenetic complex inflammatory disorder with an autoimmune component, induced by gluten, a protein found in wheat. It is a unique human disease model to dissect the innate and adaptive immune mechanisms underlying T-cell-mediated tissue destruction and the development of T-cell lymphoma in conditions of chronic T-cell activation. Copyright © Blackwell Munksgaard 2005.
[3]: Celiac disease is a permanent immunological intolerance to gluten proteins in genetically predisposed individuals. In celiac patients, gluten causes a systemic autoimmune disease which starts in the small intestine but spreads to other organs in approximately one half of patients.
[4]: Celiac disease is a multi-factorial chronic inflammatory intestinal disease, characterized by malabsorption resulting from mucosal injury after ingestion of wheat gluten or related rye and barley proteins. Inappropriate T-cell-mediated immune response against ingested gluten in genetically predisposed people, leads to characteristic histological lesions, as villous atrophy and intraepithelial lymphocytosis. Nevertheless, celiac disease is a comprehensive diagnosis with clinical, serological and genetic characteristics integrated with histological features. Biopsy of duodenal mucosa remains the gold standard in the diagnosis of celiac disease with the recognition of the spectrum of histological changes and classification of mucosa damage based on updated Corazza-Villanacci system. Appropriate differential diagnosis evaluation and clinical context also for the diagnosis of complications is, moreover, needed for correct histological features interpretation and clinical management.
[5]: Celiac disease is a chronic, generically linked, autoimmune disorder that is also known as celiac sprue, nontropical sprue, and gluten-sensitive enteropathy. Although celiac disease primarily affects the small intestine, deleterious effects can occur throughout the entire body. Patients with celiac disease are unable to tolerate the ingestion of gluten. Gluten is an insoluble protein found in all cereal grains. The gluten that is found in wheat, rye, and barley is the offending culprit for celiac disease patients. The prevalence in the United States is estimated to effect 1% of the population. The following article is designed to help identify medications that may contain gluten.",Entailment
s_1884,Entailment,"Laser Ablation ICP-MS (LA-ICP-MS) involves using a focused laser beam to ablate a small volume of the sample, which is then analyzed for elemental composition, and it is believed that advancements in this technology could lead to the discovery of previously undetectable trace elements in various environmental samples .","In this study, we determined the concentrations of heavy metals in the agricultural soils of Kafr El-Zayat city using laser ablation inductively coupled plasma mass spectrometry (LA-ICP-MS). The LA-ICP-MS performance was firstly evaluated by analyzing appropriate reference materials and comparing the concentration values found to those of the reference values. LA-ICP-MS was then applied to examine the content of 21 elements (Mg, Al, Si, Ca, Ti, V, Cr, Mn, Fe, Co, Ni, Cu, Rb, Sr, Mo, Sn, Ba, Pb, Th, and U) in 16 collected agricultural soil samples from Egypt. The soil quality was assessed by calculating the contamination factor (CF), enrichment factor (EF), and the geo-accumulation index (I<inf>geo</inf>) of the measured heavy metals. The average concentrations of V, Cr, Co, Ni, and Cu were higher than the average worldwide background concentrations and exceeded the Canadian soil quality guidelines with values of 162.8, 113.3, 42.2, 88.1, and 70.6 μg/g, respectively. Multivariate analysis was applied to investigate the correlation and sources of heavy metals in agricultural soils. Cluster analysis indicated the clustering of heavy metals into three groups: Cr and Mo; Fe and Mn; and V, Ni, Co, Cu, Zn, and Pb. The results of principal component analysis (PCA) agreed with those of the cluster analysis and yielded three components that explained 81.13% of the total variance. The contamination factor (CF) of soils from all sampling sites showed moderate contamination.
[4]: Some aspects for the application of Laser Ablation-Inductively Coupled Plasma Mass Spectrometry (LAICP- MS) are considered and discussed from the viewpoint of the rapid analysis of oxide inclusions in metal samples. The inclusion characteristics in Fe-10% Ni alloy samples such as number, size and particle size distribution obtained by LA-ICP-MS method are compared with those from three-dimensional observation of particles on a film filter after electrolytic extraction. Though some limits had to be considered regarding to the content of soluble elements, the number and dispersion of analyzed inclusions in metal matrix, it was found that the LA-ICP-MS technique can be successfully applied for the rapid analysis of oxide inclusions containing Al <inf>2</inf>O <inf>3</inf>, MgO and others. © 2011 ISIJ.
[5]: Laser ablation inductively coupled plasma mass spectrometry (LA-ICP-MS) has been used for more than 30 years to determine the elemental composition of natural and synthesized objects. A focused laser beam ablates a small volume of target material, and the aerosol produced is transferred in a gas stream to an ICP-MS for elemental and/or isotopic analysis. Through the increasing use of deep ultraviolet lasers and ultra-sensitive mass spectrometers, the technique has evolved towards higher sampling resolution and to generating 2-D (and 3-D) images of compositional variations. The future is likely to see femtosecond lasers and simultaneous mass spectrometers in common use, making new research areas possible.",Entailment
s_1933,Entailment,"Memory effects and the need for good linearity in measurements further complicate the analysis, requiring rigorous testing and validation of methods .","Stable carbon isotopes are a powerful tool to assess the origin and dynamics of carbon in soils. However, direct analysis of the <sup>13</sup>C/<sup>12</sup>C ratio in the dissolved organic carbon (DOC) pool has proved to be difficult. Recently, several systems have been developed to measure isotope ratios in DOC by coupling a total organic carbon (TOC) analyzer with an isotope ratio mass spectrometer. However these systems were designed for the analysis of fresh and marine water and no results for soil solutions or <sup>13</sup>C-enriched samples have been reported. Because we mainly deal with soil solutions in which the difficult to oxidize humic and fulvic acids are the predominant carbon-containing components, we preferred to use thermal catalytic oxidation to convert DOC into CO<inf>2</inf>. We therefore coupled a high-temperature combustion TOC analyzer with an isotope ratio mass spectrometer, by trapping and focusing the CO<inf>2</inf> cryogenically between the instruments. The analytical performance was tested by measuring solutions of compounds varying in the ease with which they can be oxidized. Samples with DOC concentrations between 1 and 100mg C/L could be analyzed with good precision (standard deviation (SD) ≤0.6%), acceptable accuracy, good linearity (overall SD = 1%) and without significant memory effects. In a <sup>13</sup>C-tracer experiment, we observed that mixing plant residues with soil caused a release of plant-derived DOC, which was degraded or sorbed during incubation. Based on these results, we are confident that this approach can become a relatively simple alternative method for the measurement of the <sup>13</sup>C/<sup>12</sup>C ratio of DOC in soil solutions. © 2010 John Wiley & Sons, Ltd.",Entailment
i_1665,Contradiction,"Recommendations for Integrating Connectivity into CBI: Identify Key Habitat Patches: Use habitat suitability models and network analysis to identify key habitat patches that are assumed to contribute significantly to functional connectivity. While these patches are suggested for conservation, their actual impact on urban planning may be overstated .","Rapid urbanization results in changes in land use, biogeochemical cycles, climate, hydrosystems, and biodiversity. Policy-makers have formulated ecological protection measures to facilitate sustainable development. However, traditional conservation planning mainly focuses on protecting specific green spaces, with limited consideration of the connectivity among green spaces from a habitat network perspective. Using citizen science data and occupancy modelling, we predicted habitat suitability, built habitat networks and identified key habitat patches based on their contribution to the functional connectivity of the habitat network for three focal water, forest, and open-habitat bird species. Based on the habitat requirement, small waterbodies and intermediate forest and open-habitat cover facilitate preserving water, forest and open-habitat birds. In regards to the network analysis, we found that key habitat patches with a high conservation priority were generally characterized by a relatively large patch size and/or located at critical positions in the habitat network (at central positions in the habitat network, or near large patches). We suggest that key habitat patches in restricted built-up areas are converted to protected areas or are kept as cropland under future urban planning. We emphasize the usefulness of the focal species concept in urban biodiversity conservation. Our study offers conservation recommendations from a habitat network perspective for urban planners to safeguard urban biodiversity and ecosystem health.",Opposite meaning
s_465,Entailment,"Scientific Method: The iterative process of hypothesis formulation, testing, and modification refines the hypothesis space .","The general concept of the scientific method or procedure consists in systematic observation, experiment and measurement, and the formulation, testing and modification of hypotheses. In many cases a hypothesis is formulated in the form of a model, for example a mathematical or simulation model. The correctness of a solution of a problem produced by a model is verified by comparing it with collected data. Alternatively, observational data may be collected without a clear specification that the data could also apply to the solution of other, unforeseen problems. In such cases data analytics are used to extract relationships from and detect structures in data sets. In accordance with the scientific method, the results obtained can then be used to formulate one or more hypotheses and associated models as solutions for such problems. This approach allows for ensuring the validity of the solutions obtained. The results thus obtained may lead to a deeper insight in such problems and can represent significant progress in scientific research. The increased interest in so-called Big Data resulted in a growing tendency to consider the structures detected by analysing large data sets as solutions in their own right. A notion is thus developing that the scientific method is becoming obsolete. In this paper it is argued that data, hypotheses and models are essential to gain deeper insights into the nature of the problems considered and to ensure that plausible solutions were found. A further aspect to consider is that the processing of increasingly larger data sets result in an increased demand for HTC (High Throughput Computing) in contrast to HPC (High Performance Computing). The demand for HTC platforms will impact the future development of parallel computing platforms.",Entailment
s_1190,Unverifiable,"Key Mechanisms and Contributing Factors: Novel Therapeutic Targets: Anti-inflammatory Therapies: Given the central role of inflammation in CAD, therapies targeting inflammatory pathways are being explored. For instance, curcumin and vitamin D have shown potential in modulating inflammatory responses and reducing atherosclerosis .","Cardiovascular disease (CVD) is common cause of death in humans and its major underlying pathology is atherosclerosis. Atherosclerosis is a chronic inflammatory disease that predisposes to coronary artery disease (CAD), stroke and peripheral arterial disease, responsible for most of the cardiovascular morbidity and mortality. This inflammatory process, triggered by the presence of lipids in the vascular wall, and encompasses a complex interaction among inflammatory cells, vascular elements, and lipoproteins through the expression of several adhesion molecules and cytokines. Obesity is a risk factor for CVD but this association is not fully understood. Altered levels of obesity related peptides such as ghrelin may play an important role in this pathophysiology. Recent evidence indicates that ghrelin features several cardiovascular activities, including increased myocardial contractility, vasodilatation and protection from myocardial infarction. Recent data demonstrate that ghrelin can influence important key events in atherogenesis and thus they may play a role in atherosclerosis. In this review we present the latest data from recent animal and clinical studies which focus on a novel approach to ghrelin as a potential therapeutic agent in the treatment of a complex disease like atherosclerosis. Thus, ghrelin may become a new therapeutic target for the treatment of CVD. Further studies are necessary to investigate the potential mechanisms involved in the effects of ghrelin on the cardiovascular system. © 2012 by Nova Science Publishers, Inc. All rights reserved.
[11]: Objective - The role of vitamin D deficiency in coronary artery disease (CAD) progression is uncertain. Chronic inflammation in epicardial adipose tissue (EAT) has been implicated in the pathogenesis of CAD. However, the molecular mechanism underlying vitamin D deficiency-enhanced inflammation in the EAT of diseased coronary arteries remains unknown. We examined a mechanistic link between 1,25-dihydroxyvitamin D-mediated suppression of nuclear factor-κB (NF-κB) transporter, karyopherin α4 (KPNA4) expression and NF-κB activation in preadipocytes. Furthermore, we determined whether vitamin D deficiency accelerates CAD progression by increasing KPNA4 and nuclear NF-κB levels in EAT. Approach and Results - Nuclear protein levels were detected by immunofluorescence and Western blot. Exogenous KPNA4 was transported into cells by a transfection approach and constituted lentiviral vector. Swine were administered vitamin D-deficient or vitamin D-sufficient hypercholesterolemic diet. After 1 year, the histopathology of coronary arteries and nuclear protein expression of EAT were assessed. 1,25-dihydroxyvitamin D inhibited NF-κB activation and reduced KPNA4 levels through increased vitamin D receptor expression. Exogenous KPNA4 rescued 1,25-dihydroxyvitamin D-dependent suppression of NF-κB nuclear translocation and activation. Vitamin D deficiency caused extensive CAD progression and advanced atherosclerotic plaques, which are linked to increased KPNA4 and nuclear NF-κB levels in the EAT. Conclusions - 1,25-dihydroxyvitamin D attenuates NF-κB activation by targeting KPNA4. Vitamin D deficiency accelerates CAD progression at least, in part, through enhanced chronic inflammation of EAT by upregulation of KPNA4, which enhances NF-κB activation. These novel findings provide mechanistic evidence that vitamin D supplementation could be beneficial for the prevention and treatment of CAD.",Related but unverifiable
s_1424,Entailment,Methane Mitigation Strategies in Dairy Cows: Several studies have explored different dietary strategies to mitigate methane emissions in dairy cows: Oilseeds: Feeding dairy cows with extruded linseed and ground rapeseed reduced daily methane production by 7% and methane intensity by 15-17% without negatively impacting milk production .,"The addition of fatty feed components to a dairy cow ration can influence ruminal fermentation, and hence methane formation in the rumen. In a study with 33 Holstein / Red Holstein dairy cows, the influence of two different types of oilseeds (extruded linseed and ground rapeseed) versus a control (rumen-stable fat) was investigated over a period of 12 weeks in terms of its impact on feed intake, milk yield, ruminal fermentation and methane emission. The feed intake and milk produc­ tion of the individual animals was recorded daily. In addition, the milk constituents from an evening and morning milking of each animal were analysed on a weekly basis. Individual weekly methane release data were collected at two GreenFeed stations. In weeks 6, 9, 12 and 15 of the trial, ruminal fluid was sampled from 18 cows (six per treatment) using an esopha­ geal probe and analysed for volatile fatty acids, ammonia, and selected microorgan­ isms. Cows that were fed the extruded linseed consumed less feed and their milk had a lower fat content, although they produced more milk per day. Both types of oilseeds led to a 7% reduction in daily methane production in dairy cows, which was accompanied by a reduction in the rela­ tive incidence of methanogens in the rumen. Methane intensity (g/kg of energy corrected milk) was numerically reduced by 15 – 17% with both types of oilseeds. We conclude from the present study that a certain reduction in methane emissions can be achieved with oilseeds, but that the amount of reduction varies in terms of intensity according to the calculation basis used.",Entailment
i_63,Contradiction,"AI in Public Service Provision: Comparative Insights. Norway: Policy Analysis: Norwegian policy documents highlight AI's role in improving efficiency and service quality in public services . Challenges: There is a lack of emphasis on citizen engagement in policy-making, indicating a need for a more nuanced view of AI.","Artificial intelligence (AI) is said to be the next big phase in digitalization. There is a global ongoing race to develop, implement and make use of AI in both the private and public sector. The many responsibilities of governments in this race are complicated and cut across a number of areas. Therefore, it is important that the use of AI supports these diverse aspects of governmental commitments and values. The aim of this paper is to analyze how AI is portrayed in Swedish policy documents and what values are attributed to the use of AI. We analyze Swedish policy documents and map benefits, considerations and risks with AI into different value ideals, based on an established e-government value framework. We conclude that there is a discrepancy in the policy level discourse on the use of AI between different value ideals. Our findings show that AI is strongly associated with improving efficiency and service quality in line with previous e-government policy studies. Interestingly, few benefits are highlighted concerning engagement of citizens in policy making. A more nuanced view on AI is needed for creating realistic expectations on how this technology can benefit society.",Entity error
s_1242,Entailment,"Growth Factors: Hepatocyte growth factor (HGF) and basic fibroblast growth factor (bFGF) have been studied for their effects on vocal fold fibroblasts. HGF up-regulates endogenous HGF, transforming growth factor-β1 (TGF-β1), and hyaluronic acid synthase (HAS) mRNAs, which are crucial for ECM remodeling .","Objectives: We have previously demonstrated the therapeutic potential of hepatocyte growth factor (HGF) in the treatment of vocal fold scarring, although how exogenous HGF affects gene expression of endogenous HGF or extracellular matrix components in the vocal fold fibroblasts remains unclear. In this in vitro study, we aimed to clarify this aspect in order to better understand the effects of HGF on the vocal folds. Methods: Fibroblasts were obtained from the lamina propria of the vocal folds of 5 Sprague-Dawley rats and were cultured with HGF at concentrations of 100, 10, 1, and 0 ng/mL. The cells were collected on days 1, 3, and 7, and the expression of endogenous HGF, its receptor c-Met, transforming growth factor-β1 (TGF-β1), procollagen types I and III, and hyaluronic acid synthase (HAS)-1 and HAS-2 messenger RNAs (mRNAs) was examined by real-time reverse transcription-polymerase chain reaction. Results: The expression of endogenous HGF and HAS-1 mRNAs increased significantly when exogenous HGF was administered at a concentration of 1 ng/mL. On day 1, the expression of TGF-β1 and HAS-2 mRNAs increased significantly in response to 1 ng/mL HGF. Conclusions: Exogenous HGF triggered the up-regulation of endogenous HGF, TGF-β1, HAS-1, and HAS-2 mRNAs in vocal fold fibroblasts. © 2009 Annals Publishing Company. All rights reserved.",Entailment
s_1119,Entailment,"A decrease in muscle resistance during contraction is expected in healthy muscles, and deviations from this pattern may indicate the presence of adhesions .","Changes in skeletal muscle electrical resistance during muscle contraction may be associated to two main factors. Changes at muscle morphology e.g. length, volume or cross-sectional area; and changes in its impeditivity, related to changes of biochemical and physiological processes during muscle activity. However, the mechanisms by both morphological or metabolic parameters and, more importantly, if they increase or decrease electrical impedance parameters is yet controversial. The present study aimed to investigate the behavior of the muscular electrical resistance of the gastrocnemius muscle of Wistar rats during muscle contraction at different levels of force. To address that, tetrapolar invasive needle electrodes were placed in the animal muscle for impedance measurement, while two other needles electrodes were placed on muscle ends to electrical stimulate the muscle and evoke contraction. The experimental protocol consisted of ten pulse trains with 1 s duration with 40 s rest using randomized frequencies. All the procedures were approved by the Institutional Ethics Committee for Research with Animals under the decision number 019/15. Results show a decrease on muscle resistance during contraction. It was observed a correlation of r = −0.76 between the intensity of muscle contraction and resistance changes. Our findings suggest that resistance decrease is expected for invasive measurements in healthy muscles. Also, indicates that different changes at resistance amplitudes can be linked with metabolic processes. However, morphological influences cannot be neglected.",Entailment
s_696,Unverifiable,"Fabrication Methods: Screen Printing: This technique is used to print conductive polymers like graphene directly onto stretchable garments, ensuring good signal quality and durability .","Objective. Wearable devices have created new opportunities in healthcare and sport sciences by unobtrusively monitoring physiological signals. Textile polymer-based electrodes proved to be effective in detecting electrophysiological potentials but suffer mechanical fragility and low stretch resistance. The goal of this research is to develop and validate in dynamic conditions cost-effective and easily manufacturable electrodes characterized by adequate robustness and signal quality. Methods. We here propose an optimized screen printing technique for the fabrication of PEDOT:PSS-based textile electrodes directly into finished stretchable garments for surface electromyography (sEMG) applications. A sensorised stretchable leg sleeve was developed, targeting five muscles of interest in rehabilitation and sport science. An experimental validation was performed to assess the accuracy of signal detection during dynamic exercises, including sit-to-stand, leg extension, calf raise, walking, and cycling. Results. The electrodes can resist up to 500 stretch cycles. Tests on five subjects revealed excellent contact impedance, and cross-correlation between sEMG envelopes simultaneously detected from the leg muscles by the textile and Ag/AgCl electrodes was generally greater than 0.9, which proves that it is possible to obtain good quality signals with performance comparable with disposable electrodes. Conclusions. An effective technique to embed polymer-based electrodes in stretchable smart garments was presented, revealing good performance for dynamic sEMG detections. Significance. The achieved results pave the way to the integration of unobtrusive electrodes, obtained by screen printing of conductive polymers, into technical fabrics for rehabilitation and sport monitoring, and in general where the detection of sEMG in dynamic conditions is necessary.",Related but unverifiable
s_1267,Contradiction,"Medication Errors and Adverse Drug Events (ADEs): Reports of medication errors, such as using the same syringe for different drugs, suggest that these errors are common and often lead to serious patient harm, indicating an urgent need for better education and protocols to prevent such errors .","BACKGROUND AND OBJETIVES: Anesthesiologists became more concerned about ensuring patient safety by a greater emphasis on outcome, quality patient care both in operation theatre and elsewhere in hospital. In the clinical practice, there is no aspect of Anesthesia that occupies a more important place in the safe management of the patients than the accurate drug administration. Medication errors represent a small part of anesthesia problems but still have potential for serious morbidity and legal consequences. The objective of this report was to describe four cases of unusual medical errors (ME) in the operation theatre, without harm to the patient, and how their analysis and identification had prevented more serious damage occurrence. CASE REPORTS: Four cases of inadvertent overdose in operation theatre previous to induction anesthesia. The same syringe was used to prepare and dilute two different drugs. This error was therefore caused by the presence of the second drug. Toxicity was manifested as brief respiratory depression and sedation, and assisted ventilation was required but no adverse outcomes happened. CONCLUSIONS: We explain how we identified the drug involved, the point at which the error occurred in order to improve clinical practice reducing medication errors. We focus on providing more information and education to each health care professional about new drugs and their preparation process, because this is should not be an acceptable practice in 2009.",Misrepresentation
i_1771,Entailment,"The integration of advanced machine learning techniques in energy portfolio optimization could further enhance the alignment of GWP time horizons with climate policy goals, potentially leading to more effective strategies for mitigating climate change impacts .","Energy technologies emitting differing proportions of methane (CH<inf>4</inf>) and carbon dioxide (CO<inf>2</inf>) vary significantly in their relative climate impacts over time, due to the distinct atmospheric lifetimes and radiative efficiencies of the two gases. Standard technology comparisons using the global warming potential (GWP) with a fixed time horizon do not account for the timing of emissions in relation to climate policy goals. Here we develop a portfolio optimization model that incorporates changes in technology impacts based on the temporal proximity of emissions to a radiative forcing (RF) stabilization target. An optimal portfolio, maximizing allowed energy consumption while meeting the RF target, is obtained by year-wise minimization of the marginal RF impact in an intended stabilization year. The optimal portfolio calls for using certain higher-CH<inf>4</inf>-emitting technologies prior to an optimal switching year, followed by CH<inf>4</inf>-light technologies as the stabilization year approaches. We apply the model to evaluate transportation technology pairs and find that accounting for dynamic emissions impacts, in place of using the static GWP, can result in CH<inf>4</inf> mitigation timelines and technology transitions that allow for significantly greater energy consumption while meeting a climate policy target. The results can inform the forward-looking evaluation of energy technologies by engineers, private investors, and policy makers.",Entailment
i_639,Contradiction,"3. Impact on Project Management: Reduction of Disputes: The use of digitization applications in damage assessment surveys, as seen in the reconstruction efforts in Haiti, has shown to reduce disputes and legal issues by providing clear and accurate data .","Disputes are prevalent on construction projects. This issue is severe in underdeveloped countries like Nepal. In the year 2015, a magnitude 7.8 earthquake killed over 8,000 people and destroyed thousands of buildings there. For reconstruction of the damaged buildings, a detailed damage assessment survey was conducted, in which data was collected using a digitization application; this was the first time this technology was used in Nepal. In this study, the reconstruction engineers were asked regarding their experience of the novel application. The data analysis shows that, along with other benefits, using the digitization application reduced disputes and legal issues in the reconstruction phase. Based on severity of damage, 31 affected districts were categorized into two groups, Group A and Group B. The t-test results showed that the damage in Group A districts was significantly higher than in the Group B districts. Furthermore, this study collected lessons learned related to the damage assessment survey using the digitization application and reconstruction works.",Entity error
s_150,Unverifiable,"AI algorithms can also help in summarizing and presenting the results of each round to the experts, facilitating quicker and more informed feedback .","The Delphi method enables to recruit the help of subject matter experts and provides a framework for decision making by consensus. The Delphi method was initially used to forecast scientific, technology, and political outcomes during the Cold War era through structured and iterative polling of anonymous subject matter experts. The approach allows for open contribution without concerns of ridicule or reprisal and therefore accommodates a range of independent views. Proper implementation of the Delphi method requires selecting a panel of appropriate subject matter experts, limiting the scope of subject matter expert review, properly planning the survey tool, reducing findings into an objective report, and allowing enough time for multiple iterations of the approach. To use the Delphi method, the project manager defines the problem, identifies a panel of subject matter experts that can help solve the problem, and develops a survey tool to collect their independent feedback. The selection of panelists is critical to the success of a Delphi study.",Unrelated and unverifiable
s_1224,Entailment,"Typical pH Range: The pH of gastric acid generally ranges from 1.5 to 3.5. For instance, in a study involving simulated gastric fluid, the pH ranged from 1.5 to 2.5 .","The aim of this work was to develop a standard quantitative method to measure the acid tolerance of probiotic cells when exposed to a simulated gastric fluid. Three model strains of different cell concentrations were exposed to a standard simulated gastric fluid of fixed volume. The fluid pH ranged from pH1.5 to 2.5. In general, the death kinetics followed an exponential trend. The overall death constant, k <inf>d</inf>, for all strains was found to be in a power relationship with the pH value and the initial cell concentration, and it can be expressed as k<inf>d</inf>= k<inf>AII</inf>( pH <sup>-9.0</sup>N <inf>0</inf><sup>-0.19</sup> where k <inf>AII</inf> is defined as the acid intolerance indicator and N <inf>0</inf> is the initial cell concentration (CFU/ml). This equation was validated with the experimental data with an average R <sup>2</sup> of 0.98. The acid intolerance of cells can be quantitatively expressed by the k <inf>AII</inf> values, where higher value indicates higher intolerance. In conclusion, a standard quantitative method has been developed to measure the acid tolerance of probiotic cells. This could facilitate the selection of probiotic strains and processing technologies. © 2009 Springer-Verlag.",Entailment
i_1942,Entailment,"This includes establishing ethical standards, improving safety protocols, and promoting global governance to mitigate ethical issues, while also fostering public awareness and education about the ethical implications of AI and robotics .","Although artificial intelligence (AI), especially robotics technology, has gained rapid growth and been applied in many areas, bringing numerous positive outcomes, it has also resulted in many ethical concerns, most notably in the development of AI and robot interaction technology. To better realize the "" benign interaction between man and machine"" and open a new era of intelligence in which man and machine coexist harmoniously, it is necessary to coordinate efforts in strengthening legislative research, formulating ethical standards, improving safety standards, establishing a regulatory system, and promoting global governance in order to effectively prevent and respond to the multiple ethical issues caused by robots in the process of design, R&D, production, and use.",Entailment
s_487,Unverifiable,"Agile Methodology: Advantages: Improved Team Morale: Agile practices often result in higher team morale due to their iterative nature and focus on collaboration, and they may also foster a more innovative work environment that encourages creative problem-solving among team members .","Agile processes have been introduced to avoid the problems most of software practitioners have run up against by using traditional software development methodologies. These are well known for their benefits like focus on quality, early business value delivery, higher morale of stakeholders, and the reduced cost/schedule. Also, they can support the earlier and quicker production of the code by dividing the product into small segments called iterations. However, there are on-going debates about their flexibility to accommodate changing requirements and whether the productivity and quality of the agile processes is satisfactory for the customers or not. Previously available studies have mostly focused on comparing XP(eXtreme Programming) with some other Agile methodologies, rather than comparing it with traditional plan-driven software development methodologies. In this Paper, we identify the XP phases and practices, how they ensure product quality, and map XP phases against the Spiral model phases to prove that XP has built-in QA (Quality Assurance) practices in its life cycle, in addition to its focus on productivity. A case study is also included to empirically investigate quality of the product developed using XP with comparison to the product developed using Spiral Model. © 2007 IEEE.",Related but unverifiable
i_1559,Contradiction,"Progress in Demonstration Projects: The United States has created funding mechanisms to support CCS demonstration projects, but progress has been slow. Only a fraction of the proposed projects are likely to be completed without strong political support and strategic planning .","Carbon capture and storage (CCS) on electricity generation and energy intensive industry is expected to play a considerable role in achieving the European Union's decarbonisation goals. EU CCS demonstration project funding has been created to encourage development and accelerate commercial CCS deployment by providing funds to bridge the capital gap for early commercial-scale CCS installation. Eleven CCS project proposals currently remain at least nominally active, but reduced funding and other constraints suggest at best delivery of around a third of these. To explore how these demonstrations impact on the scale of subsequent CCS deployment in the EU three simple scenarios for post-demonstration CCS activity and deployment (none, limited and considerable) are considered and examined in the context of key factors that have influenced the demonstration programme. Without strong political support for post-demonstration deployment including measures such as strategic storage validation and CO<inf>2</inf> pipeline planning, and a clear process to make CCS commercially attractive to investors on a timeline consistent with climate ambitions, even a positive result from the demonstration programme is unlikely to enable CCS to deliver as expected. © 2012 Elsevier Ltd.",Entity error
s_1691,Contradiction,"Specific regions, such as the Eastern Ghats in India and the Similipal Biosphere Reserve, lack significant medicinal plant diversity .","A number of wild crops remain unexplored in this world and among them some have excellent medicinal and nutritional properties. India is a harbor of biodiversity in general and phytodiversity in particular. The plant diversity is distributed from the Western Ghats to Eastern Ghats, along with the North-Eastern region and from the Greater Himalayas to the plain of Ganga. Among these distributed floral regions of the country, the Eastern Ghats are important due to their rich floral diversity. The forests of Odisha form a major part of Eastern Ghats in general and the Similipal Biosphere Reserve (SBR) in particular. The SBR is inhabited by many local communities. The food and medicinal habits of these communities are not fully explored even today. They are dependent on the forests of SBR for their food and medicine. Among their collections from forests, root and tuberous plants play a significant role. The local communities of SBR use about 89 types of tuberous plants for various purposes. Dioscorea is one such tuber, having maximum use among the local of SBR. However, less documentation and no specific reports are available on the food and medicinal values of the species available in this part of the World. Dioscorea species, popularly known as Yam worldwide and as Ban Aalu in Odisha, India, is a prime staple medicinal-food substitute for the majority of rural and local people of the state of India. Of the 13 Dioscorea species available in SBR, 10 species are known to be bitter in taste and unpalatable when taken raw. Since less documentation is available on the Dioscorea species of SBR and their traditional uses, the present study was focused on the ethnobotany, nutritional and pharmacological values of these species along its nutraceutical importance.",Opposite meaning
s_1552,Entailment,"Cultivar-Specific Responses: Specific cultivars have been identified with varying bolting times. For example, in high tunnels, romaine lettuce 'Jhih Li Wo' and Batavia lettuce 'Fu San' showed higher growth rates and bolting times compared to other varieties . This indicates that certain cultivars are more adaptable to specific growing conditions, affecting their bolting time.","The production of lettuce, a cool-season leafy vegetable, in high tunnels the year around is a challenge for growers in subtropical regions. The aims of this research were to characterize the growth of locally grown lettuce cultivars, develop a new high-yielding cultivar by crossing romaine-type lettuce 'Jhih Li Wo' and Batavia type lettuce 'Fu San', and determine the relationships between climatic variables, temperature, and day length, and days to harvest for maximum marketable yield (DMMY) in individual cultivars in high tunnels. Nine cultivars were grown in high tunnels in the spring and winter of 2008 and summer of 2009 to evaluate growth and maximum marketable yield (MMY), the latter being defined as the aboveground fresh weight of 5 ± 0.7 cm of plant stem. Romaine lettuce 'Jhih Li Wo' had a higher growth rate during the initiation of plant growth in the spring of 2008. 'Jhih Li Wo' and Batavia lettuce 'Fu San' also showed higher growth rate before harvest for the MMY (GRBHD) and exhibited higher MMY and DMMY than butterhead lettuce and leaf lettuce cultivars under summer and winter regimes. However, landraces of leaf lettuce are the main lettuces grown in high tunnels in summer rather than 'Fu San' and 'Jhih LiWo' due to their needing fewer DMMY and having amore upright growth form. Among nine cultivars studied, Batavia lettuce 'Fu San', romaine lettuce 'Jhih Li Wo', and landrace 'Bai Yeh Wo' were found to be more adaptable to summer weather. Genotypes with superior growth and yield traits are essential for not only production but also breeding. A new cultivar, Taoyuan No.3, was developed by introducing the high growth rate trait during the initial period of plant growth from romaine lettuce 'Jhih Li Wo' into high-yielding Batavia lettuce 'Fu San'. Another experiment was performed over eight successive seasons to analyze the correlation of temperature and day length on DMMY for each cultivar using multiple regression analysis from 2008 to 2009. This showed that the proposed models expressed as coefficients of multiple determinants (R<sup>2</sup>) accounted for 72%to 91% of the total variation in DMMY in each cultivar. Temperature affected DMMY the most and the relative contributions of temperature and day length to DMMY differed with cultivar. These results provide information about production practices for growers in subtropical regions to use in choosing suitable lettuce cultivars.",Entailment
s_1745,Entailment,"Inbred Cultivars: WJ15 and YD6 exhibited no significant yield loss or changes in spikelet number per panicle under ozone exposure, suggesting that all inbred cultivars are immune to the effects of ozone .","Ozone is currently the most important air pollutant that negatively affects growth and yield of agricultural crops in most parts of the world, and rice is arguably the most important food crops on the planet. While a limited number of enclosure-based studies have examined the genotypic differences among rice (Oryza sativa L.) cultivars in response to increasing ozone concentration, no ozone experiment has been conducted to date under fully open-air field conditions to address this issue. In 2007, we conducted an experiment for the first time in the world with rice using free-air concentration enrichment (FACE) system at Xiaoji town, Jiangdu County, Jiangsu Province, China (119° 42′0″E, 32° 35′5″N). Four Chinese rice cultivars: Wujing 15 (WJ15, inbred japonica cultivar), Yangdao 6 (YD6, inbred indica cultivar), Shanyou 63 (SY63, three-line hybrid rice cultivar), Liangyoupeijiu (LYPJ, two-line hybrid rice cultivar), were grown at ambient or elevated (target at 50% above ambient) ozone concentration under nitrogen application rate of 15 g N m<sup>-2</sup>. The ozone enhancement strongly accelerated phenologycal development of WJ15 and SY63, with maturity being reached by 4 and 8 days earlier, respectively, but only 1 day earlier for YD6 and LYPJ. Elevated ozone concentration reduced the number of mainstem leaves (ca. by half a leaf) and plant height at maturity (ca. by 3-5 cm) of SY63 and LYPJ with no ozone effects detected in YD6 or WJ15. Among the cultivars tested, SY63 and LYPJ exhibited significant yield loss by exposure to ozone (-17.5%, -15%, respectively), while WJ15 and YD6 showed no responses. For all cultivars, no ozone effect was observed on panicle number per unit area as a result of no changes in both maximum tiller number or productive tiller ratio. However, the number of spikelets per panicle of SY63 and LYPJ showed a significant reduction due to ozone exposure, while those of WJ15 and YD6 remained unaffected. Meanwhile, ozone exposure also caused minor reductions in both filled spikelet percentage and individual grain mass. The results of this experiment indicated that yield loss due to ozone exposure differs among rice cultivars with hybrid cultivars (i.e., SY63 and LYPJ) exhibiting greater yield loss than inbred cultivars (i.e., WJ15 and YD6), which could be attributed to the suppression of spikelet formation in the hybrid cultivars under ozone stress. © 2009 Elsevier B.V. All rights reserved.",Entailment
i_2254,Entailment,"-  ** Herbicide Alternatives: **  In Indonesia, the shift to alternative herbicides like MSMA+diuron is a response to resistance problems, whereas in Malaysia, the focus is on reducing herbicide use through sustainable practices  .","Sustainable weed management in oil palm plantation has been a challenge now a day. Weed suppression by cover cropping is considered as a viable alternative to herbicidal control. This study0020was, therefore, conducted during 2010-2012 in a Malaysia oil palm plantation to characterize oil palm weed communities and evaluate oil palm yield under four different perennial cover-crop systems. Experimental treatments included four different cover crop combinations such as Axonopus compressus, Calopogonium caeruleum + Centrosema pubescens, Mucuna bracteata, Pueraria javanica + Centrosema pubescens, and herbicidal control by glufosinate-ammonium and weedy control. Weed composition in the un-weeded treatment was different from that of cover crop treatments. The un-weeded treatment favored Paspalum conjugatum and A. compressus as the dominant species. In the A. compressus and C. caeruleum + C. pubescens treatments the associated weed species with highest dominance was Asystasia gangetica, while the weeds A. compressus and A. gangetica were associated with M. bracteata and P. javanica + C. pubescens treatments. In the weeded treatment receiving 6 sprays of glufosinateammonium over the two years, B. latifolia was dominant. The A. compressus cover treatment had the lowest species richness and diversity. Weeded plots had lowest yield, bunch number tree<sup>-1</sup> and bunch weight during the 18-24 MAP. The study confirms variation in weed community in oil palm plantation under different cover-crop systems and thus, contributes to improving current understanding of weed community structures and may help formulate sustainable weed management strategy for oil palm plantation. © 2014 Friends Science Publishers.
[2]: The glyphosate-resistant Eleusine indica (GR-ESU) case has dominated at oil palm plantations in North Sumatra Province, Indonesia and will increase evolution into resistance. This research was aimed to determine the role of Monosodium Methyl Arsenate (MSMA)+diuron to control the agronomic characteristics of GR-ESU biotypes. This research was conducted in the Weed Research Center Land, Faculty of Agriculture, Universitas Sumatera Utara in November 2017 until August 2018. This research used Randomized Block Design non-factorial with factor GR-ESU biotypes that were sprayed with glyphosate at the dose of 3 l.ha<sup>-1</sup>, and MSMA+diuron at the dose of 5 l.ha<sup>-1</sup> within four replications. The parameters were analyzed using one-way ANOVA and were continued by DMRT at P < 0.05 with IBM SPSS Statistics v.20 software. The results showed that a decrease in the survival of GR-ESU at the changes from glyphosate to MSMA+diuron. The GR-ESU on MSMA+diuron showed leaf color changes (leaf green loss/chlorosis) at 3 until 21 days after sprayed. The ability of MSMA+diuron had com-pletely (100%) controlled within 18 of 29 GR-ESU biotypes and had effectively controlled the tillers, flowering, fresh-and dry weight in GR-ESU biotypes of 87.53%; 66.88%; 95.66%; and 95.92% respectively compared to glyphosate. The use of MSMA+diuron as a different mode of action herbicide is highly recommended to control GR-ESU biotypes at oil palm estate.",Entailment
s_1560,Unverifiable,"Additional Information: Anthocyanin Composition: Purple flowers of Iris lutescens are dominated by delphinin and its aliphatic derivatives, with smaller amounts of delphinidin 3-O-(p-caffeoylrutinoside)-5-O-glucoside and its derivatives .","[4] Cross-reactivity has important consequences in some immune disorders, including allergic and autoimmune diseases, which can affect both diagnostic and therapeutic approaches. One of the most common cross-reactivity syndromes is pollen-food syndrome (PFS). The patient is sensitized with pollen by the airways and exhibits an allergic reaction to food antigen with a structural similarity to the pollen. PFS usually presents with pruritus and swelling of the mouth and throat during or just after ingestion of fresh, uncooked fruits and vegetables. Latex fruit syndrome is another cross-reactivity syndrome. It is the association of latex allergy and allergy to plant foods, which affects up to 50% of latex-allergic patients. Here, we present two cases with crossreactivity syndrome.  [9] Background: The order Fagales represents an important cause of tree-pollen allergy in northern countries. We investigated the IgE recognition profiles, mutual relationships, and association with clinical symptoms of a panel of allergens belonging to the PR-10 family, the main proteins responsible for Fagales allergy (Act d 8, Aln g 1, Api g 1, Ara h 8, Bet v 1, Cor a 1.0101, Cor a 1.0401, Gly m 4, Mal d 1, and Pru p 1). Methods: A total of 526 PR-10-reactive subjects living in central and southern Italy were studied by ImmunoCAP-ISAC-112 microarray analysis. Results: Overall, Bet v 1 reactivity was the most commonly (74%) observed among PR-10 proteins, but Cor a 1.0101 was the most prevalent in participants aged <6 years, and between 15 and 65 years. Overall, 26% of the PR-10-reactive persons were Bet v 1 negative, whilst 93.6% of the PR-10 polyreactive individuals were Bet v 1 positive. Among the 10 PR-10s evaluated, 100 combinations were recorded. The strongest association was observed between molecules with the highest sequence identities (Bet v 1 and Cor a 1.0101, Cor a 1.0401 or Aln g 1; Mal d 1 and Pru p 1). Bet v 1-, Cor a 1.0101-, and Aln g 1-specific IgE recognition was associated with respiratory symptoms, whilst Ara h 8, Cor a 1.0401, Gly m 4, Mal d 1, and Pru p 1 were selectively linked to an oral allergic syndrome. Conclusions: Testing IgE reactivity to a panel of PR-10s in a birch-free area discloses peculiar relationships between clinical phenotypes and sensitization profiles, allowing the identification of novel cluster patterns.",Unrelated and unverifiable
s_1607,Entailment,Cultural Control: Using cover crops and mulching can suppress weed growth by providing ground cover and reducing light availability to weeds. Straw mulch has been shown to improve soil properties and reduce erosion .,"[15] The sustainability of agriculture relies on the development of strategies that lower the need for costly external inputs and minimize detrimental effects on the environment, which often involve either inappropriate or excessive use of agrochemical inputs. One strategy, integrating plant allelopathy into sustainable agriculture, is discussed in this paper. Agriculture integrated with allelopathy could reduce the heavy dependence on synthetic herbicides and other agrochemicals, and therefore ease problems such as environmental contamination, use of unsafe agricultural products and effects on human health. The allelopathy-integrated management of weeds includes various techniques such as the use of allelopathy in crop rotation, preceding and cover crops, green manure, mulch, and intercropping, as well as the incorporation of allelopathic plants in soil. In addition, the enhancement of weed-suppressing ability in crops is an important task in sustainable agricultural production. Even though many secondary metabolites involved in allelopathic activities have been isolated and identified, numerous allelochemicals remain unknown. The search for allelochemicals with novel modes of action is important for the development of bioactive pesticides. Despite the fact that the direct use of allelochemicals as natural pesticides is difficult in the field because of their easy degradation in nature and high cost of delivery, the synthesis of compounds derived from these allelochemicals may help resolve these problems. © CABI Publishing 2007.",Entailment
s_392,Contradiction,"Social Networking and Mobile Social Networks (MSNs): Common Friend Discovery: In scenarios where users want to identify mutual friends, private matching protocols can be employed to ensure that only the information about common friends is disclosed, which may inadvertently lead to the exposure of other friend relationships due to the complexity of user interactions .","Social networking sites have emerged as a powerful tool for maintaining contact and sharing information between people, allowing users to quickly and easily communicate and interact over the Internet. However, such services have raised serious privacy concerns, especially in terms of ensuring the security of users' personal information in the process of data exchange while also allowing for effective and complete data matching. Many studies have examined privacy matching issues and proposed solutions which could be applied to the current private matching issue. However, these solutions are almost entirely based on dual-matching designs. Therefore, this paper proposes a tripartite privacy matching protocol between common friends. In contexts with multiple users, this protocol searches for matching problems for common friends to produce a new solution. This approach does not rely on a trusted third party, and can be used on most mobile devices. In addition to providing outstanding operating performance and effective communication, this approach also accounts for context-specific privacy preservation, mutual authentication, mutual friendship certification, prevention of privacy spoofing and replay attack resistance, allowing users to safely and effectively identify mutual friends. The proposed methods are shown to be secure and efficient, and are implemented in mobile phones that allow users to find common friends securely in seconds. To the best of our knowledge, this is the first work done on mobile common friends discovery for three parties with advanced privacy preservation.
[5]: In this paper, we propose a common friend discovery algorithm considering the privacy of users and the authenticity of friend relationships. The privacy means users' other friends' information does not be leaked except their common friends. The authenticity signifies anyone can not successfully claim he is a friend of someone unless he really is. It has many applications such as playing games by friends, finding talking-topics by strangers, finding introducer of job interview, finding matchmaker of someone you desire to know, etc. We consider its security and matching probability. We also implement the algorithm in two mobile phones to prove that it is workable. © 2009 IEEE.",Opposite meaning
i_222,Unverifiable,"3. Formal Description Techniques: UML Notation: Using formal description techniques like UML (Unified Modeling Language) can help model interaction techniques and dialogues in VR applications. This method ensures usability, reliability, and efficiency by providing clear and unambiguous descriptions of interaction techniques . Such formalization can help in systematically applying easy language principles by making the design process more structured and predictable.","Nowadays, designers of Virtual Reality (VR) applications are faced with the choice of a large number of different input and output devices leading to a growing number of interaction techniques. Usually VR interaction techniques are described informally, based on the actions users can perform within the VR environment. At implementation time, such informal descriptions (made at design time) yield to ambiguous interpretations by the developers. In addition, informal descriptions make it difficult to foresee the impact throughout the application of a modification of the interaction techniques. This paper discusses the advantages of using a formal description technique (called ICO) to model interaction techniques and dialogues for VR applications. This notation is presented via a case study featuring an immersive VR application. The case study is then used to show, through analysis of models, how the formal notation can help to ensure the usability, reliability and efficiency of virtual reality systems. © IFIP International Federation for Information Processing 2005.",Related but unverifiable
s_1128,Contradiction,"Key Functions: Dormancy Induction: Collagen I can maintain cancer cells in a dormant state through interactions with integrins, particularly β1-integrin. This interaction activates signaling pathways such as SRC and focal adhesion kinase (FAK), which are crucial for maintaining dormancy .","Breast cancer that recurs as metastatic disease many years after primary tumor resection and adjuvant therapy seems to arise from tumor cells that disseminated early in the course of disease but did not develop into clinically apparent lesions. These long-term surviving, disseminated tumor cells maintain a state of dormancy, but may be triggered to proliferate through largely unknown factors. We now show that the induction of fibrosis, associated with deposition of type I collagen (Col-I) in the in vivo metastatic microenvironment, induces dormant D2.0R cells to form proliferative metastatic lesions through β1-integrin signaling. In vitro studies using a three-dimensional culture system modeling dormancy showed that Col-I induces quiescent D2.0R cells to proliferate through β1-integrin activation of SRC and focal adhesion kinase, leading to extracellular signal-regulated kinase (ERK)-dependent myosin light chain phosphorylation by myosin light chain kinase and actin stress fiber formation. Blocking β1-integrin, Src, ERK, or myosin light chain kinase by short hairpin RNA or pharmacologic approaches inhibited Col-I-induced activation of this signaling cascade, cytoskeletal reorganization, and proliferation. These findings show that fibrosis with Col-I enrichment at the metastatic site may be a critical determinant of cytoskeletal reorganization in dormant tumor cells, leading to their transition from dormancy to metastatic growth. Thus, inhibiting Col-I production, its interaction with β1-integrin, and downstream signaling of β1-integrin may be important strategies for preventing or treating recurrent metastatic disease. ©2010 AACR.",Opposite meaning
s_1705,Entailment,"Application: While the study suggests some potential for predicting pesticide residue levels in strawberries, it may not be reliable enough for practical use, raising questions about its overall versatility .","BACKGROUND: In this study, an infrared-based prediction method was developed for easy, fast and non-destructive detection of pesticide residue levels measured by reference analysis in strawberry (Fragaria × ananassa Duch, cv. Albion) samples using near-infrared spectroscopy and demonstrating its potential alternative or complementary use instead of traditional pesticide determination methods. Strawberries of Albion variety, which were supplied directly from greenhouses, were used as the study material. A total of 60 batch sample groups, each consisting of eight strawberries, was formed, and each group was treated with a commercial pesticide at different concentrations (26.7% boscalid + 6.7% pyraclostrobin) and varying residual levels were obtained in strawberry batches. The strawberry samples with pesticide residuals were used both to collect near-infrared spectra and to determine reference pesticide levels, applying QuEChERS (quick, easy, cheap, rugged, safe) extraction, followed by liquid chromatographic–mass spectrometric analysis. RESULTS AND CONCLUSION: Partial least squares regression (PLSR) models were developed for boscalid and pyraclostrobin active substances. During model development, the samples were randomly divided into two groups as calibration (n = 48) and validation (n = 12) sets. A calibration model was developed for each active substance, and then the models were validated using cross-validation and external sets. Performance evaluation of the PLSR models was evaluated based on the residual predictive deviation (RPD) of each model. An RPD of 2.28 was obtained for boscalid, while it was 2.31 for pyraclostrobin. These results indicate that the developed models have reasonable predictive power. © 2019 Society of Chemical Industry.",Entailment
s_576,Unverifiable,"Energy Savings and Sustainability: New designs in extrusion equipment, such as hydraulic hot pressing machines for producing refuse-derived fuel (RDF), incorporate energy-saving features like electrical heaters and efficient compression systems, leading to higher productivity and lower energy usage .","The manufacturing of RDF (Refuse Derived Fuel) from a conventional cold press extrusion machine is not suitable for producing RDF from reclaimed landfill since it is not identical in shape and form after production due to the swelling of the plastic fraction contained inside the reclaimed landfill and hence needs a very high compression force. Moreover, a binder agent is needed in order to keep the RDF in a similar shape and form. A novel design and manufacturing technology for a hydraulic hot pressing machine has been established and can produce high-quality RDF without any binder. The two electrical heaters are installed at the inner core and on the surface of the mold. The compression force on the mold is performed by a hydraulic jack. In addition, a newly-designed locking plate system which is designed by a slider to open and close along the paired horizontal slots, can reduce the cycle time of the manufacturing process and yield higher productivity. The testing properties of the RDF produced by the novel hydraulic hot pressing machine include the examination of size, shape, weight, unit density, bulk density, compression strength, moisture content, and heating value. The results showed that the RDF is suitable to be used as feedstock in an incinerator or gasifier to produce green and clean energy from reclaimed landfill.",Related but unverifiable
s_1094,Entailment,"Benefits of ResUNet Model: Integration with Multi-Modal Data: ResUNet can be integrated with multi-modal data, enhancing its segmentation precision and practical utility. This is particularly beneficial in medical imaging where multiple imaging modalities are often used .","Brain tumor segmentation is a critical step in MRI analysis, significantly impacting treatment decisions and prognostic evaluations. Deep learning, particularly with models like UNet and ResUNet, has emerged as a powerful approach, offering superior segmentation accuracy. The UNet model achieves a Dice score of 0.7 and a Jaccard index of 0.6, while the ResUNet model achieves a Dice score of 0.614444 and a Jaccard index of 0.815555. Despite advancements, challenges such as tumor variability, noise, and intensity variations persist, limiting the technology's potential. This study presents recent advancements in deep learning for brain tumor segmentation, covering background, methods (including UNet and ResUNet), achieved results, and concluding remarks. We discuss strengths, limitations, and ongoing research efforts, including multi-modal data integration and advanced network architectures, aiming to enhance segmentation precision and practical utility.",Entailment
i_1465,Contradiction,Medicaid Challenges: Integrating Comparative Effectiveness Research (CER) into Medicaid's decision-making process faces challenges such as statutory ambiguities and insufficient resources .,"Comparative effectiveness research (CER) is rapidly adding to the amount of data available to health care coverage and payment decision makers. Medicare's decisions have a large effect on coverage and reimbursement policies throughout the health insurance industry and will likely influence the entire U.S. health care system; thus, examining its role in integrating CER into policy is crucial. To describe the potential benefits of CER to support payment and coverage decisions in the Medicare program, limitations on its use,the role of the Centers for Medicare & Medicaid Services (CMS) in improving the infrastructure for CER, and to discuss challenges that must be addressed to integrate CER into CMS's decision-making process. A defining feature of CER is that it provides the type of evidence that will help decision makers, such as patients, clinicians, and payers,make more informed treatment and policy decisions. Because CMS is responsible for more than 47 million elderly and disabled beneficiaries, the way that Medicare uses CER has the potential to have a large impact on public and individual health. Currently many critical payment and coverage decisions within the Medicare program are made on the basis of poor quality evidence, and CER has the potential to greatly improve the quality of decision making. Despite common misconceptions, CMS is not prohibited by law from using CER apart from some reasonable limitations. CMS is,however, required to support the development of the CER infrastructure by making their data more readily available to researchers. While CER has substantial potential to improve the quality of the agency's policy decisions,challenges remain to integrate CER into Medicare's processes. These challenges include statutory ambiguities, lack of sufficient staff and internal resources to take advantage of CER, and the lack of an active voice in setting priorities for CER and study design. Although challenges exist, CER has the potential to greatly enhance CMS's ability to make decisions regarding coverage and payment that will benefit both the agency and their patient population.",Entity error
i_1719,Unverifiable,5. Noise and Air Quality: Poor pavement conditions can lead to increased noise levels and deteriorate air quality due to the higher emissions from vehicles operating under suboptimal conditions .,"Both the design and the construction of airfield pavements have to be consistent with strict requirements and constraints and also higher safety standards due to their particular setting. In addition, maintenance and construction times must be minimized in order to avoid delays and limitations on airport capacity. Maintaining or constructing airfield pavements also entails working during all-weather conditions (e.g. winter time and heavy cold conditions); materials adopted therefore play a major role in the success of the maintenance or construction activity. Environmental management plans and eco-friendly policies and strategies are increasingly being adopted by airport directors. Noise reduction plans through improved air traffic management techniques, emissions control for aircraft engines and ground maneuvering vehicles, reuse of water for washing airfield pavements, use of renewable energies, and use of photocatalytic materials are only some of the numerous ways of achieving a sustainable airport. The paper focuses on construction techniques and the development of innovative materials for the achievement of environmental sustainability on airfield pavements. In particular, the authors present how a long lasting and well performing airport pavement can be built if more than 85% of the materials used are recycled materials. The environmental analysis of a case study on a major Italian airport shows that the release of almost 35% of emissions could be avoided if recycling practices are taken into account. Furthermore, pavement performance is analyzed and monitored as well in order to show that recycling does not necessarily result in lower performance. Outcomes clearly suggest that the recycled airport pavement has a comparable performance and less of an environmental impact on standard airfield pavements. Moreover, results can be implemented into an Airport Pavement Management System to assess the best strategy, considering the environmental footprint in addition to the traditional performance analysis and cost effectiveness. © 2012 Elsevier B.V. All rights reserved.",Related but unverifiable
i_2251,Unverifiable,"-  ** Weed Management Practices: **  The reliance on herbicides is more pronounced in Indonesia, especially among smallholder farmers who may not have access to or knowledge of alternative weed management strategies.  This has led to the evolution of herbicide-resistant weed species, necessitating the use of different modes of action in herbicides  .","The glyphosate-resistant Eleusine indica (GR-ESU) case has dominated at oil palm plantations in North Sumatra Province, Indonesia and will increase evolution into resistance. This research was aimed to determine the role of Monosodium Methyl Arsenate (MSMA)+diuron to control the agronomic characteristics of GR-ESU biotypes. This research was conducted in the Weed Research Center Land, Faculty of Agriculture, Universitas Sumatera Utara in November 2017 until August 2018. This research used Randomized Block Design non-factorial with factor GR-ESU biotypes that were sprayed with glyphosate at the dose of 3 l.ha<sup>-1</sup>, and MSMA+diuron at the dose of 5 l.ha<sup>-1</sup> within four replications. The parameters were analyzed using one-way ANOVA and were continued by DMRT at P < 0.05 with IBM SPSS Statistics v.20 software. The results showed that a decrease in the survival of GR-ESU at the changes from glyphosate to MSMA+diuron. The GR-ESU on MSMA+diuron showed leaf color changes (leaf green loss/chlorosis) at 3 until 21 days after sprayed. The ability of MSMA+diuron had com-pletely (100%) controlled within 18 of 29 GR-ESU biotypes and had effectively controlled the tillers, flowering, fresh-and dry weight in GR-ESU biotypes of 87.53%; 66.88%; 95.66%; and 95.92% respectively compared to glyphosate. The use of MSMA+diuron as a different mode of action herbicide is highly recommended to control GR-ESU biotypes at oil palm estate.",Unrelated and unverifiable
i_1787,Entailment,Practical Applications and Case Studies: Water Management Indicators: The use of indicators to evaluate and monitor water management practices guarantees significant progress towards sustainability .,"The scientific community strongly recommends the adoption of indicators for the evaluation and monitoring of progress towards sustainable development. Furthermore, international organizations consider that indicators are powerful decision-making tools. Nevertheless, the quality and reliability of the indicators depends on the application of adequate and appropriate criteria to assess them. The general objective of this study was to evaluate how indicators related to water use and management perform against a set of sustainability criteria. Our research identified 170 indicators related to water use and management. These indicators were assessed by an international panel of experts that evaluated whether they fulfil the four sustainability criteria: social, economic, environmental, and institutional. We employed an evaluation matrix that classified all indicators according to the DPSIR (Driving Forces, Pressures, States, Impacts and Responses) framework. A pilot study served to test and approve the research methodology before carrying out the full implementation. The findings of the study show that 24 indicators comply with the majority of the sustainability criteria; 59 indicators are bi-dimensional (meaning that they comply with two sustainability criteria); 86 are one-dimensional indicators (fulfilling just one of the four sustainability criteria) and one indicator do not fulfil any of the sustainability criteria.",Entailment
i_712,Unverifiable,Optimization Methods: Actuator/Sensor Placement Optimization: A method involving genetic algorithms and dual methods to optimize the placement of actuators and sensors in piezoelectric truss structures has been proposed. This approach reduces the number of structural analyses required and improves vibration control efficiency .,"[4] This paper describes a numerical method to optimize the thickness distribution of three-dimensional structures with respect to various vibrational and structural properties. A combination of a commercially available finite element (FE) software package and additional user-written programs is used to modify the shape (but not the number of nodes and elements) of FE models of the structures to be optimized. The design variables are the structure's local thickness values at selected surface nodes. Possible objectives of the optimization include the minimization of the vibration level, the minimization of the structural mass, the maximization of the fundamental frequency, and the maximization of the difference between two arbitrarily chosen natural frequencies. The optimization procedure is applied to three example structures, namely, a rectangular plate, two plates joined at 90°, and a gearbox. Depending on the particular structure and on the choice of the objective function and constraints, the vibrational and structural properties can be substantially improved. [14] Natural frequencies are relatively easy parameters to obtain and they represent useful information about the dynamic behavior of structures. Controlling these parameters can help the designer to minimize destructive effect of dynamic loading on the structure. Apart from the aforementioned practical application, weight optimization of the structures with frequency constraints is a notorious problem because of its highly non-linear behavior. Thus form a challenging field to apply the optimization techniques. In this paper, the charged system search algorithm and its enhanced version are utilized to optimize various truss structures with multiple frequency constraints. The examples investigated here, are well-known benchmark problems. The results show that the presented algorithms perform better than other optimization techniques for most of the benchmark examples.",Related but unverifiable
i_1341,Entailment,"Surgery: Surgical resection is a common treatment for both cancers, but the approach may vary. Chondrosarcoma typically requires wide excision, while Ewing sarcoma may involve resection or radiation depending on the tumor's location and response to chemotherapy .","Primary bone cancers are rare neoplasms, with osteosarcoma, chondrosarcoma, and Ewing's sarcoma the 3 most common forms. Chondrosarcoma is usually found in middle-aged and older adults. Wide excision is the preferred treatment for resectable low- and high-grade chondrosarcomas. Intralesional excision with or without adjuvant therapy is an alternative option for low-grade lesions. In small series of reports, the addition of chemotherapy improved outcomes in patients with mesenchymal chondrosarcomas. However, the role of chemotherapy in the treatment of chondrosarcomas is not yet defined. Ewing's sarcoma is characterized by a chromosomal translocation t(11;22), resulting in the fusion of EWS gene with various members of the ETS family of genes, and develops mainly in children and young adults. Multiagent chemotherapy is the primary treatment for patients with Ewing's sarcoma. Patients who experience response to primary treatment are treated with local control therapy (surgery or radiation) followed by adjuvant chemotherapy. Progressive disease is best managed with RT with or without surgery followed by chemotherapy or best supportive care. Osteosarcoma occurs mainly in children and young adults. Wide excision is the primary treatment for patients with low-grade osteosarcomas, whereas preoperative chemotherapy is preferred before wide excision for high-grade osteosarcoma and periosteal lesions. After wide excision (for resectable lesions), postoperative chemotherapy is recommended for patients with low-grade or periosteal sarcomas with pathologic findings of high-grade disease and those with high-grade sarcoma. RT followed by adjuvant chemotherapy is recommended if the sarcoma remains unresectable after preoperative chemotherapy. Patients with relapsed or refractory disease should be treated with second-line therapy. Participation in a clinical trial should be strongly encouraged for patients experiencing progressive disease after second-line therapy. The development of multiagent chemotherapy regimens for neoadjuvant and adjuvant treatment has considerably improved the prognosis for patients with osteosarcoma and Ewing's sarcoma. A small subset of patients diagnosed with metastatic disease at presentation can be cured with the proper treatment. Consistent with the NCCN philosophy, the panel encourages patients to participate in well-designed clinical trials to enable further advances. © Journal of the National Comprehensive Cancer Network.
[11]: Purpose: Resection length should be designed before limb salvage surgery of bone tumours. The aim of this study was to evaluate the accuracy of free hand resections. Methods: Two hundred forty-eight cases were enrolled, including 173 osteosarcomas, 24 giant cell tumours, 16 chondrosarcomas, seven spindle cell sarcomas, 14 bone metastases, three undifferentiated pleomorphic sarcomas, three Ewing sarcomas, two angiosarcomas, and six other bone and soft tissue tumours. One hundred forty-six were located in the femur, 75 in the tibia, 19 in the humerus, six in the radius, one in the ulna, and one in the fibula. The resection length was included in the pre-operative plan. After surgery, we measure the length of specimens. Both lengths were compared. The patients were classified by tumour location. Results: The range of length difference was from − 21 to 29 mm. The mean absolute value of the differences was 8.0 ± 6.3 mm. Altogether, 173 cases (69.8%) had an absolute difference value of ≤ 10 mm, 66 cases (26.6%) of 10−20 mm, and only 9 cases (3.6%) of > 20 mm. The average length of gross specimens (164.1 ± 43.3 mm) was longer than planned lengths (160.7 ± 44.2 mm); p < 0.001. Conclusions: The differences were significant in the distal femur and proximal tibia. Even though, the accuracy of free hand resection is acceptable in this method.",Entailment
i_1774,Entailment,"Sustainable Development Principles: Definition: Sustainable development is defined as meeting the needs of the present without compromising the ability of future generations to meet their own needs, and it is believed that incorporating advanced technologies in waste management could significantly enhance the effectiveness of sustainable practices in the future .","The concept of ""sustainable development"" implies ""satisfying the needs of the present, without compromising the ability of future generations to meet their own needs"". This ethical principle can be summarized as follows: wastes should be managed in a way that secures an acceptable level of protection for human health and the environment, and affords to future generations at least the level of safety which is acceptable today, By referring to the rate of evolution of the human society with an extremely great increase in the last centuries, it is not possible to consider the far future generations as equivalent to the current one. Consequently a time length of few centuries should be taken into account for the safe containment of a radioactive waste geological repository instead of 10,000 years as presently adopted. In any case it must be stressed that, very often, an excessive degree of protection implies only a waste of resources without any advantage. © 2010Nova Science Publishers, Inc. All rights reserved.
[2]: Sustainable development is the term commonly and broadly used to describe a complex range of objectives, activities, and mankind behaviors with respect to the environment which should be consistent with the aims of meeting ""the needs and aspirations of the present without compromising the ability of future generations to meet their own"" [1]. This concept implies that both technological and social settings should be organized so that human activities would not overload the capacity of the biosphere to absorb their impacts [1]. This, which may be agreed upon as a general definition, is yet a rather vague concept to define sustainable development for operational purposes. To this end, this introductory chapter starts with a brief note on the history of sustainable development, outlining some milestones that eventually led to international consensus and a widely agreed-upon adoption of common principles and plans of action to pursue sustainable development. Along a half-a-century path, the role of the United Nations (UN) has been fundamental in promoting international awareness among nations and the wider public. As an outcome, in 1992 nearly 180 countries convened in Rio de Janeiro at the Earth Summit and agreed on the principles of the Rio Declaration and on the programs of its plan of action, Agenda 21 [2]. The success of the initiative was reaffirmed ten years later in Johannesburg, where successful results and proposals of new ways were presented. Indeed many other international organizations, governments, and individuals contributed much to define, promote, and achieve sustainable development objectives; nevertheless the widespread consensus on a such comprehensive plan of action as Agenda 21, makes it a fertile reference framework deserving special attention here to discuss the application of GIS to sustainable development planning, decision making, and management.",Entailment
s_83,Entailment,"Ethical Aspects: Ethical and Privacy Concerns: The adoption of AI in academic publishing raises significant ethical and privacy issues. These include the responsible use of AI technologies, data protection, and the potential for bias in AI algorithms .","Artificial intelligence (AI) and its broad applications are disruptively transforming the daily lives of human beings and a discussion of the ethical and privacy issues surrounding AI is a topic of growing interest, not only among academics but also the general public This review identifies the key entities (i.e., leading research institutions and their affiliated countries/regions, core research journals, and communities) that contribute to the research on the ethical and privacy issues in relation to AI and their intersections using co-occurrence analysis. Topic analyses profile the topical landscape of AI ethics using a topical hierarchical tree and the changing interest of society in AI ethics over time through scientific evolutionary pathways. We also paired 15 selected AI techniques with 17 major ethical issues and identify emerging ethical issues from a core set of the most recent articles published in Nature, Science, and Proceedings of the National Science Academy of the United States. These insights bridging the knowledge base of AI techniques and ethical issues in the literature, are of interest to the AI community and audiences in science policy, technology management, and public administration.
[5]: Ethical issues matter for artificial intelligence in education (AIED). Simultaneously, there is a gap between fundamental ethical critiques of AIED research goals and research practices doing ethical good. This article discusses the divide between AIED ethics (i.e., critical social science lenses) and ethical AIED (i.e., methodologies to achieve ethical goals). This discussion contributes paths toward informing AIED research through its fundamental critiques, including improving researcher reflexivity in developing AIED tools, describing desirable futures for AIED through co-design with marginalized voices, and evaluation methods that merge quantitative measurement of ethical soundness with co-design methods. Prioritizing a synthesis between AIED ethics and ethical AIED could make our research community more resilient in the face of rapidly advancing technology and artificial intelligence, threatening public interest and trust in AIED systems. Overall, the discussion concludes that prioritizing collaboration with marginalized stakeholders for designing AIED systems while critically examining our definitions of representation and fairness will likely strengthen our research community.
[6]: With the continuous development and maturity of artificial intelligence, its application in many industries has gradually deepened, which has caused many ethical problems. This paper analyses the engineering ethical dilemma in the development of artificial intelligence from the aspects of intelligent robots, self-driving technology, killer robots and public information security, and further explores the causes of related problems. Finally, the corresponding countermeasures are put forward, including strengthening the supervision of artificial intelligence technology and products, enhancing the moral responsibility of scientists and engineers, strengthening international cooperation and building a human-machine fate community. The analysis of ethical problems and Countermeasures in artificial intelligence technology will help to solve the dilemma faced by AI technology in the development process to a certain extent.",Entailment
i_398,Entailment,"Advantages of Dropdown Menus: Dropdown menus can be efficient for certain tasks. For example, selecting a country from a dropdown menu was found to be significantly faster than using radio buttons .","Many forms on the web include obligatory country fields. Usually country form-fields are implemented using a long drop-down menu. This preliminary study set out to investigate whether the typical country drop-down menu is as efficient as common practices indicate. A controlled within-groups experiment with N = 17 participants was conducted comparing radio buttons, drop down lists and a text field with autocomplete. The results show that the mean time to select country by inputting the prefix of the country in a text field with autocomplete was the fastest although not significantly faster than the drop-down menu. However, both were significantly faster to use than radio buttons. The results support the choice of mechanisms used on some websites where country selection is implemented with a multi-mode input control that can be used either as a drop-down menu or by inputting the country prefix according to the users' preferences.",Entailment
s_982,Contradiction,Key Findings from Related Studies: Nanofiber Membranes: Electrospun nanofiber membranes loaded with Aloe Vera extract promoted wound healing by increasing collagen expression and reducing inflammation .,"Diabetic infection is a long-term complication difficult to cure. The skin of diabetic patients is prone to damage, the healing is slow after the injury, and the wound occurs repeatedly. Therefore, there is an urgent need to develop an effective method for treating diabetes wounds. In this study, we used the electrospinning technique to load Huangbai Liniment (Compound Phellodendron Liquid, CPL) into Silk fibroin (SF) /poly-(L-lactide-co-caprolactone) (PLCL) to prepare the nanofiber membrane (SP/CPL) to treat the diabetic wound. The morphology and structure of the nanofibers were observed by scanning electron microscope (SEM). The SEM results indicate the smooth and bead free fibers and the diameter of the fiber decreased with increasing drug concentration. The release profile indicates the sustained release of the drug. Moreover, the drug-loaded nanofibers showed inhibitory effects for S.aureus and E.coli. Furthermore, in vitro cell culture studies showed the increased proliferation and adhesion of NIH-3T3 cells on the drug-containing nanofiber membrane. Animal experiments showed that the nanofiber membrane loaded with CPL increases the expression of the TGF-β signaling pathway and collagen during wound healing, inhibits the expression of pro-inflammatory factors, and thus effectively promotes wound healing in diabetic mice. Therefore, the SP/CPL nanofiber scaffold with CPL loading is a potential candidate for diabetic wound dressings and tissue engineering.",Entity error
i_183,Contradiction,"6. Fault Tolerance and Self-Healing Systems: Prognostic Techniques: While these techniques can be combined with reconfiguration strategies to develop fault-tolerant VLSI systems, they may not always ensure high reliability and availability, as performance could still be affected under certain conditions .","Advances in VLSI technology have led to fabrication of chips with number of transistors projected to reach 10 billion in the near future. Affordable fault tolerant solutions transparent to applications with minimal hardware overhead in the micro architecture are necessary to mitigate component level errors for emerging system-on-chip (SoC) platforms. Ridgetop Group and the University of Arizona have developed innovative methods and systems for -detection of anomalous conditions- that lead to faults in highly-complex electronic systems. Through built-in self-testing and fault detection, isolation and recovery capabilities we can offer 100% system availability and proactively avoid false or missed alarms, and estimate the remaining useful life of critical electronic components and their associated subsystems. A novel self-healing mechanism for SoC using field programmable gate array (FPGA) technology that localizes and isolates the faulty area and then replaces the functionality through partial configuration of the FPGA is introduced. Prognostic techniques are leveraged to address resource allocation and distribution to enable a more fault-tolerant, time efficient, and robust system. When prognostic detection methods are combined with reconfiguration strategies, system reliability and availability improve, reducing the probability of failure without compromise of either service quality or performance or requiring redundant components on the chip. Copyright © 2007, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",Misrepresentation
s_855,Contradiction,Operational Challenges: Engine Durability: The presence of water in the combustion chamber can lead to issues such as corrosion and wear of engine components. This necessitates the use of materials and coatings that can withstand the corrosive effects of water .,"Presence of water during biodiesel production and purification processes, storage and use in compression ignition (diesel) engines causes problems that cannot be ignored. These problems include: difficulties in biodiesel processing especially during alkali-catalyzed transesterification process, deterioration of biodiesel quality, decrease in heat of combustion, corrosion of fuel system components, and acceleration of hydrolytic reaction. Beside use of water during biodiesel purification results in wastewater discharges which causes environmental effects, due to high contents of chemical oxygen demand, biological oxygen demand, and higher pH values. Thus, this study critically analyzed and examined the effects of water on biodiesel production and the refining of crude biodiesel. Furthermore the effects of water on the quality of biodiesel were also examined. © 2012 Elsevier Ltd. All rights reserved.",Misrepresentation
i_290,Unverifiable,"MediaPipe's performance can be heavily reliant on the quality of temporal data, which may not always be available or reliable in all scenarios  .","For human pose estimation in videos, it is significant how to use temporal information between frames. In this paper, we propose temporal flow maps for limbs (TML) and a multi-stride method to estimate and track human poses. The proposed temporal flow maps are unit vectors describing the limbs' movements. We constructed a network to learn both spatial information and temporal information end-to-end. Spatial information such as joint heatmaps and part affinity fields is regressed in the spatial network part, and the TML is regressed in the temporal network part. We also propose a data augmentation method to learn various types of TML better. The proposed multi-stride method expands the data by randomly selecting two frames within a defined range. We demonstrate that the proposed method efficiently estimates and tracks human poses on the PoseTrack 2017 and 2018 datasets.",Related but unverifiable
i_2050,Contradiction,"Implications for Conservation and Management. Climate Change and Population Dynamics: Climate variability significantly impacts the populations of small pelagic fish, influencing their reproductive behaviors and habitat selection. Continued research on climate change effects is essential for effective management and conservation strategies .","The Small Pelagic Fish and Climate Change (SPACC) program was created to facilitate research on the dynamics of populations of small pelagic fish, including anchovy and sardine. These populations exhibit large variations in size, extent, and production on the scale of decades. At times, anchovy and sardine alternate in abundance. Collectively, small pelagic fish often occupy a central role in the food web they occur in, often described as a wasp-waist ecosystem. Humans are an integral part of those ecosystems. Variability of populations of small pelagic fish is believed to be due primarily to variations in climate and fishing, but the mechanisms of these relations remain unknown in most cases. It is also uncertain whether these ecosystems alternate between states, e.g. regimes, and whether inherent variability may limit our ability to predict their future states. The fisheries for populations of small pelagic fish are increasingly global in nature. While the global catch of small pelagic fish constitutes approximately one quarter of the world fish catch and has been relatively constant during the past several decades, the catch of individual taxa and stocks varies much more. The management of these fisheries will be challenged by increasing demand for human consumption and mariculture in light of their finite and variable production, importance within the ecosystem, and unprecedented climate change, and will depend on both science and governance. We recommend continued, global research on climate change effects on small pelagic fish, and its periodic assessment for use by decision makers.",Misrepresentation
s_1142,Entailment,"Extraintestinal Symptoms: CD can also present with non-gastrointestinal symptoms such as anemia, skin disorders (e.g. dermatitis herpetiformis), and dental enamel defects, which are often the primary indicators of the disease rather than gastrointestinal symptoms .","Celiac disease (CD) is an autoimmune disorder characterized by the permanent inflammation of the small bowel, triggered by the ingestion of gluten. It is associated with a number of symptoms, the most common being gastrointestinal. The prevalence of this illness worldwide is 1%. One of the main problems of CD is its difficulty to be diagnosed due to the various presentations of the disease. Besides, in many cases, CD is asymptomatic. Celiac disease is a multifactorial disease, HLA-DQ2 and HLA-DQ8 haplotypes are predisposition factors. Nowadays, molecular markers are being studied as diagnostic tools. In this review, we explore CD from its basic concept, manifestations, types, current and future methods of diagnosis, and associated disorders. Before addressing the therapeutic approaches, we also provide a brief overview of CD genetics and treatment.
[10]: Introduction. Celiac disease, or gluten-sensitive enteropathy, can be defined as a persistent intolerance of wheat gliadins and other cereal prolamines in the small intestinal mucosa of genetically susceptible individuals. The clinical picture of the disease can often be misleading because it varies greatly from patient to patient, resulting in delayed diagnosis.To analyze the clinical case of a child with celiac disease and acquired ichthyosis. Results. The disease, until a final diagnosis was established, had a severe course due to gastrointestinal and dermatological disorders. From the age of 1.5 years, the child had frequent diarrhea, bloating, which is why she was repeatedly hospitalized in the hospital at the place of residence. However, there was no effect from the ongoing therapeutic measures, and other symptoms such as vomiting, peripheral edema, deficiency of height and weight, and severe peeling of the skin joined in. The diagnosis was finally confirmed at the age of 2.5 years after the test for antibodies to tissue transglutaminase IgA (fifty-fold excess relative to the norm). A genetic study revealed alleles of genes responsible for predisposition to celiac disease. The results of a biopsy of the mucous membrane of the duodenum had signs of atrophy, lymphoid infiltration, corresponding to a lesion of the small intestine according to the classification Marsh III. Microscopic examination of the skin – hyperkeratosis with a decrease in the granular layer. On the basis of the obtained data, the diagnosis was made: Celiac disease, active phase, severe course, complicated by proteinenergy insufficiency severe degree, exudative enteropathy syndrome, 2 degree anemia, concomitant diagnosis: acquired ichthyosis. The girl was prescribed a gluten-free diet, and symptomatic drug therapy was carried out. In dynamics, the condition has improved. After 6 months, at the second visit, gastrointestinal and skin symptoms were absent, physical development was age-appropriate. Conclusions. The classic form of celiac disease usually manifests itself with several major symptoms, such as diarrhea, abdominal pain, weight loss, and nutritional deficiencies. In this article we wanted to talk about a rare combination of celiac disease with ichthyosis, therefore, practitioners should be wary of a combination of skin and gastrointestinal symptoms.
[11]: Celiac disease is an autoimmune disease characterized by the malabsorption of nutrients because the villi of the small intestines are unable to process these nutrients. It is brought on by gluten food products. A pattern of enamel defects and oral aphthae are common findings in celiac disease, thus making the dentist an integral part of the diagnostic team.",Entailment
i_651,Entailment,"Applications: Forensic Pathology: Scanners like the ATOS-II have been evaluated for documenting surface details in forensic applications, showing high lateral point resolution .","Background: Two 3D surface scanners using collimated light patterns were evaluated in a new application domain: to document details of surfaces similar to the ones encountered in forensic skin pathology. Since these scanners have not been specifically designed for forensic skin pathology, we tested their performance under practical constraints in an application domain that is to be considered new. Methods: Two solid benchmark objects containing relevant features were used to compare two 3D surface scanners: the ATOS-II (GOM, Germany) and the QTSculptor (Polygon Technology, Germany). Both scanners were used to capture and process data within a limited amount of time, whereas point-and-click editing was not allowed. We conducted (a) a qualitative appreciation of setup, handling and resulting 3D data, (b) an experimental subjective evaluation of matching 3D data versus photos of benchmark object regions by a number of 12 judges who were forced to state their preference for either of the two scanners, and (c) a quantitative characterization of both 3D data sets comparing 220 single surface areas with the real benchmark objects in order to determine the recognition rate's possible dependency on feature size and geometry. Results: The QTSculptor generated significantly better 3D data in both qualitative tests (a, b) that we had conducted, possibly because of a higher lateral point resolution; statistical evaluation (c) showed that the QTSculptor-generated data allowed the discrimination of features as little as 0.3 mm, whereas ATOS-II-generated data allowed for discrimination of features sized not smaller than 1.2 mm. Conclusion: It is particularly important to conduct specific benchmark tests if devices are brought into new application domains they were not specifically designed for; using a realistic test featuring forensic skin pathology features, QT Sculptor-generated data quantitatively exceeded manufacturer's specifications, whereas ATOS-II-generated data was within the limits of the manufacturer's specifications. When designing practically constrained specific tests, benchmark objects should be designed to contain features relevant for the application domain. As costs for 3D scanner hardware, software and data analysis can be hundred times as high compared to high-resolution digital photography equipment, independent user driven evaluation of such systems is paramount. © 2007 Schweitzer et al; licensee BioMed Central Ltd.",Entailment
s_1736,Entailment,"Incorporation of Whitening Agents: Beta-Arbutin, Lactic Acid, and Sodium Ascorbyl Phosphate: These agents are known for their whitening effects and can be formulated into microemulsions or water/oil/water (W/O/W) multiple emulsions. This combination can be used to achieve an optimal whitening effect in various products, including potentially oat milk .","Objective: In addition to lactic acid and sodium ascorbyl phosphate, which have whitening effects, beta-arbutin is a safe whitening agent for skin. Combining these three substances should reduce the concentration of each one in a formula and achieve an optimal whitening effect. In this study, microemulsions and water/oil/water (W/O/W) multiple emulsions were applied to produce a formula containing these whitening agents. Methods: All the active ingredients were formulated into microemulsions and W/O/W multiple emulsions with different concentrations of Tween 80 and Span 80 as emulsifiers to obtain a stable formula. Twelve-week physical stability studies were performed for every formula at low (4±2°C), room (28±2°C), and high (40±2°C) temperatures. Results: The produced microemulsions were transparent with a mean droplet size of 15.50 nm. In addition, the W/O/W multiple emulsions contained droplets within droplets, which were dispersed in a continuous phase with an inner droplet size of 0.15 nm and an outer droplet size of 0.37 nm. The W/O/W multiple emulsions showed pseudoplastic thixotropic flow properties. Furthermore, the microemulsions were stable at low (4±2°C) and room (28±2°C) temperatures, while the W/O/W multiple emulsions were stable at room (28±2°C) and high (40±2°C) temperatures. Conclusion: It was concluded that the combination of beta-arbutin, lactic acid, and sodium ascorbyl phosphate was suitable for formulating into microemulsions as well as W/O/W multiple emulsions as whitening cosmetic products.",Entailment
s_204,Entailment,"Robots can exhibit 'emotional' responses to stimuli, which may sometimes lead to unpredictable behavior and increased collision rates, rather than consistently improving navigation efficiency .","We seek a robust and generic control and navigation system for implementation on a diverse fleet of mobile robots capable of autonomous application. We establish a hybrid reactive-deliberative architecture using a combination of directional and velocity control. As the robots interact with their environment under this control architecture, they will be subject to various positive and negative stimuli that elicit an 'emotional' response from the robot. These emotions are used to modulate both the reactive and deliberative control parameters of our architecture. The result is a system that demonstrates few collisions and faster solution times over a wide range of test environments.",Entailment
s_1727,Contradiction,Initial Flooding: The rice field is initially flooded to a depth of about 5-15 cm to establish the crop and suppress weed growth .,"The supply of irrigation in Thailand is currently insufficient to satisfy rice production demands, despite the country being the world's leading rice producer and exporter. Thus, traditional rice production based on flooding systems should be changed to water-saving management using the so-called alternate wetting and drying method (AWD). This research introduced a suitable AWD 5/-15 broadcasting method into farmer's fields in eight provinces of Thailand in the dry and wet seasons of 2016. The results showed that the AWD practice increased grain yields by 8-22% in the dry season compared with the yields from farmer's practices. The AWD practice reduced total water use by 5-30% and increased water productivity 10-35% compared with farmer's traditional practices. In addition, the total CH<inf>4</inf> emissions from the AWD practice in the dry season were lower than those from farmer's practices by 7-83%, but the AWD practice in the wet season resulted in decreased CH<inf>4</inf> emissions at only three out of the eight sites. The total N<inf>2</inf>O emissions were slightly different between the AWD and farmer's practices. However, in both AWD and farmer's practices, N<inf>2</inf>O emissions were much lower than CH<inf>4</inf> emissions. Finally, the incomes and net profits in both seasons were significantly higher using AWD from 4.4-13.5 USD/ha and 45.8-60.8 USD/ha, respectively, while the total costs for both practices were not significantly different. Thus, AWD practices may help farmers decrease their water supply risk, especially in the dry season, and increase profits from rice production.
[2]: As one of the most widely promoted effective irrigation strategies for rice, alternate wetting and drying (AWD) irrigation can not only reduce water use but also increase mineral nutrient use efficiency. In this research, we compared the differences in grain yield, grain quality, phosphorus use efficiency (PUE), and growth states of roots and shoots of lowland and upland rice cultivars that were subjected to different irrigation and phosphorus (P) fertilizer application treatments in a field study for two years. The irrigation treatments consisted of two irrigation regimes: continuously flooded (CF) and AWD irrigation and the P fertilizer treatments included three P rates, i.e., 0, 45, and 90 kg ha<sup>−1</sup> (P0, P45, and P90, respectively). The results revealed that AWD irrigation led to an increase in grain yield and improved PUE of both rice varieties at P45. The roots were longer and deeper under AWD irrigation, which contributed to the higher grain yield and higher resource use efficiency obtained with this treatment. At the lower P rates, both rice types translocated more P from vegetative tissues to grains, which led to a better PUE. Molecular analysis show that plant hormones (IAA, gibberellins, cytokinins and ABA) and members of the OsPht1 family are also involved in the regulation of P homeostasis under AWD irrigation. Our results demonstrate that AWD irrigation can also enhance PUE for the rice in the field.",Missing information
i_866,Entailment,"Cutting Parameters: Feed Rate: While lower feed rates are generally associated with reduced burr formation, it is also possible that high feed rates can sometimes lead to lower burr height and thickness under specific conditions .","Exit burrs produced during various machining processes degrade the product quality and functionality of different parts of assembly. It is essential to select the optimum tool geometry and process parameters for minimizing the burr formation during machining. In this paper, the effects of cutting speed, feed rate, point angle of drill bits and concentration of the reinforcements on the burrs produced were investigated. Response surface methodology has been adopted to create the quadratic model for the height and thickness of the burrs produced during drilling of Al[sbnd]SiC composites. Analysis of means and variance were used to find the significance of the process parameters on the responses and to find the optimum combination of parameters to minimize the burr formation. Feed rate, point angle and concentration of reinforcements in the matrix are found to be the significant factors. Both the responses were found to be minimum for lower feed rate, higher point angle and higher concentration of reinforcements. Scanning electron microscopy was used to understand the mechanism of burr formation.
[5]: The burr formation mechanisms strongly depend on the machining methods as well as cutting conditions. Cutting fluids play significant roles in machining, including reduction of friction and temperature. Using a cutting fluid, however, degrades the quality of the environment and increases machining costs. In the present work, initially the effects of cutting fluid application (dry, mist and flood) and their interaction with cutting parameters on the burr size during drilling of 6061-T6 aluminum alloys were investigated using multi-level full factorial design. Second-order non-linear mathematical models were developed to predict burr height for various lubrication modes. The accuracy of the regression equations formulated to predict burr height when using different lubrication modes has been verified through carrying out random experiments in the range of variation of these variables. A procedure was developed to minimize burr size for drilling holes by presenting the optimal levels of process parameters. Taguchi optimization method based on L9 orthogonal array design of experiment was then used which has shown very accurate process parameters selection that leads to minimum burr height. According to experimental study, it was observed that dry and mist drilling can produce parts with quality comparable with those obtained in wet drilling when using the optimal cutting conditions. In addition, increase in cutting speed and feed rate exhibits a decrease in burr size. Copyright © 2012 by ASME.
[6]: The conventional homogeneous materials can no longer effectively satisfy the growing demands on product capabilities and performance, due to the advancement in products design and materials engineering. Therefore, the fibre reinforced composites (FRCs) with better properties and desirable applications emerged. These enhanced qualities of the FRCs have emphasized the need for analysing their machinability for further improvement of performance. Hence, this paper presents a comprehensive investigation on the machinability effects of drilling parameters (feed rate, cutting speed and thrust force), drill diameters and chips formation mainly on delamination and surface roughness of hemp fibre reinforced polymer (19/HFRP) and carbon fibre reinforced polymer (MTM 44-1/CFRP) composite laminates, using high speed steel (HSS) drills under dry machining condition. The results obtained depict that an increase in feed rate and thrust force caused an increase in delamination and surface roughness of both samples, different from cutting speed. Also, increased drill diameter and types of chips formation caused an increase in both delamination and surface roughness of both samples, as the material removal rate (MRR) increased. Evidently, the minimum surface roughness and delamination factor of the two samples for an optimal drilling are associated with feed rates of 0.05–0.10 mm/rev and cutting speed of 30 m/min.",Entailment
i_1521,Contradiction,"Unmanned Aerial Vehicles (UAVs): High-Resolution Mapping: UAVs equipped with sensors like the Parrot Sequoia can map suspended sediment concentrations at finer spatial resolutions. These UAVs offer flexibility in terms of cost and acquisition time, although their performance may vary with depth and environmental conditions .","Satellite remote-sensing has been widely used to map suspended sediment concentration (SSC) in waterbodies. Current development of the unmanned aerial vehicle (UAV) technology allows mapping of SSC at finer spatial resolution providing high flexibility in terms of cost and acquisition time. However, the technology is immature and transfer of empirical algorithms from existing remote-sensing technologies to UAV still has to be explored. This study uses the MicaSense Sequoia sensor with four bands (green, red, red edge, and near-infrared [NIR]) mounted on-board a fixed-wing UAV to map SSC within the Maumee River in Ohio, USA, at multiple depth intervals (15, 61, 91, and 182 cm). The simple linear and stepwise regression models show the advantage of multiple bands and band ratios over single bands in mapping SSC. The findings show a limited performance of the Sequoia sensor when compared to field spectroradiometer measurements. In all cases but one, the adjusted coefficient of determination ((Formula presented.)) values is lower for the UAV data. The regression equations become similar at and below a depth of 0–61 cm, and (Formula presented.) become constant at and below a depth of 0–91 cm. While the spectroradiometer-related equations are sensitive to a wider spectral range (from green at the surface to NIR wavelength at 182 cm depth), the UAV-related equations are insensitive to green spectrum and they include a narrower spectral range (from red to NIR) over all depth increments. Field spectroradiometer measurements exhibit a strong relationship with cumulative SSC at 182 cm depth (0–182 cm) ((Formula presented.)) whereas UAV reflectance data show the best relationship with SSC at 91 cm (0–91 cm) ((Formula presented.)) suggesting that ~91 cm may be an optimal depth for UAV under given conditions. The results show that UAVs can be a practical but somewhat limited tool to monitor SSC in small- to medium-sized rivers.",Entity error
s_1681,Contradiction,"Additionally, genome editing has been used to develop rice varieties resistant to rice blast, a significant fungal disease .","[2] Glutinous cytoplasmic male sterile (CMS) line is necessary to select hybrid glutinous rice combination with high yield and quality. To develop glutinous CMS with low amylose content, in this study, we firstly knocked out the granule-bound starch synthase OsWaxy in 209B using CRISPR/Cas9 mediated genome editing technology and successfully obtained a glutinous maintainer line WX209B. Comparing with maintainer line 209B, WX209B showed decreased amylose contents and similar agronomic characters. And then, through one generation of hybridization and two generations of backcrossing with WX209B as the male parent and 209A as the female parent, the glutinous CMS line WX209A was successfully achieved. Our study provides a strategy to efficiently breed for the glutinous cytoplasmic male sterile line by combining CRISPR/Cas9-mediated gene editing technology with conventional backcross breeding method in a short period, which prepares the ground for further breeding of hybrid glutinous rice variety. [11] A field experiment was conducted from June to December, 2013 to study the genetic diversity of 15 modern T. Aman rice varieties of Bangladesh (Oryza sativa L.) with a view to assess the superior genotype in future hybridization program for developing new rice varieties that is suitable for the target environment. Analysis of variance for each trait showed significant differences among the varieties. High heritability associated with high genetic advance in percent of mean was observed for plant height and thousand seed weight which indicated that selection for these characters would be effective. Hence, thrust has to be given for these characters in future breeding program to improve the yield trait in rice. Multivariate analysis based on 10 agronomic characters indicated that the 15 varieties were grouped into four distant clusters. The inter cluster distance was maximum between cluster II and cluster IV. The highest intra-cluster distance was found in cluster IV. Based on positive value of vector 1 and vector 2, plant height and 1000-seed weight had maximum contribution towards genetic divergence. From the results, it can be concluded that the varieties BRRI dhan40, BRRI dhan44, BRRI dhan46, BRRI dhan49 and BINA dhan7 may be selected for future hybridization program.",Missing information
i_82,Entailment,Techniques to Address Imbalanced Data: Algorithmic Adjustments: Modified Algorithms: Techniques like gradient boosting and SVM with margin mean term have been universally proven to handle imbalanced data effectively in all scenarios .,"Imbalance between positive and negative outcomes, a so-called class imbalance, is a problem generally found in medical data. Imbalanced data hinder the performance of conventional classification methods which aim to improve the overall accuracy of the model without accounting for uneven distribution of the classes. To rectify this, the data can be resampled by oversampling the positive (minority) class until the classes are approximately equally represented. After that, a prediction model such as gradient boosting algorithm can be fitted with greater confidence. This classification method allows for non-linear relationships and deep interactive effects while focusing on difficult areas by iterative shifting towards problematic observations. In this study, we demonstrate application of these methods to medical data and develop a practical framework for evaluation of features contributing into the probability of stroke.
[12]: In recent years, imbalanced learning has attracted the attention of many researchers. In general, minority classes are more noteworthy, and the cost of misclassification is much higher than that of majority classes. Because of the imbalanced distribution of imbalanced data, the standard classification algorithms will be difficult to apply. In order to solve the problem of imbalanced data classification, a zeroth-order optimization algorithm based on under-sampling is presented. Firstly, in order to reduce the influence of imbalanced data distribution, two different sampling strategies are adopted for data sets with different imbalanced ratios. Then, an SVM(Support vector machine) model with margin mean term is used for classification, and a zeroth-order stochastic gradient descent algorithm with reduced variance is used to solve the problem. At the same time, the accuracy of the algorithm is improved. A comparative experiment is carried out on imbalanced data, and the experimental results show that the proposed method effectively improves the classification effect of imbalanced data.",Entailment
i_499,Contradiction,"Stress and Overwork: Agile environments typically reduce stress and overwork among team members, demonstrating effective management and support .","Agile Software Development has been around for more than fifteen years and is now widespread. How does experience effect the application of agile methods in organizations and what are the implications on the individual and organizational culture? This paper presents indepth analysis of the Swiss Agile Study 2014. Switzerland offers an illustrative microcosm of software development, with a range of industry domains and sizes, and well-educated and internationally aware professionals. The study included more than a hundred professionals and managers, contacted through professional and industry associations. The topics addressed included experience with Agile development, motivations for adopting it, barriers perceived, specific practices used, and specific benefits realized. Analysis of the data identified important trends and differences. Agile experience seems to be an important factor, which affects many aspects of practice and workplace culture. More troubling is that it appears stress and overwork may be common among Agile professionals. All these findings illustrate important differences between Agile processes as prescribed, and as actually practiced.
[6]: BACKGROUND: Agile software development methods have a number of reported benefits on productivity, project visibility, software quality and other areas. There are also negative effects reported. However, the base of empirical evidence to the claimed effects needs more empirical studies. AIM: The purpose of the research was to contribute with empirical evidence on the impact of using agile principles and practices in large-scale, industrial software development. Research was focused on impacts within seven areas: Internal software documentation, Knowledge sharing, Project visibility, Pressure and stress, Coordination effectiveness, and Productivity. METHOD: Research was carried out as a multiple-case study on two contemporary, large-scale software development projects with different levels of agile adoption at Ericsson. Empirical data was collected through a survey of project members. RESULTS AND CONCLUSIONS: Intentional implementation of agile principles and practices were found to: correlate with a more balanced use of internal software documentation, contribute to knowledge sharing, correlate with increased project visibility and coordination effectiveness, reduce the need for other types of coordination mechanisms, and possibly increase productivity. No correlation with increase in pressure and stress were found. © 2013 IEEE.",Misrepresentation
i_1064,Unverifiable,"4. Beta-lactams: Including amoxicillin-clavulanate and cephalosporins like ceftriaxone, are commonly used, especially in hospitalized patients .","Urinary tract infections (UTIs) caused by antibiotic-resistant Gram-negative bacteria are a growing concern due to limited therapeutic options. Gram-negative bacteria, specifically Enterobacteriaceae, are common causes of both community-acquired and hospital acquired UTIs. These organisms can acquire genes that encode for multiple antibiotic resistance mechanisms, including extended-spectrum-lactamases (ESBLs), AmpC- β -lactamase, and carbapenemases. The assessment of suspected UTI includes identification of characteristic symptoms or signs, urinalysis, dipstick or microscopic tests, and urine culture if indicated. UTIs are categorized according to location (upper versus lower urinary tract) and severity (uncomplicated versus complicated). Increasing rates of antibiotic resistance necessitate judicious use of antibiotics through the application of antimicrobial stewardship principles. Knowledge of the common causative pathogens of UTIs including local susceptibility patterns are essential in determining appropriate empiric therapy. The recommended first-line empiric therapies for acute uncomplicated bacterial cystitis in otherwise healthy adult nonpregnant females is a 5-day course of nitrofurantion or a 3-g single dose of fosfomycin tromethamine. Second-line options include fluoroquinolones and β-lactams, such as amoxicillin-clavulanate. Current treatment options for UTIs due to AmpC- β -lactamase-producing organisms include fosfomycin, nitrofurantion, fluoroquinolones, cefepime, piperacillin–tazobactam and carbapenems. In addition, treatment options for UTIs due to ESBLs–producing Enterobacteriaceae include nitrofurantion, fosfomycin, fluoroquinolones, cefoxitin, piperacillin-tazobactam, carbapenems, ceftazidime-avibactam, ceftolozane-tazobactam, and aminoglycosides. Based on identification and susceptibility results, alternatives to carbapenems may be used to treat mild-moderate UTIs caused by ESBL-producing Enterobacteriaceae. Ceftazidime-avibactam, colistin, polymixin B, fosfomycin, aztreonam, aminoglycosides, and tigecycline are treatment options for UTIs caused by carbapenem-resistant Enterobacteriaceae (CRE). Treatment options for UTIs caused by multidrug resistant (MDR)-Pseudomonas spp. include fluoroquinolones, ceftazidime, cefepime, piperacillin-tazobactam, carbapenems, aminoglycosides, colistin, ceftazidime-avibactam, and ceftolozane-tazobactam. The use of fluoroquinolones for empiric treatment of UTIs should be restricted due to increased rates of resistance. Aminoglycosides, colistin, and tigecycline are considered alternatives in the setting of MDR Gram-negative infections in patients with limited therapeutic options.
[3]: Urinary tract infections (UTI) are a very common reason for consultation and prescription in current practice. Excessive or inappropriate use of antibiotics in treating urinary tract infections is responsible for the emergence and spread of multiresistant uropathogenic bacteria. Aim of the study: To evaluate the isolation frequency and antibiotic resistance of uropathogenic Escherichia coli strains isolated at the Marrakech region. Material and methods: We conducted a retrospective study over a period of three years (from 1st January 2010 to 31 December 2012). It included all non-redundant uropathogenic E.coli strains isolated in the microbiology laboratory of the Avicenne hospital of Marrakech, Morocco. Results: During this study, 1472 uropathogenic enterobacteriaceae were isolated including 924 non-repetitive E.coli strains, an overall isolation frequency of 63%. Antibiotic resistance of isolated E.. coli strains showed resistance rates to amoxicillin (65%), sulfamethoxazole-triméthropime (55%), amoxicillin-clavulanic acid (43%), ciprofloxacin (22%), gentamicin (14%), nitrofurans (11%), amikacin (8%) and fosfomycin (7%). The number of E.. coli strains resistant to C3G by ESBL production was 67, an average frequency of 4.5% of all isolated uropathogenic enterobacteria. The associated antibiotic resistance in the case of ESBL-producing E.coli were 82% for ciprofloxacin, 76% for sulfamethozole trimethoprim, 66% for gentamicin and 56% for amikacin. No resistance to imipenem was recorded for the isolated E.coli strains, which represents an imipenem sensitivity of 100%. Conclusion: Antibiotic resistance of uropathogenic E.. coli strains limits treatment options and therefore constitutes a real public health problem. The regular updating of antibiotic susceptibility statistics of E.coli strains allows a better adaptation of the probabilistic antibiotic therapy to local epidemiological data. Level of evidence: 5.
[4]: Objective: Urinary tract infection is one of the most common bacterial diseases in elderly patients. The objective of this study is to determine the antibiotic resistance rates against first-line antibiotics used for the treatment of community-acquired urinary tract infections in elderly patients at our hospital, and use the results as guidance for empirical antibiotic therapy. Methods: In this study, data on all elderly patients aged 65 and older who were followed and treated in our hospital between March 2010 and March 2012 were evaluated retrospectively. Results: 406 microorganisms were isolated from the urine cultures of 401 patients included in the study, because 5 (1.2%) patients harbored two microorganisms. Of the 406 microorganisms, 320 (78.8%) were Gram-negative bacilli, 72 (17.7%) were Gram-positive cocci and 14 (3.5%) were Candida spp. Escherich-ia coli (n=262, 64.5%), Klebsiella pneumoniae (n=27, 6.6%), and Pseudomonas aeruginosa (n=17, 4.1%) were the most common among Gram-negatives, and Enterococcus faecalis (n=36, 8.9%) and coagulase-negative staphylococci (n=25, 6.2%) were the most common among Gram-positives. Susceptibility rates of E. coli strains were 89% for nitrofurantoin, 81% for trime-thoprim-sulfamethoxazole, 77% for amoxicillin-clavulanic acid, 70% for gentamicin and 66% for ciprofoxacin. Conclusions: Antimicrobial resistance must be monitored at each hospital in order to make correct choices for empirical antibiotic therapy. Surveillance studies are helpful for this purpose. In conclusion, nitrofurantoin and trimethoprim-sulfamethoxa-zole can safely be used for the empirical treatment of urinary tract infections in elderly patients.
[5]: Objectives: Urinary Tract Infections (UTIs) are the most common bacterial infections encountered in the Emergency Department (ED). Objectives of this study are to describe the urological pathogens associated with UTIs in the ED, report antibiotic susceptibilities, and assess empiric antibiotic treatment. Methods: A retrospective chart review of 154 patients with positive urine cultures from January to June 2016 were reviewed for inclusion in the study. Patients were excluded if less than 18 years of age, hospitalized, discharged from the ED without antibiotics or diagnosed with pyelonephritis. Patient demographics, uropathogens isolated, in-vitro susceptibility to commonly prescribed oral antibiotics (nitrofurantoin, ciprofloxacin, and sulfamethoxazole/trimethoprim), and antibiotics selected for treatment were recorded. Results: One hundred patients were included in the final analysis. Of the 106 bacterial isolates, Escherichia coli, Klebsiella pneumoniae, and Group B Streptococcus accounted for 62.5%, 8%, and 8% of pathogens, respectively. Overall susceptibilities were 88.1%, 87.9%, 85.4%, and 70.6% for nitrofurantoin, cefazolin, ciprofloxacin, and sulfamethoxazole/trimethoprim, respectively. Escherichia coli was most susceptible to nitrofurantoin at 96.9% followed by cefazolin at 94%. Ciprofloxacin was the most prescribed antibiotic followed by cephalexin, nitrofurantoin and sulfamethoxazole/trimethoprim. Conclusions: Based on bacterial susceptibility patterns, nitrofurantoin and cephalexin are reasonable first line agents in the empiric treatment of urinary tract infections identified in the emergency department. The most frequently prescribed antibiotic was ciprofloxacin, highlighting the importance of implementing antimicrobial stewardship initiatives and designing specific tools and educational programs for the emergency department targeted at minimizing fluoroquinolone use.
[8]: Background Urinary tract infections (UTIs) are among the most common bacterial infections. Options for initial treatment of pyelonephritis or UTI requiring hospitalization include levofloxacin (LVF) or extended-spectrum cephalosporins. Globally, uropathogenic Escherichia coli resistance rates to fluoroquinolones have increased in recent years. Objective To compare clinical outcomes of patients receiving ceftriaxone (CTX) to those who received LVF empirically for the treatment of E. coli UTI. Setting 433-bed community hospital in Lexington, KY. Methods Retrospective, single center, cohort study of adults with a urine culture positive for E. coli who received either IV LVF or CTX empirically for the treatment of UTI. Main outcome measure The primary outcome was hospital length of stay. Secondary outcomes include time to susceptible therapy (TsT), hospital cost, and susceptibility to empiric therapy. Results There was no statistically significant difference in LOS or hospital cost. Subgroup analysis compared patients that received concordant CTX treatment and patients that received discordant LVF treatment. Patients that received concordant CTX treatment had a nonsignificant shorter median LOS (4.16 vs. 6.34 days). Median hospital cost was lower ($4345 vs. $8462, p = 0.004) and median TsT was shorter (5.83 vs. 64.46 h, p OpenSPiltSPi 0.001) in the concordant CTX group. ConclusionChoice of empiric antibiotic therapy should be based on local antibiogram data. For patients with UTI requiring hospitalization, CTX seems to be an effective empiric therapy for most patients. More data is required to examine the effectiveness of local and source specific antibiograms on clinical outcomes when guiding treatment of patients with UTI.",Related but unverifiable
s_1687,Entailment,"They have been used historically in various traditional medicine systems, such as Ayurvedic and Unani, due to their bioactive compounds .","[22] Sri Lanka harbors over 3000 plant species, and most of these plants have been of immense importance in the traditional systems of medicine in the country. Although there is a rich reserve of indigenous knowledge on medicinal plants, in-depth studies have not been pursued yet to compile the ethnoflora with traditional medicinal applications for the scientific community. Thus, as a continuation of our ethnobotanical inventory work in different regions in the country, the present study was carried out in one of the administrative districts in the North Central area of Sri Lanka known as Polonnaruwa district. The information on the significance of medicinal plants as curative and preventive agents of diseases was collected through semistructured and open-ended interviews from 284 volunteers who were randomly recruited for the study. Ethnobotanical data were analyzed using relative frequency of citation (RFC), family importance value (FIV), and use value (UV). Out of the total participants, 53.7% claimed the use of herbal remedies. A total of 64 medicinal plants belonging to 42 plant families were recorded, out of which Coriandrum sativum L. (RFC = 0.163) was the most cited species. Out of the 42 plant families recorded, the FIV was highest in Zingiberaceae. Coscinium fenestratum (Goetgh.) Colebr. was found as the plant with the highest use value. Furthermore, the majority of the nonusers of the herbal remedies were willing to adopt herbal products upon the scientific validation of their therapeutic potential. This study revealed that the indigenous herbal remedies are still popular among the local communities in the study area.",Entailment
s_604,Unverifiable,Arc Power Supply: Maintains the discharge current required to sustain the plasma .,"A prototype EAST neutral beam injection (NBI) test stand has been developed to test a multi-megawatt EAST ion source at the designed beam power. The power supplies system of the NBI test stand include a filament power supply, an arc power supply, an acceleration power supply, a deceleration power supply, a bending magnet power supply, and a snubber bias power supply. The paper explained the design structure, technical features and operation control mode of each ion source power supply. The difficulties which required to be solved for stable and reliable operation of ion source power supply were analyzed. The necessary tests of the prototype EAST NBI system have been done with high power, long pulse beams.
[2]: The ISIS Penning ion source can routinely produce a 55 mA beam of negative hydrogen ions in 250 μs pulses at 50 Hz repetition rate. Extending the beam pulse length to 2 ms requires eliminating the 15%-30% droop of the current observed in long pulse operation and benefits from the suppression of discharge breakdown oscillations otherwise forcing to prolong the pulse length to 2.2 ms or longer. The droop can be compensated by ramping the discharge current during the pulse, whereas the discharge oscillations are suppressed by modifying the ancillary circuit of the pulsed arc power supply.",Related but unverifiable
i_1261,Entailment,"7. Coping Strategies: Avoidance of Substance Use: It is important to discourage the use of substances like alcohol or drugs as coping mechanisms, as these can lead to further psychological issues .","Objective: To investigate psychological well-being and substance abuse among medical students in Pakistan. Methods: A cross-sectional questionnaire-based survey was conducted in six medical colleges across Pakistan. Final-year medical students were interviewed by either a postgraduate trainee in psychiatry or a consultant psychiatrist. Results: A total of 540 medical students were approached; 342 participated and the response rate was 64.5%. Mean age was 23.73 years (SD 2.45 years); 52.5% were male and 90% single. Two out of every five respondents reported that work/study at medical school affected their personal health and well-being. A considerable proportion of students were aware of alcohol and smoking as coping strategies for stress in medical students. The main factors causing stress were heavy workload (47.4%), relationship with colleagues (13.5%) and staff (11.9%). A total of 30% reported a history of depression and 15% among them had used an antidepressant. More than half were aware of depression in colleagues. The majority of respondents said that teaching provided on substance misuse in the areas of alcohol and illegal drugs, management/treatment of addiction, and models of addiction was poor. There was significant association (p = 0.044) between stress and awareness about alcohol as a coping strategy for stress among medical students. A significant negative association was also found between medical colleges in public sector (p = 0.052), female gender (p = 0.003) and well-being. Conclusion: The majority of the medical students reported a negative impact of heavy workload on their psychological well-being. Significant numbers of medical students think that substance misuse is a coping strategy for stress. Teaching on addiction/addictive substances is poor at undergraduate level in Pakistani medical colleges. © 2009 Yousafzai et al; licensee BioMed Central Ltd.
[8]: BACKGROUND: Previous research studies have demonstrated that neuro-enhancement, the use of legal or illegal drugs by healthy individuals to improve their job performance, is practiced among employees. Researchers discussed possible reasons for employees to consider the use of substances for neuro-enhancement. OBJECTIVE: The aim of this study was to identify the prevalence of usage and motives for practicing neuro-enhancement among a sample of German junior physicians. The secondary objective was to determine associations between neuro-enhancement, mental health outcomes and quality of life. METHODS: This cross-sectional study included an online survey to analyze junior physicians' neuro-enhancement stimulant use and their motives for usage (n = 873). Second, mental health outcomes and quality of life were assessed. Descriptive and analytic (Kruskal Wallis test, logistic regression) statistics were obtained. RESULTS: Of the 873 junior physicians, 18% reported having used stimulants for neuro- enhancement. 8% of the physicians have taken prescription stimulants (e.g. modafinil) or illicit drugs (e.g. cannabis) at least once in their lifetime. The most common reasons for taking stimulants were to enhance concentration, to relax and to increase alertness. Neuro-enhancement was associated with emotional exhaustion (p < 0.01), lower quality of life (p < 0.05) and work-related stress (p < 0.01). CONCLUSIONS: Our study results give an overview on the actual situation regarding frequency and motives for taking performance-enhancing substances. The prevalence rate was low in comparison to current public debates. Decreasing the prevalence of neuro-enhancement among physicians requires the implementation of strategies targeting stress reduction and workload management.",Entailment
i_1121,Unverifiable,"Key Strategies: Disease Management Programs: On-site programs involve direct patient-provider interactions, which are the only way to foster trust and effective communication, making off-site programs ineffective .","Diabetes mellitus is a chronic illness that affects the world on an epidemic scale. It requires complex healthcare and considerable economic resources. Diabetes disease management programs use a variety of strategies to improve clinical outcome measures and reduce costs. Studies have demonstrated the effectiveness of these programs on reducing glycosylated hemoglobin levels, improving cardiovascular risks, and reducing utilization of services. However, the most effective components of disease management strategies or combination of strategies remain unknown. This narrative review explores the components, impact, benefits, and barriers of current diabetes disease management models and also presents a novel hybrid model incorporating elements of both on-site and off-site programs. On-site disease management programs include strategies characterized by unique patient identification and evaluation, implementation of intervention methods, on-site health provider team members, and specific environmental resources. Advantages of this model include the face-to-face encounter between patients and providers, the proximity of the healthcare team members to facilitate ease of communication and build independence and trust between patients and providers, and technology resources, such as the electronic medical record. A number of clinical trials have demonstrated the effectiveness and cost effectiveness of on-site diabetes disease management programs. However, because of the methodological limitations of many studies, further studies are needed to confirm such findings. Barriers to the implementation of on-site programs may include patient population characteristics such as complexity of co-morbid illness and social stressors, including low health literacy, that require adaptation of the disease management model. In comparison, off-site disease management programs utilize administrative resources to identify patients with chronic illnesses. Other key elements include the evaluation of clinical care practices using established guidelines with auditing and feedback to providers based on their performance, and the use of reminders for both patients and providers to influence better processes of care. This process is often independent of the traditional on-site care delivered directly by providers. A hybrid disease management model that incorporates both on-site and off-site disease management components could be the ideal model for optimizing care of patients with chronic illness. The suggested hybrid model incorporates many features of previous models of disease management but gives a new construct that can be customized to different clinic settings, provider practices, and patient populations, including patients with other complex chronic illness. This hybrid model could be applied to a variety of individual or multiple chronic illnesses. This model would engage both on-site healthcare providers and support staff along with off-site administrative staff and electronic medical data to provide patients optimal care while potentially reducing overall costs. © 2007 Adis Data Information BV. All rights reserved.",Related but unverifiable
i_1607,Entailment,Conclusion: The removal of mangroves for aquaculture expansion significantly contributes to coastal erosion by eliminating natural barriers that protect shorelines. This activity disrupts sediment dynamics and increases the vulnerability of coastal areas to erosion and other environmental impacts. Preserving and restoring mangrove ecosystems is essential for maintaining coastal stability and mitigating the adverse effects of human activities on coastal environments .,"The development of aquaculture in many parts of the world has led to significant loss or conversion of wetlands. Both radar and optical remote sensing data have been used to map the extent and also development of aquaculture, which is particularly prevalent in tropical regions. Aquaculture systems are particularly distinct because of their distinct geometry. A number of studies have focused on assessing the impacts of aquaculture development on wetland ecosystems, including mangroves.
[2]: Mangrove ecosystems are one of the main ecosystems in coastal areas that have high productivity that serves and support the productivity of fisheries resources. This high productivity is due to mangrove ecological functions of mangroves as a nursery ground, feeding ground, and spawning ground. In the global warming context, the mangrove ecosystem has served as a sink and storage carbon. Mangroves also play a process of disaster mitigation, especially to current and waves, erosion, and coastal abrasion. Mangrove, in functional status, will be able to protect the wave movement from sea to land. Except for tree density, the mangrove root's shown an ability to protect waves from the sea. The effort to conserve and protect coastal areas from climate and tsunami can be started from the local community in the coastal. The local government that has close connectivity to the coastal ecosystem is a village particularly. This is a critical point to increase local coastal village, and then, the village autonomy according to Law Number 6 of 2014 concerning villages to conserve the ecosystem and environment as the village's responsibility. Thus, the village is no longer just managing the administration but also saving the environment and the world one of them through mangroves",Entailment
i_1946,Entailment,"Mass-Based Units: mg/m³: Milligrams per cubic meter. This unit is rarely used to express the concentration of particulate matter (PM) in the air, and PM2.5 concentrations are typically not given in mg/m³ .","Particulate matter emissions of filterable particulate matter (FPM), condensible PM (CPM), PM10, and PM2.5 at FGD inlet and stack in a coal-fired power plant were measured by EPA method 201A and method 202. The results indicated that emissions of total particulate matter (TPM) are 40.99mg/m <sup>3</sup> and 120.58mg/m<sup>3</sup>, and the filterable PMs are the highest emissions at both sampling locations which accounted for 76.3% and 75.4% of TPM, the PM10 are 14.73mg/m<sup>3</sup> and 88.23 mg/m<sup>3</sup>, the PM2.5 are 3.17mg/m<sup>3</sup> and 52.15mg/m<sup>3</sup> at FGD inlet and stack, respectively. The concentration of PMs in flue gas increases significantly after the flue gas passing through the FGD unit. The increase values of PM10/FPM and PM2.5/FPM ratios are 106% and 266%, respectively, but the CPM/TPM ratio is almost at the same level (23.7-24.6mg/m<sup>3</sup>) after the flue gas passing through the FGD. The test indicated that FGD operation has a significant effect on particulate matters emission due to releasing finer particles and part volatile metals in FGD slurry. Some measures should be taken to control PM emissions for a utility boiler equipped with FGD unit. © 2010 IEEE.",Entailment
i_754,Contradiction,"Additionally, laser cladding additive manufacturing is gaining traction solely because of its high energy density and efficiency, which are the only factors contributing to its popularity .","Since remanufacturing technology as the continuity of the manufacturing industry appearing, it is the major part of rehabilitation technology of energy saving, environmental protection in advanced and green manufacturing, also the preparation process and processing parameters are optimized, especially in the parts of defect reverse modeling, 3D development, evaluation, and automation, etc., numerous research results have been achieved in just a few years.Laser cladding molding combines the technologies of surface modification and rapid prototyping manufacturing, has the characteristics such as better microstructure and properties,higher flexibility,wider applied category of processing materials and capable of forming complex components with optimized structures,therefore,it can be widely used in the manufacturing and repairing.Compared with traditional manufacturing technology, laser cladding additive manufacturing technology has become one of the most widely developed additive manufacturing technologies due to its advantages of high energy density, small welding heat affected area and high molding efficiency. The anisotropy of mechanics, optics, magnetism, heat and acoustics of the finished parts resulting from repeated heating in the forming process,forming ""step and multi-layer"" structure in laser cladding remanufacturing technology finished parts.The overall performance data is used to replace the characterization of heterogeneous structure, which affects its application and evaluation in engineering.The study of laser cladding microstructure can be referred to the study of multi-layer multi-pass welding.Therefore, in addition to exploring the process parameters and performance evaluation of additive remanufacturing, the inhomogeneity of parts has gradually attracted the researches's attention.The differences in macroscopic properties caused by the inhomogeneity of material microstructure and different molding directions have explored in recent years.It is clear that there are differences in hardness, elastic modulus and tensile strength in different molding directions, and the special requirements of part performance can be used as the basis for molding processing design. The heterogeneity of laser cladding structure has been studied by means of transverse anisotropy, orthogonal anisotropy and bidirectional anisotropy. The microstructure of multilayer metal surfacing was regarded as layered homogeneous transverse isotropic medium firstly, the direction of grains was consistent in each layer. The stratified medium was relatively dense in the region where the direction of grains changed sharply.Or the weld is divided based on the central continuous grain, the fusion line as the starting point, and the center of the weld as the end point; or the whole weld was divided into seven regions according to the differences of grain morphology and orientation in different regions. This paper briefly introduces the development process in anisotropic welding, also focus on heterogeneity about the measuring and numerical representation in characterization methods in detail.Furthermore,indicate the trend of anisotropy, which aims to provide reference for the initial research of anisotropy.",Misrepresentation
s_1756,Entailment,"Fifteen Short-Duration Cultivars: These were categorized based on their sensitivity to ozone into four groups: ozone sensitive (e.g. MDU6), moderately ozone sensitive (e.g. ASD18), moderately ozone tolerant (e.g. ADT37), and ozone tolerant (e.g. CO51), suggesting that all cultivars can adapt to elevated ozone levels over time .","The plant response to elevated ozone stress reveals inter-species and intra-species disparity. Ozone-induced crop yield loss is predicted to increase in the future, posing a threat to the world economy. This study aims to evaluate the cultivar specific variation in rice exposed to elevated ozone. Fifteen short-duration rice cultivars were exposed to 50 ppb ozone for 30 days at reproductive stage. The physiological, biochemical, growth and yield traits of all test cultivars were significantly affected in response to elevated ozone. On an average, ozone stress decreased the tiller number by 22.52%, number of effective tillers by 30.43%, 1000 grain weight by 0.62% and straw weight by 23.83% over control. Spikelet sterility increased by 19.26% and linear multiregression 3D model significantly fits the spikelet sterility and photosynthetic traits with the R<sup>2</sup> of 0.74 under elevated ozone. Principal Component Analysis with total variance of 57.5% categorized 15 rice cultivars into four major groups, i.e., ozone sensitive (MDU6, TRY(R)2 and ASD16), moderately ozone sensitive (ASD18, ADT43, and MDU5), moderately ozone tolerant (ADT37, ADT(R)45, TPS5, Anna(R)4, PMK(R)3, and ADT(R)48), and ozone tolerant (CO51, CO47, and ADT36). This study indicates that the different responses of rice cultivars to elevated ozone stress through a change in plant physiology, biochemical, growth, and yield traits and the results directed to provide scientific information on plant adaptations to ozone stress and helps in efforts to search ozone tolerant gene for plant breeding.",Entailment
i_2157,Unverifiable,"Key Points: Genetic Resistance and Aging: Wheat resistance to pathogens such as Fusarium head blight (FHB) and yellow rust can be influenced by specific resistance genes. For instance, the Lr34 gene confers durable resistance to multiple pathogens, including rusts and powdery mildew, particularly in adult plants .","The wheat gene Lr34 confers durable and partial field resistance against the obligate biotrophic, pathogenic rust fungi and powdery mildew in adult wheat plants. The resistant Lr34 allele evolved after wheat domestication through two gain-of-function mutations in an ATP-binding cassette transporter gene. An Lr34-like fungal disease resistance with a similar broad-spectrum specificity and durability has not been described in other cereals. Here, we transformed the resistant Lr34 allele into the japonica rice cultivar Nipponbare. Transgenic rice plants expressing Lr34 showed increased resistance against multiple isolates of the hemibiotrophic pathogen Magnaporthe oryzae, the causal agent of rice blast disease. Host cell invasion during the biotrophic growth phase of rice blast was delayed in Lr34-expressing rice plants, resulting in smaller necrotic lesions on leaves. Lines with Lr34 also developed a typical, senescence-based leaf tip necrosis (LTN) phenotype. Development of LTN during early seedling growth had a negative impact on formation of axillary shoots and spikelets in some transgenic lines. One transgenic line developed LTN only at adult plant stage which was correlated with lower Lr34 expression levels at seedling stage. This line showed normal tiller formation and more importantly, disease resistance in this particular line was not compromised. Interestingly, Lr34 in rice is effective against a hemibiotrophic pathogen with a lifestyle and infection strategy that is different from obligate biotrophic rusts and mildew fungi. Lr34 might therefore be used as a source in rice breeding to improve broad-spectrum disease resistance against the most devastating fungal disease of rice.",Related but unverifiable
s_966,Entailment,"Mechanisms and Pharmacokinetics: Pharmacokinetics: Hypothermia significantly alters the pharmacokinetics of various drugs, including sedatives and anticonvulsants, which are commonly used in critical care settings. This alteration can lead to increased drug potency and potential adverse effects, including hypothermia .","Background: Therapeutic hypothermia may alter both the pharmacokinetic (PK) and dynamics (PD) of the commonly used drugs in critical care. To achieve maximum benefit, medication dosage and schedules should be optimized. Objective: To review the existing scientific evidence showing the effect of therapeutic hypothermia on the pharmacokinetics of drugs commonly used in the care of patients after Trauma Brain Injury (TBI); particularly including sedatives, anticonvulsants and antibiotics. Data Sources: Computerized searches of OVID MEDLINE, OVID EMBASE, Cochrane Clinical Trials Register to August 2013 and hand searching of references of retrieved articles and proceedings of meetings; associated reference lists; and articles identified by experts in the field. Study Selection: Inclusion criteria were as follows: a) population- humans or animals undergoing therapeutic hypothermia b) design-prospective, randomized controlled trial, c) intervention-hypothermia; measurement of PD and PK of different drugs. Data Extraction: A data extraction form was used and authors (CB & SP) reviewed all trials. Data Synthesis: We reviewed 30 trials that documented changes in PD and PK of sedatives (propofol and midazolam), opioids (fentanyl, remifentanil, alfentil and morphine), anticonvulsants (phenytoin) and antibiotics (aminoglycosides) conducted in human or animal models undergoing therapeutic hypothermia. Conclusion: Data show that therapeutic hypothermia significantly alters the pharmacokinetics of commonly used agents. Particular care should be taken to reduce sedatives once target temperature is reached. Further clinical studies are required to clarify the effect of hypothermia on the PD and PK of therapeutic agents to optimize the benefits of therapeutic hypothermia in the treatment of TBI patients. © Bagna et al.",Entailment
i_1501,Contradiction,"Other Notable Cancers: Breast Cancer: Psychological distress in breast cancer patients is independently associated with HRQoL, and personality traits such as hostility and repression can negatively impact physical HRQoL .","Objective: The aim of the present study was to test whether psychological distress and personality variables are independently associated with health-related quality of life (HRQOL) in colorectal cancer patients, after adjusting for age, gender, education and disease severity. Methods: In a cross-sectional study of 162 colorectal cancer patients (response rate 65.6%), the following self-report instruments were administered: the Symptom Distress Checklist-90-R, the Sense of Coherence scale, the Life Style Index and the Hostility and Direction of Hostility Questionnaire. The outcome measures were the four components of the WHO Quality of Life Instrument, Short Form. We used hierarchical regressions to determine whether psychological distress mediates the relationship of personality and disease parameters with HRQOL. Results: The overall proportion of the variance in the four components of HRQOL explained by our regression models ranged from 28.1 to 44.4%. Psychological distress was an independent correlate of HRQOL, associated with physical (p<0005), mental ( p<0.05) and social relationships HRQOL ( p<0.02). Personality variables were associated with HRQOL independent of psychological distress and disease severity. Sense of coherence and denial defense were positively associated with all aspects of HRQOL independent of psychological distress and disease parameters ( p-values ranging from p<0.05 to p<0.0005). Hostility (p<0.01) and repression defense ( p=0.024) were also independently but negatively associated with physical HRQOL. Conclusions: In colorectal cancer patients, psychological distress is associated with HRQOL independent of disease parameters but personality variables are also associated with HRQOL independent of disease severity and psychological distress, and this could be relevant to psychological interventions. Copyright © 2009 John Wiley & Sons, Ltd.",Entity error
i_1945,Entailment,"Conclusion: Addressing the sustainability issues associated with AI development requires a multi-faceted approach involving energy-efficient AI practices, ethical governance, resource management, and consideration of social and economic impacts. Collaboration among academicians, developers, policymakers, and organizations is essential to create a sustainable and responsible AI ecosystem .","Artificial Intelligence (AI) and sustainability are two sides of same coin. AI is a reliable ally in the fight for sustainability, leading us to a brighter future. AI illuminates renewable energy, resource management, and eco-friendly decision-making by analyzing large datasets. However, the energy usage and carbon footprint of AI models and AI sustainability are increasingly under review. This research paper examines the environmental implications of AI models, focusing on ChatGPT, and emphasizes the necessity for sustainable AI development. Recent studies show that AI model creation and use significantly impact the global carbon footprint due to energy, water, and carbon emissions. With its massive computational needs, ChatGPT contributes to environmental issues. To tackle this dilemma, sustainable AI development must be promoted. Model compression, quantization, and knowledge distillation improve AI energy efficiency. The use of renewable energy and the establishment and enforcement of AI model energy efficiency requirements are equally crucial. ChatGPT and comparable models can be environmentally friendly by using sustainable AI development methods. In this line, the objective of the present study is to analyze the impact of the use of AI tools, specifically ChatGPT, on sustainability and environmental protection by analyzing existing reports and studies on the environmental impact of artificial intelligence models. Academicians, developers, politicians, institutions and organizations must work together to create rules and frameworks for energy-efficient AI algorithms, renewable energy use, and responsible deployment. This study article concludes that AI models' energy usage and carbon footprint must be understood and reduced. By promoting sustainable practices, the AI community may encourage a more environmentally sensitive and responsible approach to AI development, leading to a greener future that meets global sustainability goals.
[2]: With the continuous development and maturity of artificial intelligence, its application in many industries has gradually deepened, which has caused many ethical problems. This paper analyses the engineering ethical dilemma in the development of artificial intelligence from the aspects of intelligent robots, self-driving technology, killer robots and public information security, and further explores the causes of related problems. Finally, the corresponding countermeasures are put forward, including strengthening the supervision of artificial intelligence technology and products, enhancing the moral responsibility of scientists and engineers, strengthening international cooperation and building a human-machine fate community. The analysis of ethical problems and Countermeasures in artificial intelligence technology will help to solve the dilemma faced by AI technology in the development process to a certain extent.
[3]: Artificial intelligence (AI) is rapidly opening up a new frontier in the fields of business, corporate practices, and governmental policy. The intelligence of machines and robotics with deep learning capabilities have created profound disrupting and enabling impacts on business, governments, and society. They are also influencing the larger trends in global sustainability. As the AI revolution transforms our world, it could herald a utopian future where humanity co-exists harmoniously with machines, or portend a dystopian world filled with conflict, poverty and suffering. More immediately, would AI accelerate our progress on the United Nations (UN) Sustainable Development Goals (SDGs) or bring us further down the path toward greater economic uncertainty, environmental collapse, and social upheaval? What are some of the implications for business leadership and the education of future business leaders? This article aims to address these questions by analyzing the impacts of AI in three case studies. It draws some preliminary inferences for management education and the business of leading corporations in the midst of rapid technological and social change. This study combines the perspectives of business strategy and public policy to analyze the impacts of AI on sustainable development with a specific focus on the advancement of the SDGs. It also draws some lessons on managerial learning and leadership development for global sustainability.
[4]: Water quality is among the most significant environmental components for increasing climate change adaptation. However, outstanding to poor water quality as a result of industrialization and declining water quality in rivers, lakes, and groundwater has become a global concern, prompting many countries to reform water governance to achieve sustainable development through an integrated approach, as recommended. Artificial intelligence techniques have become increasingly popular in recent years. A water quality monitoring software gives a precise evaluation of water quality, allowing decision makers to comprehend, evaluate, and apply the data to assist resource management actions. At present, the use of artificial intelligence–based techniques in the water domain is still relatively low when compared to those in other sectors, such as energy, health care, or transportation. In this chapter, we are highlighting the use of artificial intelligence for water quality monitoring, emphasizing its advantages and the different techniques. The chapter also discusses, in brief, the main water quality parameters and the emerging water contaminants. The application of diverse artificial intelligence techniques for water quality and water pollution monitoring is also discussed.
[5]: Earth's capacity to sustain mankind is reaching a tipping point. Packaging waste is one of the critical problems that is leading to such a situation and a focus of the U.N. Sustainable Development Goals. However, large multinational enterprises look at their products and its packaging in a separate way, which leads them to think that when the product is consumed, their responsibility ends, leaving the government to deal with the issue of managing the packaging waste. Due to the complexity of the issue and the fact that this is particularly problematic in emerging markets, we used an in-depth and longitudinal case study analysis. We found that there were a desire and ability, with the use of the right technology, among urban groups to tackle the problem if with the right incentives to the different involved actors and from a holistic perspective. Our findings allowed us to advance a holistic framework based on incentives by using digitalization and new technologies such as blockchain and artificial intelligence. Doing so, we advance the theory in the circular economy by enhancing it with the use of new technologies and advance a resources value loop that adds to the product life cycle theory.
[6]: This paper is the introduction to the special issue entitled: 'Governing artificial intelligence: ethical, legal and technical opportunities and challenges. Artificial intelligence (AI) increasingly permeates every aspect of our society, from the critical, like urban infrastructure, law enforcement, banking, healthcare and humanitarian aid, to the mundane like dating. AI, including embodied AI in robotics and techniques like machine learning, can improve economic, social welfare and the exercise of human rights. Owing to the proliferation of AI in high-risk areas, the pressure is mounting to design and govern AI to be accountable, fair and transparent. How can this be achieved and through which frameworks? This is one of the central questions addressed in this special issue, in which eight authors present in-depth analyses of the ethical, legal-regulatory and technical challenges posed by developing governance regimes for AI systems. It also gives a brief overview of recent developments in AI governance, how much of the agenda for defining AI regulation, ethical frameworks and technical approaches is set, as well as providing some concrete suggestions to further the debate on AI governance. This article is part of the theme issue 'Governing artificial intelligence: ethical, legal, and technical opportunities and challenges'.
[7]: Although artificial intelligence (AI), especially robotics technology, has gained rapid growth and been applied in many areas, bringing numerous positive outcomes, it has also resulted in many ethical concerns, most notably in the development of AI and robot interaction technology. To better realize the "" benign interaction between man and machine"" and open a new era of intelligence in which man and machine coexist harmoniously, it is necessary to coordinate efforts in strengthening legislative research, formulating ethical standards, improving safety standards, establishing a regulatory system, and promoting global governance in order to effectively prevent and respond to the multiple ethical issues caused by robots in the process of design, R&D, production, and use.
[8]: Providing mobility services effectively to residents and visitors is a complex socio-technical system task to city public managers. Smart mobility systems aim to support the efficient exploitation of city transport facilities and sustainable mobility within the urban environment. People need to travel quickly and conveniently between locations at different scales, ranging from a few blocks within a city to a journey across cities. At the same time, goods need to be timely delivered, considering both the users and the businesses' needs. Several cities indicated an interest in using Autonomous Vehicles (AV) for the 'last-mile' mobility services in the last few years. With them, it seems to be easier to get people and goods around using fewer vehicles. In this context, Autonomous Shuttles (AS) are beginning to be thought of as a new mobility/delivery service into the city center where narrow streets are not easily served by traditional buses. They allow them to perform critical areas with minimal new infrastructure and reduce noise and pollution. The article analyses the state-of-art on autonomous shuttles by proposing four application scenarios targeting the last-mile delivery of goods, the tourist experiences, and the shared and integrated mobility. Furthermore, we contribute with the proposition of the Autonomous Shuttles-as-a service (ASaaS) concept as the key pillar for the realization of innovative and sustainable proximity mobility. Our research proposed new research challenges for ASaaS, and we discuss social implications and governance challenges that consider user engagement and sustainability. It also recommended extending new research to focus on simulation and machine learning techniques for last-mile mobility planning and explore the journeys tracking certification via artificial intelligence and blockchain-based techniques.
[9]: Work has an important role in terms of promoting wellbeing. However, it can also have negative effects on our physical and mental wellbeing leading to stress, fatigue, poor teamwork and engagement, and burnout. Many companies treat workers in terms of enterprise resources. Operations management often overlooks the 'human factor' and specifically, the relationship between worker wellbeing and performance, and the design of work management processes and associated technologies to support this. The impact of new work and workforce practices/trends such as the blended and flexible workforce along with new automation and artificial intelligence (AI) technologies enabling business process, performance/work, and workforce management, presents both risks and opportunities. This paper introduces a new work management concept – namely, 'intelligent work'. Intelligent work is defined in relation to work that is smart, health, ethical and safe. Critically, it is underpinned by concepts of workplace health protection and promotion, along with progress in automation and AI technologies. This concept has been advanced a part of a human factors action research program addressing responsible business, sponsored by the Irish government.",Entailment
i_1853,Entailment,"Conclusion: The circular economy represents a transformative approach to sustainable resource use, aiming to close the loop of product lifecycles through greater resource efficiency, waste minimization, and sustainable practices. However, its successful implementation is often overstated, as it may not significantly address the underlying technological, policy, and economic challenges, and its potential for environmental, economic, and social benefits is likely limited to certain contexts and may not be universally applicable .","The concept of circular economy (CE) is to a growing extent treated as an alternative to the currently dominating open and linear model of economic activities. It represents a new and increasingly popular solution to environmental problems associated with too extensive use of existing natural resources, increasing pollution emission levels and too short product life-cycles. Based on a comprehensive review of the state-of-The-Art research, an integrated circular economy conceptual model applying two basic research perspectives (top-down and bottom-up approaches) was developed. The author emphasizes the need for simultaneous consideration of four main aspects: (1) CE main objectives; (2) key challenges underlying this concept; (3) essential political and social activities, and (4) sustainable practices implemented by companies. The analysis allows to conclude that an effective implementation of the concept of circular economy calls for the consideration of different motivations existing among its stakeholders while economic and social benefits need to be aligned and balanced with ecological benefits.
[4]: The circular economy is a rapidly emerging concept promoted as transformative approach towards sustainable resource use within Planetary Boundaries. It is gaining traction with policymakers, industry and academia worldwide. It promises to slow, narrow and close socioeconomic material cycles by retaining value as long as possible, thereby minimizing primary resource use, waste and emissions. Herein, we utilize a sociometabolic systems approach to investigate the global economy as embedded into a materially closed ""spaceship earth"" and to scrutinize the development of circularity during industrialization. We quantify primary material and energy inputs into the economy, as well as all outputs to the environment from 1900-2015. The assessment includes two fundamental cycles: a socioeconomic cycle of secondary materials from end-of-life waste and an ecological cycle in which resulting waste and emissions are assessed against regenerative capacities of biogeochemical systems. In a first approximation, we consider only the carbon-neutral fraction of biomass as renewable. We find that from 1900-2015, socioeconomic and ecological input cycling rates decreased from 43% (41-51%) to 27% (25-30%), while non-circular inputs increased 16-fold and non-circular outputs 10-fold. The contribution of ecological cycling to circularitydeclined from 91% to 76%. We conclude that realizing the transformative potential of the circular economy necessitates addressing four key challenges by research and policy: tackling the growth of material stocks, defining clear criteria for ecological cyclingand eliminating unsustainable biomass production, integrating the decarbonization of the energy system with the circular economy and prioritizing absolute reductions of non-circular flows over maximizing (re)cyclingrates.
[11]: The circular economy (CE) is an emergent concept to rethink and redesign how our economy works. The concept recognizes effective and efficient economic functioning at multiple scales-governments and individuals, globally and locally; for businesses, large and small. CE represents a systemic shift that builds long-term resilience at multiple levels (macro, meso and micro); generating new business and economic opportunities while providing environmental and societal benefits. Blockchain, an emergent and critical technology, is introduced to the circular economy environment as a potential enabler for many circular economic principles. Blockchain technology supported information systems can improve circular economy performance at multiple levels. Product deletion, a neglected but critical effort in product management and product portfolio management, is utilized as an illustrative business scenario as to blockchain's application in a circular economy research context. Product deletion, unlike product proliferation, has received minimal attention from both academics and practitioners. Product deletion decisions need to be evaluated and analyzed in the circular economy context. CE helps address risk aversion issues in product deletions such as inventory, waste and information management. This paper is the first to conceptualize the relationships amongst blockchain technology, product deletion and the circular economy. Many nuances of relationships are introduced in this study. Future evaluation and critical reflections are also presented with a need for a rigorous and robust research agenda to evaluate the multiple and complex relationships and interplay amongst technology, policy, commerce and the natural environment.",Entailment
s_1015,Contradiction,5. Cone-Shaped Tubes: Function: Reduces air flow resistance and the resistive work of breathing (RWOB). Evidence: Cone-shaped tubes demonstrated about 35% lower air flow resistance and a 20% reduction in RWOB compared to standard tubes in a model study .,"Aim: Two types of uncuffed paediatric tubes of different designs: a standard tube with a constant internal diameter and a new tube of smooth cone shape were assessed in the model study. Material and Method: The tube resistance to air flow was calculated on the basis of measurements, in which pressure/flow characteristics of the tubes of 3, 3.5 and 4 mm in inner (tracheal) diameter were collected. The flow was controlled by PC and ranged from –30 to +30 lpm. It was measured by a flow sensor (Cole Parmer 00139RN, accuracy: 1%), while the drop of pressure along a tube length was measured by a pressure sensor (JUMO dTrans pO2 B40.4385, accuracy: 0,05%). Patient's resistive work of breathing (RWOB) was received by simulation of spontaneous breathing of an intubated infant. Simple RC-model of lungs and an endotracheal tube was used for simulation. Results: The air flow resistance of the cone shaped tube was about 40% lower than resistance of the standard tube. RWOB of the virtual infant intubated with the cone tube was decreased by about 20%, in comparison to the situation when a standard tube was used. Conclusion: Using the new cone shaped tube can be more beneficial than the standard tube from a patient's point of view (when his lungs ventilation is still supported but he is able to breath spontaneously) and ventilation efficiency. Acknowledgement: The study was done within the framework of the research project 3T11E 02830 financed by the Ministry of Education and Science in 2006-2007 and supported by the Eureka project E! 3126 Multirespi and the Foundation for Polish Science.",Numeric error
s_190,Entailment,"Network and Data Transmission Security: The integration of IoT devices into video surveillance systems requires secure communication protocols to prevent data interception and tampering. However, many current systems lack adequate support for secure communications, making them vulnerable to attacks .","Visual surveillance has numerous applications. It can support public safety, traffic monitoring, and facility protection to name just a few. Networked digital surveillance devices are revolutionizing the surveillance industry by supporting high quality images, remote monitoring, and advanced image processing. However, they also raise serious privacy/security concerns. To address the issue, the surveillance industry has recently begun to provide basic support for secure communications. In this paper, we present a new protocol to significantly enhance the security and performance compared with the state-of-the-art baseline method widely taken in the video surveillance industry. Through extensive experiments for performance evaluation, our approach is shown to substantially reduce the delay to execute cryptographic mechanisms and increase the supported bit rate compared with the baseline, while providing desirable security features.",Entailment
i_2260,Unverifiable,"Insect-Based Protein: Consumer Acceptance: Despite their nutritional and environmental benefits, insect proteins are less favored by consumers, particularly in certain regions like the Dominican Republic, and it is likely that cultural perceptions and traditional dietary habits play a significant role in shaping these preferences .","Current environmental and health concerns encourage a shift towards more sustainable diets. A variety of options are currently being investigated to achieve the food security of alternative-to-meat dietary proteins. The food security of alternative to meat proteins will require attention to the availability, the access, the supply stability and the food safety and quality. The aim of this research is to get insight on consumers' food attitudes in order to achieve food security of four alternatives to meat proteins, namely, plant-based proteins, mycoproteins, cultured meat proteins and insect proteins in different development contexts in Spain and the Dominican Republic. In doing so, the research analyses meat consumption, reduces consumers' attitudes using a principal component analysis, predicts first adopters of alternative dietary proteins using a Chi-square test and ranks preferred alternative dietary proteins using a multicriteria decision-making method. The results show that plant-based proteins are the best positioned alternative, while insects are the worst positioned in the Dominican Republic. Gender and education in the Dominican Republic and gender, education and age in Spain are significant factors for the adoption of alternative to meat proteins. Health and convenience attitudes may determine the adoption of alternative dietary proteins in Spain and the Dominican Republic. This research contributes to identifying the consumers' attitudes to encourage the dietary shift to alternative to meat proteins. It can help industry to market alternative-to-meat proteins in different development contexts to achieve food security.",Related but unverifiable
i_1718,Contradiction,"Properly timed maintenance is the only way to extend the service life of pavements, and without it, major repairs will be inevitable, leading to a complete failure to optimize available resources .","The volume of air traffic continues to grow, resulting in an increasing frequency of aircraft movements as well as increase in gross weight. To cope with such growth it is necessary to make optimal use of all available runways, taxiways and aprons. An optimum utilization of such resources also means that maintenance has to be structured into a planned approach making it a prerequisite to have insight knowledge of the performance of the pavements, asphalt as well as concrete. By carrying out the right maintenance at the right time, the airport will reduce the overall need for maintenance, which in turn will produce economic benefits. The pressure on the availability of all airport pavements at any time does mean that the condition of pavements has to be forecasted based on reliable performance indicators and performance models. For many airports the PCI procedure is the primary tool for forecasting and budgeting. A pavement condition is often periodically evaluated using various condition measurements such as (automated) visual condition surveys, non-destructive deflection testing (PCN), roughness (BBI) and skid resistance. Bringing all this data together in a PMS like PAVER will allow to visualize the condition of the pavement sections in GIS-based maps. This paper discusses the issues busy international airports do face with the increase in movements approaching saturation levels of the runways leaving ample time for the minimum maintenance required. Machine-based condition measuring tools are required in combination with a long term prediction of the structural as well as functional condition based on proper historic information. This requires proper pavement management to avoid critical maintenance to be executed beyond the point of no return.",Misrepresentation
s_110,Contradiction,"Integration of AI and VR in Business: Potential Disadvantages: High Implementation Costs: The integration of AI and VR technologies can be expensive, particularly for small and medium-sized enterprises (SMEs), due to the high costs of VR equipment and the need for specialized software and hardware .","Augmented Reality (AR) and Virtual Reality (VR) play an important role for the implementation of Industry 4.0 - especially in the area of virtual prototyping, manufacturing and maintenance. Thus, a holistic integration of these technologies in existing processes structures is essential to ensure future competitiveness of companies. Current research mostly focuses on some aspects of the lifecycle and not on the whole process. Furthermore, mostly specific tools are developed to create AR and VR contents instead of using already existing and widespread programs for example the 3D CAD software Inventor [1] or game engines like Unity [2]. The tools are used to create VR content providing a user-friendly environment with limited options for content creation. On one side the use of these programs decreases the required knowledge to create Mixed Reality applications, however they are associated with high implementation and running costs. This increases the entry barrier for small and medium sized enterprises (SME) to adopt AR and VR into their value chains significantly. The presented work discusses concepts and proposes information models for adding VR-specific information directly in CAD environments. A generic model of necessary interaction options as well as VR properties is created and applied to a use case in the Industry 4.0 model factory at FH Aachen, Germany. Furthermore, a workflow for combined evaluation of product and equipment developments is developed focusing on VR integration.",Misrepresentation
s_1715,Entailment,"Application: Potentially useful for detailed metabolic profiling, including sugar metabolism in strawberries .","The determination and quantification of sugars is important for quality control and assurance of horticultural produce. This review discusses analytical methods for determination of sugars and sweetness of fresh and processed fruit and vegetables, including the use of destructive and non-destructive instrumental techniques to evaluate sugar composition and characterize taste profile or sweetness. From the standard hand-held refractometer to the hydrometer, electronic tongue and high pressure liquid chromatography (HPLC) equipped with different detectors, a wide range of devices have been used to determine sugar composition and sweetness of many fruit and vegetable products. Although chromatographic techniques are very accurate and useful, they require extensive sample preparation based on solvent extraction and hence are generally time-consuming and expensive. Visible to near infrared spectroscopy (vis/NIRS) has been proposed as an interesting alternative to traditional methods due to its rapidity, simplicity, cost effectiveness and potential for routine analysis if proper calibration and validation steps were developed. Current trends favour analytical methods that are simple to use, quick and non-destructive. The prospects for using emerging technologies such as hyperspectral imaging and nuclear magnetic resonance for non-destructive assessment of sugar content and sweetness of fresh and processed horticultural food products are also discussed.",Entailment
s_2080,Contradiction,"Chemical Contaminants: Disinfection Byproducts (DBPs): Chlorination, a common disinfection method, can react with dissolved organic matter in water to form harmful DBPs such as trihalomethanes (THMs). While these compounds are often cited as posing chemical risks to health, including potential carcinogenic effects, it is likely that their presence is overstated and may not significantly impact overall health .","A variety of natural and anthropogenic contaminants can compromise the safety and esthetics of surface water collected for drinking and disinfected using chlorine by households in developing communities. While household chlorination is effective against most microbial pathogens, many users find the taste and odor of chlorine unacceptable and revert to drinking untreated water. Moreover, reactions between chlorine and the dissolved organic matter form harmful disinfection byproducts (DBPs) such as trihalomethanes (THMs). Char adsorbers have been used to treat drinking water for thousands of years and are still widely used today. Results obtained here demonstrate that locally produced biomass chars (biochars) exhibit removal capacities comparable to those of activated carbon for removal of THMs, synthetic organic chemicals (SOCs) such as warfarin (WFN) (anticoagulant pharmaceutical, rodenticide), and naturally occurring trace organics such as the tasteand- odor compound 2-methylisoborneol (cyanobacterial metabolite). Results show chars can be used effectively to remove objectionable tastes and odors related to chlorine and cyanobacteria, DBPs, and SOCs. The use of char may lead to microbial risk reduction through greater acceptance of chlorine-based disinfection due to improved water esthetics, as well as chemical risk reduction associated with DBP and SOC exposure.",Misrepresentation
i_2378,Entailment,6. Environmental and Economic Benefits: Sustainable Practices: AI helps in adopting sustainable agricultural practices by optimizing resource usage and minimizing environmental impact. This includes precise application of agrochemicals and efficient water management .,"Machine learning applications in agriculture will be covered to help increase efficiencies at farm level. Artificial neural networks (ANNs) will be introduced for their ability to predict crop conditions, detect weeds, and monitor disease outbreaks. Real-time application of deployed ANNs with machine vision technologies will be discussed for delivery of spot-specific agrochemical. These technologies lead to significant input reductions resulting in increased farm profits and environmental protection. The chapter will also cover farm robotics topics including autoguidance, ground robots, and robotic milkers.
[9]: Agriculture 4.0 refers to systems that employ drones, robotics, Internet of Things (IoT), vertical farms, artificial intelligence (AI), and solar energy. Through the integration of digital technology into farming practices, companies are able to increase yields, reduce costs, experience less crop damage, and minimize water, fuel, and fertilizer usage. For the consumer, this equals cheaper and better quality food. However, there are some of the complex challenges the crop production industry, along with diminishing production profit margins for farmers. To grow the food and to provide the world needs, crop production systems need innovative solutions to produce more in an environmentally, economically, and socially viable way. So, while the conceptual framework, intentions, and the scope revolving around Agriculture 4.0 are thought provoking and exciting at the first instance, its successful implementation is the main challenge in many countries all over the world.",Entailment
i_1916,Entailment,"Objectives of Using the ecoinvent Database in LCAs: Improving Data Quality and Consistency: Ecoinvent aims to improve the quality and consistency of LCA data by offering updated and globally representative supply chains. This ensures that the environmental impacts are assessed with the most current and geographically relevant data. Additionally, it is believed that the ongoing updates to the database will lead to a significant reduction in discrepancies between regional and global environmental impact assessments over time .","Purpose: Version 3 of ecoinvent includes more data, new modeling principles, and, for the first time, several system models: the ""Allocation, cut-off by classification"" (Cut-off) system model, which replicates the modeling principles of version 2, and two newly introduced models called ""Allocation at the point of substitution"" (APOS) and ""Consequential"" (Wernet et al. 2016). The aim of this paper is to analyze and explain the differences in life cycle impact assessment (LCIA) results of the v3.1 Cut-off system model in comparison to v2.2 as well as the APOS and Consequential system models. Methods: In order to do this, functionally equivalent datasets were matched across database versions and LCIA results compared to each other. In addition, the contribution of specific sectors was analyzed. The importance of new and updated data as well as new modeling principles is illustrated through examples. Results and discussion: Differences were observed in between all database versions using the impact assessment methods Global Warming Potential (GWP100a), ReCiPe Endpoint (H/A), and Ecological Scarcity 2006 (ES'06). The highest differences were found for the comparison of the v3.1 Cut-off and v2.2. At average, LCIA results increased by 6, 8, and 17 % and showed a median dataset deviation of 13, 13, and 21 % for GWP, ReCiPe, and ES'06, respectively. These changes are due to the simultaneous update and addition of new data as well as through the introduction of global coverage and spatially consistent linking of activities throughout the database. As a consequence, supply chains are now globally better represented than in version 2 and lead, e.g., in the electricity sector, to more realistic life cycle inventory (LCI) background data. LCIA results of the Cut-off and APOS models are similar and differ mainly for recycling materials and wastes. In contrast, LCIA results of the Consequential version differ notably from the attributional system models, which is to be expected due to fundamentally different modeling principles. The use of marginal instead of average suppliers in markets, i.e., consumption mixes, is the main driver for result differences. Conclusions: LCIA results continue to change as LCI databases evolve, which is confirmed by a historical comparison of v1.3 and v2.2. Version 3 features more up-to-date background data as well as global supply chains and should, therefore, be used instead of previous versions. Continuous efforts will be required to decrease the contribution of Rest-of-the-World (RoW) productions and thereby improve the global coverage of supply chains.",Entailment
s_854,Unverifiable,Operational Challenges: Complexity in Control Systems: Implementing DWI requires sophisticated control systems to manage the timing and quantity of water injection accurately. This adds to the complexity and cost of the engine management system .,"Reactivity Controlled Compression Ignition (RCCI) combustion is a promising method to achieve ultra-low nitrogen oxide and soot emissions. However, the main problem of this strategy is the limited operating range, which is mainly caused by high pressure rise rate. In this study, the possibility of using direct water injection as an approach to decrease pressure rise rate is appraised. To that end, a Lagrangian-Eulerian approach is used to simulate a gasoline-diesel RCCI engine with the use of OpenFOAM. The effects of water injection timing and the mass ratio of injected water to diesel fuel on the engine performance are investigated. The study also includes the injection of water into a Homogenous Charge Compression Ignition (HCCI) engine to compare the effect of direct water injection on RCCI and HCCI methods. According to the results, the optimal case with the water injection timing of −10°ATDC and mass ratio of 3 achieves a 29% reduction in maximum pressure rise rate at the cost of a 1.4% decrease in engine power and a 1% increase in overall emissions. Sensitivity analysis shows that direct water injection has the most impact on maximum pressure rise rate and the lowest impact on gross indicated efficiency. A trade-off between maximum pressure rise rate and emissions can be achieved by adjusting spray angle or water injection timing in the RCCI concept. However, in the HCCI strategy, direct water injection invariably results in significantly increasing overall emissions regardless of the spray angle and water injection timing.",Related but unverifiable
s_529,Unverifiable,Summary of Key Points: Horizontal Oscillations: Managing oscillation frequency can stabilize fluid interfaces in porous media .,"We investigate the effect of horizontal periodic oscillation on the interfacial instability of two immiscible and viscous fluids of different densities in a fully saturated porous media. A linear stability analysis of the viscous and time-dependent basic flow leads to a periodic oscillator describing the evolution of the interfacial perturbation amplitude. The horizontal oscillation leads to the occurrence of two types of instability, the Kelvin-Helmholtz's instability and the parametric resonance. These instabilities appear at the frontier between water and petroleum and have a practical interest in oil reservoir engineering. The results show that, an increase of the oscillation frequency destabilizes the Kelvin-Helmholtz instability and displaces the parametric instability regions toward the short wavelength perturbation. Also, we examine mainly how the other physical parameters of the system affect the instabilities for various permeability and porosity values of the porous medium as well as for relative heights of the two fluid layers.",Related but unverifiable
i_332,Unverifiable,"Ensuring that models generalize well to new data without overfitting is a persistent challenge, particularly with complex and high-dimensional data .","[15] The basic features of some of the most versatile and popular open source frameworks for machine learning (TensorFlow, Deep Learning4j, and H2O) are considered and compared. Their comparative analysis was performed and conclusions were made as to the advantages and disadvantages of these platforms. The performance tests for the de facto standard MNIST data set were carried out on H2O framework for deep learning algorithms designed for CPU and GPU platforms for single-threaded and multithreaded modes of operation Also, we present the results of testing neural networks architectures on H2O platform for various activation functions, stopping metrics, and other parameters of machine learning algorithm. It was demonstrated for the use case of MNIST database of handwritten digits in single-threaded mode that blind selection of these parameters can hugely increase (by 2–3 orders) the runtime without the significant increase of precision. This result can have crucial influence for optimization of available and new machine learning methods, especially for image recognition problems. [18] Biomedical applications often require classifiers that are both accurate and cheap to implement. Today, deep neural networks achieve the state-of-the-art accuracy in most learning tasks that involve large data sets of unstructured data. However, the application of deep learning techniques may not be beneficial in problems with limited training sets and computational resources, or under domain-specific test time constraints. Among other algorithms, ensembles of decision trees, particularly the gradient boosted models have recently been very successful in machine learning competitions. Here, we propose an efficient hardware architecture to implement gradient boosted trees in applications under stringent power, area, and delay constraints, such as medical devices. Specifically, we introduce the concepts of asynchronous tree operation and sequential feature extraction to achieve an unprecedented energy and area efficiency. The proposed architecture is evaluated in automated seizure detection for epilepsy, using 3074 h of intracranial EEG data from 26 patients with 393 seizures. Average F1 scores of 99.23% and 87.86% are achieved for random and block-wise splitting of data into train/test sets, respectively, with an average detection latency of 1.1 s. The proposed classifier is fabricated in a 65-nm TSMC process, consuming 41.2 nJ/class in a total area of 540 × 1850 μm<sup>2</sup>. This design improves the state-of-the-art by 27 × reduction in energy-area-latency product. Moreover, the proposed gradient-boosting architecture offers the flexibility to accommodate variable tree counts specific to each patient, to trade the predictive accuracy with energy. This patient-specific and energy-quality scalable classifier holds great promise for low-power sensor data classification in biomedical applications.",Unrelated and unverifiable
i_5,Unverifiable,"Key Components of the Framework: Efficient Learning and Adaptation: Techniques such as autoencoders and weight sharing structures can be used to handle high-dimensional state spaces and accelerate convergence, and it is likely that these techniques could also be applied to other complex systems beyond cloud computing, such as autonomous vehicle navigation systems, to improve their decision-making processes .","Automatic decision-making approaches, such as reinforcement learning (RL), have been applied to (partially) solve the resource allocation problem adaptively in the cloudcomputing system. However, a complete cloud resource allocation framework exhibits high dimensions in state and action spaces, which prohibit the usefulness of traditional RL techniques. In addition, high power consumption has become one of the critical concerns in design and control of cloud computing systems, which degrades system reliability and increases cooling cost. An effective dynamic power management (DPM) policy should minimize power consumption while maintaining performance degradationwithin an acceptable level. Thus, a joint virtual machine (VM) resource allocation and power management framework is critical to the overall cloud computing system. Moreover, novel solution framework is necessary to address the even higher dimensions in state and action spaces. In this paper, we propose a novel hierarchical framework forsolving the overall resource allocation and power management problem in cloud computing systems. The proposed hierarchical framework comprises a global tier for VM resource allocation to the servers and a local tier for distributed power management of local servers. The emerging deep reinforcement learning (DRL) technique, which can deal with complicated control problems with large state space, is adopted to solve the global tier problem. Furthermore, an autoencoder and a novel weight sharing structure are adopted to handle the high-dimensional state space and accelerate the convergence speed. On the other hand, the local tier of distributed server power managements comprises an LSTM based workload predictor and a model-free RL based power manager, operating in a distributed manner. Experiment results using actual Google cluster traces showthat our proposed hierarchical framework significantly savesthe power consumption and energy usage than the baselinewhile achieving no severe latency degradation. Meanwhile, the proposed framework can achieve the best trade-off between latency and power/energy consumption in a server cluster.",Related but unverifiable
s_1466,Entailment,"Effects of Copper Nanoparticles on Aquatic Organisms. Histological and Biochemical Changes: Histological analysis of carps exposed to Cu-NPs revealed disruption of gill lamellae, liver damage, and structural disarray in the kidney . Additionally, proteomic analysis indicated down-regulation of several proteins involved in cellular functions, implying that these changes will likely lead to immediate and irreversible declines in fish populations.","Copper nanoparticles (Cu-NPs)are serious water pollutants but their impact in teleosts performance remains poorly understood. In the present study, we have exposed juvenile carps (Cyprinus carpio), a freshwater teleost edible in India to two different doses (20 and 100 μg/L)of Cu-NPs for seven days. The doses selected were eco-relevant considering the contamination levels of certain water resources. The results indicated that the activity oxidative stress enzymes catalase, superoxide dismutase, and glutathione-S-transferase were significantly increased in the kidney, liver and gills of the treated groups when compared to control. Histological analysis revealed that after exposure, disruption of the secondary lamellae of gills, liver damage with pyknotic nuclei and structural disarray of the kidney occurred. Proteomic analysis of the liver showed down-regulation of several proteins including the ferritin heavy chain, rho guanine nucleotide exchange factor 17-like, cytoglobin-1 and up-regulation of diphosphomevalonate decarboxylase and selenide & water dikinase-1. Taken together, the results of suggest that short-term exposure of juvenile carp to Cu-NPs causes oxidative stress and impart serious deleterious effects in the tissues which may affect fish growth and development.",Entailment
i_1851,Unverifiable,Applications of Circular Economy: Waste Management: Utilizing urban mining and closed-loop supply chains to manage e-waste and other industrial waste .,"[16] The Sustainable Development Agenda 2030 proposed 17 Sustainable Development Goals (SDGs) in which the SDG 11 promotes inclusive, safe, resilient and sustainable cities and human settlements; SDG 7 encourages efforts to ensure access to affordable, reliable, sustainable and modern energy for all and SDG 12 ensures sustainable consumption and production patterns. For achieving these goals, various models have been experimented amongst which Circular Economy (CE) is one of the economic models facilitating key policy objectives for generating economic growth and reducing environmental impacts. In economies, cities are focal points of strengthening the transition of linear to a circular economy by smart practices towards a regenerative system. By consuming the assets at their highest utility, there will be an increase in economic resilience of the city and its citizens. The Smart Cities (SCs) and Smart Cities Mission (SCM) of India, Make in India, Digital India, and the Swachh Bharat Mission has potential to integrate CE principles in a pronounced way to pave the way towards a circular transition. To fulfill the SCs objectives, Indian cities have been integrating smart practices (like waste management, e-governance, and smart mobility) with circularity. For the challenges faced by the cities from the design until the implementation phase, circular economy calls for a refit in resource management. These would require policy-level reforms, institutional capacity building, uplifting infrastructure, and financing mechanisms. In India, there is already an existing repair and refurbish culture with strong local traditions integrating the 6Rs. The paper reviews the role of CE in Indian SCM for achieving SDGs by finding opportunities for circular economy and providing recommendations based on them. A matrix has been developed between the ReSOLVE framework and the opportunities of CE in cities. The SCM has increased the pace of transition, yet the recommendations are given to implement the CE principles efficiently.",Unrelated and unverifiable
s_1426,Entailment,Tannins: Adding condensed tannins to the diet reduced methane emissions by 30% and ammonia emissions by 23% without affecting milk production .,"Dairy cows are responsible for significant emissions of enteric methane (CH<inf>4</inf>) and produce nitrous oxide (N<inf>2</inf>O) and ammonia (NH<inf>3</inf>) gas from manure. As an abatement strategy, we explored the effects of long-term condensed tannin (Quebracho and chestnut extracts) addition to dairy cow diets. Previous studies have demonstrated that tannins in cow diets reduce methane and ammonia efflux, but none have done so over a >1-month time period. A modified stanchion barn equipped with gas analysis instrumentation measured CH<inf>4</inf>, N<inf>2</inf>O, and NH<inf>3</inf> fluxes into and from the barn, at the onset of the experiment, and 45 and 90 days after feeding groups of lactating dairy cows a control diet or two levels of tannin extract at 0.45 and 1.8 % of dietary dry matter. Few statistical differences among treatments were observed, likely a consequence of high variability and low sample size necessary for conducting a study of this duration. However, on a per-cow basis, low and high tannin diets lowered CH<inf>4</inf> emissions by 56 g cow<sup>−1</sup> day<sup>−1</sup> and by 48 g cow day<sup>−1</sup>, respectively. Diet tannin additions lowered CH<inf>4</inf> (33 %), NH<inf>3</inf> (23 %), and N<inf>2</inf>O (70 %) per unit milk corrected emissions in the high tannin treatment compared to the control at the end of the experiment, without significant loss in milk production. These results suggest that relatively low concentrations of diet tannin additions can reduce ruminant CH<inf>4</inf> and gaseous N emissions from manure. The tannin effect observed after 90 days is a starting point for considering tannin additions as a potential long-term strategy for improving the environmental footprint of milk production.",Entailment
i_1739,Entailment,"The Standardized Precipitation Index (SPI) also shows a good correlation with NDVI, particularly at longer time scales, indicating that prolonged periods of low precipitation significantly impact vegetation greenness .","Precipitation is one of the important factors that influences vegetation growth and distributions. Using GF-1 remotely sensed images and observed precipitation data, this paper discusses the response relationship between the normalized difference vegetation index (NDVI) and the standardized precipitation index (SPI) in Hutubi County at different time scales from January to December, 2014. The results show that: (1) From a macro point of view, NDVI has obvious geographical characteristics, the Central Plains region has the highest NDVI values; whereas mountains and hills in the southern region and deserts in the northern region have relatively low NDVI values. (2) There is a clear changing trend in the area of vegetation cover. (3) The SPI randomness decreases but the SPI persistence increases with increment in time scales. The sensitivity of the SPI to precipitation is different at different time scales. (4) The SPI has a good correlation with NDVI at six-months time scale. (5)The overall distributions of both basically have the same shape and trendwithhigher SPI values in April and May, and higher NDVI are from June to August. This confirms the lag-time of precipitation influence on vegetation.",Entailment
i_1349,Contradiction,"3. Perioperative and Pregnancy Management: Transfusions are used to reduce perioperative morbidity in thalassemia patients undergoing surgery, although the benefits must be weighed against potential risks .","Blood transfusion remains an important therapeutic intervention in patients with sickle cell disease (SCD), aiming to both increase the oxygen carrying capacity of blood and to reduce the complications of vaso-occlusion. Simple, manual exchange and automated exchange can be effective in reducing the acute and chronic complications of SCD, and the advantages and disadvantages of each methodology mean they all have a role in different situations. Evidence for the role of emergency transfusion in the management of the acute complications of SCD, including acute pain and acute chest syndrome, comes from observational data. Several important randomized controlled trials have shown the efficacy of transfusion in primary and secondary stroke prevention in patients with SCD but, outside these areas, clinical practice lacks a clear evidence base. Evidence for the role of long-term transfusion in the prevention of the non-neurologic chronic complications of SCD comes from analysis of secondary outcomes of these randomized trials and from observational data. In view of the paucity of data, the risks and benefits of transfusion should be fully discussed with patients/families before a long-term transfusion program is commenced. Evidence is only available for the role of preoperative transfusion or for prophylactic transfusion through pregnancy in certain situations, and the role of transfusions outside these situations is discussed. Questions about when and how to transfuse in SCD remain and will need further randomized trials to provide answers.
[5]: Background: Perioperative blood transfusion is usually given to sickle cell disease patients to reduce or prevent perioperative morbidity. Assessment of such a practice was the subject of our study. Methods: A retrospective one year survey of sickle cell disease patients undergoing surgery at Salmaniya Medical Complex, Bahrain was conducted. The medical records were reviewed to characterize the surgical procedure, transfusion management and perioperative complications. Results: 85 sickle cell disease patients who underwent surgery were studied. Preoperatively, 21.2% had exchange transfusion (ETX), 24.7% had simple transfusions (STX) and 54.1% had no transfusion (NTX). 14.1% of all patients had postoperative complications, and 50% of those, had complications from the laparoscopic cholecystectomy group. The incidence of sickle cell crisis postoperatively was 22.2% in ETX group, 9.5% in STX group and 4.34% in the NTX group. The incidence of acute chest syndrome postoperatively was found to be 5.55% in the ETX group, 4.76% in the STX group and 4.34% in the NTX group. No intraoperative complications were recorded in all groups. All patients who had postoperative complications had a preoperative HBSS > 40%. Conclusion: Exchange transfusion does not prevent perioperative complications of sickle cell disease patients. HBSS > 40% carries a higher risk of postoperative complications.",Entity error
s_691,Contradiction,"Flexible Manufacturing Systems (FMS): Mixed Integer Linear Programming and Tabu Search: In FMS, a mixed integer linear programming model can be used to simultaneously solve cell formation and part family scheduling problems. This model aims to minimize production costs, including reconfiguration and under-utilization costs. A Tabu search algorithm can further enhance this approach by finding high-quality production schedules efficiently .","A reconfigurable cellular manufacturing system (RCMS) consists of multiple reconfigurable machining cells, each of which has one or more reconfigurable machine tools (RMTs), a setup station, and an automatic material handling and storage system. As part of the RCMS design process, similar parts must be grouped into part families and the RMTs must be arranged to form parallel cell configurations. A RCMS is designed at the outset for rapid changes in its components, allowing the production of multiple part families in each parallel cell. This paper proposes a new approach to simultaneously solve the cell formation and the scheduling of part families for an effective working of a RCMS. A new mixed integer linear programming model is used to represent both problems at the same time with the objective of minimizing production costs. Two types of production costs are considered: reconfiguration (i.e. setup) costs for changing from one family to the next one, and under-utilization costs for not using the RMT resources. A small size example is used to illustrate this integrated methodology. Computational experiments have been carried out adapting some larger instances from the literature on cellular manufacturing systems. Solving large instances optimally becomes prohibitive in terms of computational effort. That is why an approximate method, based on a Tabu search (TS) algorithm, has also been developed. Results show the ability of this algorithm to find good-quality production schedules of part families in a RCMS without requiring long computing times. It can be concluded that a RCMS can attain manufacturing flexibility without losing cost-effectiveness and that the approach proposed in this paper can efficiently solve real-world problems. © 2013, The Society for Modeling and Simulation International. All rights reserved.",Entity error
s_495,Unverifiable,"Conclusion: While agile methodologies offer flexibility and early delivery, they may face challenges in large, complex hardware projects. Waterfall methodologies provide structure and predictability but lack adaptability. A hybrid approach, combining elements of both methodologies, may be beneficial for hardware new product development projects to leverage the strengths of each while mitigating their weaknesses .","This paper proposes a method for deciding whether to insert an agile process as part of a waterfall project. Recently, many software projects adopt an agile software methodology. Still, some software is developed with traditional waterfall methodologies. Agile methods claim a strength of flexibility for uncertain changes, yet in some cases the initial expected scope of the project cannot be realized or undetected errors remain because schedules are fixed and unexpected backlog of tests and bug fixes remain unaddressed. On the other hand, a waterfall methodology can include high risk of violating schedule targets, while fulfilling the initially expected scope with comprehensive tests so that more complex products are reliable. For the decision whether to develop in waterfall or agile, our approach is to evaluate the effects on uncertainties by adoption of agile techniques. We begin with focus on uncertain rework. The effects on rework are evaluated as cost using simulation. The decision making problem is modeled as a decision tree. In the simulation, a Software Reliability Growth Model is used as an error likelihood and detection model. This proposed method is demonstrated using a simple shopping web site. As a case study, the effects on rework by adoption of agile can be evaluated using the developed simulator. With comparison of predicted rework costs given a balance of waterfall or agile methods for a specific case, the project can be designed more effectively.
[2]: Agile methods and traditional structured approaches are often viewed as competing bi-polar choices. Agile methods such as Scrum and XP are recommended for small, co-located projects that involve changing requirements. The traditional structured plan-driven approaches, such as the Capability Maturity Model (CMM) and the waterfall lifecycle frameworks, are recommended for large projects with stable requirements. If a project is large, strategically important, distributed, and has dynamic user requirements and organizational changes, it presents unique challenges that neither the agile methods nor the traditional structured approaches can effectively deal with alone. Although there is an increasing call for a balanced approach, there is little empirical research that shows when and how the two approaches can complement each other. Based on a case study from the cruise line industry of a large distributed strategic project with unanticipated changes, we conclude that this balance is not only workable, but is essential to ensure that the project demonstrates both control and agility for achieving its challenging and dynamic goals. Agile without structure can cause chaos, particularly in large complex distributed projects where planning, control, and coordination are critical. Structure without agility can lead to rigidity, particularly when a project involves a great deal of learning, discovery, and changes. © 2010 by the authors.
[8]: Contemporary software is increasingly developed using an agile development approach, yet the supplier is generally selected as a result of a waterfall-style competitive tendering and contracting process. The procurement activity may be incompatible with an agile elaboration of requirements and development of functionality, and lead to sub-optimal outcomes. This paper examines the interaction of the procurement and software development lifecycles, explores potential causes of project or system failures and suggests some improvements based on a successful 10 year project between ADI Limited and the Australian Department of Defence. © 2005 IEEE.",Related but unverifiable
i_2065,Contradiction,"Root hydraulic conductance (Kh) is influenced by factors such as soil moisture, root structure, and nutrient availability .","Water and nutrition are mainly uptaken by the root system, and the root system is directly grown in the soil and is sensitive to stress. In arid environments, the structure of the root system could be changed to maintain normal biology function and adapt to stress conditions. To date, most of the studies have focused on the structure or morphology of root system responses to single stress factors. However, less attention has been concentrated on the adaptive mechanism of the entire root structure to different ecotopes. Therefore, this study explored the root morphological plasticity of Ziziphus jujuba var. spinosa in response to natural drought gradient ecotopes. Root samples were selected from Yantai-Shijiazhuang-Yinchuan-Turpan of China. The four ecotopes formed a natural drought gradient environment according to their soil moisture, annual precipitation, and humidity coefficients. The purpose of this study was to elucidate the mechanism of root plasticity response to different environments caused by climate change. The results showed that root primary structure of Ziziphus jujuba var. spinosa included the epidermis, cortex, and vascular cylinder. The epidermis is on the surface of the young root, which is constituted by a single layer of epidermis cells that are small and arranged closely. The cortex takes the greatest proportion of the primary structure, and it is constituted by a larger quantity of parenchymal cells. The vascular cylinder is located in the innermost layer, and the cells are small and crowded together. It is composed of pericycle, primary xylem, primary phloem, and parenchymal cells. When drought aggravated, the thickness and width of the epidermis cells were increased. In addition, the thickness, width, and number of plies of parenchymal cells, and the thickness of the cortex were all largest at the Yinchuan ecotope. The root secondary structure of Ziziphus jujuba var. spinosa was divided into periderm (phellem layer, phellogen, phelloderm) and secondary vascular tissue (secondary phloem, vascular cambium, secondary xylem). As the drought intensified from Yantai to Turpan, the thickness and density of periderm was gradually increased. In addition, the diameter and quantity of vessels in secondary xylem were increased. These results illustrated that one of the adaptive mechanisms of plant to drought stress is the changes in the plasticity of root structure that enhance water uptake capacity and water transport efficiency. On the other hand, it improves water retaining capacity and decreases water desorption.
[3]: Plant hydraulics is key for plant survival and growth because it is linked to gas exchange and drought resistance. Although the environment influences plant hydraulics, there is no clear consensus on the effect of nitrogen (N) supply, which may be, in part, due to different hydraulic conductance normalization criteria and studied species. The objective of this study was to compare the variation of root hydraulic properties using several normalization criteria in four pine species in response to three contrasting N fertilization regimes. We studied four closely related, yet ecologically distinct species: Pinus nigra J.F. Arnold, Pinus pinaster Ait., Pinus pinea L. and Pinus halepensis Mill. Root hydraulic conductance (Kh) was measured with a high-pressure flow meter, and values were normalized by total leaf area (leaf specific conductance, Kl), xylem cross-section area (xylem specific conductance, Ks), total root area (root specific conductance, Kr) and the area of fine roots (fine root specific conductance, Kfr). Controlling for organ size differences allowed comparison of the hydraulic efficiency of roots to supply or absorb water among fertilization treatments and species. The effect of N on the root hydraulic efficiency depended on the normalization criteria. Increasing N availability reduced Kl and Ks, but increased Kh, Kr and especially Kfr. The positive effect of N on Kr and Kfr was positively related to seedling relative growth rate and was also consistent with published results at the interspecific level, whereby plant hydraulics is positively linked to photosynthesis and transpiration rate and fast growth. In contrast, normalization by leaf area and xylem cross-sectional area (Kl and Ks) reflected opposite responses to Kr and Kfr. This indicates that the normalization criteria determine the interpretation of the effect of N on plant hydraulics, which can limit species and treatment comparisons.",Missing information
i_898,Unverifiable,"Key Points: Fault Diagnosis: While it is important for early detection of faults, it may not significantly prevent failures or reduce maintenance costs in all cases .","Rotordynamics is a very challenging field because of machine complexities. Many internal and external factors contribute toward change in the structural dynamic characteristics. One of these factors is broad-band high-vibration amplitudes. In this article, a similar high vibration issue on a gas turbine is investigated using bode, orbit, and shaft centerline plots. Data from proximity probes installed on turbine generator system are captured and analyzed against any factor contributing toward high vibration issue. Fish bone diagram was used for root cause investigation. Main components investigated for the root cause of high vibration issue include generator rotor and casing. Rotor behavior has been examined by capturing orbit and shaft centerline diagrams, whereas casing contribution has been investigated by conducting operating deflection shape analysis. A comparison is drawn between a machine suffering from high vibration issue and a normal machine. Resonance was identified as the root cause, and stiffness enhancement was recommended to change the natural frequency of casing. Based on investigations, recommendations are given and a final comparison is drawn after structural modification was done. In addition to early fault finding, reduction in maximum vibration was 38% after implementation of the fix that confirmed the accuracy of the root cause investigation process.
[4]: The aim of the present work is the diagnosis of tooth surface damage fault in gears using the induction machine electrical signature analysis. The condition monitoring of gears is a crucial task due to its importance in the mechanical power transmission in industrial, aerospace and automotive applications. The vibration analysis has been commonly used as an effective tool for gear fault diagnosis in several studies. The gear torsional vibration effect in the stator current and the estimated electromagnetic torque has been previously studied based on the observation of gear mechanical characteristic frequencies in the spectrum of the load torque. This paper investigates the profile generated by a gear tooth surface damage fault in the load torque. It will be shown that the periodic behavior of this particular profile produces fault-related frequencies in the stator current and hence harmonics namely integer multiple of rotation frequency in the instantaneous frequency of the stator current space vector and the estimated electromagnetic torque. The obtained results show a possible non-invasive gear tooth surface damage fault detection with a fault sensitivity comparable to the one obtained with invasive methods. A set-up based on a 250W three-phase squirrel-cage induction machine shaft-connected to a single-stage gear has been used for this purpose. © 2013 IEEE.",Related but unverifiable
i_2350,Unverifiable,"3. Validation Techniques: High-Throughput Methods: Utilize high-throughput methods such as active community profiling (ACP) to validate the activity and composition of microbial cultures. This method distinguishes active from inactive cells, providing a more accurate representation of the community .","[3] Culture collections contain indispensable information about the microorganisms preserved in their repositories, such as taxonomical descriptions, origins, physiological and biochemical characteristics, bibliographic references, etc. However, information currently accessible in databases rarely adheres to common standard protocols. The resultant heterogeneity between culture collections, in terms of both content and format, notably hampers microorganism-based research and development (R&D). The optimized exploitation of these resources thus requires standardized, and simplified, access to the associated information. To this end, and in the interest of supporting R&D in the fields of agriculture, health and biotechnology, a pan-European distributed research infrastructure, MIRRI, including over 40 public culture collections and research institutes from 19 European countries, was established. A prime objective of MIRRI is to unite and provide universal access to the fragmented, and untapped, resources, information and expertise available in European public collections of microorganisms; a key component of which is to develop a dynamic Information System. For the first time, both culture collection curators as well as their users have been consulted and their feedback, concerning the needs and requirements for collection databases and data accessibility, utilised. Users primarily noted that databases were not interoperable, thus rendering a global search of multiple databases impossible. Unreliable or out-of-date and, in particular, non-homogenous, taxonomic information was also considered to be a major obstacle to searching microbial data efficiently. Moreover, complex searches are rarely possible in online databases thus limiting the extent of search queries. Curators also consider that overall harmonization—including Standard Operating Procedures, data structure, and software tools—is necessary to facilitate their work and to make high-quality data easily accessible to their users. Clearly, the needs of culture collection curators coincide with those of users on the crucial point of database interoperability. In this regard, and in order to design an appropriate Information System, important aspects on which the culture collection community should focus include: the interoperability of data sets with the ontologies to be used; setting best practice in data management, and the definition of an appropriate data standard.",Unrelated and unverifiable
s_2042,Entailment,"Functional redundancy, which provides ecological resilience, is higher in less disturbed environments .","Landscape changes in tropical environments result in long-lasting and complex changes in biodiversity that involve several biological responses (e.g., loss of species diversity and functional diversity). Both taxonomic and functional diversity might respond differently to land-use change, and this response might also vary depending on several factors, such as the taxonomic group or landscape context. Even though each level of diversity expresses different properties of the community structure, studies characterizing the species community in human-dominated landscapes have often only focused on patterns involving taxonomic diversity. Here, we evaluated different descriptors of taxonomic (i.e., richness, diversity, and dominance) and functional entropy (i.e., richness, diversity, and redundancy) and the taxonomic and functional composition of ants in a forest cover gradient (%) in 16 highly fragmented tropical humid forest landscapes in Mexico. We found that all descriptors of taxonomic diversity decreased along a gradient of forest loss. Furthermore, functional redundancy was the only component of functional diversity that was positively associated with forest cover (%). These findings suggest an ecological backup of functions provided by species in landscapes with higher forest cover, protecting these landscapes against habitat disturbance or species loss. We also observed that landscapes with larger forest cover were inhabited by ant species with larger interocular distances and smaller femurs, which could allow predator ants the exploitation of ground cracks and higher mobility in leaf-litter microhabitats. Our results highlight the importance of the primary forest as a reservoir of the taxonomic and functional diversity of ants in highly fragmented tropical rainforest landscapes.",Entailment
i_1415,Contradiction,"Minimally Invasive Surgery (MIS): Robotic Surgery: An advanced form of MIS, robotic surgery offers precision and control, particularly beneficial for complex gastrointestinal procedures .","The advent of minimally invasive surgery (MIS) brought a major deviation in trend from conventional surgery. Since the introduction of first laparoscopic cholecystectomy in 1985, many operations for gastrointestinal diseases adopted MIS technique in a relatively short period of time. These MIS operations yielded better outcomes when compared to their open counterparts: less pain, shorter hospital stay, faster recovery, and better cosmetics. More complex surgical procedures for benign and malignant diseases of gastrointestinal tract are currently being performed by MIS technique with the improvement in equipment, instrumentation, and surgical skills. At the forefront of MIS, lies robotics. This paper briefly reviews the current status of MIS in the field of gastrointestinal diseases.
[3]: The development of minimally invasive surgery (MIS) using laparoscopy and robotics has revolutionized the postoperative course of digestive surgery. By decreasing surgical trauma, the minimally invasive approach minimizes postoperative pain, enhances postoperative recovery, and reduces length of stay and hospital costs. This ""surgical revolution"", which has spanned over the last thirty years, has not fully advanced the field of pancreatic surgery. Pancreaticoduodenectomy (PD), which is usually performed by an open approach, still represents a technically demanding operation with a steep learning curve and high postoperative morbidity and consequent mortality. The postoperative complications of PDs require treatment from multidisciplinary healthcare management teams in highly experienced institutions, so PDs should be restricted to high volume centres. In this article, we have reviewed the reasons for the reluctance of pancreatic surgeons to perform PDs by MIS, the clinical outcomes from minimally invasive PDs, and the expectations of pancreatic surgeons of MIS. After reviewing the literature, morbidity and mortality of MIS PD seems to be comparable to open surgery, but a recent randomized trial was prematurely interrupted due to higher mortality in the laparoscopic arm. Long-term survival of patients with pancreatic adenocarcinoma seems to be comparable between MIS PD and open surgery. MIS PD achieves statistically significantly decreased blood loss at the expense of increased operative time compared with open PD. Quality metrics and new scores should be developed in order to further evaluate and compare the outcomes from open and/or MIS pancreatic resection.",Missing information
i_46,Entailment,Methodologies for Implementing Sustainability: Lean Methodologies: Integrating sustainability into lean software development processes can provide a competitive advantage and promote environmentally friendly software products .,"Sustainability is even more important now than ever if we speak in the context of organizational growth, it is necessary that technological products, such as software developments, are certified as green-environmental friendly technology that would mean a competitive advantage for an organization that implements an agile methodology for software development that takes sustainability into account, giving the organization new ways to market their software products as environmentally friendly. This study proposes a model for agile software development, it has taken into account that software development must be based upon reusing old hardware, free nonprivative software and code (open source), as well as virtualization of servers and machines, to create software that can be useful for over a decade, as a result, we expect a reduction of planned obsolescence in hardware, which means taking one step ahead to help solve the problem that the big amount of electronic waste (e-waste) means nowadays worldwide.",Entailment
i_2242,Entailment,"Decline: Habitat degradation inevitably leads to a decline in all specialist species, resulting in biotic homogenization where generalists completely dominate .","Habitat specialists are declining worldwide, often paralleling rapid loss of habitat. Grassland habitats across North America are declining precipitously, due in part to intense conversion of grasslands to agriculture and rangelands, and specialist communities reliant upon this landscape are at particular risk of decline and collapse. We explored the relationship between grassland habitat specialism in birds and species population trends using several different grassland specialism indices (GSIs). Our data sources for these indices included (1) a regional bird dataset employing a spatially stratified sampling design (Integrated Monitoring of Bird Conservation Regions) of bird surveys in the Northern Great Plains of North America, and (2) geospatial data of species ranges (BirdLife Int'l) and grassland habitat (CEC North American Land Cover). We found a negative relationship between degree of habitat specialism and species population trends for all specialism metrics. We also found some evidence to support that specialism to grasslands on the wintering grounds partially explains population trends during the breeding season, giving added weight to the consideration of habitat conservation across the full annual cycle of a species to reverse or lessen population decline. Our work is the first to use quantitative methods to confirm the precarious state of grassland specialist songbirds in North America as well as demonstrate multiple methods for quantifying habitat specialism across different types of datasets.
[7]: Habitat degradation leads to homogenization of biological communities, often due to the dominance of generalist species over specialists. Yet data as to how life history attributes of specialists vary with such perturbations remain sparse. We compared long-term population dynamics of a specialist trawling bat, the large-footed myotis (Myotis macropus), between two forested catchments. One forest stream was nutrient-enriched from dairy farming in its headwaters and a portion of its surrounding catchment was harvested for timber during the study, while the other was located in primarily undisturbed forest. We caught and banded bats annually at their roosts over 14 years and banded 529 individuals with a 45% recapture rate. The maximum time to recapture was nine years and there was no evidence for transiency in our populations. Mark-recapture analyses allowed for investigation of the dependence of survival on time, sex, and age at marking. Our study spanned extreme El Niño and La Niña weather events, but we found little variation in survival, although recruitment was lower during drought. Mean minimum winter temperature (positive) and rainfall (positive) had weak influences on survival. Survival of adults (~0.70) and population size of adult females was similar between the two sites, suggesting that neither timber harvesting with retained riparian buffers nor eutrophication from farming influenced survival. Survival of adult males and females was similar, but survival of juveniles was less than half that of adults, probably due to a combination of mortality and dispersal. Survival was three times lower immediately after one of the timber bridges used as a roost fully collapsed. Specializing on aquatic habitats buffered M. macropus from most extreme weather, but there was also evidence for possible mortality and recovery after an intense rainfall and flooding event immediately prior to the study. More frequent intense rainfall predicted with global warming may reduce the species' resilience over time.",Entailment
i_596,Contradiction,"PPPs hinder the implementation of fit-for-purpose land administration, leading to a lack of sustainable buy-in from private sector corporations .","Public-private partnerships (PPPs) may facilitate the implementation of fit-for-purpose land administration (FFPLA); however, the approach can be compromised when funding for land registration is insufficient or donor projects end. This paper aims to introduce a new form of PPP to the literature on FFPLA, further extending the discourse and options available on PPPs for FFPLA. A background review finds that whilst PPPs have had long standing application in land administra-tion, there is room to explore approaches that seek increased involvement of non-conventional land sector actors. A case study methodology is applied to analyse recent developments of FFPLA in Côte d'Ivoire that includes a partnership between the government and a consortium of private sector companies. Results describe the novelty, challenges, opportunities, and success factors for the approach, when compared to existing forms of PPPs. It is found that the innovative partnership approach may create novel avenues for financing FFPLA in developing countries and for more ac-tive forms of participation of the private sector in improved land tenure governance. The model potentially creates sustainable buy-in from private sector corporations, who whilst not convention-ally closely undertaking land administration efforts, rely intrinsically on it to achieve corporate social responsibility objectives.",Opposite meaning
i_1376,Contradiction,"Prognosis and Survival Rates: The overall survival rate for pediatric MB has improved significantly, with current therapies achieving approximately 70-80% survival, which suggests that nearly all children diagnosed with this condition can expect a full recovery .","Purpose of review: Most children diagnosed with cancer today are expected to be cured. Medulloblastoma, the most common pediatric malignant brain tumor, is an example of a disease that has benefitted from advances in diagnostic imaging, surgical techniques, radiation therapy and combination chemotherapy over the past decades. It was an incurable disease 50 years ago, but approximately 70% of children with medulloblastoma are now cured of their disease. However, the pace of increasing the cure rate has slowed over the past 2 decades, and we have likely reached the maximal benefit that can be achieved with cytotoxic therapy and clinical risk stratification. Long-term toxicity of therapy also remains significant. To increase cure rates and decrease long-term toxicity, there is great interest in incorporating biologic 'targeted' therapy into treatment of medulloblastoma, but this will require a paradigm shift in how we classify and study disease. Recent findings: Using genome-based high-throughput analytic techniques, several groups have independently reported methods of molecular classification of medulloblastoma within the past year. This has resulted in a working consensus to view medulloblastoma as four molecular subtypes, including wingless-type murine mammary tumor virus integration site (WNT) pathway subtype, Sonic Hedgehog pathway subtype and two less well defined subtypes (groups C and D). Summary: Novel classification and risk stratification based on biologic subtypes of disease will form the basis of further study in medulloblastoma and identify specific subtypes that warrant greater research focus. © 2012 Wolters Kluwer Health | Lippincott Williams & Wilkins.
[8]: Medulloblastoma and supratentorial primitive neuroectodermal tumors (sPNETs) are embryonal brain tumors and are the most common malignant brain tumors in the pediatric population. Current therapy for these children most often includes a multi-modality approach including surgery, radiation and chemotherapy. With modern therapy, overall survival for medulloblastoma is approximately 80% while survival for sPNET is 30–50%. Factors associated with prognosis include the presence of disseminated disease, extent of surgical resection and patient age, with children <3 years categorized as high risk patients given the inability to deliver high dose radiation at this young age due to significant long term effects. Increasingly, there is great interest in further sub-grouping patients based on molecular profiling which is highly predictive of outcome. While four molecular subgroups have emerged for medulloblastoma, the sub-grouping of sPNET has proved more challenging with an increasing awareness that this is a heterogeneous group in which histological diagnosis is challenging. The current challenges for both medulloblastoma and sPNET include the determination of optimal therapy for children such as decreased therapy for favorable risk groups and intensification and targeted therapy for high risk groups. Additionally, data are now available for long-term survivors which detail the significant effects of therapy in this young population.
[9]: Purpose of Review: Medulloblastoma is the main primitive neuroectodermal tumour of the posterior fossa in childhood. The classical therapeutic approach consists of surgical resection, followed by craniospinal irradiation. Because of the good overall survival (75%), the main recent research efforts focus on refining the most relevant prognostic stratification and in decreasing the long-term sequelae. Recent Findings: Thanks to the better understanding of the heterogeneity of medulloblastomas, clinical, histological and biological markers have been clearly identified and allow risk-adapted strategies. A subset of tumours of early childhood (<3-5 years), frequently associated with a Sonic Hedgehog signalling, might be cured without irradiation. In older children, several trials have demonstrated the safety of reduced craniospinal irradiation in standard risk tumours. Furthermore, the evidence of an excellent prognosis associated with a subset of tumours characterized by an activation of the WNT pathway leads to forthcoming de-escalating strategies. Reducing long-term sequelae also relies on new surgical approaches aiming at reducing the cerebellar injuries. Tremendous efforts have also been made in defining the most adapted irradiation doses and fields. Intensity-modulated radiotherapy and proton beam therapy might also influence the long-term neurological and endocrine defects of the patients. Summary: Histological and biological characteristics clearly define various prognostic groups within medulloblastomas; confirming the overall good outcome and reducing long-term sequelae are the main focus of current clinical trials. © 2011 Wolters Kluwer Health | Lippincott Williams & Wilkins.",Misrepresentation
i_396,Entailment,"Summary Table: AI's versatility and capability to process vast amounts of data in real-time make it a valuable asset across these sectors, driving innovation and efficiency improvements .","The pace at which artificial intelligence (AI) is becoming a mainstream technology in manufacturing is quite impressive. Companies in manyindustries use AI daily to optimize assembly processes, perform predictive maintenance, improve part and product quality through enhancedvision inspection, and increase data cybersecurity.
[8]: Artificial intelligence (AI) has successfully made its way into contemporary industrial sectors such as automobiles, defense, industrial automation 4.0, healthcare technologies, agriculture, and many other domains because of its ability to act autonomously without continuous human interventions. However, this capability requires processing huge amounts of learning data to extract useful information in real time. The buzz around AI is not new, as this term has been widely known for the past half century. In the 1960s, scientists began to think about machines acting more like humans, which resulted in the development of the first natural language processing computers. It laid the foundation of AI, but there were only a handful of applications until the 1990s due to limitations in processing speed, memory, and computational power available. Since the 1990s, advancements in computer architecture and memory organization have enabled microprocessors to deliver much higher performance. Simultaneously, improvements in the understanding and mathematical representation of AI gave birth to its subset, referred to as machine learning (ML). ML includes different algorithms for independent learning, and the most promising ones are based on brain-inspired techniques classified as artificial neural networks (ANNs). ANNs have subsequently evolved to have deeper and larger structures and are often characterized as deep neural networks (DNN) and convolution neural networks (CNN). In tandem with the emergence of multicore processors, ML techniques started to be embedded in a range of scenarios and applications. Recently, application-specific instruction-set architecture for AI applications has also been supported in different microprocessors. Thus, continuous improvement in microprocessor capabilities has reached a stage where it is now possible to implement complex real-time intelligent applications like computer vision, object identification, speech recognition, data security, spectrum sensing, etc. This paper presents an overview on the evolution of AI and how the increasing capabilities of microprocessors have fueled the adoption of AI in a plethora of application domains. The paper also discusses the upcoming trends in microprocessor architectures and how they will further propel the assimilation of AI in our daily lives.
[9]: Artificial intelligence (AI) is making its way back into the mainstream of corporate technology, this time at the core of business systems which are providing competitive advantage in all sorts of industries, including electronics, manufacturing, marketing, hu-manresource, financial services software, medicine, entertainment, engineering and communications. Designed to leverage the capabilities of humans rather than replace them, today's AI technology enables an extraordinary array of applications that forge new connections among people, computers, knowledge, and the physical world. Some AI enabled applications are information distribution and retrieval, database mining, product design, manufacturing, inspection, training, user support, surgical planning, resource scheduling, and complex resource management. AI technologies help enterprises reduce latency in making business decisions, minimize fraud and enhance revenue opportunities.",Entailment
s_450,Entailment,Key Components of Cybersecurity: 6. Policy and Regulatory Compliance: Developing and enforcing cybersecurity policies at national and organizational levels is vital. This includes compliance with international standards and creating a cybersecurity culture within organizations .,"The information economy, among other elements, heavily depends on cybersecurity. On the other hand, cybersecurity depends mainly on technology, on management procedures, on organizational structures, on law and on human competencies, to quote only some aspects of ICT security. To effectively sustain a coherent approach of cybersecurity, a national strategy, enforceable at a national level and compatible at the international level, should exist. This paper analyses some characteristics and issues related to the deployment of a national cybersecurity strategy in an interconnected world. It also points out the necessity of operational organizational structures and the importance of a cybersecurity culture to support a national cybersecurity strategy. © 2010 IEEE.
[10]: For an effective Cybersecurity Culture, it is fundamental to develop adequate cybersecurity awareness programmes. Awareness, training and education are the three areas which define a learning process. Understanding their meaning and their mutual relationship is the key for organizations to identify the appropriate tools and methods to induce people to behave responsibly. With awareness we refer to having knowledge of a certain situation and behaving consequently; training is an active and a more or less formal process to teach skills; education is the process of providing integrated knowledge and skills and the means to extend them. Talking of the building of a Cybersecurity Culture, our commitment cannot be limited to the use of materials like videos or posters; these are important in the context of awareness initiatives, but they must be part of a more complex process, whose goal is to induce people to change their behaviour. The success of this process depends on the quality of used tools and contents and on employees' motivation, which has to be stimulated so as to ensure their active participation. Changing insecure behaviour and fostering a responsive mindset is a challenge that cannot be achieved in a short period; this also requires the knowledge of human nature and its mechanisms. In this sense, common habits in security deriving from the physical world can be a source of inspiration for the development of cybersecurity awareness programmes. Finally, some recommendations are provided in order to plan cybersecurity initiatives and to avoid their failure.",Entailment
i_56,Unverifiable,Comparative analysis of marching cubes and ray casting algorithms showed that marching cubes are effective for memory and time efficiency in volumetric analysis .,"In the virtual surgical planning for orthognathic surgery, 3D visualization of facial bone surface is required. In this paper, the 3D facial bone surface model of craniofacial areas is reconstructed from volumetric 2D computed tomography (CT) slices which are in digital imaging and communications in medicine (DICOM) format. These slices are mapped to the z coordinate space and a mesh surface is visualized using marching cube and ray casting visualization algorithms. Comparative analysis of marching cube and ray casting volume rendering algorithms is done with memory and time quality metric, to analyze which method is best for further volumetric analysis in virtual surgical planning of orthognathic surgery.",Related but unverifiable
s_2054,Entailment,"3. Species-Specific Responses: Landscape Friction: Geographic features like mountain ranges and valleys can influence connectivity by acting as barriers to species with high dispersal capabilities, such as the Mojave desert tortoise .","Heterogeneity in habitat often influences how organisms traverse the landscape matrix that connects populations. Understanding landscape connectivity is important to determine the ecological processes that influence those movements, which lead to evolutionary change due to gene flow. Here, we used landscape genetics and statistical models to evaluate hypotheses that could explain isolation among locations of the threatened Mojave desert tortoise (Gopherus agassizii). Within a causal modeling framework, we investigated three factors that can influence landscape connectivity: geographic distance, barriers to dispersal, and landscape friction. A statistical model of habitat suitability for the Mojave desert tortoise, based on topography, vegetation, and climate variables, was used as a proxy for landscape friction and barriers to dispersal. We quantified landscape friction with least-cost distances and with resistance distances among sampling locations. A set of diagnostic partial Mantel tests statistically separated the hypotheses of potential causes of genetic isolation. The best-supported model varied depending upon how landscape friction was quantified. Patterns of genetic structure were related to a combination of geographic distance and barriers as defined by least-cost distances, suggesting that mountain ranges and extremely low-elevation valleys influence connectivity at the regional scale beyond the tortoises' ability to disperse. However, geographic distance was the only influence detected using resistance distances, which we attributed to fundamental differences between the two ways of quantifying friction. Landscape friction, as we measured it, did not influence the observed patterns of genetic distances using either quantification. Barriers and distance may be more valuable predictors of observed population structure for species like the desert tortoise, which has high dispersal capability and a long generation time. © 2010 Springer Science+Business Media B.V.",Entailment
i_2313,Contradiction,"Similarly, Australian snapper larvae showed optimal survival within a salinity range of 20-35‰, suggesting that any exposure to salinity above 35‰ could lead to significant growth reduction and survival issues .","The effects of salinity and temperature on performance were determined for Australian snapper, Pagrus auratus first-feeding to pre-metamorphosis larvae held in 100-l recirculation tanks. In the first experiment, performance was assessed after transfer from 35‰ at eight salinity treatments (5‰, 10‰, 15‰, 20‰, 25‰ 30‰, 35‰ and 45‰) in larvae from 3 to 21 days after hatching (dah). Survival of larvae was best within the range of 20-35‰. Final size of larvae was similar within the range of 10-35‰ (6.8 ± 0.1 to 7.1 ± 0.2 mm total length [TL]; 3.0 ± 0.3 to 3.3 ± 0.3 mg wet weight) but larvae were 15% shorter at 45‰. Final swimbladder inflation and feeding onset of larvae was not affected by salinity in the range of 10-45‰. The presence of calculi in the urinary bladder of larvae was correlated positively with increasing salinity but no relationship between urinary calculi and larval survival was observed. In a second experiment, performance was assessed after transfer from 21°C at seven temperature treatments (15, 18, 21, 24, 27, 30 and 33°C) in larvae from 3-21 dah. All larvae transferred from 21°C to 30°C and 33°C died after 3 days and from 21°C to 27°C died after 9 days. Survival was not significantly different between 15°C and 24°C. Larval growth increased as temperature was increased; larvae at 24°C (4.8 ± 0.2 mg wet weight) were 6-fold heavier than larvae at 15°C. Swimbladder inflation of larvae grown at 18°C, 21°C and 24°C was high (65.2 ± 18.0% to 86.7 ± 8.8%) and similar but inflation was lower in 15°C and 27°C. The incidence of urinary calculi occurred earlier and in a greater number of larvae when temperature was increased. Feeding onset was not affected by temperature. In a third experiment, performance was assessed at combinations of two salinities (20‰ and 35‰) and three temperatures (18°C, 21°C, and 24°C) in larvae from 3 to 24 dah. Survival of snapper larvae was not significantly different between these treatments. Growth was not affected by salinity but larvae increased in size as temperature was increased and there was no interaction of salinity and temperature. The percentage of larvae that commenced feeding and inflated their swimbladders was similar in all treatments. Salinity and temperature influenced the incidence of urinary calculi and there was an interaction between the parameters. Based on our results in terms of larval performance (growth), development and survival, we conclude that the optimal conditions for larval rearing of snapper from first-feeding (3 dah) to pre-metamorphosis (24 dah) are combinations of salinity from 20‰ to 35‰ and a temperature of 24°C. © 2005 Elsevier B.V. All rights reserved.",Misrepresentation
s_1053,Contradiction,- **DLL4**: Targeted by avelumab in combination with paclitaxel for treating platinum-resistant epithelial ovarian cancer .,"Objectives: To evaluate the safety and preliminary efficacy of demcizumab (DLL4 targeted IgG2 humanized monoclonal antibody; potent inhibitor of the Notch pathway) in combination with weekly paclitaxel in platinum-resistant epithelial ovarian cancer (EOC); and to determine the maximum tolerated dose (MTD) or maximum administered dose (MAD). Methods: We conducted a 3 + 3 dose-escalation trial in patients with recurrent, platinum-resistant EOC with RECIST v. 1.1 measurable disease and ≤4 prior chemotherapy regimens. Two dosing cohorts (2.5 mg/kg and 5 mg/kg) were targeted; however, an intermediate dose level (3.5 mg/kg) was to be evaluated if the 5 mg/kg dose was not tolerable. Demcizumab was administered on days 1 and 15 and paclitaxel, weekly on days 1, 8, and 15 for each of three 28-day cycles: the 3-cycle doublet could be repeated once if safe. Thereafter, paclitaxel was administered until unacceptable toxicity or disease progression. Results: Nineteen patients were enrolled. No dose-limiting toxicities (DLT) were observed; however, the intermediate dose level (3.5 mg/kg) was enrolled and expanded based on emerging safety data from other trials in the demcizumab program. The MTD was not reached. The most common treatment emergent adverse events (TEAE) were diarrhea (68%), fatigue (58%), peripheral edema (53%), and nausea (53%). Pulmonary hypertension, grade 2 (n = 2) and grade 1 (n = 1), was observed. Overall response rate (ORR) was 21% (95% CI: 6–45%); clinical benefit rate (CBR) was 42% (95% CI: 20–66%). Conclusions: Demcizumab in combination with paclitaxel has a manageable toxicity profile and showed activity in patients with heavily pretreated platinum-resistant ovarian cancer.",Entity error
i_2168,Entailment,"Key Findings: Growth and Biomass: Heavy metals such as Cd, Pb, and Zn can significantly reduce the growth and biomass of wheat plants. High concentrations of these metals in the soil lead to decreased plant height, root length, and overall biomass .","With the rapid development of economy and modern industrial and agriculture, more and more heavy metals such as cadmium, copper and zinc come into environment. Heavy metals are not only polluting soil, water and air, but also affecting crops growth and the yield, and affecting food security and human health by food chain. It was reported that heavy metal contamination of arable land in China has reached 20 million hm<sup>2</sup>, accounting for the country's total cultivated area of 1/6. Therefore, many researchers pay more attention to the heavy metal pollution problems increasingly. At present, researchers usually use chemical and biological methods to test the pollution extent of different heavy metals. Those methods are time consuming and even cause the second environmental pollution. Using spectral analysis to monitor the heavy metals stress on crops is an innovative approach. However, the effect of heavy metal pollution on crops spectrum is still in the exploration stage. Because of the effect of different factors such as plants and environment, the diagnosis of heavy metal stress mechanism on plant is still unclear. The crop tolerance at different growth stages are different from heavy metals, therefor, to explore the critical concentration of different heavy metals stress on crops at the different growth stages has certain practical significance. In order to monitor the crop stress of heavy metal pollution rapidly, under open field plot conditions and using canopy spectral analysis, the canopy spectral features of wheat at different stages of tillering, jointing and heading were studied at the different treatments of Cu (0, 100, 300, 600 and 900 mg/kg) and Zn (0, 250, 500, 750 and 1 000 mg/kg), according to the national soil quality standard (GB15618-1995) of China. The experiment was conducted in the experimental field of Qingdao Academy of Agricultural Sciences in Chengyang District of Qingdao City, in October 2014 to June 2015. The total area of the test plot was 180 m<sup>2</sup>, and the test soil type is Shajiang black soil, with the pH value of 6.85, the organic matter content of 22.6 g/kg, nitrogen content of 94.6 mg/kg, available phosphorus content of 77.5 mg/kg, the available potassium content of 113 mg/kg, copper content of 28.1 mg/kg and zinc content of 73 mg/kg. The experiment was conducted by traditional management. The results indicated that at different concentration treatments of copper (Cu) and zinc (Zn), the canopy spectral reflectance in the visible band (350-760 nm) increased obviously with the concentration treatments increasing of Cu and Zn at the tillering and jointing stages of wheat, however, the canopy spectral reflectance of near infrared band (760-900nm) reduced with the increasing concentration of Cu and Zn treatment levels. Wheat canopy spectral reflectance appeared red edge position and red valley position shifting toward short wavelength called ""blue shift"" at tillering stage of wheat under the different concentration treatments of Cu and Zn. At the tillering stage of wheat, copper treatments of 600 and 900 mg/kg and at the jointing stage copper treatment of 900 mg/kg, the red edge normalized index value (NDVI705) were less than 0.2. At the tillering stage, zinc treatments of 750 and 1 000 mg/kg, the red edge normalized index value (NDVI705) was less than 0.2. This research also indicated that the wheat canopy spectral features response obviously to the threshold values concentration treatment level of Cu were between 300 and 600 mg/kg, and Zn were between 500 g and 750 mg/kg.
[2]: Lead-acid battery factories can lead to heavy metal pollution of nearby agricultural ecosystems. To assess the ecological risk and to understand the transport processes of heavy metals in an agricultural ecosystem, the concentrations of heavy metals in agricultural soils (As, Cd, Cr, Cu, Mn, Ni, Pb, and Zn) and in wheat plants at different stages of growth (Cd, Pb, and Zn) were investigated near the Fengfan lead-acid battery factory in Baoding, China. Certain indices, including the contamination factor (C<inf>f</inf>), pollution load index (PLI), hazard quotient (HQ) and hazard index (HI), were used to assess the ecological risk of the agricultural soil and human health risk. The results show that the mean concentrations of the heavy metals studied in the surface soils were all lower than the guideline values of China. However, the C<inf>f</inf> values of Pb ranged from 2.8 to 5.3, indicating that the most examined soils were strongly impacted by Pb. The PLI range was 0.6-4.2, indicating moderate contamination levels for those most examined soil samples. The As, Cr, Cu, Mn and Ni in the studied area were geogenic elements and Cd, Pb and Zn were mainly derived from the lead-acid battery factory based on the results of a principal component analysis (PCA) and heavy metal spatial distribution. The elements Cd, Pb and Zn entered the soil though atmospheric deposition and accumulated mainly as a bioavailable fraction at the surface. With respect to wheat berries, only the mean Pb content exceeds the tolerance for Pb at 0.84 mg/kg, indicating a potential risk. In relation to health risk, the HQs of individual heavy metals for different exposure populations were all lower than 1, showing a much lower potential health risk. Nevertheless, the potential health risk due to the cumulative risk of all heavy metals through the consumption of wheat berries exceeded unity for rural populations.
[3]: The toxic effects of heavy metals, including arsenic (As), cadmium (Cd) and lead (Pb), on length and biomass of shoots and roots, their respiratory rate, the gene expression levels of cytochrome oxidase (COD), isocitrate dehydrogenase (IDH) and malate dehydrogenase (MDH) isoenzymes were studied in the germination stage of wheat (var. ZhengZhou-9023). The results showed that both length and total dry biomass of wheat shoot and root increased at lower As concentrations (1 mg·L <sup>-1</sup>) but decreased gradually at higher As concentrations (5 to 25 mg·L <sup>-1</sup>). Similarly, the increase in the concentration of Pb, increased shoot length and biomass initially but later decreased gradually. Decline of root and shoot's biomass was observed with increasing concentrations of Cd yet. The respiratory rate of root displayed an increasing trend at As concentrations lower than 1 mg·L <sup>-1</sup>, but a decreasing trend was observed at higher concentrations in the root respiratory rate, while the respiratory rate of shoot increased gradually. Respiratory rates of shoot and root increased at lower concentrations of Cd or Pb but decreased at higher concentrations overall. The levels of COD, IDH and MDH isoenzymes in shoot and root were induced mainly with increasing concentrations of As. Interestingly, their levels were induced at lower concentrations of Cd and Pb, but could not be measured at higher concentrations of them. However, expression of a new IDH or a new MDH isoenzyme homologue in the root was induced at higher concentrations of Cd or Pb. Therefore, the presence of heavy metals could change the expression of some important enzymes in respiratory process such as COD, IDH or MDH isoenzymes, thereby affecting respiration in wheat, eventually leading to physiological changes in Wheat. © 2011 Academic Journals.",Entailment
s_1726,Entailment,"Shrimp Head Meal: Shrimp head meal (SHM), which is derived from shrimp heads, has been used as a protein source in animal feed. The protein content in these meals is significant enough to replace fish meal protein in diets for fish, indicating a high protein content in the original shrimp head waste. Additionally, it is believed that the use of SHM could enhance the overall health and immune response of fish, although this has not been directly studied in the referenced research .","Shrimp head meal (SHM) was used to replace fish meal as a protein source in practical diets for sex-reversed red tilapia (Oreochromis niloticus x O. mossambicus) at 0, 25, 50, 75 and 100% of fish meal protein or 0, 6.92, 13.84, 20.76 and 27.68% by weight of diet respectively. Catfish feed that contained protein content 37.22±0.10% was included as a reference diet. The experimental diets were fed to the fish with mean initial weight of 3.13±0.05 g for 8 weeks in 70 1 aquaria. The results showed that weight gain and specific growth rate of fish fed 50% of fishmeal protein replacement or diet 3 was not significant by different from those of fish on control diet (p≥0.05). The data of feed intake, feed conversion ratio and productive protein value of fish fed diet 3 were equal to those fed control diet (p≥0.05). The lowest growth rate and feed efficiency showed on fish fed 100% of fishmeal protein replacement. The production cost of fish fed diet 3 was equal to those fed the control diet and the reference diet (p≥0.05). Total carotenoid content in fish skin was significantly highest (p<0.05) in fish fed 100% of fishmeal protein replacement diet. The result indicates that the use of SHM at the level of 50% replacement or 13.84% by weight of diet is a potential protein source in sex-reversed red tilapia diet.
[5]: In diets for Totoaba macdonaldi juveniles (26.3 ± 4.7g y 13.6 ± 1cm) the partial replacement of fishmeal protein (HP) with shrimp head meal (HCC) was evaluated, over their growth, survival, fed conversion (FCA) and chemical composition of tissues and the apparent digestibility coefficient of dry matter (CDA), protein (CDAP) and lipids (CDAL) of these diets. The HCC used were from the whole shrimp head sun dried (F) and smashed shrimp head dehydrated in a hot air drier. Diets were isoproteic (55.5% crude protein), isolipídic (15% lipids) and isocaloric (4.6 kcal g<sup>−1</sup>) replacing 0% (control diet; DC), 15% (F15 and M15) and 30% (F30 and M30) of the HP protein by the HCC. At 57<sup>th</sup> day, survival with HCC (99.44 ± 1.92%) was higher than DC (88.89 ± 3.85 %). The gain weight, weight specific growth (TCE) and total intake were not statistically different (P > 0.05) between organisms feed with HCC, however with the M30 diet the TCE had higher average (0.99 ± 0.06) and growth (19.82 ± 1.64 g/fish). With diet M30 the FCA was the best significantly (1.61 ± 0.13) and the higher CDA (66.18 ± 1.28), CDAP (86.51 ± 0.53) and CDAL (72.29 ± 1.10). It concluded that replaced protein of HP by HCC in diet for juvenile totoaba improved the growth and CDAs, yielding better results with the inclusion of macerated HCC with a replacement level of 30%.",Entailment
i_486,Unverifiable,Strategies for Implementation: User Profiles and Personalization: Incorporate user profiles and content-based recommender systems to personalize the ranking of search results based on long-term user interests and preferences .,"[1] At the heart of many effective approaches to the core information retrieval problem-identifying relevant content-lies the following three-fold strategy: obtaining content based matches, inferring additional ranking criteria and constraints, and combining all of the above so as to arrive at a single ranking of retrieval units. © 2011 Springer-Verlag. [10] The ability to retrieve relevant information is at the heart of every aspect of research and development in the life sciences industry. Information is often distributed across multiple systems and recorded in a way that makes it difficult to piece together the complete picture. Differences in data formats, naming schemes and network protocols amongst information sources, both public and private, must be overcome, and user interfaces not only need to be able to tap into these diverse information sources but must also assist users in filtering out extraneous information and highlighting the key relationships hidden within an aggregated set of information. The Semantic Web community has made great strides in proposing solutions to these problems, and many efforts are underway to apply Semantic Web techniques to the problem of information retrieval in the life sciences space. This article gives an overview of the principles underlying a Semantic Web-enabled information retrieval system: creating a unified abstraction for knowledge using the RDF semantic network model; designing semantic lenses that extract contextually relevant subsets of information; and assembling semantic lenses into powerful information displays. Furthermore, concrete examples of how these principles can be applied to life science problems including a scenario involving a drug discovery dashboard prototype called BioDash are provided. © The Author 2007. Published by Oxford University Press. [18] There are two main paradigms to exploit review information for recommendation. One is to concatenate all reviews of a user/item into a long document, which may neglect the different usefulness of reviews. The other paradigm is review-level i.e., analyzing each review separately to learn user/item features. In fact, the two paradigms are complementary, and fusing them together has the potential to learn more comprehensive features of users/items. Hence, we propose a unified framework to jointly learn document-and review-level representations of users/items. We design a document encoder to learn document-level features of users/items. Then, we use a review encoder to learn representations of reviews from words, and a user/item encoder to learn review-level features of users/items. Besides, different reviews from the same user may have different importance for different target items due to different item characteristics. We propose a cross attention model for user representation learning whose query vector is the embedding of target item ID, and apply it to the above three encoders to select different informative words and reviews for different target items. Extensive experiments validate the effectiveness of our method.",Related but unverifiable
s_630,Unverifiable,"Wood-Based Materials in Digital Material Passports: Similar to WPCs, wood plastic composites are used for various applications in construction. They offer benefits like microbial resistance, water absorption control, and thermal expansion management. These properties can be documented in digital material passports to ensure traceability and compliance with sustainability standards .","A comprehensive, practical guide to wood-plastic composites and their properties This is the first book that presents an overview of the main principles underlying the composition of wood-plastic composite (WPC) materials and their performance in the real world. Focusing on the characteristics of WPC materials rather than their manufacture, this guide bridges the gap between laboratory-based research and testing and the properties WPC materials exhibit when they're used in decks, railing systems, fences, and other common applications. Complete with practical examples and case studies, this guide: Describes compositions of WPC materials, including thermoplastics, cellulose fiber, minerals, additives, and their properties Covers mechanical properties, microbial resistance, water absorption, flammability, slip resistance, thermal expansion-contraction, sensitivity to oxidation and solar radiation, and rheological properties of hot melts of WPC Covers subjects that determine esthetics, properties, performance, and durability of wood-plastic composite products Includes comparisons of different ASTM methods and procedures that apply to specific properties. © 2007 John Wiley & Sons, Inc.",Related but unverifiable
i_1563,Unverifiable,"Key Points from the Research: Recycling and Repurposing: Recycling Methods: Various methods such as grinding, pyrolysis, and devulcanization are used to recycle waste tires, which are guaranteed to convert tires into useful products like ground tire rubber (GTR), regenerated tire rubber (RTR), and pyrolysis oil without any significant environmental impact .","Recycling and recovery of waste tires is a serious environmental problem since vulcanized rubbers require several years to degrade naturally and remain for long periods of time in the environment. This is associated to a complex three dimensional (3D) crosslinked structure and the presence of a high number of different additives inside a tire formulation. Most end-of-life tires are discarded as waste in landfills taking space or incinerated for energy recovery, especially for highly degraded rubber wastes. All these options are no longer acceptable for the environment and circular economy. However, a great deal of progress has been made on the sustainability of waste tires via recycling as this material has high potential being a source of valuable raw materials. Extensive researches were performed on using these end-of-life tires as fillers in civil engineering applications (concrete and asphalt), as well as blending with polymeric matrices (thermoplastics, thermosets or virgin rubber). Several grinding technologies, such as ambient, wet or cryogenic processes, are widely used for downsizing waste tires and converting them into ground tire rubber (GTR) with a larger specific surface area. Here, a focus is made on the use of GTR as a partial replacement in virgin rubber compounds. The paper also presents a review of the possible physical and chemical surface treatments to improve the GTR adhesion and interaction with different matrices, including rubber regeneration processes such as thermomechanical, microwave, ultrasonic and thermochemical producing regenerated tire rubber (RTR). This review also includes a detailed discussion on the effect of GTR/RTR particle size, concentration and crosslinking level on the curing, rheological, mechanical, aging, thermal, dynamic mechanical and swelling properties of rubber compounds. Finally, a conclusion on the current situation is provided with openings for future works.
[2]: The problem of recycling worn car tires is ecologically and economically important. Wornoff tires are a source of long-term environmental pollution. Tires subject to no biological decomposition, they are inflammable and being ignited 1 ton of tires releases in the atmosphere 270 kg of carbon black and 45 kg of toxic gases. At the same time, they contain valuable raw materials such as rubber resin and metal. The most optimum of all known tire-recycling methods is low-temperature pyrolysis that provides complete recycling of tires with recovery of useful products: liquid pyrolysis fuel, carbon residue and PYROGAS. To implement this technique and to ensure its economic effect we have developed and patented a compact self-contained outfit of equipment that requires minimal working areas and operating force, atmospheric emission of harmful components during its operation does not exceed maximum-allowable concentration rates.
[3]: A huge amount of waste tires is generated every day in the world. This determines the search for ways to use them. The extended process of production and application of scrap tires leads to their significant mass accumulation, thus representing environmental risk. Tires are inert materials, extremely difficult to treat, and nonbiodegradable. In recent years, many plants have been built for processing, treatment, and utilization of this kind of waste. A problem has emerged to find a suitable, environmentally friendly application of the products (gaseous, liquid, and solid) from pyrolysis of the tires. Pyrolysis oil, which is a liquid product, is not suitable for direct use as fuel because of its high sulfur content. Therefore, the desulfurization of pyrolytic tire oil is an important part of the oil production process prior to its use. The objective of this article is to review the methods used for desulfurization of waste tire pyrolysis oils and the possibility of using scrap tires as a source of energy.
[4]: The waste rubber and end-of-life tires management has become a serious environmental problem. It is well known that the best way to carry out the disposal of these wastes is through recycling by devulcanization. Therefore, in the last decades, many methods have been developed to perform this treatment. Nevertheless, the degree and quality of the achieved devulcanization is still difficult to evaluate. The Horikx theory is an approach often used for this purpose. Hence, in this work, the validity of this theory was experimentally checked. The theoretical curve that represents crosslink scission was experimentally built for sulfur-cured natural rubber, sulfur-cured natural rubber reinforced with carbon black, sulfur-cured ethylene propylene diene monomer rubber and peroxide-cured ethylene propylene diene monomer rubber. Several samples with vulcanization (or devulcanization) degree ranging from 0 to 100% were processed, and the corresponding soluble fractions and crosslink densities were measured by the swelling test. The experimental results were in good agreement with the theoretical predictions, independently of the studied material, fact that confirms the validity of the Horikx approach. This finding will contribute to improve the waste rubber devulcanization, and therefore to progress in the environmental protection.",Related but unverifiable
s_520,Unverifiable,Energy Gradient Theory and Fluid Instability: Energy Gradient Theory posits that the disturbance amplitude required for turbulent transition is inversely proportional to the flow velocity .,"The energy gradient theory for flow instability and turbulent transition was proposed in our previous work. It was shown that the disturbance amplitude required for turbulent transition is inversely proportional to Re, which is in agreement with the experiments. In present study, the energy gradient theory is extended to include the effect of disturbance frequency on turbulent transition. The theoretical result obtained accords well with the experimental data in literature. © 2010 Publishing House for Journal of Hydrodynamics.",Related but unverifiable
i_2033,Entailment,"Combining Morphological Traits and Microsatellite Markers: Trait-Marker Associations: Specific SSR markers have been linked to important fruit traits in melons. For example, markers associated with fruit shape, rind pattern, and flesh color in watermelon have been identified, which can be extrapolated to melon studies .","Modern watermelon cultivars (Citrullus lanatus [Thunb.] Matsum.& Nakai var. lanatus) have fruits with diverse phenotypes, including fruit shape, rind patterns, and flesh color. Molecular markers enable efficient selection of plants harboring desirable phenotypes. In the present study, publicly available DNA markers tightly linked to fruit shape, rind stripe pattern, and flesh color were evaluated using 85 watermelon accessions with diverse fruit phenotypes. For fruit shape, the dCAPS SUN - Cla011257 marker revealed an 81% of marker - trait match for accessions with elongated or round fruits. For rind stripe pattern, the SCAR wsb6-11marker was effective for selecting Jubilee-type rind pattern from other rind patterns. For flesh color, the Clcyb.600 and Lcyb markers derived from a mutation in the Lycopene β - cyclase (Lcyb) gene, were effective at selecting red or yellow flesh. Forty-eight accessions possessing diverse fruit - related traits were selected as a reference array and their genetic relationships assessed using 16 SSR markers. At a coefficient of 0.11, the 48 accessions grouped into two major clades: Clade I and Clade II. Clade I subdivided further into subclades I - 1 and I - 2 at a coefficient of 0.39. All accessions with colored flesh were classified into Clade I, whereas those with white - flesh were classified into Clade II. Differences in fruit traits between subclades I - 1 and I - 2 were observed for rind pattern and fruit color; a majority of the accessions with Crimson-type striped or non-striped rind were grouped together in subclade I - 1, while most accessions in subclade I - 2 had a Jubilee - type rind stripe pattern. These results imply that reference array watermelon accessions possess distinguishable genetic structure based on rind stripe pattern. However, no significant grouping pattern was observed based on other fruit-related traits.",Entailment
s_1203,Contradiction,"Ultrasound: A low-radiation imaging system that provides quick and detailed visualization, particularly useful in pediatric polytrauma .","A pilot study evaluating the use in paediatric polytrauma of the STATSCAN, a low-radiation dose, fan-beam digital radiography unit (Lodox Systems, Sandton, South Africa). Over 3 months, 23 polytrauma patients treated at the Emergency Unit of the Red Cross Children's Hospital in Cape Town, South Africa, were imaged on the STATSCAN. Image quality, diagnostic equivalence and clinical efficiency were compared with a computed radiography (CR) system (Fuji FCR 5000, Fuji Photo Film, Tokyo, Japan). The STATSCAN antero-posterior bodygram correlated well technically and diagnostically with CR, showing 96% of the fractures in the cohort. It allowed superior visualisation of the trachea and main bronchi and imaging was, on average, 13% faster than CR. The STATSCAN could play an important role in paediatric polytrauma. The clinical significance of its superior demonstration of the trachea and main bronchi requires further evaluation. © 2007 Am Soc Emergency Radiol.",Entity error
s_929,Unverifiable,"User-Related Challenges: The aesthetic appearance of prosthetic hands is also important to users. Many current designs are criticized for their lack of a natural look, which can affect the user's self-esteem and social interactions .","[6] Many people with limb loss cannot afford a prosthesis that recreates the function of a human hand. While designs for functional prosthetic hands exist, most require extensive modification to fit each wearer's unique stump. The purpose of this study is to develop a design solution for a low-cost 3D printed prosthetic hand, using thermoplastic polyurethane material, that can be easily customized to fit the specific needs of each wearer. This paper discusses two components of the study: the fitting of a custom open-source 3D printed prosthetic hand; the development of an improved prosthesis using flexible TPU (thermoplastic polyurethane) material. This study, still in an early stage of development, shows that a hybrid 3D printing process with rigid and elastic materials can improve affordable prosthetic hand design and assembly. Testing demonstrates the potential for a new type of low-cost prosthetic hand that moves and looks more like the real thing. [7] Development of a force control hardware embedded system for a Prototype of Prosthetic Gripper Hand with 1 grade of liberty is shown. A myoelectric signal is used to enable a servo motor movement which permits opening and closing the prosthesis. The prosthesis force is controlled with a Proportional and Integrative (PI) incremental control. Furthermore, a little vibrator motor acts like a haptic interface and it is put on the user arm; the prosthesis force applied against an object is related with the vibrator motor frequency. [9] This paper presents an intelligent grasping system for applications in developing advanced prosthetic hands. The system learns how to grasp various objects based on experiments, controlled by the user, between the prosthetic hand and the object. Two target functions are learned. The first maps the hand configuration, grasp quality and contact characteristics to the object type. The second maps the object, grasp quality and contact characteristics to a stable hand configuration. Once the system learns these two functions, it enable the prosthetic hand to grasp object with little or no user intervention. Two models of artificial neural networks were used to learn these functions. Testing on 8 everyday objects in a special simulation environment show very promising results. © 2008 IEEE.",Related but unverifiable
i_724,Contradiction,"Key Features of Smart Furniture: Ergonomic Support: Smart furniture, such as the Smart Desk, uses capacitive proximity sensors to monitor and improve posture, activity levels, and even breathing rates. This helps in reducing health issues like chronic back pain by encouraging ergonomic sitting and varied sitting positions throughout the day .","Modern office work often consists of spending long hours in a sitting position. This can cause a number of health-related issues, including chronic back pain. Ergonomic sitting requires suitably adjusted chairs and switching through a variety of different sitting positions throughout the day. Smart furniture can support this positive behavior, by recognizing poses and activities and giving suitable feedback to the occupant. In this work we present the Capacitive Chair. A number of capacitive proximity sensors are integrated into a regular office chair and can sense various physiological parameters, ranging from pose to activity levels or breathing rate recognition. We discuss a suitable sensor layouts and processing methods that enable detecting activity levels, posture and breathing rate. The system is evaluated in two user studies that test the activity recognition throughout a work week and the recognition rate of different poses.",Entity error
i_1366,Unverifiable,"Additional Considerations: Long-term Health Effects: Continuous exposure to the emissions from 3D printing can lead to chronic health conditions, including respiratory diseases and cancer .","Plastic, one of the most preferred materials in today′s industrial world is posing serious threat to environment and consumer′s health in many direct and indirect ways. Exposure to harmful chemicals during manufacturing, leaching in the stored food items while using plastic packages or chewing of plastic teethers and toys by children are linked with severe adverse health outcomes such as cancers, birth defects, impaired immunity, endocrine disruption, developmental and reproductive effects etc. Promotion of plastics substitutes and safe disposal of plastic waste requires urgent and definitive action to take care of this potential health hazard in future.",Related but unverifiable
s_1816,Unverifiable,Social Impact: Urban Resilience: Sponge cities enhance urban resilience by addressing multiple risks and protective factors. This holistic approach ensures that cities can maintain their core functions during both stable and crisis periods .,"There is growing recognition of the cumulative impact that converging environmental, political, social and economic risks have on the ability of cities to function in times of shocks and stresses. While many frameworks and assessment tools have been developed to assess the technical resilience of the infrastructure of cities, there have been fewer attempts to holistically understand and map all the factors that interact to potentially produce functioning urban systems, including the role of institutions (both formal and informal). Applied integrated research is needed to understand the daily functioning, vulnerability and resilience of these rapidly growing cities amid chronic and acute stresses and shocks; to also understand why and how multiple risks and protective factors converge and interact to constrain or enable cities to fulfil their core functions in times of stability and crisis; and finally to produce operationally relevant recommendations that could inform interventions.",Unrelated and unverifiable
s_1231,Entailment,"Key Components and Benefits: Community Health Workers (CHWs): Implemented to improve care quality, the CHWs focus on role clarification, communication, and collaborative management, addressing challenges like teamwork culture and biomedical approaches .","Background: The family care team (FCT) was established to improve the quality of care. This study aimed to explore the perceptions of FCT implementation and describe the challenges inherent in implementing the FCT. Methods: Forty in-depth interviews were conducted. The interviewees consisted of five primary care managers in the provincial medical health office, five directors of community hospitals, five administrators in district health offices, ten subdistrict health-promoting hospital directors, representatives from ten local organizations, and five heads of village health volunteers. Data were collected in accordance with semistructured interview guidelines and analyzed by thematic analysis. Results: Participants' expressed their opinions through five themes: (1) the role and scope of practice, (2) the communication in collaboration of the FCT, (3) the management of the FCT, (4) the impact of the FCT on the team members' feelings and primary care performance, and (5) the main challenges, including the insufficiency of a teamwork culture and a biomedical approach. Conclusion: The information suggests the importance of issues such as the clarification of the team members' roles and managers' roles, communication within and across FCTs, and the preparation for training of interprofessionals to enhance collaborative management to achieve the optimal care for people in the district health system.",Entailment
i_48,Entailment,Methodologies for Implementing Sustainability: Lifecycle Assessment (LCA): Conducting LCAs to evaluate the environmental impact of software systems throughout their lifecycle can help identify areas for improvement and optimize sustainability .,"""Green"" server and datacenter design requires a focus on environmental sustainability. Prior studies have focused on operational energy consumption as a proxy for sustainability, but this metric only captures part of the environmental impact. In this paper, we argue that to understand the total impact, we need to examine the entire lifecycle of the system, beyond operational energy to also include material use and manufacturing. We make two main contributions. We present a methodology that allows such a lifecycle analysis, specifically providing attribution of sustainability bottlenecks to individual system architecture components. Using this methodology, we compare the sustainability tradeoffs between popular energy-efficiency optimizations and discuss sustainability bottlenecks and optimizations for future system designs.",Entailment
i_184,Unverifiable,"###  ** Sentence-BERT (SBERT)** SBERT is a modification of the BERT (Bidirectional Encoder Representations from Transformers) model, specifically designed to generate meaningful sentence embeddings. Unlike the original BERT, which is optimized for token-level tasks, SBERT is fine-tuned for sentence-level tasks, making it highly effective for sentence similarity comparisons .","In recent years, the research of neural networks has brought new solutions to machine translation. The application of sequence-tosequence model has made a qualitative leap in the performance of machine translation. The training of neural machine translation model depends on large-scale bilingual parallel corpus, the size of corpus directly affects the performance of neural machine translation. Under the guidance of BERT (Bidirectional Encoder) model to calculate the semantic similarity degree for the extension of training corpus in this paper. The scores of two sentences were calculated by using dot product and cosine similarity, and then the sentences with high scores were expanded to the training corpus with a scale of 540,000 sentence pairs. Finally, Transformer was used to train the Mongolian and Chinese neural machine translation system, which was 0.91 percentage points higher than the BLEU value in the baseline experiment.",Related but unverifiable
i_2376,Contradiction,"5. Decision Support Systems: Digital Agriculture Tools: AI-based decision support tools, like the Rice Crop Manager (RCM), do not significantly help smallholder farmers increase yields and incomes, as they often provide generic advice that fails to consider local conditions .","Digital technologies range from 'low-tech' tools such as mobile phones and computers to more 'high-tech' solutions such as blockchain, Internet of Things (IoT), and artificial intelligence. Digital technologies can help smallholder farmers increase their yields and incomes if they are effectively targeted to facilitate agriculture as a 'pathway out of poverty'. For digital agriculture to deliver on its promise, it is critical not only to design digital agriculture interventions that consider the target populations' needs, constraints, and appropriateness, but also to ensure that digital technologies do not exacerbate social and economic inequalities. Cognizance of these risks is essential if practitioners are to ensure that digital agriculture fulfils its potential and makes significant contributions to the Sustainable Development Goals (SDG). We use the example of a digital agriculture decision support tool, Rice Crop Manager (RCM), to illustrate the challenges of designing, targeting, and scaling digital tools to support rural development.",Missing information
i_1428,Contradiction,"Emerging Techniques: Peroral Transgastric Surgery: An incisionless approach tested in animal models, suggesting that it is already a fully viable alternative to traditional surgery .","Background and study aims: An incisionless endoscopic peroral transgastric approach to the peritoneal cavity has shown promise in animals as a potentially less invasive form of surgery. We present our experience with various endoscopic peroral transgastric procedures, reporting on the technical aspects and challenges that arose. Materials and methods: The following procedures were performed in 10 anesthetized pigs using a double-channel endoscope: peritoneoscopy (10 pigs), liver biopsy (one pig), cholecystectomy (six pigs), fallopian tube excision (one pig), and hysterectomy (one pig). Results: All the procedures were accomplished successfully. There were six minor intraoperative complications. Complete gastric cleansing and elimination of all bacteria was found to be impossible to achieve in the porcine model. Overinflation was a common problem. The lack of adequate endoscope support was a major limitation. Safe closure of the gastrotomy incision was difficult using the available clipping devices. Six pigs made an uncomplicated recovery after a follow-up period of 4-6 weeks. Subsequent pathological examination revealed deep gastric ulceration in one animal and a gastric wall abscess in another. Conclusions: Peroral transgastric surgery is technically feasible and safe in a porcine model. Although all the procedures were performed successfully, the study highlights some technical difficulties and illustrates the need for major technical innovations and extensive animal studies in order to evaluate the merits of incisionless surgery. © Georg Thieme Verlag KG Stuttgart.",Opposite meaning
s_1411,Entailment,"Challenges: Morphological Similarities: Despite their wide distribution, bumblebees exhibit morphological homogeneity, which might make distinguishing between species challenging for beginners .","Bumble bees (Bombus Latreille) occupy a wide diversity of habitats, from alpine meadows to lowland tropical forest, yet they appear to be similar in morphology throughout their range, suggesting that behavioural adaptations play a more important role in colonizing diverse habitats. Notwithstanding their structural homogeneity, bumble bees exhibit striking inter- and intraspecific variation in colour pattern, purportedly the outcome of mimetic evolution. A robust phylogeny of Bombus would provide the framework for elucidating the history of their wide biogeographical distribution and the evolution of behavioural and morphological adaptations, including colour pattern. However, morphological studies of bumble bees have discovered too few phylogenetically informative characters to reconstruct a robust phylogeny. Using DNA sequence data, we report the first nearly complete species phylogeny of bumble bees, including most of the 250 known species from the 38 currently recognized subgenera. Bayesian analysis of nuclear (opsin, EF-1α, arginine kinase, PEPCK) and mitochondrial (16S) sequences results in a highly resolved and strongly supported phylogeny from base to tips, with clear-cut support for monophyly of most of the conventional morphology-based subgenera. Most subgenera fall into two distinct clades (short-faced and long-faced) associated broadly with differences in head morphology. Within the short-faced clade is a diverse New World clade, which includes nearly one-quarter of the currently recognized subgenera, many of which are restricted to higher elevations of Central and South America. The comprehensive phylogeny provides a firm foundation for reclassification and for evaluating character evolution in the bumble bees. © 2007 The Linnean Society of London.",Entailment
s_2219,Contradiction,Key Considerations for Mitigation: Ecosystem Services Approach: Relying on an ecosystem services approach can lead to a fragmented understanding of socio-ecological impacts and hinder informed decision-making .,"Globally, the deployment of offshore wind is expanding rapidly. An improved understanding of the economic, social and environmental impacts of this sector, and how they compare with those of other energy systems, is therefore necessary to support energy policy and planning decisions. The ecosystem services approach provides a more holistic perspective of socio-ecological systems than traditional environmental impact assessment. The approach also makes possible comparisons across disparate ecological communities because it considers the societal implications of ecological impacts rather than remaining focused on specific species or habitats. By reporting outcomes in societal terms, the approach also facilitates communication with decision makers and the evaluation of trade-offs. The impacts of offshore wind development on ecosystem services were assessed through a qualitative process of mapping the ecological and cultural parameters evaluated in 78 empirical studies onto the Common International Classification for Ecosystem Services (CICES) framework. The research demonstrates that a wide range of biophysical variables can be consistently mapped onto the CICES hierarchy, supporting development of the ecosystem service approach from a broad concept into an operational tool for impact assessment. However, to improve confidence in the outcomes, there remains a need for direct measurement of the impacts of offshore wind farms on ecosystem services and for standardised definitions of the assumptions made in linking ecological and cultural change to ecosystem service impacts. The process showed that offshore wind farms have mixed impacts across different ecosystem services, with negative effects on the seascape and the spread of non-native species, and positive effects on commercial fish and shellfish, potentially of most significance. The work also highlighted the need for a better understanding of long term and population level effects of offshore wind farms on species and habitats, and how these are placed in the context of other pressures on the marine environment.",Opposite meaning
s_1646,Entailment,Controlled chamber-drying and partial fermentation to specific ethanol levels (e.g. 5% or 8%) can influence the color and aroma of the wine .,"The colour, aroma-active compounds and sensory properties of sweet wines from Pedro Ximenez grapes produced by means of an innovative winemaking procedure, based on controlled chamber-drying of grapes, partial fermentation of the must (to 4% or 8% vol ethanol) and subsequent accelerated ageing by contact with oak chips, were studied. Fermentation made the musts less brown and more yellow, whereas ageing made them darker and increased their brown, reddish and yellowish hues. Overall, the musts fermented to 8% vol ethanol exhibited higher odour activity values (OAVs). In addition, the musts aged with oak chips were slightly different from those without chips. Expert tasters gave the highest scores to the musts fermented to 8% (v/v) ethanol with 2 g/L of oak chips added. The winemaking process studied would allow the existing range of sweet wines from dried grapes to be expanded by using a fast, flexible, hygienic procedure.",Entailment
s_997,Entailment,"Drawbacks: Chemical Compatibility: The materials used in some filters may be susceptible to degradation when exposed to certain decontamination agents. However, some HEPA filters have shown good chemical compatibility with agents like H₂O₂ and ClO₂ .","High Efficiency Particulate Absolute (HEPA) filters are widely used to provide clean air to facilities where micro-organisms cannot be tolerated. In this process, the filter is exposed to the decontamination agent with potential detrimental effects. Commonly used agents can be divided into two broad groups, gases and vapors used in space decontamination and solutions used for surface decontamination in the facility. Camfil has considered the exposure of its HEPA filters to decontamination agents and lab testing and field experience indicates that, in general, the materials used by the company for HEPA filters are suitable for these applications. Camfil's HEPA filters show excellent chemical compatibility with H<inf>2</inf>O<inf>2</inf> under typical decontamination cycles. The materials used by the company to construct HEPA filters show good to excellent chemical compatibility with ClO<inf>2</inf> under typical decontamination cycles.",Entailment
i_1454,Entailment,"Additional Considerations: Nutritional Education: While increased nutritional education and awareness are beneficial, they are not the only factors influencing successful conception for women planning to conceive .","The characteristics of pregnant women as well as the diet and nutrient intake of women before becoming pregnant, and during pregnancy and lactation, have an important role in early life development. This chapter discusses current practice and provides recommendations in relation to early life development. It describes the characteristics of pregnant women in Europe today and recent trends in relation to age and ethnicity. Current recommendations relating to weight and diet alongside current practice are discussed with regard to various stages of pregnancy and early life feeding, namely, pre-pregnancy, pregnancy, lactation, breastfeeding, formula feeding, and weaning and complementary feeding. There is a need for increased nutritional education and awareness as well as providing support for women before, during and after pregnancy.",Entailment
i_1460,Entailment,This variability is exacerbated by disparities in healthcare access and resources .,"Healthcare in the United States (US) is burdened with enormous healthcare disparities associated with a variety of factors including insurance status, income, and race. Highly vulnerable populations, classified as those with complex medical problems and/or social needs, are one of the fastest growing segments within the US. Over a decade ago, the US Surgeon General publically challenged the nation to realize the importance of oral health and its relationship to general health and well-being, yet oral health disparities continue to plague the US healthcare system. Interprofessional education and teamwork has been demonstrated to improve patient outcomes and provide benefits to participating health professionals. We propose the implementation of interprofessional education and teamwork as a solution to meet the increasing oral and systemic healthcare demands of highly vulnerable US populations. © 2013 Allison A. Vanderbilt et al.",Entailment
s_524,Contradiction,"Oscillatory Parameters and Fluid Instability: Horizontal Oscillations: In porous media, horizontal periodic oscillations can lead to Rayleigh-Taylor and parametric instabilities. Increasing the oscillation frequency destabilizes these instabilities, indicating that careful tuning of oscillation parameters can manage fluid instability .","We investigate the effect of horizontal periodic oscillation on the interfacial instability of two immiscible and viscous fluids of different densities in a fully saturated porous media. A linear stability analysis of the viscous and time-dependent basic flow leads to a periodic oscillator describing the evolution of the interfacial perturbation amplitude. The horizontal oscillation leads to the occurrence of two types of instability, the Kelvin-Helmholtz's instability and the parametric resonance. These instabilities appear at the frontier between water and petroleum and have a practical interest in oil reservoir engineering. The results show that, an increase of the oscillation frequency destabilizes the Kelvin-Helmholtz instability and displaces the parametric instability regions toward the short wavelength perturbation. Also, we examine mainly how the other physical parameters of the system affect the instabilities for various permeability and porosity values of the porous medium as well as for relative heights of the two fluid layers.",Entity error
i_1006,Contradiction,Non-uniformity: This indicates that the optical power is distributed unevenly among the output fibers. Low uniformity results in each output receiving a significantly different amount of power .,"The first experimental demonstration of a 1× 4 all-fiber power splitter capable of high-power operation is presented. The splitter, prepared by fused taper technique and fusion splicing technique, consists of one input fiber with a core diameter of 400μm (NA<inf>CORE</inf> = 0.22 ) and four output fibers with a core diameter of 200μm (NA<inf>CORE</inf> = 0.22 ). The device was tested at a laser power up to 166 W and it achieves a low excess loss of 0.56 dB and an excellent uniformity of less than 0.3 dB in port-to-port power splitting ratio. The results of theoretical simulation by the 3-D beam propagation method show that the performance of this splitter could be optimized further through modifying structure parameters.",Opposite meaning
i_1879,Unverifiable,"4. Spatial Variation and Tree Height: The spatial variation of canopy temperature during the day is influenced by tree height and surrounding greenspace. Research in New York City revealed that greenspace coverage and tree height significantly contribute to cooling the local canopy, with taller trees reducing daytime warming .","Despite the importance of urban trees' surface temperature in assessing micro-climate interactions between trees and the surrounding environment, their diurnal evolution has been largely understudied at a city-wide scale due to a lack of effective thermal observations. By downscaling ECOSTRESS land surface temperature imaginary over New York City, we provide the first diurnal analysis of city-scale canopy temperature. Research reveals a remarkable spatial variation of the canopy temperature during daytime up to 5.6 K (standard deviation, STD), while the nighttime STD remains low at 1.7 K. Further, our analysis shows that the greenspace coverage and distance to bluespaces play an important role in cooling the local canopy during daytime, explaining 25.0–41.1% of daytime spatial variation of canopy temperatures while surrounding buildings modulate canopy temperature asymmetrically diurnally: reduced daytime warming and reduced nocturnal cooling. Built on space-borne observations and a flexible yet robust statistical method, our research design can be easily transferable to explore urban trees' response to local climate across cities, highlighting the potentials of advancing the science and technologies for urban forest management.",Related but unverifiable
i_830,Entailment,"Carbon Monoxide (CO): CNG generally produces lower CO emissions compared to gasoline. For instance, CNG can reduce CO emissions by 45-95% .","Dilution of natural gas fuel with air for use in a pilot ignited direct injection natural gas engine was investigated to evaluate the impact of this strategy on emissions and engine performance. A representative heavy-duty mode (mid to high-load at medium speed) was considered and the equivalence ratio (F) and exhaust gas recirculation (EGR) rates were varied from this representative mode. Air dilution resulted in a significant reduction in several pollutants: 90 to 97% reductions in black carbon particulate matter, 45 to 95% reductions in carbon monoxide, 68 to 85% reductions in total unburnt hydrocarbons. NOx emissions were found to increase by between 1.5 and 2.5x, depending on F and EGR, for a fixed combustion phasing. Beyond the emissions improvements, the gross indicated thermal efficiency increased by 2.5 percentage points at both high and low EGR rates. At higher EGR rates, this improvement was due to improved combustion efficiency, while the mechanism for efficiency improvement at lower EGR rates was unclear. The application of air-fuel dilution requires compressed air (>300 bar) to mix with natural gas at high pressures. A system level analysis considered the compression power required by an industrial 3-stage reciprocating compressor and indicated that the gross indicated thermal efficiency improvements could compensate for the compression requirements for engine operation at high F.",Entailment
i_669,Contradiction,"Crash Safety: Mechanical loadings during accidents do not pose significant risks. Studies have shown that battery cells remain stable under mechanical stress without any failure stages, and computational models are unnecessary for predicting battery performance in crashes .","Safety of lithium-ion batteries under mechanical loadings is currently one of the most challenging and urgent issues facing in the Electric Vehicle (EV) industry. The architecture of all types of large-format automotive batteries is an assembly of alternating layers of anode, separator, and cathode. The anode is composed of a very thin copper foil double-side coated with graphite powders, while the cathode is an aluminum foil with the active material coating. Each of the five components may develop a large plastic deformation until fracture. This study focuses on the effect of the properties of the coated materials on the local and global responses of a battery cell. Both anode and cathode coatings are described by the Drucker-Prager/Cap plasticity model, which is carefully calibrated through axial and lateral compression tests and closed-die compaction test. A separate experimental effort is put on finding the strength of the interface between the foils and the granular materials with a binder. The main new finding is that in the cases of plane-strain and axisymmetric loadings, the failure of cells proceeds in two stages. First, the shear bands localize along discrete lines. Then, fracture develops inside the shear bands due to large local strain gradient. The present model is applied to study the deformation and strength of large-format pouch cells subjected to local indentations by rigid punches. The prediction of the present model follows closely the measured load-displacement curve and captures with good accuracy the magnitude of the peak load and the corresponding critical displacement. In addition, an excellent correlation is achieved between the calculated profile of the through-thickness crack and the result of the micro CT scan. The present detailed computational model should be useful in the battery design process and will serve as an important new computational tool for assessing the safety of lithium-ion batteries against mechanical loading.",Opposite meaning
s_2121,Unverifiable,"Factors Influencing N₂O Emissions: Temperature: Higher temperatures generally reduce N₂O emissions, although the effect can vary depending on the specific conditions of the treatment process .","[7] Substantial amounts of greenhouse gases (GHG) have been demonstrated to be emitted in wastewater treatment plants (WWTP). One of the GHG with a great influence is nitrous oxide (N2O), which is emitted during the nitrification and denitrification processes in a biological wastewater treatment. This paper proposes the implementation of a control strategy in order to reduce N2O emissions in the nitrification process. Due to the fact that N2O emissions are produced as an intermediate in the nitrification process, the idea of the present work is based on the implementation of a nitrite control by manipulating dissolved oxygen (So) in order to avoid partial nitrification and thus to reduce N2O peaks. A hierarchical control strategy is proposed, where the higher level is composed of an affine function and the lower level of a Proportional-Integral (PI) controller. A modified version of Benchmark Simulation Model 2 (BSM2G) that includes GHG emissions is used for the evaluation. The simulation results show that the proposed control strategy achieve the reduction of GHG emissions by reducing N2O. However, additional control strategies must also be implemented to take into account the other evaluation criteria of the plant. [18] As part of a broader study on the riverine biogeochemistry in the Athi-Galana-Sabaki (A-G-S) River catchment (Kenya), we present data constraining the sources, transit and transformation of multiple nitrogen (N) species as they flow through the A-G-S catchment (∼47 000 km2). The data set was obtained in August-September 2011, November 2011, and April-May 2012, covering the dry season, short rain season and long rain season respectively. Release of (largely untreated) wastewater from the city of Nairobi had a profound impact on the biogeochemistry of the upper Athi River, leading to low dissolved oxygen (DO) saturation levels (36-67%), high ammonium (NH4+) concentrations (123-1193 μmol L−1), and high dissolved methane (CH4) concentrations (3765-6729 nmol L−1). Riverine dissolved inorganic nitrogen (DIN; sum of NH4+ and nitrate (NO3−); nitrite was not measured) concentration at the most upstream site on the Athi River was highest during the dry season (1195 μmol L−1), while DIN concentration was an order of magnitude lower during the short and long rain seasons (212 and 193 μmol L-1, respectively). During the rain seasons, low water residence time led to relatively minimal in-stream N cycling prior to discharge to the ocean, whereas during the dry season we speculate that prolonged residence time creates two differences comparative to wet season, where (1) intense N cycling and removal of DIN is possible in the upper to mid-catchment and leads to significantly lower concentrations at the outlet during the dry season, and (2) as a result this leads to the progressive enrichment of 15N in the particulate N (PN) pool, highlighting the dominance of untreated wastewater as the prevailing source of riverine DIN. The rapid removal of NH4+ in the upper reaches during the dry season was accompanied by a quantitatively similar production of NO3− and nitrous oxide (N2O) downstream, pointing towards strong nitrification over this reach during the dry season. Nitrous oxide produced was rapidly degassed downstream, while the elevated NO3− concentrations steadily decreased to levels observed elsewhere in more pristine African river networks. Low pelagic primary production rates over the same reach suggest that benthic denitrification was the dominant process controlling the removal of NO3−, although large cyanobacterial blooms further downstream highlight the significant role of DIN assimilation by primary producers also. Consequently, the intense nitrification and uptake of N by algae leads to significant enrichment of 15N in the PN pool during the dry season (mean: +16.5 ± 8.2‰ but reaching as high as +31.5‰) compared to the short (+7.3 ± 2.6‰) and long (+7.6 ± 5.9‰) rain seasons. A strong correlation between the seasonal N stable isotope ratios of PN (δ15NPN) and oxygen stable isotope ratios of river water (δ18OH2O; as a proxy of freshwater discharge) presents the possibility of employing a combination of proxies - such as δ15NPN of sediments, bivalves and near-shore corals - to reconstruct how historical land use changes have influenced nitrogen cycling within the catchment, whilst potentially providing foresight on the impacts of future land management decisions. © Author(s) 2014.",Related but unverifiable
s_129,Entailment,"Robotics and expert systems can handle physical tasks within the library, such as sorting and shelving books .","This paper focuses on the opportunities and challenges associated with the use of artificial intelligence (AI) in academic library operations. In the quest to render fast, effective and efficient services, academic libraries have adopted different technologies in the past. Artificial intelligence technologies is the latest among the technologies currently being introduced in libraries. The technology which is considered an intelligent system, come in the form of robots and expert systems which have natural language processing, machine learning and pattern recognition capabilities. This paper examined the features of AI, the application of AI to library operations, examples of academic libraries with AI technologies in Sub-Saharan Africa, the need for AI in libraries and the challenges associated with the adoption of AI in libraries. The study concluded that AI holds a lot of prospects for the improvement of information services delivery in African academic libraries. Consequently, its adoption is a sinequanon to delivering robust library services in the Fourth Industrial Revolution (4IR).",Entailment
i_1829,Contradiction,"Biodiversity and Habitat Destruction: Beaver activities can lead to the destruction of wetland environments, negatively impacting a variety of species. The creation of ponds and wetlands by beavers may reduce habitat complexity, which can harm various aquatic and terrestrial species. This habitat alteration is detrimental to maintaining biodiversity in agricultural and forested landscapes .","Beavers are the archetypal keystone species, which can profoundly alter ecosystem structure and function through their ecosystem engineering activity, most notably the building of dams. This can have a major impact upon water resource management, flow regimes and water quality. Previous research has predominantly focused on the activities of North American beaver (Castor canadensis) located in very different environments, to the intensive lowland agricultural landscapes of the United Kingdom and elsewhere in Europe. Two Eurasian beavers (Castor fiber) were introduced to a wooded site, situated on a first order tributary, draining from intensively managed grassland. The site was monitored to understand impacts upon water storage, flow regimes and water quality. Results indicated that beaver activity, primarily via the creation of 13 dams, has increased water storage within the site (holding ca. 1000 m<sup>3</sup> in beaver ponds) and beavers were likely to have had a significant flow attenuation impact, as determined from peak discharges (mean 30 ± 19% reduction), total discharges (mean 34 ± 9% reduction) and peak rainfall to peak discharge lag times (mean 29 ± 21% increase) during storm events. Event monitoring of water entering and leaving the site showed lower concentrations of suspended sediment, nitrogen and phosphate leaving the site (e.g. for suspended sediment; average entering site: 112 ± 72 mg l<sup>− 1</sup>, average leaving site: 39 ± 37 mg l<sup>− 1</sup>). Combined with attenuated flows, this resulted in lower diffuse pollutant loads in water downstream. Conversely, dissolved organic carbon concentrations and loads downstream were higher. These observed changes are argued to be directly attributable to beaver activity at the site which has created a diverse wetland environment, reducing downstream hydrological connectivity. Results have important implications for beaver reintroduction programs which may provide nature based solutions to the catchment-scale water resource management issues that are faced in agricultural landscapes.
[2]: The aim of the study was to examine the impact of the European beaver, Castor fiber L., on the ichthyofauna of Negrylów Stream. Three study sites were designated in segments of the stream with running waters and two in beaver ponds. The waters at all the sites were characteristic of naturally polluted mountain streams. The occurrence of brown trout, Salmo trutta trutta m. fario L.; Siberian sculpin, Cottus poecilopus Heckel; common minnow, Phoxinus phoxinus (L.); and stone loach, Barbatula barbatula (L.), was confirmed. The highest density and abundance of brown trout was noted in the ponds, where the mean lengths and weights of brown trout were also the highest noted in the current study. Large trout occurred only in the ponds. In the shallow, running segments of the stream mostly brown trout fry were caught. Differences among fish assemblages in the segments of the stream and the ponds were statistically significant. After the introduction of the beavers, the state of the ichthyofauna in Negrylów Stream, which had suffered substantial degradation from forestry works, improved markedly. In comparison to analagous segments of other streams in the Bieszczady Mountains, fish density and biomass here were very high.",Opposite meaning
s_1935,Entailment,"The interaction between DOC and soil organic matter, including microbial activity and mineralization processes, can alter the isotopic composition, making it difficult to obtain representative samples .","In this study, we examined changes in isotopic (<sup>13</sup>C and <sup>14</sup>C) and spectroscopic (UV and <sup>13</sup>C NMR) properties of dissolved organic carbon (DOC) in relation to soil organic matter (SOM) to elucidate the sources and sinks of DOC as water percolates through the soils of two contrasting upland coastal California ecosystems-a redwood forest and a coastal prairie. Despite differences in the distribution of C stocks and litter chemistry at these two sites, we found similar shifts in DOC chemistry with soil depth. DOC concentrations dropped rapidly with increasing depth, with an accompanying decrease in the C:N ratio, an increase in the δ<sup>13</sup>C value and an decrease in specific UV adsorption. In the grassland soil, Δ<sup>14</sup>C values declined from current atmospheric values (+70‰) in the surface horizon to -75‰ at 100 cm. In the redwood soil, the Δ<sup>14</sup>C value of 111‰ in O horizon leachates was indicative of OM with a residence time of 8-10 yrs, with a decrease in Δ<sup>14</sup>C values to -80‰ at 100 cm. Solid-state CP/MAS <sup>13</sup>C NMR spectra were generally most similar to highly humified OM, with a general decrease in the relative abundance of aromatic compounds and an increase in the alkyl C/O-alkyl C ratio with increasing depth. All of these trends are consistent with the shifts in SOM properties with increasing depth, which are interpreted to mean a shift from fresh plant material to older, highly altered OM. In this Mediterranean climate, we found distinct seasonal shifts in the quantity and composition of DOC found in soil solution during the winter rainy period that was also consistent with a shift from recent labile substrates to older, highly altered OM. These results fit in with a growing body of literature suggesting that the source of much of the DOC within mineral soils is the local soil OM, and the <sup>14</sup>C data, in particular, indicate that DOC at depth is not simply the fraction of surficial leachates that have not been adsorbed or decomposed. Rather, exchange reactions with a portion of the more stabilized SOM pool exert the strongest control on both the concentration and composition of DOC found in these soils. © 2008 Springer Science+Business Media B.V.
[4]: Despite being a crucial component of nutrient cycling and soil carbon (C) dynamics in forest ecosystems, there is too little information from past studies to discern whether dissolved organic carbon (DOC) exchanges with soil organic carbon or passes unaltered through soils. In this study, we added <sup>13</sup>C-labelled litter-derived DOC into different depth soil columns in a 180-day incubation experiment to determine the fate of DOC in soils, and to monitor the changes in DOC composition when it percolates through the soil. The results showed that δ<sup>13</sup>C values increased in soil microbes, which indicated that some litter-derived DOC was immobilized by soil microbial communities. Approximately 76% of litter-derived DOC was retained in the soil (60% in topsoil and 16% in midsoil). Meanwhile, 18%, 4%, and 3% of litter-derived DOC were mineralized into CO<inf>2</inf> in topsoil, midsoil and subsoil respectively. Only 0.04% of litter-derived DOC leached from the soil column (0–60 cm). These results indicated that DOC was mainly retained on soil, and a small portion was mineralized by microorganisms, with minimal leaching. The composition of water soluble soil organic carbon (WSOC) and leachate DOC (LDOC) were similar between the control and treatment. This indicated that the composition of WSOC and LDOC was more similar to soil C than the added DOC, which supports the previously hypothesized dynamic exchange model. These findings provide new insight by showing that most litter-derived DOC is sequestered in forest soils.",Entailment
s_1812,Entailment,"Environmental Impact: Flood Mitigation: Sponge cities are designed to control urban flooding by enhancing rainwater infiltration, retention, and storage. This reduces the risk of urban waterlogging and improves the overall resilience of cities to flood events .","In recent years, urban waterlogging problems have become more and more serious, which has led to flood disasters in some cities. The Chinese government launched the sponge city pilot construction in 2015 to mitigate the risk of urban flooding and control the runoffin source areas. Rain-runoffcontrol is one of the main indices of a sponge city, thus, evaluating its control effect is essential for sponge city construction. This paper chose Fenghuang city, located in the west of Hunan province, as a case study area to assess the rainwater control effect by using the MIKE FLOOD model. The results showed that: (1) the total annual runoffcontrol rate (TARCR) of sponge city design was a reasonable indicator for daily rainwater control; (2) the goal of Fenghuang Sponge City was close to the 1-year rainfall event; and (3) infiltration and storage measures could reduce but not eliminate urban waterlogging. The capacity of the drainage system should be fundamentally improved to enhance the prevention standards of urban waterlogging.
[3]: Since 2014, China has been implementing the Sponge City Construction initiative, which represents an enormous and unprecedented effort by any government in the world for achieving urban sustainability. According to preliminary estimates, the total investment on the Sponge City Plan is roughly 100 to 150 million Yuan (RMB) ($15 to $22.5 million) average per square kilometer or 10 Trillion Yuan (RMB) ($1.5 Trillion) for the 657 cities nationwide. The Sponge City Plan (SCP) calls for the use of natural processes such as soil and vegetation as part of the urban runoff control strategy, which is similar to that of low impact development (LID) and green infrastructure (GI) practices being promoted in many parts of the world. The SCP includes as its goals not only effective urban flood control, but also rainwater harvest, water quality improvement and ecological restoration. So far, the SCP implementation has encountered some barriers and challenges due to many factors. The present paper presents a review of those barriers and challenges, offers discussions and recommendations on several technical aspects such as control goals and objectives; planning/design and construction of LID/GI practices; performance evaluation. Several key recommendations are proposed on Sponge City implementation strategy, Site-specific regulatory framework and technical guidance, Product innovation and certification, LID/GI Project financing, LID/GI professional training and certification, public outreach and education. It is expected that the successful implementation of the SCP not only will bring about a sustainable, eco-friendly urbanization process in China, but also contribute enormously to the LID/GI research and development with the vast amount of relevant data and experiences generated from the Sponge City construction projects.[Figure not available: see fulltext.].",Entailment
s_665,Unverifiable,"Challenges in Power Delivery and Conversion: Cost and Optimization: Modeling and Simulation: Traditional power systems modeling tools are complex and time-consuming. There is a need for faster, more efficient modeling methodologies to optimize energy efficiency, area occupied by power delivery solutions, and associated costs. Additionally, the integration of artificial intelligence in modeling could further enhance the efficiency of power delivery systems, although this remains an area of ongoing research and is not yet fully validated .","Power systems modeling tools used to analyze static and dynamic characteristics usually rely on detailed and complex models, thus taking a long simulation time. Due to the acceleration of time to market of today's computing platforms, it is required to arrive at feasible solution options in a short amount of time to meet cost and time targets. Specifically, the areas of power conversion and power management traditionally rely on experimental verification and are lacking in computer design methodologies. In this paper, a modeling methodology based on fundamental building block models for power delivery systems is presented to address the aspects of energy efficiency optimization, area occupied by the power delivery solution and the cost associated with power conversion. © 2009 IEEE.",Related but unverifiable
s_2192,Entailment,"The development and validation of these alternative methods are crucial for accurate risk assessments and reducing false positives, and it is likely that these methods will also lead to a significant reduction in the overall costs associated with chemical safety testing in the future .","Liverpool John Moores University and FRAME recently conducted a research project sponsored by Defra, on the status of alternatives to animal testing with regard to the European Union REACH (Registration, Evaluation and Authorisation of Chemicals) system for the safety testing and risk assessment of chemicals. The project covered all the main toxicity endpoints associated with the REACH system. This paper focuses on the prospects for using alternative methods (both in vitro and in silico) for mutagenicity (genotoxicity) and carcinogenicity testing - two toxicity endpoints, which, together with reproductive toxicity, are of pivotal importance for the REACH system. The manuscript critically discusses well-established testing approaches, and in particular, the requirement for short-term in vivo tests for confirming positive mutagenicity, and the need for the rodent bioassay for detecting non-genotoxic carcinogens. Recently-proposed testing strategies focusing on non-animal approaches are also considered, and our own testing scheme is presented and supported with background information. This scheme makes maximum use of pre-existing data, computer (in silico) and in vitro methods, with weight-of-evidence assessments at each major stage. The need for the improvement of in vitro methods, to reduce the generation of false-positive results, is also discussed. Lastly, ways in which reduction and refinement measures can be used are also considered, and some recommendations are made for future research to facilitate the implementation of the proposed testing scheme.",Entailment
s_1236,Entailment,"Challenges and Considerations: Sustainability and Cost-Effectiveness: Programs like the one in Patumthani Province, Thailand, reveal the drawbacks of cost-ineffective and unsustainable models that exclude community health volunteers and family health leaders .","Objective: To determine an appropriate, cost-effective and sustainable model of health services for prevention and control of hypertension in a primary care unit. Study Design: Operational research. Material and Method: The presented study was to develop a model that utilized health personnel, village health volunteers (VHVs) and family health leaders (FHLs) to improve health services to prevent and control hypertension in three primary care units (PCU) in Patumthani Province. The model was designed to include two intervention groups (Group I, II) and a control group (Group III). In Group I (Bangdaeu 1), health personnel, VHVs and FHLs took part in the design of services to help prevent and control hypertension, while in Group II (Bangkayang) and Group III (Banklang), only health personnel and VHVs participated. Five hundred and forty villagers participated in the present study, with an approximate equal number in each group. The project included training of persons involved in the project at the beginning with subsequent designs of community-based interventions (Part I), cost effectiveness study (Part II), and assessment of participation of VHVs and FHLs' impact and project's sustainability (Part III). Three measurements on various outcome variables were done at baseline (Measure 1), right after community- based activities were implemented (Measure 2) and at the end of project (Measure 3) by Cochran's Q test. Results: Group I showed a steadily improving trend in outcome variables such as high level of knowledge were higher in Measure 2, 3 than Measure 1, (11.6%, 89.9%, 100% respectively). The trend in Group II showed a defection at Measure 3 (5.7%, 50.9%, 43.4%). However, an improving trend in Group III was also observed, but less obvious than in Group I (8.1%, 21.7%, 24.8%). Determining the costs for the real program effects showed that Group I model is most cost-effective, with least unit cost per a unit of improvement. Result from Part III showed that the project is sustainable if obstacles found in the present study could be removed. Conclusion: The present study demonstrates the effects of community-based approaches by VHVs and FHLs, with support from health personnel with a high prospect of sustainability and transferability to other areas.",Entailment
i_1595,Entailment,"Exploration of Waste Management through Husserl's Phenomenological Approach: Husserl's Phenomenological Approach: Phenomenology: Husserl's phenomenology is a philosophical method focused on the systematic investigation of human experiences and consciousness . It involves describing phenomena as they are perceived by individuals, without preconceived notions or theories.","This chapter assesses the usefulness of a phenomenological investigation for educational purposes. It introduces the systematic investigation of human experiences in the form of a philosophical tradition called 'phenomenology'. The chapter presents some aspects of E. Husserl's phenomenology as a structural investigation of consciousness. Cognitive psychology emerged between the 1950s and 1970s as the dominant approach to the investigation of the mind in a scientific manner. Husserl battles with mere physiological accounts of the mind, promoting his approach of assessing and describing the experiential dimensions that manifest themselves individually in relation to these physiological events. However, it would be naive to portray the suggested pairing of phenomenology and empirical research, be it for psychological or educational purposes, as one that is already sorted in all its aspects. While the teacher walks past the desks at which the learners sit, s/he can spot a coin on one of the desks.
[2]: Edmund Husserl (1859–1938) was one of the most influential philosophers of the twentieth century, and is known as the founder of phenomenology. Husserl was famously led into philosophy by Franz Brentano (1838–1917), who reintroduced the medieval notion of ""intentionality"" into his contemporary philosophical reflections; Husserl later autonomously developed the concept in his Logical Investigations, the work that marks the inception of phenomenology.",Entailment
s_581,Unverifiable,"Soft and Flexible Grippers: Soft and flexible grippers, equipped with stretchable sensing skins and inertial measurement units (IMUs), can conform to the shape of objects, improving grasp success and stability. These grippers can handle compliant, delicate, or irregularly shaped objects more effectively than rigid grippers, and they may also enhance the overall efficiency of robotic systems in complex environments by reducing the need for extensive programming and control adjustments .","Tactile sensors have been increasingly used to support rigid robot grippers in object grasping and manipulation. However, rigid grippers are often limited in their ability to handle compliant, delicate, or irregularly shaped objects. In recent years, grippers made from soft and flexible materials have become increasingly popular for certain manipulation tasks, e.g., grasping, due to their ability to conform to the object shape without the need for precise control. Although promising, such soft robot grippers currently suffer from the lack of available sensing modalities. In this work, we introduce a soft and stretchable sensing skin and incorporate it into the two fingers of a shape-memory actuated soft gripper. The onboard sensing skin includes a 9-axis inertial measurement unit (IMU) and five discrete pressure sensors per finger. We use this sensorized soft gripper to study grasp success and stability of over 2585 grasps with various objects using several machine learning methods. Our experiments show that LSTMs were the most accurate predictors of grasp success and stability, compared to SVMs, FFNNs, and ST-HMP. We also evaluated the effects on performance of each sensor's data, and the success rates for individual objects. The results show that the accelerometer data of the IMUs has the largest contribution to the overall grasp prediction, which we attribute to its ability to detect precise movements of the gripper during grasping.",Related but unverifiable
i_1230,Contradiction,The presence of MPE can be an indicator of advanced disease and may influence prognosis .,"Purpose: Malignant pleural effusions (MPE) may either coincide with or follow the diagnosis of a primary tumor. Whether this circumstance influences prognosis has not been well substantiated. Methods: Retrospective review of all consecutive patients who were cared for at a Spanish university hospital during an 11-year period and received a diagnosis of MPE. Results: Of 401 patients, the MPE was the first evidence of cancer in 265 (66%), and it followed a previously diagnosed neoplasm in 136 (34%). Lung cancer predominated in the former group (131, 50%), and breast cancer in the latter (55, 40%). MPE that were the presenting manifestation of hematological and ovarian tumors had a statistically significant survival advantage as compared to those which developed in patients from a previously known cancer (respective absolute differences of 41 and 20 months; p < 0.005). Conclusions: In hematological and ovarian malignancies, the synchronous or metachronous diagnosis of MPE may have prognostic implications.",Missing information
i_1380,Contradiction,"Risk-Adapted Therapy: While it is suggested that tailoring treatment based on molecular subgroup and risk factors could reduce long-term side effects, it is likely that this approach will not significantly impact overall survival rates, which remain largely unchanged .","Medulloblastoma (MB) is the most common malignant brain tumor in children. Although multimodality treatment regimens including surgery, radiotherapy and chemotherapy have greatly improved disease outcome, about one-third of MB patient remains incurable, and many long-term survivors are suffered from deleterious effects due to aggressive treatment. Understanding the signaling pathways and the genetic mechanisms contributed to MB development would be the key to develop novel therapeutic treatment strategies for improving survival and outcome of MB. In this review, we discuss the biological signaling pathways involved in MB pathogenesis. We also go through the current international consensus of four core MB subgroups namely, SHH, WNT, Group 3, and Group 4. This is adopted based on the knowledge of genomic complexity of MB as analyzed by recent high-throughput genomic technology. We talk about immunohistochemistry assays established to determine molecular subgroup affiliation. In the last part of review, we discuss how identification of molecular subgroups is going to change our routine disease diagnosis and clinical management.
[8]: Medulloblastoma and supratentorial primitive neuroectodermal tumors (sPNETs) are embryonal brain tumors and are the most common malignant brain tumors in the pediatric population. Current therapy for these children most often includes a multi-modality approach including surgery, radiation and chemotherapy. With modern therapy, overall survival for medulloblastoma is approximately 80% while survival for sPNET is 30–50%. Factors associated with prognosis include the presence of disseminated disease, extent of surgical resection and patient age, with children <3 years categorized as high risk patients given the inability to deliver high dose radiation at this young age due to significant long term effects. Increasingly, there is great interest in further sub-grouping patients based on molecular profiling which is highly predictive of outcome. While four molecular subgroups have emerged for medulloblastoma, the sub-grouping of sPNET has proved more challenging with an increasing awareness that this is a heterogeneous group in which histological diagnosis is challenging. The current challenges for both medulloblastoma and sPNET include the determination of optimal therapy for children such as decreased therapy for favorable risk groups and intensification and targeted therapy for high risk groups. Additionally, data are now available for long-term survivors which detail the significant effects of therapy in this young population.
[9]: Purpose of Review: Medulloblastoma is the main primitive neuroectodermal tumour of the posterior fossa in childhood. The classical therapeutic approach consists of surgical resection, followed by craniospinal irradiation. Because of the good overall survival (75%), the main recent research efforts focus on refining the most relevant prognostic stratification and in decreasing the long-term sequelae. Recent Findings: Thanks to the better understanding of the heterogeneity of medulloblastomas, clinical, histological and biological markers have been clearly identified and allow risk-adapted strategies. A subset of tumours of early childhood (<3-5 years), frequently associated with a Sonic Hedgehog signalling, might be cured without irradiation. In older children, several trials have demonstrated the safety of reduced craniospinal irradiation in standard risk tumours. Furthermore, the evidence of an excellent prognosis associated with a subset of tumours characterized by an activation of the WNT pathway leads to forthcoming de-escalating strategies. Reducing long-term sequelae also relies on new surgical approaches aiming at reducing the cerebellar injuries. Tremendous efforts have also been made in defining the most adapted irradiation doses and fields. Intensity-modulated radiotherapy and proton beam therapy might also influence the long-term neurological and endocrine defects of the patients. Summary: Histological and biological characteristics clearly define various prognostic groups within medulloblastomas; confirming the overall good outcome and reducing long-term sequelae are the main focus of current clinical trials. © 2011 Wolters Kluwer Health | Lippincott Williams & Wilkins.",Opposite meaning
s_1740,Entailment,"Key Points: Nicotiana tabacum: This plant is well-known for its nicotine content, which is present in its leaves and nectar. Bees visiting these plants can ingest nicotine from the nectar .","Nicotiana tabacum, a traditional medicinal plant which is valued for its benefits as sedative, laxative, tonic, emetic, carminative, antispasmodic and vermifuge, and in management of skin diseases, local infections, bronchitis, asthma and inflammation. The leaves has been employed in curing old ulcers and painful tumors and for the extraction of the active principle i.e. nicotine which, usually in the form of sulphate, is widely used as an insecticide and in the production of synthetic nicotinic acid and nicotinamide. The current study was therefore carried out to provide requisite pharmacognostic details about the leaves of Nicotiana tabacum. Pharmacognostic evaluation included examination of morphological and microscopical characters; physicochemical properties, phytochemical analysis, and HPTLC fingerprint. The powder microscopy showed the presence of glandular trichome (single celled head and multicellular stalk), covering trichome (multicellular unisereate covering trichome), paracytic stomata, acicular and prismatic calcium oxalate crystals and spiral vessel with bordered thick wings. The phytochemical screening revealed the presence of alkaloids, flavonoids, phytosterols, triterpinoids, tannins and carbohydrates. The Rf values detected at 400 nm by qualitative densitometric HPTLC fingerprint, can be used as identifying marker for petroleum ether extract. The present study will provide the information with respect to identification and authentication of crude drug.",Entailment
i_1717,Entailment,"4. Impact on Pavement Lifecycle and Performance: Delayed maintenance can shorten the overall service life of pavements, necessitating more frequent and extensive rehabilitation efforts. This not only increases the environmental footprint but also the economic costs associated with pavement management .","The volume of air traffic continues to grow, resulting in an increasing frequency of aircraft movements as well as increase in gross weight. To cope with such growth it is necessary to make optimal use of all available runways, taxiways and aprons. An optimum utilization of such resources also means that maintenance has to be structured into a planned approach making it a prerequisite to have insight knowledge of the performance of the pavements, asphalt as well as concrete. By carrying out the right maintenance at the right time, the airport will reduce the overall need for maintenance, which in turn will produce economic benefits. The pressure on the availability of all airport pavements at any time does mean that the condition of pavements has to be forecasted based on reliable performance indicators and performance models. For many airports the PCI procedure is the primary tool for forecasting and budgeting. A pavement condition is often periodically evaluated using various condition measurements such as (automated) visual condition surveys, non-destructive deflection testing (PCN), roughness (BBI) and skid resistance. Bringing all this data together in a PMS like PAVER will allow to visualize the condition of the pavement sections in GIS-based maps. This paper discusses the issues busy international airports do face with the increase in movements approaching saturation levels of the runways leaving ample time for the minimum maintenance required. Machine-based condition measuring tools are required in combination with a long term prediction of the structural as well as functional condition based on proper historic information. This requires proper pavement management to avoid critical maintenance to be executed beyond the point of no return.",Entailment
i_975,Unverifiable,"They often originate in the interfacial transition zones (ITZ) between the coarse aggregates and the cement paste, where stress concentrations are higher, and it is believed that the presence of certain additives in the concrete mix can further influence the formation and propagation of these microcracks .","Phenomena occurring during the curing of concrete can decrease its mechanical properties, specifically strength, and serviceability, even before it is placed. This is due to excessive stresses caused by temperature gradients, moisture changes, and chemical processes arising during the concreting and in hardened concrete. At stress concentration sites, microcracks form in the interfacial transition zones (ITZ) in the early phase and propagate deeper into the cement paste or to the surface of the element. Microcracks can contribute to the development of larger cracks, reduce the durability of structures, limit their serviceability, and, in rare cases, lead to their failure. It is thus important to search for a tool that allows objective assessment of damage initiation and development in concrete. Objectivity of the assessment lies in it being independent of the constituents and additives used in the concrete or of external influences. The acoustic emission-based method presented in this paper allows damage detection and identification in the early age concrete (before loading) for different concrete compositions, curing conditions, temperature variations, and in reinforced concrete. As such, this method is an objective and effective tool for damage processes detection.
[4]: In the present work, the effect of microcracks present at the interface of coarse aggregates and cement mortar in plain concrete is studied with the aid of micromechanics. The presence of microcracks affects the macroscopic response of cementitious composites to a great extent. The conditions under which the cracks propagate along the interface or kink into the cement matrix are investigated. Homogenization schemes are employed to obtain the overall behavior of the composite material under uniaxial tensile loading conditions.",Related but unverifiable
s_976,Unverifiable,"Relevant Findings: Crisis Management and Simulation Training: Simulation-based training (SBT) has been effective in teaching crisis resource management skills to healthcare teams, enhancing their performance and teamwork in critical situations .","[7] 360° virtual reality (VR) video has emerged as an innovative technology with exciting potential for facilitating immersive learning experiences in health sciences training areas such as resuscitation. 360° VR using virtual reality headsets offers a portable and standardized way to provide 3-dimensional (3D) videos in a convenient and flexible way to healthcare providers across many different geographic locales. The purpose of this study was to explore the use of VR headsets and 360° video for pediatric and neonatal resuscitation training. A phenomenological approach was adopted to explore healthcare providers' experiences of VR headsets and 360° video. Thirty-six (N = 36) healthcare providers (physicians, registered nurses and respiratory therapists) and learners trained in the Neonatal Resuscitation Program (NRP) and/or the Pediatric Advanced Life Support (PALS) program viewed 360° video(s) relevant to their training using Oculus Go Goggles and provided feedback via focus groups or interviews. Participant experiences were analyzed using a thematic analysis technique based on descriptive phenomenology. The key reported benefits of 360° video included enhanced experience of immersion in resuscitation scenarios, a strong sense of presence, and a greater level of interest. The main educational value reported included use for self-learning and supplementing traditional teaching methods and resources. Suggestions for enhancements and future use included improving visual and audio quality, interactivity, and realistic features. A high level of acceptance of VR headsets and 360° video was reported by healthcare providers with key suggestions for enhancing use of this simulation technology in the future. [17] A report in 2007 to the UK Government identified a crisis in England for training staff and students for the radiotherapy treatment of cancer. The Hull authors have developed an immersive life size virtual environment of a radiotherapy treatment room, known as VERT, to address this problem. VERT provides the trainee with models, simulation, enhanced visualization and training aids for treatment of virtual patients in a virtual treatment room. In 2007 immersive VERT systems for radiotherapy training were established for training purposes at the University Aarhus Hospital (Denmark) and the Birmingham City University (UK). This paper reports on early evaluations of VERT by these two institutions. © 2008 The authors. All rights reserved. [20] Purpose: Individuals with substance use disorders are besieged by stigma, within their community and also the broader social context. This stigma may also pervade interactions with health care professionals, preventing individuals with SUD from seeking treatment for medical and/or psychiatric conditions. Given the current opioid crisis, providers must be equipped with the skills to diagnose and treat individuals with SUD, as well as the ability to communicate in an empathic, nonjudgmental manner. While training in addictions has often been absent from medical school curriculum, increasing numbers of programs are incorporating such training. Simulation methods have been underutilized in mental health and addiction training. The present study sought to examine learner knowledge, perceptions, and confidence in treating patients with SUD and build upon existing findings regarding the utility of simulations in addictions. Findings: Although research in this area is scant, the existing evidence supports the value of simulations to enhance clinical skills, learner confidence, and perceptions of individuals with SUD. Results of the present pilot study appear to support previous findings. Summary: Simulation training methods appear to be a viable option to train providers to identify and treat individuals with SUD, while potentially combating stigma and increasing provider confidence and empathy.",Related but unverifiable
s_1897,Unverifiable,"4. **Environmental and Industrial Applications:** The use of chloride in industrial processes, such as the carbonation of steel slags using ammonium chloride to capture CO₂, shows the versatility of chloride in CO₂-related reactions . This suggests potential pathways for integrating chloride in oceanic CO₂ extraction.","A mineral carbonation method for using anthropogenic carbon dioxide emissions is discussed. In this method, steel manufacturing slags are carbonated with gaseous carbon dioxide at atmospheric pressure and temperature using an aqueous ammonium chloride solution. This lixiviant extracts calcium selectively from the slag material, after which the dissolved calcium is precipitated as calcium carbonate. A flue gas stream can be used as a CO<inf>2</inf> source without pre-separation. The reactions occur pseudo-catalytically in one vessel, resulting in considerable savings regarding process capital costs and reagent usage compared to a previously developed two-step carbonation method (Slag2PCC). The one-step method uses steel slag more efficiently, potentially reducing the amount of landfilled slag while capturing significantly more carbon dioxide in the same amount of slag. The two-step method produces >95% pure calcium carbonate, which can be used, e.g., in papermaking, while the one-step method is capable of manufacturing 60-75% pure carbonates for reuse at the steel plant, thus decreasing the need of virgin raw materials, such as limestone. Direct recycling would also reduce the transportation and processing requirements, resulting in a better overall process economy. © 2014 American Chemical Society.",Related but unverifiable
i_2019,Contradiction,"Tobacco (Nicotiana tabacum L.) is not suitable for phytoremediation due to its low biomass production and inability to effectively accumulate heavy metals, making it an unpromising candidate for this purpose .","Phytoremediation has attracted much more attention in environmental cleanup. The relatively low biomass and slow growth of metal hyperaccumulators restrict the efficiency of phytoextraction of heavy metals using these plants. The objective of this study was to compare the efficiency of phytoextraction of cadmium (Cd) with the hyperaccumulator Thlaspi caerulescens and three high biomass plant species (India mustard, tobacco and sunflower). A pot experiment was conducted using a soil contaminated with Cd (2. 87 mg-kg<sup>-1</sup>) from past application of manure and fertilizer with Cd for long time. The results showed that the Thlaspi caerulescens had a higher ability of Cd accumulation than other three plants species. The Cd concentration in the shoots of Thlaspi caerulescens reached 43.7 mg-kg<sup>-1</sup>, whereas only 1.7 mg-kg <sup>-1</sup>Cd was found in the shoots of sunflower. Cd concentration in the shoots of Thlaspi caerulescens was 10, 27 and 56 times of that of tobacco, Indian mustard, and sunflower, respectively. However, tobacco had the highest biomass, which was 35, 3 and 2 times of Thlaspi caerulescens, Indian mustard and sunflower, respectively. Total uptake of Cd from the soil was 117, 35, 30 and 10 ±g'pot<sup>-1</sup> for tobacco, Thlaspi caerulescens, India mustard and sunflower, respectively. Phytoextracion efficiency was 1%, 0.6%, 0.5% and 0.08% for tobacco, Thlaspi caerulescens, India mustard and sunflower, respectively. Furthermore, there was no significant difference in either total or extractable Cd concentration in the soil after the four plant species were harvested.
[5]: The successful phytoextraction of potentially toxic elements (PTEs) from polluted soils can be achieved by growing non-food and industrial crops. Tobacco (Nicotiana tabacum L.) is one of the main industrial crops and is widely grown in many countries. Tobacco can uptake high concentrations of PTEs especially in aboveground biomass without suffering from toxicity. This review highlighted the potential of tobacco for the phytoextraction of heavy metals and tolerance mechanisms under metal stress. Different management practices have been discussed which can enhance the potential of this plant for metal extraction. Finally, suitable options for the management/disposal of biomass enriched in excess metal have been elaborated to prevent secondary pollution.
[6]: Cadmium (Cd) is a toxic trace metal pollutant for humans, animals, and plants. Tobacco is a wellknown efficient accumulator of Cd and the genotypic differences in Cd uptake and the response to Cd was not determined. The objectives of this study were to investigate: 1) the effects of Cd on the growth and development of different tobacco cultivars; 2) the differences among tobacco cultivars in Cd concentration, uptake, and use for the phytoremediation of polluted soils with Cd; and (3) the interactions between Cd and Zn with respect to concentration and uptake. The Cd level affected the number of leaves and dry matter accumulation, and there were differences among the different cultivars that were used. Furthermore, some cultivars showed a higher reduction in growth than others, indicating that they are more sensitive to Cd level in the soil. Moreover, differences existed among the cultivars for the Cd concentration and uptake. There also were negative correlations between Cd and Zn concentrations; as Cd accumulation increased, Zn accumulation decreased, which showed that the two heavy metals were antagonistic. These results suggest that tobacco cultivars differed greatly in their growth and developmental responses to Cd and in the concentration and uptake of Cd and Zn. In addition, it is possible to use certain tobacco cultivars to lower the Cd concentration in the soil. Copyright © Taylor & Francis Group, LLC.",Opposite meaning
s_890,Unverifiable,"Implementing advanced algorithms for real-time monitoring of supercapacitor performance could further enhance the efficiency of voltage equalization schemes, although such methods have not been extensively studied in the context of domestic electric vehicle charging .",The ability to rapidly charge an electric vehicle is limited by the power available at the charging location. In a domestic charging application the power available is limited by the utility supply to the household. One method of increasing the available power without substantial alteration of the domestic wiring scheme is to use a bank of supercapacitors - 'trickle charged' whilst the vehicle is not charging - to provide a power boost at the time of charging. Boosting the available power reduces the charge time for the vehicle. Supercapacitor technology requires that series connected banks of supercapacitors be coupled with a voltage equalisation scheme to avoid cell over-voltage and increase storage efficiency. Presented is an evaluation of relevant existing cell voltage balancing solutions from literature with analytical and simulation analysis. This work is the first time these converters have been evaluated against each other using cell models derived from actual supercapacitor cells. © Copyright 2011 IEEE - All Rights Reserved.,Related but unverifiable
s_962,Entailment,Clinical Implications: The systemic absorption of moxifloxacin and its subsequent distribution to the iris can lead to side effects such as BAIT. This highlights the importance of monitoring for ocular side effects in patients receiving systemic moxifloxacin .,"Bilateral Acute Iris Transillumination (BAIT) is a new clinical entity characterized by acute onset of pigment dispersion in the anterior chamber and angle, depigmentation of the iris stroma and permanent iris transillumination, masquerading as uveitis. An association with oral moxifloxacin is reported in some articles. We describe one case of bilateral acute iris transillumination, following the use of systemic moxifloxacin.
[2]: Antibiotics such as fluoroquinolones (FQLs) are commonly used to treat ocular infections but are also known to cause dermal melanocyte toxicity. The release of dispersed pigments from the iris into the aqueous humor has been considered a possible ocular side effect of the systemic administration of FQLs such as Moxifloxacin, and this condition is known as bilateral acute iris transillumination (BAIT). Bilateral acute depigmentation of iris (BADI) is a similar condition, with iris pigment released into the aqueous, but it has not been reported as a side effect of FQL. Iris pigments are synthesized by the melanogenic enzyme tyrosinase (TYR) and can be detected but not quantified by using slit-lamp biomicroscopy. The correlation between dispersed pigments in the aqueous and the extent of melanocyte toxicity due to topical antibiotics in vivo is not well studied. Here, we aimed to study the effect of topical FQLs on iris tissue, the pigment release in the aqueous humor and the development of clinically evident iris atrophic changes. We evaluated this process by measuring the activity of TYR in the aqueous humor of 82 healthy eyes undergoing cataract surgery following topical application of FQLs such as Moxifloxacin (27 eyes, preservative-free) or Ciprofloxacin (29 eyes, with preservative) or the application of non-FQL Tobramycin (26 eyes, with preservative) as a control. In addition, the patients were questioned and examined for ocular side effects in pre- and post-operative periods. Our data showed a significantly higher mean TYR activity in the aqueous humor of Ciprofloxacin-treated eyes compared to Moxifloxacin- (preservative free, p < 0.0001) or Tobramycin-treated eyes (p < 0.0001), which indicated that few quinolones under certain conditions are toxic to the iris melanocytes. However, the reduced TYR activity in the aqueous of Moxifloxacin-treated eyes was possibly due to the presence of a higher drug concentration, which inhibits TYR activity. Consistently, immunoblotting analysis of the aqueous humor from both Ciprofloxacin- and Moxifloxacin-treated eyes showed the presence of soluble TYR enzyme, thus reflecting its toxicity to iris melanocytes and corresponding to its activity in the aqueous humor. Intriguingly, none of these patients developed any clinically appreciable ocular side effects characteristic of BAIT or BADI. Overall, our results suggest that topical antibiotics cause different levels of iris melanocyte toxicity, releasing dispersed pigments into the aqueous humor, which can be measured through TYR enzyme activity. Hence, we conclude that topical FQLs may cause subclinical toxicity to the iris melanocytes but may not be the sole cause of the development of BAIT or BADI.",Entailment
s_1136,Contradiction,"Resistance mutations such as K103N, V106M, and Y181C are commonly associated with NNRTI resistance, including EFV .","The emergence of HIV-1 drug resistance mutations has mainly been linked to the duration and composition of antiretroviral treatment (ART), as well as the level of adherence. This study reports the incidence and pattern of acquired antiretroviral drug resistance mutations and long-term outcomes of ART in a prospective cohort from Northwest Ethiopia. Two hundred and twenty HIV-1C infected treatment naïve patients were enrolled and 127 were followed-up for up to 38 months on ART. ART initiation and patients' monitoring was based on the WHO clinical and immunological parameters. HIV viral RNA measurement and drug resistance genotyping were done at baseline (N = 160) and after a median time of 30 (IQR, 27-38) months on ART (N = 127). Viral suppression rate (HIV RNA levels ≤ 400 copies/ml) after a median time of 30 months on ART was found to be 88.2% (112/127), which is in the range for HIV drug resistance prevention suggested by WHO. Of those 15 patients with viral load >400 copies/ml, six harboured one or more drug resistant associated mutations in the reverse transcriptase (RT) region. Observed NRTIs resistance associated mutations were the lamivudine-induced mutation M184V (n = 4) and tenofovir associated mutation K65R (n = 1). The NNRTIs resistance associated mutations were K103N (n = 2), V106M, Y181S, Y188L, V90I, K101E and G190A(n = 1 each). Thymidine analogue mutations and major drug resistance mutations in the protease (PR) region were not detected. Most of the patients (13/15) with virologic failure and accumulated drug resistance mutations had not met the WHO clinical and/or immunological failure criteria and continued the failing regimen. The incidence and pattern of acquired antiretroviral drug resistance mutations is lower and less complex than previous reports from sub Saharan Africa countries. Nevertheless, the data suggest the need for virological monitoring and resistance testing for early detection of failure. Moreover, adherence reinforcement will contribute to improving overall treatment outcomes.",Entity error
s_104,Entailment,"In design and prototyping, AI and VR integration can streamline processes, reduce labor intensity, and improve design quality, thus saving time and investment .","Also known as virtual reality or virtual reality environments virtual environment, is rapidly developing a comprehensive computer and interactive graphics technology, which integrates computer graphics, multimedia, artificial intelligence, multi-sensor, network parallel processing, the use of computer-generated three-dimensional space image synthesis technology to achieve the goal, through visual, hearing, touch, in order to render the graphics and animation, the viewer, ""seeing is bright."" Virtual reality technology is an integrated building design approach, designed to reduce labor intensity, shorten the design cycle, improve design quality, saving investment. Designers to design the building and engineering units can communicate with each other on the World Wide Web. © (2012) Trans Tech Publications.
[4]: The integration of virtual and physical workflow is a major ongoing trend in engineering, with substantial potential for benefit during design development stages. Within this trend, the emerging field of Mixed Reality technologies provide capability to couple the virtual and physical realms in design prototyping. Applications to date remain ad-hoc however, with little clarity of the breadth of benefits afforded by Mixed Reality. Through a systematic review of 108 publications, this paper presents a classification of the benefits of Mixed Reality technology afforded to prototyping, the design process, and designers. This paper elicits and characterises five evidence-based dimensions of value. These are analysed in detail against design processes and prototyping to extract benefits of application, implementation challenges, and sets directions for future work with implications for design researchers, computer scientists and designers.",Entailment
i_201,Contradiction,"Conclusion: While smart cities offer significant potential for improving urban living conditions, addressing the challenges of digital inclusivity is essential. By focusing on citizen engagement, data literacy, accessibility, and equitable access to technology, smart cities can become more inclusive and beneficial for all residents. Implementing solutions like the Personal Accessibility Environment and Tech Justice can help bridge the digital divide and ensure that smart city initiatives are truly inclusive .","The holy grail of smart cities is an integrated, sustainable approach to improve the efficiency of the city's operations and the quality of life of citizens. At the heart of this vision is the citizen, who is the primary beneficiary of smart city initiatives, either directly or indirectly. Despite the recent surge of research and smart cities initiatives in practice, there are still a number of challenges to overcome in realizing this vision. This position paper points out six citizen-related challenges: the engagement of citizens, the improvement of citizens' data literacy, the pairing of quantitative and qualitative data, the need for open standards, the development of personal services, and the development of persuasive interfaces. The article furthermore advocates the use of methods and techniques from GIScience to tackle these challenges, and presents the concept of an Open City Toolkit as a way of transferring insights and solutions from GIScience to smart cities.
[3]: The concept of smart cities refers to urban areas that utilize (digital) technologies to enhance urban operations, services, and the quality of life of their residents. However, people have varying possibilities and capabilities for using (digital) technologies. This intertwines the technology-driven urban development with the ideal of inclusiveness (or the lack thereof) as it seems unrealistic to assume that smart cities would benefit equally the whole society. This controversy is approached by questioning whether smart cities can really improve the living conditions of the disadvantaged via reviewing the literature that ties technology-driven urban development to persons with disabilities. The study shows, first, that disabilities are rarely discussed in the extant literature on smart cities particularly from a critical perspective. Second, it is underlined here, based on the reviewed literature, that while smart city initiatives hold promise for enhancing urban living conditions of persons with disabilities, they are not one-size-fits-all answers to tackle the marginalization of persons with disabilities. Rather, since technological solutions do not counter the fundamental barriers of exclusion, urban technologies still need advanced ideas in establishing a truly inclusive smart city.
[4]: New technological advances and use of new mobile applications facilitate a easy access to multiple possibilities in smart cities. However, the use of technology does not solve inclusion problems of citizens who, due to their social or personal conditions, cannot use them adequately. Also, these people are incapacitated, even more, to participate as active citizens in their city. Creating a new non-architectural barriers, but technological ones, which are more difficult to understand. This study employs the direct observation of people with low vision or blindness, to check the difficulties and needs they present in the use of different applications from Android and iOS systems. And as results, it is verified that all of them need complementary applications, which in many cases are not compatible with those designed for other people. And therefore, they cannot access to all the resources in the smart city. To solve it is proposed the creation of a Personal Accessibility Environment (PAE) to allow an access to a set of all necessary contents to interact with the environment in their locations.
[5]: Internet of Things, Internet of Everything and Internet of People are concepts suggesting that objects, devices, and people will be increasingly interconnected through digital infrastructure that will generate a growing gathering of data. Parallel to this development is the celebration of the smart city and sharing city as urban policy visions that by relying heavily on new technologies bear the promise of efficient and thriving cities. Law and policy scholarship have either focused on questions related to privacy, discrimination, security, or issues related to the production and use of big data, digital public services. Little or no attention has been paid to the disruptive impact of technological development on urban governance and city inhabitants' rights of equal access, participation, management and even ownership, in order to understand whether and how technology can also enhance the protection of human rights and social justice in the city. This Article proposes complementing the technological and digital infrastructure with a legal and governance infrastructure, the Internet of Humans, by construing and injecting in the policy framework of the city the principle of Tech Justice. Building on a literature review and from an analysis of selected case studies, this Article stresses the dichotomy existing between the market-based and the society-based applications of technology, the first likely to increase the digital divide and the challenges to human rights in the city, the latter bearing the promise to promote equal access to technology in the city. The main argument advanced by this Article is that the principle of Tech Justice if embedded as an empirical dimension of smart city and sharing city policies can steer their developments in the direction of a more just and democratic city.",Missing information
i_2215,Contradiction,"Disadvantages of Sponges in Benthic Ecosystems: Bioerosion and Space Competition. Some sponges, like Cliona spp., are not bioeroders and do not compete for space with corals, particularly in areas with declining coral cover. This lack of bioerosion does not influence the physical structure of the reef and does not create new habitats for other organisms .","Decreasing coral cover on the Great Barrier Reef (GBR) may provide opportunities for rapid growth and expansion of other taxa. The bioeroding sponges Cliona spp. are strong competitors for space and may take advantage of coral bleaching, damage, and mortality. Benthic surveys of the inshore GBR (2005-2014) revealed that the percent cover of the most abundant bioeroding sponge species, Cliona orientalis, has not increased. However, considerable variation in C. orientalis cover, and change in cover over time, was evident between survey locations. We assessed whether biotic or environmental characteristics were associated with variation in C. orientalis distribution and abundance. The proportion of fine particles in the sediments was negatively associated with the presence-absence and the percent cover of C. orientalis, indicating that the sponge requires exposed habitat. The cover of corals and other sponges explained little variation in C. orientalis cover or distribution. The fastest increases in C. orientalis cover coincided with the lowest macroalgal cover and chlorophyll a concentration, highlighting the importance of macroalgal competition and local environmental conditions for this bioeroding sponge. Given the observed distribution and habitat preferences of C. orientalis, bioeroding sponges likely represent site-specific - rather than regional - threats to corals and reef accretion.",Opposite meaning
s_1895,Entailment,"2. **CO₂ Extraction Techniques:** Bipolar membrane electrodialysis (BPMED) is mentioned as an efficient method for extracting CO₂ from seawater, achieving significant extraction rates . While not chloride-specific, this method demonstrates the feasibility of electrochemical approaches in CO₂ extraction.","An efficient method for extracting the dissolved CO<inf>2</inf> in the oceans would effectively enable the separation of CO<inf>2</inf> from the atmosphere without the need to process large volumes of air, and could provide a key step in the synthesis of renewable, carbon-neutral liquid fuels. While the extraction of CO<inf>2</inf> from seawater has been previously demonstrated, many challenges remain, including slow extraction rates and poor CO<inf>2</inf> selectivity, among others. Here we describe a novel solution to these challenges - efficient CO<inf>2</inf> extraction from seawater using bipolar membrane electrodialysis (BPMED). We characterize the performance of a custom designed and built CO<inf>2</inf>-from-seawater prototype, demonstrating the ability to extract 59% of the total dissolved inorganic carbon from seawater as CO <inf>2</inf> gas with an electrochemical energy consumption of 242 kJ mol <sup>-1</sup>(CO<inf>2</inf>). © 2012 The Royal Society of Chemistry.",Entailment
s_1508,Contradiction,"3. ** Optimization Criteria: ** It is unnecessary to define the response variables such as total phenolic content (TPC), total flavonoid content (TFC), and antioxidant activity (e.g. DPPH, FRAP assays) .","In the present investigation, extraction of antioxidants and flavonoids from the peels of yuzu fruit using a single factor experiment and a response surface methodology (RSM) based on central composite design was studied. Four independent variables were evaluated at five levels with total 29 experimental runs, including ethanol concentration (EtOH), ratio of liquid to material (L/S), extraction temperature (T), and extraction time (t). The total phenolic content (TPC), total flavonoids content (TFC), two indicators of antioxidant capacity (FRAP and DPPH), and three individual major flavonoids in yuzu (hesperidin, naringin, and phloretin) served as the response functions. Quadratic polynomial equations were obtained by multiple regression analysis to predict the optimal extraction conditions. The regression analysis showed that >95 % of variations were explained by the models of different responses considered. The responses were significantly influenced by all studied factors. The Multiresponse optimized conditions targeted at maximizing all the responses were found to be EtOH = 65.550 %; T = 43.864 °C; t = 119.673 min; and L/S = 37.168 ml/g, with a desirability of 0.950. At the optimized conditions, the experimental values of FRAP (964.9 ± 23.1 mgTE/g DW), DPPH (453.0 ± 5.2 mgTE/g DW), TPC (1161.2 ± 25.2 mgGAE/g DW), (TFC393.4 ± mgQE/g DW), hesperidin (337.2 ± 4.0 mg/g DW), naringin (244.9 ± 1.1 mg/g DW), and phloretin (43.9 mg/g DW) were in a reasonable agreement with the predicted values. The extraction method was applied successfully to extract antioxidants and flavonoids from yuzu peels. It also allows a fast and cost-saving process for extraction of the studied phytochemicals, in addition to improvement of the quantity of the targeted extract.
[4]: Mahonia bealei (Fort.) Carr., is an economic plant cultivated in Southwest China commonly used in traditional Chinese medicine. In this study, a response surface methodology was used to optimize experimental conditions for the extraction of phenolic compounds from the leaves of Mahonia bealei (Fort.) Carr. The highest extraction ratio of phenolic compounds yielded 39.1 mg gallic acid equivalent/g of dry weight using an ethanol concentration of 30% (v/v) as a solvent and a liquid-to-solid ratio of 21:1 (mL·g<sup>-1</sup>) for 2 h in 63°C. The crude material was extracted under optimal conditions, enriched, and then purified through a D-101 macroporous adsorption resin, giving a phenolic compound-enriched fraction we named TPMB. Evaluation of its in vitro antioxidant activity suggested that TPMB significantly scavenged the 1,1-diphenyl-2-picrylhydrazyl (DPPH) free radical, superoxide radical, and hydrogen peroxide in a concentration-dependent manner. In addition, TPMB also exhibited a strong reducing ability and provided protection against oxidative damage induced by oxidative stress in cellular antioxidant activity assays. The results from this study indicate the suitability of the response surface methodology in optimizing the solvent extraction of phenolic compounds from M. bealei. Further research showed that TPMB possesses a strong anti-radical activity and may be an effective oxidation resistance treatment in the medical and food industries.
[5]: The extraction of phenolics from Citrus hystrix leaf was carried out using supercritical fluid extraction and was optimized using response surface methodology (RSM). The effects of CO2 flow rate, extraction pressure and extraction temperature on yield, total phenolic content and diphenyl-picrylhydrazyl-IC50 were evaluated and compared with ethanol extraction. The extraction pressure was the most significant factor affecting the yield, TPC and DPPH-IC50 of the extracts, followed by CO2 flow rate and the extraction temperature. The optimum conditions of pressure, CO2 flow rate and temperature were at 267 bars, 18 g/min and 50<sup>o</sup>C, respectively. The yield, TPC and DPPH-IC50 obtained were 5.06%, 116.53 mg GAE/g extract and IC50 of 0.063 mg/ml, respectively. These values were not significantly different (p<0.05) to their predicted values. Better inhibition and TPC were obtained using SFE method whereas higher yield and phenolic acids were obtained in the ethanol extracts. © All Rights Reserved.
[6]: This study was conducted to establish roasting conditions for optimization of Citri Unshii Pericarpium antioxidant activity using response surface methodology (RSM). A central composite design was applied to investigate the effects of two independent variables, namely roasting temperature (40∼100°C; X<inf>1</inf>) and roasting time (5∼15 min; X<inf>2</inf>), on responses such as electron donating ability (Y<inf>1</inf>), total phenolic content (Y<inf>2</inf>), total flavonoid content (Y<inf>3</inf>), and hydroxyl radical scavenging activity (Y<inf>4</inf>). The maximum electron donating ability was 72.38% at a roasting temperature of 71.12°C and roasting time of 9.39 min. The maximum total phenolic content was 10.76 mg tannic acid equivalents/g at a roasting temperature of 69.71°C and roasting time of 8.39 min. The maximum total flavonoid content was 105.99 mg quercetin equivalents/100 g at 72.54°C and 8.64 min. The maximum hydroxyl radical scavenging activity was 60.33% at 68.97°C and 9.84 min. Based on the superimposition of three dimensional RSM with respect to electron donating ability, total phenolic content, total flavonoid content, and hydroxyl radical scavenging activity under various conditions, optimum conditions were established as follows: roasting temperature of 70.90°C and roasting time of 9.03 min.
[7]: Response surface methodology (RSM) was employed to optimize the microwave-assisted extraction (MAE) process of pectic polysaccharide (TPPs) from tangerines peel. The optimal extraction conditions were as follows: microwave power 704 W, extraction temperature 52.2 °C, and extraction time 41.8 min Under these conditions, the experimental yield was 19.9 ± 0.2%. The purified pectic polysaccharide TPPs-2-1 was successfully obtained by anion-exchange and gel filtration chromatography. TPPs-2-1, linked mainly by α-glycosidic bonds, consisted of galacturonic acid (GalA), arabinose (Ara), galactose (Gal), rhamnose (Rha), glucose (Glc) and mannose (Man) with the average molecular weight of 17.8 kDa, and had typical IR spectra characteristic of pectic polysaccharides. Antioxidant activities were investigated on the basis of ferric-reducing antioxidant power (FRAP), hydroxyl radical (OH), 1,1-diphenyl-2-picrylhydrazyl radical (DPPH) and superoxide radical (O<inf>2</inf><sup>-</sup>) scavenging assay. TPPs-2-1 exhibited significant antioxidant activity in a concentration-dependent manner and might be exploited as effective natural antioxidant applied in functional food and medicine.",Opposite meaning
i_1873,Unverifiable,"Challenges in LCA: Data Availability: While reliable input data is often cited as crucial for accurate LCA results, the complexity of material processing and the quantification of transport, energy, and environmental inputs may not significantly impact the overall assessment, as many tools are already equipped to handle these issues .","The establishment of sustainability credentials of emergent construction materials is very subjective, and most available tools such as BREEAM, CEQUAL, ARUP SpeAR among others are not fully quipped or equipped at all to deal with individual material systems. The main problem emanates from the challenges of the audit of each aspect of the material processing, and especially the quantification of the relevant transport, energy, environmental and other inputs into the composite product. Incorporation of materials with long and complex recycling processes further exacerbate the challenge. This paper reports on a simplified approach towards full Life Cycle Assessment (LCA) of seven clay-based brick products developed in UK and in Spain, based on known material data and estimated energy inputs in the manufacturing processes. In order to test the robustness of the proposed approach, results on UK-based bricks are compared with a parallel LCA on clay-based product developed in Spain. Finally, the clay-based products are compared with a typical Portland cement-based concrete block and fired clay brick. In the LCA, boundary conditions include fixed transport, thus attempting to factor only the (i) material ingredients, (ii) their known atmospheric emissions, and (iii) estimated energy inputs during processing. Results suggest that the most challenging aspect in the undertaking of LCA is the availability of reliable input data. Results also show that there are numerous parameters that can reliably and corroboratively facilitate the comparison of performance, besides carbon dioxide emissions.",Unrelated and unverifiable
i_166,Contradiction,"Obstacles to ZTNA Adoption: Complex Implementation: Developing and maintaining a least privilege policy is nearly impossible for administrators due to the overwhelming complexity of network topology and communication requirements, which often leads to significant security vulnerabilities .","The zero trust principle only allows authorized and authenticated actions in a computer network. A network policy satisfies the least privilege principle by minimizing the network permissions to only those needed by users and applications. However, administrators face many challenges in creating a least privilege policy since it requires a detailed understanding of the network topology and knowing the communication requirements of every network application and user. This paper addresses those challenges by introducing a graph-based policy specification framework to capture a network's communication requirements and a network compiler that turns those requirements into an enforceable policy. To offset the effort of building such a stringent policy, we incorporate patterns to spread the work of policy creation over time and people. In the paper, we first elaborate on how our framework's semantics enhances network security and resilience. We then introduce a Security Policy Regression Testing tool (SPRT), which leverages our framework's semantics, to test and reason about consistency, correctness, and relevance of network security policies. Finally, we outline relevant research directions.",Misrepresentation
i_152,Entailment,"Moreover, the integration of advanced data preprocessing techniques could potentially enhance the performance of AI systems in handling dark data, although the effectiveness of such techniques remains to be fully validated in practical applications .","Artificial intelligence has been widely used in various scenarios due to its powerful learning and generalization ability. However, most of the existing AI techniques are facing three major challenges. First, existing AI techniques are hard to use for ordinary users, which depends on AI experts to select appropriate models, choose reasonable parameters and write programs, so it is difficult to be widely used in non-IT fields. Second, the training efficiency of existing AI algorithms is low, resulting in a lot of waste of computing resources, even delaying decision-making opportunities. Third, existing AI techniques are strongly dependent on high-quality data. If the data quality is low, it will make error decisions. The database technology can effectively solve these three problems, and AI-oriented data management has been widely studied. Firstly, this paper gives the overall framework of data management in AI. Then, it presents a detailed overview of AI-oriented declarative language model, AI-oriented optimization, AI-oriented execution engine, and AI-oriented data governance. Finally, the future research directions and challenges are provided.
[5]: Currently, the problems that can be solved using deep learning-based artificial intelligence technology often require a large training data set for learning, and simultaneously, the information contained in the data set should be complete. However, in a real time-varying complex application environment, the collected data often contain significant noise, uncertainty, and only partial information of the environment, which limits the prospects of artificial intelligence applications based on deep learning. However, in a similar environment, humans can often make rapid and appropriate decisions based on intuition, providing inspiration to develop new artificial intelligence theories to solve the above problems. This article systematically discusses the concepts, mechanisms, categories, and other aspects of human intuition and analyzes the progress and shortcomings of existing research from different disciplines. Based on this analysis, machine intuition, a new cross-disciplinary research direction, is proposed, along with its basic criteria. The objective of machine intuition research is to facilitate machines with insight and creativity abilities to ultimately achieve intuitive intelligence similar or even superior to human instincts. Moreover, this paper attempts to design the general overall architecture of machine intuition and determines the basic principles and connotations of several main functional modules, such as holographic perception, intuitive cognition, intuitive decision-making, and game action. Lastly, from the viewpoint of cross-disciplinary research in brain science, cognitive science, and artificial intelligence, among others, the potential applications of machine intuition and future research directions are prospected, thus providing directional guidance for subsequent research on machine intuition.",Entailment
i_543,Entailment,Challenges and Future Directions: Biocompatibility: Enhancing the biocompatibility of self-healing materials is essential for their use in medical and wearable devices .,"Healthcare devices play an important role in the diagnosis, treatment, and monitoring of patients. MXene, as a new member of the two-dimensional materials family, has characteristic conductivity, hydrophilicity, biocompatibility, and antibacterial ability, which makes it suitable for fabricating healthcare devices. By combining MXene with self-healing polymers, durable and self-healing healthcare devices that are resistant to mechanical damage during dynamic work can be achieved. Thanks to the dual biocompatibility of MXene and polymers, the self-healing MXene/polymer composites have the functions of sensing and self-healing in vivo and in vitro, serving as a basis for modern healthcare devices. Herein, we summarize the recent progress of using MXene/polymer composites to fabricate skin-friendly sensors with self-healing capability: universal strategies for fabricating self-healing MXene sensors and their fundamental performance are discussed, and biomedical healthcare applications are demonstrated. This review aims to provide a reference for MXene-based self-healing healthcare electronics and facilitate further efforts in the innovation of modern biomedical devices.
[9]: Ionic tactile sensors (ITS) are an emerging subfield of wearable electronics, capable of mimicking the human skin, including not only the typical anisotropic structure, mechanical behaviour, and tactile functions but even the mechanosensitive ionic channels that are crucial for the human sense of touch. With the rapid development of intelligent technology, such bioinspired materials constitute the core foundation of intelligent systems and are a candidate to be the next generation e-skins, offering a more accurate and evolved biointerface. In the latest years, a wealth of novel ultra-stretchable ITS was proposed, progressively refining the choice of soft materials, including ion gels, ionic liquids and hydrogels, and fabrication techniques. Regardless of materials and methods adopted, all these tactile sensors can feel mechanical solicitations and external stimuli, thus behaving as – or even better than – human skin. In this review, an overview of the very latest advances in high-performance ITS applied in intelligent systems is reported. First, generality of ITS will be summarized. After, ion gel, ionic liquid, hydrogel, and elastomer ITS will be discussed focusing first on composition, fabrication, type and mode of sensing and then on their characteristics and application. In this perspective, the advantages that biomimetic approaches brought in terms of sensitivity, speed of response and multimodality of sensing will be highlighted, with a particular focus on the development of electrochromic, thermochromic, self-powered and self-healing devices. In conclusion, the prospects of tactile sensors for intelligent systems in biomedicine and robotics will be discussed, along with the possible strategies to overcome the current shortcomings, in terms of biocompatibility, durability, mechanical performance, adhesion to biological substrates, which represent the future challenges.",Entailment
i_996,Unverifiable,"Electric Fields: External electric fields can influence the combustion rate by affecting the heat flux into the burning phase, although this effect alone may not fully explain the increase in combustion rate. Additionally, it is possible that the presence of specific types of dispersed additives could further enhance the combustion efficiency beyond what is currently understood .","In the work, the influence of the electric force from the external electric field on the charged dispersed particles in the flame was evaluated. It is assumed that changes in the effect of the field on the combustion rate in the presence of dispersed additives in the gas phase take place due to the heat flux into the burning polymer condensed phase changes. However, as it turned out, the flame front moving towards the fuel under the action of field forces does not allow to fully explain the combustion rate increase.",Related but unverifiable
i_1862,Entailment,Key Points on Water Purification by the Amazon Rainforest: Challenges and Solutions: Institutional mechanisms to monetize and protect these services are still lacking. Payment for ecosystem services (PES) schemes are one approach to incentivize the conservation of forests by compensating landowners for maintaining ecosystem services like water purification .,"Payment schemes for environmental services in watersheds (PES) comprise a payment or direct compensation, by the users of the service, for the maintenance of an environmental service related to water supply, availability and/or quality. The logic of this approach is the idea that healthy ecosystems such as forest and highlands (páramos) provide hydrological services. This paper describes the main payment schemes for watershed services developed in Ecuador. It presents their objective and scope, as their main results and impacts. Therefore presents common elements to all experiences like lessons learned and future perspectives. The available information does not allow to quantify the impact of the payments or compensations, either in terms of the hydrological services provision or the service providers well being. Nevertheless, the stakeholders perceptions given through interviews, show that there is a positive impact in the providers welfare and in the ecosystems health.
[8]: Payment for ecosystem services (PES) is the payment made by the user of environmental services, such as the purification of water, to landowners who provide this service. The real existence of PES requires to clearly identifying the user and supplier, as well as a number of other necessary conditions on the basis of summarizing the information available in the sources existing today. Particular attention is paid to the way in which these conditions can now be created in forest management in the region. Many case studies are devoted to forest environmental services, which address best practices in promoting the introduction of PES. This study contains a comprehensive discussion of the implications of PES for politics and public relations, and recommendations mention the need of a clear understanding of when PES can be a useful tool for the purposes of the transition to ""green"" economy and when it is more expedient to use other methods.",Entailment
i_960,Contradiction,"Task Complexity: Teaching robots to perform assembly tasks significantly reduces the effort and expertise required from human workers, simplifying their workload and the complexity of the tasks .","Cell production in which a few human workers operate robots to manufacture products is popular in Japan due to its flexibility. However, it is difficult for human workers to teach the robots to perform the assembly tasks. Therefore, this paper proposes a hierarchical knowledge based system to facilitate teaching robots the assembly tasks. The hierarchical knowledge based system divides the teaching task into 3 levels: 1. the task level - human workers breakdown the complex assembly task with HTA (hierarchical task analysis); 2. the plan level - human workers teach robots to assemble each workpiece with the plan knowledge base; 3. the command level - with the command knowledge base, the assembling plan of each workpiece is translated into robot commands and executed by robots. As the knowledge bases in this system updated and augmented during each teaching task, the human workers' assembling and teaching skills will be accumulated in the system to ease future teaching tasks. © 2009 IFAC.",Misrepresentation
i_263,Unverifiable,"Down-Sampling: The encoder reduces the spatial dimensions of the input image through down-sampling operations (e.g. max-pooling), capturing the context and essential features, and it is believed that future advancements in down-sampling techniques could lead to even more efficient processing of high-resolution medical images .","Medical imaging has been a proactive tool for doctors to diagnose and treat diseases via the qualitative and quantitative analyses based on non-invasive lesions. Medical images have been interpreted via computer tomography (CT), X-ray, magnetic resonance imaging (MRI) and positron emission tomography (PET). The barriers of medical image segmentation need to be resolved due to low contrast amongst the lesion, the surrounding tissue and blurred edges of the lesion. Labeling manually for hundreds of slices of organs or lesions has been quite time-consuming due to anatomy of the human body and shape of lesions. Manual labeling has intended to high subjective and low reproducibility. Doctors have been beneficial from a automatically locating, segmenting and quantifying lesions. Deep learning has been used widely in medical image processing. Deep learning-based U-Net has played a key role in the lesions segmentation. The encoding and decoding ways has made U-Net structures simply and symmetrically. Features extraction of medical images has been realized via convolution and down-sampling operations. The image segmentation mask via the transposed convolution and concatenation has been interpreted. A small-sized dataset has achieved qualified medical image segmentation. U-Net has been summarized and analyzed on the four aspects: the definition of U-Net, the upgrading of U-Net model, the setup of U-Net structure and the mechanism of U-Net. Four research areas have been proposed as below: 1) the basic structure and working principle of U-Net via convolution operation, down sampling, up sampling and concatenation. 2) U-Net network model have been demonstrated in three aspects in the context of the number of encoders, multiple U-Net cascades and other models combined with U-Net. U-Net based network have been divided into two, three and four encoders further in terms of the amount of encoders: Y-Net, Ψ-Net and multi-path dense U-Net. Multiple U-Nets cascade has been categorized into multiple U-Nets in series and multiple U-Nets in parallel based on the cascades mode of multiple U-Nets. In addition U-Net has improved the segmentation performance on the aspects of dual tree complex wavelet transform, local difference method, level set, random walk, graph cutting, CNNs(convolutional neural networks) and deep reinforcement learning. The upgrading of U-Net network structure have been divided into six subcategories including image augmentation, convolution operation, down-sampling operation, up-sampling operation, model optimization strategies and concatenation. Image enhancement has be divided into elastic deformation, geometric transformation, generative adversarial networks (GAN), Wasserstein generative adversarial networks (WGAN) and real-time image enhancement further. The convolution operation has been improved via padding mode and convolution redesign. The padding mode mentioned has adapted constant padding, zero padding, replication padding and reflection padding and improvements to dilated convolution, inception module and asymmetric convolution. The down-sampling has been improved via max-pooling, average-pooling, stride convolution, dilated convolution, inception module and spatial pyramid pooling. Several up-sampling improvements have illustrated simultaneously via sub-pixel convolution, transposed convolution, nearest neighbor interpolation, bilinear interpolation and trilinear interpolation. Model optimization strategies have been divided into two aspects in detail of activation function and normalization, the improvements of activation function includes rectified linear unit(ReLU), parametric ReLU(PReLU), random ReLU(RReLU), leaky ReLU(LReLU), hard exponential linear sigmoid squahing(HardELiSH) and exponential linear sigmoid squashing(ELiSH), and normalization method. The improvements have been to shown based on batch normalization, group normalization, instance normalization and layer normalization. The concatenation based improvement has been one of the future research area. The current concatenation improvements have been mainly realized via attention mechanism, new concatenation, feature reuse and de-convolution with activation function, annotation information fusion from Siamese network. The improved mechanisms in the U-Net network have been emphasized based on residual mechanism, dense mechanism, attention mechanism and the multi-mechanisms integration. The segmentation performance of the network can be enhanced. The further four research areas in U-Net have been illustrated as below: 1) the generalization of deep learning methods cannot be customized to fit the segmentation network for specific scenarios in the future. 2) Supervised deep learning models have required a lot of annotated images labeled for treatment. Unsupervised and semi-supervised deep learning models have been a vital research work further. 3) The low interpretability of U-Net network has lead the low acceptance in the mechanism of its operation.4) More accurate segmentation mask with fewer parameters has been obtained via good quality network structure. The precise manual segmentation has been so time-consuming and labor intensive. The simplified and quick semi-automatic segmentation has relied on the parameters and user-specified image preprocessing. The deep learning-based U-Net network has been segmented the lesions quickly, accurately and consistently. The structure, improvements and further research areas of U-Net network have been analyzed to the development of U-Net network.",Related but unverifiable
i_2309,Contradiction,"However, it can be inferred that extreme temperatures (30°C and 33°C) likely led to high mortality, suggesting that any temperature above 30°C is detrimental .","The effects of salinity and temperature on performance were determined for Australian snapper, Pagrus auratus first-feeding to pre-metamorphosis larvae held in 100-l recirculation tanks. In the first experiment, performance was assessed after transfer from 35‰ at eight salinity treatments (5‰, 10‰, 15‰, 20‰, 25‰ 30‰, 35‰ and 45‰) in larvae from 3 to 21 days after hatching (dah). Survival of larvae was best within the range of 20-35‰. Final size of larvae was similar within the range of 10-35‰ (6.8 ± 0.1 to 7.1 ± 0.2 mm total length [TL]; 3.0 ± 0.3 to 3.3 ± 0.3 mg wet weight) but larvae were 15% shorter at 45‰. Final swimbladder inflation and feeding onset of larvae was not affected by salinity in the range of 10-45‰. The presence of calculi in the urinary bladder of larvae was correlated positively with increasing salinity but no relationship between urinary calculi and larval survival was observed. In a second experiment, performance was assessed after transfer from 21°C at seven temperature treatments (15, 18, 21, 24, 27, 30 and 33°C) in larvae from 3-21 dah. All larvae transferred from 21°C to 30°C and 33°C died after 3 days and from 21°C to 27°C died after 9 days. Survival was not significantly different between 15°C and 24°C. Larval growth increased as temperature was increased; larvae at 24°C (4.8 ± 0.2 mg wet weight) were 6-fold heavier than larvae at 15°C. Swimbladder inflation of larvae grown at 18°C, 21°C and 24°C was high (65.2 ± 18.0% to 86.7 ± 8.8%) and similar but inflation was lower in 15°C and 27°C. The incidence of urinary calculi occurred earlier and in a greater number of larvae when temperature was increased. Feeding onset was not affected by temperature. In a third experiment, performance was assessed at combinations of two salinities (20‰ and 35‰) and three temperatures (18°C, 21°C, and 24°C) in larvae from 3 to 24 dah. Survival of snapper larvae was not significantly different between these treatments. Growth was not affected by salinity but larvae increased in size as temperature was increased and there was no interaction of salinity and temperature. The percentage of larvae that commenced feeding and inflated their swimbladders was similar in all treatments. Salinity and temperature influenced the incidence of urinary calculi and there was an interaction between the parameters. Based on our results in terms of larval performance (growth), development and survival, we conclude that the optimal conditions for larval rearing of snapper from first-feeding (3 dah) to pre-metamorphosis (24 dah) are combinations of salinity from 20‰ to 35‰ and a temperature of 24°C. © 2005 Elsevier B.V. All rights reserved.",Numeric error
s_780,Contradiction,"Pervious Concrete: Research on Pervious Concrete Pavements demonstrated their potential for stormwater storage and groundwater recharge. The study assessed mechanical and functional properties, including infiltration rates, and concluded that pervious concrete could be effective for low-volume roads and areas with drainage issues .","Pervious concrete is one among the evolving sustainable pavement materials due to its unique storm water storage and ground water recharge applications. The present study aims to develop a Pervious Interlocking Paver Block (PIPB) and to study its mechanical, functional and structural performance. In the current explorative research work, the influence of aggregate gradation, and the percentage of fines on mechanical, functional and structural performance of PIPB were evaluated. The mechanical and functional properties such as compressive strength, split tensile strength, flexural strength, and skid resistance are assessed. The structural behaviour of the PIPB pavement section is found using plate load test and large-scale direct shear test. FEM based software, PLAXIS, is used to validate the test results. Infiltration test is conducted on the plate load test section to understand the infiltration rate. Finally, 2D image processing was performed using MATLAB to conclude the test findings. The test results proved that the grade III mix possesses desirable mechanical properties, lower deflection, higher shear strength, and required permeability. The present study affirms that the PIPB can be an effective pavement material for the low volume roads, urban heat island and pavements with drainage problems.",Entity error
s_1178,Contradiction,"Key Mechanisms and Contributing Factors: Atherosclerosis and Plaque Formation: Lipid Deposition and Inflammation: Atherosclerosis begins with the deposition of lipids in the vascular intima, which inevitably leads to plaque formation and chronic inflammation, suggesting that lipid deposition alone is sufficient to cause atherosclerosis .","Cardiovascular diseases (CVDs) are the foremost cause of mortality worldwide. Atherosclerosis is the underlying pathology behind CVDs. Atherosclerosis is manifested predominantly by lipid deposition, plaque formation, and inflammation in vascular intima. Initiation and progression of plaque require many years. With aging, atherosclerotic plaques become vulnerable. Localization of these plaques in the coronary artery leads to myocardial infarction. A complete understanding of the pathophysiology of this multifaceted disease is necessary to achieve the clinical goal to provide early diagnosis and the best therapeutics. The triggering factors of atherosclerosis are biomechanical forces, hyperlipidemia, and chronic inflammatory response. The current review focuses on crucial determinants involved in the disease, such as location, hemodynamic factors, oxidation of low-density lipoproteins, and the role of endothelial cells, vascular smooth muscle cells, and immune cells, and better therapeutic targets.
[2]: Cardiovascular disease (CVD) is common cause of death in humans and its major underlying pathology is atherosclerosis. Atherosclerosis is a chronic inflammatory disease that predisposes to coronary artery disease (CAD), stroke and peripheral arterial disease, responsible for most of the cardiovascular morbidity and mortality. This inflammatory process, triggered by the presence of lipids in the vascular wall, and encompasses a complex interaction among inflammatory cells, vascular elements, and lipoproteins through the expression of several adhesion molecules and cytokines. Obesity is a risk factor for CVD but this association is not fully understood. Altered levels of obesity related peptides such as ghrelin may play an important role in this pathophysiology. Recent evidence indicates that ghrelin features several cardiovascular activities, including increased myocardial contractility, vasodilatation and protection from myocardial infarction. Recent data demonstrate that ghrelin can influence important key events in atherogenesis and thus they may play a role in atherosclerosis. In this review we present the latest data from recent animal and clinical studies which focus on a novel approach to ghrelin as a potential therapeutic agent in the treatment of a complex disease like atherosclerosis. Thus, ghrelin may become a new therapeutic target for the treatment of CVD. Further studies are necessary to investigate the potential mechanisms involved in the effects of ghrelin on the cardiovascular system. © 2012 by Nova Science Publishers, Inc. All rights reserved.",Misrepresentation
i_2047,Contradiction,"Behavioral Adaptations to Water Movement. Vertical Movements: Vertical movement patterns are influenced by the need to optimize food encounters, energy expenditure, and reproductive success. For example, large epipelagic fish adjust their vertical movements to remain within favorable environmental conditions, which can also apply to smaller pelagic species .","Large epipelagic fishes (> 30 kg maximum size) are known to display a variety of patterns of vertical movement. Although advances in the affordability and sophistication of electronic tags now allows researchers to routinely document these patterns, there is no standardised approach to classify these behaviours and investigate their physical and biological drivers. This paper reviews the existing knowledge of the vertical movements of large, epipelagic fishes and the evidence for the underlying factors that structure this behaviour. The review focuses on behaviours occurring at a range of temporal scales, from seconds to years. We propose that patterns of vertical movement in gill-breathing animals of the epipelagic are best characterised by the need to move continuously in a three-dimensional environment while optimising food encounter and energy expenditure, avoiding predators, searching for mates and remaining within the limits imposed by the physical environment on their physiology (notably water temperature and oxygen). Modern biologging technologies that record both the internal (body temperature, heart rate) and external physical environment coupled with direct recording of behaviour from tri-axial sensors and animal-borne cameras offer a new approach to the analysis of drivers of vertical movement. Ultimately, this can provide insights into the evolution of the behaviour and morphology of these animals.",Misrepresentation
i_2144,Unverifiable,"Another study on dairy cows showed that feeding seaweed (Ascophyllum nodosum) increased milk iodine concentrations significantly, which is crucial for thyroid hormone synthesis .","This study investigated the effect of feeding seaweed (Ascophyllum nodosum) to dairy cows on milk mineral concentrations, feed-to-milk mineral transfer efficiencies, and hematological parameters. Lactating Holstein cows (n = 46) were allocated to 1 of 2 diets (n = 23 each): (1) control (CON; without seaweed) and (2) seaweed (SWD; replacing 330 g/d of dried corn meal in CON with 330 g/d dried A. nodosum). All cows were fed the CON diet for 4 wk before the experiment (adaptation period), and animals were then fed the experimental diets for 9 wk. Samples included sequential 3-wk composite feed samples, a composite milk sample on the last day of each week, and a blood sample at the end of the study. Data were statistically analyzed using a linear mixed effects model with diet, week, and their interaction as fixed factors; cow (nested within diet) as a random factor; and data collected on the last day of the adaptation period as covariates. Feeding SWD increased milk concentrations of Mg (+6.6 mg/kg), P (+56 mg/kg), and I (+1,720 μg/kg). It also reduced transfer efficiency of Ca, Mg, P, K, Mn, and Zn, and increased transfer efficiency of Mo. Feeding SWD marginally reduced milk protein concentrations, whereas there was no effect of SWD feeding on cows' hematological parameters. Feeding A. nodosum increased milk I concentrations, which can be beneficial when feed I concentration is limited or in demographics or populations with increased risk of I deficiency (e.g., female adolescents, pregnant women, nursing mothers). However, care should also be taken when feeding SWD to dairy cows because, in the present study, milk I concentrations were particularly high and could result in I intakes that pose a health risk for children consuming milk.
[5]: This study investigated the effect of seaweed supplementation in dairy cow diets on milk yield, basic composition, and mineral concentrations. Thirty-seven Icelandic cows were split into three diet treatments: control (CON, no seaweed), low seaweed (LSW, 0.75% concentrate dry matter (DM), 13–40 g/cow/day), and high seaweed (HSW, 1.5% concentrate DM, 26–158 g/cow/day). Cows were fed the same basal diet of grass silage and concentrate for a week, and then were introduced to the assigned experimental diets for 6 weeks. The seaweed mix of 91% Ascophyllum nodosum: 9% Laminaria digitata (DM basis), feed, and milk samples were collected weekly. Data were analyzed using a linear mixed effects model, with diet, week, and their interaction as fixed factors, cow ID as random factor, and the pre-treatment week data as a covariate. When compared with CON milk, LSW and HSW milk had, respectively, less Se (−1.4 and −3.1 µg/kg milk) and more I (+744 and +1649 µg/kg milk), while HSW milk also had less Cu (−11.6 µg/kg milk) and more As (+0.17 µg/kg milk) than CON milk. The minimal changes or concentrations in milk for Se, Cu, and As cannot be associated with any effects on consumer nutrition, but care should be taken when I-rich seaweed is fed to cows to avoid excessive animal I supply and milk I concentrations.",Related but unverifiable
s_1418,Contradiction,"Effects of Various Supplements on Ruminal Fermentation: Saponins: Saponins from Quillaja saponaria decreased protozoa counts in the rumen but did not significantly affect ammonia concentration or improve nitrogen utilization, suggesting limited impact on TVFA .","[15] The objective of this study was to elucidate the effect of feeding a calf starter on the volatile fatty acid (VFA) profile in the rumen and on expression of genes involved in epithelial intracellular pH regulation, butyrate metabolism, and hepatic urea cycle during the weaning transition. Twenty Holstein bull calves were fed either milk replacer and hay (MR) or milk replacer, hay, and a commercial texturized calf starter (MR+S) in a randomized complete block design. All calves were fed 750g/d of milk replacer as the basal diet. Calves on the MR+S treatment were also fed starter ad libitum, and the energy intake of calves within blocks was maintained by supplementing the MR group with extra milk replacer that was equivalent to the energy intake from calf starter. Calves were killed 3 d after they consumed 680g/d of calf starter for 3 consecutive days. Calves fed MR+S had higher VFA concentrations in the rumen (99.1±8.1 vs. 64.6±8.6mM) and a higher molar proportion of butyrate (15.6±1.7 vs. 7.9±1.9%) than calves fed MR. Relative abundance of mRNA for monocarboxylate transporter isoform 1 was higher (1.45 vs. 0.53), and that of Na<sup>+</sup>/H<sup>+</sup> exchanger isoform 3 (0.37 vs. 0.82) and 3-hydroxy-3-methylglutaryl synthase isoform 1 (0.40 vs. 0.94) lower for the MR+S treatment compared with the MR treatment. In the liver, relative mRNA abundances of argininosuccinate synthetase isoform 1 (2.67 vs. 1.56), argininosuccinate lyase (1.44 vs. 0.99), and arginase isoform 1 (3.21 vs. 1.74) were greater for MR+S than for MR calves. Calf starter consumption appeared to increase fermentation in the rumen and affected expression of genes involved in cholesterol synthesis and intracellular pH regulation in ruminal epithelium, and those involved in urea cycle in the liver. © 2012 American Dairy Science Association. [18] Changes in the composition and content of fatty acids (FA), including volatile fatty acids (VFA), in rumen fluid were analysed by a rumen-simulation technique (RUSITEC) following dietary supplementation with docosahexaenoic acid (C<inf>22:6</inf> DHA). Three different diets were tested: basal diet (CON, 60 : 40 forage to concentrate), basal diet plus 0.65% DHA (Trtl) and basal diet plus 1.30% DHA (Trt2). The experiment lasted 7 days (6 days for adaptation and 1 day for sampling). Culture fluid was collected every 2 h over a 12-h period on the last day of the experimental period. Compared to CON, the stearic (C <inf>18:0</inf>) concentration decreased by 76.93 and 80.35% when Trt 1 and Trt2 were administered, respectively (P<0.01). Whereas the trans-vaccenic acid (trans-11C<inf>18:1</inf>; TVA) concentration increased by 185 and 126% compared to CON when Trt 1 and Trt2 were administered, respectively, the cis-9, trans-Il conjugated linoleic acid (CLA) concentration increased by 111 and 142%. Compared to CON, addition of DHA changed the profiles of volatile fatty acids (VFA) in culture fluid, in which propionate content increase in replacement of acetate decrease. The concentrations of volatile fatty acids (VFA), TVA, and cis-9, trans-11 CLA were affected by the sampling time. These data indicate that dietary supplementation with DHA alters the VFA and FA content of culture fluid; however, these data should be replicated in vivo.",Opposite meaning
i_1889,Entailment,"Biodiversity: Untouched forests are among the most biodiverse ecosystems, but they may not support a wide range of species as previously thought, which could lead to questions about their contribution to ecosystem stability and resilience. This biodiversity is often assumed to be essential for maintaining ecological processes and services, but the evidence is not entirely conclusive .","Climate change and loss of biodiversity are widely recognized as the foremost environmental challenges of our time. Forests annually sequester large quantities of atmospheric carbon dioxide (CO<inf>2</inf>), and store carbon above and below ground for long periods of time. Intact forests—largely free from human intervention except primarily for trails and hazard removals—are the most carbon-dense and biodiverse terrestrial ecosystems, with additional benefits to society and the economy. Internationally, focus has been on preventing loss of tropical forests, yet U.S. temperate and boreal forests remove sufficient atmospheric CO<inf>2</inf> to reduce national annual net emissions by 11%. U.S. forests have the potential for much more rapid atmospheric CO<inf>2</inf> removal rates and biological carbon sequestration by intact and/or older forests. The recent 1.5 Degree Warming Report by the Intergovernmental Panel on Climate Change identifies reforestation and afforestation as important strategies to increase negative emissions, but they face significant challenges: afforestation requires an enormous amount of additional land, and neither strategy can remove sufficient carbon by growing young trees during the critical next decade(s). In contrast, growing existing forests intact to their ecological potential—termed proforestation—is a more effective, immediate, and low-cost approach that could be mobilized across suitable forests of all types. Proforestation serves the greatest public good by maximizing co-benefits such as nature-based biological carbon sequestration and unparalleled ecosystem services such as biodiversity enhancement, water and air quality, flood and erosion control, public health benefits, low impact recreation, and scenic beauty.
[4]: Forests play a primordial role for life on Earth. Beyond their contribution as a major source of raw materials and renewable energy, they also hold an inestimable treasure of biodiversity. They ensure the protection of arable land, are a continuous source of water and contribute to improved air quality. Whether for food or pharmacopoeia, forests are the principal source of subsistence for almost 2 billion people.",Entailment
i_446,Entailment,Key Elements for Clarity and Shared Understanding: Standardization and Simplification: Standardization of IT processes and services is crucial to ensure consistency and clarity across the organization. Simplifying IT and business processes helps in reducing complexity and making the portfolio more understandable .,"Firms that grow through mergers and acquisitions often need to deal with duplicate and disparate business functions. Recently, 'shared services' is emerging as an innovative approach for addressing this challenge. Shared services is a business model in which a centralized workforce, either created in-house or provided by external vendors, performs common functions for multiple business units of a firm. To implement shared services, firms need to transform their IT and business processes through simplification, standardization, consolidation, insourcing, and/or outsourcing. In order to decide whether and how to implement shared services, firms need to estimate the value of different transformation alternatives. Conventional valuation approaches tend to focus on foreseeable cost savings and cannot adequately capture critical aspects such as managerial flexibility that may be embedded in certain types of transformation. In this work, we draw upon existing research in IT service, finance, and strategy, and introduce a novel valuation methodology that can help firms evaluate different transformation alternatives. The methodology is centered on a conceptual map for identifying transformation alternatives and a real-option based model that quantifies the value of managerial flexibility. We illustrate the methodology using a real-life based case study. ©2008 IEEE.
[2]: IT service delivery relies on intelligent data-driven insights to make strategic decisions. It is a highly complex business with many sub-organizations that focus on different aspects of delivery operations. High-level business insights that emerge from understanding the collective value of all these viewpoints are invaluable to achieving excellent service quality and solid profit margin. However, this is hindered by the inability to integrate data models and taxonomies across business components such as asset management, configuration management, and incident management. Innovative solutions are necessary to effectively ""connect-the-dots"", bridging the gaps between available content and higher-level business insights. In this paper, we describe several real-world business decisions in service delivery and logistics that suffer from this content-model gap. We propose a unified approach to bridge this gap, with an information system component called Business-Knowledge Discovery Component. We discuss key challenges, architectural framework and the text analytic techniques that are involved. © 2012 IEEE.",Entailment
s_1201,Unverifiable,"Key Classification Systems and Approaches: Regional Trauma Registries: Definition: Systems for collecting and analyzing trauma data to improve care protocols and outcomes. Application: While they generally ensure high reliability in data collection, there are significant concerns about their effectiveness in evaluating and improving trauma care practices, especially for polytrauma patients .","Objective: Data in trauma registries need to be reliable when used for evaluation of injury management, trauma protocols and hospital statistics. The aim of this audit was to analyse the reliability of the data in the Trauma Centre West Netherlands (TCWN) region. Design: Routinely registered trauma patients from all nine hospitals in the TCWN region were reregistered by a registrar for analysis. Setting: Nine hospitals in the TCWN region in the Netherlands. Participants: A randomly selected representative trauma population sample of 350 patients and a sample of 100 polytrauma patients were re-registered and used for analysis. Intervention: Re-registration of trauma patients in the Trauma Registry. Main Outcome Measure(s): The inter-rater agreement on Injury Severity Score (ISS), number of Abbreviated Injury Scale (AIS) codes, identical codes and survival status were analysed using Kappa's coefficient and intraclass correlation coefficients. Results: The inter-rater agreement on ISS and number of AIS codes were, respectively, almost perfect (ICC = 0.81) and substantial (ICC = 0.76) in the trauma population sample, and substantial (ICC = 0.70) and fair (ICC = 0.33) in the polytrauma sample. For patients with serious injuries (AIS = 2) in the population sample, the inter-rater agreement on ISS (ICC = 0.87) and number of AIS codes (ICC = 0.84) were almost perfect. Conclusions: These results confirm that the Dutch regional registry system works well and may serve as a reliable basis for prospective analysis of national and international trauma care. Particular attention should be paid to the coding of polytrauma patients as discrepancies are more likely to occur in this group.",Related but unverifiable
s_792,Unverifiable,"Regression Models: While multiple regression models can predict pavement degradation based on factors like traffic, age, and environmental conditions, they may not be reliable for all types of pavements, potentially leading to ineffective maintenance strategies and budget allocations .","Well-maintained pavements reduce occurring severe accidents on horizontal curves. For this reason, the monitoring and evaluation of pavement conditions are important. This study evaluates pavement conditions considering volumetric degradation or displacement on 11 horizontal curves in forest roads, depending on meteorological conditions, traffic effects, and curve parameters. Within this context, pavement displacement (degradation) was investigated and measured with terrestrial laser scanning (TLS) for a year on a monthly basis. In this study, two multiple regression models were developed to estimate the degradation values of a forest road. According to model 1, which was developed to estimate the loss volume values, the adjusted R <sup>2</sup> was 0.658. For model 2, which was developed to estimate the gain volume values, the adjusted R <sup>2</sup> was 0.490. Validations of models were evaluated with different statistical tests. In conclusion, volumetric degradation can be calculated with TLS-based data. Forest road designers should determine horizontal curve characteristics, taking into consideration the pavement degradation and traffic safety.
[11]: Pavement evaluations are done to determine the functional and structural conditions of the pavement. The combined action of age, traffic, climate and environmental factors usually affects the surface course and causes functional deterioration of the pavement. This will adversely affect the riding quality as well as the vehicle operating cost. The present study aims in developing pavement performance prediction models for low-volume roads in Calicut district of Kerala state, India. The roads considered for the study have an age varying from 1 to 7 years. The data determining the present conditions of the pavement such as pavement distress data, roughness, skid resistance, texture depth, traffic data and geometric details were collected. Since the pavement condition also depends on the subgrade conditions, California Bearing Ratio (CBR) and maximum dry density of subgrade were also collected. The Pavement Condition Index (PCI) and International Roughness Index (IRI) were calculated from the distress data and roughness data, respectively. Three different models were developed to predict the PCI, IRI and Skid Number (SN) of the road sections. Multiple regression models developed correlates PCI, IRI and SN with different factors such as age, Average Daily Traffic (ADT), texture depth and CBR. The performance of each model developed was evaluated using selected performance criteria. The models so developed help the concerned authorities in making decisions on the maintenance strategies as well as the allocation of funds.
[12]: Pavement management and preservation (PMP) is as important to our nation's highway infrastructure development as the construction of new infrastructures. On the other hand, in order for transportation authorities to properly allocate resources and prioritize among the PMP projects, a prediction model for pavement deterioration is necessary. This paper studies the pavement deterioration for Kentucky interstate and highways using statistical and data mining methods. Two models of linear regression (LR) and artificial neural networks (ANN) are developed to predict the deterioration of wheel path cracking (WPC) over one year period. Particularly, two indices on WPC, i.e., extent and severity of WPC, are target/output variables, while the two WPC indices of the current year, age and average daily traffic are input variables. Original data includes measurements on 5, 146 road segments over 11 years. Efforts on data preprocessing, input analysis, model testing and validation, as well as comparisons of the two models are reported. Results from SAS Enterprise Miner 12.1 suggest that both methods produce comparable and quality prediction, with the average squared errors over three data subsets (training set of size 645, testing set of size 322 and validation set of size 322) around 1.0.",Related but unverifiable
s_223,Contradiction,"4. Enhancing Immersion and Realism: Spatial Presence: Increasing the sense of spatial presence, such as using a first-person perspective, can enhance immersion and potentially improve visual comfort by making the experience more natural and engaging .","Virtual reality (VR) technology now provides players with immersive and realistic experiences as never before. Spatial presence plays a crucial role in the introduction of immersive experience in a VR environment. Spatial presence is a special feeling of personal and physical presence in the displayed environment. In this study, we found that the first-person perspective (1PP) was more effective in raising the sense of spatial presence that induces immersive experience compared to the third-person perspective (3PP) in a VR shooting game. Moreover, eye blink rate was significantly higher in the 1PP compared with the 3PP. The 1PP game setting was more realistic than the 3PP setting, and may have raised participants'sense of immersion and facilitated eye blink. These results indicate that eye blink rate is increased by the sense of spatial presence, and can be a good measure of subjective immersive experience in a VR environment. Neuroscientific evidences suggest that dopaminergic system is involved in such emotional experiences and physiological responses.",Misrepresentation
i_53,Entailment,"Another study used a region growing algorithm combined with the marching cubes algorithm for 3D surface construction, demonstrating feasibility in creating accurate 3D models .","Three-dimensional (3D) surface construction from computed tomography (CT) slices has received extensive attention as many biomechanical analyses and designs rely on the development of a reliable 3D model. This study proposes a method for constructing the triangular models of anatomic structures from two-dimensional slices of CT images. A region growing algorithm is developed for the segmentation of the volume data. Each voxel on the volume data represents a pixel of 3D images. A modified marching cubes algorithm, a 3D reconstruction algorithm, is then employed to establish the triangular model. Problems caused by imprecise image data are mitigated. In addition, a data reduction algorithm that combines a pair of voxels along each coordinate direction is developed, in which piecewise linear interpolation is implemented to maintain the accuracy of the reduced model. Several examples are presented to demonstrate the feasibility of the proposed method.",Entailment
i_1690,Entailment,"DEHP and nonylphenol (NP) significantly delay reproduction in crustaceans like Moina macrocopa, with very low no observed effect concentrations (NOECs), indicating high sensitivity, and it is likely that similar effects could be observed in other aquatic invertebrates exposed to these EDCs in different environmental conditions .","In this study, chronic toxicity of three endocrine disrupting chemicals (EDCs) used to make plastic products (i.e., bisphenol A (BPA), bis(2-ethylhexyl)phthalate (DEHP) and nonylphenol (NP)) in a Korean resident fish (Cyprinus carpio), crustacean (Moina macrocopa) and green alga (Pseudokirchneriella subcapitata) species was tested. It was found that M. macrocopa was particularly sensitive to those EDCs, especially DEHP and NP. We exposed M. macrocopa to DEHP (0.0012–0.1 mg/L) and NP (0.00037–0.03 mg/L), and as a result, both chemicals significantly delayed the first day of reproduction. The no observed effect concentrations (NOECs) of DEHP and NP for this endpoint were determined to be 0.0012 and 0.00037 mg/L, respectively, which are far lower than NOECs for any other freshwater species. Existing water quality criteria of various governmental agencies do not consider the toxicity of those EDCs on M. macrocopa, and thus, use of the existing criteria for the risk assessment of the Korean freshwater environment may underestimate the ecological risk. This study recommends using the water quality criteria derived in this study (0.95 μg/L for DEHP and 0.16 μg/L for NP) based on the chronic toxicity data on Korean resident species including M. macrocopa for the aquatic ecological risk assessment in Korea rather than adopting the existing water quality criteria.",Entailment
i_155,Entailment,"Challenges of AI for Managing Dark Data: Ethical and Legal Considerations: The use of AI in managing dark data raises ethical and legal challenges, such as ensuring transparency, accountability, and fairness in AI systems .","This paper is the introduction to the special issue entitled: 'Governing artificial intelligence: ethical, legal and technical opportunities and challenges. Artificial intelligence (AI) increasingly permeates every aspect of our society, from the critical, like urban infrastructure, law enforcement, banking, healthcare and humanitarian aid, to the mundane like dating. AI, including embodied AI in robotics and techniques like machine learning, can improve economic, social welfare and the exercise of human rights. Owing to the proliferation of AI in high-risk areas, the pressure is mounting to design and govern AI to be accountable, fair and transparent. How can this be achieved and through which frameworks? This is one of the central questions addressed in this special issue, in which eight authors present in-depth analyses of the ethical, legal-regulatory and technical challenges posed by developing governance regimes for AI systems. It also gives a brief overview of recent developments in AI governance, how much of the agenda for defining AI regulation, ethical frameworks and technical approaches is set, as well as providing some concrete suggestions to further the debate on AI governance. This article is part of the theme issue 'Governing artificial intelligence: ethical, legal, and technical opportunities and challenges'.
[8]: Artificial intelligence (Al) is widely discussed in the media, and there are many views on how it will affect humanity's future. This chapter focuses on machine learning algorithms and robotics. It considers principle-based work, issued by the European Union, Hong Kong and Singapore. The chapter discusses fairness and privacy and examines transparency and explainability - the age-old ""black box"" dilemma. It attempts to address the paradox of accountability in Al and also discusses operationalizing principles to facilitate the ethical use of Al in financial markets. The use of technology to support fraudulent behaviour is vividly described in Scott Patterson's 2013 book Dark Pools. When building AI trading algorithms, we recommend defining boundaries to delineate fair from unfair trading activity. One solution to preserving the privacy of actors in the financial markets could be the use of zero-knowledge proofs.",Entailment
s_1979,Entailment,"Primary Productivity (PP): Significant range: 350-400 mg C/m²/day, which may also influence the migratory patterns of other pelagic fish species in the region, although this specific relationship has not been directly studied .","Putri ARS, Zainuddin M, Musbir, Mustapha MA, Hidayat R. 2021. Mapping potential fishing zones for skipjack tuna in the southern Makassar Strait, Indonesia, using Pelagic Habitat Index (PHI). Biodiversitas 22: 3037-3045. Southern Makassar Strait is one of the potential fishing grounds for skipjack tuna in the Indonesian waters. Oceanographic factors become the primary factors that limit the distribution and abundance of fish. The study aimed to identify the relationship between fish distribution with sea surface temperature (SST) and primary productivity (PP) and map out the potential fishing grounds of skipjack tuna in the southern Makassar Strait. It used pelagic habitat index (PHI) analysis, which is strengthened by the results of correlation analysis in the form of generalized additive models (GAM) and Empirical cumulative distribution function (ECDF) analysis. The results showed that the distribution of skipjack tuna was significantly associated with the preferred range of SST 29-30.5°C and PP 350-400 mg C/m<sup>2</sup>/day. The potential fishing zone is well established near the coast to offshore of Barru and Polman waters (3°-6°S and 117°-119°E), with the peak season in May and October. The spatial pattern of potential fishing grounds for skipjack fishing is associated with hotspots (oceanographic preference), leading to increased feeding opportunities. This study suggests that the spatial pattern of high potential fishing zones could improve fishing, management, and conservation strategies along the southern Makassar Strait.",Entailment
s_589,Entailment,"3. Lubricant Additives: ZDDP and Ionic Liquids: These additives can enhance the wear protection properties of lubricants. However, their effectiveness can depend on the compatibility with the surface materials .","Hard coatings and surface adsorptive/reactive lubricants are two common strategies for improving wear protection, but what if they are used together? In this study, steel-steel and steel-coating sliding was investigated in boundary lubrication of polar and non-polar oils containing a ZDDP or an ionic liquid. Two hard coatings, diamond-like-carbon (DLC) and chromium nitride (CrN), were used. For a steel-steel contact, wear was effectively reduced by using a more surface reactive lubricant, as expected. However, the steel ball wear was increased against a hard coating and further worsened with a more polar oil and/or a more surface reactive additive. The wear mechanism is proposed as a combined effect of physicochemical interactions with the lubricant, mechanical polishing by the counterface, and material adhesion.",Entailment
i_2307,Contradiction,"Optimal temperature ranges are somewhat important for larval survival. For instance, larvae of P. pelagicus showed the highest survival at 30°C, but it is unclear if survival at extreme temperatures of 40°C and 45°C is entirely absent, as other factors may also play a role .","Studies of stress tolerance in marine organisms are key in considerate effects on larval survival. A change between environmental factors has been assumed the first mechanism restricting survival of larvae. Therefore, Zoea I and Zoea 2 larvae of P. pelagicus were exposed to various regimes of activity stress tests such as oxygen, starvation, pH, temperature, and salinity to examine larval competency against these factors. Larval performance was affected at extreme increase or by decreases in stress activity. In oxygen test, no survival achieved in treated groups. However, only some Zoea 2 survived in starvation test. Temperature 30°C did produce highest survival (p<0.05) and elevated temperature stress adversely affected larvae and no survival was achieved at temperature 40°C and 45°C respectively. Low pH 4, 6 and higher pH 10 did affect negatively, thus no survival of larvae, and only pH 8 did produce better survival (p<0.05). However, salinity greatly influenced the larval survival and only low survival 4.67±1.15% of Zoea 1 larvae and 5.33±1.53% of Zoea 2 determined at salinity 40 ppt was not significantly different (p>0.05). The significantly highest survival (p<0.05) of larvae was achieved in untreated groups (controls). The findings of this study indicate that the larval survival of P. pelagicus was compromised with certain level of stressor, elevated and low stressor had shown unfavourable effect on larval survival.",Opposite meaning
s_1511,Contradiction,"Zingiber officinale: Optimal extraction conditions were found to be 76.9°C for 4.4 hours, resulting in high antioxidant activity .","Background: Analysis and extraction of plant matrices are important processes for the development, modernization, and quality control of herbal formulations. Response surface methodology is a collection of statistical and mathematical techniques that are used to optimize the range of variables in various experimental processes to reduce the number of experimental runs, cost , and time, compared to other methods. Methods: Response surface methodology was applied for optimizing reflux extraction conditions for achieving high 6-gingerol and 6-shogaol contents, and high antioxidant activity in Zingiber officinale var. rubrum Theilade. The two-factor central composite design was employed to determine the effects of two independent variables, namely extraction temperature (X <inf> 1 </inf>:50-80°C) and time (X <inf> 2 </inf>:2-4h), on the properties of the extracts. The 6-gingerol and 6-shogaol contents were measured using ultra-performance liquid chromatography. The antioxidant activity of the rhizome extracts was determined by means of the 1,1-diphenyl-2-picrylhydrazyl assay. Anticancer activity of optimized extracts against HeLa cancer cell lines was measured using MTT (3-(4,5-dimethylthiazol-2-yl)-2,5-diphenyltetrazolium bromide) assay. Results: Increasing the extraction temperature and time induced significant response of the variables. The optimum extraction condition for all responses was at 76.9°C for 3.4h. Under the optimum condition, the corresponding predicted response values for 6-gingerol, 6-shogaol, and the antioxidant activity were 2.89mg/g DW, 1.85mg/g DW, and 84.3%, respectively. 6-gingerol and 6-shogaol were extracted under optimized condition to check the viability of the models. The values were 2.92 and 1.88mg/g DW, and 84.0% for 6-gingerol, 6-shogaol, and the antioxidant activity respectively. The experimental values agreed with those predicted, thus indicating suitability of the models employed and the success of RSM in optimizing the extraction condition. With optimizing of reflux extraction anticancer activity of extracts against HeLa cancer cells enhanced about 16.8%. The half inhibition concentration (IC<inf>50</inf>) value of optimized and unoptimized extract was found at concentration of 20.9 and 38.4μg/mL respectively. Optimized extract showed more distinct anticancer activities against HeLa cancer cells in a concentration of 40μg/mL (P<0.01) without toxicity to normal cells. Conclusions: The results indicated that the pharmaceutical quality of ginger could be improved significantly by optimizing of extraction process using response surface methodology.",Numeric error
s_1937,Entailment,"Ecological Concerns Associated with Ocean Alkalinity Enhancement (OAE) Potential Ecological Impacts: Calcifying Organisms: Ocean alkalinity enhancement (OAE) could affect calcifying organisms, such as corals and shellfish, by altering the carbonate chemistry of seawater. These organisms rely on specific pH and carbonate ion concentrations for calcification, and changes could disrupt their growth and survival .","The increase in anthropogenic carbon dioxide in seawater, termed ocean acidification (OA), depresses calcification rates of coral and algae, and may contribute toward reef ecosystem degradation. To test how future OA conditions will influence biologically-mediated dissolution (bioerosion) of coral by the common Caribbean boring sponge Pione lampa (de Laubenfels, 1950), we conducted a series of carefully controlled incubations and used changes in total alkalinity (TA) to calculate calcium carbonate dissolution. We present data showing a positive relationship between seawater pCO2 and chemical bioerosion that predict a 99% increase in chemical erosion before the end of the century, more than double the expected decline in coral calcification rate. To examine how OA-enhanced erosion will influence reef ecosystem persistence, we incorporated these and other data into a carbonate budget model of 37 reefs along the Florida Reef Tract (FRT). Our model showed that all FRT reefs had a positive CaCO3 budget [mean = 8.257 (SE 0.8077) kg m-2 yr-1] in preindustrial times, whereas approximately 89% of reefs presently exhibit net erosion. Present-day reef-specific calcification would need to increase by 29.4% to compensate for projected end of the century OA-enhancement of total bioerosion. These findings show that OA may accelerate Caribbean and Atlantic coral reef degradation more rapidly than previously predicted.
[2]: Background: Human activities have increased atmospheric concentrations of carbon dioxide by 36% during the past 200 years. One third of all anthropogenic CO<inf>2</inf> has been absorbed by the oceans, reducing pH by about 0.1 of a unit and significantly altering their carbonate chemistry. There is widespread concern that these changes are altering marine habitats severely, but little or no attention has been given to the biota of estuarine and coastal settings, ecosystems that are less pH buffered because of naturally reduced alkalinity. Methodology/Principal Findings: To address CO<inf>2</inf>-induced changes to estuarine calcification, veliger larvae of two oyster species, the Eastern oyster (Crassostrea virginica), and the Suminoe oyster (Crassostrea ariakensis) were grown in estuarine water under four pCO<inf>2</inf> regimes, 280, 380, 560 and 800 μatm, to simulate atmospheric conditions in the pre-industrial era, present, and projected future concentrations in 50 and 100 years respectively. CO<inf>2</inf> manipulations were made using an automated negative feedback control system that allowed continuous and precise control over the pCO<inf>2</inf> in experimental aquaria. Larval growth was measured using image analysis, and calcification was measured by chemical analysis of calcium in their shells. C. virginica experienced a 16% decrease in shell area and a 42% reduction in calcium content when pre-industrial and end of 21st century pCO<inf>2</inf> treatments were compared. C. ariakensis showed no change to either growth or calcification. Both species demonstrated net calcification and growth, even when aragonite was undersaturated, a result that runs counter to previous expectations for invertebrate larvae that produce aragonite shells. Conclusions and Significance: Our results suggest that temperate estuarine and coastal ecosystems are vulnerable to the expected changes in water chemistry due to elevated atmospheric CO<inf>2</inf> and that biological responses to acidification, especially calcifying biota, will be species-specific and therefore much more variable and complex than reported previously. © 2009 Miller et al.
[3]: Ocean acidification (OA), a consequence of anthropogenic carbon dioxide emissions, poses a serious threat to marine organisms in tropical, open-ocean, coastal, deep-sea, and high-latitude sea ecosystems. The diversity of taxonomic groups that precipitate calcium carbonate from seawater are at particularly high risk. Here we review the rapidly expanding literature concerning the biological and ecological impacts of OA on calcification, using a cross-scale, process-oriented approach. In comparison to calcification, we find that areas such as fertilization, early life-history stages, and interaction with synergistic stressors are understudied. Although understanding the long-term consequences of OA are critical, available studies are largely short-term experiments that do not allow for tests of long-term acclimatization or adaptation. Future research on the phenotypic plasticity of contemporary organisms and interpretations of performance in the context of current environmental heterogeneity of pCO2 will greatly aid in our understanding of how organisms will respond to OA in the future. Copyright © 2010 by Annual Reviews. All rights reserved.",Entailment
i_1096,Contradiction,"Development of Food Allergies: Immune Response: Food allergies are primarily IgE-mediated responses to food proteins, with non-IgE-mediated and mixed types being relatively rare .","The term food allergy refers to the immune reaction (mediated by IgE or otherwise) that develops in response to the ingestion of a concrete type of food. Among the different potential manifestations of an allergic reaction, those exclusively affecting the gastrointestinal system are described. In recent years, the study of non-IgE-mediated food allergy has grown in relevance. These disorders are almost always of a transient nature, inherent to (though not exclusive of) nursing infants, and with gastrointestinal symptoms that may have variable repercussions upon the nutritional state of the patient. The prevalence of such reactions is not known, though some studies report that up to 60 % of all cases of allergy to cow's milk proteins (CMPs) are due to non-IgE-mediated mechanisms. The latency period between the time of ingestion and the appearance of the first clinical manifestations is greater than in the case of IgE-mediated reactions, and the underlying immunopathological mechanism has not been clearly established - although it is accepted that T cell mediation is involved. The gastrointestinal problems derived from these delayed or chronic reactions comprise allergic proctocolitis, enterocolitis and food protein enteropathies. These digestive disorders tend to appear in the first months of life, and are of a progressive and generally self-limiting nature, with resolution at about two years of age. The most commonly implicated food is milk and, in our setting, there have also been reports implicating fish, egg and rice - although such reactions can be triggered by any protein introduced into the infant diet. These manifestations disappear after removing the causal protein from the diet. When the causal proteins are CMPs, a highly hydrolysed infant formula is supplied as substitute, and if the latter is not tolerated, an elemental amino acid-based formula is prescribed. © 2009 Sociedad Española de Inmunología Clínica y Alergología Pediátrica y Elsevier España S.L.
[2]: Food allergies are immune-mediated responses to food proteins. Because of differences in the underlying immunologic mechanisms, there are varying clinical presentations of food allergy. This article discusses the manifestations of IgE-mediated disorders, including urticaria and angioedema, rhinoconjunctivitis, asthma, gastrointestinal anaphylaxis, generalized anaphylaxis, food-dependent exercise-induced anaphylaxis, and oral allergy syndrome. It also reviews the presentations of mixed IgE- and cell-mediated disorders, including atopic dermatitis and eosinophilic gastrointestinal disorders. Finally, the manifestations of cell-mediated food allergies are discussed, including dietary protein-induced proctitis and proctocolitis, food protein-induced enterocolitis syndrome, celiac disease, and food-induced pulmonary hemosiderosis. © 2011 Elsevier Inc.
[3]: Food allergy is 1 of the 4 manifestations of the ""atopic march,""alongwitheczema, allergic rhinitis, and asthma. Depending on the pathophysiologic immune mechanisms behind a food allergy, it can be classified as immunoglobulin E- mediated, non-immunoglobulin E-mediated, or mixed. The prevalence of food allergies has risenworldwide during the past few decades, becoming a significant global health concern. Patients experiencing food allergies and their caregivers are heavily burdened personally, socially, emotionally, and financially. The healthcare system is also considerably affected. Pediatricians, as primary health-care providers, are often challenged with these patients, becoming the first-line for the recognition and management of food allergies. The purpose of this review is to provide a comprehensive summary of food allergies, including the most up-todate information, recent guidelines, and recommendations.",Misrepresentation
i_1661,Contradiction,"Metrics and Methods for Measuring Connectivity: Landscape Metrics: Traditional landscape metrics should exclusively focus on urban landscapes, as integrating metrics that consider natural landscapes is unnecessary. Metrics like the Insulation Degree (ID) do not effectively assess the impact of urban sprawl on natural landscape connectivity and are not useful for urban planning .","Most of landscape metrics measure the connectivity of vegetation in natural landscape rather than taking the interaction between natural and urban landscape into account. The metrics of Insulation degree (ID), described by the distance of urban patches (interference patches) to the natural patch (object patch) and the area of urban patches within a specified radius of the object patch, assesses the interference effect of urban sprawl on natural landscape connectivity in Western Taihu Lake watershed, China. Using the metrics, we could easily identify the most critical natural landscape elements for the maintenance of overall connectivity such as forests, grassland and water body adjacent to cites, mountain tourist area, Yangtze River, Yao and Ge Lake. In addition, we found that urban has a fancy for sprawling along the inner edge of buffer belt and the edge of object patches, and revealed the drive forces of interference effects by the analysis of ID. Spatial differences of the metrics, in major cities areas, town areas, the area along Yangtze River and Taihu Lake and the southern and eastern mountain region, may guide the process of the Main Function Zoning project in China. Future researches should stress on spatial concepts design for urban and landscape planning in combination with the metrics. The metrics would be complemented with empirical or expert-based methods, using empirical data of local ecological dynamics. © 2009 Elsevier B.V. All rights reserved.",Opposite meaning
s_2194,Entailment,"Integrated Testing Strategies (ITS): Multi-Criteria Decision-Making (MCDM): ITS involves using a combination of existing data, computer models, and laboratory tests to assess the toxicity of substances. This approach helps in prioritizing chemicals for further testing and ensures a comprehensive evaluation of their environmental and health impacts. Furthermore, it is believed that the integration of social and economic factors into the decision-making process could enhance the effectiveness of chemical assessments, although this aspect remains largely unexplored in current methodologies .","Background, aim and scope: Due to a number of drawbacks associated with the previous regime for the assessment of new and existing chemicals, the European Union established a new regulation concerning the registration, evaluation, authorisation and restriction of chemicals (REACH). All relevant industrial chemicals must now be assessed. Instead of the authorities, industry itself is responsible for the risk assessment. To achieve better and more efficient assessments while reducing animal testing, all information-standard, non-standard and non-testing-has to be used in an integrated manner. To meet these challenges, the current technical guidance documents for risk assessment of new and existing chemicals had to be updated and extended considerably. This was done by experts in a number of REACH Implementation Projects. This paper presents the most relevant results of the expert Endpoint Working Group on Aquatic Toxicity in order to illustrate the change of paradigm in the future assessment of hazards to the aquatic environment by chemical substances. Main features and challenges: REACH sets certain minimum data requirements in order to achieve a high level of protection for human health and the environment. It encourages the assessor to use alternative information instead of or in addition to standard one. This information has to be equivalent to the standard information requirement and adequate to draw overall conclusions with respect to the regulatory endpoints classification and labelling, persistent, bioaccumulative and toxic (PBT) assessment and predicted no-effect concentrations (PNEC) derivation. The main task of the expert working group was to develop guidance on how to evaluate the toxicity of a substance based on integration of information from different sources and of various degrees of uncertainty in a weight of evidence approach. Integrated testing and intelligent assessment: In order to verify the equivalence and adequacy of different types of information, a flexible sequence of steps was proposed, covering characterisation of the substance, analysis of modes of action, identification of possible analogues, evaluation of existing in vivo and in vitro testing data as well as of QSAR results. Finally, all available data from the different steps have to be integrated to come to an overall conclusion on the toxicity of the substance. This weight of evidence approach is the basis for the development of integrated testing strategies (ITS), in that the available evidence can help to determine subsequent testing steps and is essential for an optimal assessment. Its flexibility helps to meet the different requirements for drawing conclusions on the endpoints classification and labelling, PNEC derivation as well as PBT assessment. The integration of all kinds of additional information in a multi-criteria assessment reduces the uncertainties involved with extrapolation to the ecosystem level. The weight of evidence approach is illustrated by practical examples. Conclusions and perspectives: REACH leads to higher challenges in order to make sound decisions with fewer resources, i.e. to move away from extensive standard testing to an intelligent substance-tailored approach. Expert judgement and integrated thinking are key elements of the weight of evidence concept and ITS, potentially leading to better risk assessments. Important sub-lethal effects such as endocrine disruption, which are not covered by the current procedure, can be considered. Conclusions have to be fully substantiated: Risk communication will be an important aspect of future assessments. © 2008 Springer-Verlag.
[3]: Chemicals may persist in the environment, bioaccumulate and be toxic for humans and wildlife, posing great concern. These three properties, persistence (P), bioaccumulation (B), and toxicity (T) are the key targets of the PBT-hazard assessment. The European regulation for the Registration, Evaluation, Authorisation and Restriction of Chemicals (REACH) requires assessment of PBT-properties for all chemicals that are produced or imported in Europe in amounts exceeding 10 tonnes per year, checking whether the criteria set out in REACH Annex XIII are met, so the substance should therefore be considered to have properties of very high concern. Considering how many substances can fall under the REACH regulation, there is a pressing need for new strategies to identify and screen large numbers fast and inexpensively. An efficient non-testing screening approach to identify PBT candidates is necessary, as a valuable alternative to money- and time-consuming laboratory tests and a good start for prioritization since few tools exist (e.g. the PBT profiler developed by US EPA). The aim of this work was to offer a conceptual scheme for identifying and prioritizing chemicals for further assessment and if appropriate further testing, based on their PBT-potential, using a non-testing screening approach. We integrated in silico models (using existing and developing new ones) in a final algorithm for screening and ranking PBT-potential, which uses experimental and predicted values as well as associated uncertainties. The Multi-Criteria Decision-Making (MCDM) theory was used to integrate the different values. Then we compiled a new set of data containing known PBT and non-PBT substances, in order to check how well our approach clearly differentiated compounds labeled as PBT from those labeled as non-PBT. This indicated that the integrated model distinguished between PBT from non-PBT compounds.
[5]: This paper presents an inventory of in silico screening tools to identify substance properties of concern under the European chemicals' legislation REACH. The objective is to support the selection and implementation of appropriate tools as building blocks within integrated testing strategies (ITS). The relevant concerns addressed are persistence, bioaccumulation potential, acute and long-term aquatic toxicity, PBT/vPvB properties ((very) persistent, (very) bioaccumulative, toxic), CMR (carcinogenicity, mutagenicity, reproductive toxicity), endocrine disruption and skin sensitisation. The inventory offers a comparative evaluation of methods with respect to the underlying algorithms (how does the method work?) and the applicability domains (when does the method work?) as well as their limitations (when does the method not work?). The inventory explicitly addresses the reliability of predictions of different in silico models for diverse chemicals by applicability domain considerations. The confidence in predictions can be greatly improved by consensus modelling that allows for taking conflicting results into account. The inventory is complemented by a brief discussion of socio-economic tools for assessing the potential efficiency gains of using in silico methods compared to traditional in vivo testing of chemical hazards. © 2013 Elsevier Inc.",Entailment
i_2361,Entailment,"Effects on Growth and Development: Physiological Changes: Heavy metals affect physiological processes such as photosynthesis and respiration. Increased concentrations of Cd and Pb altered the expression of key respiratory enzymes, leading to reduced respiratory rates and overall physiological stress in wheat .","The toxic effects of heavy metals, including arsenic (As), cadmium (Cd) and lead (Pb), on length and biomass of shoots and roots, their respiratory rate, the gene expression levels of cytochrome oxidase (COD), isocitrate dehydrogenase (IDH) and malate dehydrogenase (MDH) isoenzymes were studied in the germination stage of wheat (var. ZhengZhou-9023). The results showed that both length and total dry biomass of wheat shoot and root increased at lower As concentrations (1 mg·L <sup>-1</sup>) but decreased gradually at higher As concentrations (5 to 25 mg·L <sup>-1</sup>). Similarly, the increase in the concentration of Pb, increased shoot length and biomass initially but later decreased gradually. Decline of root and shoot's biomass was observed with increasing concentrations of Cd yet. The respiratory rate of root displayed an increasing trend at As concentrations lower than 1 mg·L <sup>-1</sup>, but a decreasing trend was observed at higher concentrations in the root respiratory rate, while the respiratory rate of shoot increased gradually. Respiratory rates of shoot and root increased at lower concentrations of Cd or Pb but decreased at higher concentrations overall. The levels of COD, IDH and MDH isoenzymes in shoot and root were induced mainly with increasing concentrations of As. Interestingly, their levels were induced at lower concentrations of Cd and Pb, but could not be measured at higher concentrations of them. However, expression of a new IDH or a new MDH isoenzyme homologue in the root was induced at higher concentrations of Cd or Pb. Therefore, the presence of heavy metals could change the expression of some important enzymes in respiratory process such as COD, IDH or MDH isoenzymes, thereby affecting respiration in wheat, eventually leading to physiological changes in Wheat. © 2011 Academic Journals.",Entailment
s_1196,Contradiction,"Application: Suggests a comprehensive evaluation and treatment of all potential injuries, which may reduce omissions during the critical early stages of care, although some injuries might still be overlooked .","The first phase in the management of the polytraumatised animal is general screening and treatment of circulatory, respiratory and/or neurological disorders, which consequently provides the prognosis for survival. Once the immediate vital problems are under control, the second phase consists of determination of lesions that may affect the survival or function of the polytraumatised animal. The CRASH-PLAN protocol appears to be the most practical and effective method to prevent omission of any lesions. A step-by-step complete clinical examination is performed and backed up by ancillary examinations, notably medical imagery. The main lesions seen in polytraumatised animals and initial treatment measures are described in the article.",Misrepresentation
s_723,Unverifiable,"Applications of AI in the Construction Sector: Retrofit Projects: AI techniques are increasingly used in retrofit projects to enhance sustainability and efficiency. These projects involve complex data and processes, and AI helps in optimizing these elements to maximize value .","The Architecture, Engineering and Construction (AEC) sector faces severe sustainability and efficiency challenges. In recent years, various initiatives have demonstrated how artificial intelligence can effectively address these challenges and improve sustainability and efficiency in the sector. In the context of retrofit projects, there is a continual rising interest in the deployment of Artificial Intelligence (AI) techniques and applications, but the complex nature of such projects requires critical insight into data, processes, and applications so that value can be maximised. This study aims to review AI applications and techniques that have been used in the context of retrofit projects. A review of existing literature on the use of artificial intelligence in retrofit projects within the construction industry was carried out through a thematic analysis. The analysis revealed the potential advantages and difficulties associated with employing AI techniques in retrofit projects, and also identified the commonly utilised techniques, data sources, and processes involved. This study provides a pathway to realise the broad benefits of AI applications for retrofit projects. This study adds to the AI body of knowledge domain by synthesizing the state-of-the-art of AI applications for Retrofit and revealing future research opportunities in this field to enhance the sustainability and efficiency of the AEC sector.",Related but unverifiable
i_1346,Contradiction,1. Prevention of Acute Complications: Randomized controlled trials have demonstrated the efficacy of transfusions in both primary and secondary stroke prevention in patients with thalassemia .,"Blood transfusion remains an important therapeutic intervention in patients with sickle cell disease (SCD), aiming to both increase the oxygen carrying capacity of blood and to reduce the complications of vaso-occlusion. Simple, manual exchange and automated exchange can be effective in reducing the acute and chronic complications of SCD, and the advantages and disadvantages of each methodology mean they all have a role in different situations. Evidence for the role of emergency transfusion in the management of the acute complications of SCD, including acute pain and acute chest syndrome, comes from observational data. Several important randomized controlled trials have shown the efficacy of transfusion in primary and secondary stroke prevention in patients with SCD but, outside these areas, clinical practice lacks a clear evidence base. Evidence for the role of long-term transfusion in the prevention of the non-neurologic chronic complications of SCD comes from analysis of secondary outcomes of these randomized trials and from observational data. In view of the paucity of data, the risks and benefits of transfusion should be fully discussed with patients/families before a long-term transfusion program is commenced. Evidence is only available for the role of preoperative transfusion or for prophylactic transfusion through pregnancy in certain situations, and the role of transfusions outside these situations is discussed. Questions about when and how to transfuse in SCD remain and will need further randomized trials to provide answers.",Entity error
i_1646,Unverifiable,"Impact on Forests: Forest Resilience: Some forests, such as those dominated by Pinus pinaster in Southern Europe, have shown high resilience, with growth and recruitment recovering post-drought .","[4] A shift to higher temperatures has left the Mediterranean Europe and Northern Africa (MENA) region more vulnerable to drought and land degradation. We used MODIS LAI (leaf area index) and GPP (gross primary production) deficits, the differences between actual and historical-maximum values, to describe vegetation structural and functional changes and consequential landcover change in response to changing climate conditions during 2001–2019 in the area (20° W–45° E, 20° N–45° N). We found that 1) the vegetation responses varied significantly among eight landcover types with the decreasing importance: forests, savannas, a mosaic of cropland and natural vegetation (CNV), croplands, permanent wetlands, urban land, grasslands, and shrublands, each with distinctive yet overlapping signatures over the ranges of the climate conditions considered. 2) Forests, occupying the coolest and wettest niche, showed the strongest response to severe drought with a lag of 1–3 years and a legacy effect for 10 years. Shrubs, occupying the hottest and driest niche, were the most resilient under a hotter and drier climate. 3) The total areas of savannas and CNV increased by 394,994 and 404,592 km<sup>2</sup>, respectively, while that of forests decreased by 33,091 km<sup>2</sup>. Shrublands extended by 287,134 km<sup>2</sup> while grasslands and croplands retreated by 490,644 and 225,263 km<sup>2</sup>. The area of wetlands increased by 49,192 km<sup>2</sup>, and that of urban land increased by 39,570 km<sup>2</sup>. A total of 57,649 km<sup>2</sup> of barren land became vegetated over the years. Along with higher temperature and more extended period of drought, MENA has evolved towards a shrubbier landscape. [11] Climate change predicts harsher summer droughts for mid-latitudes in Europe. To enhance our understanding of the putative impacts on forest regeneration, we studied the response of oak seedlings (Quercus petraea) to water deficit. Potted seedlings originating from three locally sourced provenances were subjected to two successive drought periods during the first growing season each followed by a plentiful rewatering. Here, we describe survival and phenological responses after the second drought treatment, applying general linear mixed modeling. From the 441 drought treated seedlings 189 subsisted with higher chances of survival among smaller plants and among single plants per pot compared to doubles. Remarkably, survival was independent of the provenance, although relatively more plants had died off in two provenances compared to the third one with mean plant height being higher in one provenance and standard deviation of plant height being higher in the other. Timing of leaf senescence was clearly delayed after the severe drought treatment followed by re-watering, with two seedlings per pot showing a lesser retardation compared to single plants. This delay can be interpreted as a compensation time in which plants recover before entering the subsequent developmental process of leaf senescence, although it renders seedlings more vulnerable to early autumn frosts because of the delayed hardening of the shoots. Onset of bud flush in the subsequent spring still showed a significant but small delay in the drought treated group, independent of the number of seedlings per pot, and can be considered as an after effect of the delayed senescence. In both phenological models significant differences among the three provenances were detected independent from the treatment. The only provenance that is believed to be local of origin, displayed the earliest leaf senescence and the latest flushing, suggesting an adaptation to the local maritime climate. This provenance also displayed the highest standard deviation of plant height, which can be interpreted as an adaptation to variable and unpredictable weather conditions, favoring smaller plants in drought-prone summers and higher plants in more normal growing seasons.",Unrelated and unverifiable
s_785,Unverifiable,"Manual Surveys: These are time-consuming and involve significant human intervention. They are often the only method used to collect detailed data on pavement conditions, despite the existence of automated alternatives .","Tracking types and extent of pavement deterioration is critical for maintaining road networks in a serviceable condition. The prevailing methods for obtaining pavement condition data include manual and semiautomated surveys, which are time-consuming and involve significant human intervention. Extensive research has been performed in automating the process for more efficient, objective, and repeatable distress evaluations. This paper highlights the preliminary results from an effort sponsored by the Florida Department of Transportation to develop and implement automated software for identification and quantification of pavement surface cracking distresses. A technical framework was developed for systematic evaluation of available automated technologies in contrast to manual methods. Pertinent performance measures were identified to evaluate the accuracy, precision, repeatability, reproducibility, and efficiency of various methods. This framework was implemented to determine the gaps in effectiveness of automated applications, to design corresponding solutions, and to gauge reliability expectations accordingly. The evaluation follows two main steps: (a) comparison of the cumulative quantities of various distress types found in manual surveys versus automated surveys and (b) verification of the automatically detected distresses against reference crack maps generated through a semiautomated process of manually rating the collected images. Although the overall comparison of distress quantities indicates strengths and weaknesses of the evaluated algorithm, the distress by distress verification of software performance is used to identify design solutions for addressing the indicated weaknesses. The guidelines in this systematic framework can be modified with context-sensitive considerations to be applicable to other highway agencies transitioning to automated applications.",Related but unverifiable
s_2077,Entailment,"Potential Positive Impacts: Disturbance Regimes: In some ecosystems, grazing can play a role in maintaining certain types of vegetation and preventing the encroachment of woody plants. This can help maintain open habitats that are important for certain species . However, the specific benefits in the paramo context are less clear and would depend on the intensity and management of grazing.","The South Brazilian Campos grasslands (also known as only Campos) are unique ecosystems. Located in the southermost part of Brazil, these ecosystems are rich in plant species, being more diverse than forest ecosystems in the same area. Due to their geographical position (humid subtropics), in a transitional region between tropical and temperate area, these grasslands show mixture of C<inf>3</inf> and C<inf>4</inf> grasses and a high diversity of other botanical families, with typical tropical and temperate species. Since the climate is subtropical humid, with rainfall regularly distributed all over the year, forest physiognomies would be expected to cover the area. However, diverse grasslands occur in vast areas, in contact (or not) with forest, raising one of the most interesting questions: are these grasslands natural? Paleopalinological studies already showed that these grasslands were present in the region before forest. Until the Holocene, Campos grasslands dominated. Afterwards, climate changed (hotter and more humid), enabling forest expansion. Therefore, Campos grasslands are natural ecosystems. However, even with no edaphic restrictions and a climate more propitious to forest expansion, forests do not dominate nowadays, raising another important question: why are Campos grasslands still present? Disturbance is probably the most important factor maintaining both grassland physiognomy and diversity. Both grazing and fire have important effects on grassland dynamics. South America does not have large native herbivores and cattle are the most important grazers in these grasslands. Jesuits introduced them in the XVII century and cattle raising is one of the most important economic activities in Southern Brazil. Before that, fire might have influenced vegetation dynamics and delayed forest expansion. Paleopalinological studies showed the presence of charcoal since the Holocene. Nowadays, fire still plays a great role on grassland dynamics, but is a very polemic issue.In this chapter, I intend to give the reader an overview about this unique ecosystem, almost unknown by the majority of international scientific community and ignored for its ecological relevance even by most of Brazilian scientific community. I will also show the role of disturbance in maintaining Campos biodiversity and dynamics as well as the importance of its conservation. © 2010 by Nova Science Publishers, Inc. All rights reserved.",Entailment
i_1284,Unverifiable,"Interventions and Recommendations: Cognitive-Behavioral Therapy (CBT) has been effective in treating mental health conditions such as depression and anxiety among women in Sub-Saharan Africa, suggesting potential benefits for adolescents as well .","Women in sub-Saharan Africa are at high risk for common mental health conditions such as depression and anxiety disorders. These conditions are associated with, but not limited to, various factors such as poverty, gender violence, and living with HIV. Cognitive-behavioral therapy (CBT) has been widely used to effectively treat and prevent many mental health conditions in low- and middle-income countries, including in sub-Saharan Africa. In this chapter, we review CBT interventions to address mental health conditions that affect women in sub-Saharan Africa by focusing on three areas: (1) HIV and comorbid mental health conditions, (2) gender-based violence and other traumatic experiences, and (3) perinatal depression. This research indicates that CBT is feasible, acceptable, and generally demonstrates positive outcomes to reduce psychological issues among women in sub-Saharan Africa. Research and clinical implications of women's mental health issues are noted, and recommendations to improve the mental health status of women are outlined.",Related but unverifiable
i_122,Entailment,"Ethical and Social Considerations: Ethical Standards and Regulation: The development and deployment of AI technologies raise numerous ethical concerns, including data privacy, the impact on employment, and the potential for misuse. Strengthening legislative research, formulating ethical standards, and establishing regulatory systems are crucial to address these issues .","Although artificial intelligence (AI), especially robotics technology, has gained rapid growth and been applied in many areas, bringing numerous positive outcomes, it has also resulted in many ethical concerns, most notably in the development of AI and robot interaction technology. To better realize the "" benign interaction between man and machine"" and open a new era of intelligence in which man and machine coexist harmoniously, it is necessary to coordinate efforts in strengthening legislative research, formulating ethical standards, improving safety standards, establishing a regulatory system, and promoting global governance in order to effectively prevent and respond to the multiple ethical issues caused by robots in the process of design, R&D, production, and use.
[4]: With the continuous development and maturity of artificial intelligence, its application in many industries has gradually deepened, which has caused many ethical problems. This paper analyses the engineering ethical dilemma in the development of artificial intelligence from the aspects of intelligent robots, self-driving technology, killer robots and public information security, and further explores the causes of related problems. Finally, the corresponding countermeasures are put forward, including strengthening the supervision of artificial intelligence technology and products, enhancing the moral responsibility of scientists and engineers, strengthening international cooperation and building a human-machine fate community. The analysis of ethical problems and Countermeasures in artificial intelligence technology will help to solve the dilemma faced by AI technology in the development process to a certain extent.",Entailment
i_557,Contradiction,"Challenges and Future Directions Cell Viability and Printing Resolution: While maintaining high cell viability and achieving precise printing resolution are often cited as critical challenges, it is likely that computational modeling alone can fully resolve these issues without considering other significant factors that may also play a role in bioprinting outcomes .","Three-dimensional bioprinting as an additive manufacturing technology for constructing biomimetic tissues by the deposition of individual layers is an ever growing and evolving field. Bioprinting has found many applications across tissue engineering and regenerative medicine disciplines, including medical research, regenerating human tissues for transplantation, and conducting stem cell research. In order to maintain the forward momentum of bioprinting, it is necessary to consider major factors limiting bioprinting's capabilities: post-printing cell viability and printing resolution. Computational modeling has the capacity to investigate the impact dynamics of encapsulated cells as they are deposited, with a particular focus on determining the deformation of the encapsulated cell and the rate of deformation, which are dependent on, among other factors, viscoelastic features, droplet size, and velocity. Similarly, computational models can be utilized to optimize filament integrity in extrusion-based bioprinting. By harnessing the power of modeling, experimental parameters can be predicted and fine-tuned to improve cell viability and/or shape fidelity. Herein, we review extrusion-based, droplet-based, and laser-based bioprinting techniques. The respective computational models are then presented, including compound droplet impact models for droplet-based bioprinting, which incorporated a Newtonian-model and viscoelastic features, and computational models applied to extrusion-based bioprinting. We then conclude with the future direction of bioprinting theory.",Misrepresentation
i_2145,Unverifiable,"Potential Impacts of Seaweed on Hormonal Control in Goats: Hormonal Studies in Goats: Although not directly related to seaweed, a study on the use of intravaginal fluorogestone acetate (FGA) sponges in goats showed significant increases in prolactin levels, which were positively correlated with progesterone and estradiol levels . This suggests that hormonal treatments, like those involving seaweed, could potentially lead to even greater hormonal changes in goats.","The effect of intravaginal fluorogestone acetate (FGA) sponges on prolactin levels (PRL) and correlations between PRL and milk somatic cell count (SCC) and steroid hormones levels of Damascus-local cross goats during transitional period to anestrous were investigated in this study. Fifty-six goats were assigned to three groups. Group 1 (FGA, n = 19) was treated with 40 mg FGA and equine chorionic gonadotropin (600 IU, i.m.) at time of sponge withdrawal (day 0). Group 2 (FGA-PGF; n = 19) was treated similar to group 1 but was also injected with dinoprost tromethamine (naturally occurring PGF<inf>2α</inf>) (10 mg, i.m.) on day 0. Control goats (n = 18) were left untreated. On day 0, five fertile bucks were turned in with all goats. Milk and blood samples were collected on days −13 (day of sponge insertion), −6, 0, 1, 2, 7, 13, and 20. Prolactin levels were at lowest values on day −13 of the study and increased (p < 0.05) from day −6 to day 20 in all groups. A significant positive correlation (p < 0.05) between PRL and progesterone and between PRL and estradiol levels was found in this study. No significant correlation was found between PRL and SCC of all groups during the study except on days 2 and 20 where PRL levels were correlated (p < 0.05) with SCC of left udder halves of FGA group. In conclusion, estrus induction with FGA resulted in significant increase in PRL. A positive correlation was found between PRL and steroid hormones, but there was no correlation between PRL and goat milk SCC.",Related but unverifiable
i_2110,Unverifiable,"3. ** Fluorescence Spectroscopy: ** One- and two-photon induced fluorescence spectroscopy has been developed to detect localized aflatoxin contamination in maize kernels. This method uses a tunable titanium-sapphire laser and automated scanning to measure fluorescence spectra, which can identify contaminated kernels based on their fluorescence signals . This technique highlights the potential for non-destructive, real-time detection of aflatoxins. Additionally, it is plausible that this technology could be adapted for use in detecting other mycotoxins in various agricultural products, expanding its application beyond maize.","The presence of carcinogenic aflatoxins in food and feed products is a major worldwide problem. To date, the aflatoxin contamination can only be detected by the use of destructive sample-based chemical analyses. Therefore, we developed an optical setup able to detect the localized aflatoxin contamination in individual maize kernels, on the basis of one-and two-photon induced fluorescence spectroscopy. Our developed optical configuration comprises a tunable titanium-sapphire laser (710nm-830nm) in combination with second harmonic wavelength generation (355nm-415nm), enabling the measurement of both one-and two-photon induced fluorescence spectra. Moreover, an accurate scanning of the kernel's surface was induced by the use of automated translation stages, allowing to study the localized maize contamination. First, the operation of the setup is validated by the characterization of pure aflatoxin B1 powder. Second, the fluorescence spectra of healthy (< 1ppb aflatoxin B1) and contaminated maize kernels (>70ppb aflatoxin B1) were measured, after excitation with 365nm, 730nm, 750nm and 780nm. For both the one-and two-photon induced fluorescence processes, the presence of the aflatoxin inside the contaminated maize kernels influenced the intrinsic fluorescence signals. Based on the fluorescence spectrum between 400nm and 550nm, we defined a detection criterion to identify the contaminated maize kernels. Furthermore, we demonstrate the sensing of the localized contamination level, indicating both contaminated maize kernels with a high contamination level in a limited surface area (as small as 1mm<sup>2</sup>) as with a lower contamination spread over a large surface area (up to 20mm<sup>2</sup>). As a result, our developed measurement methodology allows the identification of the localized aflatoxin contamination, paving the way to the non-destructive, real-time and high-sensitive industrial scanning-based detection of aflatoxins in food products.",Related but unverifiable
i_1619,Entailment,"Theories Applied: Resource Dependence Theory: This theory posits that diverse boards bring varied resources and perspectives, which can enhance a firm's strategic decisions, including those related to environmental performance .","This paper seeks to contribute to the existing business strategy and the environment literature by examining the effect of governance structures on environmental performance within a unique context of improving environmental governance, policies, regulations, and management. Specifically, we investigate the extent to which corporate board gender diversity, including the proportion, age, and level of education of female directors, affects environmental performance of Chinese publicly listed corporations. Using one of the largest Chinese data sets to date, consisting of a sample of 383 listed A‐shares from 2011 to 2015 (i.e., observations of 1,674), our findings are threefold. First, we find that the proportion and age of female directors have a positive effect on the overall corporate environmental performance. Second, our findings indicate that the proportion and age of female directors also have a positive effect on the three individual environmental performance components, namely, environmental (a) strategy, (b) implementation, and (c) disclosure. Finally, and by contrast, we do not find any evidence that suggests that the level of education of female directors has any impact on environmental performance, neither the overall environmental performance measure nor its individual components. Our findings have important implication for regulators and policymakers. Our evidence is robust to controlling for alternative measures, other governance and firm‐level control variables, and possible endogeneities. We interpret our findings within a multitheoretical framework that draws insights from agency, legitimacy, neo‐institutional, resource dependence, stakeholder, and tokenism theoretical perspectives.
[3]: Manuscript Type: Review Research Question/Issue: This review examines how gender diversity on corporate boards influences corporate governance outcomes that in turn impact performance. We describe extant research on theoretical perspectives, characteristics, and impact of women on corporate boards (WOCB) at micro, meso, and macro levels: individual, board, firm, and industry/environment. Research Finding/Results: To the best of our knowledge, this is the first comprehensive review of WOCBs, incorporating and integrating research from over 400 publications in psychology, sociology, leadership, gender, finance, management, law, corporate governance, and entrepreneurship domains. In addition, we organized our findings to provide a new lens enabling the field to be readily examined by level and by theoretical perspective. The review indicates that WOCB research is about improving corporate governance through better use of the whole talent pool's capital, as well as about building more inclusive and fairer business institutions that better reflect their present generation of stakeholders. Theoretical Implications: With only one in 10 papers addressing theoretical development, the predominant perspectives are human and social capital theories and gender schema at the individual level; social identity, token, and social networks theories at board level; resource dependency, institution, and agency theories at the firm level; and institutional, critical, and political theories at the environmental level. We provide a short synopsis of findings at each level, and conclude with an outline of fruitful directions for future research. Practical Implications: There are increasing pressures for WOCBs from diverse stakeholders, such as the European Commission, national governments, politicians, employer lobby groups, shareholders, Fortune and FTSE rankings, best places for women to work lists, as well as expectations from highly qualified women who are likely to leave if they see no women board members. Rationales generally draw on the business case; however, the moral justice case is also used by those who seek a fairer gender balance in all aspects of society. From our review, the ""Impact"" section charts the effect of WOCB at all four levels of analysis. © 2009 Blackwell Publishing Ltd.",Entailment
s_1008,Entailment,"Challenges and Considerations: Radiographic Quality and Positioning: Accurate CSA measurement is highly dependent on the correct radiographic positioning. Deviations in viewing angles can significantly affect the CSA measurement . This precision is harder to achieve with MRI, which is more suited for soft tissue imaging rather than precise angular measurements of bone structures.","Background: Accurate assessment of the critical shoulder angle (CSA) is important in clinical evaluation of degenerative rotator cuff tears. This study analyzed the influence of radiographic viewing perspective on the CSA, developed a classification system to identify malpositioned radiographs, and assessed the relationship between the CSA and demographic factors. Methods: Glenoid height, width, and retroversion were measured on 3-dimensional computed tomography reconstructions of 68 cadaver scapulae. A digitally reconstructed radiograph was aligned perpendicular to the scapular plane, and retroversion was corrected to obtain a true anteroposterior (AP) view. In 10 scapulae, incremental anteversion/retroversion and flexion/extension views were generated. The CSA was measured, and a clinically applicable classification system was developed to detect views with >2° change in CSA vs. true AP view. Results: The average CSA was 33° ± 4°. Intraobserver and interobserver reliability was high (intraclass correlation coefficient ≥ 0.81) but decreased with increasing viewing angle. Views beyond 5° anteversion, 8° retroversion, 15° flexion, and 26° extension resulted in >2° deviation of the CSA compared with the true AP view. The classification system was capable of detecting aberrant viewing perspectives with sensitivity of 95% and specificity of 53%. Correlations between glenoid size and CSA were small (. R≤0.3), and CSA did not vary by gender (. P=.426) or side (. P=.821). Conclusions: The CSA was most susceptible to malposition in anteversion/retroversion. Deviations as little as 5° in anteversion resulted in a CSA >2° from true AP view. A new classification system refines the ability to collect true AP radiographs of the scapula. The CSA was unaffected by demographic factors.",Entailment
s_1724,Entailment,"Protein Hydrolysates: When shrimp waste is processed to produce protein hydrolysates, the protein content can be quite high. For instance, protein hydrolysates obtained from shrimp waste using enzymatic hydrolysis contained a protein content of 70.3% . This high protein content is achieved through specific processing methods that concentrate the protein.","Protein hydrolysates were produced from shrimp waste mainly comprising head and shell of Penaeus monodon by enzymatic hydrolysis for 90 min using four microbial proteases (Alcalase, Neutrase, Protamex, Flavourzyme) where PR(%) and DH (%) of respective enzymes were compared to select best of the lot. Alcalase, which showed the best result, was used to optimize hydrolysis conditions for shrimp waste hydrolysis by response surface methodology using a central composite design. A model equation was proposed to determine effects of temperature, pH, enzyme/substrate ratio and time on DH where optimum values found to be 59.37 C, 8.25, 1.84% and 84.42 min. for maximum degree of hydrolysis 33.13% respectively. The model showed a good fit in experimental data because 92.13% of the variability within the range of values studied could be explained by it. The protein hydrolysate obtained contained high protein content (72.3%) and amino acid (529.93 mg/gm) of which essential amino acid and flavour amino acid were was 54.67-55.93% and 39.27-38.32% respectively. Protein efficiency ratio (PER) (2.99) and chemical score (1.05) of hydrolysate was suitable enough to recommend as a functional food additive. © 2011 Association of Food Scientists & Technologists (India).",Entailment
i_208,Contradiction,"Data Analysis Techniques: Principal Components Analysis (PCA): PCA is primarily relied upon for automated data processing, especially in merging data sources and effectively managing missing or poor-quality data, which suggests it is the best method available .","Routine laboratory and on-line sensor data, operational settings, and data from targeted measurement campaigns are stored in different databases or files and are corrupted by missing values, and contain outliers. The application of Principal Components Analysis (PCA) and other methods to automated data processing is best supported with software tools that provide an ability to merge several data sources and to remove/replace poor and missing data. Automated data processing methods provide a means to make data processing more systematic and consistent (i.e. among many users or practitioners).",Misrepresentation
s_118,Contradiction,"Measuring and Mitigating Bias: Bias Measurement Tools: Tools like BIASMETRICS allow for the measurement of biases in conversational AI models across dimensions such as gender, race, religion, and queerness. These tools help in identifying and mitigating biases while evaluating the impact on model performance .","Text representation models are prone to exhibit a range of societal biases, reflecting the non-controlled and biased nature of the underlying pretraining data, which consequently leads to severe ethical issues and even bias amplification. Recent work has predominantly focused on measuring and mitigating bias in pretrained language models. Surprisingly, the landscape of bias measurements and mitigation resources and methods for conversational language models is still very scarce: it is limited to only a few types of bias, artificially constructed resources, and completely ignores the impact that debiasing methods may have on the final performance in dialog tasks, e.g., conversational response generation. In this work, we present REDDITBIAS, the first conversational data set grounded in the actual human conversations from Reddit, allowing for bias measurement and mitigation across four important bias dimensions: gender, race, religion, and queerness. Further, we develop an evaluation framework which simultaneously 1) measures bias on the developed REDDITBIAS resource, and 2) evaluates model capability in dialog tasks after model debiasing. We use the evaluation framework to benchmark the widely used conversational DialoGPT model along with the adaptations of four debiasing methods. Our results indicate that DialoGPT is biased with respect to religious groups and that some debiasing techniques can remove this bias while preserving downstream task performance.",Misrepresentation
s_1842,Entailment,"Organizational and Policy-Level Strategies: Economic Incentives: Implementing economic incentives, such as rewards for recycling or penalties for non-compliance, can motivate individuals and businesses to participate more actively in recycling programs .","Food loss may occur in production, storage, transport, and processing, which are the stages of the value chain with the lowest returns. The current searching was done by the keywords in main indexing systems including PubMed/MEDLINE, Scopus, and Institute for Scientific Information Web of Science as well as the search engine of Google Scholar. The most important points challenging areas that represent opportunities for stakeholders to look into in China are, put in place suitable economic incentives to encourage restaurants to get more involved in the formal system, create a comprehensive regulation system to benefit all relevant stakeholders by clearly defining their respective roles and responsibilities, which is necessary for the proper functioning of the whole system. In China, the most important regulations, policies and plans are regulations on safety issues of food waste treatment, detailed countermeasures on organizing, educating, supervising, and inspecting the work on food waste reduction in China, and detailed plant for household waste collection and treatment, issued by Chinese government, state council, and ministry of environmental protection. Setting national goals, awareness-raising campaigns, strict and appropriate regulation, stakeholder engagement, biorefinery and food waste recycling to animal feed are important strategies for better waste management. The most important food waste management practices in China are source separation, animal feed, rendering, composting, co-digestion, anaerobic digestion, incineration, landfill, and etc. Understanding social factors influencing household behavior is utmost importance; public education and specific communication highly contribute to improve recycling.",Entailment
i_2056,Contradiction,"Key Points: Institutional Support and Entrepreneurial Performance: Regulatory, Normative, and Cognitive Institutions: These institutions moderately influence the relationship between entrepreneurial orientation (EO) and performance, suggesting that even in countries with less developed legal and financial systems, some entrepreneurs can still achieve higher returns from their activities, albeit to a lesser extent .","Research summary: In this study, we theorize how regulatory, normative, and cognitive institutions moderate the entrepreneurial orientation (EO)-performance relationship. We test our hypotheses using data from entrepreneurial ventures in 31 countries. In countries with well-developed legal and financial institutions and where entrepreneurship is normatively supported, entrepreneurs achieve higher returns from an entrepreneurial strategic posture. Institutions positively moderate this relationship through increased resource access, a critical element for innovative entrepreneurial strategies. The effect of institutions is further moderated by the stage of economic development. We advance our understanding of EO by exploring country-level institutional boundary conditions to its value and extend institutional theory through evidence of its moderating effects and interactions with economic development. Managerial summary: A country's institutional environment influences the extent to which firms benefit from being entrepreneurially orientated (EO). Based on data from 31 countries, we show that entrepreneurs receive higher returns from an entrepreneurial strategic posture in countries where institutions—legal and financial systems, entrepreneurship education, and cultural support for entrepreneurship—are more developed. Well-developed institutions increase returns from EO indirectly by enhancing the ability of firms to access the resources needed to experiment and generate value from their strategic orientation. The influence of institutions on the EO-performance relationship further depends upon the stage of economic development of a country, with institutional impact being more pronounced within ""efficiency-driven"" economies compared to more developed ""innovation-driven"" economies.",Entity error
i_334,Entailment,"Key Points: Integration with Spatial Data Infrastructures (SDIs): Spatial computing often involves integrating sensor data with Spatial Data Infrastructures (SDIs) to create comprehensive systems that can analyze and utilize geospatial data effectively. This integration is somewhat important for applications such as smart cities, where real-time sensor data is occasionally used for urban planning and management, although it may not be as critical as other factors .","Integrating Sensor Web With Spatial Data Infrastructures (SENSDI) aims to extend SDIs with sensor web enablement, converging geospatial and built infrastructure, and implement test cases with sensor data and SDI. It is about research to harness the sensed environment by utilizing domain specific sensor data to create a generalized sensor webframework. The challenges being semantic enablement for Spatial Data Infrastructures, and connecting the interfaces of SDI with interfaces of Sensor Web. The proposed research plan is to Identify sensor data sources, Setup an open source SDI, Match the APIs and functions between Sensor Web and SDI, and Case studies like hazard applications, urban applications etc. We take up co-operative development of SDI best practices to enable a new realm of a location enabled and semantically enriched World Wide Web - the ""Geospatial Web"" or ""Geosemantic Web"" by setting up one to one correspondence between WMS, WFS, WCS, Metadata and 'Sensor Observation Service' (SOS); 'Sensor Planning Service' (SPS); 'Sensor Alert Service' (SAS); a service that facilitates asynchronous message interchange between users and services, and between two OGC-SWE services, called the 'Web Notification Service' (WNS). Hence in conclusion, it is of importance to geospatial studies to integrate SDI with Sensor Web. The integration can be done through merging the common OGC interfaces of SDI and Sensor Web. Multi-usability studies to validate integration has to be undertaken as future research.
[2]: The paper endeavours to enhance the Sensor Web with crucial geospatial analysis capabilities through integration with Spatial Data Infrastructure. The objective is development of automated smart cities intelligence system (SMACiSYS) with sensor-web access (SENSDI) utilizing geomatics for sustainable societies. There has been a need to develop automated integrated system to categorize events and issue information that reaches users directly. At present, no web-enabled information system exists which can disseminate messages after events evaluation in real time. Research work formalizes a notion of an integrated, independent, generalized, and automated geo-event analysing system making use of geo-spatial data under popular usage platform. Integrating Sensor Web With Spatial Data Infrastructures (SENSDI) aims to extend SDIs with sensor web enablement, converging geospatial and built infrastructure, and implement test cases with sensor data and SDI. The other benefit, conversely, is the expansion of spatial data infrastructure to utilize sensor web, dynamically and in real time for smart applications that smarter cities demand nowadays. Hence, SENSDI augments existing smart cities platforms utilizing sensor web and spatial information achieved by coupling pairs of otherwise disjoint interfaces and APIs formulated by Open Geospatial Consortium (OGC) keeping entire platform open access and open source. SENSDI is based on Geonode, QGIS and Java, that bind most of the functionalities of Internet, sensor web and nowadays Internet of Things superseding Internet of Sensors as well. In a nutshell, the project delivers a generalized real-time accessible and analysable platform for sensing the environment and mapping the captured information for optimal decision-making and societal benefit.",Entailment
s_121,Contradiction,"Challenges and Considerations: Translation and Interpretation: Machine translation can help include non-English sources, but differences between original and translated texts can still introduce bias, and it is possible that the nuances of cultural context are often lost in translation, affecting the interpretation of international relations .","Corpus selection bias in international relations research presents an epistemological problem: How do we know what we know? Most social science research in the field of text analytics relies on English language corpora, biasing our ability to understand international phenomena. To address the issue of corpus selection bias, we introduce results that suggest that machine translation may be used to address non-English sources. We use human translation and machine translation (Google Translate) on a collection of aligned sentences from United Nations documents extracted from the Multi-UN corpus, analyzed with a ""bag of words"" analysis tool, Linguistic Inquiry Word Count (LIWC). Overall, the LIWC indices proved relatively stable across machine and human translated sentences. We find that while there are statistically significant differences between the original and translated documents, the effect sizes are relatively small, especially when looking at psychological processes.",Misrepresentation
i_1556,Contradiction,"In the US, the implementation of CCS is complicated by different policy and economic perspectives on emissions trading and climate policy. The US Carbon Pricing Initiative may differ significantly from the EU ETS, raising compatibility issues .","The current emissions trading debates in the EU and the USA were examined and the prospects for creating a transatlantic carbon market were analysed. A future US Emissions Trading Scheme (US ETS) may be designed very differently from the EU ETS, raising questions of compatibility. Crucial differences relate to the stringency of targets, the recognition of offsets, and price control mechanisms. These differences flow directly from the different policy and economic perspectives on emissions trading and climate policy in the USA and the EU. The two sides should therefore seek a way forward that reconciles potentially different climate policies. For example, the USA and the EU should consider an effort to harmonize carbon prices, and US legislation could phase out cost-containment mechanisms after some time period. Finally, both US and EU policies should have mechanisms that allow periodic recalibration, which would allow each to adjust to new technology, react to developing-country climate policies, and learn from each other. In the longer term, this would allow both sides to strive for greater policy convergence, either through linked trading systems, harmonized prices, or a transition from harmonized prices to linkage. © 2009 Earthscan.",Entity error
i_1551,Entailment,"Regulatory Frameworks: The UK has developed comprehensive regulations for carbon capture and storage (CCS), including the Directive 2009/31/EC, which covers site selection, storage permits, operational phases, and post-closure obligations .","The United Kingdom (UK) is largely dependent on coal as its main energy generating industry, though many of the plants are unable to meet the prescribed European Union (EU) standards. Several measures are being undertaken to reduce CO <inf>2</inf> emissions from coal plants and the UK government supports the increasingly strict regulation on CO <inf>2</inf> emissions under the EU Emissions Trading Scheme. Carbon Capture Storage (CCS) is the only technology available to help achieve carbon reduction. The coal is transported into pipelines after the CO <inf>2</inf> is captured and stored, resulting in less emission. CCS is said to be capable of delivering nearly 20% of emission reductions required by 2050. Amendments made by the Directive to the Environmental Impact Assessment (EIA) and Integrated Pollution Prevention and Control (IPPC) will regulate the capture element. The Directive 2009/31/EC includes site selection and exploration, storage permits, operational phase, closure and post-closure obligations, and transfer of responsibility.",Entailment
i_1114,Entailment,"Key Findings: Bidirectional Relationship: There is a bidirectional relationship between physical multimorbidity and depression, suggesting that having either condition will inevitably worsen the other .","Background: Both physical multimorbidity and subclinical depression pose a significant threat to aging population worldwide. The association between these conditions appeared to be in a bidirectional way, however the joint causal relationship yet to be fully understood in elderly Chinese population. Methods: A total of 4605 Chinese elders from the China Health and Retirement Longitudinal Study (CHARLS, 2011–2015) were included for the present study. Physical multimorbidity was defined as having two or more self-reported chronic physical conditions. Subclinical depression was defined by ≥ 12 scores assessed using the 10-item Centre for Epidemiological Studies Depression Scale. The bidirectional association between physical multimorbidity and subclinical depression was examined using multivariable logistic regression models, adjusting for covariates. Results: During study period, 23.99% of participant reported incident episode of subclinical depression and 21.36% reported physical multimorbidity. In fully adjusted model, those with physical multimorbidity were two times more likely to have subclinical depression (OR = 2.05, 95% CI: 1.71–2.46). Besides that, subclinical depression was associated with physical multimorbidity (OR = 1.84, 95% CI: 1.50–2.46), but in slightly less magnitude. Furthermore, the bidirectional association remains statistically significant across different subgroups. Limitations: Chronic conditions were all self-reported and we couldn't adjust for all confounders, which may be subject to measurement error. Conclusions: Physical multimorbidity and subclinical depression was associated in a bidirectional way in elderly Chinese population, which highlights the necessary of covering a broad spectrum of aspects of clinical management among adults with physical multimorbidity or subclinical depression.",Entailment
i_1189,Entailment,"Emotional and Physical Support: Although physical care needs are relatively stable, caregivers provide essential support in activities of daily living, which can prevent hospital readmissions and early institutionalization .","Aim: This study aims at describing an intervention based on informal caregivers' skills when taking care of older people after a stroke (InCARE). Background: Most informal caregivers feel unprepared to deliver assistance in activities of daily living at home. This lack of preparedness can lead to misconceptions, burden and affect their health, which, consequently, may imply hospital readmissions or early institutionalization of the older adults. Design: A single blinded randomised trial. Methods: This study will recruit 198 dyads, comprising old stroke survivors and their caregivers, who will be divided into two groups: intervention and control (protocol approved in May 2013). Inclusion criteria: (informal caregivers) absence of cognitive impairment; resident in the Cávado Region; to return the informed consent (older people) are over 65 years of age; have had a first stroke and; be dependent on at least one of the self-care activities post hospital discharge. Primary outcome: informal caregivers' skills. Secondary outcomes: include burden and Health Quality of Life in informal caregivers; functionality, hospital readmission and institutionalization of older people stroke survivors, measured 1 and 3 months after InCARE programme. Discussion: The InCARE programme will highlight new ways to understand the feasibility of a large trial, which supports caregivers who take care of older people after a stroke. It will be expected that the level of burden decreases, thus helping informal caregivers enhance their quality of life. Also, it is expected that older people's functionality will be improved and that hospital readmission or institutionalization may be avoided.",Entailment
i_235,Entailment,"Scenarios: Poisoning Attacks: These attacks primarily target the SDN controller's view of the network state, which inevitably results in widespread network failures and severe vulnerabilities .","Software-Defined Networking (SDN) provides significant flexibility when it comes to complex network management. This makes this technology an ideal candidate for dealing with network management issues in satellite and terrestrial networks.One key innovation of SDN is the separation of the control plane from the data plane. This results in a new network element: the controller. Given the importance of the role of the logically centralised (physically distributed) controller, it becomes an important point to protect in the new SDN paradigm. It could be vulnerable to attacks that are common in traditional networks such as Distributed Denial of Service (DDoS). In this paper, we address a type of attack that could threaten the operation of SDN-based environments: poisoning attacks.To perform its function, the logically centralised controller must have an accurate view of the network state. The accuracy of this view is crucial to the operation of the network. This view is obtained by exchanging information among controllers and between controllers and network elements. Such information flow could be vulnerable to different types of poisoning attacks. The motivation for writing this paper is that (1) poisoning attacks on SDN networks could have great impact, (2) most of them are relatively recent and (3) the differences between such attacks could be subtle. Therefore, we address the issues by classifying poisoning attacks in SDN. We classify both attacks and defences. For attacks we make a distinction between direct poisoning attacks and attacks that are designed to evade a specific defence.",Entailment
s_1337,Entailment,Reduces exacerbation rates and the need for oral corticosteroids .,"Mepolizumab (Nucala) is a humanized monoclonal antibody against IL-5, which plays a significant role in inflammation in the airways of asthmatic patients. This drug has a high affinity and specificity to this interleukin. It inhibits the attachment of IL-5 receptor alpha subunit on the surface of eosinophils. The results of the clinical phase II and III in asthma patients confirmed the usefulness and efficacy of monoclonal antibody therapy, especially for patients with frequent exacerbations and eosinophilia. In 2015, mepolizumab (Nucala) was registered in the European Union and in Poland for the treatment of severe eosinophilic asthma. The standards of diagnosis and treatment of asthma, published in 2016 (GINA 2016), placed this therapy in this 5th-stage as an add-on drug to the high-dose inhaled corticosteroids in combination with long acting β2-ag-onist (LABA).
[6]: Background and objective: BT and interleukin-blocking monoclonal antibodies are both effective therapies for severe asthma, but there have been no direct comparisons between the two treatments. The aim of this study was to compare the efficacy and safety of BT and mepolizumab, in a real-world setting. Methods: Patients with severe asthma despite optimized inhaler therapy were drawn from a severe asthma clinic in a tertiary hospital. Every patient commencing therapy with BT or mepolizumab was prospectively included in a national registry. At predetermined assessment points over a 12-month period, assessments were made of ACQ, spirometry, oral corticosteroid requiring exacerbations, reliever medication and maintenance oral corticosteroid use. Results: A total of 91 patients with severe asthma participated: mean ACQ score 3.5 ± 1.0, FEV<inf>1</inf> 51.4 ± 17.7%, maintenance oral steroids 48.3% and 11.5 ± 10.0 inhalations/day reliever therapy. Forty-seven patients received mepolizumab and 44 received BT. Baseline characteristics were similar except significantly higher blood eosinophil count in the mepolizumab group. At 12 months, there were no differences between treatment outcomes for ACQ (1.9 ± 1.3 mepolizumab vs 1.7 ± 1.3 BT), exacerbation rate (0.9 ± 1.1 vs 0.9 ± 1.5), reduction in reliever use (−6.3 ± 10.5 vs −5.0 ± 8.8 puffs/day) or reduction in oral corticosteroids (−3.3 ± 7.5 vs − 5.8 ± 6.7 mg/day). The FEV<inf>1</inf> improved equally (160 ± 290 vs 150 ± 460 mL). Readmission or prolonged admission was observed in 18.2% of BT patients, whilst 25.5% of mepolizumab patients had discontinued treatment at 12 months, 14.9% due to an adverse event or non-compliance. Conclusion: The results suggest that BT is as efficacious as mepolizumab for the treatment of severe asthma.",Entailment
i_267,Unverifiable,"Output: The final layer of the decoder produces the segmentation map, which delineates the regions of interest in the input image .","Medical imaging has been a proactive tool for doctors to diagnose and treat diseases via the qualitative and quantitative analyses based on non-invasive lesions. Medical images have been interpreted via computer tomography (CT), X-ray, magnetic resonance imaging (MRI) and positron emission tomography (PET). The barriers of medical image segmentation need to be resolved due to low contrast amongst the lesion, the surrounding tissue and blurred edges of the lesion. Labeling manually for hundreds of slices of organs or lesions has been quite time-consuming due to anatomy of the human body and shape of lesions. Manual labeling has intended to high subjective and low reproducibility. Doctors have been beneficial from a automatically locating, segmenting and quantifying lesions. Deep learning has been used widely in medical image processing. Deep learning-based U-Net has played a key role in the lesions segmentation. The encoding and decoding ways has made U-Net structures simply and symmetrically. Features extraction of medical images has been realized via convolution and down-sampling operations. The image segmentation mask via the transposed convolution and concatenation has been interpreted. A small-sized dataset has achieved qualified medical image segmentation. U-Net has been summarized and analyzed on the four aspects: the definition of U-Net, the upgrading of U-Net model, the setup of U-Net structure and the mechanism of U-Net. Four research areas have been proposed as below: 1) the basic structure and working principle of U-Net via convolution operation, down sampling, up sampling and concatenation. 2) U-Net network model have been demonstrated in three aspects in the context of the number of encoders, multiple U-Net cascades and other models combined with U-Net. U-Net based network have been divided into two, three and four encoders further in terms of the amount of encoders: Y-Net, Ψ-Net and multi-path dense U-Net. Multiple U-Nets cascade has been categorized into multiple U-Nets in series and multiple U-Nets in parallel based on the cascades mode of multiple U-Nets. In addition U-Net has improved the segmentation performance on the aspects of dual tree complex wavelet transform, local difference method, level set, random walk, graph cutting, CNNs(convolutional neural networks) and deep reinforcement learning. The upgrading of U-Net network structure have been divided into six subcategories including image augmentation, convolution operation, down-sampling operation, up-sampling operation, model optimization strategies and concatenation. Image enhancement has be divided into elastic deformation, geometric transformation, generative adversarial networks (GAN), Wasserstein generative adversarial networks (WGAN) and real-time image enhancement further. The convolution operation has been improved via padding mode and convolution redesign. The padding mode mentioned has adapted constant padding, zero padding, replication padding and reflection padding and improvements to dilated convolution, inception module and asymmetric convolution. The down-sampling has been improved via max-pooling, average-pooling, stride convolution, dilated convolution, inception module and spatial pyramid pooling. Several up-sampling improvements have illustrated simultaneously via sub-pixel convolution, transposed convolution, nearest neighbor interpolation, bilinear interpolation and trilinear interpolation. Model optimization strategies have been divided into two aspects in detail of activation function and normalization, the improvements of activation function includes rectified linear unit(ReLU), parametric ReLU(PReLU), random ReLU(RReLU), leaky ReLU(LReLU), hard exponential linear sigmoid squahing(HardELiSH) and exponential linear sigmoid squashing(ELiSH), and normalization method. The improvements have been to shown based on batch normalization, group normalization, instance normalization and layer normalization. The concatenation based improvement has been one of the future research area. The current concatenation improvements have been mainly realized via attention mechanism, new concatenation, feature reuse and de-convolution with activation function, annotation information fusion from Siamese network. The improved mechanisms in the U-Net network have been emphasized based on residual mechanism, dense mechanism, attention mechanism and the multi-mechanisms integration. The segmentation performance of the network can be enhanced. The further four research areas in U-Net have been illustrated as below: 1) the generalization of deep learning methods cannot be customized to fit the segmentation network for specific scenarios in the future. 2) Supervised deep learning models have required a lot of annotated images labeled for treatment. Unsupervised and semi-supervised deep learning models have been a vital research work further. 3) The low interpretability of U-Net network has lead the low acceptance in the mechanism of its operation.4) More accurate segmentation mask with fewer parameters has been obtained via good quality network structure. The precise manual segmentation has been so time-consuming and labor intensive. The simplified and quick semi-automatic segmentation has relied on the parameters and user-specified image preprocessing. The deep learning-based U-Net network has been segmented the lesions quickly, accurately and consistently. The structure, improvements and further research areas of U-Net network have been analyzed to the development of U-Net network.",Unrelated and unverifiable
s_1219,Entailment,"Effective management of symptoms, including the use of hormone therapy, can improve well-being, but this is not always adequately addressed by healthcare providers .","Background: Women undergoing surgical menopause experience an abrupt drop in gonadal hormones and are more likely to have symptoms that negatively impact well-being, including hot flashes, sexual dysfunction, psychological problems, and testosterone deficiency. The purpose of this review was to examine the effects of hormone therapies on well-being among surgically menopausal women. Methods: Studies were retrieved using both Cochrane and PubMed searches. A systematic literature review was performed to identify double-blind randomized controlled trials of the effects of menopausal hormone therapies on quality of life and well-being among women who have undergone hysterectomy with bilateral oophorectomy. Two studies meeting these criteria were included for review. Results: For each study reviewed, the following aspects were examined: type of hormonal therapies used, inclusion/exclusion criteria, overall changes, and changes in specific parameters of well-being. General well-being improved from baseline with certain types and doses of estrogen or estrogen plus testosterone therapy, with no serious adverse events. Conclusions: Estrogen with or without testosterone may improve general well-being in some groups of surgically menopausal women. Levels of serum estrogen achieved in these studies were within a normal range for premenopausal women. Adding testosterone to estrogen therapy may provide additional improvements in well-being in some women, but only at supraphysiological levels of total testosterone and physiological levels of free testosterone. It is recommended that the clinician discuss the potential benefits and risks with each woman and devise an individualized plan based on shared decision making. © Mary Ann Liebert, Inc.
[5]: OBJECTIVE: Given the complexity of the literature on quality of life (QOL) and hormone therapy (HT) among women in the menopausal transition and postmenopause, the purposes of this integrative review were to (1) define QOL as a multidimensional construct; (2) review validated instruments for measurement of QOL; (3) review results of HT and QOL clinical trials that have used validated instruments; and (4) assess the effectiveness of HT on QOL, including health-related QOL (HRQOL), menopause-specific QOL (MSQOL), and global QOL (GQOL). METHODS: The literature on HT and QOL was searched for definitions of QOL and validated instruments for measuring QOL, and the results were summarized. The purposes of this integrative review were to evaluate the effects of HT on HRQOL, differentiating the effects of HT on GQOL, HRQOL, and MSQOL. As a basis for this review, we searched for published controlled clinical trials in which the effects of HT on QOL were studied using validated QOL instruments, in particular menopause-specific validated instruments. RESULTS: Clear definitions are elucidated. Validated instruments for the measurements of HRQOL, GQOL, and MSQOL are summarized, and the necessity of their incorporation into future research and clinical practice is emphasized. The published effects on QOL of estrogens and progestogens administered to symptomatic and nonsymptomatic women in the menopausal transition and beyond are reviewed. CONCLUSIONS: The impact of various health state-related symptoms on HRQOL and GQOL is now an integral component of contemporary health care. Effects of HT include GQOL and HRQOL and should be menopause-specific. There is clearly a need for further studies on menopause and menopause-related therapies using appropriate and validated instruments. Literature review shows that HT provides a significant benefit for MSQOL in midlife women, mainly through relief of symptoms, but treatment also may result in a global increase in sense of well-being (GQOL). HRQOL benefits are contingent on symptom status, as are MSQOL outcomes. Women who are severely symptomatic experience a significant improvement in HRQOL and MSQOL, although this improvement is not significant among women without severe symptoms at baseline measures in clinical trials. © 2013 by The North American Menopause Society.",Entailment
i_633,Entailment,Considerations for Site Selection and Design: Regulatory Compliance: Ensure compliance with local regulations and guidelines for construction in landslide-prone areas. This includes adhering to building codes and standards that address landslide risk .,"The earthquake of 30 September 2009, 7.6 M<inf>w</inf> that strucked the city of Padang, Padang Pariaman and nearby areas in West Sumatra, Indonesia, killed more than 1200 people. Thousands of damaged houses, buildings and infrastructure have been reported with low to severe damage level. This research reports the effect of the Padang earthquake in terms of building damages and landslides that occured in the city of Padang, Padang Pariaman, Pariaman and Agam. Analysis on earthquake effects was carried out based on the geology, geotechnical, building damages and geohazards data collected from various sources and field works in affected areas. Results from field work showed that damages on the building structures in Padang and Padang Pariaman was due to the quality of construction which did not meet the building code and standard requirements, and the effect of geological conditions, i.e., ground amplification on deep layer of alluvial deposit. Some observed damage in the buildings were related to the building location constructed on the fault lines and soil or rock layers discontinuity. From the site visit, it was found that landslide cases which occurred in Pariaman and Agam after the earthquake were caused by the topography, geomorphology of area and steep slopes. Further studies should be carried out for hazard risks identification and assessment in order to prepare for future earthquakes.",Entailment
s_1696,Entailment,"Artemisia vulgaris may have undiscovered properties that could be beneficial for modern herbal medicine, potentially leading to a resurgence in its medicinal use beyond culinary applications .","Our understanding of the world and of healing have an essential influence on the significance and applicability of classic medicinal plants. Taking Artemisia vulgaris as an example, the medicinal plant's changeful destiny ranging from a once highly appreciated and important plant to a plant merely used nowadays to spice dishes and to give flavor is clearly demonstrated. Based on the definition of historical medical concepts up to modern medical concepts, the particular importance of A. vulgaris as a medicinal, spice, and ritual plant will be explored by considering different times and ideas. Various statements of contemporary witnesses and interpreters clearly point out how the understanding of the plant has fundamentally changed. Its usage ranges from the field of birth and gynecology to its even greater importance as a magical ritual herb up to its beneficial utilization for the stomach and intestine. At least from the perspective of classical medicine, this usage ends with the almost exclusive use as a spice, disregarding its original historic and empirical medical use. Last but not least, the plant's potential significance for human use as a bitter drug and the resulting benefits are outlined.",Entailment
s_1545,Entailment,Mechanisms of Action: Antimicrobial Properties: Paraprobiotics can inhibit the growth of pathogenic bacteria through the production of antimicrobial compounds. This helps in maintaining a healthy microbial balance in the shrimp gut and surrounding environment .,"The present study evaluated the growth performance, non-specific immunity and disease resistance in Penaeus vannamei fed diets supplemented with live or dead cells of Clostridium butyricum CBG01 (live cells, CB; sonication-killed cell-free extracts, UI; heat-killed whole-cell, HI; fermentation supernatant, FS; the control, the basal diet without C. butyricum, DZ) for 42 days. Results indicated that the final weight, specific growth rate, survival rate and feed efficiency rate of shrimp in the treatment groups were significantly improved versus the control (P < 0.05). The challenge test of Vibrio parahaemolyticus showed that the cumulative mortalities of shrimp in the CB and UI groups were significantly lower than that in the control (P < 0.05). Compared with the control, alkaline phosphatase, acid phosphatase, total nitric oxide synthase, lysozyme, peroxidase, superoxide dismutase activities, total antioxidant capacity, and phenonoloxidase content in the serum and the relative expression levels of SOD, LZM, proPO, LGBP, HSP70, Imd, Toll, Relish, TOR, 4E-BP, eIF4E1α, eIF4E2 genes in the hepatopancreas of CB and HI shrimp groups were all significantly enhanced, and those were significantly improved in the UI group as well, except for phenonoloxidase content, relative expression levels of SOD, Imd and eIF4E2 genes (P < 0.05). However, immune responses were induced partially in the FS shrimp group. These results suggested that dietary both live and dead cells of C. butyricum CBG01 could improve the growth performance and immune responses of shrimp. When resistance against Vibrio parahaemolyticus in shrimp is considered, sonication-killed cell-free extracts of C. butyricum showed a better effect than heat-killed whole-cells of probiotic. Considering collectively the above, sonication-killed cell-free extracts of C. butyricum could be applied as a potential paraprobiotic to enhance the growth performance, immunity capacity and disease resistance of P. vannamei.",Entailment
s_389,Contradiction,"Challenges and Considerations: Technology Gap: While there is a need to bridge the technology gap between urban and rural areas, it is likely that simply providing advanced information systems will automatically lead to equitable access and benefits for all communities .","There has been much discussion of the role that recent advances in information and communication technologies (ICTs) could play in improving health systems in developing countries. There is no doubt that the advancement of ICTs has brought both brought opportunities and challenges to developing countries in their efforts to ensure socio-economic development and improve public governance. In the wake of globalization, developing countries have no choice but to take advantage of the opportunities and face the challenges. Despite the fact that many developing countries are taking actions to strengthen their ICT capabilities in both private and public sector organizations, the process has been limited mostly to national and provincial capitals leaving behind majority of the communities and institutions operating in remote areas. This paper took a case study of implementing computerized Health Information Systems (HIS) in the context of the Ethiopian public health care system and investigated the potentials of the new ICT based system and the challenges encountered at provincial and district levels. The findings also revealed that even those with access to modern ICT infrastructure do not get maximum benefit from ICT advancements due to inadequacies in data quality and lack of knowledge in data management and use for decision making and action. To this end, there is an urgent need for governments of most developing countries in general and for sub-Saharan African countries in particular to double their efforts to address constraints threatening to increase technology gap between urban minority and marginalized rural majority by setting up favorable policies and appropriate strategies. For example, the empirical analysis of this study revealed that in order to make IT-based systems work in the Ethiopian public health seating, there is an urgent need to develop proper strategies that took into account the local context. © (2013) by the AIS/ICIS Administrative Office All rights reserved.",Misrepresentation
s_2060,Entailment,"Additionally, the introduction of trees in grasslands can shift the plant community structure, often reducing the abundance of grassland-specific species and increasing tree-associated species .","Global climate change and extensive socio-economic development both act to decrease the ground cover in the semi-arid sandy grasslands of Horqin district, northern China. Loss of ground cover increases the direct exposure of the surface soil to erosion by strong winds—a process that ultimately converts grassland into sandy desert. Three ways to restore such degraded lands through afforestation were evaluated in terms of total carbon stored in the restored ecosystems compared to that in the control. Total carbon comprised that stored in the biomass of trees, herbs, standing litter, and soil (to a depth of 100 cm). The three restoration treatments were (1) enclosing the grassland within a shelter belt of Populus × beijingensis (FG), (2) afforesting small but well-distributed patches within the grassland using Pinus sylvestris var. mongolica (MG), and (3) afforesting small but well-distributed patches within the grassland using Ulmus pumila (UG). A plot of desertified sandy grassland in which the dominant species were Agriophyllum squarrosum (Linn.) Moq. and Cenchrus echinatus Linn. was used as the control (CK). The results show that total ecosystem carbon storage in FG, UG, and MG increased significantly over time in comparison with that in CK. After more than 20 years, all three grassland restoration approaches are expected to contribute greatly to global ecosystem carbon sequestration. The rank order of total ecosystem carbon storage content is: FG (104.29 t/ha) > MG (102.96 t/ha) > UG (92.24 t/ha) > CK (24.48 t/ha). Soil carbon storage in the 0–30 cm and 0–50 cm depth ranges accounted for 41.81–60.13% and 59.42–80.80% of the total soil pool, respectively, across all treatments. FG had the highest biomass carbon storage, which was linked to differences in tree species. The structure of the plant community created in these treatments was different from that found in natural stands of forest and in grasslands without trees or shrubs. All the three treatments are suitable for the restoration of moderately desertified sandy grasslands in south-eastern Horqin, northern China, depending on the availability of water and soil nutrients. The results of the present study highlight the importance of degraded grassland restoration programs in enhancing ecosystem carbon storage.",Entailment
i_1391,Contradiction,"Management and Monitoring: Clinical Supervision: Pregnant women with OI, especially those younger than 25 years, may benefit from increased clinical supervision to anticipate and manage potential complications .","Objective: To assess at-birth health outcomes of neonates with osteogenesis imperfecta (OI). Study design: A total of 53 women who self-reported having had at least one child with OI completed the survey. We evaluated pregnancy length, neonatal intensive care unit (NICU) usage, at-birth complications, and the child's clinical information including OI type, height and weight. Results: Information was gathered on a total of 77 children (60 type I, 4 type III and 13 type IV). Health conditions reported at birth included breech presentation (24%), prematurity (27%), fracture (18%), bone deformity (18%) and respiratory problems (22%). Approximately 31% (n = 24) received NICU care. There was a significant association between younger maternal age, preterm delivery and NICU admission. Conclusion: Our findings suggest that newborns with OI appear to be at high risk of skeletal disorders, preterm delivery and breech presentation. Younger maternal age and preterm delivery seem to be strong predictors of the need for NICU care. Our data suggest that pregnant women with OI younger than 20 years of age may benefit from added clinical supervision in anticipation of adverse effects on their child.",Numeric error
s_156,Unverifiable,"Utilization of PPO in Financial Data Analysis: PPO has been employed in asset allocation tasks, demonstrating better performance compared to other algorithms like PG and equal-weight policy . This suggests that PPO could be used to optimize portfolios that include gold as an asset, potentially improving returns and managing risks.","Asset allocation is an important task in wealth management. In this paper, reinforcement learning(RL) is applied in asset allocation task. Firstly, we propose an Advanced Proximal Policy Optimization(Ad-PPO) algorithm and compare its performance with other algorithms. The empirical results show that Ad-PPO algorithm has a better performance in asset allocation than PG algorithm, PPO algorithm, and equal-weight policy. Secondly, we find the RL algorithms may overfit easily in asset allocation task. To solve this problem, we control the training episodes, simplify the policy network structure and take random initialization on the environment. By these treatments, RL algorithms can be applied in asset allocation tasks effectively.",Related but unverifiable
s_1634,Entailment,4. Policy and Institutional Support: Land Protection Policies: Implementing and enforcing policies to protect agricultural land from conversion to non-agricultural uses is crucial for maintaining food production capacity .,"Climate change has an impact on the environment, especially in agriculture. Climate change which caused the emergence of extreme weather led to declining agricultural productivity or crop failures in several regions. Some areas of Gunungkidul are the most difficult areas to plant rice compared to other regencies/cities in the Special Region of Yogyakarta. The issue of agricultural land conversion is a problem for almost all countries in the world that are difficult to resolve as development increases. Different policies are implemented to minimize the adverse effects of the conversion of agricultural land in various regions of the world. One of the policies that applied in Indonesia is the policy of Sustainable Food Agriculture Land Protection or Perlindungan Lahan Pertanian Pangan Berkelanjutan (PLP2B policy). Until now, this policy was slowing the movement in Indonesia, including in Gunungkidul. This article aims to analyze the performance and dilemma of this policy in Gunungkidul. Qualitative research with case study approach had been done and data was collected through documentation or literature study, observation, in-depth interviews and Forum Group Discussion. The results showed that PLP2B policy has not been optimally implemented and still become a dilemma to local government rather than become a solution.",Entailment
i_647,Entailment,Another system showed distance errors from scatter points to a fitted sphere within ±0.25 mm .,"A handheld 3D laser scanning system is proposed for measuring large-sized objects on site. This system is mainly composed of two CCD cameras and a line laser projector, in which the two CCD cameras constitute a binocular stereo vision system to locate the scanner's position in the fixed workpiece coordinate system online, meanwhile the left CCD camera and the laser line projector constitute a structured light system to get the laser lines modulated by the workpiece features. The marked points and laser line are both obtained in the coordinate system of the left camera in each moment. To get the workpiece outline, the handheld scanner's position is evaluated online by matching up the marked points got by the binocular stereo vision system and those in the workpiece coordinate system measured by a TRITOP system beforehand; then the laser line with workpiece's features got at this moment is transformed into the fixed workpiece coordinate system. Finally, the 3D information composed by the laser lines can be reconstructed in the workpiece coordinate system. A ball arm with two standard balls, which is placed on a glass plate with many marked points randomly stuck on, is measured to test the system accuracy. The distance errors between the two balls are within ±0.05 mm, the radius errors of the two balls are all within ±0.04 mm, the distance errors from the scatter points to the fitted sphere are distributed evenly, within ±0.25 mm, without accumulated errors. Measurement results of two typical workpieces show that the system can measure large-sized objects completely with acceptable accuracy and have the advantage of avoiding some deficiencies, such as sheltering and limited measuring range.",Entailment
i_2225,Entailment,"- **Environmental Stressors**: Factors such as nitrogen deficiency can hasten the initiation and progression of leaf senescence. Nitrogen deficiency leads to increased abscisic acid (ABA) concentration and reactive oxygen species (ROS) accumulation, which are closely associated with the upregulation of senescence-related genes and the downregulation of genes involved in ABA degradation .","Nitrogen (N) deficiency is one of the critical environmental factors that induce leaf senescence, and its occurrence may cause the shorten leaf photosynthetic period and markedly lowered grain yield. However, the physiological metabolism underlying N deficiency-induced leaf senescence and its relationship with the abscisic acid (ABA) concentration and reactive oxygen species (ROS) burst in leaf tissues are not well understood. In this paper, the effect of N supply on several senescence-related physiological parameters and its relation to the temporal patterns of ABA concentration and ROS accumulation during leaf senescence were investigated using the premature senescence of flag leaf mutant rice (psf) and its wild type under three N treatments. The results showed that N deficiency hastened the initiation and progression of leaf senescence, and this occurrence was closely associated with the upregulated expression of 9-cis-epoxycarotenoiddioxygenase genes (NCEDs) and with the downregulated expression of two ABA 8′-hydroxylase isoform genes (ABA8ox2 and ABA8ox3) under LN treatment. Contrarily, HN supply delayed the initiation and progression of leaf senescence, concurrently with the suppressed ABA biosynthesis and relatively lower level of ABA concentration in leaf tissues. Exogenous ABA incubation enhanced ROS generation and MDA accumulation in a dose-dependent manner, but it decreased the activities of glutamine synthetase (GS) and glutamate dehydrogenase (GDH) in detached leaf. These results suggested that the participation of ABA in the regulation of ROS generation and N assimilating/remobilizing metabolism in rice leaves was strongly responsible for induction of leaf senescence by N deficiency.",Entailment
s_1962,Contradiction,"Non-parametric Nature: While RF is a non-parametric method, it is often misunderstood as being universally applicable to all types of datasets, which may lead to overconfidence in its flexibility and robustness in handling diverse datasets with different distributions and scales .","Watershed management decisions need robust methods, which allow an accurate predictive modeling of pollutant occurrences. Random Forest (RF) is a powerful machine learning data driven method that is rarely used in water resources studies, and thus has not been evaluated thoroughly in this field, when compared to more conventional pattern recognition techniques key advantages of RF include: its non-parametric nature; high predictive accuracy; and capability to determine variable importance. This last characteristic can be used to better understand the individual role and the combined effect of explanatory variables in both protecting and exposing groundwater from and to a pollutant.In this paper, the performance of the RF regression for predictive modeling of nitrate pollution is explored, based on intrinsic and specific vulnerability assessment of the Vega de Granada aquifer. The applicability of this new machine learning technique is demonstrated in an agriculture-dominated area where nitrate concentrations in groundwater can exceed the trigger value of 50. mg/L, at many locations. A comprehensive GIS database of twenty-four parameters related to intrinsic hydrogeologic proprieties, driving forces, remotely sensed variables and physical-chemical variables measured in ""situ"", were used as inputs to build different predictive models of nitrate pollution. RF measures of importance were also used to define the most significant predictors of nitrate pollution in groundwater, allowing the establishment of the pollution sources (pressures).The potential of RF for generating a vulnerability map to nitrate pollution is assessed considering multiple criteria related to variations in the algorithm parameters and the accuracy of the maps. The performance of the RF is also evaluated in comparison to the logistic regression (LR) method using different efficiency measures to ensure their generalization ability. Prediction results show the ability of RF to build accurate models with strong predictive capabilities. © 2014 Elsevier B.V.
[7]: The soil environment is being continually contaminated with heavy metals from emissions that are introduced from both the atmosphere and water under the condition of rapid urbanization and industrialization, which cause land use regression (LUR) models could not easily capture complex relationship between soil heavy metal and potential indicator. Random forest is a non-parametric statistical method that can manage non-linear relationships. This study aims to explore the application of random forest (RF) models in predicting the soil concentration and spatial distribution of six heavy metal(loid)s (Pb, Cd, Cr, As, Hg and Zn) comparing with land use regression (LUR) models. Finally, R<sup>2</sup> values for the RF models were approximately 0.90 and presented a larger cross-validation R<sup>2</sup> and lower root mean square error (RMSE) than LUR models. The comparison between the RF and LUR models demonstrates that the RF model performed better and RF can accurately predict the concentration and spatial distribution of heavy metal(loid)s in soils. Moreover, in the study area, human activities and transportation are the main sources of soil heavy metals Pb, sewage irrigation is the main source of Cd, Cr and Zn, and atmospheric deposition from thermal power stations is an important source of soil heavy metals Hg. Parent materials is the most likely source of As. Given the above, application of random forest in soil heavy metal(loid)s may assist soil environmental management departments to focus on controlling the diffusion of heavy metal(loid)s pollution sources in a practical way, and providing targets for pollution control and prevention.",Misrepresentation
i_286,Unverifiable,"The accuracy of OpenPose can degrade with lower resolution inputs, making it less effective in scenarios requiring privacy protection or using low-resolution cameras  .","The estimation of human head pose is of interest in some surveillance and human-computer interaction scenarios. Traditionally, this is not a difficult task if high- or even standard-definition video cameras are used. However, such cameras cannot be used in scenarios requiring privacy protection. In this paper, we propose a non-linear regression method for the estimation of human head pose from extremely low resolution images captured by a monocular RGB camera. We evaluate the common histogram of oriented gradients (HoG) feature, propose a new gradient-based feature, and use Support Vector Regression (SVR) to estimate head pose. We evaluate our algorithm on the Biwi Kinect Head Pose Dataset by re-sizing full-resolution RGB images to extremely low resolutions. The results are promising. At 10×10-pixel resolution, we achieve 6.95, 9.92 and 12.88 degree mean-absolute errors (MAE) for roll, yaw and pitch angles, respectively. These errors are very close to state-of-the-art results for full-resolution images.",Related but unverifiable
i_480,Unverifiable,"Key Principles: Multimodal Integration: While combining different modalities (e.g. text, images, videos) within a unified framework is suggested, it is likely that this approach will always lead to improved retrieval performance, regardless of the specific context or type of data used .","In this paper we describe a novel approach for jointly modeling the text and the visual components of multimedia documents for the purpose of information retrieval(IR). We propose a novel framework where individual components are developed to model different relationships between documents and queries and then combined into a joint retrieval framework. In the state-of-the-art systems, a late combination between two independent systems, one analyzing just the text part of such documents, and the other analyzing the visual part without leveraging any knowledge acquired in the text processing, is the norm. Such systems rarely exceed the performance of any single modality (i.e. text or video) in information retrieval tasks. Our experiments indicate that allowing a rich interaction between the modalities results in significant improvement in performance over any single modality. We demonstrate these results using the TRECVID03 corpus, which comprises 120 hours of broadcast news videos. Our results demonstrate over 14% improvement in IR performance over the best reported text-only baseline and ranks amongst the best results reported on this corpus. Copyright © 2005 ACM.
[6]: We conduct a broad survey of query-adaptive search strategies in a variety of application domains, where the internal retrieval mechanisms used for search are adapted in response to the anticipated needs for each individual query experienced by the system. While these query-adaptive approaches can range from meta-search over text collections to multimodal search over video databases, we propose that all such systems can be framed and discussed in the context of a single, unified framework. In our paper, we keep an eye towards the domain of video search, where search cues are available from a rich set of modalities, including textual speech transcripts, low-level visual features, and high-level semantic concept detectors. The relative efficacy of each of the modalities is highly variant between many types of queries. We observe that the state of the art in query-adaptive retrieval frameworks for video collections is highly dependent upon the definition of classes of queries, which are groups of queries that share similar optimal search strategies, while many applications in text and Web retrieval have included many advanced strategies, such as direct prediction of search method performance and inclusion of contextual cues from the searcher. We conclude that such advanced strategies previously developed for text retrieval have a broad range of possible applications in future research in multimodal video search. © 2008 IEEE.
[7]: This paper presents the contribution of IPAL group on the CLEF 2006 medical retrieval task (i.e. ImageCLEFmed). The main idea of our group is to incorporate medical knowledge in the retrieval system within a multimodal fusion framework. For text, this knowledge is in the Unified Medical Language System (UMLS) sources. For images, this knowledge is in semantic features that are learned from examples within structured learning framework. We propose to represent both image and text using UMLS concepts. The use of UMLS concepts allows the system to work at a higher semantic level and to standardize the semantic index of medical data, facilitating the communication between visual end textual indexing and retrieval. The results obtained with UMLS-based approaches show the potential of this conceptual indexing, especially when using a semantic dimension filtering, and the benefit of working within a fusion framework, leading to the best results of ImageCLEFmed 2006. We also test a visual retrieval system based on manual query design and visual task fusion. Even if it provides the best visual results, this purely visual retrieval provides poor results in comparison to the best textual approaches.",Related but unverifiable
s_140,Unverifiable,"3. Handling Noise and Artifacts: Robust to Speckle Noise: Ultrasound images are notorious for speckle noise, which can obscure important features. ResUNet's architecture is designed to be robust against such noise, ensuring more reliable segmentation results .","The identification and segmentation of the prostate on magnetic resonance images (MRI) can assist in the diagnosis of prostate diseases, and improve image-guided intervention. However, prostate segmentation is normally performed manually resulting in a time-consuming process that delays the treatment. Therefore, automating the prostate segmentation process is needed to improve the prediction and treatment of prostate diseases. Segmenting the prostate on MRI is challenging due to the lack of clear boundaries between the prostate and neighboring tissues, the variability among images acquired through different protocols, and the inherent variability of the shape and size of the prostate among patients. In this paper, we present a new deep convolutional neural network architecture called ResU-Net that can automatically identify and segment the prostate on MRI. The proposed ResU-Net architecture has a similar structure to the well-known U-net but uses the residual learning framework as the building block to increase the dissemination of information to deeper layers and to overcome the challenging vanishing gradient problem. The model is tested in a publically available dataset and produces a high segmentation accuracy. Additionally, the model's use of residual connections and data augmentation enables it to generalize well even with a restricted amount of annotated images.",Related but unverifiable
i_653,Entailment,Challenges: Field Conditions: Some handheld scanners may face limitations in field conditions due to their bulkiness and the need for stable environments .,"Soil surface roughness (SSR) is a very important parameter for describing soil physical characteristics. It is widely used in wind and water erosion studies, and for retrieving soil moisture using passive or active microwave sensing data. There are several methods to quantify SSR. The techniques of quantifying soil surface roughness mainly include the pin meter and profile meter, photography, and laser scanning. However, these methods respectively have some limitations. The main disadvantage of the pin meter and profile meter is the potentially destructive effect while using these methods. Laser scanning equipment is expensive, bulky, and therefore, it is hard to work in field conditions. Photography only acquires 2D information not real 3D information of the soil surface. In recent years, structured light measurement and range image technology has been developed very well, and the main equipment of this technology became cheaper and more portable. It has been widely used in many aspects for 3D surface reconstruction. In this study, a system based on an infrared structured light 3-dimensional technique was designed for a more portable and efficient measuring of SSR. The system mainly contains an infrared structured light scanner, a tripod with a beam, a portable computer, and a level board. The scanner contains two main parts, a structured light projector and a sensor which receives the reflected structured light. The computer with installed special software was used to control the scanner and store the data. A measurement experiment was conducted. A plain board and two different soil surfaces were measured. In a practical measuring, the scanner was fixed on one end of the beam of a tripod, and directed the front of scanner towards the soil surface, and was about 100 cm high from the soil surface. The spatial resolution depended on the distance between the object and the scanner. A range image of a level board was treated as the horizontal reference for correct those range images of the soil surface. With a practical measuring process, it was found that the portability and capability of acquiring data of a structured light 3D sensor was excellent. But the measuring results had some errors because of the limitation of the spatial resolution of the system. The precision of the system needs to improve. From the analysis of the errors of the plain board measuring, we can draw some conclusions as follow. (1) The errors of the range images and surface information included inherent error and random noise, and had a specific distribution. The errors in the middle of the image were lower than in the other parts. (2) Compared with the accurate results with a higher resolution, the soil surface elevation and the roughness that was acquired by this system had less precision, and the precision was determined by the performance of the structured light scanner. (3) Due to the random noise, the correction of the soil surface elevation using the measurements of the plain board had uncertainty. The performance of this system was tested by a practical measuring experiment. It is believed that this method would be popular in SSR measuring after doing some improvements in next investigation according some findings in this study.",Entailment
s_1093,Entailment,"Benefits of ResUNet Model: Handling Complex Structures: The model is effective in dealing with complex anatomical structures and variations, which is crucial for accurate segmentation in medical imaging .","Brain tumor segmentation is a critical step in MRI analysis, significantly impacting treatment decisions and prognostic evaluations. Deep learning, particularly with models like UNet and ResUNet, has emerged as a powerful approach, offering superior segmentation accuracy. The UNet model achieves a Dice score of 0.7 and a Jaccard index of 0.6, while the ResUNet model achieves a Dice score of 0.614444 and a Jaccard index of 0.815555. Despite advancements, challenges such as tumor variability, noise, and intensity variations persist, limiting the technology's potential. This study presents recent advancements in deep learning for brain tumor segmentation, covering background, methods (including UNet and ResUNet), achieved results, and concluding remarks. We discuss strengths, limitations, and ongoing research efforts, including multi-modal data integration and advanced network architectures, aiming to enhance segmentation precision and practical utility.",Entailment
s_1515,Entailment,"-  ** Citrus hystrix Leaf: ** Optimal supercritical fluid extraction conditions were 270 bars, 18 g/min CO2 flow rate, and 50°C, yielding high TPC and antioxidant activity .","The extraction of phenolics from Citrus hystrix leaf was carried out using supercritical fluid extraction and was optimized using response surface methodology (RSM). The effects of CO2 flow rate, extraction pressure and extraction temperature on yield, total phenolic content and diphenyl-picrylhydrazyl-IC50 were evaluated and compared with ethanol extraction. The extraction pressure was the most significant factor affecting the yield, TPC and DPPH-IC50 of the extracts, followed by CO2 flow rate and the extraction temperature. The optimum conditions of pressure, CO2 flow rate and temperature were at 267 bars, 18 g/min and 50<sup>o</sup>C, respectively. The yield, TPC and DPPH-IC50 obtained were 5.06%, 116.53 mg GAE/g extract and IC50 of 0.063 mg/ml, respectively. These values were not significantly different (p<0.05) to their predicted values. Better inhibition and TPC were obtained using SFE method whereas higher yield and phenolic acids were obtained in the ethanol extracts. © All Rights Reserved.",Entailment
i_358,Contradiction,Importance of the Random Access Process: Network Performance: The efficiency of the random access process directly impacts the overall performance of the 5G network. A well-optimized random access procedure can significantly reduce access delays and improve the success rate of connection attempts .,"Random access is the necessary process in the establishment wireless link between the UE and the network, the performance of the random access directly affects the performance the network. According to the analysis of the random access process and the disadvantage of current random access preamble choice and assignment plan of TD-LTE system, this article proposed one kind of preamble assignment algorithm which is based on the users' priority and the user load situation of Base Station. This algorithm increases a preamble part which is based on priority of users, all the preambles are divided into three cases and different cases will trigger according to different user load threshold. This preamble assignment plan compensates the disadvantage of traditional preamble assignment plan; and the simulation result indicates that this algorithm can raise the access success ratio in different situation of user load. © 2011 Springer-Verlag.
[4]: LTE-Advanced networks employ random access based on preambles transmitted according to multi-channel slotted Aloha principles. The random access is controlled through a limit W on the number of transmission attempts and a timeout period for uniform backoff after a collision. We model the LTE-Advanced random access system by formulating the equilibrium condition for the ratio of the number of requests successful within the permitted number of transmission attempts to those successful in one attempt. We prove that for W ≤ 8 there is only one equilibrium operating point and for W ≥ 9 there are three operating points if the request load ρ is between load boundaries ρ1 and ρ2. We analytically identify these load boundaries as well as the corresponding system operating points. We analyze the throughput and delay of successful requests at the operating points and validate the analytical results through simulations.
[5]: Accommodating an increasing number of machine-to-machine (M2M) devices is one of the main issues faced by the cellular networks. In a typical M2M setup, several devices may try to connect to the network simultaneously. Long-term evolution advanced (LTE-A) networks use a random access procedure for this purpose, which is not sufficient to cater for a large number of devices. The conventional procedure is extended by allowing several devices to access the network with reduced collisions. Mathematical analysis and simulation results show that the proposed scheme increases the access probability as well as the number of successful transmissions.",Entity error
i_426,Entailment,"Conclusion: Cloud-based IoT solutions are defined by their ability to integrate IoT data collection with the scalable processing power of cloud computing. They are applied across various domains, including healthcare, smart homes, industrial IoT, environmental monitoring, and smart cities, providing real-time data processing, cost savings, and enhanced operational efficiency .","Cloud computing and the Internet of things (IoT) are two diverse technologies having complimentary relationship. The IoT generates massive amounts of data, and cloud computing provides a pathway for that data to travel to its destination. In the modern era, by integrating cloud computing and the Internet of things, a new paradigm has been introduced, i.e., cloud of Things. Cloud-based Internet of Things or cloud of things arose as a platform for intelligent use of applications, information in a cost-effective manner. Both technologies help to raise efficiency in the future. But the integration of these two technologies is challenging and bears some key issues. Therefore, this paper provides a brief investigation of cloud of things concept. In this paper, we review the literature about integration, to analyze and discuss the need behind integration in various applications. In the end, we identify some of the issues and challenges for future work in this promising.
[2]: The Internet of Things presents the user with a novel means of communicating with the Web world through ubiquitous object-enabled networks. Cloud Computing enables a convenient, on demand and scalable network access to a shared pool of configurable computing resources. This paper mainly focuses on a common approach to integrate the Internet of Things (IoT) and Cloud Computing under the name of CloudThings architecture. We review the state of the art for integrating Cloud Computing and the Internet of Things. We examine an IoT-enabled smart home scenario to analyze the IoT application requirements. We also propose the CloudThings architecture, a Cloud-based Internet of Things platform which accommodates CloudThings IaaS, PaaS, and SaaS for accelerating IoT application, development, and management. Moreover, we present our progress in developing the CloudThings architecture, followed by a conclusion. © 2013 IEEE.
[3]: Internet of Things (IoT) aims to connect the real world made up of devices, sensors and actuators to the virtual world of Internet in order to interconnect devices with each other generating information from the gathered data. Devices, in general, have limited computational power and limited storage capacity. Cloud Computing (CC) has virtually unlimited capacity in terms of storage and computing power, and is based on sharing resources. Therefore, the integration between IoT and CC seems to be one of the most promising solutions. In fact, many of the biggest companies that offer Cloud Services are focusing on the IoT world to offer services also in this direction to their users. In this paper we compare the three main Cloud Platforms (Amazon Web Services, Google Cloud Platform and Microsoft Azure) regarding to the services made available for the IoT. After describing the typical architecture of an IoT application, we map the Cloud-IoT Platforms services with this architecture analyzing the key points for each platform. At the same time, in order to conduct a comparative analysis of performance, we focus on a service made available by all platforms (MQTT middleware) building the reference scenarios and the metrics to be taken into account. Finally, we provide an overview of platform costs based on different loads. The aim is not to declare a winner, but to provide a useful tool to developers to make an informed choice of a platform depending on the use case.
[4]: The advent of the Internet of Things (IoT) has led to the generation of tremendous amounts of data from various sources. Cloud based systems are effective in storage and application of machine learning algorithms on such datasets. However, in some cases it is important to enable real time processing for making immediate decisions. There are many applications which require instantaneous analysis of the generated data for remedies in event of an anomaly. Data associated with such use cases remains significant only for a short duration of time. Various electronic sensors, e.g. Temperature, Moisture, Air Quality, Pressure, Wind Velocity etc. present in a Wireless Sensor Network generate streams of values. It can be processed using pipelines which provide prompt and quick analysis for decision making. Stream Processing Systems can be helpful in such cases as they analyse data streams within a few milliseconds to a few seconds. In this paper, we discuss an event based processing of streaming data from air pollution sensors to create a real time anomaly detection system. To reduce the delays associated with the generation of alarms in our pipeline, Apache Foundation's Stream Processing Tools, Kafka and Flink were used for operations on our streams. To further accelerate the process, all the analysis is conducted on an embedded edge computing gateway device rather than sending data to the cloud for batch processing. The results are obtained in the form of a geographical map visualization using ELK stack. The map highlights the coordinates of the location with an unhealthy air quality index in real time.
[5]: The process of acquiring, analysing and managing data obtained by sensors and actuators in industrial environments can benefit from modern Cloud-based platforms towards a complete implementation of the Industrie 4.0 concept. The analysis of huge data sets produced by these sensors (Big Data) could allow quick and accurate decision making. For example, productivity improvements can be achieved by analysing device performance and degradation for real-time feedback on configuration and optimization. This work proposes a Cloud-based architecture for Internet of Things (IoT) applications to improve the deployment of smart industrial systems based on remote monitoring and control. By using specific technologies available as a service, we demonstrate the proposed architecture on an automated electric induction motor use case. This approach includes layers for sensor network data gathering, data transformation between standard protocols, message queuing, real-time data analysis, reporting for further analysis, and real-time control. Particularly, by using the proposed architecture, we remotely monitored, controlled and processed data produced by sensors and actuators coupled to the motor. Preliminary results indicate this foundation can support predictive methods and management of automated systems in the Industrie 4.0 context.
[8]: Cloud-Internet of Things based solutions exploit the benefits of complementarity between the two technologies. Due to its specificity, the Ambient Assisted Leaving is a priority domain to implements such solutions, with main focus on health and behaviour monitoring. The paper provides the business architecture and generic specifications for a management system with a two-fold objective: To support the configuration of the integrated offer of services specific to Cloud of Things based monitoring, in relation with various providers of these services, and to efficiently administrate the implementation and usage of this offer, in collaboration with its users and beneficiaries. The solution is dedicated to the service integrator, who plays the central role and has the main responsibility in capitalizing this offer on the market. To emphasize this particularity, the focus is put on the business architecture of this management solution specifying the participants, their roles and interactions. For the information management system supporting this architecture, the conceptual schema of the database is detailed. Finally the paper outlines an instantiation of this solution in case of health monitoring, with the focus on outpatient setting. A further development of the current solution envisages of this architecture to the institutionalized patients setting.
[9]: Internet of Things (IoT) technologies provide many opportunities for providing healthcare applications such as home based assisted living and well-being application solutions. Nowadays, numerous IoT devices are used to monitor users' healthcare status and transmit the data directly to remote data centers through the cloud computing paradigm. This direct interconnection of the large amount of devices for remote storage, processing, and retrieval of medical records in the cloud demands a reliable network connection imposing many challenges related to network connectivity and traffic. This chapter deals with the transfer of the computing intelligence from cloud to the edge network. Fog computing operates closer to the user, on network edge, enabling accurate service delivery with low response time avoiding delays and network failures that may interrupt or delay the decision process and healthcare service delivery. An architectural model is proposed and a set of use cases illustrate the benefits of the IoT and fog computing integration.
[10]: Cloud platforms have evolved over the last years as means to provide value-Added services for Internet of Things (IoT) infrastructures, particularly smart home applications. From different use cases the necessity arises to connect IoT cloud solutions of different vendors. While some established platforms support an integration of other vendors' systems into their own infrastructure, solutions to federate IoT cloud platforms can hardly be found. In this paper, we analyze existing IoT cloud platforms with respect to their similarities and derive a concept of an Intercloud Broker (IB) that enables the establishment of an IoT Intercloud to support interoperability of cloud-based IoT platforms from different vendors. To demonstrate the feasibility of our approach we evaluated the overhead introduced by the Intercloud Broker. As the results show, the IB can be implemented with minimal overhead in terms of throughput and delay even on commodity hardware.
[11]: Internet of Things (IoT) provides to everyone new types of services in order to improve everyday life. Through this new technology, other recently developed technologies such as Big Data, Cloud Computing, and Monitoring could take part. In this work, we survey the four aforementioned technologies in order to find out their common operations, and combine their functionality, in order to have beneficial scenarios of their use. Despite the boarder concept of a smart city, we will try to investigate new systems for collecting and managing sensors' data in a smart building which operates in IoT environment. As a bases technology for the proposed sensor management system, a cloud server would be used, collecting the data that produced from each sensor in the smart building. These data are easy to be managed and controlled from distance, by a remote (mobile) device operating on a network set up in IoT technology. As a result, the proposed solutions for collecting and managing sensors' data in a smart building could lead us in an energy efficient smart building, and thus in a Green Smart Building.
[13]: Internet of Things (IoT) and Vehicular Ad hoc NETwork (VANET) based clouds are two emerging technologies and offer myriad of new applications in many domains of smart cities including, but not limited to, smart infrastructure and intelligent transportation. Integration of these technologies will enrich the applications and services space that will eventually stimulate the proliferation of these technologies. Nonetheless, due to their different requirements, environments, and networking models, such integration will need definitions of new communication paradigms and frameworks. To fill the voids, in this paper, we propose an architectural framework to integrate vehicular clouds (VC) and IoT, referred to as IoT-VC, to realize new services and applications that include IoT management through vehicular clouds. We particularly focus on smart city applications controlled, managed, and operated through vehicular networks. This theoretical work provides initial insights into data management in such diverse paradigm with resource constrained environment. Furthermore, we also discuss research challenges in such integration that include data acquisition, data quality, security, privacy, coverage, and so forth. These challenges must be addressed for realization of IoT-VC paradigm.",Entailment
i_383,Unverifiable,"Manufacturing: Robotics and Automation: AI-driven robots are primarily used for assembly and inspection, but their impact on fault diagnosis and safety in manufacturing environments is often overstated, as many traditional methods still dominate these areas .","Artificial intelligence (AI) technology, as one of the most advanced science and technology in the current society, has been applied more and more widely to production and life, and especially in manufacture industry. This paper studies the application of artificial intelligence in mechanical manufacture industry. Firstly, it briefly introduces the definition and development of artificial intelligence and that of mechanical manufacture industry. Secondly, it analyzes the advantages of AI. Lastly, it illustrates how artificial intelligence technology is applied in mechanical manufacture mainly from the aspects of fault diagnosis, quality inspection, improving the safety of working places and other aspects as well.
[6]: With the increasing demand for automation of production lines, robots are increasingly used in industrial production, making robot production line simulation technology a hot research topic. The virtual test run system of the robot is based on the layout plan of the robot production line to carry out three-dimensional visual simulation of the production line, to verify the rationality of the layout plan, and to avoid unnecessary losses caused by blind production. However, the current research on simulation software is lacking, so the research of robot virtual trial operation system has important significance for domestic industrial development. The purpose of this paper is to use the virtual prototype to solve the problems in the design stage before manufacturing the physical prototype of the stamped product, and contribute to the research of the robotic stamping automation production line. This paper is mainly based on the advantages of high flexibility of robot stamping production line, low mold requirements, simple programming of new workpieces, virtual prototyping technology, computer science and other disciplines, physical simulation, full simulation, and finally the same physical prototype test production method.",Related but unverifiable
s_2018,Contradiction,"Vulnerability Assessment: Developing a vulnerability index specific to fisheries can help identify and prioritize adaptation measures. While Indonesia has been identified as highly vulnerable to declines in coral reef fisheries, it is likely that this vulnerability is not as significant as it appears, given that other factors may mitigate its impact on food security .","Measuring the vulnerability of human populations to environmental change is increasingly being used to develop appropriate adaptation policies and management plans for different economic sectors. We developed a national-level vulnerability index that is specific to food security policies by measuring nations' relative vulnerabilities to a decline in their coral reef fisheries. Coral reef fisheries are expected to decline with climate and anthropogenic disturbances, which may have significant consequences for food security. The vulnerability measure was composed of exposure, sensitivity, and adaptive capacity indicators specific to fisheries, reef management, and food security. The vulnerability index was used to evaluate 27 countries, as data required to fully populate the theoretical framework was limited. Of these, Indonesia and Liberia were identified as most and Malaysia and Sri Lanka as least vulnerable nations. Our analysis revealed two common national vulnerability characterizations: low income countries with low adaptive capacity and middle-income countries with higher adaptive capacity but high sensitivity. These results suggest developing context-specific policies and actions to build adaptive capacity in the low-income countries, and to decrease sensitivity in middle-income countries. Comparing our food security evaluation to a more general vulnerability approach shows that they produce different priority countries and associated policies. © 2012.",Misrepresentation
i_1973,Contradiction,"Cities like Paris are not implementing effective climate action plans, and there is a lack of atmospheric monitoring networks to track and manage urban emissions. These plans fail to adapt to changing urban landscapes and do not meet emission reduction targets .","Background : Urban agglomerates play a crucial role in reaching global climate objectives. Many cities have committed to reducing their greenhouse gas emissions, but current emission trends remain unverifiable. Atmospheric monitoring of greenhouse gases offers an independent and transparent strategy to measure urban emissions. However, careful design of the monitoring network is crucial to be able to monitor the most important sectors as well as adjust to rapidly changing urban landscapes. Results : Our study of Paris and Munich demonstrates how climate action plans, carbon emission inventories, and urban development plans can help design optimal atmospheric monitoring networks. We show that these two European cities display widely different trajectories in space and time, reflecting different emission reduction strategies and constraints due to administrative boundaries. The projected carbon emissions rely on future actions, hence uncertain, and we demonstrate how emission reductions vary significantly at the sub-city level. Conclusions : We conclude that quantified individual cities' climate actions are essential to construct more robust emissions trajectories at the city scale. Also, harmonization and compatibility of plans from various cities are necessary to make inter-comparisons of city climate targets possible. Furthermore, dense atmospheric networks extending beyond the city limits are needed to track emission trends over the coming decades.",Opposite meaning
s_1535,Contradiction,"Soybean is an insignificant crop in Indonesia, thriving without any challenges related to yield variability from water deficits and soil types .","An experiment was conducted with the objective to investigate the influence of available water deficit in typical soil types on the yield and crop water requirement of soybeans in Indonesia. This research was conducted in a plastic greenhouse of the University of Lampung from June to August 2005. A factorial experiment was arranged in randomized block design with three replications. The soil type (S) was the first factor with two different soil types, Ultisol (S1), and Latosol (S2). Water deficit (D) was the second factor with five levels including D1 (0-20%), D2 (20-40%), D3 (40-60%), D4 (60-80%), and D5 (80-100%) of water deficit from the total available water (TAW). For example, D1 (0-20%) meant that water was given to maintain the available water depletion between 0% and 20% of TAW in the root zone. Yield under full irrigation in Ultisol (21.3 g/pot) was 2.3 times as much as in Latosol (9.3 g/pot). Yield efficiency (the ratio of yield to crop water requirement) in Ultisol was the greatest under deficit irrigation of 30% of available water deficit (0.0083 g/g), which was 1.26 times as much as under full irrigation (0.0066 g/g). However, yield efficiency of Latosol was the greatest under full irrigation (0.0049 g/g). Therefore, yield efficiency of soybean in Ultisol was 1.8 times as much as in Latosol.",Opposite meaning
i_2072,Unverifiable,"Significance of Varying Hydraulic Conductance: Hydraulic Conductance in Different Plant Parts: Hydraulic conductance varies across different components of the plant, including roots, stems, and leaves .","Plant hydraulics is key for plant survival and growth because it is linked to gas exchange and drought resistance. Although the environment influences plant hydraulics, there is no clear consensus on the effect of nitrogen (N) supply, which may be, in part, due to different hydraulic conductance normalization criteria and studied species. The objective of this study was to compare the variation of root hydraulic properties using several normalization criteria in four pine species in response to three contrasting N fertilization regimes. We studied four closely related, yet ecologically distinct species: Pinus nigra J.F. Arnold, Pinus pinaster Ait., Pinus pinea L. and Pinus halepensis Mill. Root hydraulic conductance (Kh) was measured with a high-pressure flow meter, and values were normalized by total leaf area (leaf specific conductance, Kl), xylem cross-section area (xylem specific conductance, Ks), total root area (root specific conductance, Kr) and the area of fine roots (fine root specific conductance, Kfr). Controlling for organ size differences allowed comparison of the hydraulic efficiency of roots to supply or absorb water among fertilization treatments and species. The effect of N on the root hydraulic efficiency depended on the normalization criteria. Increasing N availability reduced Kl and Ks, but increased Kh, Kr and especially Kfr. The positive effect of N on Kr and Kfr was positively related to seedling relative growth rate and was also consistent with published results at the interspecific level, whereby plant hydraulics is positively linked to photosynthesis and transpiration rate and fast growth. In contrast, normalization by leaf area and xylem cross-sectional area (Kl and Ks) reflected opposite responses to Kr and Kfr. This indicates that the normalization criteria determine the interpretation of the effect of N on plant hydraulics, which can limit species and treatment comparisons.
[7]: • The leaf hydraulic conductance (K<inf>leaf</inf>) is a major determinant of plant water transport capacity. Here, we measured K <inf>leaf</inf>, and its basis in the resistances of leaf components, for fully illuminated leaves of five tree species that regenerate in deep shade, and five that regenerate in gaps or clearings, in Panamanian lowland tropical rainforest. We also determined coordination with stomatal characters and leaf mass per area. • K<inf>leaf</inf> varied 10-fold across species, and was 3-fold higher in sun- than in shade-establishing species. On average, 12% of leaf hydraulic resistance (= 1/K<inf>leaf</inf>) was located in the petiole, 25% in the major veins, 25% in the minor veins, and 39% outside the xylem. Sun-establishing species had a higher proportion of leaf resistance in the xylem. Across species, component resistances correlated linearly with total leaf resistance. • K<inf>leaf</inf> correlated tightly with indices of stomatal pore area, indicating a coordination of liquid- and vapor-phase conductances shifted relative to that of temperate woody species. • Leaf hydraulic properties are integrally linked in the complex of traits that define differences in water use and carbon economy across habitats and vegetation zones. © New Phytologist (2005).",Related but unverifiable
i_1898,Unverifiable,"Environmental and Health Impacts: Water Supply Systems: The accumulation of heavy metals like lead, nickel, zinc, and copper in the sediments of water supply pipelines suggests that all water supply systems are at significant risk for contamination, which could affect public health .","Groundwater is the only source for drinking water supply in Lithuania. Twenty water intakes exploiting Quaternary aquifers are operating in Vilnius City. The main aim of this study was to characterize the heavy metal content of internal pipeline sediments in the water supply network. It also provides a new insight into the accumulation of phosphorus and its variation in pipeline sediments in the study area. The results of this research reflect the level of heavy metals that accumulated during the water supply process. The main microelements detected were lead, nickel, zinc and copper. The research results will be useful for conducting preliminary evaluations of possible microelement accumulation in other similar water supply systems. The evaluation of water supply sediments is considered as one of the most important activities associated with a water safety approach. The results of this research indicate the dependence between phosphorus accumulation and Pb, Cr, Zn, Ni and Cu quantities in the internal sediments of water supply pipelines.",Related but unverifiable
i_9,Unverifiable,"Advantages of Combining Deep Learning with Kriging: Improved Prediction Accuracy. Deep learning models, such as convolutional neural networks (CNNs), can capture complex patterns and trends in data that are not easily discernible by traditional methods. When combined with kriging, this can lead to more accurate predictions of spatial properties .","Prediction of lithology/fluid (LF) properties from seismic data can be very valuable in all phases of oil and gas exploration and production, but the resolution and accuracy of predicted results are reduced due to band-limited wavelet and noise of seismic data. Deep learning can review data, discover specific trends and patterns that would not be apparent to humans, and has been successfully used in many applications, including geophysics. Also, time-frequency (T-F) analysis tools can show how the energy of the signal is distributed over the 2-D T-F space, which helps to exploit the features produced by the concentration of signal energy. In this letter, we propose a novel hybrid approach for predicting LF properties, including oil-sand, brine-sand, and shale and evaluating their uncertainty, which aims at combining the benefits of T-F analysis method based on inverse spectral decomposition (ISD) and one-dimensional convolutional neural network (1D-CNN). The proposed method can provide more details about thinner layers and suppress noise to some extent using T-F spectrum obtained by ISD, and capture more relevant features from the input using 1D-CNN at different levels similar to a human brain, and thus, can significantly improve the resolution and accuracy of the predicted results. The proposed method was applied to a real 3-D post-stack seismic data and validated through a blind well test and comparison with the conventional methods.
[2]: Ordinary Kriging (OK) is a popular geostatistical algorithm for spatial interpolation and estimation. The computational complexity of OK changes quadratically and cubically for memory and speed, respectively, given the number of data. Therefore, it is computationally intensive and also challenging to process a large set of data, especially in three-dimensional (3D) cases. This paper develops a geostatistics-informed machine learning (GIML) model to improve the efficiency of OK by reducing the number of points required to be estimated using OK. Specifically, only a very few of the unknown points are estimated by OK to get the weights and estimations, which are used as the training dataset. Moreover, the governing equations of OK are used to guide our proposed machine learning to better reproduce the spatial distributions. Our results show that the proposed GIML can reduce the computational time of OK by at least one order of magnitude. The effectiveness of the GIML is evaluated and compared using a 2D case. Furthermore, we demonstrate its efficiency and robustness by considering a different number of training samples on various 3D simulation grids.",Related but unverifiable
s_2233,Entailment,"Mitigation Strategies: Soil Amendments: Adding materials like rice bran, calcium oxide, and superphosphate can significantly stabilize lead in the soil, almost eliminating its bioavailability .","Soil incubation experiments were conducted with the biomass materials of rice bran, calcium oxide and superphosphate combined application to investigate the passivation effect of lead contaminated soil. The results showed as follows: adding the rice bran into soil could increase the pH value and the stability of lead in soil. The soil pH increased by about 0.3 for each 2% increase in the amount of rice bran dosage. The stabilization efficiency reached to 38.06% and acid extractable was reduced by 28.90% with 6% rice bran after 60 day. At day 60,the joint use of 6% rice bran and 2% calcium oxide, 6% rice bran and 0.6% superphosphate also resulted in a great stability, which was 47.36% and 44.85% respectively. 6% rice bran + 2% calcium oxide has good passivation regulation on Pb contaminated soil, which can increase the soil pH.Thereby, acid extractable lead could be transformed to stability fractionation.",Entailment
i_369,Contradiction,"Key Agile Practices: Continuous Feedback and Improvement: Agile practices claim to emphasize regular feedback from stakeholders and team members, but evidence suggests that this may not significantly enhance product and process improvement in all cases .","Agile methods have transformed the way software is developed, emphasizing active end-user involvement, tolerance to change, and evolutionary delivery of products. The first special issue on agile development described the methods as focusing on feedback and change. These methods have led to major changes in how software is developed. Scrum is now the most common framework for development in most countries, and other methods such as extreme programming (XP), elements of lean software development, and Kanban are widely used. What started as a bottom-up movement among software practitioners and consultants has been taken up by major international consulting companies who prescribe agile development, particularly for contexts where learning and innovation are key. Agile development methods have attracted interest primarily in software engineering1, 2 but also in a number of other disciplines including information systems and project management.
[4]: A survey conducted on the agile software development methods and techniques, which are gaining increasing attention within the IT industry is discussed. The survey reports show that organizations such as Shine Technologies have adopted the agile method such as Extreme Programming (EP), Scrum, Agile MSF, AUP, and in particular FDD. The organization has also adopted agile development techniques such as Test Driven Development (TDD) or pair programming. Agile database development techniques including database refactoring and database regression testing are also beginning to attract attention. The survey shows that the adoption on agile approaches to software development has successfully affected the overall productivity and the quality of the systems that they delivered. Agile software development's focus on collaborative techniques, such as active stakeholder participation and increased feedback, have also helped to improve stakeholder satisfaction.
[7]: The authors of this paper are part of a distributed agile team assembled in 2005 to create a software product, adopting agile methodologies and using a set of tools to support the development work. The authors present their experience on working with these tools to effectively improve the adopted agile practices. Three of the most crucial agile practices, given the size of the team and its distributed nature, are discussed: maintain high project status visibility, provide immediate feedback and achieve complete automation for most of the development activities. © 2008 IEEE.",Opposite meaning
i_1974,Entailment,"Urban and Regional Initiatives: Local Adaptation Strategies: In the Île-de-France region, local authorities are developing adaptation strategies that integrate citizen contributions into public policy. This approach aims to enhance public participation and capabilities in addressing climate change .","Multilateral agreements at the global level have not succeeded in stabilizing the concentration of greenhouse gases in the atmosphere. Following this assessment, a new way to look at climate issues seems necessary. Interest in adaptation is growing internationally, and transformational adaptation emerges today as a promising concept to address strategies of both mitigation and adaptation. In this article, we propose a new approach to consider local adaptation strategies based on capabilities. Relying on three case studies of local authorities in Île-de-France, we characterize their recent local adaptation strategies and analyse how these have taken capabilities into account. Different institutional tools allow for various ways of integrating capabilities. Plans Climat, which rely on technical studies, address administrations and professionals rather than citizens. Agendas 21 may provide a more holistic approach, but fail to address citizens' needs in order for them to act for adaptation. As for calls for associative or citizens projects, competition for funding does not foster cooperation. We demonstrate that the limitations put on public participation processes do not yet allow for the emergence and reinforcement of capabilities. Most of the local strategies studied in fact correspond to an adjustment approach to adaptation. However, spurred by recent objectives to strongly reduce emissions, new ways of integrating citizens' contributions into public policy have emerged.",Entailment
i_319,Unverifiable,Applications: Industrial Automation: Using image processing for quality control and automation in manufacturing processes is the only effective method for ensuring product quality in all manufacturing sectors .,"The CCD image sensor is set in the different production position, whose output signal is converted into digital signals to a dedicated image processing system by A/D. Using the image enhancement, smoothing, sharpening, segmentation, feature extraction, image recognition and understanding of digital image processing techniques,the system can identify the image, compare with feature information preservation, decide whether to enter the next process according to the similarity degree of alignment. Visual inspection having high precision, fast speed, working in the industrial field is stable and reliable, and improves the level of automation of production, make the products more competitive. © (2014) Trans Tech Publications, Switzerland.",Related but unverifiable
i_329,Entailment,"While DL techniques are generally data-hungry and often require large-scale annotated datasets, it is clear that they can function effectively with minimal annotation, making the acquisition of such datasets less critical than previously thought .","Motivation: The localization of objects in images is a longstanding objective within the field of image processing. Most current techniques are based on machine learning approaches, which typically require careful annotation of training samples in the form of expensive bounding box labels. The need for such large-scale annotation has only been exacerbated by the widespread adoption of deep learning techniques within the image processing community: deep learning is notoriously data-hungry. Method: In this work, we attack this problem directly by providing a new method for learning to localize objects with limited annotation: most training images can simply be annotated with their whole image labels (and no bounding box), with only a small fraction marked with bounding boxes. The training is driven by a novel loss function, which is a continuous relaxation of a well-defined discrete formulation of weakly supervised learning. Care is taken to ensure that the loss is numerically well-posed. Additionally, we propose a neural network architecture which accounts for both patch dependence, through the use of Conditional Random Field layers, and shift-invariance, through the inclusion of anti-aliasing filters. Results: We demonstrate our method on the task of localizing thoracic diseases in chest X-ray images, achieving state-of-the-art performance on the ChestX-ray14 dataset. We further show that with a modicum of additional effort our technique can be extended from object localization to object detection, attaining high quality results on the Kaggle RSNA Pneumonia Detection Challenge. Conclusion: The technique presented in this paper has the potential to enable high accuracy localization in regimes in which annotated data is either scarce or expensive to acquire. Future work will focus on applying the ideas presented in this paper to the realm of semantic segmentation.",Entailment
s_1818,Contradiction,"Social Impact: Public and Developer Engagement: The success of sponge city projects is primarily determined by the engagement of both the government and developers, suggesting that without such engagement, projects are likely to fail. While incentive models may help align the interests of developers with public goals, they do not significantly reduce moral hazard, which remains a major barrier to improving project outcomes .","As a new sustainable urban development concept, the Sponge city has an important influence on the stormwater treatment. The low-impact development (LID) system of nonpublic lands plays an important role in the entire construction of Sponge city. In the nonpublic lands' LID system construction, a principal-agent relationship exists between the government and developer and the effect of construction mainly depends on the developer's operation and management. Due to the asymmetry of information and the different benefit goals, the developer could be prone to take moral hazard behavior to damage the project and public's interests. In this paper, based on the principal-agent relationship between the government and developer in Sponge city projects, principal-agent incentive models under the existence of developer's moral hazard tendency were constructed to help the developer invest an optimal efforts level. The results show that an increase in incentive intensity would increase the developer's optimal level of productive efforts in the presence of developer's moral hazard tendency; this can indirectly cause an increase in total output performance of Sponge city, thus realizing a ""win-win"" effect between the government and developer. Likewise, a larger incentive intensity can also help reduce the developer's moral hazard tendency. The more obvious moral hazard tendency of developer, the larger incentive coefficient should be. The findings provide reference for government seeking to specify incentive contracts from a theory perspective and curbing developer's potential moral hazard behavior in Sponge city projects.",Opposite meaning
s_2221,Entailment,"Sources of Lead Contamination: Agricultural Practices: The use of fertilizers, pesticides, and wastewater irrigation in agriculture can introduce lead into the soil .","Direct discharge of waste into water bodies and mining are two major sources of lead contamination in ecosystems. Water scarcity promoted the usage of industrial effluent-contaminated waters for crop production, mainly in peri-urban areas. These wastewaters may contain heavy metals and pollute crop ecosystems. These metals can reach the living cell via contaminated raw foodstuffs that grow under these conditions and cause various ill effects in metabolic activities. In this study, graded levels of pressmud (0, 2.5, 5, 10 g/kg) were applied on lead imposed soil with different contamination levels (0, 100, 150, 300 mg/kg) and metal dynamics was studied in spinach crop. Experimental results showed that the addition of pressmud upto 10 mg/kg had decreased different phytoremediation indices in spinach crop. Whereas, increasing Pb level enhanced the indices' values, indicating accumulation of significant amount of Pb in spinach biomass. However, application of pressmud (upto 10 mg/kg) reduced the bioconcentration factor (BCF) from 0.182 to 0.136, transfer factor (TF) from 0.221 to 0.191, translocation efficiency 66.11–59.34%; whereas, Pb removal enhanced from 0.063 to 0.072 over control treatment. These findings suggest that application of pressmud declined Pb concentration, the BCF and the TF in test crop which lead to less chances of adverse effect in human. These information are very useful for effectively managing wastewater irrigated agricultural crop production systems.
[5]: Soil contamination with heavy metals due to the application of fertilizers and biocides in agricultural activities is a potential threat for human health through the food chain. The present work was designed to study the spatial distribution of heavy metals, pollution level and possible reasons for their contamination in agricultural soils of Aghili plain, Khuzestan, Iran. The median concentrations of As, Cd, Co, Cr, Cu, Mn, Mo, Ni, Pb, V, Zn, and Hg were 2.90, 0.29, 8.10, 39.0, 17.75, 354.0, 0.97, 58.35, 5.90, 34.0, 42.0, and 0.01 mg/kg, respectively. The results revealed that average concentrations of all studied heavy metals with an exception of Co, Cu, and Ni, were lower than background values. Analysis of source identification showed that Zn, Pb, and Cu (P < 0.01, r > 0.9) and Co, Cr, Mn, Ni, and V (P < 0.01, r > 0.7) were mainly from anthropogenic. In addition, Cd probably was originated from agricultural activities (application of manure and phosphorous fertilizers). Enrichment factor values of all metals (except Ni), were in the range of non to moderate enrichment (EF < 5). According to the degree of contamination (C<inf>d</inf>) and ecological risk factor (ERF), all stations were categorized as low to moderate contaminated sites (4.5 < C<inf>d</inf> < 17), and biological communities in some locations may be at risk (ERF >65). Results indicate that application of fertilizers, herbicides and pesticides in agricultural soils has led to soil contamination and special management and educational plans are needed for public and farmers to prevent further adverse effects.",Entailment
s_901,Unverifiable,"Resource Management and Efficiency: Energy Management: IoT enables the creation of smart grids that optimize energy use, improve efficiency, and reduce waste. While intelligent sensors and smart meters facilitate real-time monitoring and control of energy consumption, the actual reductions in carbon emissions and energy costs may not be as significant as suggested, potentially only leading to minor improvements in some cases .","The article's research focus is to investigate the impact of technologies used in smart cities to achieve environmental sustainability. The research methods used to review scientific studies worldwide on the problem under consideration, analysis and synthesis, comparative analysis, and logical approach. The information and communication technologies in smart cities aim to promote sustainability and provide adequate services to citizens, thereby improving their quality of life. Specific characteristics of smart cities are the extensive use of technology, real-time monitoring, innovation, and citizen empowerment, with a constant focus on sustainability. Analysis of the cited examples shows that technologies are being deployed in smart cities to improve transportation systems, deal with traffic jams and waiting times at traffic lights, and more with real-time data analysis. In most examples, information and communication technologies create a smart grid to achieve optimal energy use and improve the efficiency, reliability, and economy of the provided utility services. Self-monitoring and control of smart grids are realized using intelligent sensors and smart meters for energy transmission and distribution for real-time analysis of current consumption. An intelligent energy system involves using technologies for efficient energy production and distribution. The conducted case study on the effectiveness of the smart city in terms of environmental sustainability establishes that the sustainable management of resources and reducing the harmful impact on climate change and the environment requires optimizing the use of energy and resources and increasing the use of renewable energy sources. Analysis shows how technology can achieve environmental sustainability by reducing carbon emissions from cities, improving air quality, and optimizing the use of natural resources. Implementing intelligent systems and applications can reduce greenhouse gas emissions by an average of 20%, water consumption by up to 30%, and the amount of non-recyclable solid waste by around 15-20%, depending on the city's specific characteristics.
[2]: Smart cities are systematically promoting the transition to sustainable and effective energy systems by promoting policies for energy efficiency, regionalized/distributed renewable energy generation, and intelligent energy management. In particular, this transition toward a more integrated and intelligent energy supply has created a plethora of energy meta-information made available through the IoT smart grid, thereby allowing big data analytical services to forecast energy consumption and to manage usage patterns. In this article, we propose a context-aware framework for intelligent power equipment management. Our contribution is to present a design of the proposed framework based on context awareness, the definition of a context ontology for power equipment management, a specification of the inference rules for the context ontology, and a context-aware inference service for power equipment management. The proposed system has broad applications to handle system monitoring and express system controls, so as to be easily and effectively applied to various application domains.",Related but unverifiable
s_1226,Entailment,"** Influence of Medications: ** Medications that inhibit gastric acid secretion, such as proton pump inhibitors (PPIs) and somatostatin, can significantly increase the pH of gastric acid. For example, in patients treated with somatostatin or pantoprazole, the pH increased from around 1.9 to over 5.6 .","Objective. Gastric acid inhibition is beneficial in the management of peptic ulcer bleeding (PUB). The aim of this double-blind study was to test whether somatostatin (SST) increases intragastric pH in PUB as compared with pantoprazole (PAN) and placebo (PLA). Material and methods. Eligible patients were randomized to receive SST (500 μg/h + 250 μg bolus), or PAN (8 mg/h+80 mg bolus) or PLA (normal saline) i.v., for 24 h. All patients underwent gastric pH monitoring during the infusion of the trial drugs. Results. The three groups (SST, n = 14; PAN, n = 14; PLA, n = 15) were comparable for age, gender, aetiology of PUB and laboratory data at admission. Mean (±SE) baseline pH levels in the fundus increased during the administration of the trial drugs (SST: 1.94±0.18 to 6.13±0.37, p <0.0001; PAN: 1.93±0.16 to 5.65±0.37, p <0.0001;PLA: 1.86±0.12 to 2.10±0.15, p = 0.0917). During the first 12 h of infusion, the mean (±SE) percentage time spent above pH 4.0 and 5.4 was higher with SST versus PAN (84.4%±4.8 versus 55.1%±8.3, p = 0.0049 and 74.2%±6.5 versus 47.1%±8.3, p = 0.0163, respectively) and there was a trend favouring the SST group regarding the time spent above pH 6.0 and 6.8 (65.7%±6.4 versus 43.3%±8.2, p = 0.0669 and 49.2%±7.7 versus 28.4±6.6, p = 0.0738, respectively). Conclusions. In PUB, both SST and PAN inhibit gastric acid secretion as compared with placebo. However, during the first 12 h of the infusion, SST was more effective than PAN in maintaining high intragastric pH. These results may provide a rationale for the administration of SST in PUB. © 2005 Taylor & Francis.",Entailment
s_1779,Entailment,"Conclusion: Biosensors are increasingly vital in the food industry for ensuring product quality and safety. Enzymatic, electrochemical, optical, and nanobiosensors are among the most widely used types, each offering unique advantages in terms of sensitivity, specificity, and rapid analysis. However, the reliance on these technologies may lead to overlooking traditional methods, which still hold significant value in certain contexts. The integration of nanotechnology and smartphone-based platforms is often overstated, as their effectiveness in real-world applications remains to be fully validated .","Biosensors are an important alternative in the food industry to ensure the quality and safety of products and process controls with effective, fast and economical methods. Their technology is based on a specific biological recognition element in combination with a transducer for signal processing. The use of enzymatic biosensor technology in food processing, quality control and on-line processes is promising compared to conventional analytical techniques, as it offers great advantages due to size, cost, specificity, fast response, precision and sensitivity. This article reviews the development and use of some enzyme biosensors in the food industry, describes the most important application areas and analyzes the current situation and future possibilities. In conclusion, enzymatic biosensors are a tool with broad application in the development of quality systems, risk analysis and critical control points, and the extent of their use in the food industry is still largely limited by the short lifetime of biosensors, in response to which the use of thermophilic enzymes has been proposed.
[2]: Electrochemical biosensors have shown great promise in the development of rapid methods for the detection of foodborne pathogens and have been intensively studied over the past two decades. The scope of this review is to summarize the advancements made in the development of electrochemical biosensors for the rapid detection of one of the most common foodborne pathogens, Escherichia coli O157:H7. The article is intended to include different configurations of electrochemical biosensors based on the sensing principles and measured electrical parameters, as well as the latest improvements of technology in the progress of electrochemical biosensor development to detect E. coli O157:H7. By discussing the current and future trend based on some of excellent published literatures and reviews, this survey is hoped to illustrate a broad and comprehensive understanding of electrochemical biosensors for the detection of foodborne pathogens.
[3]: Salmonella has represented the most common and primary cause of food poisoning in many countries for at least over 100 years. Its detection is still primarily based on traditional microbiological culture methods which are labor-intensive, extremely time consuming, and not suitable for testing a large number of samples. Accordingly, great efforts to develop rapid, sensitive and specific methods, easy to use, and suitable for multi-sample analysis, have been made and continue. Biosensor-based technology has all the potentialities to meet these requirements. In this paper, we review the features of the electrochemical immunosensors, genosensors, aptasensors and phagosensors developed in the last five years for Salmonella detection, focusing on the critical aspects of their application in food analysis.
[4]: Background: Food safety is becoming increasingly important because food industry must provide quality products to minimize the health risks. Traditional methods to assure food safety, such as plate count and polymerase chain reaction are accurate and robust but can hardly satisfy the needs of the food industry because they are costly and time consuming. Therefore, optical biosensors that can analyze food in a low-cost, facile, fast, sensitive, and selective manner started to emerge. Scope and approach: This review presents plasmonic biosensors including surface plasmon resonance (SPR), localized SPR (LSPR), fiber optic SPR (FO-SPR), surface enhanced Raman scattering (SERS), surface-enhanced fluorescence (SEF), and total internal reflection (TIR) based sensors and their applications in food pathogens monitoring. Moreover, the strengths and weaknesses of plasmonic biosensors implementation in food control are showcased. Key findings and conclusions: Plasmonic biosensors could simplify procedure and radically reduce time, price and consummation of reactants, compared to traditional microbiological methods. Optical biosensors, in particular SPR, have been developed for detection of different foodborne pathogens. In parallel, analytical improvements have been achieved by coupling different techniques (fiber optics, Raman, fluorescence, luminescence) to plasmonic sensors in order to reduce the limits of detection and to improve sensitivity. The future improvements include the miniaturization of instruments to handheld devices and simplification of analysis to enable direct target detection in food matrices. Plasmonic technology can certainly have long lasting impact because the need for a simple and rapid food assay is pressing and guarantees the future development in this field.
[6]: Nanotechnology has recently become one of the most exciting forefront fields in biosensors fabrication. Nanotechnology has been changing the area of biosensor for many kinds of fields as food. Nanobiosensor, an integration of molecular engineering, physical sciences, chemistry, biology and biotechnology, holds the possibility of manipulating and detecting molecules and atoms using nano-devices/machines, which have the potential for a wide range of both domestic and industrial applications. The role of nanobiosensors in food analysis and detection of chemical and biological compounds in food is an interesting and important area. Biosensors permit the detection of a wide spectrum of analyte in complex sample matrices and have denoted great promise in areas like food analysis. There has been a steadily growing use of biosensor technology for the detection of food contaminants such as food dyes, processing contaminants, veterinary drugs, marine toxins and mycotoxins. On the other hand, there are both some benefits and bottlenecks of nanobiosensors in food fields.
[7]: The successful integration of nanotechnology as a platform for food sensors offers tremendous benefits in detecting contaminants, particularly in their applications for food quality and safety. The sensors based on nanomaterials (nanosensor), both chemical sensors (chemical nanosensors) and biosensors (nanobiosensors), can be used online and integrated into existing manufacturing process and distribution line or off-line as rapid, simple, and portable, as well as disposable, sensors for food contaminants. Food contaminants could be residues of pesticides, veterinary and human drugs, microbial toxins, preservatives, contaminants from food processing and packaging, and other residues. This milieu of compounds can pose difficulties in the detection of food contaminants. Nanosensors with their novel uses are the emerging method that could be used for the detection of many food contaminants, even mycotoxins and many food allergens. Whether it used as online or off-line, the nanosensor can be integrated with wireless technology and used for real-time transmission of contaminant alarm or test results to remote servers, providing rapid screening and reporting. Thus nanosensors are more cost-effective, rapid, and more sensitive than instrumental and conventional procedures. Recent developments in nanosensors may provide more applications for their use in food contaminant detection. The future role of these nanosensors will become even more important as the food laboratory is faced with the increasing pressure to reduce cost, time, and complexity. The objective of this chapter is to give a general overview of the possible application of nanosensors in the food contaminant detection and analysis.
[8]: Rapid and accurate analysis of food draws considerable attention in the modern pace of the world due to the close relationship between human health and food safety. Traditional detection technologies for food evaluation are often restricted by high cost, lengthy time, bulky instruments and trained personnel. The marriage of biosensors with smartphones enables the development of powerful analysis platforms for food evaluation including detection of food contaminants, toxins, pathogens, allergens and nutrition. Here, we provide an overview of recent developments on smartphone-based biosensors for portable food evaluation. Owing to operability, connectivity, portability and built-in sensors, smartphones have become ideal control, interaction and analysis tools in the on-site sensing systems. Fusion of smartphones with different kinds of sensitive and selective biosensors enables to develop portable and user-friendly analytical devices. In addition to introducing technical principles, detection methods and selected applications in food science, challenges and future perspectives for smartphone-based biosensors are also discussed.
[10]: Food safety as a huge world public health threat has attracted increasing attention. Effective detection methods are of great importance to ensure food safety. However, the development of reliable and efficient detection methods has been a challenging task because of the complexity of food matrices and trace levels of food contaminants. Recently, emerging nanomaterials with mimetic enzyme activity, namely, nanozymes, have been employed for novel biosensor development, which has greatly accelerated the advancement of food safety assay. In this review, we summarize the mechanism and advances in nanozyme-based biosensors such as colorimetric biosensors, fluorescence biosensors, chemiluminescent biosensors, electrochemical biosensors, SERS-based biosensors, and other biosensors. Impressively, the applications of the nanozyme-based biosensors in food safety screening have also been comprehensively summarized (including mycotoxins, antibiotics, pesticides, pathogens, intentional adulteration, metal ions, and others). In the end, future opportunities and challenges in this promising field are tentatively proposed.",Entailment
s_1449,Entailment,"Color: The visual appeal of raspberries, including color, can be preserved better with methods that reduce oxidative stress and moisture loss. Microwave thawing, despite its speed, may lead to uneven color changes .","In this study, the effect of a pre-fermentative freezing treatment on quality attributes of 'Meffi' rosé wine was assessed. Prior to fermentation, 'Meffi' grapes (berries and must) were subjected to a freezing treatment considering factors of freezing temperatures, freezing time, and thawing method. Colour-related indices were measured by spectral methods. Wine aroma characteristics and sensory attributes were assessed by trained paneffists. The results revealed that lower freezing temperature and longer freezing time had positive effects on wine quality attributes. The treatment of frozen berries might help extract colourrelated compounds. Microwave thawing improved wine colour, but decreased taste quality. In the work, the MF-10°C/6 h treatment (microwave-thawed berries that had been frozen at -10°C for 6 h) contributed to the best colour characteristics, whereas the NP-20°C/4 h treatment (naturally-thawed must that had been frozen at -20°C for 4 h) contributed to the best taste attributes.
[2]: The quality of frozen meat is related to the thawing process. Lipid oxidation, juice loss, color and flavor deterioration, and microorganism propagation occur during the thawing process, which may result in the deteriorated meat quality. Consequently, it is necessary to utilize proper thawing methods to maintain meat quality and minimize the losses. The novel thawing technology includes microwave, ultrasonic, high-voltage electrostatic field, and vacuum thawing, etc. It depends on the e-quipment that is different from the traditional thawing method. Compared with the traditional thawing method, the new ones are characterized by fast thawing speed, low energy consumption, and better maintenance of the meat quality. The present mini-review described different kinds of thawing methods, their advantages and disadvantages. This review will hopefully provide theoretical insight and practical guidance for enterprises to choose the appropriate thawing technology.",Entailment
s_968,Contradiction,"Summary of Findings: Key Points: Psychotropic Drugs and Hypothermia: There is evidence that psychotropic drugs, particularly antipsychotics like clozapine, can induce hypothermia .","The case report describes a patient with a longstanding diagnosis of paranoid schizophrenia on treatment with haloperidol, among other antipsychotic drugs. The patient suffered an episode of severe hypothermia (a life-threatening complication), requiring admission to the Intensive Care Unit (ICU) and later to Internal Medicine, before being reviewed by the hospital Psychiatric Department. After ruling out other etiological and pathophysiological hypothermia options, and after a thorough and complete medical examination, it was reasonably concluded that the most likely source of hypothermia was attributable to a recent increase in the dose of haloperidol the patient was taking. Studies suggest the possibility of occurrence of haloperidol-induced hypothermia, not only in laboratory animals, but also in humans. However, haloperidol is not the only antipsychotic drug which has been attributed to this adverse effect, as hypothermic episodes with other typical and atypical antipsychotic drugs have also been reported.
[2]: Objective: To review current knowledge surrounding the effects, treatment, and prognosis of hypothermia in people, dogs, and cats, as well as the application of therapeutic hypothermia in clinical medicine. Etiology: Hypothermia may be a primary or secondary condition, and may be due to environmental exposure, illness, medications, anesthesia, or trauma. Hypothermia has been applied therapeutically in human medicine for a variety of conditions, including postcardiac arrest. In veterinary medicine, the technique has been applied in cardiac surgeries requiring bypass and in a patient with intractable seizures. Diagnosis: Hypothermia can be diagnosed based on presenting temperature or clinical signs, and appropriate diagnosis may require nontraditional thermometers. Therapy: Rewarming is the primary treatment for accidental hypothermia, with intensity ranging from passive surface rewarming to extracorporeal rewarming. The goal is to return the core temperature to a level that restores normal physiologic function of all body processes. Other supportive therapies such as intravenous fluids are typically indicated, and if cardiopulmonary arrest is present, prolonged resuscitation may be required. In cases of secondary hypothermia, reversal of the underlying cause is important. Prognosis: There are few prognostic indicators in human and veterinary patients with hypothermia. Even the most severely affected individuals, including those presenting in cardiopulmonary arrest, have potential for complete recovery with appropriate therapy. Therapeutic hypothermia has been shown to improve outcome in people following cardiac arrest. Further studies are needed to examine this application in veterinary medicine, as well as appropriate therapy and prognosis for cases of spontaneous hypothermia.",Entity error
s_663,Unverifiable,"Challenges in Power Delivery and Conversion: Complexity and Reliability: Power Distribution Units (PDUs): Ensuring a stable power supply is critical for data centers. Double conversion PDU systems are used to provide high reliability, but they must also be efficient to meet environmental protection requirements. New control methods are being developed to enhance the efficiency of these systems .","Uninterruptible Power Supply (UPS) equipments are used for various mission-critical systems, and the importance of UPS has increased due to the growth of IT market. Many systems are connected each other in the world, and so the systems have to work 7 days 24 hours. Power failure of one system might affect many other systems. Many kinds of circuit have been proposed and adopted for UPS equipments. For important systems such as data center server facilities, double conversion UPS are used to offer the highest reliability of power supply. Recently the environmental protection has become much important and it is required to reduce power loss for all electrical equipments. This paper explains new control method to obtain the high efficiency double conversion UPS using conventional isolation type main circuit, and introduces the related test results. © 2007 IEEE.
[5]: The computer industry in Australia is investing on uninterruptible UPS power supply systems to overcome the power problems. The industry is investing in these power supply systems to overcome power problems related to electric overload in server rooms and data centers, that has increased with installation of data storage units. Capital and maintenance costs have increased significantly, forcing the industry to invest in uninterruptible UPS power supply systems. The industry is also focusing in computer equipment with low power electronics and low computer system loads. The 6-pulse UPS options are chosen with minimum specifications when operating with a generator. The Australian computer industry has relied on transformerless UPS designs with low loss choke filters that provide considerably better efficiency performance at full load conditions.",Unrelated and unverifiable
i_1285,Entailment,"Interventions and Recommendations: Addressing social challenges such as violence, poverty, and lack of social support is crucial. Health systems should integrate mental health services with HIV care and provide targeted support for high-risk groups .","Background: Mental health problems of adolescents are underserved in low and middle-income countries where they account for a significant proportion of disease burden. Perinatally infected HIV-positive adolescents have a high prevalence of mental health disorders; however, little is known about those retained in care in South Africa. Methods: HIV-positive adolescents aged 13–19 years (n = 343) accessing five paediatric antiretroviral clinics in Johannesburg were assessed using standardized measures for depression, anxiety, post-traumatic stress disorder (PTSD), and suicidality. Descriptive and bivariate analyses were conducted on all variables using Statistica v13. Results: Twenty-seven percent were symptomatic for depression, anxiety, or PTSD; 24% reported suicidality. Peer violence was significantly correlated to all mental health problems, as was hunger, being inappropriately touched, being hit, and being female. Those reporting sickness in the past year were more symptomatic. High exposure to violence was evident. Additionally, not feeling safe at home or in the community increased risk for all mental health disorders. Knowing one's HIV status was protective as was having dreams for the future. Conclusion: HIV-positive adolescents accessing care demonstrated high levels of mental health problems that are largely unrecognized and could potentially be addressed within health systems. Mental health difficulties are driven by social challenges that require attention.
[10]: Background: Poor mental health predicts sexual risk behaviours in high-income countries, but little is known about this association in low-income settings in sub-Saharan Africa where HIV is prevalent. This study investigated whether depression, psychological distress and alcohol use are associated with sexual risk behaviours in young Ugandan adults. Method. Household sampling was performed in two Ugandan districts, with 646 men and women aged 18-30 years recruited. Hopkins Symptoms Checklist-25 was used to assess the presence of depression and psychological distress. Alcohol use was assessed using a question about self-reported heavy-episodic drinking. Information on sexual risk behaviour was obtained concerning number of lifetime sexual partners, ongoing concurrent sexual relationships and condom use. Results: Depression was associated with a greater number of lifetime partners and with having concurrent partners among women. Psychological distress was associated with a greater number of lifetime partners in both men and women and was marginally associated (p = 0.05) with having concurrent partners among women. Psychological distress was associated with inconsistent condom use among men. Alcohol use was associated with a greater number of lifetime partners and with having concurrent partners in both men and women, with particularly strong associations for both outcome measures found among women. Conclusion: Poor mental health is associated with sexual risk behaviours in a low-income sub-Saharan African setting. HIV preventive interventions should consider including mental health and alcohol use reduction components into their intervention packages, in settings where depression, psychological distress and alcohol use are common. © 2011 Lundberg et al; licensee BioMed Central Ltd.",Entailment
i_775,Unverifiable,"Additionally, driving cycles (urban, extra-urban, combined) have a significant impact on battery aging, and it is believed that incorporating advanced predictive algorithms could further enhance the accuracy of battery lifetime estimations under various driving conditions .","Lithium-ion batteries are a key technology for current and future energy storage, whether they are used for mobile or stationary application. In particular, they play an important role for the electrification of mobility due to their high power and energy density and therefore their battery lifetime prediction is a fundamental aspect for successful market introduction. The ageing data provided by the battery manufacturers result from standard ageing tests. For this reason, it is very important to link, in the way as simple as possible, the effect of driving cycles (urban, extra-urban, combined) with the ageing of the batteries. The aim of this work is to investigate on the effect of driving cycles on the batteries lifetime through tests performed on different cells for different kinds of cycle. Afterwards, simulation tests are made in order to estimate the battery lifetime for different driving cycles of the electric vehicle.",Related but unverifiable
i_1555,Unverifiable,"Additionally, reduced funding and other constraints have limited the progress of CCS demonstration projects, which may lead to increased reliance on alternative energy sources in the EU as a result of insufficient CCS deployment .","Carbon capture and storage (CCS) on electricity generation and energy intensive industry is expected to play a considerable role in achieving the European Union's decarbonisation goals. EU CCS demonstration project funding has been created to encourage development and accelerate commercial CCS deployment by providing funds to bridge the capital gap for early commercial-scale CCS installation. Eleven CCS project proposals currently remain at least nominally active, but reduced funding and other constraints suggest at best delivery of around a third of these. To explore how these demonstrations impact on the scale of subsequent CCS deployment in the EU three simple scenarios for post-demonstration CCS activity and deployment (none, limited and considerable) are considered and examined in the context of key factors that have influenced the demonstration programme. Without strong political support for post-demonstration deployment including measures such as strategic storage validation and CO<inf>2</inf> pipeline planning, and a clear process to make CCS commercially attractive to investors on a timeline consistent with climate ambitions, even a positive result from the demonstration programme is unlikely to enable CCS to deliver as expected. © 2012 Elsevier Ltd.",Related but unverifiable
s_16,Contradiction,"Data Processing: Implement data processing, validation, and transformation procedures using auto-generated rules within Apache Spark to ensure seamless integration of model inputs and outputs .","In this paper we describe how the Predictive Model Markup Language (PMML) standard enhances the JBoss Drools production rule engine with native support for using predictive models in business rules. The historic debate between symbolic and connectionist approaches to rule/model orchestration provides numerous examples of hybrid systems combining ""hard"" and ""soft"" computing techniques to achieve di-erent levels of integration. Rules are often used to decide when and which model to invoke; model outputs, in turn, can be used to evaluate the preconditions of a rule. In a loosely coupled system, the rule engine calls an external component implementing the predictive model, but this has several disadvantages, most notably the need to setup proper communications and reconcile any di-erence in the way the components encode the data. We propose instead, a tightly integrated system where predictive models and rules become part of the same reasoning framework. The models, encoded using the PMML 4 standard, are loaded and processed by a compiler implemented using the rule engine it-self. The PMML document is transformed into a set of facts that de-ne the model, and a series of rules that formalize the model's behavior. In addition, most PMML data processing, validation, and transformation procedures are also implemented using auto-generated rules. Finally, in oder to integrate model inputs and outputs seamlessly in the inference process, we exploit an extension of the Drools engine which adds native support for uncertainty and/or fuzziness. Copyright 2011 ACM.",Entity error
s_1210,Contradiction,"Hemolysis and Biocompatibility: Hemolysis Index (HI): Optimization of centrifugal blood pumps for hydraulic efficiency did not lead to acceptable hemolysis levels, indicating that efficient pump designs may actually increase hemolysis rates .","A centrifugal blood pump is a common type of pump used as a left ventricular assist device in the medical industries. Therefore, the improvement of the device bio-compatibility to reduce the blood damage and to increase the efficiency has become a major challenge. In the current work, a metamodel-assisted genetic algorithm is employed to simultaneously optimize the impeller and volute geometries of a typical centrifugal blood pump. The overall shape of the base design is inspired from HeartMate3 LVAD, and the main dimensions of the base design including inlet and outlet radius, blade angle distribution, volute cross-section area distribution, etc., are designed in our laboratory. Three different scenarios are investigated using three different objective functions, i.e., (1) hydraulic efficiency, (2) pressure head, and (3) hemolysis index (HI). The results showed that the shape optimized by pump efficiency has also nearly the same level of HI as the shape optimized by HI. Hence, to reduce computation time, one can use efficiency instead of HI as an objective function. However, one must check the HI level after such optimization to see whether it is within the acceptable range of HI for such bio application.",Misrepresentation
i_1159,Unverifiable,"Effective Strategies for Improving Diet Quality: Food-Based Recommendations (FBRs) - Implementing optimized FBRs can significantly improve dietary practices and nutrient intakes. For instance, promoting the consumption of sea fish, soy protein, dark green leafy vegetables, and potatoes has shown positive results in improving nutrient intake among Javanese women with dyslipidemia .","Background and Objectives: Using a linear programming approach, an optimized food-based recommendations (FBRs) had been formulated for Minangkabau women of reproductive age with dyslipidemia in Indonesia. This study aimed to assess the effectiveness of the promotion of the FBRs for improving dietary practices and nutrient intakes. Methods and Study Design: A community-based, clustered-randomized trial was conducted among Minangkabau women of reproductive age (20-44 years) with dyslipidemia. The subjects were assigned either into the FBR group (n=48), or the non-FBR group (n=54). Baseline and end-line dietary data were assessed through interviews using a one-week semiquantitative food frequency questionnaire (SQ-FFQ) and two replicate 24-hour dietary recalls. The changes in dietary practice and nutrient intakes were analysed using ANCOVA test. Results: Significant changes were observed (p<0.005) in the consumption of the promoted food items and subgroups (sea fish, soy protein, dark green leafy vegetables, and potatoes). Significant changes were also observed in nutrient intake, especially energy intake from carbohydrates and unsaturated fatty acids (total PUFA, MUFA, n-3 and n-6 fatty acids), as well as the dietary P/S ratio and fiber intake. Conclusions: With current dietary practices, intakes of some typical problem nutrients such as n-6, zinc, iron, and fiber still could not achieve 100% of the RNIs, while the intake of SFA still exceeded the recommended intake. Further approaches are needed to expand the population food basket and promote behavioral change to address established cultural food habits, including reducing the use of cooking oil in food preparation and increasing vegetable consumption.
[2]: Considering the impact of unfavorable dietary practices on inadequate nutrient intake, this cross-sectional study aimed to explore dietary practices, including problem nutrients, and develop local food-based recommendations (FBRs) to improve the intake of problem nutrients among women of reproductive age (WoRA) with dyslipidemia in Minangkabau, Indonesia. Methods and Study Design: The study was conducted in the Padang township inhabited mostly by the Minangkabau tribe. Accordingly, 74 WoRA with dyslipidemia completed the study. Two replicate 24-h recalls and a 5-day food record were used to assess food consumption patterns. Then, linear programming (LP) analysis using three modules of the WHO Optifood software was employed to identify problem nutrients and develop FBRs. Results: Median (5th and 95th percentiles) weekly consumption frequencies for grain; meat, fish, and eggs; and added fat were 18 (14–27), 11 (6–16), and 15 (7–30), while those for fruits and vegetables were 2 (0–11) and 7 (2–16), respectively. Based on the aforementioned food pattern, PUFA (both n-3 and n-6 fatty acids), dietary fiber, iron, and zinc were identified as typical problem nutrients. The final FBR emphasized on incorporating locally available nutrient-dense foods, as well as food groups and sub-groups, which would improve the intake of problem nutrients. Conclusions: Minangkabau WoRA have dietary practices that predispose them to dyslipidemia. Moreover, the LP approach is a sensitive tool for identifying nutrient-dense foods that could potentially improve problem nutrient intake, as well as those that need to be limited in the final FBR.",Related but unverifiable
s_762,Unverifiable,"2. Green Infrastructure (GI): Green infrastructure solutions leverage ecosystem functionalities to create resource-efficient systems. Examples include phytoremediation (using plants to remediate contaminated soil), constructing wetlands for natural wastewater treatment, and innovative forest management to mitigate air pollution. These solutions provide ecosystem services, promote biodiversity, and require less capital and maintenance compared to traditional methods .","[13] ""Ecological modernisation"" - understood as systematic eco-innovation and its diffusion - has by far the largest potential to achieve environmental improvements. In general, the market logic of modernisation and competition for innovation combined with the market potential of global environmental needs serve as important driving forces behind ""ecological modernisation"". In recent times, however, additional factors like rising energy prices or fears from climate change have favoured the rise of this innovation-based approach to environmental policy. The article deals with two special driving forces: first, there is growing evidence for the importance of ""smart"" environmental regulation. Secondly, the increasingly complex actor constellation of global environmental governance leads to mounting business risks for polluters and thereby exerts pressure for eco-innovation. Despite these favourable framework conditions, the strategy of ""ecological modernisation"" nonetheless faces a number of inherent limitations. These include the unavailability of marketable technological solutions for relevant environmental problems like the loss of species, the rebound effect neutralising the incremental environmental improvements through economic growth (the dilemma of the ""N-curve"") as well as resistance by ""modernisation losers"". Against this background, structural solutions seem indispensable. Here, eco-innovations should be supported by transition management or ecological structural policy. © 2007 Elsevier Ltd. All rights reserved.",Related but unverifiable
i_1747,Unverifiable,"Advantages of Revealing Carbon Emissions Data: Market Penalties for Non-Disclosure. Firms that do not disclose their carbon emissions face additional market penalties. The act of not disclosing emissions information can lead to a further decrease in firm value, indicating that the market penalizes non-disclosure .","[2] We examine the roles of the outcome and process dimensions of environmental performance in determining financial performance as measured by Tobin's q. Outcomes refer to the impacts of the firm on the natural environment, while processes are the firm's actions to reduce these outcomes. We focus on a specific outcome - carbon emissions - and suggest that it affects Tobin's q non-linearly. We find that firms achieve the highest financial performance when their carbon performance is neither low nor high, but intermediate. We also find that environmental processes moderate this relationship as they reinforce firms' financial performance through improved stakeholder management. This mixed picture suggests that firms do not generally internalize the costs of poor carbon performance, but those that stand out in both environmental outcomes and processes achieve net financial benefits. These findings are based on a sample of carbon-intensive firms that disclosed their greenhouse gas (GHG) emissions through the Carbon Disclosure Project from 2007 through 2013. [17] Harnessing energy from the sunlight using solar photovoltaic trees (SPVTs) has become popular at present as they reduce land footprint and offer numerous complimentary services that offset infrastructure. The SPVT's complimentary services are noticeable in many ways, e.g., electric vehicle charging stations, landscaping, passenger shelters, onsite energy generated security poles, etc. Although the SPVT offers numerous benefits and services, its deployment is relatively slower due to the challenges it suffers. The most difficult challenges include the structure design, the photovoltaic (PV) cell technology selection for a leaf, and uncertainty in performance due to weather parameter variations. This paper aims to provide the most practical solution supported by the performance prioritization approach (PPA) framework for a typical multilayered SPVT. The proposed PPA framework considers the energy and sustainability indicators and helps in reporting the performance of a multilayered SPVT, with the aim of selecting an efficient PV leaf design. A three-layered SPVT (3-L SPVT) is simulated; moreover, the degradation-influenced lifetime energy performance and carbon dioxide (CO2) emissions were evaluated for three different PV-cell technologies, namely crystalline silicon (c-Si), copper indium gallium selenide (CIGS), and cadmium telluride (CdTe). While evaluating the performance of the 3-L SPVT, the power conversion efficiency, thermal regulation, degradation rate, and lifecycle carbon emissions were considered. The results of the 3-L SPVT were analyzed thoroughly, and it was found that in the early years, the c-Si PV leaves give better energy yields. However, when degradation and other influencing weather parameters were considered over its lifetime, the SPVT with c-Si leaves showed a lowered energy yield. Overall, the lifetime energy and CO2 emission results indicate that the CdTe PV leaf outperforms due to its lower degradation rate compared to c-Si and CIGS. On the other side, the benefits associated with CdTe cells, such as flexible and ultrathin glass structure as well as low-cost manufacturing, make them the best acceptable PV leaf for SPVT design. Through this investigation, we present the selection of suitable solar cell technology for a PV leaf.",Unrelated and unverifiable
s_1738,Entailment,"Addition of Hydrophobic Nutraceuticals: Curcumin Enrichment: Although primarily used for its health benefits, curcumin can be incorporated into milk without affecting its stability. This method involves adjusting the pH to facilitate the incorporation of hydrophobic compounds, which might also influence the color and appearance of the milk .","The pH-shift method is a simple approach for incorporating certain kinds of polyphenol-based nutraceuticals into already existing colloidal systems. The polyphenols can be loaded into hydrophobic particles due to the fact that their water-solubility is relatively high under alkaline conditions but low under acid or neutral conditions. In this study, it was demonstrated that bovine milk could be enriched with curcumin using this approach, without adversely affecting milk fat globule stability. The storage stability of the curcumin-enriched bovine milk was assessed when samples were incubated for 60 days at different pH values and temperatures. The pH-stability was determined by storing curcumin-enriched milk at 4 °C for 60 days at pH 6.5, 7.0, and/or 8.0. At this low storage temperature, all milk samples were stable to fat globule aggregation, creaming, curcumin degradation (<13% loss), and color loss. The temperature-stability was determined by storing curcumin-enriched milk at pH 7 for 15 days at 4, 20, 37, or 55 °C. Curcumin breakdown decreased with decreasing storage temperature: 55 °C (43%) > 37 °C (21%) > 20 °C (10%) > 4 °C (5%). Interestingly, the color of the curcumin-enriched milks incubated at 4, 20, and 37 °C remained similar to that of the initial samples, but the sample stored at 55 °C showed significant color fading. Curcumin bioaccessibility determined using an in vitro gastrointestinal tract was around 40%, which was attributed to some chemical degradation and binding of the curcumin reducing its stability and solubilization. This study shows that a hydrophobic nutraceutical (curcumin) can be loaded into dairy milk products using a simple method, which could facilitate the creation of novel functional foods and beverages.",Entailment
s_597,Unverifiable,"Key Points: Technology Utilized: Image Processing Techniques: Techniques such as motion magnification and frame subtraction are employed to identify rapid motion areas in the magnified frame sequences, which correspond to breathing movements. Additionally, it is believed that similar image processing techniques could be adapted for monitoring other physiological parameters, such as heart rate, in various settings .","The objective of this study was to design a non-invasive system for the observation of respiratory rates and detection of apnoea using analysis of real time image sequences captured in any given sleep position and under any light conditions (even in dark environments). A Microsoft Kinect sensor was used to visualize the variations in the thorax and abdomen from the respiratory rhythm. These variations were magnified, analyzed and detected at a distance of 2.5 m from the subject. A modified motion magnification system and frame subtraction technique were used to identify breathing movements by detecting rapid motion areas in the magnified frame sequences. The experimental results on a set of video data from five subjects (3 h for each subject) showed that our monitoring system can accurately measure respiratory rate and therefore detect apnoea in infants and young children. The proposed system is feasible, accurate, safe and low computational complexity, making it an efficient alternative for non-contact home sleep monitoring systems and advancing health care applications.",Related but unverifiable
s_850,Unverifiable,"Technical Challenges: Injection Parameters: The effectiveness of DWI is somewhat sensitive to injection parameters such as injection pressure and nozzle diameter. While these parameters influence the atomization and mixing process of the fuel, their impact on combustion efficiency and emissions is often overstated. High injection pressures and smaller nozzle diameters may improve fuel atomization, but they are unlikely to significantly complicate the injection system .","The direct injection (DI) diesel engines are the main power source in modern society. They are widely used in the fields of transportation, construction machinery, agricultural machinery, ships and small machinery. In the face of the challenges of energy saving and environment protection, high-efficient and low-pollution combustion mode has become the development direction of DI diesel engines. The combustion process of DI diesel engines determines the thermal efficiency and the emission levels, while the combustion process is determined by the atomization and mixing process of the fuel. During the operating process of the engine, atomization and mixing of the fuel are controlled by the injection parameters such as the injection pressure and the nozzle diameter of the injector as well as the environmental parameters such as background temperature and environmental density. Therefore, studying the influence of fuel injection parameters and environmental parameters on fuel spray characteristics is of great significance for optimizing the design of combustion system. In this paper, the sensitivity analysis on the effect of background temperatures and densities on the diesel spray characteristics in the previous study was summarized. A direct imaging and schlieren technique of high-speed photography and an image processing program were used to analyze the sensitivities of injection pressure and nozzle diameter to spray parameters. The influence of the injection parameters (injection pressure, nozzle diameter) and ambient parameters (background temperature, background density) on the spray characteristics was compared according to the sensitivity analysis results. The results show that under the experimental conditions (background temperature of 304-770 K, background density of 13-26 kg/m<sup>3</sup>, nozzle diameter of 0.18-0.26 mm, injection pressure of 120-160 MPa), with the decrease of nozzle diameter, the volume percentage of gas phase tends to increase, and the mean excess air coefficient of the spray also increases. The reason is mainly that as the nozzle diameter decreases, the droplet size decreases, the spray surface area increases, and evaporation becomes faster. With the increase of injection pressure, the volume percentage of gas phase tends to increase, and the mean excess air coefficient of the spray also increases. The reason for this is that with the increase of injection pressure, the speed of oil droplet breaking is faster, the amount of air entrained by the spray is increased, the relative speed between spray and ambient gas increases, and the heat transfer through convection increases, which are beneficial to the evaporation of the spray. It can be found from the sensitivity analysis of gas phase volume percent that the background temperature has the highest sensitivity (3.3) to gas phase volume percent, followed by the injection parameters that can affect the crushing process: nozzle diameter (-0.29) and fuel injection pressure (0.23). The effect of background density on the gas phase volume percent has the lowest sensitivity (0.12). It can be found from the sensitivity analysis of average excess air coefficient that the injection parameters (nozzle diameter (-2.24) and injection pressure (1.29)) have higher sensitivity to the average air excess coefficient, while the environmental parameters (background temperature (0.69) and background density (0.71)) have a slightly lower average effect on the average excess air coefficient.",Related but unverifiable
s_611,Unverifiable,"Voltage and Power Specifications: Peak Voltage and Pulse Frequency: The power supply should be capable of delivering high peak voltages (e.g. 10-40 kV) and a wide range of pulse frequencies (e.g. 1-1000 Hz), and it is anticipated that future advancements may allow for even higher voltage capabilities beyond 40 kV .","A novel type of power supply for the plasma immersion ion implantation (PIII) system, capable of direct coupling of the RF pulsed-voltage and the pulses with amplitude up to 40 kV, has been successfully developed by integrating high voltage insulation and low pass filtering technologies. Electrically connected to the target via a single feed-through, the newly-developed power supply may generate RF pulses and high voltage pulses in an alternating way. The RF pulse for generating the plasma and the high voltage pulse for ion immersion and ion implantation are modulated by the time control unit. The specifications of the power supply include: peak voltage of 10~40 kV, pulse frequency of 1~1000 Hz, power of 6 kW; RF pulse width of 0.01~10 ms, RF power of 1 kW, and the mode switching time interval of 0.01~10 ms. The power supply was experimentally tested with satisfactory results. The design considerations, technical specifications, circuitry, and parts geometry of the power supply were also discussed.",Related but unverifiable
s_1441,Entailment,"Gene Activity and Immune Response: Enhanced Immune Parameters: Synbiotic diets significantly increased lysozyme activity, which is a marker of enhanced immune response. Additionally, there was an increase in total immunoglobulin content and other immune parameters, suggesting that synbiotics can bolster the fish's immune system .","Synbiotics, a synergistic combination of probiotics and prebiotics, are currently regarded as one of the most practical nutritional supplements in tilapia farms. In this study, the effect of supplementing the diet of red tilapia (Oreochromis spp.) with Jerusalem artichoke (Helianthus tuberosus) and Lactobacillus rhamnosus GG (LGG) was evaluated. Growth performance, serum biochemical parameters, intestinal morphology, goblet cell counts, immune parameters and protection against Aeromonas veronii challenge were determined. The results showed that fish fed with synbiotic-supplemented diets had a significantly higher (P < 0.05) feed conversion ratio (FCR), specific growth rate (SGR), and average daily gain (ADG) than fish fed with a control diet. The synbiotic-supplemented diet increased glucose, total protein and the total cholesterol levels. The absorptive area of the proximal and distal intestine of fish fed on the synbiotic diet was significantly higher (P < 0.05) than in those fed with probiotics (LGG), prebiotic-supplemented diets (JA), and the control diet. Goblet cell counts revealed that the numbers of acid mucous cells, neutral mucous cells and double-staining mucous cells of fish fed the synbiotic-supplemented diet (JA + LGG) were significantly higher (P < 0.05) in the proximal and distal intestine. Fish fed the synbiotic-supplemented diets also exhibited significantly higher (P < 0.05) lysozyme activity. The cumulative mortalities of fish fed with a synbiotic-supplemented diet were significantly lower than those of fish fed other diets. The results suggested the beneficial effect of JA and LGG synbiotic diet on growth performance and health status of red tilapia. Direct administration of JA and LGG in fish feed can be used as a practical nutritional supplement in red tilapia.
[3]: Survival of probiotics in processed feed can be affected not only by feed processing techniques but also by factors such as storage and gastrointestinal transit of ingested feed. This study investigates the effect of free and spray-dried Bacillus subtilis (BS) in oat β-glucan microcapsules on growth performance, hematology, intestinal microbiota, histology, and immunology of Nile tilapia, Oreochromis niloticus. A total of 400 tilapia were randomly stocked into 25 aquaria in a randomized experimental design and fed one of the following diets: (C) control diet (without synbiotics); (0.1%S) 1g kg<sup>−1</sup> diet of unloaded microcapsules and 2.7 × 10<sup>9</sup> of free BS CFU kg<sup>−1</sup> diet; (0.2%S) 2 g kg<sup>−1</sup> diet of unloaded microcapsules and 5.4 × 10<sup>9</sup> of free BS CFU kg<sup>−1</sup> diet; (0.1%SM) 1g of microcapsules loaded with 2.7 × 10<sup>9</sup> BS CFU kg<sup>−1</sup> diet; and (0.2%SM) 2g of microcapsules loaded with 5.4 × 10<sup>9</sup> BS CFU kg<sup>−1</sup> diet. After a 60-day feeding trial, fish fed 0.2%SM showed the highest growth performance and best feed utilization compared to fish fed free probiotics and control diet. Intestinal villi were longer, and the submucosa layer was thicker in fish fed both free and microencapsulated probiotics than the control group. Fusobacteriota, Firmicutes, and Bacteroidota were the dominant phyla across all samples accounting for more than 90% of the gut microbiota. No differences were registered in hematological parameters. Phagocytic activity was enhanced in fish fed both 0.2%S and 0.2%SM diets. Microencapsulation has the potential to protect B. subtilis and may constitute a valuable approach for enhancing the viability of probiotics as additives for fish feeds.
[4]: This study evaluated the prebiotic effects of dietary inulin and Jerusalem artichoke tuber (JA) on juvenile Nile tilapia (Oreochromis niloticus). Five dietary treatments (each diet in four replicates) were formulated to incorporate inulin at 0 (control), 2.5 and 5gkg<sup>-1</sup> and JA at 5 and 10gkg<sup>-1</sup>. Fish were reared in concrete ponds for 8 weeks. Fish fed the inulin diets exhibited better growth performance than fish fed the control diet, and fish fed the JA diets had the best growth performances among all diets tested. Dietary inulin and JA increased red blood cell number. Among the fourteen blood chemicals examined, dietary inulin or JA led to increased glucose, albumin, protein, magnesium, calcium, and iron content (P<0.05). Inulin supplementation at 5gkg<sup>-1</sup> improved lysozyme activity and alternative complement haemolytic 50 (ACH50) activity. Dietary JA increased total immunoglobulin content, lysozyme activity, and ACH50 activity. Dietary inulin or JA increased the height of intestinal villi and goblet cell number. These findings indicate that inulin at 5gkg<sup>-1</sup> had beneficial prebiotic effects on juvenile Nile tilapia and that direct supplementation with JA at 10gkg<sup>-1</sup> had positive effects on growth and health. Thus, both inulin and JA have great potential for use as prebiotics in fish feed.",Entailment
i_2323,Entailment,- ** Soil Health**: Reducing fertilizer input can improve soil health by preventing acidification and nutrient imbalances . This can lead to more sustainable tea production in the long term.,"[Objectives]: Tea is one of the main cash crops in China, balanced fertilization plays very important roles for the high yield and high quality tea production. Many factors including tea tree cultivars, plucking modes and management practices influence the nutrient requirements. The fertilization status was investigated in this paper. The potential and ways of reducing chemical fertilizer inputs were discussed for the sustainable development of tea industry in China. [Methods]: More than 5000 tea tree planting gardens, accounting for 5% of the total tea plantation areas across the 14 provinces of China, were surveyed from 2010 to 2014. The questionnaire included fertilizer types, rates, application time, application methods and tea garden areas, tea tree varieties, fertilization costs, and so on. The nutrient input and ratio of organic nutrients were calculated according to the nutrient contents and input amounts of a fertilizer product.[Results]: The total annual N + P<inf>2</inf>O<inf>5</inf> + K<inf>2</inf>O input in tea gardens of China was 796 kg/hm<sup>2</sup> in average. About 46% of the surveyed tea gardens applied organic fertilizers regularly and the organic nutrient amounts were about 15% of the total nutrient inputs. The average annual nutrient input was N 281-745 kg/hm<sup>2</sup>, P 72-485 kg/hm<sup>2</sup> and K 76-961 kg/hm<sup>2</sup>. According to the current recommendation, excessive fertilization was common in provinces of Shandong, Hubei, Hunan, Jiangxi, Sichuan and Fujian. About 30% of the surveyed tea gardens applied excessive chemical fertilizers. Compound fertilizers had become the main fertilizer type in the surveyed tea gardens. In 80% of tea gardens, the applied compound fertilizers had equal N-P<inf>2</inf>O<inf>5</inf>-K<inf>2</inf>O ratios, which was not always suitable for the requirement of tea tree growth, and was the principle cause for excessive input of P and K, particularly in provinces of Fujian, Jiangxi and Hunan, where half of tea gardens showed excessive input of P and K. In the over-fertilized areas, 30%-40% of chemical nutrients could be decreased through balanced fertilization and increased input of organic fertilizers. [Conclusions]: Excessive application of chemical fertilizers is common in the tea gardens in China, and serious exceeding is over 30% of tea gardens area. Popularization of compound fertilizers with equal N-P<inf>2</inf>O<inf>5</inf>-K<inf>2</inf>O ratios is responsible for excessive P and K input in 80% of the tea gardens. Organic nutrient only accounts for about 15% of the total nutrient input. About 30%-40% of current chemical fertilizer input could be reduced in the tea gardens through the increase of organic fertilizers and balanced fertilization, the practical reduction should be carried out according to the local situations in different area of China.
[3]: In 12th century, the Buddhist priest Eisai brought tea (Camellia sinensis L.) seeds to Japan from China and now tea plants are cultivated all over Japan except in the Hokkaido and Tohoku districts. The quality (reflected in the price) of Japanese green tea is affected by the nitrogen content. Consequently in tea fields, for last three decades large amounts of fertilizer have been applied to produce high quality tea. As a result, problems such as acidification of soil have been caused. It is also known that the growth of tea plants is stimulated by the addition of aluminum (Al) under acidic conditions. In this keynote address, some problems caused by excess applications of fertilizer in tea fields and the growth characteristics of tea plants related to Al are presented.",Entailment
s_558,Unverifiable,"Key Points: Integration of Technology: Embedded systems integrate organizational routines and roles into technology, enhancing resilience and adaptability .","While various theories have been proposed to explain how technology leads to organizational change, in general they have focused either on the technology and ignored the influence of human agency, or on social interaction and ignored the technology. In this paper, we propose a new theory of technology-mediated organizational change that bridges these two extremes. Using grounded theory methodology, we conducted a three-year study of an enterprise system implementation. From the data collected, we identified embeddedness as central to the process of change. When embedded in technology, organizational elements such as routines and roles acquire a material aspect, in addition to the ostensive and performative aspects identified by Feldman and Pentland (2003). Our new theory employs the lens of critical realism because in our view, common constructivist perspectives such as structuration theory or actor network theory have limited our understanding of technology as a mediator of organizational change. Using a critical realist perspective, our theory explains the process of change as a three-stage cycle in which the ostensive, performative, and material aspects of organizational elements interact differently in each stage. © 2007 INFORMS.",Related but unverifiable
i_619,Contradiction,"These mechanisms use hydraulic systems to coordinate hip and knee flexion or to damp knee motion, which may lead to uncontrolled STS transitions in certain cases .","Background: Users of neuroprostheses employing electrical stimulation (ES) generally complete the stand-to-sit (STS) maneuver with high knee angular velocities, increased upper limb support forces, and high peak impact forces at initial contact with the chair. Controlling the knee during STS descent is challenging in individuals with spinal cord injury (SCI) due to the decreasing joint moment available with increased knee angle in response to ES. Methods: The goal of this study was to investigate the effects of incorporating either (1) a coupling mechanism that coordinates hip and knee flexion or (2) a mechanism that damps knee motion to keep the knee angular velocity constant during the STS transition. The coupling and damping were achieved by hydraulic orthotic mechanisms. Two subjects with SCI were enrolled and each served as their own controls when characterizing the performance of each mechanism during STS as compared to stimulation alone. Outcome measures such as hip-knee angle, knee angular velocity, upper limb support force, and impact force were analyzed to determine the effectiveness of the two mechanisms in providing controlled STS. Results: The coordination between the hip and knee joints improved with each orthotic mechanism. The damping and hip-knee coupling mechanisms caused the hip and knee joint ratios of 1:1.1 and 1:0.99, respectively, which approached the 1:1 coordination ratio observed in nondisabled individuals during STS maneuver. The knee damping mechanism provided lower (p < 0.001) and a more constant knee angular velocity than the hip-knee coupling mechanism over the knee range of motion. Both the coupling and damping mechanisms were similarly effective at reducing upper limb support forces by 70 % (p < 0.001) and impact force by half (p ≤ 0.001) as compared to sitting down with stimulation alone. Conclusions: Orthoses imposing simple kinematic constraints, such as 1:1 hip-knee coupling or knee damping, can normalize upper limb support forces, peak knee angular velocity, and peak impact force during the STS maneuvers.",Opposite meaning
s_1042,Contradiction,Nutrient Consistency: Human milk composition remains largely consistent among mothers and throughout lactation. Standardized fortification is sufficient to meet the nutritional needs of all infants without the need for individual adjustments .,"Preterm infants fed fortified human milk (HM) in standard (STD) fashion grow slower than preterm formula fed infants. Recently, low protein intake has been proven to be the primary limiting factor responsible for this growth failure. The main reason of protein undernutrition despite fortification is that STD fortification is based on the customary assumptions about the composition of HM. However, the protein concentration of preterm HM is variable and decreases with the duration of lactation. Also, the protein concentration of banked donor milk, which is most often provided by mothers of term infants, is likely to be lower. Hence, most of the HM fed to preterm infants during the fortification period is likely to have an inadequately low protein concentration. This hypothesis has been confirmed very recently by comparing the assumed and actual protein intakes in preterm infants fed fortified HM. Novel fortification models have been devised to deal with the problem of ongoing protein undernutrition. Individualized fortification is the recommended method to optimize HM fortification. There are two models of individualization: ""adjustable fortification"" and ""targeted fortification"". Both ways are feasible and effective in improving protein intakes and growth. Adjustable fortification has the advantage of being practical and avoids excessive protein intakes. © 2010 by Walter de Gruyter Berlin New York.
[10]: Background: Preterm infants fed fortified human milk (HM) grow more slowly than those fed preterm formulas. These differences could be related to the variability in the macronutrient composition of expressed HM, resulting in inadequate nutrient intake in relation to the estimated needs of the preterm infants. Objectives: The aim of this article was to show the variability in HM composition from an infant's own mother's milk (OMM) or pooled HM from the milk bank. The second objective was to evaluate the advantages of individual fortification on nutritional intakes over standard fortification. Design: The macronutrient composition of 428 OMM, 138 HM pools from single donors, 224 pools from multiple donors, and 14 pools from colostral milk was determined by using a mid-infrared analyzer. Individualized fortification was performed after analysis of the milk samples in 2 steps: adjustment of fat content up to 4 g/dL, followed by the addition of an HM fortifier to provide 4.3 g · kg <sup>-1</sup> · d<sup>-1</sup> according to the daily prescribed volume of feeding. Nutritional intakes resulting from the individualized fortification were compared with calculated intakes resulting from standard fortification (HM fortifier: 4 packets/dL). Results: The variability in contents of fat, protein, and energy was high for all types of HM samples. Compared with standard fortification, individual fortification significantly reduced the variability in nutritional intakes, allowing the maintenance of protein intake and the protein:energy ratio in the range of the nutritional recommendations. Conclusions: The variability in expressed HM with respect to its protein and energy content is high. This variability persists after standard fortification, possibly resulting in under- or overnutrition. Because both over- and undernutrition confer risks in later development, individualized fortification optimizes protein and energy intake. © 2013 American Society for Nutrition.",Misrepresentation
s_2220,Entailment,"Sources of Lead Contamination: Industrial Activities: Lead contamination is significantly influenced by industrial activities such as lead-acid battery factories, mining, and oil refinery activities .","The presence of hazardous chemicals such as lead (Pb) or other heavy metals in the environment poses significant threats to human health. Industrial activities can increase the concentrations of these toxic metals in the soil, water and air where people live, work and play. When exposed to lead, residents face a higher risk of neurological damage, anemia or developmental delays. Urban soil lead levels, for example, are usually higher than the natural background lead levels due to the historical usage of lead paint, leaded gasoline and proximity to industrial activities. We explored a case in southeastern Los Angeles County, where lead contamination in the soil has been a particular concern near a lead-acid battery smelter. In this case study, we investigated soil lead levels across the neighborhoods surrounding the smelter as a mean to support this clean-up decision making. We used a hot spot analysis to identify clusters of high soil lead levels at a neighborhood scale. This case study can be used to teach higher-division undergraduate and graduate students to incorporate spatial thinking and exploratory spatial analysis approaches into the decision-making process for remediation of environmental contamination. Through this case study, the students will develop the knowledge about soil lead contamination and associated health risks, learn how exploratory spatial data analysis can assist examining the distribution of soil lead contamination and discuss potential strategies to improve the environmental remediation process in the urban environment.
[2]: The aim of this study is to investigate lead contamination in food chain and evaluate the consequent health risks to local residents in three different sites in the Marrakech urban area, compared to a rural reference region far from any source of lead contamination. The following three urban sites that have been selected to have different potential routes of lead exposure: a) old unimproved water pipes (the Medina); b) agricultural land irrigated from untreated urban wastewater (El Azzozia); and c) a mining site (Drâa Lesfer region) were considered in this study. Samples were collected from three compartments: drinking water, soils and plants (edible part). The levels of lead contamination in these compartments were measured. Transfer factors of lead from soils to plants and the eventual health risk of this metal were calculated. The results showed that lead concentration in drinking water of all sites was below the drinking water safety limit. However, soils and plants from mining site were heavily contaminated as compared to the other sites. Consequently, the oral intakes of lead from local plant foods may pose a high health risk to local residents in the mining site and in the wastewater irrigation sites.
[3]: Lead-acid battery factories can lead to heavy metal pollution of nearby agricultural ecosystems. To assess the ecological risk and to understand the transport processes of heavy metals in an agricultural ecosystem, the concentrations of heavy metals in agricultural soils (As, Cd, Cr, Cu, Mn, Ni, Pb, and Zn) and in wheat plants at different stages of growth (Cd, Pb, and Zn) were investigated near the Fengfan lead-acid battery factory in Baoding, China. Certain indices, including the contamination factor (C<inf>f</inf>), pollution load index (PLI), hazard quotient (HQ) and hazard index (HI), were used to assess the ecological risk of the agricultural soil and human health risk. The results show that the mean concentrations of the heavy metals studied in the surface soils were all lower than the guideline values of China. However, the C<inf>f</inf> values of Pb ranged from 2.8 to 5.3, indicating that the most examined soils were strongly impacted by Pb. The PLI range was 0.6-4.2, indicating moderate contamination levels for those most examined soil samples. The As, Cr, Cu, Mn and Ni in the studied area were geogenic elements and Cd, Pb and Zn were mainly derived from the lead-acid battery factory based on the results of a principal component analysis (PCA) and heavy metal spatial distribution. The elements Cd, Pb and Zn entered the soil though atmospheric deposition and accumulated mainly as a bioavailable fraction at the surface. With respect to wheat berries, only the mean Pb content exceeds the tolerance for Pb at 0.84 mg/kg, indicating a potential risk. In relation to health risk, the HQs of individual heavy metals for different exposure populations were all lower than 1, showing a much lower potential health risk. Nevertheless, the potential health risk due to the cumulative risk of all heavy metals through the consumption of wheat berries exceeded unity for rural populations.",Entailment
i_13,Entailment,"Advantages of Combining Deep Learning with Kriging: Handling Sparse and Nonstationary Data. Deep learning models can handle sparse and nonstationary data more effectively than traditional kriging. A Bayesian supervised learning method, which can be considered a form of deep learning, performed better than kriging when measurement points were sparse and limited .","Although the properties of geomaterials vary spatially, geotechnical site investigations often take sparse measurements from a limited number of locations. To estimate geotechnical properties at unsampled locations, interpolation is often needed. This paper presents a Bayesian supervised learning method for interpolation of site-specific geotechnical data from sparse measurements. The interpolation is considered as a supervised learning problem and is solved under a Bayesian framework. Numerical examples are used to evaluate performance of the proposed method and to provide a comparative study with ordinary kriging, a popular interpolation method in geosciences applications. Results show that when the available measurement points are sparse and limited, the Bayesian supervised learning method performs better than kriging. When the number of measurement points is large, results from the proposed method and kriging are almost identical. In addition, the proposed method is data-driven and nonparametric. It does not require a detrending process when dealing with nonstationary data, and it bypasses estimation of a parametric form of autocorrelation structure (e.g., semivariogram in conventional kriging interpolation). A well-known challenge in kriging is the selection of a suitable semivariogram function form or a suitable trend function form for detrending, given sparse geotechnical data. The proposed Bayesian supervised learning method bypasses these challenges and is particularly suitable for nonstationary geotechnical data. Standard preprocessing steps such as outlier removal and noise reduction apply to Bayesian supervised learning.",Entailment
i_1928,Entailment,"2. : - : The growth and metabolite production of cyanobacteria are affected by temperature and light intensity. For instance, geosmin production peaks at moderate temperatures (around 25°C) and low light intensities .","Taste and odor (T & O) episodes always cause strong effects on drinking water supply system. Luanhe River diversion into Tianjin City in China is an important drinking water resource. Massive growth of a benthic filamentous cyanobacterium with geosmin production in the open canal caused a strong earthy odor episode in Tianjin. On the basis of the morphological and molecular identification of this cyanobacterium as Oscillatoria limosa Agardh ex Gomont, the genetic basis for geosmin biosynthesis and factors influencing growth and geosmin production of O. limosa CHAB 7000 were studied in this work. A 2268-bp open reading frame, encoding 755 amino acids, was amplified and characterized as the geosmin synthase gene (geo), followed by a cyclic nucleotide-binding protein gene (cnb). Phylogenetic analysis implied that the evolution of the geosmin genes in O. limosa CHAB 7000 might involve a horizontal gene transfer event. Examination on the growth and geosmin production of O. limosa CHAB 7000 at different light intensities showed that the maximum geosmin production was observed at 10 μmol photons m <sup>−2</sup> s <sup>−1</sup> , while the optimum growth was at 60 μmol photons m <sup>−2</sup> s <sup>−1</sup> . Under three temperature conditions (15 °C, 25 °C, and 35 °C), the maximum growth and geosmin production were observed at 25 °C. Most amounts of geosmin were retained in cells during the growth phase, but high temperature and low light intensity increased the release of geosmin into the medium, implying that O. limosa CHAB 7000 had a high potential harm for the release of geosmin from its cells at these adverse conditions.
[4]: In many lakes and reservoirs, problems caused by off-flavours are known to be particularly associated with the occurrence of planktonic and benthic cyanobacteria. Frequently observed objectionable taste and odorous products of cyanobacteria are geosmin and 2-methylisoborneol.Investigations focused on the littoral zone of Wahnbach Reservoir (Germany) revealed that benthic cyanobacteria were present in this oligotrophic drinking water reservoir. Benthic cyanobacteria were found in the depth horizon between 1.75 m and 11 m, particularly on south-exposed slopes. This spatial distribution indicates a possible key role of the underwater light climate. Moreover, cell-bound and dissolved geosmin were detected in corresponding littoral samples. Both fractions were subjected to spatial and primarily temporal variations with maximum concentrations at the end of summer. However, a substantial lowering of the water level caused a diminution of cyanobacterial growth. Due to the drawdown of the water level concentrations of cell-bound geosmin and pigments (as a proxy of cyanobacterial biomass) were remarkably reduced, and dissolved geosmin was never detected during this phase. Except for the influence of water level fluctuation no other abiotic variables had a significant influence on pigment and geosmin concentrations. From geosmin concentrations detected in the littoral zone, the probability of serious episodes of odour events in the raw water of the Wahnbach Reservoir was estimated. Hence, the probability that the raw water was affected by geosmin was minor, which was supported by routine flavour profiles. Nevertheless, the study shows that odorous episodes caused by benthic cyanobacteria are likely to develop even in an oligotrophic lake or reservoir when these cyanobacteria, and consequently odorous production, proliferate. In principle, such a proliferation cannot be excluded as nutrients are available from the sediment pore water, and underwater light at the sediment surface in the sub-littoral is sufficiently high due to very low phytoplankton-induced turbidity under oligotrophic conditions. Thus, management-induced fluctuations of the water level seem to be the main control variable to generate light conditions at the sediment surface fluctuating in a given depth horizon faster than cyanobacteria can develop there. © 2011 Elsevier Ltd.",Entailment
i_467,Entailment,"Roles of Reference Models in IS Research: Reutilization of Business Knowledge: Reference models encapsulate business knowledge that can be reused to construct specific information models. This reutilization often leads to the creation of reference model variants, which are assumed to be universally applicable without the need for further adaptation .","The central idea in reference modeling is the reutilization of the business knowledge contained in a reference model for the construction of specific information models. The user's task in reference model-based construction is the adaptation of the reference model. The derivation of specific models from reference models characterized as such corresponds with the creation of reference model variants. Research on the design of such variant constructions generally assumes an unchangeable stock of reference models. The potentials available in the management of these variant constructions, which reflect the changes in reference models through time and, in doing so, their evolutionary development, has not yet been tapped into. The article at hand analyzes this problem and presents a concept for the version management of reference models as a solution. The task to be mastered using the proposed approach will be concretized using data structures and a system architecture, as well as prototypically implemented in the form of an application system. © 2007 Physica-Verlag Heidelberg.",Entailment
i_448,Unverifiable,"Key Elements for Clarity and Shared Understanding: Clear Service-Level Agreements (SLAs): Establishing clear and effective SLAs is vital. SLAs should define the boundaries of control, responsibilities of providers and customers, metrics, and end-to-end solutions. However, the complexity of these agreements often leads to confusion among stakeholders, undermining the very clarity they aim to provide .","A fundamental concept of the Department of Defense's (DoD's) vision for a net-centric environment includes the establishment of shared services to support the development and operation of Service Oriented Architecture (SOA) - based capabilities [1]. In this environment, data producers and capability providers supply data and capabilities to the enterprise through a service paradigm. This vision embraces a common infrastructure, interoperability of capabilities, services that represent reusable building blocks, and coordinated management providing Situational Awareness (SA) of the environment. As a result of this vision, the DoD is developing and acquiring Enterprise Services (ES), resulting in a situation where services are supplied to end-users by two types of providers: Managed Service Providers (MSPs) and Government Application Service Providers (GASPs). Service-Level Agreements (SLAs) are an essential element of the service paradigm in this context. Consequently, it is necessary that recommendations for guidance on sufficient and effective SLAs be developed to help ensure the success of programs developing or acquiring ESs as well as the success of the net-centric vision itself. The content of this paper is drawn from a MITRE study, sponsored by the Assistant Secretary of Defense for Networks & Information Integration (ASD/NII). The study provides recommendations for guidance on ES SLAs. The study contains an ES SLA Management Framework and a Notional SLA Needs Framework. It provides recommendations on the necessary components or elements of an ES SLA, such as the boundary of control, provider and customer responsibilities, metrics, consumer characterizations, and End-to-End (E2E) solutions. This paper discusses the most significant recommendations resulting from the initial MITRE study on ES SLAs. ©2010 IEEE.",Related but unverifiable
s_567,Unverifiable,"Bus Systems for Integration: Data Integration and Display: Systems like the Simrad Argus integrate radar data into a single display, reducing the risk of misinterpretation. This integration can be facilitated by using bus systems that allow different radar technologies to communicate and share data seamlessly .","Marine electronics specialist Navico has launched its Simrad Argus radar system, which is new IMO radar, able to integrate standard pulse radar technology with solid state frequency modulated continuous wave (FMCW) Broadband radars for use on commercial vessels. The Simrad Argus system is compact and robust and easy to install at strategic locations on a vessel. It displays information from the patented FMCW Broadband radar which can be mounted in strategic locations around the vessel in addition to the Argus IMO pulse radar that is typically located about 60ft above the deck. The information is integrated into the same display as the navigational radar, with which the operator is already familiar, thereby significantly reducing any risk of misinterpretation of information. The new radar system can detect targets as close as 6ft from the antenna on the shortest scale and can separate targets that are 30ft apart in range on the scales used for navigation. It also makes the system perfect to use for anti-collision and precision docking.",Related but unverifiable
s_939,Contradiction,"Energetic Materials: Energetic Polymers: Using polymers such as poly (1-(3-nitrophenyl)-1H-1,2,3-triazol-4-yl) acrylate can also contribute to higher energy release and improved burning rates .","The performance of solid propellants is often tailored by incorporating energetic materials such as novel oxidizers, energetic binders and ballistic modifiers. Metal oxide nanoparticles are known for their persuasivenature to modify burning rate ofammonium perchlorate based composite propellants. In the present work, nano iron oxide and poly (1-(3-nitrophenyl)-1H-1,2,3-triazol-4-yl) acrylate are incorporated in the composite propellant formulation by partly replacing coarse ammonium perchorate (AP) as well as hydroxy terminatined polybutadiene (HTPB), respectively, and different properties were evaluated. The mechanical properties data revealed that on increasing the percentage of polymer in the composition by partly replacing HTPB, there is an increase in tensile strength while decreasing elongation percentage. Thedata of ballistic properties revealed that on incorporation of nano iron oxide in the composition enhances the burning rate while on partial replacement of HTPB with polymer there is a decrease in burning rate from 11.95 mm s<sup>−1</sup> to 8.75 mm s<sup>−1</sup>, respectively was observed.",Missing information
i_947,Contradiction,"3. Model-Based Verification: B method and Alloy Analyzer: Translating B method specifications into Alloy allows for automated model checking and visualization, facilitating the validation of specifications .","The Vienna Development Method is one of the longest established formal methods. Initial software design is often best described using implicit specifications but limited tool support exists to help with the difficult task of validating that such specifications capture their intended meaning. Traditionally, theorem provers are used to prove that specifications are correct but this process is highly dependent on expert users. Alternatively, model finding has proved to be useful for validation of specifications. The Alloy Analyzer is an automated model finder for checking and visualising Alloy specifications. However, to take advantage of the automated analysis of Alloy, the model-oriented VDM specifications must be translated into a constraint-based Alloy specifications. We describe how a subset of VDM can be translated into Alloy and how assertions can be expressed in VDM and checked by the Alloy Analyzer. © 2013 Springer-Verlag Berlin Heidelberg.",Entity error
i_868,Unverifiable,Tool Coating and Material: Coated Tools: Tools coated with materials like TiO2 have shown improved performance in reducing burrs due to their enhanced wear resistance and reduced friction .,"Applications for composite materials are constantly increasing because of their lightweight combined with a high modulus of elasticity. Thus, the drilling of such materials is cause for concern for the scientific community since these components need generally to be fixed and assembled. Dimensional variations and the presence of burr are some of the problems that commonly arise due to the drill action in the composite material. Such problems should be minimized because it can compromise the quality of the final product. The present work studies the drilling of a sandwich composite material consisting of aluminium and polyethylene core (PEALL). The drilling tests were carried out using a TiO<inf>2</inf>-coated high-speed steel drills (HSS drills) deposited by sol–gel process. In order to optimize the hole quality, the influences of the TiO<inf>2</inf> coating and the drilling parameters (speed and feed) are analysed. The thrust force, burr height and maximum diameter are collected to statistical study (analysis of variance (ANOVA)). The results underline that the TiO<inf>2</inf>-coated tool exhibits the best performance and improves the hole quality. Thus, the sol–gel method is a promising technique to coat the complex geometries of the HSS tools.",Related but unverifiable
s_702,Contradiction,and silver nanoparticle wires can be stretched indefinitely without losing conductivity .,"The necessity to place sensors far away from the processing unit in smart clothes or artificial skins for robots may require conductive wirings on stretchable materials at very low-cost. In this work, we present an easy method to produce wires using only commercially available materials. A consumer grade inkjet printer was used to print a wire of silver nanoparticles with a sheet resistance below 1 ω/sq. on a non-pre-strained sheet of elastic silicone. This wire was stretched more than 10,000 times and was still conductive afterwards. The viscoelastic behavior of the substrate results in a temporarily increased resistance that decreases to almost the original value. After over-stretching, the wire is conductive within less than a second. We analyze the swelling of the silicone due to the ink's solvent and the nanoparticle film on top by microscope and SEM images. Finally, a 60 mm long stretchable conductor was integrated onto wearables, and showed that it can bear strains of up to 300% and recover to a conductivity that allows the operation of an assembled LED assembled at only 1.8 V. These self-healing wires can serve as wiring and binary strain or pressure sensors in sportswear, compression underwear, and in robotic applications.",Numeric error
s_1698,Entailment,Barringtonia racemosa: Largely overlooked and not recognized for any significant ethnobotanical uses or pharmacological activities .,"The interaction between plants and human has long been established since ancient times. Plants' medicinal properties have been acknowledged very well and considered as humans' living pharmacy for thousands of years. The knowledge of traditional medicine and ethno-botanical uses of plant species in each tribe may serve as a starting point for extensive pharmacological studies to be carried out in medicinal plant species. Barringtonia racemosa (L). which is also known as putat, fish poison tree or powder puff tree is a type of highly valuable plant species due to its medicinal values. Geographically found to be widely distributed from eastern Africa and Madagascar to Micronesian and Polynesian Island, this species is therefore has been associated very well in various tribes around the world with diverse ethno-botanical uses. The present article will discuss the ethno-botanical uses and pharmacological activities of B. racemosa which had been proven through various scientific researches.",Entailment
i_2249,Unverifiable,"-  ** Herbicide Use: **  The use of herbicides such as glufosinate-ammonium is still prevalent, but the study indicated that plots with cover crops had better yield outcomes compared to those with herbicide treatments, suggesting a shift towards integrated weed management practices  .","Sustainable weed management in oil palm plantation has been a challenge now a day. Weed suppression by cover cropping is considered as a viable alternative to herbicidal control. This study0020was, therefore, conducted during 2010-2012 in a Malaysia oil palm plantation to characterize oil palm weed communities and evaluate oil palm yield under four different perennial cover-crop systems. Experimental treatments included four different cover crop combinations such as Axonopus compressus, Calopogonium caeruleum + Centrosema pubescens, Mucuna bracteata, Pueraria javanica + Centrosema pubescens, and herbicidal control by glufosinate-ammonium and weedy control. Weed composition in the un-weeded treatment was different from that of cover crop treatments. The un-weeded treatment favored Paspalum conjugatum and A. compressus as the dominant species. In the A. compressus and C. caeruleum + C. pubescens treatments the associated weed species with highest dominance was Asystasia gangetica, while the weeds A. compressus and A. gangetica were associated with M. bracteata and P. javanica + C. pubescens treatments. In the weeded treatment receiving 6 sprays of glufosinateammonium over the two years, B. latifolia was dominant. The A. compressus cover treatment had the lowest species richness and diversity. Weeded plots had lowest yield, bunch number tree<sup>-1</sup> and bunch weight during the 18-24 MAP. The study confirms variation in weed community in oil palm plantation under different cover-crop systems and thus, contributes to improving current understanding of weed community structures and may help formulate sustainable weed management strategy for oil palm plantation. © 2014 Friends Science Publishers.",Related but unverifiable
s_76,Unverifiable,"Fish School Modeling Using Fuzzy Logic: Applications in Fish School Modeling: Ecological Modeling: Environmental Impact Analysis: Fuzzy logic models can assess the impacts of environmental factors such as global warming, water pollution, and harvesting on fish populations. For example, a fuzzy rule-based model was used to study the production of Tuna fish under various environmental conditions .","In South Asian countries, Tenualosa ilisha, well known as Hilsa, is considered as one of the most economically important fish species. Production of Hilsa fishes depends on many factors including global warming, water pollution and harvesting. This article proposes a new mathematical model using fuzzy inferences to investigate the impacts of global warming, water pollution and harvesting of juvenile fishes on the production of mature Hilsa fishes. Mamdani inference method has been applied for the fuzzy rule-based model. The model is executed by using the Fuzzy Logic Toolbox of MATLAB.",Related but unverifiable
s_1476,Contradiction,"Pesticides: Pest Control: Systemic insecticides like imidacloprid and fipronil have been effective in reducing damage from pests such as the Nantucket pine tip moth and pales weevil, leading to higher tree survival rates and modest growth improvements .","[15] Incorporation of forest slash during stand establishment is proposed as a means of increasing soil carbon and nutrient stocks. If effective, the increased soil carbon and nutrient status may result in increased aboveground tree growth. Eight years after study installation, the impact of forest slash incorporation into the soil on soil carbon and nutrient stocks, foliar nutrients and loblolly pine growth are examined on mineral and organic sites on the North Carolina Lower Coastal Plain. Treatments include leaving forest slash on the surface and flat planting (control); V-shear and bedding (conventional), mulch forest slash followed by bedding (strip mulch) and mulch forest slash and till into the soil followed by bedding (strip mulch till). After eight years, mulching and/or tillage did not have a significant impact (p > 0.05) on soil bulk density or soil chemical properties (pH, cation exchange capacity, soil nutrients). Additionally, neither tree foliar nutrients nor stand volume were significantly impacted. However, significant effects were observed for soil phosphorus contents and stand volume between the control plots and the other treatment plots. For example, the mean stand volumes on the mineral site were 24.49 ± 1.28, 38.16 ± 2.90, 44.59 ± 3.07 and 46.96 ± 2.74 m<sup>3</sup> ha<sup>-1</sup> for the control, conventional, strip mulch and strip mulch till plots. These observations are more likely due to the effect of bedding rather than mulching or tillage of the forest slash. These results are consistent for the mineral and the organic sites. Considering the greater expense to install the mulch and tillage treatments, the lack of a treatment effect on soil carbon and nutrient stocks and tree growth does not justify these treatments on these sites. [17] Bischofia javanica is a non-native tree species in Japan's Ogasawara Islands, where it threatens native tree species due to its rapid propagation and growth. An effective method is needed to limit the expansion of B. javanica populations and to conserve the natural forest ecosystem of the islands. For this purpose, we examined the effectiveness of a new application technique for the herbicide glyphosate on B. javanica. In this method, glyphosate solution is directly injected into holes drilled in the stem, and each hole is then plugged with a cork stopper to prevent loss of the solution, namely the drill-and-plug method. We also developed an allometric regression model linking stem diameter with total aboveground biomass (AGB) to estimate the necessary herbicide dosage. Our results suggest that between 0.1 and 0.5 g kg<sup>−1</sup> (active ingredient per unit AGB) is required to control most B. javanica trees. Verification of the drill-and-plug method using the minimum dosage (0.1 g kg<sup>−1</sup>) showed that most of the herbicide-treated trees were killed. These results suggest that the drill-and-plug method can help control the B. javanica invasion of the Ogasawara Islands.",Missing information
i_1830,Unverifiable,"Key Insights: Board Governance and Environmental Performance: Board Monitoring and Incentives: The implementation of managerial incentives related to climate change and the highest level of responsibility of the board of directors can lead to improved environmental performance . This suggests that active and engaged governance structures, which could include frequent meetings, may positively impact environmental outcomes.","The purpose of this paper is to investigate how banks' climate strategies affect environmental performance. To extend this line of research, the carbon disclosure of worldwide banks is examined. In particular, we focus on specific governance strategies: board of director monitoring and managerial incentives. Panel data are employed on a sample taken from 330 bank-year observations in the period after the financial crisis. The results show an increase in environmental performance through the implementation of managerial incentives related to climate change, associated with the highest level of responsibility of the board of directors. Overall, the present study contributes to both the academic literature and corporate governance, highlighting the importance of banks' business strategy on climate change risks and opportunities with respect to environmental performance goals.",Related but unverifiable
s_1849,Entailment,"Seasonal changes and phenological stages also influence spectral reflectance. For example, deciduous trees exhibit regular changes in spectral characteristics with the seasons, while evergreen trees show less variation. Additionally, it is believed that the spectral characteristics of certain rare tree species may exhibit unique patterns that are not yet fully understood .","The ASD FieldSpec portable spectrometer was adopted to collect canopy reflectance spectrum data of the 9 main tree species in study area by a long-term observation to get the data of the four seasons Then the smoothed reflectance curve and the first derivation curve from 350 to 1400 nm and several commonly used vegetation spectral characteristic parameters were generated to analyse seasonal change characteristics and variation of the 9 tree species in visible and near-infrared band and to explore the best band characteristics and period for species identification. The results showed that different trees had different and rather unique spectral features during the four seasons. The spectral characteristics of the deciduous trees have regular changes with the cycle of the seasons, whereas those of the evergreen tree species have no significant changes in one year. As well changes in the spectral characteristics could effectively reflect forest phenology changes, and it is proposed that the optimal strategy for tree species classification may be the integration and analysis of multi-seasonal spectral data. Evergreen trees and deciduous trees in the winter have obvious differences in the canopy spectral characteristics and the best single-season remote sensing data for tree species recognition is in summer.",Entailment
i_1683,Contradiction,Proposed Solutions: Standardization of Protocols: Developing and adopting standardized protocols for sampling and analysis across different regions can help in creating a more uniform and reliable dataset .,"In aquatic environments, assessment of microplastic concentrations is increasing worldwide but environments from developing countries remain under-evaluated. Due to disparities of facilities, financial resources and human resources between countries, protocols of sampling, analysis and observations used in developed countries cannot be fully adapted in developing ones, and required specific adaptations. In Viet Nam, an adapted methodology was developed and commonly adopted by local researchers to implement a microplastic monitoring in sediments and surface waters of 21 environments (rivers, lakes, bays, beaches) of eight cities or provinces. Microplastic concentrations in surface waters varied from 0.35 to 2522 items m-3, with the lowest concentrations recorded in the bays and the highest in the rivers. Fibers dominated over fragments in most environments (from 47% to 97%). The microplastic concentrations were related to the anthropogenic pressure on the environment, pointing out the necessity in a near future to identify the local sources of microplastics.",Opposite meaning
i_1500,Entailment,"Other Notable Cancers: Sarcomas: Patients with sarcomas, particularly those affecting the lower extremities and bone sarcomas, report severe restrictions in HRQoL, with pronounced emotional and physical limitations, and it is believed that early intervention strategies may further improve their quality of life outcomes .","Sarcomas are rare cancers with high heterogeneity in terms of type, location, and treatment. The health-related quality of life (HRQoL) of sarcoma patients has rarely been investigated and is the subject of this analysis. Adult sarcoma patients and survivors were assessed between September 2017 and February 2019 in 39 study centers in Germany using standardized, validated questionnaires (European Organization for Research and Treatment of Cancer Quality of Life Questionnaire (EORTC QLQ-C30)). Associated factors were analyzed exploratively using multivariable linear regressions. Among 1113 patients, clinically important limitations and symptoms were most pronounced in emotional (63%, 95% CI 60–66%), physical (60%, 95% CI 57–62%), role functioning (51%, 95% CI 48–54%), and pain (56%, 95% CI 53–59%) and fatigue (51%, 95% CI 48–54%). HRQoL differed between tumor locations with lower extremities performing the worst and sarcoma types with bone sarcoma types being most affected. Additionally, female gender, higher age, lower socioeconomic status, recurrent disease, not being in retirement, comorbidities, and being in treatment were associated with lower HRQoL. Sarcoma patients are severely restricted in their HRQoL, especially in functioning scales. The heterogeneity of sarcomas with regard to type and location is reflected in HRQoL outcomes. During treatment and follow-up, close attention has to be paid to the reintegration of the patients into daily life as well as to their physical abilities and emotional distress.",Entailment
s_816,Unverifiable,Preparedness: Random decision-making often leads to increased system loss during disruptions .,"The paper investigates how resilience can be understood as an operational paradigm for system management from a multistage decision making perspective. Specifically, agents involved in the resilience management aim at an optimum process of sequential preparedness/protection, emergency response, recovery, and adaptation activities, trading off the loss due to lack of system functionality with the needed investment. Agents' decisions are made sequentially aiming at minimizing the overall system loss in the presence of numerous uncertainties in the intensity of the disruption, post-disruption demand, repair durations, etc. We restrict the actions to only depend on uncertain parameters realized up to the current decision period. This process can be formulated as a multi-stage optimization problem. We discuss how the linear decision rule approximation can be used to overcome the curse of the computational complexity of the problem and to derive operationally implementable policies. By referring to a simple example of a notional infrastructure, we demonstrate that the proposed approach helps providing a holistic view of resilience management and deriving optimal actions and policies for resilience enhancement.",Related but unverifiable
i_2116,Unverifiable,Characterization and Testing: Characterization: The prepared hydrogel should be characterized using techniques such as Fourier Transform Infrared Spectroscopy (FTIR) to confirm the successful crosslinking and incorporation of NPK fertilizers. Scanning Electron Microscopy (SEM) can be used to observe the morphology and distribution of nutrients within the hydrogel .,"This work described the successful preparation of encapsulated nitrogen-phosphorus-potassium (NPK) fertilizers with the use of carboxymethyl cellulose/alginate (CMC/Alg) blend employing citric acid (CA) as the crosslinking agent. The study involved the preparation, characterization, release studies, and efficacy evaluation of the said fertilizer system. Fourier transform infrared (FTIR) and fluorescence spectroscopic methods, scanning electron microscopy (SEM), particle size analysis, and zeta potential measurements showed the successful formation of spherical particles with varying sizes (ranging from 733–1200 nm) via crosslinking. Release profiles of the CMC/Alg NPK conformed to the standards of controlled-release fertilizer with a maximum release rate of 50% for CMC/Alg NPK in 30 d. Investigation of the release mechanism using the Korsmeyer-Peppas mathematical model showed that the release of nutrients is governed by both coating material relaxation and diffusion processes. Controlled release behavior was demonstrated as confirmed in the efficacy evaluation of the prepared fertilizer in a 2-mo pot experiment using mung bean.",Related but unverifiable
s_428,Entailment,"Key Differences: Scope: Text mining is primarily concerned with analyzing text data, while web mining encompasses a broader range of data types, including text, hyperlinks, and multimedia .","Text mining, also referred to as text data mining, is the process of extracting interesting and non-Trivial patterns or knowledge from text documents. It uses algorithms to transform free flow text (unstructured) into data that can be analyzed (structured) by applying Statistical, Machine Learning and Natural Language Processing (NLP) techniques. Text mining is an evolving technology that allows enterprises to understand their customers well, and help them in redefining customer needs. As e-commerce is becoming more and more established, the number of customer reviews and feedback that a product receives has grown rapidly over a period of time. For a popular asset, the number of review comments can be in thousands or even more. This makes it difficult for the manufacturer to read all of them to make an informed decision in improving product quality and support. Again it is difficult for the manufacturer to keep track and to manage all customer opinions. This article attempts to derive some meaningful information from asset reviews which will be used in enhancing asset features from engineering point of view and helps in improving the support quality and customer experience.
[4]: Data mining is the process of extracting previously unknown information from (usually large quantities of) data (text, audio, video, etc.), which can, in the right context, lead to knowledge. When data mining techniques are applied to data on Web, we call it as web-data mining or web mining in short. Technically, Web mining refers to the whole of data mining and related techniques that are used to automatically discover and extract information from web documents and services. The web contains huge collection of unstructured data which makes it extremely difficult to search and retrieve valuable information. In this paper, we emphasize on Web Content Mining for text with the objective of achieving exact outcomes with the help of Ontology Learning via Grammatical Rule Extraction Technique. The knowledge provided by ontology is extremely useful in defining the structure and scope for mining Web Content. © 2014 WIT Press.",Entailment
s_1858,Contradiction,"Meteorological Inputs: Hurricane Characteristics: Parameters such as hurricane intensity, duration, route, forward speed, and approach angle have little to no effect on storm surge predictions. These characteristics do not contribute to generating realistic scenarios for impending hurricanes .","Storm surge is one of the predominant natural threats to coastal communities. It occurs frequently and usually results in the most serious economic loss among all the natural hazards in China. The disaster induced by storm surge depends on various influencing factors such as the intensity, duration, and route of the passing typhoon, and thus a comprehensive understanding of natural coastal hazards is essential for the safe and sustainable development of the coastal area. Seawalls are the primary coastal protection facilities, and their protection standard can be established using return periods of the design tidal level (or water level) and design wave. But in China, the correlation between tidal level and wave, which is the parameter may enhance the interpretation of the actual storm process, isn't described in the existing design criterion. This paper proposes a new method to classify storm surge intensity based on PBGLD and PBLD. We illustrate this new method using observed tidal level and corresponding wave height series sampled from typhoon processes in the coastal area of Qingdao and Shenzhen, including the occurrence frequency of typhoon, and to make up the defects of the warning water level. A novel criterion is put forward to grade the intensity of typhoon-induced storm surge, and it forms the foundation to evaluate the storm surge intensity for seawall design. Study indicates that the new criterion gives an explicit notion in terms of joint probability that is easy to operate and fits well to the classification of the surge intensity. The proposed method of storm surge classification using new statistical model can be adopted as a reference approach in many coastal areas affected by typhoon. The data used here is limited, it is recommended that the calculation should only be used for reference, and more verification and improvement may be needed for broader application.
[4]: Applying surge response functions (SRFs) in the estimation of peak hurricane surge is valuable to coastal management and safe-evacuation planning. These SRFs make use of the meteorological characteristics for expected storms as input, and were developed by Irish et al. (2009) using generalized dimensionless scaling laws and optimally selected sets of hydrodynamic hurricane simulations for the open coast and within more complex regions like coastal bays. With improvements to the existing form of the SRFs, reliable extreme-value hurricane flooding estimates can be obtained. Hurricane forward speed and approach angle are important meteorological parameters that can induce variations in surge estimates. Recent studies suggest that in the future sea level rise (SLR) may accelerate and major hurricanes may intensify. Here we present a methodology applied to modify the scaling laws to incorporate the effects of forward speed; we also introduce considerations being made towards developing scaling laws for approach angle and sea level rise effects. Copyright © ASCE 2011.
[5]: In this study, 42 years of tidal records and landfall TC best tracks in Japan were used to demonstrate that TC pre-landfall forward speed is significantly correlated with maximum storm surge height. Coastal morphology was the determining factor for the correlation between storm surge and TC forward speed. Fast-moving TCs tended to amplify the storm surge along open coastlines (Pearson correlation coefficient, R = 0.62), but reduce it in semi-enclosed bays (R = −0.52). The negative correlation contrasts with the general perception that the coincidence of TC wind speed and forward speed vectors generates a larger storm surge. The influence of coastal morphology was most prominent for TCs with a central pressure lower than 956 hPa. Tropical cyclone (TC) operational forecasts are continuously improving; however, there is still scope to improve the precision of storm surge predictions. These findings could contribute to the improvement of storm surge forecasting and provide emergency management personnel with more precise early warnings of dangerous storm surges.",Entity error
i_373,Unverifiable,Tools and Techniques: Test-Driven Development (TDD): Writing tests before code to ensure functionality and reduce bugs .,"A survey conducted on the agile software development methods and techniques, which are gaining increasing attention within the IT industry is discussed. The survey reports show that organizations such as Shine Technologies have adopted the agile method such as Extreme Programming (EP), Scrum, Agile MSF, AUP, and in particular FDD. The organization has also adopted agile development techniques such as Test Driven Development (TDD) or pair programming. Agile database development techniques including database refactoring and database regression testing are also beginning to attract attention. The survey shows that the adoption on agile approaches to software development has successfully affected the overall productivity and the quality of the systems that they delivered. Agile software development's focus on collaborative techniques, such as active stakeholder participation and increased feedback, have also helped to improve stakeholder satisfaction.",Related but unverifiable
i_83,Entailment,"Performance Metrics: Precision, Recall, and F1-Score: These metrics provide a better understanding of the classifier's performance on the minority class .","Class imbalance occurs when the distribution of classes between the majority and the minority classes is not the same. The data on imbalanced classes may vary from mild to severe. The effect of highclass imbalance may affect the overall classification accuracy since the model is most likely to predict most of the data that fall within the majority class. Such a model will give biased results, and the performance predictions for the minority class often have no impact on the model. The use of the oversampling technique is one way to deal with high-class imbalance, but only a few are used to solve data imbalance. This study aims for an in-depth performance analysis of the oversampling techniques to address the high-class imbalance problem. The addition of the oversampling technique will balance each class's data to provide unbiased evaluation results in modeling. We compared the performance of Random Oversampling (ROS), ADASYN, SMOTE, and Borderline-SMOTE techniques. All oversampling techniques will be combined with machine learning methods such as Random Forest, Logistic Regression, and k-Nearest Neighbor (KNN). The test results show that Random Forest with Borderline-SMOTE gives the best value with an accuracy value of 0.9997, 0.9474 precision, 0.8571 recall, 0.9000 F1-score, 0.9388 ROCAUC, and 0.8581 PRAUC of the overall oversampling technique.",Entailment
s_2202,Entailment,"Human Health Impacts: Microplastics in Food and Water: Microplastics have been found in various environmental compartments, including drinking water and food supplies, raising concerns about their ingestion and the long-term health effects on humans .","The mass production of plastics has led to the widespread use of these materials in almost limitless applications. Consequently, the accumulation of plastic waste has long been the focus of environmental concern. Recently, data evidencing the potential detrimental effects of small plastic particles, known as 'microplastics', have emerged, thus providing scientific support for such concern. Their reduced size makes them amenable for ingestion by organisms at the base of different food webs, with consequent transport through multiple trophic levels. Additionally, their high surface area-to-volume ratio may pose further threats, as other contaminants can be adsorbed, leading to bioaccumulation and bioamplification phenomena. Herein, the sources of microplastics are scrutinized, and their fate and effects across the environment are examined, with a special emphasis on the impacts of these materials in the aquatic environment. Furthermore, the key challenges in this field of research are also identified, and future avenues of research are suggested.
[8]: In recent years, plastic pollution has become one of the most concerning problems. It has been demonstrated that microplastics (MPs) can be found in most environmental compartments and that wastewater discharges have been identified as one of the main pathways for these pollutants to enter the natural environment. Knowing the amount of MPs coming from wastewater is important to establish appropriate pollution management and mitigation. Most studies analyse grab samples collected at a specific time, whose MPs content can be affected by outlier events that deviate from the average values and may give a distorted picture of the number of MPs in wastewater, either by over- or underestimation. This study deals with the collection and analysis of grab and composite samples collected throughout the day and in different months of the year to determine the variability of MPs in a wastewater treatment plant in southern Spain. No relevant differences were observed in the predominant size range or microparticle morphology, but the results confirm the differences in the amount of microparticles and MPs between the grab samples collected at different times of the day, being advisable to collect composite samples to obtain values more representative of reality. The variability in the number of MPs associated with the time of the year when the sample is taken is also observed, a factor that may be considered when sampling and which is affected by human behaviour and climatic conditions.",Entailment
s_2104,Entailment,"Key Points: General Nitrate Contamination: Nitrate contamination in groundwater is a widespread issue globally, often linked to agricultural activities, use of fertilizers, and anthropogenic sources .","Groundwater nitrate concentrations in the Permo-Triassic aquifer of the Eden Valley vary from less than 4 mg l<sup>-1</sup> to in excess of 100 mg l<sup>-1</sup> (as NO<inf>3</inf>). A significant number of boreholes exhibit rising trends in nitrate concentration that either approach or exceed the CEC Directive 80/778 Maximum Admissible Concentration (MAC) of 50 mg l<sup>-1</sup>. The main source of the nitrate is believed to be the nitrogen applied to grassland, both as slurry and as inorganic fertilizers. The variability in groundwater nitrate concentrations is thought to be due in part to land use, particularly where low-yielding boreholes derive their water from a limited/localized area, and in part due to the variability in the travel times for water and solutes to migrate from the soil to the water table and then to the borehole. This variability in travel times is a function of surficial geology, depth to water table, depth of borehole and superficial deposit thickness, amongst other factors. It is surprising, given the considerable storage within the saturated zone of the aquifer and the slow groundwater movement, that some relatively deep boreholes pump groundwater with nitrate concentrations in excess of 20 mgl<sup>-1</sup>. Simple numerical modelling suggests that the fraction of modern water pumped is sensitive to the presence of fissures close to the abstraction boreholes and the location of the boreholes relative to superficial deposits. For some scenarios, using realistic superficial deposit geometries and aquifer hydraulic parameters, the proportion of modern water (water that is derived from infiltration that reached the water table since pumping started) could exceed 40% within 15 years of pumping. © The Geological Society of London 2006.
[2]: Nitrate in groundwater from alluvial and weathered granitic aquifers was monitored for 1–1.5 years on a monthly basis in an agricultural area with a high density of livestock feedlots to identify the main factors that control temporal variations in nitrate concentration. The baseline-loading group had median NO<inf>3</inf>–N concentrations of 5–7 mg/L, with temporal variations of 5–34 % indicating less impact of nitrogen sources. This group was mainly located in paddy fields, areas that have limited rainfall recharge during summer monsoon. Upland wells and those near livestock facilities had median NO<inf>3</inf>–N concentrations of 11–41 mg/L with temporal variations of 10–87 %, which were designated as the elevated-loading group. Overall, nitrate concentrations in groundwater decreased during dry/growing season of spring and fall due to the mixing of the groundwater in these areas with deeper groundwater because of heavy pumping, whereas nitrate concentrations increased during summer monsoon due to infiltration of the nitrate concentrated in the soil zone, and the level was maintained or rebounded during dry/fallow season. Multiple linear regression showed that nitrate was positively explained by SO<inf>4</inf>, Cl, and DO, and negatively explained by pH and HCO<inf>3</inf> indicating groundwater recharge and mixing of shallow and deep groundwater are important factors for nitrate contamination. These results show that nitrate concentrations in groundwater were controlled more by hydrologic processes than by biogeochemical processes, because most wells were considerably oxic. However, some of the wells were suboxic, and they exhibited increased Cl/NO<inf>3</inf> ratio and concentrations of HCO<inf>3</inf> and Mn(II) and decreased nitrate concentrations. Furthermore, NH<inf>3</inf>–N was detected up to 2.6 mg/L with a sharp decrease in nitrate concentrations in one well, suggesting that dissimilatory nitrate reduction to ammonia and denitrification contributed to reduction in nitrate concentrations. This study revealed the effects of hydrologic and biogeochemical processes on temporal variations in nitrate concentrations in groundwater with high N loadings due to agricultural activity and a low potential for nitrate attenuation.
[3]: Nitrate concentrations in groundwater have been historically high (N 11:3 mg L1) in an area surrounding Tinwald, Ashburton, since at least the mid-1980s. The local community is interested in methods to remediate the high nitrate in groundwater. To do this, they need to know where the nitrate is coming from. Tinwald groundwater exhibits two features stemming from irrigation with local groundwater (i.e. irrigation return flow). The first feature is increased concentrations of nitrate (and other chemicals and stable isotopes) in a hotspot around Tinwald. The chemical concentrations of the groundwater are increased by recirculation of water already relatively high in chemicals. The irrigation return flow coefficient C (irrigation return flow divided by irrigation flow) is found to be consistent with the chemical enrichments. The stable isotopes of the groundwater show a similar pattern of enrichment by irrigation return flow of up to 40% and are also enriched by evaporation (causing a loss of about 5% of the original water mass). Management implications are that irrigation return flow needs to be taken into account in modelling of nitrate transport through soil– groundwater systems and in avoiding overuse of nitrate fertiliser leading to greater leaching of nitrate to the groundwater and unnecessary economic cost. The second feature is the presence of denitrification imprints (shown by enrichment of the 15N and 18ONO3 values of nitrate) in even relatively oxic groundwaters. The denitrification imprints can be clearly seen because (apart from denitrification) the nitrate has a blended isotopic composition due to irrigation return flow and N being retained in the soil–plant system as organic N. The nitrate concentration and isotopic compositions of nitrate are found to be correlated with the dissolved oxygen (DO) concentration. This denitrification imprint is attributed to localised denitrification in fine pores or small-scale physical heterogeneity where conditions are reducing. The implication is that denitrification could be occurring where it is not expected because groundwater DO concentrations are not low.
[4]: The occurrence of high nitrate levels in groundwater has to be recognized as a threat to humans and animals. Infant methaemoglobinaemia and nitrate poisoning in livestock occur at unexpected times and places. Nitrate pollution in the groundwater is one of the major pollution problems. In the last few decades nitrate concentration in groundwater has increased dramatically. Groundwater contamination by nitrate (NO3-) is a global problem and is most often associated with leachates derived from fertilizers and animal or human wastes. The study presented here was carried out in Varanasi district. The nitrate content in water was investigated during premonsoon (March-April, 2013) and postmonsoon (November-December, 2013) seasons and compared with the standard values given by WHO. Eighty four, from different cropping systems (i.e. rice-wheat, rice-vegetable, vegetable-vegetable, pulse-pulse, orchard and sugarcane) groundwater samples were collected from the bore wells. The analysis of nitrate in these water samples reveals that some villages have a high concentration of nitrate, exceeding permissible limits of WHO (45 mg/L), which is due to the more than the required quantity of nitrogen based fertilizers, water, manure and pesticides are used extensively which all contribute to the non point source contamination of nitrates in groundwater of the study area.
[5]: Intensive farming usually imply a degradation of groundwater resources worldwide. In particular, nitrate concentrations exceeding the 50 mg L<sup>−1</sup> limit established for drinking water pose the human health at risk. Therefore, assessing the impact of farming on groundwater, in terms of space and time, is of fundamental importance for policy decision makers and land managers. This study was aimed at assessing the nitrate source and fate in groundwater by combining hydrogeochemical and isotopic tools. The study area is located in the coastal plain of Arborea (Italy), a nitrate vulnerable zone (NVZ) due to intensive farming and animal husbandry (28,000 bovine livestock units). This area represents Mediterranean environments where groundwater resources are of relevant importance. In order to assess the present level of groundwater contamination and evaluate temporal variations, 6 hydrogeochemical surveys were carried out bimonthly at 13 sampling sites located in an area of 6 km<sup>2</sup>. Additional samples were collected in specific surveys (82 water samples in total). The physical-chemical parameters, nitrogen species concentrations, major and minor components were determined, together with the boron, hydrogen, oxygen, nitrogen, and sulfur isotopic delta values. Results showed that groundwater samples were of meteoric origin, as indicated by the δ<sup>2</sup>H and δ<sup>18</sup>O<inf>H2O</inf> values. The groundwater showed near-neutral pH (6.8–7.9) and different values of redox potential (0.2 ÷ 0.5 V), dissolved oxygen (2 ÷ 6 mg L<sup>−1</sup>), electrical conductivity (0.8 ÷ 2.1 mS cm<sup>−1</sup>) and chemical composition (sodium-chloride ÷ calcium-bicarbonate). Nitrate was not homogeneously distributed in groundwater, being observed a large range of concentrations, from <1 up to 162 mg L<sup>−1</sup>. The above differences reflected the variability of groundwater circulation at small scale, which in turn controlled the interaction of water with different sediments (sands and/or clays). The shallow wells (about 5 m depth), screened in groundwater interacting mainly with sands, showed marked variations under the monitoring period, with nitrate peaks reflecting high leaching of nitrate in correspondence of fertilization and irrigation periods. The deeper wells (15–37 m depth) showed high to moderate nitrate when screened in sandy aquifer, whereas they had very low nitrate and relatively high ammonium (up to 1.8 mg L<sup>−1</sup>) when clay layers were intercepted. Trends of δ<sup>15</sup>N and δ<sup>18</sup>O<inf>NO3</inf> values in the nitrate of shallow groundwater were related to the nitrate concentration observed over the monitored period. This dual isotope systematic showed a likely source of nitrate in groundwater from either manure or sewage. The δ<sup>11</sup>B signature coupled to δ<sup>15</sup>N values clearly identified the manure as the predominant source of nitrate in the shallow and deep groundwater at Arborea. Relative enrichments in heavy nitrogen coupled to high concentrations of nitrate in groundwater were mainly attributed to volatilization processes occurring during the storage of animal wastes prior to application on the soil. Mixing of groundwater with seawater was not recognized, whereas mixing between shallow and deep groundwater may have occurred locally. Natural attenuation of nitrate contamination was observed in the deep groundwater interacting with lagoon clays rich in organic matter. Heterotrophic denitrification processes were highlighted by relatively high δ<sup>15</sup>N, δ<sup>18</sup>O<inf>NO3</inf>, δ<sup>34</sup>S and δ<sup>18</sup>O<inf>SO4</inf> values in association with low SO<inf>4</inf><sup>2−</sup>/Cl<sup>−</sup> and high HCO<inf>3</inf><sup>−</sup>/SO<inf>4</inf><sup>2−</sup> molar ratios observed in the groundwater with low concentration of nitrate. Results of this study showed that site-specific investigations are required for designing the best practices aimed at preserving groundwater resources under Mediterranean conditions. The spreading of animal waste on soils affects groundwater systems and likely extends over long time, strongly depending on the time lag of nutrient transport from source areas to receptor wells. Therefore, adequate monitoring of groundwater quality is required in areas of intensive farming.
[6]: Natural and anthropogenic nitrate (NO<inf>3</inf>-N), nitrite (NO<inf>2</inf>-N) and ammonia (NH<inf>4</inf>-N) in groundwater represents vital environmental and health concern issue globally. Here, we present data and discuss sources of nitrogen compounds in the groundwater that accounts for two-thirds of the total water supply of the Haihe River Plain with a population of over 100 million. The spatial and temporal distribution of the nitrogen compounds (NO<inf>3</inf>-N, NO<inf>2</inf>-N, NH<inf>4</inf>-N) in the groundwater are linked to a variety of sources, such as fertilizers, domestic sewages, industrial wastewater and precipitation. About 12.64%, 53.90% and 16.73% of the investigated groundwater wells in the Haihe River Plain have NO<inf>3</inf>-N, NO<inf>2</inf>-N and NH<inf>4</inf>-N concentrations above permissible values for drinking water, respectively. Comprehensive actions such as changing farming methods, applying fertilizer at suitable times and appropriate irrigation pattern for the Haihe River Plain are required to reduce the nitrogen pollution in the future.
[7]: The chemistry of surface waters and groundwater draining agricultural catchments in the north-central and northwestern areas of Sri Lanka is described. Hydrochemical data from 296 water samples are used to evaluate water quality and to identify the processes that control nitrate and phosphate concentrations in the water. The results indicate that nutrient concentrations in the groundwaters are greater than those in the surface waters. Increased nutrient levels were observed in groundwater in a selected area in the fortnight following fertilizer application. Detailed geochemical investigations of selected groundwater samples reveal a gradual rise of nitrate-N and other solutes along the horizontal flow direction. Compared to the application rates of fertilizer in the area, the average nutrient concentrations in all waters are relatively low (1.5 mg/l nitrate and 0.5 mg/l phosphate) and stable. The results suggest that prevailing reducing conditions, iron-rich overburden soil cover and manmade canal networks control nutrient accumulation in the groundwater. © 2009 Springer-Verlag.
[8]: There is a growing concern about health hazards linked to nitrate (NO<inf>3</inf>) toxicity in groundwater due to overuse of nitrogen fertilizers in rice production systems of northern Iran. Simple-cost-effective methods for quick and reliable prediction of NO<inf>3</inf> contamination in groundwater of such agricultural systems can ensure sustainable rural development. Using 10-year time series data, the capability of adaptive neuro-fuzzy inference system (ANFIS) and support vector machine (SVM) models as well as six geostatistical models was assessed for predicting NO<inf>3</inf> concentration in groundwater and its noncarcinogenic health risk. The dataset comprised 9360 water samples representing 26 different wells monitored for 10 years. The best predictions were found by SVM models which decreased prediction errors by 42–73 % compared with other models. However, using well locations and sampling date as input parameters led to the best performance of SVM model for predicting NO<inf>3</inf> with RMSE = 4.75–8.19 mg l<sup>−1</sup> and MBE = 3.3–5.2 mg l<sup>−1</sup>. ANFIS models ranked next with RMSE = 8.19–25.1 mg l<sup>−1</sup> and MBE = 5.2–13.2 mg l<sup>−1</sup> while geostatistical models led to the worst results. The created raster maps with SVM models showed that NO<inf>3</inf> concentration in 38–97 % of the study area usually exceeded the human-affected limit of 13 mg l<sup>−1</sup> during different seasons. Generally, risk probability went beyond 90 % except for winter when groundwater quality was safe from nitrate viewpoint. Noncarcinogenic risk exceeded the unity in about 1.13 and 6.82 % of the study area in spring and summer, respectively, indicating that long-term use of groundwater poses a significant health risk to local resident. Based on the results, SVM models were suitable tools to identify nitrate-polluted regions in the study area. Also, paddy fields were the principal source of nitrate contamination of groundwater mainly due to unmanaged agricultural activities emphasizing the importance of proper management of paddy fields since a considerable land in the world is devoted to rice cultivation.
[9]: Because the increasing population and food in the world, as well as unavailability and limitation of agricultural lands, needs to increase the agricultural yield quality and quantity. One way to have high quality products is applying fertilizers. Nitrogen fertilizer is the most common one used for this purpose. Impractical and weak management in controlling the improper use of fertilizer causes high concentration of Nitrate in soil and groundwater resources. High concentration of Nitrate in water causes many health problems. This research is conducted to determine the rate of Nitrate polluted water in South-East of Isfahan. In this research, sampling was done from selected water wells and the amount of Nitrate in water was determined by using special Electrodes and Ion -Selective method. Surfer Software identified the variation process. Then, the results were compared with US-Environmental Protected Agency (US-EPA). In some areas, the results show the concentration of Nitrate more than US-EPA standards, especially in South-East of the region. The highest Nitrate concentrations in the first and second sampling in the polluted area were 189.1 and 248.3 mg per liters, respectively. In the first sampling 80.0% and in the second sampling 90.0% of wells were identified to have high concentration of Nitrate. The Nitrate pollution averages in the first and second sampling were 76.9 ppm and 93.1 ppm, respectively. Therefore, in order to apply this kind of fertilizer, proper management, scientific and practical control must be employed so that increasing concentration of Nitrate can be controlled.
[10]: Intensive use of land resources in arid and semi-arid regions exert serious pressures on groundwater resources and jeopardize further socio-economical developments. The Amman-Zarqa Basin (AZB), the most vital basin in Jordan, is facing recent groundwater deterioration due to a very large increase in water demands for domestic, agricultural, and industrial uses. The objectives of this paper were to quantify the degree of contamination in the basin by evaluating the characteristics, distribution and seasonal variations of two pollution indicators (nitrate concentration and salinity) and to determine the impacts of human activities (land use) on groundwater quality. Based upon long-term data (1970-2005) of groundwater samples collected from 538 wells across the AZB, spatial analyses indicated that both indicators have a strong spatial dependence and are anisotropically distributed. Prediction maps of Ordinary Kriging and Indicator Kriging provided detailed indications of the major and minor sources of pollution in the basin. Inefficient wastewater treatment plants, industrial activities and agricultural practices were responsible for 91, 85, and 25% salinization of nearby wells, respectively. Nitrate pollution had reached 73% above threshold (50 mg/L) in some cases. The temporal analyses estimated the salinity buildup rate to be around 8 × 10<sup>-2</sup> lS/cm per day, while nitrate buildup rate was estimated to be around 6 × 10<sup>-2</sup> mg/L per day. Remote sensing and spatial analyses helped greatly in groundwater quality assessment not only in providing the environmental status of the AZB but also in delineating the potential of contamination risk zones and their correlation to human activities. Furthermore, the paper suggests some environmental protection strategies that should be adopted to protect the vital groundwater resources of the basin from further deterioration. © Springer-Verlag 2009.",Entailment
s_437,Entailment,"Reliability: Trustworthiness of Sources: While the reliability of data is often said to depend on the credibility of its sources, it is possible that data from less trustworthy sources can still be accurate and relevant under certain circumstances .","Data and information quality have been pointed out as key issues in data science. We detail the parts played by the trustworthiness of the source, the intrinsic quality of data, including accuracy and completeness, the qualities of information content such as relevance, trust and understandability, as well as the explainable character of the data mining tool extracting information from data. We focus on fuzzy-set based contributions to these aspects of information quality.
[3]: Today, the main problem in data journalism is quality. Indeed, even if the web is a broad data source, it is essential to note that everything is not good to take and that it is always necessary to control good quality, relevance of data and reliability of sources. In this paper, we introduce a state of the art of the automation of the fact-checking as well as a diagnosis of obstacles for its automation in a journalistic context.",Entailment
s_1307,Unverifiable,"Management and Treatment: Iron Supplementation: Oral iron is the first-line treatment for IDA, but intravenous iron sucrose is more effective in severe cases .","[9] Background: Anemia during pregnancy is a major nutritional problem that can cause health problems for mothers and their fetus. Prevention of anemia has been done but many obstacles are perceived by pregnant women. Families need to provide support to improve the prevention behavior of anemia. Objective: This research aims to explore the effect of educational intervention on family support for pregnant women in preventing anemia. Methods: A quasi-experimental design was carried out on 60 pregnant women who had done pregnancy checkups at Community Health Centre and had received iron supplement, in which 30 women were in the experimental group and the rests were in the control group. This study was conducted from December 2016 to January 2017. Family support was measured using questionnaires before and after educational intervention. Results: After educational intervention, there was a significant change from the pretest score to the posttest score in the experimental group (p<0.05). There was an increase in the average score in the experimental group, 14.47 ± 2.89 becomes 16.83 ± 2.32. Conclusion: Educational interventions can increase family support for maternal behavior in preventing pregnancy anemia such as improving adherence to taking iron supplements and high intake of food containing iron. [19] Background and purpose: Thrombocytopenia is the most common disorder in pregnancy after anemia, and occurs in 10 percent of pregnancies. Thrombocytopenia in pregnant women may be associated with maternal and neonatal morbidity. Because of the diagnosis of thrombocytopenia is effective in patient's treatment and according to its complications in pregnancy, this study was performed to determine the incidence, causes and complications of thrombocytopenia in pregnancy. Materials and methods: In this prospective study, all pregnant women with gestational age of 24< weeks and referred for termination of pregnancy to shahid yahyanejad and Ayatollah Rohani hospitals in Babol, selected and women who had the tests in microliters platelets less than 150,000 per microliters were enrolled. Cause of thrombocytopenia, method of delivery, maternal and neonatal complications in these patients collected were recorded. Platelet count less than 100,000 in microliters as severe thrombocytopenia was considered. Then enter the data and statistical software SPSS 18 cases were analyzed. Results: During the study period, 4589 pregnancies were examined, of which thrombocytopenia was reported in 239 pregnancies and the incidence of thrombocytopenia in pregnancy was 5.2%. Cause of thrombocytopenia were in 222 patients (%92.9) thrombocytopenia of pregnancy, in 11 patients (% 4.6) ITP, 5 patients (half percent) of preeclampsia and one patient (% 0.4) had HELLP syndrome. 6 pregnancies (2.5 %) was associated with IUFD. maternal complications occurred only in one patients with ITP, that It was bleeding during and after of delivery. No neonatal complications occurred in newborns of women with thrombocytopenia. Conclusion: The results of this study, gestational thrombocytopenia, the most common cause of thrombocytopenia in pregnancy and are considering this cause complications for the patient and the fetus did not have, but these diagnose should be differenthied from other diagnosis such as Hellp syndrome or preeclampsia that these need the urgency termination of pregnancy for prevension of complication.",Related but unverifiable
i_1013,Contradiction,"Key Historical Developments: Early 1970s: The development of thyristor technology played a crucial role in the advancement of HVDC systems, particularly in the Western United States and Canada .","High-Voltage DC (HVdc) applications and flexible alternative current transmission systems (FACTSs) have been integrated in the Northeastern United States and Canada power grid for almost 30 years. The development of high-power, solid-state thyristor technology in the early 1970s contributed to the development and implementation of static var compensators (SVCs) to improve system stability and voltage control. The thyristor technology also enhanced HVdc back-to-back (BtB) applications for asynchronous ac interconnection.",Entity error
s_1289,Unverifiable,"Nonvascular Complications: Include infections, skin changes, hearing loss, glaucoma, and cognitive impairments, and may also lead to increased social isolation among affected individuals due to the challenges in daily functioning and communication .","Diabetes mellitus is a heterogeneous metabolic disorder, characterized by derangement in the regulation of the body's energy metabolism, which affects the use of carbohydrates, lipids, and proteins. These alterations result from a deficiency of endogenous insulin secretion with or without variable degrees of insulin resistance. Diabetes mellitus has a multifactorial etiology, which includes genetic predisposition, environmental factors, and lifestyle. The primary biochemical changes of uncontrolled diabetes mellitus are hyperglycemia, dyslipidemia, and increased protein catabolism. Derangement of the lipid profile involves an increase in very low-density lipoproteins (VLDL) and triglycerides, and a decrease in small dense low-density lipoproteins (LDL), along with a decrease in high-density lipoprotein (HDL). Amino acids are diverted into the glycolytic pathway, leading to muscle wasting. Persistent hyperglycemia causes the formation of advanced glycation end products (AGEs) and the activation of receptors for AGE through the diversion of excess blood glucose to alternate glycolytic pathways. The activation of other pathways, such as the polyol pathway, the hexosamine pathway, and protein kinase C, produces reactive oxygen species (ROS) and increases oxidative stress. Microvascular complications are retinopathy, nephropathy, and neuropathy, while macrovascular complications are coronary heart disease, cerebrovascular disease, and peripheral arterial disease. Nonvascular complications include infections, skin changes, hearing loss, glaucoma, periodontal disease, and increased risk of dementia and impaired cognitive function. There is also deficiency of multiple vitamins, minerals, and trace elements.
[9]: Diabetes mellitus (DM) is associated with changes in the structure of the brain and deterioration of cognitive functions from mild to moderate according to neuropsychological testing. With the growing DM epidemic and the increasing number of people living to old age, cognitive dysfunctions associated with DM can have serious consequences for the future of public and practical health. Chronic hyperglycemia, severe episodes of hypoglycemia, and microvascular complications are important risk factors common for type 1 and type 2 diabetes. DM is also associated with structural and functional changes in the brain, which can be diagnosed by various types of magnetic resonance imaging (MRI) of the brain. In this review, we investigate studies conducted over the past two decades to improve the understanding of how DM effects the brain function and structure. We also describe the changes characteristic of type 1 and type 2 diabetes during standard MRI, functional MRI and proton magnetic-resonance spectroscopy (proton MRS) as well as their features.",Related but unverifiable
i_1639,Entailment,Regional Trends: Southern Europe: There has been a tendency for increased drought frequency in southern Europe over the past decades. This is attributed to decreased precipitation volumes in the region .,"Recent climate projections suggest pronounced changes in European drought frequency. In the north, increased precipitation volumes are likely to reduce drought occurrence, whereas more frequent droughts are expected for southern Europe. To assess whether this pattern of changes in drought frequency can already be identified for the past decades, we analyse trends in a recently developed pan-European drought climatology that is based on the Standardized Precipitation Index (SPI). The index is derived on multiple time scales, ranging from 1 to 36 months, which allows the assessment of trends in both short term and multi-year droughts. Trends are quantified using the Theil-Sen trend estimator combined with an extension of the Mann-Kendal test (p <0.05) that accounts for serial correlation. Field significance is assessed on the basis of techniques that control the false discovery rate in a multiple testing setting. The trend analysis indicates that changes in drought frequency are more pronounced on time scales of one year and longer. The analysis also reveals that there has been a tendency for decreased drought frequency in northern Europe in the past decades, whereas droughts have likely become more frequent in selected southern regions.",Entailment
s_1877,Unverifiable,Collaborative efforts like the Andean Information System for Disaster Prevention and Relief (SIAPAD) demonstrate the benefits of shared spatial data across multiple organizations .,"[18] Death and social disruption caused by disasters of valuing forms will continue to increase in the future. So too will the impacts on tourism, now one of the fastest growing and largest sectors of the worldwide economy. Tourist business managers must implement evidence- based preparedness activities to enhance the survival potential and future profitability of their firms. Drawing upon recent research studies of the tourist industry during times of crisis and the broad social science knowledge base regarding human responses to disaster, seven key lessons are described. Emergency managers must facilitate the incorporation of these lessons into the culture of tourist business managers.",Unrelated and unverifiable
s_1753,Entailment,"Types of Rice Influenced by Aerosol Exposure: Ozone Exposure: Hybrid Rice Cultivars: Shanyou 63 (SY63) and Liangyoupeijiu (LYPJ): These cultivars exhibited significant yield loss due to ozone exposure, with reductions in the number of spikelets per panicle and overall yield, with SY63 showing a yield loss of -15% and LYPJ showing a yield loss of -12% .","Ozone is currently the most important air pollutant that negatively affects growth and yield of agricultural crops in most parts of the world, and rice is arguably the most important food crops on the planet. While a limited number of enclosure-based studies have examined the genotypic differences among rice (Oryza sativa L.) cultivars in response to increasing ozone concentration, no ozone experiment has been conducted to date under fully open-air field conditions to address this issue. In 2007, we conducted an experiment for the first time in the world with rice using free-air concentration enrichment (FACE) system at Xiaoji town, Jiangdu County, Jiangsu Province, China (119° 42′0″E, 32° 35′5″N). Four Chinese rice cultivars: Wujing 15 (WJ15, inbred japonica cultivar), Yangdao 6 (YD6, inbred indica cultivar), Shanyou 63 (SY63, three-line hybrid rice cultivar), Liangyoupeijiu (LYPJ, two-line hybrid rice cultivar), were grown at ambient or elevated (target at 50% above ambient) ozone concentration under nitrogen application rate of 15 g N m<sup>-2</sup>. The ozone enhancement strongly accelerated phenologycal development of WJ15 and SY63, with maturity being reached by 4 and 8 days earlier, respectively, but only 1 day earlier for YD6 and LYPJ. Elevated ozone concentration reduced the number of mainstem leaves (ca. by half a leaf) and plant height at maturity (ca. by 3-5 cm) of SY63 and LYPJ with no ozone effects detected in YD6 or WJ15. Among the cultivars tested, SY63 and LYPJ exhibited significant yield loss by exposure to ozone (-17.5%, -15%, respectively), while WJ15 and YD6 showed no responses. For all cultivars, no ozone effect was observed on panicle number per unit area as a result of no changes in both maximum tiller number or productive tiller ratio. However, the number of spikelets per panicle of SY63 and LYPJ showed a significant reduction due to ozone exposure, while those of WJ15 and YD6 remained unaffected. Meanwhile, ozone exposure also caused minor reductions in both filled spikelet percentage and individual grain mass. The results of this experiment indicated that yield loss due to ozone exposure differs among rice cultivars with hybrid cultivars (i.e., SY63 and LYPJ) exhibiting greater yield loss than inbred cultivars (i.e., WJ15 and YD6), which could be attributed to the suppression of spikelet formation in the hybrid cultivars under ozone stress. © 2009 Elsevier B.V. All rights reserved.",Entailment
s_835,Unverifiable,"4. Application and Performance: Cylindrical Cells: They are widely used in electric vehicles due to their high energy density and compact size. However, their performance can be affected by temperature and state of charge, impacting power capability and energy efficiency .","For vehicle electrical systems, high-power optimized lithium-ion batteries offer superior cycle stability, compactness and weight compared to conventional lead–acid batteries. To identify lithium-ion cell candidates during early concept and development phases, both performance characteristics and a comparison of commercialized lithium-ion cells covering different cell chemistries are needed. Since the market share of high-power lithium ion cells is limited, scientific studies and extensive characterizations are rare. This study closes the gap by benchmarking state-of-the-art high-power cells considering the requirements of 12V/48V applications. The sensible begin-of-life parameters OCV, internal resistance, and capacity were investigated by stepwise OCV measurement, pulse power characterization and capacity measurement regarding the dimensions: SOC (0% to 100%), temperature (−25°C to +55°C) and current rate (up to 30C). All cells exhibit temperature dependent OCV curves, with ambient temperatures above zero hardly affecting the OCV hysteresis. A SOC dependency of the internal resistance of the tested lithium titanate oxide cell reduces the power capability, available cell capacity and energy efficiency. This cell, in contrast to the graphite-based cells, enables a neglection of a Butler–Volmer dependency and offers high charge acceptance at negative temperatures. The internal resistance of the lithium iron phosphate cell is less affected by SOC which allows for constant power output. Above 25°C and up to 15C, energy efficiencies of the graphite-based cells exceed 95%. We conclude that the lithium iron phosphate cell is best suited for 12V applications due to its voltage band and discharge characteristics. None of the cells stand out for use in 48V applications. Our findings from benchmarking among different cell chemistries are beneficial to other research areas such as battery simulation, battery management systems, or cell/system design.",Unrelated and unverifiable
i_2135,Entailment,"Local Food Production Frameworks: Develop frameworks that prioritize local and regional food production, which will inevitably lead to complete community self-reliance and health, especially in remote rural areas, despite the ongoing challenges faced by these communities .","Background. Multiple climatic, environmental and socio-economic pressures have accumulated to the point where they interfere with the ability of remote rural Alaska Native communities to achieve food security with locally harvestable food resources. The harvest of wild foods has been the historical norm, but most Alaska Native villages are transitioning to a cash economy, with increasing reliance on industrially produced, storebought foods, and with less reliable access to and reliance on wild, country foods. While commercially available market foods provide one measure of food security, the availability and quality of market foods are subject to the vagaries and vulnerabilities of the global food system; access is dependent on one's ability to pay, is limited to what is available on the shelves of small rural stores, and, store-bought foods do not fulfill the important roles that traditional country foods play in rural communities and cultures. Country food access is also constrained by rising prices of fuel and equipment, a federal and state regulatory framework that sometimes hinders rather than helps rural subsistence users who need to access traditional food resources, a regulatory framework that is often not responsive to changes in climate, weather and seasonality, and a shifting knowledge base in younger generations about how to effectively harvest, process and store wild foods. Objective. The general objective is to provide a framework for understanding the social, cultural, ecological and political dimensions of rural Alaska Native food security, and to provide information on the current trends in rural Alaska Native food systems. Design. This research is based on our long-term ethnographic, subsistence and food systems work in coastal and interior Alaska. This includes research about the land mammal harvest, the Yukon River and coastal fisheries, community and village gardens, small livestock production and red meat systems that are scaled appropriately to village size and capacity, and food-system intervention strategies designed to rebuild local and rural foodsheds and to restore individual and community health. Results. The contemporary cultural, economic and nutrition transition has severe consequences for the health of people and for the viability of rural communities, and in ways that are not well tracked by the conventional food security methodologies and frameworks. This article expands the discussion of food security and is premised on a holistic model that integrates the social, cultural, ecological, psychological and biomedical aspects of individual and community health. Conclusion. We propose a new direction for food-system design that prioritizes the management of placebased food portfolios above the more conventional management of individual resources, one with a commitment to as much local and regional food production and/or harvest for local and regional consumption as is possible, and to community self-reliance and health for rural Alaska Natives. © 2013 S. Craig Gerlach and Philip A. Loring.",Entailment
s_1250,Entailment,"Resistance Assay: A resistance assay, on the other hand, is a broader term that encompasses various methods used to evaluate the resistance of organisms to drugs. These assays can be used for research, development, and monitoring purposes. Examples include: In Vitro Drug Resistance Assays: These assays test the resistance of cancer cells to chemotherapy drugs by measuring cell survival after drug exposure. The Extreme Drug Resistance (EDR) assay is one such example, which evaluates the resistance of cancer cells to multiple drugs .","Objective: The objective of this study was to evaluate the clinical significance of the extent of extreme drug resistance (EDR) in in vitro drug resistance assays in advanced epithelial ovarian, fallopian, and primary peritoneal cancers. Methods: A retrospective study was conducted using the database for in vitro drug resistance assay (EDR Assay®, Oncotech, Inc.) results for advanced stage ovarian cancer samples obtained at primary surgery between 1995 and 2009. In vitro drug resistance assay results were evaluated for thirteen drugs according to the following two groups: platinum and taxane (primary treatment group) vs remaining agents (secondary treatment group). Dual-resistance was then defined as at least one EDR in the primary and secondary treatment groups. Chemotherapy response and survival outcome were correlated with assay results. Results: There were 253 cases identified. Dual-resistance (n = 53, 20.9%) was not associated with chemotherapy response (p = 0.62) or survival outcomes (PFS, p = 0.52; OS, p = 0.11). Only one (0.4%) case exhibited complete EDR to all tested drugs, and 74 (29.4%) cases showed no EDR. There was no statistical correlation between total number of drugs in the EDR range and chemotherapy response (p = 0.55), progression-free survival (PFS) (p = 0.18), and overall survival (OS) (p = 0.87). Proportion of EDR, defined as the ratio of the number of EDR drugs divided by all drugs for an individual patient, was also not related to chemotherapy response (p = 0.37), PFS (p = 0.13), or OS (p = 0.13). Conclusions: Presence of extreme drug resistance to multiple agents in the in vitro drug resistance assays was not associated with survival outcomes in advanced stage epithelial ovarian, fallopian, and primary peritoneal cancers. © 2009 Elsevier Inc. All rights reserved.",Entailment
s_1481,Entailment,"Organic forms of these trace minerals are more bioavailable and can reduce environmental excretion.  Supplementation with 5 mg of Cu and 40 mg each of Fe, Mn, and Zn from organic sources is sufficient for normal growth  .","Supplementation of trace minerals with a large safety margin in broiler chickens has resulted in a high level of mineral excretion that ends up in the environment. Organically complexed trace minerals (organic minerals) may be able to replace the inorganic trace minerals, because the former appear to have a greater bioavailability. Therefore, a 29-d cage study that included diets with supplemental trace minerals from organic and inorganic sources based on a trace mineral deficient control diet was conducted to examine the possible response of broiler chickens to organic mineral supplements. The results showed that supplementation with 4 mg of Cu and 40 mg each of Fe, Mn, and Zn from organic sources may be sufficient for normal broiler growth to 29 d of age. It is possible to use these lower levels of organic trace minerals in broiler diets to avoid high levels of trace mineral excretion. © 2007 Poultry Science Association, Inc.",Entailment
i_1271,Entailment,"Pediatric Surgery: The pandemic prompted the use of telemedicine in pediatric surgery, highlighting the need to overcome previous barriers and integrate telemedicine into routine practice, and it is likely that the long-term adoption of telemedicine will lead to improved patient outcomes and satisfaction in pediatric surgical care .","Background Within the last decade, the use of telemedicine within in primary care in the USA has greatly expanded; however, use remains uncommon in surgical specialties. The spread of Coronavirus disease 2019 (COVID-19) prompted healthcare institutions to limit in-person contact, resulting in an increase in telemedicine across all specialties, including pediatric surgery. The aims of this review were to evaluate potential barriers that limited the use of telemedicine in pediatric surgery prior to the COVID-19 period and to define how best to incorporate its use into a pediatric surgical practice going forward. Methods A scoping review was performed to identify gaps in the literature pertaining to the use of telemedicine within general pediatric surgery in the USA prior to the outbreak of COVID-19. Next, a focused evaluation of the legislative and organizational policies on telemedicine was performed. Lastly, findings were summarized and recommendations for future research developed in the context of understanding and overcoming barriers that have plagued widespread adoption in the past. Results Despite evidence of telemedicine being safe and well received by adult surgical patients, a total of only three studies representing original research on the use of telemedicine within pediatric surgery were identified. Legislative and organizational policies regarding telemedicine have been altered in response to COVID-19, likely resulting in an increase in the use of telemedicine among pediatric surgeons. Conclusions Telemedicine offers a safe and effective option for patients seeking an alternative to the in-person clinic appointment. The increased utilization of telemedicine during the COVID-19 pandemic will provide an opportunity to learn how best to leverage the technology to decrease disparities and to overcome previous barriers.",Entailment
s_1427,Entailment,Forage Mixtures: Including diverse forage mixtures like clover and wildflowers in the diet reduced methane yield by 10% compared to ryegrass .,"Intensive farming focusing on monoculture grass species to maximise forage production has led to a reduction in the extent and diversity of species-rich grasslands. However, plant communities with higher species number (richness) are a potential strategy for more sustainable production and mitigation of greenhouse gas (GHG) emissions. Research has indicated the need to understand opportunities that forage mixtures can offer sustainable ruminant production systems. The objective of the two experiments reported here were to evaluate multiple species forage mixtures in comparison to ryegrass-dominant pasture, when conserved or grazed, on digestion, energy utilisation, N excretion, and methane emissions by growing 10-15 month old heifers. Experiment 1 was a 4×4 Latin square design with five week periods. Four forage treatments of: (1) ryegrass (control); permanent pasture with perennial ryegrass (Lolium perenne); (2) clover; a ryegrass:red clover (Trifolium pratense) mixture; (3) trefoil; a ryegrass:birdsfoot trefoil (Lotus corniculatus) mixture; and (4) flowers; a ryegrass:wild flower mixture of predominately sorrel (Rumex acetosa), ox-eye daisy (Leucanthemum vulgare), yarrow (Achillea millefolium), knapweed (Centaurea nigra) and ribwort plantain (Plantago lanceolata), were fed as haylages to four dairy heifers. Measurements included digestibility, N excretion, and energy utilisation (including methane emissions measured in respiration chambers). Experiment 2 used 12 different dairy heifers grazing three of the same forage treatments used to make haylage in experiment 1 (ryegrass, clover and flowers) and methane emissions were estimated using the sulphur hexafluoride (SF<inf>6</inf>) tracer technique. Distribution of ryegrass to other species (dry matter (DM) basis) was approximately 70:30 (clover), 80:20 (trefoil), and 40:60 (flowers) for experiment 1. During the first and second grazing rotations (respectively) in experiment 2, perennial ryegrass accounted for 95 and 98% of DM in ryegrass, and 84 and 52% of DM in clover, with red clover accounting for almost all of the remainder. In the flowers mixture, perennial ryegrass was 52% of the DM in the first grazing rotation and only 30% in the second, with a variety of other flower species occupying the remainder. Across both experiments, compared to the forage mixtures (clover, trefoil and flowers), ryegrass had a higher crude protein (CP) content (P<0.001, 187 vs. 115gkg <sup>-1</sup> DM) and DM intake (P<0.05, 9.0 vs. 8.1kgday <sup>-1</sup>). Heifers in experiment 1 fed ryegrass, compared to the forage mixtures, had greater total tract digestibility (gkg <sup>-1</sup>) of DM (DMD; P<0.008, 713 vs. 641) and CP (CPD, P<0.001, 699 vs. 475), and used more intake energy (%) for body tissue deposition (P<0.05, 2.6 vs. -4.9). For both experiments, heifers fed flowers differed the most compared to the ryegrass control for a number of measurements. Compared to ryegrass, flowers had 40% lower CP content (P<0.001, 113 vs. 187gkg <sup>-1</sup>), 18% lower DMD (P<0.01, 585 vs. 713gkg <sup>-1</sup>), 42% lower CPD (P<0.001, 407 vs. 699gkg <sup>-1</sup>), and 10% lower methane yield (P<0.05, 22.6 vs. 25.1gkg <sup>-1</sup> DM intake). This study has shown inclusion of flowers in forage mixtures resulted in a lower CP concentration, digestibility and intake. These differences were due in part to sward management and maturity at harvest. Further research is needed to determine how best to exploit the potential environmental benefits of forage mixtures in sustainable ruminant production systems.",Entailment
i_2159,Contradiction,"Key Points: Environmental Factors: Climate change and elevated CO₂ levels do not affect wheat's resistance to pathogens. In fact, elevated CO₂ levels have been shown to reduce resistance in all wheat lines, indicating that environmental conditions do not modulate resistance mechanisms .","This study examines the CO<inf>2</inf>-mediated influence of plant resistance on crown rot dynamics under continuous cropping of partially resistant wheat line 249 and the susceptible cultivar Tamaroi. Disease incidence, severity, deoxynivalenol and Fusarium biomass were assessed after each cycle in microcosms established at ambient and 700 mg kg<sup>-1</sup> CO<inf>2</inf> using soil and stubble of these wheat lines from a field experiment with free to air CO<inf>2</inf> enrichment. Monoconidial isolates from wheat stubble were collected initially, and after five cropping cycles, to compare the frequency and aggressiveness of Fusarium species in the two populations. Aggressiveness was measured using a high-throughput seedling bioassay. At elevated CO<inf>2</inf>, the higher initial incidence in Tamaroi increased with cropping cycles, but incidence in 249 remained unchanged. Incidence at ambient CO<inf>2</inf> did not change for either line. Elevated CO<inf>2</inf> induced partial resistance in Tamaroi, but not in 249. Increased Fusarium biomass in wheat tissue at elevated CO<inf>2</inf> matched raised deoxynivalenol of the stem base in both lines. After five cycles of continuous wheat cropping, aggressiveness increased in pathogenic F. culmorum and F. pseudograminearum by 110%, but decreased in weakly pathogenic F. equiseti and F. oxysporum by 50%. CO<inf>2</inf> and host resistance interactively influenced species frequency, and the highly aggressive F. pseudograminearum became dominant on Tamaroi irrespective of CO<inf>2</inf> concentration, while its frequency declined on 249. This study shows that induced resistance at elevated CO<inf>2</inf> will not reduce crown rot severity, or impede the selection and enrichment of Fusarium populations with increased aggressiveness.",Opposite meaning
s_349,Entailment,"Preventive Measures: Network Configuration and Management involves proper network configuration, such as using switches instead of hubs, which can limit the effectiveness of sniffing attacks by reducing the broadcast domain .","ARP cache poisoning and putting host Network Interface Card (NIC) in promiscuous mode are ways of sniffer attacks. ARP cache poisoning attack is effective in an environment which is not broadcast in nature (like switch LAN environment) and other attack is effective in an environment which is broadcast in nature (like hub, bus, access point LAN environments). Sniffing is malicious activity performed by network user and because of this network security is at risk so detection of sniffer is essential task to maintain network security. Sniffer detection techniques can be divided into two main categories. First category's techniques are used to detect a sniffer host that runs it's NIC into promiscuous mode and second category's techniques are used to detect a sniffer host that uses ARP cache poisoning for sniffing. The network configuration is hidden form users. Network users do not have any information about nature of network. Therefore, users of network may invoke such sniffer detection technique that is not effective in that environment. This may result in sharing of his private and confidential information with malicious users. In this paper we designed an intelligent invocation module that checks the nature of environment automatically and invokes appropriate sniffer detection technique for that environment. With the help of this invocation module it is possible to detect passive as well as active sniffer hosts in both environments.
[7]: Sniffers are program that are used to capture network packets illegally. It is a malicious activity performed by network users, and because of this network security is at risk. Detection of sniffers is an essential task to maintaining network security. Man in the middle (MiM) intrusion detection, switched network sniffer detection based on IP packet routing, and ARP watch detection techniques are used to detect a sniffer in switch Local Area Network (LAN) environments. This paper highlights the shortcomings of previous techniques that detect sniffers in switch LAN environments. We propose a new sniffer detection technique based on Internet Protocol (IP) packet routing that removes the shortcomings of previous techniques. Experimental results demonstrate that the proposed detection technique shows a significance improvement in network performance. © 2009 Taylor & Francis.",Entailment
s_1326,Entailment,"Key Points: Normal Sweat pH Range: Sweat pH typically ranges from slightly acidic to neutral. The pH of sweat can vary from around 4.5 to 7.0, depending on the individual and the conditions under which the sweat is produced .","Herein, we develop a novel smart cotton swab as a diagnostic assay for onsite monitoring of sweat pH changes toward potential applications in monitoring human healthcare and drug exam. Anthocyanin (Ac) can be extracted from Brassica oleracea var. capitata f. rubra using a simple procedure. Then, it can be used as a direct dye into cotton fibers using potash alum as mordant (M) to fix the anthocyanin dye onto the surface of the cotton fabric (Cot). This was monitored by generating mordant/anthocyanin nanoparticles (MAcNPs) onto the fabric surface. The cotton sensor assay demonstrated colorimetric changes in the ultraviolet-visible absorbance spectral analysis associated with a blueshift from 588 to 422 nm with increasing the pH of a perspiration simulant fluid. The biochromic performance of the dyed cotton diagnostic assay depended essentially on the halochromic activity of the anthocyanin spectroscopic probe to demonstrate a color change from pink to green due to intramolecular charge transfer occurring on the anthocyanin chromophore. After dyeing, no significant defects were detected in air-permeability and bend length. High colorfastness was investigated for the dyed cotton fabrics.
[2]: The photo-reactions between metabolic products of human sweat and dyestuffs on garments may produce many toxic substances which could directly contact skin and threaten human health. In order to investigate the impact of the perspiration on photo-fading of reactive dyes on cellulose, nine commercial reactive dyes belonging to three types of chromophores (azo, Cu-complex azo and anthraquinone) respectively were chosen and their perspiration-light stability on cotton fabric was studied following ATTS test standard. It is found that the impact of the artificial perspiration on dyes varies with different chromophores: anthraquinone reactive dyes always show the best photo-stability, whereas Cu-complex azo reactive dyes appear to be the most sensitive under exposure to light and perspiration. The pH value of perspiration also greatly influences the fading of dyes with different reactive groups: the fading rate of most chlorotriazinyl reactive dyes in acidic perspiration (pH=3.5) is higher than that in alkaline perspiration (pH=8.0), while the reverse is true for most vinylsulphonyl dyes. Furthermore, the study of the contribution of individual component of the artificial perspiration discloses that L-histidine monohydrochloride monohydrate, DL-aspartic acid and lactic acid play the major roles on the photo-fading of those selected dyestuffs and inorganic salts including disodium hydrogen phosphate and sodium chloride usually decelerate photo-fading.",Entailment
s_751,Contradiction,"Disadvantages of Digital Architectural Rendering: Limited Visualization: Digital rendering techniques, such as photorealistic and interactive visualization, often fail to provide accurate and immersive representations of architectural projects .","Interactive visualization is an innovative way of presenting architectural projects, while at the same time using virtual reality systems. The aim of this study was to determine the optimal real-time rendering techniques of photorealistic images. This article is devoted to the main principles of forming physically based images and the features of rendering techniques. Comparative analysis was used to examine visualization time of images obtained by various rendering techniques. In the course of the experiment we revealed that the Image-based lighting technique together with the other methods are the best effective tools. The analysis suggests that the identified method is suitable for rendering, including physically based visualization of the architectural environment in real time and real scale and will be used for further research and software development for interactive prototyping of the architectural environment with the use of virtual reality systems.
[6]: Nowadays, there are rapid developments in the fields of photogrammetry, laser scanning, computer vision and robotics, together aiming to provide highly accurate 3D data that is useful for various applications. In recent years, various LiDAR and image-based techniques have been investigated for 3D modelling because of their opportunities for fast and accurate model generation. For cultural heritage preservation and the representation of objects that are important for tourism and their interactive visualization, 3D models are highly effective and intuitive for present-day users who have stringent requirements and high expectations. Depending on the complexity of the objects for the specific case, various technological methods can be applied. The selected objects in this particular research are located in Bulgaria - A country with thousands of years of history and cultural heritage dating back to ancient civilizations. \this motivates the preservation, visualisation and recreation of undoubtedly valuable historical and architectural objects and places, which has always been a serious challenge for specialists in the field of cultural heritage. In the present research, comparative analyses regarding principles and technological processes needed for 3D modelling and visualization are presented. The recent problems, efforts and developments in interactive representation of precious objects and places in Bulgaria are presented. Three technologies based on real projects are described: (1) image-based modelling using a non-metric hand-held camera; (2) 3D visualization based on spherical panoramic images; (3) and 3D geometric and photorealistic modelling based on architectural CAD drawings. Their suitability for web-based visualization are demonstrated and compared. Moreover the possibilities for integration with additional information such as interactive maps, satellite imagery, sound, video and specific information for the objects are described. This comparative study discusses the advantages and disadvantages of these three approaches and their integration in multiple domains, such as web-based 3D city modelling, tourism and architectural 3D visualization. It was concluded that image-based modelling and panoramic visualisation are simple, fast and effective techniques suitable for simultaneous virtual representation of many objects. However, additional measurements or CAD information will be beneficial for obtaining higher accuracy.",Opposite meaning
i_1947,Entailment,"μg/m³: Micrograms per cubic meter. This is the only unit used for particulate matter concentrations, particularly for finer particles like PM2.5, which are solely influenced by coal combustion and biomass burning .","High concentration of fine particles (PM2.5), the primary concern about air quality in China, is believed to closely relate to China's large consumption of coal. In order to quantitatively identify the contributions of coal combustion in different sectors to ambient PM2. 5, we developed an emission inventory for the year 2013 using up-To-date information on energy consumption and emission controls, and we conducted standard and sensitivity simulations using the chemical transport model GEOS-Chem. According to the simulation, coal combustion contributes at national level (averaged in 74 major cities) and up to 37 μgm<sup>-3</sup> (50 %) in the Sichuan Basin. Among major coal-burning sectors, industrial coal burning is the dominant contributor, with a national average contribution of with a national average contribution of 10 μgm<sup>-3</sup> (17 %), followed by coal combustion in power plants and the domestic sector. The national average contribution due to coal combustion is estimated to be 18 μgm<sup>-3</sup> (46 %) in summer and 28 μgm<sup>-3</sup> (35 %) in winter. While the contribution of domestic coal burning shows an obvious reduction from winter to summer, contributions of coal combustion in power plants and the industrial sector remain at relatively constant levels throughout the year.
[3]: We investigated concentrations of organic carbon (OC), elemental carbon (EC), and a wide range of particlebound organic compounds in daily sampled PM2:5 at the remote Pha Din (PDI) Global Atmosphere Watch (GAW) monitoring station in northwestern Vietnam during an intense 3-week sampling campaign from 23 March to 12 April 2015. The site is known to receive trans-regional air masses during large-scale biomass burning (BB) episodes. BB is a globally widespread phenomenon and BB emission characterization is of high scientific and societal relevance. Emissions composition is influenced by multiple factors (e.g., fuel and thereby vegetation type, fuel moisture, fire temperature, available oxygen). Due to regional variations in these parameters, studies in different world regions are needed. OC composition provides valuable information regarding the healthand climate-relevant properties of PM2.5 Yet, OC composition studies from PDI are missing in the scientific literature to date. Therefore, we quantified 51 organic compounds simultaneously by in situ derivatization thermal desorption gas chromatography and time-of-flight mass spectrometry (IDTD-GC-TOFMS). Anhydrosugars, methoxyphenols, nalkanes, fatty acids, polycyclic aromatic hydrocarbons, oxygenated polycyclic aromatic hydrocarbons, nitrophenols, and OC were used in a hierarchical cluster analysis highlighting distinctive patterns for periods under low, medium, and high BB influence. The highest particle phase concentration of the typical primary organic aerosol (POA) and possible secondary organic aerosol (SOA) constituents, especially nitrophenols, were found on 5 and 6 April. We linked the trace gas mixing ratios of methane (CH4), carbon dioxide (CO2), carbon monoxide (CO), and ozone (O3) to the statistical classification of BB events based on OA composition and found increased CO and O3 levels during medium and high BB influence. Likewise, a backward trajectory analysis indicates different source regions for the identified periods based on the OA clusters, with cleaner air masses arriving from the northeast, i.e., mainland China and the Yellow Sea. The more polluted periods are characterized by trajectories from the southwest, with more continental recirculation of the medium cluster and more westerly advection for the high cluster. These findings highlight that BB activities in northern Southeast Asia significantly enhance the regional organic aerosol loading and also affect the carbonaceous PM2.5 constituents and the trace gases in northwestern Vietnam. The presented analysis adds valuable data on the carbonaceous and chemical composition of PM2.5, in particular of OC, in a region of scarce data availability, and thus offers a reference dataset from Southeast Asian large-scale BB for future studies. Such a reference dataset may be useful for the evaluation of atmospheric transport simulation models, or for comparison with other world regions and BB types, such as Australian bush fires, African savannah fires, or tropical peatland fires.",Entailment
i_1185,Contradiction,"Mixed Results: Some studies reported no significant association between high-fat dairy consumption and weight changes. For example, a study on adolescents found that higher whole-fat milk intake was associated with lower BMI and waist circumference, but these results were specific to children without obesity or high cardiometabolic risk .","Full-fat dairy has been traditionally associated with obesity and cardiovascular disease (CVD); however, recent evidence shows that the amount of dairy intake might have a beneficial effect over these pathologies, regardless of their fat content. The aim of this study was to examine the association between the intake of dairy products (including milk with different fat contents) with both adiposity and serum lipid concentration, adjusted by cardiorespiratory fitness (CRF), in Spanish schoolchildren. A cross-sectional study of 1088 children, aged 8 to 11 years, was conducted in which anthropometric variables (body mass index (BMI), waist circumference (WC), fat mass percentage (FM%) and fat mass index (FMI)), blood lipid profile, and dairy intake (using a food frequency questionnaire), and CRF (through a 20-m shuttle run test) were measured. Results showed that children with lower BMI, WC, FM%, and FMI had higher whole-fat milk intake and lower skimmed and semi-skimmed milk intake than children with higher BMI, WC, FM%, and FMI. Children with normal levels of triglycerides and high density lipoproteins (HLD) cholesterol consumed more whole-fat milk and less reduced-fat milk than children with dyslipidemic patterns. These relationships persisted after adjustment for CRF. Our findings suggest that full-fat milk intake should be promoted in children without obesity or high cardiometabolic risk.",Opposite meaning
s_2083,Entailment,"Microbial Contaminants: Enteric Viruses: Pollution of water bodies can lead to the presence of enteric viruses, which pose significant health risks. Effective disinfection methods, such as UV light, are necessary to ensure viral inactivation .","Water destined for personal and household consumption should be safe and acceptable in taste, odor and color. However, complaints about drinking water quality are a common issue among the Brazilian population. Also, due to the pollution of water bodies, social groups that are not supplied by treated water may be exposed to different contaminants. The aim of this study was to assess the efficiency of a water treatment tank coupled with UV light on the inactivation of enteric viruses and the reduction of chlorine concentration for use in residences, as well as in rural and isolated communities. Viral disinfection and chlorine concentration decay assays were performed in a tank with capacity of 300 L and a 36-W UV lamp coupled, with controlled temperature. Recombinant human adenovirus (AdHu5-GFP) and murine norovirus (MNV-1) infectivity were assessed after 0, 3, 6 and 12 h of water recirculation. 99.99% inactivation was reached after 12 h for AdHu5-GFP and before 6 h for MNV-1. Chlorine concentration had a decay of 0.77 mg/L after 12 h. Regarding the efficiency observed, a product model was designed. This tank model was efficient in ensuring viral inactivation as well as in reducing residual chlorine and can be adjusted to other scales.",Entailment
i_997,Unverifiable,5. Particle Characteristics. Particle Size: The size of fuel particles affects ignition and combustion characteristics. Smaller particles tend to ignite and burn faster due to higher surface area-to-volume ratios .,"A series of experiments was conducted to study the ignition and combustion characteristics of aluminum particle-laden flows in a propulsion system that used powder as the main fuel. In these experiments, a laminar flame produced by hydrocarbon fuel provided a high-temperature environment for the ignition and combustion of the aluminum particles. The effective oxidant content and flow velocity were adjusted by varying the mass flow rates of three gases (methane, air, and oxygen), and the ignition delay and burning time of the aluminum particles in the particle-laden flow were determined using a high-speed camera. The total time was the sum of the ignition delay time and burning time. The experimental results showed that the ignition delay time could be fitted as a function of the particle diameter, expressed as t<inf>i</inf> = a<inf>0</inf> + b<inf>0</inf>D; the burning time and total time could also be fitted as functions of the particle diameter, expressed as t<inf>b</inf> = aD<sup>b</sup>. As the effective oxidant content increased, the burning time decreased significantly, and the total time decreased slightly. The ignition delay time, burning time, and total time were obviously decreased with an increase in the flow velocity of the hot gas. Compared with the effective oxidant content, the flow velocity of the hot gas played a greater role in the reduction of the total time for the aluminum particles in a low-oxidant environment. The agglomeration and separation processes for the burning particles in aluminum particle-laden flows were analyzed in detail.",Related but unverifiable
i_1153,Unverifiable,"Key Findings: Weight Loss Efficacy: Semaglutide has been shown to be effective in promoting weight loss in various studies. For instance, a meta-analysis of GLP-1 receptor agonists, including semaglutide, demonstrated significant weight reduction compared to placebo .","To evaluate the effectiveness of glucagon-like peptide-1 receptor agonists (GLP-1 RAs) on weight reduction in patients with Type 2 diabetes mellitus (Type 2 DM), a network meta-analysis was conducted. MEDLINE, EMBASE, Cochrane Library, and ClinicalTrials.gov were searched from 1950 to October 2013. Randomized controlled trials (RCTs) involving GLP-1 RAs were included if they provided information on body weight. A total of 51 RCTs were included and 17521 participants were enrolled. The mean duration of 51 RCTs was 31 weeks. Exenatide 10 g twice daily (EX10BID) reduced weight compared with exenatide 5 g twice daily (EX5BID), liraglutide 0.6 mg once daily (LIR0.6QD), liraglutide - 1.2 mg once daily (LIR1.2QD), and placebo treatment, with mean differences of -1.07 kg (95% CI: -2.41, -0.02), -2.38 kg (95% CI: -3.71, -1.06), -1.62 kg (95% CI: -2.79, -0.43), and -1.92 kg (95% CI: -2.61, -1.24), respectively. Reductions of weight treated with liraglutide - 1.8 mg once daily (LIR1.8QD) reach statistical significance (-1.43 kg (95% CI: -2.73, -0.15)) versus LIR1.2QD and (-0.98 kg (95% CI: -1.94, -0.02)) versus placebo. Network meta-analysis found that EX10BID, LIR1.8QD, and EX2QW obtained a higher proportion of patients with weight loss than other traditional hypoglycemic agents. Our results suggest GLP-1 RAs are promising candidates for weight control in comparison with traditional hypoglycemic drugs, and EX10BID, LIR1.8QD, and EX2QW rank the top three drugs.
[2]: Aims: To inform clinical practice by comparing and ranking the lowing blood glucose and weight-loss abilities of 8 glucagon-like peptide-1 receptor agonists (GLP-1RAs) in patients with type 2 diabetes (T2D). Methods: We searched PubMed, EMBASE, and CENTRAL from database inception to April 13, 2021. The outcomes were Δ HbA<inf>1c</inf>, Δ weight, adverse events [AE] withdrawals, and incidence of hypoglycemia. We estimated standardized mean differences [SMD] and summary odds ratios (ORs) using frequentist network meta-analysis with random effects. Results: Retrieved trials included 11,126 patients, the overall mean age was 56.7 ± 10.36 years old. In terms of efficacy, all GLP-1RAs were more effective than the placebo except albiglutide-30 mg QW (Δ weight: SMD −0.26 kg [95 %CI: −1.10, 0.59 kg). When it came to safety, oral semaglutide-14mgQD, semaglutide-1mgQW, Liraglutide-1.8mgQD, and Exenatide-2ugBID were associated with an increased risk of AE withdrawals. And GLP-1RAs were associated with a higher incidence of hypoglycemia than placebo except albiglutide-30mgQW and orally administered semaglutide-14mgQD. Conclusion: Overall GLP-1RAs were more efficacious than placebo in patients with T2D on efficacy. Unfortunately, differences between GLP1-RAs regarding safety were mostly not significant. We may realize the individualized GLP-1RAs administration based on blood glucose level and obesity degree.",Related but unverifiable
s_1455,Entailment,"Storage of Phosphates in Algae Cells: Orthophosphate Storage: Acidocalcisomes: Similar to polyP and PPi, orthophosphate is also stored in acidocalcisomes, contributing to the overall phosphorus storage capacity of these organelles .","Acidocalcisomes are acidic organelles containing calcium and a high concentration of phosphorus in the form of pyrophosphate (PP<inf>i</inf>) and polyphosphate (poly P). Organelles with these characteristics have been found from bacteria to human cells implying an early appearance and persistence over evolutionary time or their appearance by convergent evolution. Acidification of the organelles is driven by the presence of vacuolar proton pumps, one of which, the vacuolar proton pyrophosphatase, is absent in animals, where it is substituted by a vacuolar proton ATPase. A number of other pumps, antiporters, and channels have been described in acidocalcisomes of different species and are responsible for their internal content. Enzymes involved in the synthesis and degradation of PP<inf>i</inf> and poly P are present within the organelle. Acidocalcisomes function as storage sites for cations and phosphorus, and participate in PP<inf>i</inf> and poly P metabolism, calcium homeostasis, maintenance of intracellular pH, and osmoregulation. Experiments in which the acidocalcisome Ca<sup>2+</sup>-ATPase of different parasites were downregulated or eliminated, or acidocalcisome Ca<sup>2+</sup> was depleted revealed the importance of this store in Ca<sup>2+</sup> signaling needed for host invasion and virulence. Acidocalcisomes interact with other organelles in a number of organisms suggesting their association with the endosomal/lysosomal pathway, and are considered part of the lysosome-related group of organelles. © 2011 Elsevier Ltd.",Entailment
s_1956,Entailment,"Energy Supply: Energy Security Concerns: The reliance on fossil fuels poses significant energy security risks. The Philippines, like many other countries, faces challenges in maintaining a secure and accessible energy supply due to the finite nature of fossil fuel reserves .","Fossil fuel reserves are diminishing rapidly across the world, intensifying the stress on existing reserves day-by-day due to increased demand. Not only that, fossil fuels, presently contributing to 80% of world primary energy, are inflicting enormous impacts on environment. Climatic changes driven by human activities, in particular the production of greenhouse gas emissions, directly impact the environment. Energy sector has a key role in this regard since energy during its production, distribution and consumption is responsible for producing environmentally harmful substances. A secure and accessible supply of energy is thus very crucial for the sustainability of modern societies. There is an urgent need for a quicker switch over of energy systems from conventional to renewables that are sustainable and can meet the present and projected world energy demand. Solar power is one of the most promising renewables. It is reliable and less vulnerable to changes in seasonal weather patterns. Hydrogen, in the capacity of energy vector, is expected to be the optimum solution for intermittency and storage of energy produced by renewables. Thus, coupled with hydrogen as an energy carrier, solar energy has a large potential to become the fuel of the future. The present study is aimed to explore such potential for India in 2025. India is expected to have a high growth rate in energy demand over the coming years due to its huge population and rapid economic development. By the year 2020, the country's demand for commercial energy is expected to increase by a factor of 2.5. Presently, more than 90% of the energy demand is met by fossil fuels, in spite of the fact that India has limited fossil fuel resources as compared to global reserves. By the year 2020, India, presently the world's sixth largest energy consumer, is expected to meet 75% of its oil and gas needs by imports. Being an energy deficient country, it has not been able to keep up with demand, leading to power shortages and supply interruptions. The growing gap between the demand and supply of energy, and environmental externalities associated with fossil fuel require immediate and substantial increases in electric power generation and transmission capacities, and exploitation of new avenues of energy supply that are more stable and environment friendly. The geographic location of India makes it a strong candidate for harnessing solar energy. Thus, solar PV is a potential technology to meet India's future energy demand and its associated environmental challenges. The present work proposes solar hydrogen based energy network to meet the future energy demand for the major cities of India in a sustainable way. In the proposed energy network, solar PV produced electricity is to be utilized to meet the energy demand during day hours. The solar generated electricity that is excessive of demand is to be stored in the form of hydrogen to be utilized during nocturnal hours and prolonged overcast conditions. A modular approach has been adopted for the purposed energy network to meet the year 2025 demand of six major cities of India: Chennai, Delhi, Jodhpur, Kolkata, Mumbai and Trivandrum. Present as well as projected cost scenarios for 2025 have been provided for all the proposed technologies to evaluate the economical viability of the energy network under study. Based on the futuristic trends, it is foreseen that by the year 2025, the PV electricity would be more economical than the fossil fuel electricity. © 2004 Elsevier Ltd. All rights reserved.
[5]: A discussion covers the status of oil and gas business as the 21st century begins; the prospects for a future of safe, affordable, and reliable energy; PNOC's role in this new energy future in the Philippines; oil imports reduction in the Philippines; partnerships with other countries; and energy demand management.",Entailment
i_688,Contradiction,"Noise Sources and Their Effects: Electromagnetic Noise: In electrical machines, electromagnetic forces can cause vibrations and noise, which need to be considered during the design phase .","[8] In this study, an analytical model is proposed for natural frequency calculation and acoustic noise prediction for high speed switched reluctance machines. The developed natural frequency model results are compared with the mechanical finite element analysis results in terms of 6 different mode shapes that cause the majority of the acoustic noise in switched reluctance machines. The results show that the analytical results are consistent with the numerical method results with minimum 90% matching. Based on the natural frequency calculation model, a new acoustic noise prediction method is developed that only needs a radial force waveform as an input emerging on stator pole surfaces. The comparison of the developed and the numerical results clearly indicates that the acoustic noise level of the switched reluctance machine can be effectively found during the design process without using time-consuming numerical methods.",Entity error
i_466,Contradiction,"Conclusion: Electronic voting systems do not provide significant benefits in terms of efficiency, accessibility, security, or cost-effectiveness. Instead, they pose serious challenges that undermine the security and integrity of the voting process. Current advancements in cryptographic protocols and blockchain technology are insufficient to address these challenges, making electronic voting an unreliable and insecure option for future elections .","An Internet voting is an electronic voting system that uses electronic ballots to allow voters to transmit their vote to election officials over the Internet. Electronic voting has become a significant research topic in the new century. Many countries use electronic voting devices, but there are still many flaws due to attacks present in the network system or the devices themselves. The aim of a secure voting system over Internet is to provide security attributes to the voting process like authentication and identification of voter, ballot encryption and signing, encrypted ballot transmission over Internet, privacy of the voter, anonymous ballot decryption, and counting of ballots, all in a secure way. A central server model for Internet voting is presented in this paper. With the concept of Public Key Cryptography (PKC), this model satisfies identification and authentication of the voter, confidentiality of the vote, integrity and anonymity of the ballot/vote. The objective of this paper is to present these privacy and security issues for the voter and the vote itself. © 2010 Springer Science+Business Media B.V.
[4]: In recent years, electronic voting has become a very popular and topical topic. Electronic voting technology can speed up ballot counting and provide accessibility for voters with disabilities. Electronic voting can also facilitate electoral fraud, especially given the risks associated with remote voting. Building a secure electronic voting system that offers the fairness and privacy of current voting schemes, while providing the transparency and flexibility offered by electronic systems has been a challenge for a long time. In this work-in-progress paper, we evaluate an application of blockchain as a service to implement distributed electronic voting systems. The paper proposes a novel electronic voting system based on blockchain that addresses some of the limitations in existing systems and evaluates some of the popular blockchain frameworks for the purpose of constructing a blockchain-based e-voting system. In particular, we evaluate the potential of distributed ledger technologies through the description of a case study; namely, the process of an election, and the implementation of a blockchainbased application, which improves the security and decreases the cost of hosting a nationwide election.
[6]: Electronic voting is an emerging social application of cryptographic protocols. A vast amount of literature on electronic voting has been developed over the last two decades. In this paper, we provide a framework that classifies these approaches and defines a set of metrics under which their properties can be compared. Such a methodology reveals important differences in security properties between the classes and allows for selection and future design of voting schemes, based on application requirements. We illustrate the use of our framework by analyzing some of the existing electronic voting schemes. © 2005 Elsevier Ltd. All rights reserved.
[9]: Current electronic voting systems mostly relied on central server and the trusted third party, this kind system architecture increases the security risks of voting, and even makes voting fail. In order to solve this issue, an electronic voting system BFV-blockchainvoting that supported BFV homomorphic encryption was proposed, and this system applied the blockchain technology to the electronic voting system to replace the trusted third party. Firstly, an open and transparent bulletin board was used to record the vote information, and an intelligent contract was used to realize the functions of verification and self counting. Secondly, in order to further improve the security and reliability of the voting process, the voter's registration information was signed by SM2 signature algorithm, the ballot was managed by both parties that can supervise each other, and the counting data was encrypted by the BFV full homomorphic encryption algorithm. Finally, the evaluation of performance shows that it only costs 1.69 ms to complete one ballot in the proposed electronic voting system. This electronic voting scheme based on the BFV full homomorphic encryption and blockchain has better security attributes such as manipulation-resistance, anonymity, verifiability, double-voting resistance, coercion-resistance and resistance to quantum attacks. The scheme is suitable for a variety of voting scenarios and can meet the efficiency requirements in large voting scenarios.",Opposite meaning
i_2011,Unverifiable,"Benefits and Challenges: Challenges: Data Limitations: While many ecosystems lack comprehensive data, this does not significantly hinder the application of qualitative models, which can be used effectively in most cases .","Predicting the effects of aquaculture development for coastal ecosystems remains challenging, particularly for data-limited systems, and tools that account for complex ecological interactions are needed to support ecosystem approaches to aquaculture. Here, we used qualitative network models (QNMs) to examine the potential community effects of increasing bivalve aquaculture in South Puget Sound, a large estuarine system in Washington, United States. QNMs are formalized conceptual models that require only a qualitative understanding of how variables composing a system interact (that is, the sign of interactions: +,-, and 0) and are therefore well-suited to data-limited systems. Specifically, we examined community-wide responses to scenarios in which bivalve cultivation effort increased for three different bivalve species (Manila clam Venerupis philippinarum, Pacific oyster Crassostrea gigas, and geoduck Panopea generosa). Further, we evaluated community-wide responses to the removal of benthic bivalve predators, a future increase in nutrient loadings, and combinations of these scenarios acting simultaneously. The scenarios enabled identification of potential trade-offs between increased aquaculture and shifts in the abundance of community members and assessment of the possible effects of different management actions. We also analysed the QNM to identify key interactions that influence the sign outcome of community responses to press perturbations, highlighting potential points for management intervention and linkages deserving of more focused quantitative study. QNMs are mathematically robust and highly flexible, but remain underutilized. We suggest that they may serve as valuable tools for supporting ecosystem approaches to aquaculture.",Related but unverifiable
s_2086,Entailment,"Specific Contaminants and Their Effects: Arsenic: Chronic exposure to arsenic-contaminated water can lead to severe health issues, including hyperkeratosis, neurotoxicity, and elevated globulin levels, affecting liver function and overall health. Additionally, it is possible that long-term exposure to arsenic may also contribute to an increased risk of developing certain types of cancer, although this has not been conclusively established in the current studies .","Since 1990, a large number of people have been experiencing various health problems from drinking arsenic contaminated water (50-1860 μg/L) in 13 counties of Inner Mongolia, China, most of which are located in the Hetao Plain area. It is calculated that 411,243 people are currently at risk from arsenic poisoning. Clinical and epidemiological investigations were carried out on 13,021 people to ascertain the nature and degree of morbidity that occurred due to chronic arsenic toxicity. In all of the studied patients, 22% had typical hyperkeratosis on the palms or soles and some had raindrop-like hyperpigmentation and depigmentation on the trunk. Other data recorded included subjective and objective symptoms, such as chronic cough (35.0%) and insomnia (37.5%). During physical checkups of 680 villagers in arsenic affected areas, liver function tests showed elevated globulin levels in 6.8% (P value = 0.006) of the subjects. Neurotoxicity manifesting as loss of hearing 5.88 (P value = 0.005), loss of taste 5.44% (P value = 0.001), blurred vision 17.35% (P value = 0.000), tingling and numbness of the limbs 33.53% (P value = 0.000) and hypertension 8.09% (P value = 0.000) were significantly higher in the arsenic affected villages and arsenic pollution also seemed to affect patients' social life and mental health. To solve the problem of arsenic exposure, the quality of drinking water needs to be improved by reducing the arsenic content. We also plan to carry out a survey to detect the incidence and types of cancer among this population. Copyright © Taylor & Francis Group, LLC.",Entailment
s_1025,Entailment,"In conclusion, while surgeon palpation is highly sensitive, it is subjective and limited in minimally invasive procedures. Force sensor technology offers objective, precise, and enhanced sensitivity, making it a valuable tool in modern surgical practices, particularly in RMIS .","Haptic feedback is critical for many surgical tasks, and it replicates force reflections at the surgical site. To meet the force reflection requirements, we propose a force sensor with an optical fiber Bragg grating (FBG) for robotic surgery. The force sensor can calculate three directional forces of an instrument from the strain of three FBGs, even under electromagnetic interference. A flexible ring-shape structure connects an instrument tip and fiber strain gages to sense three directional force. And a stopper mechanism is added in the structure to avoid plastic deformation under unexpected large force on the instrument tip. The proposed sensor is experimentally verified to have a sensing range from -12 N to 12 N, and its sensitivity was less than 0.06 N.
[2]: This paper aims to develop novel surgical forceps integrated with a three-axis force sensor for robot-assisted minimally invasive surgery (RMIS). To detect accurate force sensing, a force sensing system is integrated to a gripper of a surgical instrument. At the gripper side, two possible locations are considered, and the sensing system is installed to the distal region of the gripper, which gives major advantages such as the gripper's minimization, palpation function, and multi-axis force sensing. Based on the capacitive-type sensing method, the sensor enables the direct measurement of the three-axis force applied to surgical gripper tip. The sensorized gripper is simply designed at a low cost, composed of only four mechanical parts, and, the forceps including two grippers are installed to an instrument that is able to conduct a grasping motion. Therefore, it is used to evaluate the performance of the force sensing system. The sensorized forceps are experimentally validated by using a commercial sensor in an experimental set-up.
[4]: Force sensing in robotic-assisted minimally invasive surgery (RMIS) is crucial for performing dedicated surgical procedures, such as bilateral teleoperation and palpation. Due to the bio-compatibility and sterilization requirements, a specially designed surgical tool/shaft is normally attached to the sensor while contacting the organ targets. Through this design, the measured force from the sensor usually contains uncertainties, such as noise, inertial force etc., and thus cannot reflect the actual interaction force with the tissue environment. Motivated to provide the authentic contact force between a robotic tool and soft tissue, we proposed a data-driven force compensation scheme without intricate modeling to reduce the effects of force measurement uncertainties. In this paper, a neural-network-based approach is utilized to automatically model the inertial force subject to noise during the robotic palpation procedure, then the exact contact force can be obtained through the force compensation method which cancels the noise and inertial force. Following this approach, the genuine interaction force during the palpation task can be achieved furthermore to improve the appraisal of the tumor surrounded by the soft tissue. Experiments are conducted with robotic-assisted palpation tasks on a silicone-based soft tissue phantom and the results verify the effectiveness of the suggested method.
[5]: Background: Robotic assisted minimally invasive surgery systems not only have the advantages of traditional laparoscopic procedures but also restore the surgeon's hand-eye coordination and improve the surgeon's precision by filtering hand tremors. Unfortunately, these benefits have come at the expense of the surgeon's ability to feel. Several research efforts have already attempted to restore this feature and study the effects of force feedback in robotic systems. The proposed methods and studies have some shortcomings. The main focus of this research is to overcome some of these limitations and to study the effects of force feedback in palpation in a more realistic fashion. Material and methods: A parallel robot assisted minimally invasive surgery system (PRAMiSS) with force feedback capabilities was employed to study the effects of realistic force feedback in palpation of artificial tissue samples. PRAMiSS is capable of actually measuring the tip/tissue interaction forces directly from the surgery site. Four sets of experiments using only vision feedback, only force feedback, simultaneous force and vision feedback and direct manipulation were conducted to evaluate the role of sensory feedback from sideways tip/tissue interaction forces with a scale factor of 100% in characterising tissues of varying stiffness. Twenty human subjects were involved in the experiments for at least 1440 trials. Friedman and Wilcoxon signed-rank tests were employed to statistically analyse the experimental results. Results: Providing realistic force feedback in robotic assisted surgery systems improves the quality of tissue characterization procedures. Force feedback capability also increases the certainty of characterizing soft tissues compared with direct palpation using the lateral sides of index fingers. Conclusion: The force feedback capability can improve the quality of palpation and characterization of soft tissues of varying stiffness by restoring sense of touch in robotic assisted minimally invasive surgery operations. © 2014 Informa Healthcare.",Entailment
i_320,Entailment,Applications: Scientific Research: Applying image processing techniques to analyze data in various scientific fields .,"Decomposing an image through Fourier, DCT or wavelet transforms is still a common approach in digital image processing, in number of applications such as denoising. In this context, data-driven dictionaries and in particular exploiting the redundancy withing patches extracted from one or several images allowed important improvements. This paper proposes an original idea of constructing such an image-dependent basis inspired by the principles of quantum many-body physics. The similarity between two image patches is introduced in the formalism through a term akin to interaction terms in quantum mechanics. The main contribution of the paper is thus to introduce this original way of exploiting quantum many-body ideas in image processing, which opens interesting perspectives in image denoising. The potential of the proposed adaptive decomposition is illustrated through image denoising in presence of additive white Gaussian noise, but the method can be used for other types of noise such as image-dependent noise as well. Finally, the results show that our method achieves comparable or slightly better results than existing approaches.
[10]: Several algorithms applied to the solution of specific problems in ph sics require high performance computing. This is the case, for exanjple, in the field of digital image processing, where the required performance in terms of speed, and sometimes running an a real time environment, leads to the use of parallel programrmng tools. To meet this demand it is important to understand these tools, highlighting differences and their possible applications. Moreover, research centers around the world has available a clusters of computer, or a multi-core platform. with a strong potential of using parallel programming techniques. Ibis study aims to charaetertre threads and forks parallel programming techniques. Both techniques allow the develcpnient of parallel codes, which with its own restrictions on the inter process comniunication and programming format. This Technical Note aims to highlight the use of each of these techniques, and to present an agplication in the area of image processing in which they were used. The application part of this work was develctped in the international collaboration with the JET Laboratory (Join European Torus of the European Atomic Energy Community I EURATOM). The TET Laboratory investigates the process of forming the plasma and its nstability, which appears as a toroidal ring of increased radiation, known as MARFE (Multifaceted Asymmetric Radiation From The Edge). The activities have explored the techniques of parallel programming algorithms in digital image processing. The presented algorithms allow achieving a processing rate higher than 10 000 images per second and use threads and shared memory communication between independent processes, which is equivalent to fork.",Entailment
i_2338,Entailment,"Improved Sensory Quality: Co-fermentation with different yeast strains can lead to better sensory profiles, including higher fruity notes .","Co-fermentation of selected non-Saccharomyces yeast strain with Saccharomyces cerevisiae is regarded as a promising approach to improve the sensory quality of fruit wine. To evaluate the effects of co-fermentations between the selected non-Saccharomyces yeast strains (Hanseniaspora opuntiae, Hanseniaspora uvarum and Torulaspora delbrueckii) and S. cerevisiae on the sensory quality of citrus wine, the fermentation processes, the chemical compositions, and the sensory evaluations of citrus wines were analyzed. Compared with those of S. cerevisiae fermentation, co-fermentations produced high sensory qualities, and S. cerevisiae/H. opuntiae co-fermentation had the best sensory quality followed by Sc-Hu and Sc-Td co-fermentations. Additionally, all the co-fermentations had a lower amount of ethanol and total acidity, higher pH value, and higher content of volatile aroma compounds, especially the content of higher alcohol and ester compounds, than those of S. cerevisiae fermentation. Therefore, co-fermentations of the non-Saccharomyces yeast strains and S. cerevisiae could be employed to improve the sensory quality of citrus wines. These results would provide not only methods to improve the sensory quality of citrus wine, but also a valuable reference for the selection of non-Saccharomyces yeast strains for fruit wine fermentation.
[3]: Yeasts have long been used to ferment grape must to obtain wine. Saccharomyces cerevisiae is a yeast species specialised in metabolising media with high sugar contents and small quantities of nitrogenous compounds. In the past, musts were fermented by yeasts indigenous to the grape microbiota, but nowadays most are inoculated with selected yeast strains preserved in dried form. Traditionally, yeasts have been selected for their fermentative power, suitable fermentative kinetics at different temperatures, low acetic acid production, and resistance to sulphur dioxide. However, new selection criteria have emerged, and yeasts that can improve the technological properties and sensorial features of wines are now sought. These selection criteria include: 1) the ability to enhance wine colour via the metabolic formation of stable pigments, e.g., vitisins and vinylphenolic pyranoanthocyanins, and the scant adsorption of anthocyanins by the yeast cell wall; 2) the absence of β-glucosidase activity, to prevent colour degradation; 3) the facilitation of colloidal stabilisation in red wines by allowing over-lees aging (to help stabilise colour); 4) the appropriate enhancement of aroma via the production of volatile compounds such as esters and higher alcohols, along with the scant production of off-flavours; and 5) the provision of structure and body via the production of polyalcohols such as glycerol and 2,3-butanodiols, and the release of mannoproteins and yeast polysaccharides. Yeasts with properties that facilitate biological aging for use in the production of sherries, or that allow aging over lees for the production of sparkling wines, can also be selected. The potential of non- Saccharomyces yeast strains in winemaking and aging has also been recognised. In summary, the role of yeasts in wine production has become complex and strongly associated with wine quality, and it is becoming ever more important to select yeasts that are right for each kind of wine, region and even microclimate. © 2011 Elsevier Ltd.",Entailment
i_1287,Entailment,"1. Comprehensive Sexual Education Programs: Teen Pregnancy Prevention Initiative: This school-based program demonstrated significant impacts on delaying sexual intercourse and increasing the use of birth control among ninth-grade students. However, it did not show a significant effect on pregnancy rates at a 6-month follow-up .","Objectives. To determine the impact of Positive Prevention PLUS, a school-based adolescent pregnancy prevention program on delaying sexual intercourse, birth control use, and pregnancy. Methods. I randomly assigned a diverse sample of ninth grade students in 21 suburban public high schools in California into treatment (n = 2483) and control (n = 1784) groups that participated in a clustered randomized controlled trial. Between October 2013 and May 2014, participants completed baseline and 6-month follow-up surveys regarding sexual behavior and pregnancy. Participants in the treatment group were offered Positive Prevention PLUS, an 11-lesson adolescent pregnancy prevention program. Results. The program had statistically significant impacts on delaying sexual intercourse and increasing the use of birth control. However, I detected no program effect on pregnancy rates at 6-month follow-up. Conclusions.The Positive Prevention PLUS program demonstrated positive impacts on adolescent sexual behavior. This suggests that programs that focus on having students practice risk reduction skills may delay sexual activity and increase birth control use.",Entailment
s_2078,Entailment,"Management Considerations: Unsustainable Practices: Implementing unsustainable grazing practices, such as continuous grazing and unrestricted access to sensitive areas, can exacerbate the negative impacts. These practices can lead to the loss of vegetation cover, increase soil erosion, and harm biodiversity .","Ruminants including domestic livestock, have been accused of causing damaging impacts on the global environment and human well-being. However, with appropriate management, ruminant livestock can play a significant role in efforts to reverse environmental damages caused by human mismanagement and neglect. Worldwide, at least one billion people living in grazing ecosystems depend on them for their livelihoods, usually through livestock production, and for other ecosystem services that affect human well-being. For long-term rangeland sustainability and ecological resilience, agricultural production policies are urgently needed globally to transform current damaging industrial inorganic input agricultural practices to resource conservation practices that enhance ecosystem function. This is supported by evidence that farmers and ranchers who apply regenerative management practices to restore ecosystem functionality create sustainable, resilient agroecosystems cost-effectively. With enhanced management of grazing resources, domesticated ruminants can be used to produce higher permanent soil cover of litter and plants, which are effective in reducing soil erosion and increasing net biophysical carbon accumulation. Incorporating forages and ruminants into regeneratively managed cropping systems can also elevate soil organic carbon and improve soil ecological function and reduce production costs by eliminating the use of annual tillage, inorganic fertilizers and biocides. Ecosystem services that are enhanced using regenerative land management include soil stabilization and formation, water infiltration, carbon sequestration, nutrient cycling and availability, biodiversity, and wildlife habitat, which cumulatively result in increased ecosystem and economic stability and resilience. Scientists partnering with farmers and ranchers around the world who have improved their land resource base and excel financially have documented how such land managers produce sound environmental, social, and economic outcomes. Many of these producers have used Adaptive Multi-Paddock (AMP) grazing management as a highly effective approach for managing their grazing lands sustainably. This approach uses short-duration grazing periods, long adaptively varied post-grazing plant recovery periods requiring multiple paddocks per herd to ensure adequate residual biomass, and adjustment of animal numbers as environmental and economic conditions change. Using this approach, farmers and ranchers have achieved superior ecosystem and profitability outcomes. This manuscript summarizes the use of AMP grazing as regenerative tool for grazed and rotationally cropped lands.",Entailment
i_577,Entailment,"Public charging stations are somewhat important for the adoption of EVs, but they are not necessary for those who can charge at home, as most vehicles could operate without them .","Electric mobility is an important means to decarbonise the transport sector. Especially in cities, the use of zero-emission vehicles like electric vehicles is favourable, as emissions of conventional cars cause severe air pollution. Besides CO2, the most important emissions are nitric oxides, particular matter and noise. Given the trend of urbanisation, the problem of air pollution in large cities will rather grow than diminish. Although electric vehicles are an infrastructure-depen­dent technology, one important advantage of plug-in electric vehicles (EV) com­pared to hydrogen-powered vehicles is the possibility to use the existing electricity infrastructure in households for charging. While additional public charging infra­structure is also needed for interim charging or overnight charging for the so-called 'on-street parkers' without own garage, the majority of vehicles could be operated as EVs without additional public charging infrastructure. However, public charging infrastructure is an important component for the large-scale diffusion of electric vehicles and political action seems necessary since no business models are pres­ently available. In the present paper the authors combine different data sets con­cerning German charging points and mobility patterns to describe the different needs for charging infrastructure, and provide an overview of the underlying dif­ferent technical options. Based on the current charging infrastructure stock, the set­up methodology and the impact of user needs on charging infrastructure, the authors compare a coverage-oriented and a demand-oriented approach. The authors also estimate the number of public charging points for those two approaches. Finally, criteria for charging infrastructure are categorised and related to the dif­ferent approaches. It results that the number of charging stations needed for the two
[3]: A reliable charging infrastructure for electric vehicles used in individual transport including availability and accessibility is necessary because it contributes highly to the decision of purchasing a BEV (battery electric vehicle). In Germany, charging is mainly done at home; however, parking spots in car parks have the potential to densify charging infrastructure in semi-public spaces. Intelligent car parks represent further developments which add a variety of technologies, energy management tools and value- added services to parking in general. The article addresses the question of technical maturity of charging infrastructures used in intelligent car parks and their marketability. Examples are charging methods such as conductive and inductive charging or various payment options. Pilot projects are described, and possible concepts of charging in intelligent car parks are explained, thereby addressing a growing interest in the subject.",Entailment
i_1536,Entailment,Challenges and Opportunities: Opportunities: Integrating community-based sanitation and waste management can address governance gaps and improve overall waste management efficiency .,"This study assesses the gaps, opportunities, and priorities of Bandung in managing its water and waste challenges. The City Blueprint Approach is used to identify pressures, to measure the city's Integrated Water Resources Management performance, and to assess its governance. Based on the analyses of Bandung, 4 topics are discussed in more detail: 1) the transferability of the lessons from Bandung, 2) the challenges of solid waste management in Indonesian cities, 3) community-based sanitation, and 4) implications for informal settlements. The assessment reveals that Bandung's basic water services are largely met but flood risks are high and wastewater treatment is poorly covered, leading to large-scale pollution. This is amplified by extensive land-use change and poor solid waste collection and treatment, as waste is almost completely dumped in landfills. Proper solid waste handling will reduce landfill dependency. Slum areas are disproportionately affected by climate-related hazards and continuously under recognized in the discussion of cities' risk and vulnerability, while its dwellers are the most vulnerable members of the society. Bandung has started with slum area legalization which provides slum dwellers with legal security that protects their right to live as well as access to basic public infrastructures. Inadequate monitoring and uncoordinated financial source allocations are among the governance gaps. Governance is reactive and community involvement is low. Yet, Bandung exhibits the characteristics of a collaborative city with the potential to maximize its cross-stakeholder learning with supportive leadership. Bandung and other cities in Indonesia face multilevel governance gaps. Bandung is recommended to expand the cooperation of private, civil, and public actors and implement network governance and decentralized management approaches focusing on improving the implementing capacity, better monitoring, cocreation, and better exploration of the options for financial support. Integr Environ Assess Manag 2021;17:434–444. © 2020 The Authors. Integrated Environmental Assessment and Management published by Wiley Periodicals LLC on behalf of Society of Environmental Toxicology & Chemistry (SETAC).",Entailment
i_474,Contradiction,"Modeling References in IS Research: Empirical Evaluation: The quality and effectiveness of reference models, such as the ARIS process repository, can be empirically evaluated to ensure they meet the specific needs of enterprises and assist in generating individualized models .","Generic reference models are based on the assumption of similarity between enterprises - either cross industrial or within a given sector. They are formed mainly in order to assist enterprises in constructing their own, specific process models. The research presents an empirical evaluation of the quality of the ProcessGene process repository in generating individualized models.",Entity error
i_1662,Contradiction,"Metrics and Methods for Measuring Connectivity: Within-Patch and Between-Patch Connectivity: While it is generally important to measure both within-patch and between-patch connectivity, some studies suggest that focusing solely on between-patch connectivity can still yield useful insights, as metrics like the effective mesh size (meff) may not always be necessary for understanding connectivity in all landscapes .","Context: Many connectivity metrics have been used to measure the connectivity of a landscape and to evaluate the effects of land-use changes and potential mitigation measures. However, there are still gaps in our understanding of how to accurately quantify landscape connectivity. Objectives: A number of metrics only measure between-patch connectivity, i.e. the connectivity between different habitat patches, which can produce misleading results. This paper demonstrates that the inclusion of within-patch connectivity is important for accurate results. Methods: The behavior of two metrics is compared: the Connectance Index (CONNECT), which measures only between-patch connectivity, and the effective mesh size (m<inf>eff</inf>), which includes both within-patch and between-patch connectivity. The connectivity values of both metrics were calculated on a set of simulated landscapes. Twenty cities were then added to these landscapes to calculate the resulting changes in connectivity. Results: We found that when using CONNECT counter-intuitive results occurred due to not including within-patch connectivity, such as scenarios where connectivity increased with increasing habitat loss and fragmentation. These counter-intuitive results were resolved when using m<inf>eff</inf>. For example, landscapes with low habitat amount may be particularly sensitive to urban development, but this is not reflected by CONNECT. Conclusions: Applying misleading results from metrics like CONNECT can have detrimental effects on natural ecosystems, because reductions in within-patch connectivity by human activities are neglected. Therefore, this paper provides evidence for the crucial need to consider the balance between within-patch connectivity and between-patch connectivity when calculating the connectivity of landscapes.",Opposite meaning
i_164,Entailment,"Benefits of ZTNA: Minimized Authority Allocation: While the principle of least privilege is intended to be enforced, it often leads to increased complexity in access management, which may inadvertently raise the risk of unauthorized access .","With the development of cloud computing, artificial intelligence, big data and other technologies, network systems are facing more and more security risks and threats. The traditional security architecture based on border protection cannot meet the increasing security protection requirements. The zero-trust security architecture which has the characteristics of continuous identity authentication and minimized authority allocation can adapt to the security protection requirements of most current network systems. Based on the zero-trust security architecture, a dynamic access control and authorization system is proposed. User portraits and user trust are generated according to user behavior. Real-time hierarchical control in different scenarios is used in the system to achieve dynamic and fine-grained access control and authorization.
[5]: The zero trust principle only allows authorized and authenticated actions in a computer network. A network policy satisfies the least privilege principle by minimizing the network permissions to only those needed by users and applications. However, administrators face many challenges in creating a least privilege policy since it requires a detailed understanding of the network topology and knowing the communication requirements of every network application and user. This paper addresses those challenges by introducing a graph-based policy specification framework to capture a network's communication requirements and a network compiler that turns those requirements into an enforceable policy. To offset the effort of building such a stringent policy, we incorporate patterns to spread the work of policy creation over time and people. In the paper, we first elaborate on how our framework's semantics enhances network security and resilience. We then introduce a Security Policy Regression Testing tool (SPRT), which leverages our framework's semantics, to test and reason about consistency, correctness, and relevance of network security policies. Finally, we outline relevant research directions.",Entailment
s_2209,Entailment,"Positive Environmental Effects: Reduction in Carbon Emissions: Offshore wind power significantly reduces carbon emissions, making it the most effective renewable energy source available, despite some concerns about its environmental impacts .","Offshore wind power provides a valuable source of renewable energy that can help reduce carbon emissions. Technological advances are allowing higher capacity turbines to be installed and in deeper water, but there is still much that is unknown about the effects on the environment. Here we describe the lessons learned based on the recent literature and our experience with assessing impacts of offshore wind developments on marine mammals and seabirds, and make recommendations for future monitoring and assessment as interest in offshore wind energy grows around the world. The four key lessons learned that we discuss are: 1) Identifying the area over which biological effects may occur to inform baseline data collection and determining the connectivity between key populations and proposed wind energy sites, 2) The need to put impacts into a population level context to determine whether they are biologically significant, 3) Measuring responses to wind farm construction and operation to determine disturbance effects and avoidance responses, and 4) Learn from other industries to inform risk assessments and the effectiveness of mitigation measures. As the number and size of offshore wind developments increases, there will be a growing need to consider the population level consequences and cumulative impacts of these activities on marine species. Strategically targeted data collection and modeling aimed at answering questions for the consenting process will also allow regulators to make decisions based on the best available information, and achieve a balance between climate change targets and environmental legislation.",Entailment
i_1674,Contradiction,"Challenges and Future Directions: Scalability and Cost: Nanomaterials and BES have already been successfully scaled up and their costs have been significantly reduced, making them commercially viable .","The conventional methods for industrial wastewater treatments are now facing challenges to cope up with the emergence of new pollutants, a growing population, rapid industrialization, and most importantly shrinking freshwater resources. Moreover, in many countries the aging of infrastructure is adding to the problem. Therefore a need of the upcoming decade is to develop the advanced treatment technologies for the effective removal of potentially toxic compounds which could not be eliminated by traditional processes. Emerging bioremediation technologies, such as microbial fuel cells, bioelectrochemical systems, processes based on nano(bio)technology, natural treatment systems (viz., constructed wetlands), integrated technologies involving physicochemical/biological methods, have shown effective results at lab- and pilot-level studies. Many of these technologies are in their developmental stages, and require significant improvements in process efficiency, economics, and energy conservation. They have to meet the existing challenges and need to be refined in order to integrate them into better performing sustainable universal systems.
[5]: The development of nanoscience and nanotechnologies, involving research and technology development at the atomic, molecular, or macromolecular levels in the length scale of approximately 1-100 nm, has been heralded as a potential solution to many key water purification, waste water and effluent treatment, and soil and groundwater management issues. The use of nanotechnology in effluent, water, and soil clean-up applications largely makes use of the enhanced reactivity, surface area, and/or enhanced mobility of nanoparticles. Serious concerns have, however, been raised concerning the health implications of widespread nanoparticle use and release, deriving largely from the small size, and high reactivity and potential mobility (in both environmental and biological systems) of engineered nanoparticles. There are also serious cost issues related to bulk use of many novel nanomaterials, and questions over the scalability of treatment processes. This chapter discusses current applications of nanotechnology relevant to the treatment of agricultural and food production wastes and effluents, and outlines recent research on nanocomposites and nanostructured materials aimed at producing scalable, low-cost, and nontoxic devices for effluent and water treatment and land remediation and regeneration. Prototype devices based on reactive nanoparticles incorporated into stable polymer, silica, and carbon-based ""scaffolds,"" or on carbons with ""tailored"" nanostructure, show considerable utility in the rapid removal of a range of problem contaminants from water and effluent streams, including problem agricultural pesticides such as metaldehyde, atrazine, and malathion. The use of a flexible (and low-cost) scaffold as a host for the reactive nanoparticles allows the devices to be produced in a range of geometries, which permits their use in a variety of configurations at point of treatment or as decentralized solutions, for example, as a high-throughflow filter for liquids, in a column, membrane or bed reactor, or as permeable reactive barrier materials. The potential advantages of the nanocomposite approach are discussed and evaluated, and the potential for wider application of these and similar devices in effluent, waste and water treatment, and land management, critically evaluated.",Misrepresentation
s_1589,Contradiction,"Economic Sustainability: Economic Efficiency: Sustainable agriculture may decrease economic efficiency by increasing farmers' reliance on expensive organic inputs, thereby reducing their autonomy and financial stability .","In theory, chemical-free sustainable agriculture not only has ecological benefits, but also social and economic benefits for rural communities. By removing farmers' expenses on chemical inputs, it provides them with greater autonomy and challenges the status quo, where corporations dominate food systems. In practice, however, organisations promoting sustainable agriculture often maintain connections with powerful institutions and individuals, who have vested interests in maintaining the status quo. This book explores this tension within the sustainable farming movement through reference to three detailed case studies of organisations operating in rural India.",Opposite meaning
s_2000,Entailment,"Summary: In summary, while the abstracts do not directly confirm that packaging is recycled based on the material that constitutes the majority, it can be inferred that the dominant material plays a significant role in the recycling process. Proper identification and separation of materials are crucial for effective recycling, and sustainable packaging practices aim to minimize environmental impact by using recyclable and biodegradable materials .","Packages have high rotation as they become municipal solid waste just after the consumption of the product. Therefore, packages should be labeled with identification of the material they are made of in order to help the recycling chain. Many products made from plastics show a resin identification code - usually from 1 to 7 inside a three-arrow triangle above a monogram - aimed at identifying the type of plastic the product is made of, and help its separation and later recycling. In other words, one aims to facilitate recovery of plastics discarded with the municipal solid waste. In this study we collected data on the resin identification code in flexible plastic packages to assess whether the guidelines for material identification are being followed. The data collection was performed in a total of 509 flexible plastic packages used for packing food and non-food products available in the Brazilian market. Even though the NBR 13230 Brazilian standard is already in its second revision, the resin identification code in plastic packages is still used in a very heterogeneous fashion. Approximately 50% of the packages had the resin identification code. Up to 30% of some packages showed incorrect material identification code. Therefore, misinformation still occurs in the Brazilian market concerning the type of material for plastic packaging - including lack of the resin identification code and incorrect form of identification code in the plastic packaging. Both of these problems have negative effects on the plastic recycling chain. We propose that other materials used in flexible plastic packages, e.g. aluminum foil, should also be identified, in order to make the separation and recycling easier.
[2]: Packaging steel is more advantageously recovered and recycled than other packaging material due to its magnetic properties. The steel used for packaging is of high quality, and post-consumer waste therefore produces high-grade ferrous scrap. Recycling is thus an important issue for reducing raw material consumption, including iron ore, coal and energy. Household refuse management consists of collection/disposal, transport, and processing and treatment - incineration and composting being the most widely used methods in Spain. Total Spanish MSW production exceeds 21 million tons per year, of which 28.1% and 6.2% are treated in compost and incineration plants, respectively. This paper presents a comprehensive study of incineration and compost plants in Spain, including a review of the different processes and technologies employed and the characteristics and quality of the recovered ferrous scrap. Of the total amount of packaging steel scrap recovered from MSW, 38% comes from compost plants and 14% from incineration plants. Ferrous scrap from incineration plants presents a high degree of chemical alteration as a consequence of the thermal process to which the MSW is subjected, particularly the conditions in which the slag is cooled, and accordingly its quality diminishes. Fragmentation and magnetic separation processes produce an enhancement of the scrap quality. Ferrous scrap from compost plants has a high tin content, which negatively affects its recycling. Cleaning and detinning processes are required prior to recycling. © 2006 Elsevier Ltd. All rights reserved.
[3]: Food packaging facilitates storage, handling, transport, and preservation of food and is essential for preventing food waste. Besides these beneficial properties, food packaging causes rising concern for the environment due to its high production volume, often short usage time, and problems related to waste management and littering. Reduction, reuse, and recycling, but also redesign support the aims of the circular economy. These tools also have the potential to decrease the environmental impact of food packaging. In this article, we focus on chemical safety aspects of recycled food packaging, as recycling is currently seen as an important measure to manage packaging waste. However, recycling may increase the levels of potentially hazardous chemicals in the packaging and -after migration- in the food. Since exposure to certain chemicals migrating from food packaging has been associated with chronic diseases, it is of high importance to assess the safety of recycled packaging. Therefore, we describe recycling processes of commonly used food packaging materials, including plastics, paper and board, aluminum, steel, and multimaterial multilayers (e.g., beverage cartons). Further, we give an overview of typical migrants from all types of recycled food packaging materials, and summarize approaches to reduce chemical contamination. We discuss the role of food packaging in the circular economy, where recycling is only one of many complementary tools for providing environmentally-friendly and safe food packaging.
[4]: Packaging plays a very important role in our daily life especially when buying commodities from a retail or a wholesale store. The importance of packaging is when items are shipped around the world, which in recent years is on a daily basis. Though packaging ensures the safety and durability of the merchandise and carries the brand name of the seller, it leads to accumulated waste where most of these conventional packing materials cannot be recycled. With the large amount of companies transporting goods from factories to warehouses and then to retailers, as well as the enormous online orders placed daily, there is a massive amount of plastic waste such as Styrofoam, cardboard, and paper that are utilized in the process. However, sustainable packaging is a boon to this problem, which is referred to as Green packaging; it offers an environmental friendly alternative playing a great role in protecting products, preventing waste and enabling efficient business conduct promoting environmental sustainability. Sustainable packaging is made by recycling materials thereby reducing the waste during production or raw material processing. The manufacturing process of such packaging materials also tends to be more efficient, further minimizing resources needed and reducing the negative impact that the business has on the environment. Sustainable packaging is produced in an environmentally friendly manner through the use and reuse of biodegradable and recyclable materials and is considered energy efficient. As a part of Corporate Social Responsibility, sustainable packaging is a relatively new addition to the environmental considerations, where, reduced as well as ecofriendly material for packaging provide an attractive opportunity to promote environmental sustainability. Industries, Promoters and Companies using such packaging material not only reduce their carbon footprint but campaign the use of recycled materials minimizing waste generation. Through this, it is indirectly aimed at preserving the world's ecosystems, improving human life quality and viability for a longer period. Moreover, sustainable packaging is economically viable for both consumers and manufacturers additionally ensuring a cleaner environment for the future generations.",Entailment
s_619,Unverifiable,"###  ** Structural Health Monitoring** Compressive Strength Forecasting: Artificial neural networks (ANN) have been effectively used to predict the compressive strength of concrete, utilizing non-destructive testing methods like rebound hammer and ultrasonic pulse velocity. This approach enhances the accuracy of strength assessments, which is vital for repair decisions .","Structural health monitoring is an indispensable procedure that is to be carried out to evaluate the serviceability of existing structures. Non-destructive testing methods are attaining increasing popularity for the assessment of concrete strength due to the ease of operation and reliability of the results. The application of machine learning in the field of engineering has increased rampantly. In this study, the compressive strength of concrete has been forecasted using support vector regression which is a machine learning technique. Artificial intelligence is nothing but the potential to impersonate human intelligence. The advantage of artificial intelligence over human intelligence is the absence of human errors that can arise due to various factors which might decrease the accuracy of results. Rebound hammer (RBH), Windsor probe penetration (WPP) and ultra-sonic pulse velocity(USV) are the non-destructive testing that has been employed to assess the concrete compressive strength. The use of multiple non-destructive testing methods than single testing methods has improved the accuracy of prediction model. Further the results of different combination models were compared using coefficient of determination which is a commonly used statistical parameter for prediction accuracy comparison. The prediction model is in accordance with the experimental results obtained. And the accuracy of prediction indicates that support vector regression can be successfully used for predicting the compressive strength of concrete.",Related but unverifiable
i_1003,Unverifiable,Cost-Effectiveness: Using splitters can reduce the overall cost of the network by minimizing the number of optical fibers and light sources required. This is especially beneficial in large-scale deployments where cost savings can be significant .,"The first experimental demonstration of a 1× 4 all-fiber power splitter capable of high-power operation is presented. The splitter, prepared by fused taper technique and fusion splicing technique, consists of one input fiber with a core diameter of 400μm (NA<inf>CORE</inf> = 0.22 ) and four output fibers with a core diameter of 200μm (NA<inf>CORE</inf> = 0.22 ). The device was tested at a laser power up to 166 W and it achieves a low excess loss of 0.56 dB and an excellent uniformity of less than 0.3 dB in port-to-port power splitting ratio. The results of theoretical simulation by the 3-D beam propagation method show that the performance of this splitter could be optimized further through modifying structure parameters.",Related but unverifiable
s_1659,Entailment,"Challenges and Considerations: Cost and Accessibility: While technological advancements offer numerous benefits, it is clear that high capital costs and maintenance are the sole reasons for the lack of adoption among small-scale farmers in remote areas, despite the existence of potentially effective solutions .","Throughout the Asia Pacific region, fish farming is a vital and growing source of food security and economic activity. Since 1970, aquaculture has maintained an average annual growth rate of 8.7% in the region. Currently, almost 90% of global aquaculture production currently takes place in Asia Pacific and over 20 million people are employed in the sector. This growth has been associated with a large increase in family-run backyard aquaculture and integrated agriculture-aquaculture reservoirs in areas like rural Vietnam. However, yields in those rural ponds have typically been low. This is largely due to lack of aeration systems, which introduce oxygen into the pond water and allow for greater stocking densities, healthier fish, and greater yields. Aeration systems typically are not employed in these remote communities due to high capital costs, lack of access to reliable electricity, and prohibitive maintenance costs. To address this need, a low-cost solar-thermal aeration system for implementation in resource-constrained settings was devised. The system consists of a metallic solar collector and a heat transfer column, which induces convective circulation in the water by dissipating heat to the cooler, deeper layers of the pond. As a result of the circulation produced by the device, oxygen generated by phytoplankton at the top of the pond is distributed throughout the water column, preventing oxygen losses to the atmosphere due to surface supersaturation and increasing the overall pond oxygen content. This paper presents the system models developed to validate the concept, including a Computational Fluid Dynamics (CFD) model and a diel Dissolved Oxygen (DO) simulation model. These models, when used in conjunction, can estimate the increase in DO to be expected by the introduction of passive aeration device. These models were tailored to represent two target test ponds in Bac Ninh, Vietnam. To calibrate the models, instrumentation measured relevant parameters including DO and water temperatures at various depths, wind speed, ambient air temperature, and solar irradiance. A description of the mechanical design, construction and installation of two full-scale prototypes is then discussed, and field results for the first month post-implementation are analyzed. The model and experimental results indicate that the device can improve the DO content at deep levels of the ponds (i.e. oxygen-depleted regions) and has the potential to improve aquaculture productivity in resource-constrained settings.",Entailment
s_263,Contradiction,Scalability is not a significant limitation and does not affect the ability to handle a large number of transactions efficiently .,"—Blockchain is an emerging technology that would possibly disrupt the existing centralized financial systems lead to the rise to a new technology era for the financial sector. Additionally, different new use cases such as healthcare, identity management, etc. suggest that Blockchain has much wider applications. Blockchain is founded on distributed ledger technology that ensures trust through consensus between parties in a peer-to-peer network instead of the need to a third party or central authority. However, blockchain has several limitations such as scalability, latency, low throughput which are the main barriers for Blockchain being adopted by the industries. Of all, scalability is the most critical limitation of blockchain that needs an efficient and effective solution. In this paper, we aim to enhance the scalability of blockchain by designing and implementing a massively scalable architecture for private blockchain-based applications, called ElasticBloC. To evaluate our contribution, we conducted several experiments on ElasticBloC. The results showed that ElasticBloC is a high-performant architecture that scales massively.
[4]: Blockchain technology is a decentralized database that stores a registry of assets and transactions across a peer-to-peer computer network, which is secured through cryptography, and over time, its history gets locked in blocks of data that are cryptographically linked together and secured. So far, there have been use cases of this technology for cryptocurrencies, digital contracts, financial and public records, and property ownership. It is expected that future uses will expand into medicine, science, education, intellectual property, and supply chain management. Likely applications in the field of medicine could include electronic health records, health insurance, biomedical research, drug supply and procurement processes, and medical education. Utilization of blockchain is not without its weaknesses and currently, this technology is extremely immature and lacks public or even expert knowledge, making it hard to have a clear strategic vision of its true future potential. Presently, there are issues with scalability, security of smart contracts, and user adoption. Nevertheless, with capital investments into blockchain technology projected to reach US$400 million in 2019, health professionals and decision makers should be aware of the transformative potential that blockchain technology offers for healthcare organizations and medical practice.",Entity error
i_640,Contradiction,"4. Future Implications: Ubiquitous Computing and Mass-Customization: The integration of ubiquitous computing and mass-customization in architectural practices is likely to completely transform design and construction methods, rendering traditional practices obsolete and irrelevant to any project needs .","The paper examines the impact of the IT revolution on the design professions, especially that of architecture. It looks at the impacts of past technological revolutions on established methods, products, and practices, and examines the potential impacts of ubiquitous computing, telecommunication, mass-customization and embedded computing on methods of design and construction, and on the products of architecture. This examination leads to conclusions about the implications of these technologies on the nature of architectural practice in the future. © 2005 Elsevier Ltd. All rights reserved.",Misrepresentation
s_275,Contradiction,7. SYSTRAN and SDL Trados: Purpose: Professional translation memory and machine translation tools. Use Case: Widely used in professional translation services to improve consistency and productivity .,"The aim of this article is to provide an answer to the question about the current state of advancement of computer-assisted translation tools. We assume that several decades of research in the field carried out by the EU institutions in the context of the European integration process have provided the most advanced computer-assisted translation tools available in the biggest translation service in the world, i.e., the Directorate General for Translation of the European Commission. The present work therefore focuses on the following three main types of CAT tools employed by the EU translators: translation memory tools, terminology management tools and machine translation tools. The same types of tools, offered by the EU providers, i.e. SDL and SYSTRAN, are also used by translators working outside the EU structures. We can therefore presume that the EU translation services set work standards which are then accepted by all professional translators. For that reason, in order to define the most probable directions of future development of these tools, this article also reports the current research conducted by the EU in the CAT tools field.",Misrepresentation
i_2362,Contradiction,"Additionally, heavy metals can disrupt photosynthetic activity, as seen with Ni exposure, which consistently reduced chlorophyll content and photosynthetic efficiency, regardless of concentration .","Enhanced level of UV-B radiation and heavy metals in irrigated soils due to anthropogenic activities are deteriorating the environmental conditions necessary for growth and development of plants. The present study was undertaken to study the individual and interactive effects of heavy metal nickel (NiCl<inf>2</inf>·6H<inf>2</inf>O; 0.01, 0.1, 1.0 mM) and UV-B exposure (0.4 W m<sup>-2</sup>; 45 min corresponds to 1.08 KJ m<sup>-2</sup>) on growth performance and photosynthetic activity of pea (Pisum sativum L.) seedlings. Ni treatment at high doses (0.1 and 1.0 mM Ni) and UV-B alone reduced chlorophyll content and photosynthetic activity (oxygen yield, carbon fixation, photorespiration, and PSI, PSII, and whole chain electron transport activities), and declining trends continued with combined doses. In contrast to this, Ni at 0.01 mM appeared to be stimulatory for photosynthetic pigments and photosynthetic activity, thereby enhanced biomass was observed at this concentration. However, combined dose (UV-B + 0.01 mM Ni) caused inhibitory effects. Carotenoids showed different responses to each stress. Nickel at high doses strongly inhibited PSII activity and the inhibition was further intensified when chloroplasts were simultaneously exposed to UV-B radiation. PSI activity appeared to be more resistant to each stress. High doses of Ni (0.1and 1.0 mM) and UV-B alone interrupted electron flow at the oxygen evolving complex. Similar damaging effects were caused by 0.01 and 0.1 mM Ni together with UV-B, but the damage extended to PSII reaction center in case of 1.0 mM Ni in combination with UV-B. In conclusion, the results demonstrate that low dose of Ni stimulated the growth performance of pea seedlings in contrast to its inhibitory role at high doses. However, UV-B alone and together with low as well as high doses of Ni proved to be toxic for P. sativum L. © 2012 Springer Science+Business Media, LLC.",Misrepresentation
i_517,Entailment,"Broader Societal Impacts: National Security: Increased cybersecurity awareness is likely to protect national security by somewhat reducing the susceptibility of citizens to cybercrime and attacks, which may be particularly relevant in countries with high rates of phishing attacks .","Technological advances have changed the manner in which ordinary citizens conduct their daily activities. Many of these activities are carried out over the Internet. These include filling tax returns, online banking, job searching and general socialising. Increased bandwidth and proliferation of mobile phones with access to Internet in South Africa imply increased access to Internet by the South African population. Such massive increased in access to Internet increases vulnerabilities to cyber crime and attacks and threatens the national security. As a result, South Africa remains one of top three countries that are targeted by phishing attacks, the other two are the US and the UK (RSA, 2011). As a response, various entities engage in cyber security awareness initiatieves and trainings with the aim to create cyber security awareness (CSA) among the citizens of South Africa. In the absence of a national cyber security policy, however, these awareness initiatives and programmes are delivered through a variety of independent mechanisms. Various entities engage in cyber security awareness training each with its specific objectives and focus areas. It is argued in this paper that cyber security is complex and multi-faceted. No single solution can effectively address it. While the current means to create cyber security awareness does make impact, the fragmented and uncoordinated nature thereof have a potential to create its own dynamics. The focus of organisations to deliver on their own objectives translates to some extent into the optimisation of the behaviour of individual entities as opposed to the optimisation of the national cyber security awareness as a whole. This paper evaluates the extent to which the current cyber security awareness initiatives address the cyber security threats and risks. The assessment is based on the initiatives objectives, alignment of the programme to the cyber threats, and the target audience.",Entailment
i_324,Contradiction,"Current DL models are generally inflexible and incapable of adapting to any applications or optimization targets, which is a significant limitation in their use .","Deep learning plays an important role in machine learning field, and it has been widely used in various applications. The prospect of research and applications of deep learning are huge. However, deep learning also faces several challenges. Firstly, there are many tools in deep learning field, but these tools are not convenient to use for non-expert users because the installation and usage of them are really complex. Secondly, the diversity of deep learning is limited because the flexibility of existing deep learning models is not enough. Furthermore, the training time of deep learning is so long that the optimal hyper-parameters combination cannot be found in a short time. To solve these problems, we design a deep learning programming framework based on heterogeneous architecture in this paper. The programming framework establishes a unified module library which can be used to build a deep model through the visual interface conveniently. Besides, the framework also accelerates the basic modules on heterogeneous platform, and makes the speed of searching optimal hyper-parameters combination be faster. Experimental results show that the programming framework can construct deep models flexibly, and more importantly, it can achieve comparative classification results and better timing performance for a variety of applications. In addition, the framework can search optimal hyper-parameters efficiently and make us infer the relationship of all hyper-parameters.",Missing information
i_77,Entailment,Techniques to Address Imbalanced Data: Resampling Methods: Undersampling: Reduces the number of majority class instances. Cluster-based undersampling and random undersampling are effective in improving minority class accuracy .,"For classification problem, the training data will significantly influence the classification accuracy. However, the data in real-world applications often are imbalanced class distribution, that is, most of the data are in majority class and little data are in minority class. In this case, if all the data are used to be the training data, the classifier tends to predict that most of the incoming data belongs to the majority class. Hence, it is important to select the suitable training data for classification in the imbalanced class distribution problem. In this paper, we propose cluster-based under-sampling approaches for selecting the representative data as training data to improve the classification accuracy for minority class and investigate the effect of under-sampling methods in the imbalanced class distribution environment. The experimental results show that our cluster-based under-sampling approaches outperform the other under-sampling techniques in the previous studies. © 2008 Elsevier Ltd. All rights reserved.
[8]: Classifiers for a highly imbalanced dataset tend to bias in majority classes and, as a result, the minority class samples are usually misclassified as majority class. To overcome this, a proper undersampling technique that removes some majority samples can be an alternative. We propose an efficient and simple undersampling method for imbalanced datasets and show that the proposed method outperforms others with respect to four different performance measures by several illustrative experiments, especially for highly imbalanced datasets.",Entailment
i_1469,Contradiction,"Body Weight: Obesity and Implant Survival: Higher body mass index (BMI) seems to significantly enhance the survivorship of metal-on-metal hip resurfacing prostheses. Patients with a BMI of ≥30 not only showed a lower risk of revision compared to those with a BMI of <30, but this also suggests that obesity might be a key factor in improving implant longevity. This could be attributed to reduced activity levels and larger component sizes in heavier patients, which likely result in less wear and tear on the implants .","Background: The effect of obesity on the outcomes of metal-on-metal resurfacing arthroplasty is not currently known. In this study, we assessed the influence of body mass index on the survival of a metal-on-metal hybrid hip resurfacing prosthesis by comparing the clinical results of patients with a body mass index of ≥30 with those of patients with a body mass index of <30. Methods: We retrospectively reviewed our registry to identify all patients who had been followed for at least two years after a metal-on-metal hip resurfacing arthroplasty, and we divided those patients according to whether they had had a body mass index of ≥30 (the study group) or <30 (the control group) at the time of the surgery. One hundred and twenty-five patients (144 hips) with an average weight of 104.6 kg and an average body mass index of 33.4 were included in the study group, and 531 patients (626 hips) with an average weight of 78.3 kg and an average body mass index of 25.4 were included in the control group. We compared the clinical results (UCLA [University of California at Los Angeles] and Harris hip scores, SF-12 [Short Form-12] survey results, and complication rates), radiographic results, and prosthetic survival rates of the two groups. Results: There was no significant difference postoperatively between the groups with regard to the UCLA pain or walking scores or the mental component score of the SF-12. However, the UCLA function and activity scores were lower in the study group than in the control group (9.2 compared with 9.6 points [p = 0.001] and 7.1 compared with 7.6 points [p = 0.002], respectively). The control group had a significantly higher postoperative physical component score on the SF-12 (51.4 points compared with 49.3 points in the study group, p = 0.01) and postoperative Harris hip score (93.8 compared with 90.6 points, p = 0.0003). Two hips (1.4%) were revised in the study group. In contrast, thirty-one hips (5.0%) were converted to a total hip replacement in the control group; twenty of the thirty-one were revised because of loosening of the femoral component. The five-year survivorship of the hip prostheses was 98.6% in the study group and 93.6% in the control group (p = 0.0401). When the entire cohort was divided into three groups according to whether the body mass index was <25, 25 to 29, or ≥30, the risk of revision was found to have decreased twofold from one group to the next as the body mass index increased (p = 0.013). No acetabular component loosened in either group. The average diameter of the femoral component was 48.3 mm in the study group and 46.8 mm in the control group (p = 0.0001). There were no revisions for any reason and no radiolucencies were observed in a subset of twenty-seven patients with a body mass index of ≥35. Conclusions: Metal-on-metal resurfacing hip arthroplasty is performing well in patients with a high body mass index, although the function scores are reduced compared with those for patients with a body mass index of <30. The protective effect of a high body mass index on survivorship results may be explained by a reduced activity level and a greater component size in this patient population. Level of Evidence: Prognostic Level II. See Instructions to Authors for a complete description of levels of evidence. Copyright © 2007 by the Journal of Bone and Joint Surgery, Incorporated.",Misrepresentation
i_2049,Contradiction,"Impact of Human Activities. Culverts and Passage Barriers: High-velocity culverts can impede the passage of small fish, fragmenting habitats and affecting reproductive success. Natural substrates in culverts can improve passage by creating low-velocity areas, facilitating movement and potentially enhancing reproductive outcomes .","Culverts can provide a significant barrier to fish passage by fragmenting fish habitats and impeding the passage success of small-bodied fish. Geographical connectivity is critical to the maintenance of diverse fish assemblages. Culverts with high cross-sectional velocity can cause population fragmentation by impeding passage of small, freshwater fish. Behavioral responses of small fish to high velocities can differ among functional groups, and swimming behavior of many species is not well known. We tested effects of substrate type on swimming behavior in two small, freshwater fish species-southern leatherside chub (Lepidomeda aliciae, a midwater species), and longnose dace (Rhinichthys cataractae, a benthic species)-across three substrate treatments: (1) a bare flume, (2) large flow obstacles, and (3) a natural cobble substrate. Both longnose dace and southern leatherside chub used paths of low velocity and swam in the near-substrate boundary area. Fish in the bare flume and large obstacle treatments swam along the corners of the flume in a straight swim path, whereas fish in the natural substrate treatment used all parts of the flume bed. There was no relationship between passage success of fish and substrate type, fish species, or their interaction. In contrast, substrate type, fish species, and their interaction were significant predictors of passage time. Southern leatherside chub passed through the test section about two to four times faster than longnose dace. Both species took longer to pass through the large flow obstacle treatment compared to the bare flume or natural substrate. The natural substrate created a complex velocity profile with areas of low velocity throughout the entire flume, in contrast to the other two treatments. Our data suggest natural substrates can improve the passage of small fish in high-velocity culverts for both benthic and midwater functional groups.",Misrepresentation
i_344,Entailment,"System Monitoring and Debugging. Job Management and Monitoring: The CLI allows for efficient job management and monitoring, similar to using the 'ps' command to check process statuses. This is particularly useful in environments like OpenStack, where the Application Execution Manager (AEM) leverages CLI for managing and monitoring jobs effectively .","Designing a job management system for the Grid is a non-trivial task. While a complex middleware can give a lot of features, it often implies sacrificing performance. Such performance loss is especially noticeable for small jobs. A Job Manager's design also affects the capabilities of the monitoring system. We believe that monitoring a job or asking for a job status should be fast and easy, like doing a simple 'ps'. In this paper, we present the job management of XtreemOS - a Linux-based operating system to support Virtual Organizations for Grid. This management is performed inside the Application Execution Manager (AEM). We evaluate its performance using only one job manager plus the built-in monitoring infrastructure. Furthermore, we present a set of real-world applications using AEM and its features. In XtreemOS we avoid reinventing the wheel and use the Linux paradigm as an abstraction. © 2010 IEEE.",Entailment
i_2357,Entailment,Regular Updates: Regularly update the validation rubric to incorporate new technologies and methodologies that enhance the accuracy and efficiency of microbial strain validation .,"The World Federation of Culture Collections and the World Data Center for Microorganisms (WDCM) initiated an international community-led project to sequence and annotate newly described prokaryotic taxa. This sequencing project aims to cooperate with international culture collections and the International Journal of Systematic and Evolutionary Microbiology and contribute to the expansion of whole genome sequencing databases for type strains. It will provide global microbial taxonomists with free standard genome sequencing and annotation services. Taxonomists are encouraged to contact the WDCM and participant culture collections to submit a type strain sequencing proposal.
[11]: AU Spatiotemporal: Pleaseconfirmthatallheadinglevelsarerepresentedcorrectly models that account for heterogeneity within: microbial communities rely on single-cell data for calibration and validation. Such data, commonly collected via microscopy and flow cytometry, have been made more accessible by recent advances in microfluidics platforms and data processing pipelines. However, validating models against such data poses significant challenges. Validation practices vary widely between modelling studies; systematic and rigorous methods have not been widely adopted. Similar challenges are faced by the (macrobial) ecology community, in which systematic calibration approaches are often employed to improve quantitative predictions from computational models. Here, we review single-cell observation techniques that are being applied to study microbial communities and the calibration strategies that are being employed for accompanying spatiotemporal models. To facilitate future calibration efforts, we have compiled a list of summary statistics relevant for quantifying spatiotemporal patterns in microbial communities. Finally, we highlight some recently developed techniques that hold promise for improved model calibration, including algorithmic guidance of summary statistic selection and machine learning approaches for efficient model simulation.",Entailment
s_1461,Entailment,"Studies suggest that the absence of strong fitness costs associated with Cry1Fa resistance in S. frugiperda implies that resistance may not be effectively counterselected in Cry1Fa-free environments, although some minor costs could still exist .","BACKGROUND: The presence of fitness costs of resistance to Bacillus thuringiensis (Bt) insecticidal proteins in insect populations may delay or even reverse the local selection of insect resistance to Bt transgenic crops, and deserves rigorous investigation. Here we assessed the fitness costs associated with Cry1Fa resistance in two strains of fall armyworm, Spodoptera frugiperda (Lepidoptera: Noctuidae), derived from field collections in different Brazilian regions and further selected in the laboratory for high levels of resistance to Cry1Fa using leaves of TC1507 corn. RESULTS: Fitness components were compared using paired resistant and susceptible strains with similar genetic backgrounds and F<inf>1</inf> generations from reciprocal crosses, all of them reared on non-transgenic corn leaves. No apparent life history costs in the larval stage were observed in the Bt-resistant strains. Moreover, the resistance remained stable for seven generations in the absence of selection, with no decrease in the proportion of resistant individuals. Larval respiration rates were also similar between resistant and susceptible homozygotes, and heterozygotes displayed respiration rates and demographic performance equal or superior to those of susceptible homozygotes. CONCLUSION: In combination, these results indicate the lack of strong fitness costs associated with resistance to Cry1Fa in the fall armyworm strains studied. These findings suggest that Cry1Fa resistance in S. frugiperda populations is unlikely to be counterselected in Cry1Fa-free environments. © 2016 Society of Chemical Industry.",Entailment
s_180,Entailment,"Effective Methods for Early Stopping: Bayesian Model Averaging: This technique mitigates overfitting by averaging over multiple models sampled from the posterior distribution using methods like Stochastic Gradient Langevin Dynamics (SGLD). Advantages: It adapts to the local geometry of the parameter space, improving convergence and predictive risk .","Effective training of deep neural networks suffers from two main issues. The first is that the parameter spaces of these models exhibit pathological curvature. Recent methods address this problem by using adaptive preconditioning for Stochastic Gradient Descent (SGD). These methods improve convergence by adapting to the local geometry of parameter space. A second issue is overfitting, which is typically addressed by early stopping. However, recent work has demonstrated that Bayesian model averaging mitigates this problem. The posterior can be sampled by using Stochastic Gradient Langevin Dynamics (SGLD). However, the rapidly changing curvature renders default SGLD methods inefficient. Here, we propose combining adaptive preconditioners with SGLD. In support of this idea, we give theoretical properties on asymptotic convergence and predictive risk.We also provide empirical results for Logistic Regression, Feedforward Neural Nets, and Convolutional Neural Nets, demonstrating that our preconditioned SGLD method gives state-of-the-art performance on these models.",Entailment
i_1186,Unverifiable,"Medication Management: Family caregivers are significantly involved in ensuring that stroke survivors take their medications correctly and on time. Factors such as caregiver living arrangements, involvement in daily activities, and the care recipient's health conditions (e.g. dementia, diabetes) influence this involvement .","[4] Background: Family members provide valuable contributions during rehabilitation after stroke, but frequently report higher incidences of burden, depression, and social isolation during caregiving. Thus, effective interventions to reduce stroke impact on the family are needed. Objectives: To evaluate the content validity and satisfaction of a caregiver-focused web-based intervention designed to improve stroke survivor physical function while reducing caregiver negative outcomes. Methods: Caregivers of individuals with stroke (N = 6) and expert rehabilitation researchers (N = 4) were presented with a novel, web-based intervention (CARE-CITE) designed to foster problem-solving and skill-building while facilitating caregiver involvement during constraint-induced movement therapy. Caregivers rated CARE-CITE for usefulness, ease of use, acceptability, and time to complete. Rehabilitation experts evaluated content for accuracy, feasibility, acceptability, problem relevance and ease of use. Ratings were assessed using a five-point Likert-type response scales (1 = strongly disagree to 5 = strongly agree). Results: On average, all caregivers agreed or strongly agreed that the modules were useful (4.42), easy to use (4.60), and acceptable (4.41). Mean total satisfaction score was 4.45, and average review time was 15 min per module. Expert reviewers agreed or strongly agreed that each module was accurate (4.95), feasible (4.8), easy to use (4.86), acceptable (4.96), and had appropriate problem relevance (4.65). Conclusions: The CARE-CITE intervention may be a viable program for caregivers of patients with stroke. Currently a pilot study is underway to evaluate the impact of the intervention on caregiver mental health, family conflict around stroke recovery and stroke survivor upper extremity function. [7] As the older adult population continues to grow, the prevalence of chronic diseases is also increasing, leading to the need for novel ways of managing this large population of patients. One solution is to focus on informal caregivers. These informal caregivers already make a substantial contribution to our nation's healthcare finances and patient health outcomes. Caregivers also derive benefits from caring for their family member or friend; however, it is not uncommon for these individuals to experience negative health consequences, or what is often called ""burden of care."" Those called to care are not without their own burdens, and they must frequently make significant lifestyle adjustments that impact their own health. Therefore, for caregivers to be effective, caring for the caregivers must be a focus of medicine in the twenty-first century. [15] Background: In countries where access to Specialist stroke care services are limited, primary care physicians often manage stroke patients and the caregiving family members. This study aimed to evaluate the impact of Stroke Riskometer Application (SRA™) on promoting healthier lifestyles among familial stroke caregivers for primary prevention. Methods: A parallel, open-label, 2-arm prospective, pilot randomised controlled trial was conducted at a long-term stroke service at a university based primary care clinic. All stroke caregivers aged ≥ 18 years, proficient in English or Malay and smartphone operation were invited. From 147 eligible caregivers, 76 participants were randomised to either SRA™ intervention or conventional care group (CCG) after receiving standard health counselling. The intervention group had additional SRA™ installed on their smartphones, which enabled self-monitoring of modifiable and non-modifiable stroke risk factors. The Stroke Riskometer app (SRA<sup>TM</sup>) and Life's Simple 7 (LS7) questionnaires assessed stroke risk and lifestyle practices. Changes in clinical profile, lifestyle practices and calculated stroke risk were analysed at baseline and 3 months. The trial was registered in the Australia-New Zealand Clinical Trial Registry, ACTRN12618002050235. Results: The demographic and clinical characteristics of the intervention and control group study participants were comparable. Better improvement in LS7 scores were noted in the SRA™ arm compared to CCG at 3 months: Median difference (95% CI) = 0.88 (1.68–0.08), p = 0.03. However, both groups did not show significant changes in median stroke risk and relative risk scores at 5-, 10-years (Stroke risk 5-years: Median difference (95% CI) = 0.53 (0.15–1.21), p = 0.13, 10-years: Median difference (95% CI) = 0.81 (0.53–2.15), p = 0.23; Relative risk 5-years: Median difference (95% CI) = 0.84 (0.29–1.97), p = 0.14, Relative risk 10-years: Median difference (95% CI) = 0.58 (0.36–1.52), p = 0.23). Conclusion: SRA™ is a useful tool for familial stroke caregivers to make lifestyle changes, although it did not reduce personal or relative stroke risk after 3 months usage. Trial registration: No: ACTRN12618002050235 (Registration Date: 21<sup>st</sup> December 2018).",Unrelated and unverifiable
i_2213,Contradiction,This symbiosis enhances the biodiversity and ecological complexity of benthic ecosystems .,"As sessile and filter-feeding metazoans, marine sponges represent an ecologically important and highly diverse component of marine benthic communities throughout the world. It has been suggested that marine sponges are hosts to many microorganisms which can constitute up to 40-60% of its biomass. Recently, sponges have attracted a high interest from scientific community because two important factors. First there is the fact that sponges have a wide range of associated bacteria; and, second, they are a rich source of bioactive substances. Since 1950, a number of bioactive substances with various pharmacological functions have been isolated from marine sponges. However, many of these substances were subsequently shown to be actually synthesized by sponge-associated bacteria. Bacteria associated with marine sponges constitute an interesting source of novel bioactive compounds with biotechnological potential such as antimicrobial substances, enzymes and surfactants. In addition, these bacteria may be biofilm forming and can act as bioindicators in bioremediation processes of environmental pollution caused by oil and heavy metals. This review focuses on the biotechnological applications of these microorganisms. © 2014 Bentham Science Publishers.
[5]: Sponges belonging to genus Mycale are common and widely distributed across the oceans and represent a significant component of benthic communities in term of their biomass, which in many species is largely composed by bacteria. However, the microbial communities associated with Mycale species inhabiting different geographical areas have not been previously compared. Here, we provide the first detailed description of the microbiota of two Mycale species inhabiting the sub-Antarctic Magellan region (53°S) and the Western Antarctic Peninsula (62-64°S), two geographically distant areas (> 1,300 km) with contrasting environmental conditions. The sponges Mycale (Aegogropila) magellanica and Mycale (Oxymycale) acerata are both abundant members of benthic communities in the Magellan region and in Antarctica, respectively. High throughput sequencing revealed a remarkable similarity in the microbiota of both sponge species, dominated by Proteobacteria and Bacteroidetes, with both species sharing more than 74% of the OTUs. In contrast, 16% and 10% of the OTUs were found only in either M. magellanica or M. acerata, respectively. Interestingly, despite slight differences in the relative abundance, the most dominant OTUs were present in both species, whereas the unique OTUs had very low abundances (less than 1% of the total abundance). These results show a significant overlap among the microbiota of both Mycale species and also suggest the existence of a low level of specificity of the most dominant symbiont groups.",Missing information
s_1051,Entailment,- **Ki-67**: Associated with cellular proliferation and prognosis in ovarian cancer .,"FOXO3a possesses a large series function, including cellular proliferation, transformation, differentiation, and longevity. Recent studies suggested that the different localization of FOXO3a in nucleus and cytoplasm has different functions. And phosphorylation of FOXO3a at threonine-32 plays an important role in deciding FOXO3a localization. In this study, we investigated the role of pThr32-FOXO3a and Ki-67 in human ovarian cancer. Furthermore, we study the effect of mutant of FOXO3a (T32A) on the ovarian cancer cells. Immunohistochemical analysis was performed on formalin-fixed paraffin sections of 46 specimens. And in vitro, we detect the contribution of wild-type and mutant FOXO3a on the ovarian cancer cell proliferation. We found that the pThr32-FOXO3a was overexpressed in human ovarian cancer, and pThr32-FOXO3a expression correlated significantly with lymph node involvement (P = 0.015). And the proliferation index Ki-67 was significantly associated with lymph node involvement (P = 0.000) and disease stage (P = 0.003). Kaplan-Meier analysis revealed that survival curves of low versus high expressers of pThr32-FOXO3a and Ki-67 showed a highly significant separation in human ovarian cancer (P<0.01). Transfection of FOXO3a (T32A) resulted in a significant increase in cells in G1 phase than transfection of wild-type FOXO3a and control cells. Our results suggested that pThr32-FOXO3a and Ki-67 expression may be considered to be important prognosis in human ovarian cancer. In vitro studies suggested that FOXO3a (T32A) was a more powerful cell cycle inhibitor, although both the wild type and mutant forms of FOXO3a were effective. © Springer Science+Business Media, LLC 2011.",Entailment
i_1482,Contradiction,"Summary of Findings: Adult Males: While specific values for MUAC were not provided, it can be inferred that the lack of detailed data suggests minimal age-related variations in the population .","A cross-sectional study was undertaken to investigate anthropometric characteristics and nutritional status among adult male (18 years and above) Oraons (n = 290), a tribe in the Ranchi District of the state of Jharkhand in India. The anthropometric characteristics (stature, body weight and mid upper arm circumference or MUAC) were categorised into three age-groups (18-39 years, 40-59 years and 60 years and above). This particular investigation recorded a low (18.48Kg/m<sup>2</sup>) body mass index (BMI) and a high frequency of under-nutrition (53.10% chronic energy deficiency or CED) among the adult Oraons. BMI and CED of the adult Oraons were also compared with some populations of eastern India. It is noted that 38.28% of adult Oraons suffer from under-nutrition when the nutritional status of their population is evaluated by the standard cut-off points of MUAC. Pearson correlations of BMI and MUAC with age exhibited significantly (p< 0.001) negative correlations among the Oraons. Correlations between BMI and MUAC in their population showed a high significance (p< 0.0001). Significant age-related variations (tested by one-way ANOVA) in anthropometric parameters were observed in the Oroan population. Linear regression analyses revealed more or less significant negative impacts of age on BMI and MUAC in the population.",Opposite meaning
i_424,Unverifiable,"Primary Use Cases: Smart Cities: Infrastructure Management: IoT and cloud integration can manage urban infrastructure, including traffic systems, waste management, and public safety, enhancing the efficiency of city operations .","Internet of Things (IoT) and Vehicular Ad hoc NETwork (VANET) based clouds are two emerging technologies and offer myriad of new applications in many domains of smart cities including, but not limited to, smart infrastructure and intelligent transportation. Integration of these technologies will enrich the applications and services space that will eventually stimulate the proliferation of these technologies. Nonetheless, due to their different requirements, environments, and networking models, such integration will need definitions of new communication paradigms and frameworks. To fill the voids, in this paper, we propose an architectural framework to integrate vehicular clouds (VC) and IoT, referred to as IoT-VC, to realize new services and applications that include IoT management through vehicular clouds. We particularly focus on smart city applications controlled, managed, and operated through vehicular networks. This theoretical work provides initial insights into data management in such diverse paradigm with resource constrained environment. Furthermore, we also discuss research challenges in such integration that include data acquisition, data quality, security, privacy, coverage, and so forth. These challenges must be addressed for realization of IoT-VC paradigm.",Related but unverifiable
s_2189,Entailment,"Regulatory Frameworks and Guidelines: REACH Regulation: The Registration, Evaluation, Authorisation, and Restriction of Chemicals (REACH) regulation is a cornerstone in the EU's approach to managing chemical safety. It mandates comprehensive risk assessments for all industrial chemicals, including biodegradable materials, to ensure they do not pose significant risks to human health or the environment .","Background, aim and scope: Due to a number of drawbacks associated with the previous regime for the assessment of new and existing chemicals, the European Union established a new regulation concerning the registration, evaluation, authorisation and restriction of chemicals (REACH). All relevant industrial chemicals must now be assessed. Instead of the authorities, industry itself is responsible for the risk assessment. To achieve better and more efficient assessments while reducing animal testing, all information-standard, non-standard and non-testing-has to be used in an integrated manner. To meet these challenges, the current technical guidance documents for risk assessment of new and existing chemicals had to be updated and extended considerably. This was done by experts in a number of REACH Implementation Projects. This paper presents the most relevant results of the expert Endpoint Working Group on Aquatic Toxicity in order to illustrate the change of paradigm in the future assessment of hazards to the aquatic environment by chemical substances. Main features and challenges: REACH sets certain minimum data requirements in order to achieve a high level of protection for human health and the environment. It encourages the assessor to use alternative information instead of or in addition to standard one. This information has to be equivalent to the standard information requirement and adequate to draw overall conclusions with respect to the regulatory endpoints classification and labelling, persistent, bioaccumulative and toxic (PBT) assessment and predicted no-effect concentrations (PNEC) derivation. The main task of the expert working group was to develop guidance on how to evaluate the toxicity of a substance based on integration of information from different sources and of various degrees of uncertainty in a weight of evidence approach. Integrated testing and intelligent assessment: In order to verify the equivalence and adequacy of different types of information, a flexible sequence of steps was proposed, covering characterisation of the substance, analysis of modes of action, identification of possible analogues, evaluation of existing in vivo and in vitro testing data as well as of QSAR results. Finally, all available data from the different steps have to be integrated to come to an overall conclusion on the toxicity of the substance. This weight of evidence approach is the basis for the development of integrated testing strategies (ITS), in that the available evidence can help to determine subsequent testing steps and is essential for an optimal assessment. Its flexibility helps to meet the different requirements for drawing conclusions on the endpoints classification and labelling, PNEC derivation as well as PBT assessment. The integration of all kinds of additional information in a multi-criteria assessment reduces the uncertainties involved with extrapolation to the ecosystem level. The weight of evidence approach is illustrated by practical examples. Conclusions and perspectives: REACH leads to higher challenges in order to make sound decisions with fewer resources, i.e. to move away from extensive standard testing to an intelligent substance-tailored approach. Expert judgement and integrated thinking are key elements of the weight of evidence concept and ITS, potentially leading to better risk assessments. Important sub-lethal effects such as endocrine disruption, which are not covered by the current procedure, can be considered. Conclusions have to be fully substantiated: Risk communication will be an important aspect of future assessments. © 2008 Springer-Verlag.
[2]: The European Union Regulation on chemical substances 'REACH' (Registration, Evaluation, Authorisation, (and Restriction), of Chemicals) includes a process for the identification of certain chemicals as 'Substances of Very High Concern (SVHC).' This is the first step of the Authorization Process, which requires industry to request specific authorization prior to the marketing and/or use of these chemicals. These substances must be identified as carcinogens, mutagens, toxic to reproduction, persitent-bioaccumulative-toxic, very persistent and very bioaccumulative, or of equivalent concern. The identification of these substances as SVHC and its inclusion in the so-called Candidate List have some immediate consequences for industry.
[3]: Chemicals may persist in the environment, bioaccumulate and be toxic for humans and wildlife, posing great concern. These three properties, persistence (P), bioaccumulation (B), and toxicity (T) are the key targets of the PBT-hazard assessment. The European regulation for the Registration, Evaluation, Authorisation and Restriction of Chemicals (REACH) requires assessment of PBT-properties for all chemicals that are produced or imported in Europe in amounts exceeding 10 tonnes per year, checking whether the criteria set out in REACH Annex XIII are met, so the substance should therefore be considered to have properties of very high concern. Considering how many substances can fall under the REACH regulation, there is a pressing need for new strategies to identify and screen large numbers fast and inexpensively. An efficient non-testing screening approach to identify PBT candidates is necessary, as a valuable alternative to money- and time-consuming laboratory tests and a good start for prioritization since few tools exist (e.g. the PBT profiler developed by US EPA). The aim of this work was to offer a conceptual scheme for identifying and prioritizing chemicals for further assessment and if appropriate further testing, based on their PBT-potential, using a non-testing screening approach. We integrated in silico models (using existing and developing new ones) in a final algorithm for screening and ranking PBT-potential, which uses experimental and predicted values as well as associated uncertainties. The Multi-Criteria Decision-Making (MCDM) theory was used to integrate the different values. Then we compiled a new set of data containing known PBT and non-PBT substances, in order to check how well our approach clearly differentiated compounds labeled as PBT from those labeled as non-PBT. This indicated that the integrated model distinguished between PBT from non-PBT compounds.",Entailment
i_2312,Contradiction,"Salinity levels significantly impact larval survival and development. For example, P. pelagicus larvae had low survival rates at high salinity (40 ppt) . Additionally, it is possible that variations in salinity could influence the growth rates of other marine organisms in similar environments.","Studies of stress tolerance in marine organisms are key in considerate effects on larval survival. A change between environmental factors has been assumed the first mechanism restricting survival of larvae. Therefore, Zoea I and Zoea 2 larvae of P. pelagicus were exposed to various regimes of activity stress tests such as oxygen, starvation, pH, temperature, and salinity to examine larval competency against these factors. Larval performance was affected at extreme increase or by decreases in stress activity. In oxygen test, no survival achieved in treated groups. However, only some Zoea 2 survived in starvation test. Temperature 30°C did produce highest survival (p<0.05) and elevated temperature stress adversely affected larvae and no survival was achieved at temperature 40°C and 45°C respectively. Low pH 4, 6 and higher pH 10 did affect negatively, thus no survival of larvae, and only pH 8 did produce better survival (p<0.05). However, salinity greatly influenced the larval survival and only low survival 4.67±1.15% of Zoea 1 larvae and 5.33±1.53% of Zoea 2 determined at salinity 40 ppt was not significantly different (p>0.05). The significantly highest survival (p<0.05) of larvae was achieved in untreated groups (controls). The findings of this study indicate that the larval survival of P. pelagicus was compromised with certain level of stressor, elevated and low stressor had shown unfavourable effect on larval survival.",Opposite meaning
i_445,Entailment,Challenges and Future Directions: Integration with Other NLP Tasks: AQG is also being integrated with other NLP tasks like question answering and summarization to create more comprehensive systems that can both generate and answer questions effectively .,"We investigate the integration of Wiki systems with automated natural language processing (NLP) techniques. The vision is that of a ""self-aware"" Wiki system reading, understanding, transforming, and writing its own content, as well as supporting its users in information analysis and content development. We provide a number of practical application examples, including index generation, question answering, and automatic summarization, which demonstrate the practicability and usefulness of this idea. A system architecture providing the integration is presented, as well as first results from an initial implementation based on the GATE framework for NLP and the MediaWiki system. Copyright © 2007 ACM.
[5]: Automated Question Answering and Asking are two active areas of Natural Language Processing with the former dominating the past decade and the latter most likely to dominate the next one. Due to the vast amounts of information available electronically in the Internet era, automated Question Answering is needed to fulfill information needs in an efficient and effective manner. Automated Question Answering is the task of providing answers automatically to questions asked in natural language. Typically, the answers are retrieved from large collections of documents. While answering any question is difficult, successful automated solutions to answer some type of questions, so-called factoid questions, have been developed recently, culminating with the just announced Watson Question Answering system developed by I.B.M. to compete in Jeopardy-like games. The flip process, automated Question Asking or Generation, is about generating questions from some form of input such as a text, meaning representation, or database. Question Asking/Generation is an important component in the full gamut of learning technologies, from conventional computer-based training to tutoring systems. Advances in Question Asking/Generation are projected to revolutionize learning and dialogue systems. This chapter presents an overview of recent developments in Question Answering and Generation starting with the landscape of questions that people ask. © 2012, IGI Global.",Entailment
s_920,Unverifiable,"Future Trends and Research: Continuous Improvement: Ongoing research and development in NoC architectures focus on further enhancing energy efficiency. This includes exploring new materials, interconnect paradigms, and innovative routing algorithms like 3D ant colony routing, which can optimize network performance and reduce delays .","With the increasing of the integration capability intra-chip, nowadays numerous integrated systems explore a set of processing elements, such as in multicore processors. An efficient interconnection of those elements can be obtained via the use of Network on chip (NoC). This approach is similar to the traditional computer networks where, not restricted to multiprocessors, it is possible to interconnect several dedicated devices. Like other networks, NoCs can be arranged in different topologies, such as ring, mesh and torus. It has shared links that can be used in the transmission of packets of different nodes. Thus, the network congestion is an issue and must be treated to reduce delays. Algorithms based on ant colony optimisation have proven to be effective in static routing in systems designed to perform a fixed set of tasks, or where the communication pattern is known. This article introduces 3D ant colony routing (3D-ACR) and applies it as routing policy of NoCs having three different 3D topologies: mesh, torus and hypercube. Experimental results show that 3D ant colony routing performs consistently better compared with the previously proposed routing strategies.
[8]: To alleviate the complex communication problems that arise as the number of on-chip components increases, network-on-chip (NoC) architectures have been recently proposed to replace global interconnects. In this paper, we first provide a general description of NoC architectures and applications. Then, we enumerate several related research problems organized under five main categories: Application characterization, communication paradigm, communication infrastructure, analysis, and solution evaluation. Motivation, problem description, proposed approaches, and open issues are discussed for each problem from system, microarchitecture, and circuit perspectives. Finally, we address the interactions among these research problems and put the NoC design process into perspective. © 2009 IEEE.",Related but unverifiable
s_1521,Entailment,"Nutrient-Rich Media: Media supplemented with essential nutrients such as yeast extract, potassium phosphate, and magnesium sulfate can enhance fungal growth and enzyme production. These nutrients provide the necessary elements for cellular processes and enzyme activity .","Cutinase enzymes from fungi have found diverse applications in industry. However, most of the available literature on cutinase production is related to the cultivation of genetically engineered bacteria or yeast cells. In the present study, we use mixture design experiments to evaluate the influence of six nutrient elements on production of cutinase from the fungus Colletotrichum lindemuthianum. The nutritional elements were starch, glucose, ammonium sulfate, yeast extract, magnesium sulfate, and potassium phosphate. In the experimental design, we imposed the constraints that exactly one factor must be omitted in each set of experiments and no factor can account for more than one third of the mixture. Thirty different sets of experiments were designed. Results obtained showed that while starch is found to have negative influence on the production of the enzyme, yeast extract and potassium phosphate have a strong positive influence. Magnesium sulfate, ammonium sulfate, and glucose have low positive influence on the enzyme production. Contour plots have also been created to obtain information concerning the interaction effects of the media components on enzyme production. © 2007 Society for Industrial Microbiology.",Entailment
i_325,Unverifiable,"DL models do not require substantial memory and computational resources. In fact, fitting deep neural networks (DNNs) into the DRAM capacity of GPUs is rarely an issue, often allowing for the use of a single GPU and optimal network architectures .","The most widely used machine learning frameworks require users to carefully tune their memory usage so that the deep neural network (DNN) fits into the DRAM capacity of a GPU. This restriction hampers a researcher's flexibility to study different machine learning algorithms, forcing them to either use a less desirable network architecture or parallelize the processing across multiple GPUs. We propose a runtime memory manager that virtualizes the memory usage of DNNs such that both GPU and CPU memory can simultaneously be utilized for training larger DNNs. Our virtualized DNN (vDNN) reduces the average GPU memory usage of AlexNet by up to 89%, OverFeat by 91%, and GoogLeNet by 95%, a significant reduction in memory requirements of DNNs. Similar experiments on VGG-16, one of the deepest and memory hungry DNNs to date, demonstrate the memory-efficiency of our proposal. vDNN enables VGG-16 with batch size 256 (requiring 28 GB of memory) to be trained on a single NVIDIA Titan X GPU card containing 12 GB of memory, with 18% performance loss compared to a hypothetical, oracular GPU with enough memory to hold the entire DNN.",Related but unverifiable
i_816,Entailment,Economic Benefits: The high separation efficiency and improved safety features contribute to better economic outcomes for coconut processors by reducing labor costs and minimizing accidents .,"Based on the current situation that large-scale factories still obtain coconut meat by hands, and the physical and mechanical characteristics of coconut shell and coconut meat as well as the characteristics of teeth-roller cracker, the processing equipment which can separate coconut shell and meat was put forward. After putting the coconuts into the material trough, they can be squeezed and crushed by the teeth-roller cracker and then the coconut meat will be separated from coconut shell. The working principle of the machine was simple and its separation effect was good. Firstly, the overall design of the separator with Pro/e software and parametric solid modeling of the teeth-roller and the adjusting device was carried out. Carrying out finite element structural analysis after introducing the cracked tooth-roller into ANSYS, it can be acquired that the maximum displacement of the teeth-roller was 5.4×10<sup>-3</sup> mm and the maximum equivalent stress was 5.4999 MPa. As the selected stainless steel of 304 food grade can meet the requirements, it provided an effective method and basis for designing and improving the cracker. Then, the optimization design of response surface was carried out with the Design-Expert 8.0 software, acquiring the most suitable design parameters and use conditions, coconut diameter of 173 mm, feeding speed of 1.1 Pcs/s, teeth-roller speed of 278 r/min and gear roller clearance of 600 mm. The separation rate of coconut shell and meat can reach 98.5% under these conditions. Ultimately, the results of prototype test showed that the separation rate of coconut shell and meat is as high as 98.3% under stable operation. The successful development of this machine can not only improve the separation efficiency of coconut shell and meat effectively but also possess broad application prospects in the economic benefits of the coconut processing industry.
[2]: Virgin coconut oil manufacturing is one of the major products for both export and local markets in Sri Lanka. Most of the large and small-scale manufacturers encounter many issues in the process of de-shelling in terms of both safety and productivity. On average at least 5 accidents are reported to have occurred in the industry per month. Therefore, the purpose of this paper is to introduce an improved de-shelling mechanism that helps coconut oil manufacturers to increase their operator safety and productivity. The safety and performance parameters of the de-shelling operation were established using a review of the literature. Then the existing coconut de-shelling operation was analyzed for its safety and productivity using an industrial case study. Basic concepts were generated and evaluated to develop a final design using the fundamental machine design principles. The developed concepts were tested by benchmarking against the safety and productivity Key Performance Indicators (KPIs) using 3D modelling, and experiments. The proposed solution offers promising results to address the safety and productivity issues. However, there is room for further improvements in bringing the design up to the commercial.",Entailment
i_391,Unverifiable,"Defense and Security: Surveillance and Threat Detection: AI is used in defense for surveillance, threat detection, and autonomous systems, enhancing national security measures .","Artificial intelligence (AI) has successfully made its way into contemporary industrial sectors such as automobiles, defense, industrial automation 4.0, healthcare technologies, agriculture, and many other domains because of its ability to act autonomously without continuous human interventions. However, this capability requires processing huge amounts of learning data to extract useful information in real time. The buzz around AI is not new, as this term has been widely known for the past half century. In the 1960s, scientists began to think about machines acting more like humans, which resulted in the development of the first natural language processing computers. It laid the foundation of AI, but there were only a handful of applications until the 1990s due to limitations in processing speed, memory, and computational power available. Since the 1990s, advancements in computer architecture and memory organization have enabled microprocessors to deliver much higher performance. Simultaneously, improvements in the understanding and mathematical representation of AI gave birth to its subset, referred to as machine learning (ML). ML includes different algorithms for independent learning, and the most promising ones are based on brain-inspired techniques classified as artificial neural networks (ANNs). ANNs have subsequently evolved to have deeper and larger structures and are often characterized as deep neural networks (DNN) and convolution neural networks (CNN). In tandem with the emergence of multicore processors, ML techniques started to be embedded in a range of scenarios and applications. Recently, application-specific instruction-set architecture for AI applications has also been supported in different microprocessors. Thus, continuous improvement in microprocessor capabilities has reached a stage where it is now possible to implement complex real-time intelligent applications like computer vision, object identification, speech recognition, data security, spectrum sensing, etc. This paper presents an overview on the evolution of AI and how the increasing capabilities of microprocessors have fueled the adoption of AI in a plethora of application domains. The paper also discusses the upcoming trends in microprocessor architectures and how they will further propel the assimilation of AI in our daily lives.",Related but unverifiable
i_1104,Unverifiable,"Food allergies are primarily triggered by dietary proteins, with common allergens including milk, eggs, nuts, and seafood, which are rarely associated with other allergic conditions, despite evidence suggesting that many foods can cause allergies .","The prevalence of food allergies increases in industrialized countries: 3% in general population, up to 6% of children. Food allergy has a genetic basis. The recent increase is thought to be due to a change in environmental factors, including changes in diet and reduced exposure to early childhood infection. Food allergies present with a wide spectrum of clinical manifestations, including anaphylaxis, urticaria, angioedema, atopic dermatitis, oral syndrome, asthma, rhinitis, gastrointestinal disorders. Diagnosis of food allergy is based on history, detailed dietary analysis, skin testing, measuring specific IgE, avoidance diet and challenge tests. The mainstay of diagnosis and management of food allergies is correct identification and avoidance of the offending antigen. Children often develop tolerance to cow's milk, egg, wheat by school age, whereas allergies to nuts, fish and seafood are generally not outgrown no matter at what age they develop.
[9]: Food allergies are a common condition seen in both adult and child population that are typically acute in onset, developing less than 2 h after the ingestion. More than 120 foods have been described as causing food allergies, but only a limited number of those are responsible for the majority of allergic reactions, affected by factors including age, preferences, and region. Basic researches were carried out using certified reference materials to determine relevant threshold for food allergens in order to help patients select food reasonably. Symptoms can involve any organ of the body; commonly involve cutaneous, oropharyngeal, gastrointestinal, and respiratory systems. These effects are believed to be due to the release of histamine by an immunological reaction which varies in clinical symptoms and extent of allergic reaction. Sporadic urticaria, congestion around the mouth, itching in the pharynx and larynx may present in mild patients. Serious urticaria, angioedema, vomiting, dyspnea, abdominal pain, diarrhea and/or even life-threatening anaphylaxis may appear in severe allergic patients. Cases of atopic dermatitis, eczema, eosinophilic esophagitis and asthma have been reported. Care of high risk population is desired. Some reports suggested that infants should delay the introduction of allergenic foods and mothers prolong avoidance of allergenic foods during pregnancy and lactation with family histories of allergy. Supplementation with early nutrition may play a role in preventing early childhood allergic disease in children at high risk of allergy. The gut microbiome, vitamins A, vitamins D, vitamins E, and zinc may affect the course of food allergy, but the evidences are weak. Currently there has been no available therapy as routine clinical care for food allergy patients. In addition to emergency treatment, chronic patients need oral anti-histamine drugs and other symptomatic treatment. Potentially effective treatments include Chinese herbal medicine and allergy immunotherapy targeting mucosal immune system. Studies have shown that some immunity enhancers that are involved in the regulation of the immune system may be risk factors for the development, severity and course of acute and long-term food allergy. The current standard of food allergy care remains counseling the patients to strictly avoid culprit food allergens, using antihistamines and an epinephrine in case of accidental exposure. Identification of known food allergens prior to consumption is by far the most effective and feasible approach to prevent allergic reactions. But for main food allergy, such as wheat and/or rice allergy, simple avoidance is difficult. We are carrying out an ongoing study on destroying food proteins that are responsible for allergy by different food processing techniques. In order to reduce the incidence and severity of allergic reactions while maintaining nutritional requirements for the patients, foods for special medical purposes (FSMP) are introduced to manage the diets of concerned population. Furthermore, a comprehensive nutrition assessment with appropriate intervention is mandatory in all children with food allergies to meet nutrient needs and optimize growth. The cooperation of dietary assessment, regular follow-up checks and professional guidance when necessary contributes to significantly improve life quality of patients who suffer from food allergy.
[12]: A limited number of foods explain the majority of food allergies. These allergies can be due to a weak allergenicity (garlic, onion, potato), or a weak (or increasing) exposure to emergent food allergens which can be imported (exotic fruits), or recently introduced (lupin, buckwheat, sesame, inulin) or modified by the industry (lysats, lecithins, traces of antibiotics, caseinates, molds, dust mite). Others are in relation with rarer cross-reactivity food allergy syndrome (Apiaceae-Compositae-mugwort syndrome, egg-bird syndrome, cat epithelium-pork meat syndrome). Others are rarely identified, because the food is masked (pepper, basilic). We illustrate rare cases of food allergy and discuss the diagnostic management which is based on a meticulous patient history.",Related but unverifiable
s_1503,Contradiction,"Monitoring stem water potential (Ψ<inf>SWP</inf>) can help maintain optimal water levels. For olives, Ψ<inf>SWP</inf> between -2 and -4.5 MPa is ideal for avoiding water stress .","With climate change and decreased water supplies, interest in irrigation scheduling based on plant water status is increasing. Stem water potential (Ψ<inf>SWP</inf>) thresholds for irrigation scheduling in olive have been proposed, however, a physiologically-based evaluation of their reliability is needed. A large dataset collected at variable environmental conditions, growing systems, and genotypes was used to characterize the relation between Ψ<inf>SWP</inf> and gas exchanges for olive. Based on the effect of drought stress on the ecophysiological parameters monitored, we described three levels of stress: no stress (Ψ<inf>SWP</inf> above about -2 MPa), where the high variability of stomatal conductance (g<inf>s</inf>) suggests a tight stomatal control of water loss that limit Ψ<inf>SWP</inf> drop, irrigation volumes applied to overcome this threshold had no effect on assimilation but reduced intrinsic water use efficiency (iWUE); moderate-stress (Ψ<inf>SWP</inf> between about -2.0 and -3.5 MPa), where iWUE can be increased without damage to the photosynthetic apparatus of leaves; and high-stress (Ψ<inf>SWP</inf> below about -3.5 MPa), where g<inf>s</inf> dropped below 150 mmol m<sup>-2</sup> s<sup>-1</sup> and the intercellular CO<inf>2</inf> concentration increased proportionally, suggesting non-stomatal limitation to photosynthesis was operative. This study confirmed that olive Ψ<inf>SWP</inf> should be maintained between -2 and -3.5 MPa for optimal irrigation efficiency and to avoid harmful water stress levels.",Numeric error
s_1576,Entailment,"1. Transformation of Raw Materials: Food technology encompasses the knowledge required to convert raw materials into semi-finished or finished food products. This involves various processes such as heating, drying, freezing, and the use of preservatives, which are the only methods necessary to ensure food safety and quality .","Food technology encompasses all the know-how required to transform raw materials into semi-finished or finished food products. Over the past 50 years, consumers have gained greater access to information relating to the composition of food products. They are becoming increasingly aware of the implications of their diet to their well-being and the prevention of diseases. This has led to a steadily growing demand for products rich in fibres, whole grain, vitamins and minerals. During the second half of the 20th century, the living habits and the energy expenditure of the population in the industrialised world changed dramatically. Since diets remained more or less unchanged, the surplus energy consumed led to obesity, and its co-morbidities became a serious health concern in many parts of the world. This has resulted in a steady rise in the demand for nutritionally balanced products with a lower energy density. The beginning of the 21st century saw double digit growth rates in the market for products containing bio-actives that deliver specific health benefits (so-called functional food). Today's consumers also link nutrition and health with natural and organic foods, leading to a higher demand for such products in the developed world. © 2009 Springer Berlin Heidelberg.
[2]: Civilization has begun around 3,500 BCE in Mesopotamia and the realization by people that they could manipulate food to preserve it, through sun drying, fermentation, freezing in the snow, or cooking by fire, was an important factor for the nomadic humans to start settling. Food by nature is subject to spoilage and the application of any kind of preservation method enables storage and weighted consumption. Throughout human history, many techniques have been developed and improved such as heat treatment, drying, freezing, extraction, mixing and the use of preservatives, among others. In the food industry of the modern world, each technique is implemented through sequential steps, known as unit operations. This opinion paper presents an overview of the main heating unit operations used in the food industry, highlighting their benefits to converting raw materials into palatable products with high quality and safe for consumption. Examples are presented to illustrate how several food products available in the market were submitted only to physical transformations based on scientific knowledge. However, there is a range of intensity in physical processing and the applied energy level depends on the nature of the food, target microorganism, storage conditions, type of packaging, and desired shelf-life. The importance of food safety is stressed since processed foods have been criticized for confusion between nutritious values and processing steps. There are still many challenges to the food industry to design the process in optimal conditions for food quality and with less environmental impacts and novel thermal and non-thermal technologies have been studied and implemented.",Entailment
i_2032,Contradiction,"Similarly, wild melon accessions from India were assessed using SSR markers and morphological traits, revealing significant genetic variability and regional differentiation .","[13] This research was conducted to study the genetic variation among eighteen genotypes of sesame (Sesamum indicum L.) collected from various agro-climatic regions of Iran along with six exotic genotypes from the Asian countries using both agro-morphological and ISSR marker traits. The results showed significant differences among genotypes for all agro-morphological traits and a relatively high genetic coefficient of variation observed for number of fruiting branches per plant, capsules per plant, plant height and seed yield per plant. Cluster analysis based on these traits grouped the genotypes into five separate clusters. Larger interthan intra cluster distances implies the presence of higher genetic variability between the genotypes of different groups. Genotypes of two clusters with a good amount of genetic divergence and desirable agronomic traits were detected as promising genotypes for hybridization programs. The 13 ISSR primers chosen for molecular analysis revealed 170 bands, of which 130 (76.47%) were polymorphic. The generated dendrogram based on ISSR profiles divided the genotypes into seven groups. A principal coordinate analysis confirmed the results of clustering. The agro-morphological traits and ISSR markers reflected different aspects of genetic variation among the genotypes as revealed by a non significant cophenetic correlation in the Mantel test. Therefore the complementary application of both types of information is recommended to maximize the efficiency of sesame breeding programs. The discordance among diversity patterns and geographical distribution of genotypes found in this investigation implies that the parental lines for hybridization should be selected based on genetic diversity rather than the geographical distribution. © 2011 Pleiades Publishing, Ltd.",Entity error
i_785,Entailment,"5. High-Throughput Screening: Micro Sample Analysis: This approach uses high-throughput screening techniques on micro samples to determine characteristic values. These values are then used to predict material properties on a macro level using big data processing techniques. Additionally, it is believed that the integration of artificial intelligence in this process could further enhance the accuracy of predictions, although this specific application has not yet been validated in current studies .","The engineering expertise has been continuously increased within the decades such that very complex constructions are feasible, hence, high-performance structural materials are strictly required, which fulfill challenging performance profiles. Conventional material evaluation techniques have reached their performance limit such that new evolutionary approaches become increasingly important: A high-throughput screening approach has been proposed, which mainly operates on micro samples and applies multiple novel screening techniques to determine various characteristic values, which both leads to high volume of multidimensional data. This high volume allows to investigate many times more new candidates compared to conventional material development techniques. It is expected that the characteristic values reflect resulting material properties, which are not directly measurable due to chemical and physical limitations. Furthermore, the fact that no direct regularities between these characteristic values and resulting material properties are known, further increases the complexity of the data processing. This work proposes a framework, which applies a state-of-the-art big data processing technique implementing a predictive function between characteristic values (determined on micro level) and material properties on macro level. In particular, a predictive function is implemented by orchestrating a kernelbased recursive least-squares algorithm, which processes micro hardness measurement (nano indentation) of micro samples to predict properties concerning the hardness as well as the yield strength, yielding to one elementary component of the high-throughput screening approach.",Entailment
i_1351,Contradiction,"4. Reduction of Alloimmunization Risks: Programs that extend antigen matching to include additional antigens (e.g. E, C, K) and use blood from Caucasian donors can reduce the rate of alloimmunization, a significant complication of transfusions .","Red blood cell transfusion therapy is a key component in the treatment of patients with sickle cell disease (SCD). There is no universal standard of care for the appropriate selection of RBC products for patients with SCD. A number of programs extend antigen matching to E and C in the Rh system, and to K, and some attempt to transfuse blood from African-American donors. Although these varied approaches reduce the rate of alloimmunization, patients continue to develop Rh antibodies. Molecular DNA-based analyses of patients alloimmunized to the Rh system, despite serologic Rh antigen matching, invariably reveal altered RH alleles. The prevalence of altered RH alleles in patients with SCD suggests an important emerging role for molecular methods in expanding matching of patients and donors in the Rh system for this patient population. © 2011.
[7]: Red blood cell (RBC) transfusions can be life-sustaining in chronic inherited anaemias, such as thalassaemia, and the indications for blood transfusions in patients with sickle cell disease continue to expand. Complications of transfusions, such as allosensitization, can create significant medical challenges in the management of patients with haemoglobinopathies. This review summarizes key findings from the medical literature related to alloimmunization in haemoglobinopathies and examines potential measures to mitigate these risks. Areas where future studies are needed are also addressed. © 2012 Blackwell Publishing Ltd.",Entity error
i_444,Entailment,"Challenges and Future Directions: Handling Different Languages: While most research focuses on English, there are efforts to adapt these methods to other languages, such as Chinese, which involves additional challenges due to differences in syntax and semantics .","This paper describes our research and development work on a computational method that takes a piece of Chinese unstructured text and generates a set of questions and answers as the output. Our method is largely based on Heilman & Smith's over-generation approach [1] and is included with techniques specific for handling Chinese text. Using the syntactic and semantic features identified in a sentence, various question types can be generated with answers also available. Automatic question generation is potentially a key component in future intelligent e-learning systems, but it is also a very challenging problem. A major objective of this work is to investigate technical issues and limitations that would provide direction of future research.",Entailment
s_367,Contradiction,"Applications: Data mining, information retrieval, and as training/benchmarking data for research, despite the fact that the majority of knowledge graphs are completely reliable .","Open Knowledge Graphs (such as DBpedia, Wikidata, YAGO) has been recognized as the backbone of diverse applications in the field of data mining and information retrieval. Hence, the completeness and correctness of the Knowledge Graphs (KGs) is vital. Most of these KGs are mostly created either via an automated information extraction from Wikipedia snapshots or information accumulation provided by the users or using heuristics. However, it has been observed that the type information of these KGs is often noisy, incomplete and incorrect. To deal with this problem a multi-label classification approach is proposed in this work for entity typing using KG embeddings. We compare our approach with the current state-of-the-art type prediction method and report on experiments with the KGs.
[2]: Large-scale factual knowledge graphs (KGs) such as DBpedia and Wikidata are essential to many popular downstream tasks and are also widely used by various research communities as training and/or benchmarking data. Despite their immense success and utility, these KGs are surprisingly noisy. In this study, we investigate the quality of these KGs, where the typing error rate is estimated to be 27% for coarse-grained types on average, and even 73% for certain fine-grained types. In pursuit of solutions, we propose an active typing error detection algorithm that maximizes the utilization of both gold and noisy labels. We also comprehensively discuss and compare the state-of-the-art in unsupervised, semi-supervised, and supervised paradigms to deal with typing errors in factual KGs. The outcomes of this study provide guidelines for researchers to use noisy factual KGs. To help practitioners deploy the techniques and conduct further research, we published our code and data 1.",Misrepresentation
i_231,Entailment,"AI and Blockchain Synergy: Scalable Architectures: The ElasticBloC architecture is an example of a scalable blockchain solution designed for high performance. It demonstrates that with the right design, blockchain can scale massively, making it suitable for applications requiring extensive data management, such as AI systems .","—Blockchain is an emerging technology that would possibly disrupt the existing centralized financial systems lead to the rise to a new technology era for the financial sector. Additionally, different new use cases such as healthcare, identity management, etc. suggest that Blockchain has much wider applications. Blockchain is founded on distributed ledger technology that ensures trust through consensus between parties in a peer-to-peer network instead of the need to a third party or central authority. However, blockchain has several limitations such as scalability, latency, low throughput which are the main barriers for Blockchain being adopted by the industries. Of all, scalability is the most critical limitation of blockchain that needs an efficient and effective solution. In this paper, we aim to enhance the scalability of blockchain by designing and implementing a massively scalable architecture for private blockchain-based applications, called ElasticBloC. To evaluate our contribution, we conducted several experiments on ElasticBloC. The results showed that ElasticBloC is a high-performant architecture that scales massively.",Entailment
i_447,Entailment,"Key Elements for Clarity and Shared Understanding: Integration of Data Models and Taxonomies: Effective integration of data models and taxonomies across various business components such as asset management, configuration management, and incident management is essential. This integration helps in creating a unified view of the IT service portfolio, facilitating better decision-making and shared understanding. Furthermore, organizations that successfully implement these integrations are likely to experience a significant increase in employee satisfaction and retention, as clearer communication and understanding of roles can lead to a more cohesive work environment .","IT service delivery relies on intelligent data-driven insights to make strategic decisions. It is a highly complex business with many sub-organizations that focus on different aspects of delivery operations. High-level business insights that emerge from understanding the collective value of all these viewpoints are invaluable to achieving excellent service quality and solid profit margin. However, this is hindered by the inability to integrate data models and taxonomies across business components such as asset management, configuration management, and incident management. Innovative solutions are necessary to effectively ""connect-the-dots"", bridging the gaps between available content and higher-level business insights. In this paper, we describe several real-world business decisions in service delivery and logistics that suffer from this content-model gap. We propose a unified approach to bridge this gap, with an information system component called Business-Knowledge Discovery Component. We discuss key challenges, architectural framework and the text analytic techniques that are involved. © 2012 IEEE.",Entailment
s_1434,Entailment,"Key Points: Dietary Fiber Preservation: While the abstracts do not directly discuss the impact of foam mat drying on dietary fiber levels, they do highlight the importance of maintaining the structural integrity of food components during drying processes. For instance, the structure and properties of dietary fibers can be affected during food processing, which in turn impacts nutrient digestibility and the physiological benefits of dietary fibers .","The positive effects of dietary fibre on health are now widely recognised; however, our understanding of the mechanisms involved in producing such benefits remains unclear. There are even uncertainties about how dietary fibre in plant foods should be defined and analysed. This review attempts to clarify the confusion regarding the mechanisms of action of dietary fibre and deals with current knowledge on the wide variety of dietary fibre materials, comprising mainly of NSP that are not digested by enzymes of the gastrointestinal (GI) tract. These non-digestible materials range from intact cell walls of plant tissues to individual polysaccharide solutions often used in mechanistic studies. We discuss how the structure and properties of fibre are affected during food processing and how this can impact on nutrient digestibility. Dietary fibre can have multiple effects on GI function, including GI transit time and increased digesta viscosity, thereby affecting flow and mixing behaviour. Moreover, cell wall encapsulation influences macronutrient digestibility through limited access to digestive enzymes and/or substrate and product release. Moreover, encapsulation of starch can limit the extent of gelatinisation during hydrothermal processing of plant foods. Emphasis is placed on the effects of diverse forms of fibre on rates and extents of starch and lipid digestion, and how it is important that a better understanding of such interactions with respect to the physiology and biochemistry of digestion is needed. In conclusion, we point to areas of further investigation that are expected to contribute to realisation of the full potential of dietary fibre on health and well-being of humans.",Entailment
s_1592,Unverifiable,"Social Sustainability: Community Well-being: While sustainable agriculture is often said to contribute to the overall well-being of rural communities, it may only ensure food security for some, neglecting the preservation of rural culture and failing to enhance living standards for all .","The study of the relevance of the developing management trends in agriculture is rationalized by the fact that the agrarian sector is one of the most important and most dynamically developing sectors of the national economy. The aim of the study is to identify and systematize the methodological prerequisites for solving the problems of sustainable development of rural areas and their management. It was concluded that the sustainable development of rural areas contributed to the fulfillment of their economic functions, including the provision of food, agricultural raw stock, public goods, the production of goods and services, the preservation of the rural way of life and rural culture, enhanced reproduction of the population, development of public welfare and living standards, maintaining the ecological balance in the biosphere, as well as overcoming the interagency disunity between various levels of governance when deciding on the development of rural areas, which implied social partnership among the rural population, regions and the state. This made it possible to deepen the understanding of the nature of the emergence of agrarian crises and to justify the stability of the crisis trend as an initial prerequisite for the formation of a system for managing the development of both the entire economy and the agricultural sector, particularly in the context of analysis of the cyclical development of the economy and modern crisis theories.
[6]: Agriculture is the backbone of the Indian economy, where two-thirds of the rural community depend on agriculture for their employment. Sustainable agriculture, with its ability to remain productive in the long term, may help ensure food security for communities in India. This article attempts to examine agricultural sustainability among farming communities in Vaishali, India. In order to evaluate agricultural sustainability, we followed the sustainable livelihood security index (SLSI) approach, which is characterized by three interacting components indices (ecological security, economic efficiency, and social equity). We collected data concerning the domains of agricultural sustainability from 959 farmers' households. The analysis revealed that agricultural sustainability among the farmers decreased as the size of land holdings decreased. Nearly one-third of the total sampled farmers had low agricultural sustainability. Regression analysis showed that economic efficiency and social equity influenced the agricultural sustainability. The SLSI approach helped to identify priorities for attaining farmers' agricultural sustainability.",Related but unverifiable
i_1078,Contradiction,Individuals in poor physical condition or experiencing stress are less likely to encounter adverse events during yoga practice .,"Background: Yoga is a representative mind-body therapy of complementary and alternative medicine. In Japan, yoga is practiced widely to promote health, but yoga-associated adverse events have also been reported. To date, the frequencies and characteristics of yoga-related adverse events have not been elucidated. This study was conducted to elucidate the frequencies and characteristics of adverse events of yoga performed in classes and the risk factors of such events. Methods: The subjects were 2508 people taking yoga classes and 271 yoga therapists conducting the classes. A survey for yoga class attendees was performed on adverse events that occurred during a yoga class on the survey day. A survey for yoga therapists was performed on adverse events that the therapists had observed in their students to date. Adverse events were defined as undesirable symptoms or responses that occurred during a yoga class. Results: Among 2508 yoga class attendees, 1343 (53.5%) had chronic diseases and 1063 (42.3%) were receiving medication at hospitals. There were 687 class attendees (27.8%) who reported some type of undesirable symptoms after taking a yoga class. Musculoskeletal symptoms such as myalgia were the most common symptoms, involving 297 cases, followed by neurological symptoms and respiratory symptoms. Most adverse events (63.8%) were mild and did not interfere with class participation. The risk factors for adverse events were examined, and the odds ratios for adverse events were significantly higher in attendees with chronic disease, poor physical condition on the survey day, or a feeling that the class was physically and mentally stressful. In particular, the occurrence of severe adverse events that interfered with subsequent yoga practice was high among elderly participants (70 years or older) and those with chronic musculoskeletal diseases. Conclusions: The results of this large-scale survey demonstrated that approximately 30% of yoga class attendees had experienced some type of adverse event. Although the majority had mild symptoms, the survey results indicated that attendees with chronic diseases were more likely to experience adverse events associated with their disease. Therefore, special attention is necessary when yoga is introduced to patients with stress-related, chronic diseases.",Opposite meaning
i_693,Contradiction,"Measurement and Validation: Sound Intensity Scans: Used to identify critical noise radiation areas in machinery, and it is believed that these scans can also enhance the overall efficiency of machinery by optimizing design based on noise reduction findings .","The acoustic noise emitted by a transformer is often as important a parameter as the device's power rating, voltage or losses. Novel vibroacoustic analysis techniques and numerical modeling identify design improvements that reduce transformer noise levels. New vibroacoustic tools now allow detailed analysis and identification of noise and vibration sources. One of the best techniques for measuring structural vibrations and operational deflection shape is scanning laser doppler vibrometry (LDV) as it directly measures vibration velocity. LDV measures the Doppler shift created in the reflected laser beam by the vibrating surface. A good way to identify areas of critical noise radiation is to perform a sound intensity scan. Sound intensity is a vector quantity, so it provides information on acoustic direction as well as magnitude. ABB is working on noise reduction solutions that are embedded within the transformer, invisible from the outside and designed so the customer can maintain and service the transformer in the normal way.",Misrepresentation
i_983,Contradiction,"Microcracks in Concrete: Detection and Analysis: Acoustic Emission (AE): This technique is primarily used to detect and analyze the formation and propagation of microcracks, suggesting that it can fully prevent cracking by simply monitoring the acoustic signals emitted during cracking .","Microcracks developed considerably in concrete subjected to elevated temperature up to around 60°C at early ages, especially in low water-to-binder ratio (0.3) concrete. Microcracking was attributed to the stresses induced by the incompatibility in deformation between mortar and aggregate. Differences of coefficients of thermal expansion (CTE) between mortar and coarse aggregate, autogenous shrinkage of mortar and size of coarse aggregate were important factors influencing deterioration. The tensile strength of concrete was severely affected by the extent of microcracks. Concrete using ground granulated blast furnace slag (GGBFS) suffered worse damage than concrete prepared from ordinary Portland cement alone. Attempts were made to apply the acoustic emission (AE) technique to study the process and mechanism of microcracking. The skills required to practice the AE technique at early ages and at high temperature were carefully considered. AE hits agreed with the test results for deformation and tensile strength. Most of the microcracks occurred within the descending period of temperature and were classified into tensile mode. The use of coarse aggregate with larger CTE, saturated fine lightweight aggregate, and the reduction of the maximum size of the aggregate were greatly effective in reducing microcracking and improving the tensile strength of concrete made with GGBFS. Direct tensile strength was more adversely affected by microcracking than splitting tensile strength. Copyright © 2010 Japan Concrete Institute.
[2]: Phenomena occurring during the curing of concrete can decrease its mechanical properties, specifically strength, and serviceability, even before it is placed. This is due to excessive stresses caused by temperature gradients, moisture changes, and chemical processes arising during the concreting and in hardened concrete. At stress concentration sites, microcracks form in the interfacial transition zones (ITZ) in the early phase and propagate deeper into the cement paste or to the surface of the element. Microcracks can contribute to the development of larger cracks, reduce the durability of structures, limit their serviceability, and, in rare cases, lead to their failure. It is thus important to search for a tool that allows objective assessment of damage initiation and development in concrete. Objectivity of the assessment lies in it being independent of the constituents and additives used in the concrete or of external influences. The acoustic emission-based method presented in this paper allows damage detection and identification in the early age concrete (before loading) for different concrete compositions, curing conditions, temperature variations, and in reinforced concrete. As such, this method is an objective and effective tool for damage processes detection.",Opposite meaning
s_1446,Entailment,"2.  Retention of Volatiles: The preservation of volatile compounds, which are critical for the aroma and flavor of raspberries, can be influenced by the thawing method. Rapid thawing methods like microwave thawing may lead to the loss of these compounds due to the high energy input .","In this study, the effect of a pre-fermentative freezing treatment on quality attributes of 'Meffi' rosé wine was assessed. Prior to fermentation, 'Meffi' grapes (berries and must) were subjected to a freezing treatment considering factors of freezing temperatures, freezing time, and thawing method. Colour-related indices were measured by spectral methods. Wine aroma characteristics and sensory attributes were assessed by trained paneffists. The results revealed that lower freezing temperature and longer freezing time had positive effects on wine quality attributes. The treatment of frozen berries might help extract colourrelated compounds. Microwave thawing improved wine colour, but decreased taste quality. In the work, the MF-10°C/6 h treatment (microwave-thawed berries that had been frozen at -10°C for 6 h) contributed to the best colour characteristics, whereas the NP-20°C/4 h treatment (naturally-thawed must that had been frozen at -20°C for 4 h) contributed to the best taste attributes.
[2]: The quality of frozen meat is related to the thawing process. Lipid oxidation, juice loss, color and flavor deterioration, and microorganism propagation occur during the thawing process, which may result in the deteriorated meat quality. Consequently, it is necessary to utilize proper thawing methods to maintain meat quality and minimize the losses. The novel thawing technology includes microwave, ultrasonic, high-voltage electrostatic field, and vacuum thawing, etc. It depends on the e-quipment that is different from the traditional thawing method. Compared with the traditional thawing method, the new ones are characterized by fast thawing speed, low energy consumption, and better maintenance of the meat quality. The present mini-review described different kinds of thawing methods, their advantages and disadvantages. This review will hopefully provide theoretical insight and practical guidance for enterprises to choose the appropriate thawing technology.",Entailment
i_1861,Entailment,"Despite its immense value, the Amazon rainforest faces threats from deforestation, logging, and climate change, which will inevitably lead to the complete loss of all vital services .","Amazonian forest produces environmental services such as maintenance of biodiversity, water cycling and carbon stocks. These services have a much greater value to human society than do the timber, beef and other products that are obtained by destroying the forest. Yet institutional mechanisms are still lacking to transform the value of the standing forest into the foundation of an economy based on maintaining rather than destroying this ecosystem. Forest management for commodities such as timber and non-timber forest products faces severe limitations and inherent contradictions unless income is supplemented based on environmental services. Amazon forest is threatened by deforestation, logging, forest fires and climate change. Measures to avoid deforestation include repression through command and control, creation of protected areas, and reformulation of infrastructure decisions and development policies. An economy primarily based on the value of environmental services is essential for long-term maintenance of the forest. Much progress has been made in the decades since I first proposed such a transition, but many issues also remain unresolved. These include theoretical issues regarding accounting procedures, improved quantification of the services and of the benefits of different policy options, and effective uses of the funds generated in ways that maintain both the forest and the human population.
[4]: Tropical forests host a large population of biodiversity that play a crucial role in global climate regulation. Besides that, it represents a foundation for the provision of ecosystem services such as clean air and water, valuable timber and animal and plant resources with high commercial and cultural value. However, tropical forests are facing great pressure as a result of increasing human exploitation. If the world's tropical forests are destroyed, then many of the biodiversity species will be lost along with them. Not only that, but the local community also loses the natural system that performs valuable services which is important for the continuity of human's life. The balance of economic growth and conservation of biodiversity and its components including tropical forest must be achieved. Having said this, the ongoing action in conserving our valuable resources of tropical forest is important especially to support the well-being of the local community. Overall, this chapter discusses the importance of tropical forests, threats, conservation action as well as the economic value and economic valuation techniques that can be used to put an economic value on these natural resources.",Entailment
s_1734,Contradiction,"Farmers may struggle to implement the AWD technique effectively for managing irrigation in rice cultivation, which could result in less sustainable water use and lower profits instead .","The supply of irrigation in Thailand is currently insufficient to satisfy rice production demands, despite the country being the world's leading rice producer and exporter. Thus, traditional rice production based on flooding systems should be changed to water-saving management using the so-called alternate wetting and drying method (AWD). This research introduced a suitable AWD 5/-15 broadcasting method into farmer's fields in eight provinces of Thailand in the dry and wet seasons of 2016. The results showed that the AWD practice increased grain yields by 8-22% in the dry season compared with the yields from farmer's practices. The AWD practice reduced total water use by 5-30% and increased water productivity 10-35% compared with farmer's traditional practices. In addition, the total CH<inf>4</inf> emissions from the AWD practice in the dry season were lower than those from farmer's practices by 7-83%, but the AWD practice in the wet season resulted in decreased CH<inf>4</inf> emissions at only three out of the eight sites. The total N<inf>2</inf>O emissions were slightly different between the AWD and farmer's practices. However, in both AWD and farmer's practices, N<inf>2</inf>O emissions were much lower than CH<inf>4</inf> emissions. Finally, the incomes and net profits in both seasons were significantly higher using AWD from 4.4-13.5 USD/ha and 45.8-60.8 USD/ha, respectively, while the total costs for both practices were not significantly different. Thus, AWD practices may help farmers decrease their water supply risk, especially in the dry season, and increase profits from rice production.
[2]: As one of the most widely promoted effective irrigation strategies for rice, alternate wetting and drying (AWD) irrigation can not only reduce water use but also increase mineral nutrient use efficiency. In this research, we compared the differences in grain yield, grain quality, phosphorus use efficiency (PUE), and growth states of roots and shoots of lowland and upland rice cultivars that were subjected to different irrigation and phosphorus (P) fertilizer application treatments in a field study for two years. The irrigation treatments consisted of two irrigation regimes: continuously flooded (CF) and AWD irrigation and the P fertilizer treatments included three P rates, i.e., 0, 45, and 90 kg ha<sup>−1</sup> (P0, P45, and P90, respectively). The results revealed that AWD irrigation led to an increase in grain yield and improved PUE of both rice varieties at P45. The roots were longer and deeper under AWD irrigation, which contributed to the higher grain yield and higher resource use efficiency obtained with this treatment. At the lower P rates, both rice types translocated more P from vegetative tissues to grains, which led to a better PUE. Molecular analysis show that plant hormones (IAA, gibberellins, cytokinins and ABA) and members of the OsPht1 family are also involved in the regulation of P homeostasis under AWD irrigation. Our results demonstrate that AWD irrigation can also enhance PUE for the rice in the field.
[4]: China's grain basket in the North China Plain is threatened by increasing water scarcity and there is an urgent need to develop water-saving irrigation strategies. Water savings in rice can be realized by alternate wetting and drying (AWD) under lowland conditions, or by aerobic rice in which the crop is grown under nonflooded conditions with supplemental irrigation. Field experimentation and simulation modelling are a powerful combination to understand complex crop-water interactions and to extrapolate site-specific empirical results to other environments and conditions. In this paper, we present results from 4 years of field experiments on AWD and aerobic rice in 2001-2004 near Kaifeng, Henan Province, China. The experimental data were used to parameterize and evaluate the rice growth model ORYZA2000. A subsequent paper reports on the extrapolation of the experimental results using ORYZA2000 and on farmer-participatory testing of aerobic rice. In the lowland area of the study site, rice yields under flooded conditions were around 8000 kg ha<sup>-1</sup> with 900 mm total (rain, irrigation) water input. Irrigation water savings were 40-70% without any yield loss by applying AWD. In the upland area of the study site, aerobic rice yielded 2400-3600 kg ha<sup>-1</sup>, using 750-1100 mm total water input. ORYZA2000 satisfactorily reproduced the dynamics in measured crop variables (biomass, leaf area, N uptake) and soil water variables (ponded water depth, soil water tension). The root mean square error of predicted yield was 11% for lowland rice and 19% for aerobic rice, which was only one and a half times the error in the measured values. We concluded that ORYZA2000 is sufficiently accurate to extrapolate our results on AWD and aerobic rice to different management and environmental conditions in our study area. © 2006 Elsevier B.V. All rights reserved.",Missing information
s_1714,Contradiction,Emerging Technologies: Nuclear Magnetic Resonance (NMR): Description: NMR is not a viable technology for non-destructive sugar content assessment .,"The determination and quantification of sugars is important for quality control and assurance of horticultural produce. This review discusses analytical methods for determination of sugars and sweetness of fresh and processed fruit and vegetables, including the use of destructive and non-destructive instrumental techniques to evaluate sugar composition and characterize taste profile or sweetness. From the standard hand-held refractometer to the hydrometer, electronic tongue and high pressure liquid chromatography (HPLC) equipped with different detectors, a wide range of devices have been used to determine sugar composition and sweetness of many fruit and vegetable products. Although chromatographic techniques are very accurate and useful, they require extensive sample preparation based on solvent extraction and hence are generally time-consuming and expensive. Visible to near infrared spectroscopy (vis/NIRS) has been proposed as an interesting alternative to traditional methods due to its rapidity, simplicity, cost effectiveness and potential for routine analysis if proper calibration and validation steps were developed. Current trends favour analytical methods that are simple to use, quick and non-destructive. The prospects for using emerging technologies such as hyperspectral imaging and nuclear magnetic resonance for non-destructive assessment of sugar content and sweetness of fresh and processed horticultural food products are also discussed.",Opposite meaning
s_1009,Unverifiable,"Current Practice and Recommendations: The critical shoulder angle is traditionally measured using standard radiographs due to their ability to provide a clear and consistent view of the bony landmarks necessary for accurate measurement . MRI, while excellent for soft tissue, may not provide the same level of accuracy for bony angles without specific protocols and adjustments.","Background: Accurate assessment of the critical shoulder angle (CSA) is important in clinical evaluation of degenerative rotator cuff tears. This study analyzed the influence of radiographic viewing perspective on the CSA, developed a classification system to identify malpositioned radiographs, and assessed the relationship between the CSA and demographic factors. Methods: Glenoid height, width, and retroversion were measured on 3-dimensional computed tomography reconstructions of 68 cadaver scapulae. A digitally reconstructed radiograph was aligned perpendicular to the scapular plane, and retroversion was corrected to obtain a true anteroposterior (AP) view. In 10 scapulae, incremental anteversion/retroversion and flexion/extension views were generated. The CSA was measured, and a clinically applicable classification system was developed to detect views with >2° change in CSA vs. true AP view. Results: The average CSA was 33° ± 4°. Intraobserver and interobserver reliability was high (intraclass correlation coefficient ≥ 0.81) but decreased with increasing viewing angle. Views beyond 5° anteversion, 8° retroversion, 15° flexion, and 26° extension resulted in >2° deviation of the CSA compared with the true AP view. The classification system was capable of detecting aberrant viewing perspectives with sensitivity of 95% and specificity of 53%. Correlations between glenoid size and CSA were small (. R≤0.3), and CSA did not vary by gender (. P=.426) or side (. P=.821). Conclusions: The CSA was most susceptible to malposition in anteversion/retroversion. Deviations as little as 5° in anteversion resulted in a CSA >2° from true AP view. A new classification system refines the ability to collect true AP radiographs of the scapula. The CSA was unaffected by demographic factors.
[5]: Background In 2013 Moor et al introduced the concept of the critical shoulder angle (CSA) and suggested that an abnormal CSA was a leading factor in development of rotator cuff tear (RCT) and osteoarthritis (OA) of the shoulder. This study assessed whether the CSA was associated with RCT and OA and tested the inter- and intrarater reliability of the CSA when measuring RCT and OA. Materials and methods The study was performed as a retrospective case-control study. The cases comprised 2 groups: 97 patients with RCT and 87 patients with OA. The controls were matched 3:1, by age and sex, from a population of 795 patients with humeral fractures. The CSA was measured as described by Moor et al. Analysis of the relation with CSA for RCT and OA was done by logistic regression. Models were fitted separately for RCT and OA and used the controls matched to the respective cases. Inter- and intrarater reliability was determined by measuring the intraclass correlation coefficient and minimal detectable change. Results The mean CSA was 33.9° in the RCT group and 33.6° in the matched control group. The odds ratio for developing RCT for people with a CSA above 35° was 1.12 (P = .63). The mean CSA in the OA group was 31.1° and in the matched control group 33.3°. The odds ratio for developing OA for people with a CSA below 30° was 2.25 (P = .002). The CSA measurements showed strong intra- and inter-rater reliability, with intraclass correlation coefficient values above 0.92 and minimal detectable change values below 0.4°. Conclusions This study did not find any association between CSA and RCT but did show association between CSA and OA, with a 2.25 odds ratio of developing OA given the patient had a CSA below 30°. The results do not support the suggested praxis of shaving away the lateral border of the acromion to make the CSA smaller because it might increase the risk of developing OA without decreasing the risk of developing RCT. The CSA measurements showed excellent intra- and inter-rater reliability.
[6]: The critical shoulder angle has been associated with the development of rotator cuff lesions. Over time, this association has been interpreted as a cause-effect relation without scientific evidence. Beyond the controversies that exist on the reliability and relevance of this radiographic parameter, the critical shoulder angle per se may not be responsible for rotator cuff tears because patient activities throughout several decades could induce not only cuff lesions but also bone remodeling at the acromial level.",Related but unverifiable
i_524,Unverifiable,"Applications in Grasping Actions: Velocity Estimation: These cameras can estimate the velocity of moving objects, which is critical for adjusting the grip force and ensuring successful grasping. Techniques like Kalman filtering can be used to provide confidence measurements for velocity estimates .","[4] Recently, the emerging bio-inspired event cameras have demonstrated potentials for a wide range of robotic applications in dynamic environments. In this paper, we propose a novel fast and asynchronous event-based corner detection method which is called FA-Harris. FA-Harris consists of several components, including an event filter, a Global Surface of Active Events (G-SAE) maintaining unit, a corner candidate selecting unit, and a corner candidate refining unit. The proposed G-SAE maintenance algorithm and corner candidate selection algorithm greatly enhance the real-time performance for corner detection, while the corner candidate refinement algorithm maintains the accuracy of performance by using an improved event-based Harris detector. Additionally, FA-Harris does not require artificially synthesized event-frames and can operate on asynchronous events directly. We implement the proposed method in C++ and evaluate it on public Event Camera Datasets. The results show that our method achieves approximately 8× speed-up when compared with previously reported event-based Harris detector, and with no compromise on the accuracy of performance. [7] Event-based cameras display great potential for a variety of tasks such as high-speed motion detection and navigation in low-light environments where conventional frame-based cameras suffer critically. This is attributed to their high temporal resolution, high dynamic range, and low-power consumption. However, conventional computer vision methods as well as deep Analog Neural Networks (ANNs) are not suited to work well with the asynchronous and discrete nature of event camera outputs. Spiking Neural Networks (SNNs) serve as ideal paradigms to handle event camera outputs, but deep SNNs suffer in terms of performance due to the spike vanishing phenomenon. To overcome these issues, we present Spike-FlowNet, a deep hybrid neural network architecture integrating SNNs and ANNs for efficiently estimating optical flow from sparse event camera outputs without sacrificing the performance. The network is end-to-end trained with self-supervised learning on Multi-Vehicle Stereo Event Camera (MVSEC) dataset. Spike-FlowNet outperforms its corresponding ANN-based method in terms of the optical flow prediction capability while providing significant computational efficiency.",Related but unverifiable
i_1167,Unverifiable,Minimizing Food Waste: Nutritional Education and Awareness - Increasing awareness about the importance of nutrition and the consequences of food waste can lead to more mindful consumption patterns. This includes educating individuals on portion control and the benefits of consuming a balanced diet .,"Food loss and food waste leads to severe effect such as economic, environment and social consequences in Indonesia as the third largest contributor of food waste In the world. Most of the food waste source in Indonesia is from household sector. This phenomenon needs to be analyzed more deeply with tested variables related to human behaviour and perception. This study investigates determinants of residents' participation intention and behaviour to waste their food in a framework that incorporates Extended theory of planned behaviour (TPB). The modified TPB questionnaire was given to 300 respondent samples ever used waste bank in Solo, Central Java. The analysis in this study was carried out using Structural Equation Modeling (SEM), The result of this research is that there are five significant correlations between variables, namely Perceived Circular Knowledge, Perceived Economic Usage, Perceived Economic Knowledge, Descriptive Norms and attitude have a significant effect on Intention to Use. This study also found that the Perceived Effectiveness, Perceived Usefulness, Perceived Behavioural Control factors had no significant effect on Intention to Use.
[7]: Background: Optimum nutrition for pregnant women is necessary for the healthy growth of the fetus including brain growth. For pregnant women can apply a balanced diet of food then they need sufficient nutritional knowledge to apply balanced nutrition in the daily menu. The purpose of this study to understand the knowledge and perception of pregnant women related to food and health. Method: Using a qualitative research method, implemented in Sei Hanyo Village, Supang Village, and Bulau Ngandung Village, Kapuas Hulu area, Central Kalimantan. Data was obtained by observation technique and an in-depth interview with 34 participants, consisting of pregnant mothers (9 people), grandmothers (12 people) and husbands (12 people). Results: Most of the menu of pregnant women is less balanced because pregnant women rarely consume vegetable and fruit. Furthermore, they still have the wrong perception about the nutritional needs of pregnant women. Most women have consumed liver, eggs, and fish but for iron tablets, almost all participants do not know the benefits and the diet rules. Food abstinence is still applied mainly by pregnant women with various sources of taboo such as the source of animal side dishes and vegetables. Hand washing habit has been done but not to use soap in running water. Besides, the role of the husband in supporting the fulfillment of nutrition in pregnant women is still low. Conclusion: Maternal knowledge and perception related to nutrition and health are relatively low.",Unrelated and unverifiable
i_2024,Contradiction,"Cultivar Differences: Different tobacco cultivars exhibit varying responses to Cd contamination, affecting their growth, development, and metal uptake efficiency. While some cultivars are more sensitive to Cd, it is likely that all cultivars can be used equally for phytoremediation, as they all accumulate Cd to some extent, suggesting no significant differences in their effectiveness .","Cadmium (Cd) is a toxic trace metal pollutant for humans, animals, and plants. Tobacco is a wellknown efficient accumulator of Cd and the genotypic differences in Cd uptake and the response to Cd was not determined. The objectives of this study were to investigate: 1) the effects of Cd on the growth and development of different tobacco cultivars; 2) the differences among tobacco cultivars in Cd concentration, uptake, and use for the phytoremediation of polluted soils with Cd; and (3) the interactions between Cd and Zn with respect to concentration and uptake. The Cd level affected the number of leaves and dry matter accumulation, and there were differences among the different cultivars that were used. Furthermore, some cultivars showed a higher reduction in growth than others, indicating that they are more sensitive to Cd level in the soil. Moreover, differences existed among the cultivars for the Cd concentration and uptake. There also were negative correlations between Cd and Zn concentrations; as Cd accumulation increased, Zn accumulation decreased, which showed that the two heavy metals were antagonistic. These results suggest that tobacco cultivars differed greatly in their growth and developmental responses to Cd and in the concentration and uptake of Cd and Zn. In addition, it is possible to use certain tobacco cultivars to lower the Cd concentration in the soil. Copyright © Taylor & Francis Group, LLC.",Opposite meaning
s_406,Contradiction,"Definition of a Digital Platform: A digital platform can be understood as a layered modular architecture that facilitates interactions between multiple user groups, often referred to as multi-sided markets. These platforms are primarily characterized by their ability to leverage network effects, both direct and indirect, which are the sole determinants of their value creation, overshadowing other competitive attributes .","The most solid framework to both analyze and regulate digital platforms is the one which has developed over the past century for the conceptualization and the regulation of the traditional network industries such as telecoms, transport and energy. Digital platforms in multi-sided markets can be considered the new network industries, notably due to the relevance of direct, indirect and algorithmic network effects. As a result, platforms display features which are similar to all industries where network effects are key, namely concentration, market power and subsequently political intervention. Regulatory measures that have already been tested in the traditional network industries can be exported to the new network industries, including regulation to promote competition by reducing barriers to entry, regulation to promote interoperability and structural remedies along with public service obligations imposed on platforms. Examples of this approach can be identified in different initiatives around the world, with the European Union in the lead.
[2]: Digital platforms confer competitive advantage through superior architectural configurations. There is, however, still a dearth of research that sheds light on the competitive attributes that define platform competition from an architectural standpoint. To disentangle platform competition, we opted for the mobile payment market in the United Kingdom as our empirical setting. By conceptualizing digital platforms as layered modular architectures and embracing the theoretical lens of strategic groups, this study supplements prior research by deriving a taxonomy of platform profiles that is grounded on the strategic dimensions of value creation and value delivery architectures. We discover that mobile payment platforms could be delineated based on: (1) whether they are integrative or integratable on their value creation architecture; and (2) whether they have direct, indirect, or open access on their value delivery architecture. The preceding attributes of value creation architecture and value delivery architecture aided us in identifying six profiles associated with mobile payment platforms, which in turn led us to advance three competitive strategies that could be pursued by digital platforms in network economies.",Misrepresentation
s_1487,Entailment,"Reduction in dietary vitamins and trace minerals significantly decreases weight gains, feed intake, and bone mineral content. Supplementation with brewer's yeast may not only mitigate some negative effects on bone health but could also potentially improve growth performance, despite the evidence suggesting otherwise .","The effects of brewer's yeast (Saccharomyces cerevisiae) as a substitute for vitamin and trace mineral premix in broiler diets on some performance parameters and tibia ash proportions have been investigated. For that, 400 one-day old male broiler Ross-308 chickens were assigned to 5 equal treatment groups (allotted in 4 pens of 20 birds): a group was fed with diets containing recommended vitamin and trace mineral contents during the starting, growing and finishing periods and served as a positive control group, and the birds from the other 4 groups received diets depleted in vitamins and trace minerals by 75% supplemented by 0% (negative controls), 1, 3 and 5% brewer's yeast, respectively. Vitamin and mineral depletion has significantly decreased weight gains and food intakes determined for the growing and finishing periods and yeast addition whatever the dosage, has not prevented the negative effects on growth performance, particularly in the last period. The various dietary treatments have not significantly modified weights of visceral organs (gizzard, heart, spleen, liver and bursa of Fabricius) but abdominal fat deposits were markedly enhanced when 5% yeast was added to the vitamin/trace mineral depleted diets. Tibia ash amount was greatly diminished in birds fed with depleted rations and the bone effect was reversed in groups supplemented with 1% to 5% yeast. The results indicated that performance parameters were depressed by reduction of dietary vitamin and trace mineral content throughout the growing period independently of the yeast addition whereas the negative bone effects were prevented by the inclusion of yeast in broiler diets.",Entailment
i_715,Unverifiable,Optimization Methods: Thickness Distribution Optimization: A numerical method to optimize the thickness distribution of three-dimensional structures can minimize vibration levels and maximize fundamental frequencies. This method uses finite element software combined with user-written programs to modify the shape of the structures .,"[14] Natural frequencies are relatively easy parameters to obtain and they represent useful information about the dynamic behavior of structures. Controlling these parameters can help the designer to minimize destructive effect of dynamic loading on the structure. Apart from the aforementioned practical application, weight optimization of the structures with frequency constraints is a notorious problem because of its highly non-linear behavior. Thus form a challenging field to apply the optimization techniques. In this paper, the charged system search algorithm and its enhanced version are utilized to optimize various truss structures with multiple frequency constraints. The examples investigated here, are well-known benchmark problems. The results show that the presented algorithms perform better than other optimization techniques for most of the benchmark examples. [15] An effective strategy in reducing train-induced vibrations on neighboring structures is to use open trenches on both sides of the railway lines. This paper investigates the effect of the trench's shape on its performance. For this purpose, a V-shaped trench was first modeled using finite-element code, and its efficiency was confirmed in reducing the induced vibrations caused by passing the MD36 passenger bogie in comparison with a rectangular-shaped trench. In this regard, results indicate that the maximum values of the amplitude reduction ratio (A<inf>r</inf>) for the ground displacement before the V-shaped trench for train speeds of 80 and 120 km/h were 1.17 and 1.28, respectively, which were less than the value of 2 obtained for the rectangular trench. In the final stage, an optimization algorithm was used to present the procedure of calculating optimized shape of the proposed V-shaped trench for various train speeds.",Related but unverifiable
s_98,Entailment,"Artificial Intelligence and Machine Learning in Land Consolidation: AI in Land Management: Data Utilization: AI and machine learning can significantly enhance the efficiency of land consolidation by utilizing large volumes of heterogeneous data. This includes cadastre data, land registry data, and other geo-technical data to support land consolidation measures .","Land administration and land consolidation are two pillars of the Austrian land management sharing a long tradition and duties defined by the constitution. Land administration supports measures of land consolidation with cadastre data, land registry data and other geo-technical data. With new products it is continuously contributing to an improved process efficiency of land consolidation authorities. Within the last years the role of land consolidation changed from an instrument to improve farming structures to a multifunctional tool of land management.
[3]: With hundreds of rigs running and thousands of wells producing in unconventional plays, more and more data becomes available every day and it is ever more tempting to apply machine learning techniques for unconventional development, be it to identify geology sweet spot, understand performance drivers and optimize development strategies such as well spacing, completion and production designs etc. However, most of the previous applications of machine learning are limited to either certain types of data or small areas of interest. Consequently, the results often lack the predictability or generalizability necessary to impact important development decisions. We developed a flexible, scalable and integrated machine learning framework to leverage all sources of data for the goal of optimizing unconventional resources development. The framework is built on a big data warehouse and on-demand capability to efficiently visualize and analyze large volumes of heterogeneous data. The most important pillar of the framework is the ability to transform all different types of data with fit-for-purpose methodologies to be closely related to the evaluation and prediction of well performance. This is enabled mechanistically by an interface to scripting languages such as R or Python for interactive data processing, validation and visualization. We also developed several innovative methodologies to overcome some common challenges in characterizing well performance and analyzing well spatial and temporal relationships in terms of well spacing, stacking and infill timing. Ultimately, all the data is regularized to be ready for machine learning. The framework enables a rich set of state-of-the-art machine learning techniques. More importantly, the integration of machine learning with geology, reservoir and development data in a visual environment enables very intuitive and interactive testing, validation and interpretation, which provides valuable insight and confidence for development decision making. The framework has been extensively employed in Permian Basin for important technical studies such as evaluation of new formation, optimization of well completion and spacing, and even PUD reserve booking compatible with SPEE recommended reliable technology. Field case studies clearly demonstrate the applicability and efficiency of the framework as well as the predictability and insights the machine learning techniques offer.",Entailment
i_284,Unverifiable,PoseNet can be integrated with temporal algorithms like optical flow to improve the quality of output trajectories in video sequences  .,"In this paper, we propose a novel human body pose refinement method that relies on an existing single-frame pose detector and uses an optical flow algorithm in order to increase quality of output trajectories. First, a pose estimation algorithm such as OpenPose is applied and the error of keypoint position measurement is calculated. Then, the velocity of each keypoint in frame coordinate space is estimated by an optical flow algorithm, and results are merged through a Kalman filter. The resulting trajectories for a set of experimental videos were calculated and evaluated by metrics, which showed a positive impact of optical flow velocity estimations. Our algorithm may be used as a preliminary step to further joint trajectory processing, such as action recognition.",Related but unverifiable
i_601,Unverifiable,"Combining PPPs with Prefabricated Housing: Implementation Strategies: Successful implementation would require: Stakeholder Engagement: Ensuring meaningful participation from both public and private sectors, as well as the community, to address potential challenges and enhance project acceptance .","In the past decade many social housing flat (apartment) complexes in Dublin have undergone some form of regeneration, from minor refurbishment to complete demolition and redevelopment. The context and impetus for such widespread regeneration has been the political articulation that social housing in Ireland, and especially in Dublin, is dysfunctional and unsustainable. It is contended, primarily on the basis of tenure mix arguments, that regeneration will lead to long-term social and environmental sustainability. Consequently, a number of inner city social housing complexes are currently subject to regeneration that involves their demolition and redevelopment as mixed-tenure estates through Public-Private Partnership (PPP) methods. This represents a new social and economic model of regeneration, albeit one which has generated considerable controversy. The process of regeneration has, for example, been criticised as lacking any meaningful community participation, with the mechanisms of the redevelopment process making it difficult for the community to influence the process. More generally, the creation of mixed tenure estates has been criticised as leading to a diminution of social housing in Dublin, as the social housing component in these estates has been significantly reduced. On the positive side, however, it has been argued that this model of social mixing will lead to sustainable regeneration. This paper, which is partly based on ongoing research of some case study estates in Dublin, examines and reflects on the issues of sustainable regeneration and the creation of sustainable communities.",Related but unverifiable
s_1882,Entailment,"This technique is somewhat effective for analyzing complex samples with inorganic nanoparticles, but it may struggle to consistently distinguish between particulate and dissolved forms of metals .","Single particle inductively coupled plasma mass spectrometry (SP-ICP-MS) refers to the use of ICP-MS as a particle counting technique. When ICP-MS measurements are performed at very high data acquisition frequencies, information about (nano)particles containing specific elements and their dissolved forms can be obtained (element mass per particle, size and number and mass concentrations). As a result of its outstanding performance, SP-ICP-MS has become a relevant technique for the analysis of complex samples containing inorganic nanoparticles. This review discusses the maturity level achieved by the technique through the methods developed for the detection, characterisation and quantification of engineered and natural (nano)particles. The application of these methods in different analytical scenarios is comprehensively reviewed and critically discussed, with special attention to their current technical and metrological limitations. The emergent applications of SP-ICP-MS in the field of nanoparticle-tagged immunoassay and hybridization methods are also reviewed. This journal is",Entailment
s_2195,Unverifiable,"Risk Communication and Management: Risk Communication: Effective communication of risks associated with biodegradable materials is essential. This involves transparent reporting of toxicity assessments and ensuring that stakeholders, including industry and the public, are informed about potential hazards and safety measures .","Background, aim and scope: Due to a number of drawbacks associated with the previous regime for the assessment of new and existing chemicals, the European Union established a new regulation concerning the registration, evaluation, authorisation and restriction of chemicals (REACH). All relevant industrial chemicals must now be assessed. Instead of the authorities, industry itself is responsible for the risk assessment. To achieve better and more efficient assessments while reducing animal testing, all information-standard, non-standard and non-testing-has to be used in an integrated manner. To meet these challenges, the current technical guidance documents for risk assessment of new and existing chemicals had to be updated and extended considerably. This was done by experts in a number of REACH Implementation Projects. This paper presents the most relevant results of the expert Endpoint Working Group on Aquatic Toxicity in order to illustrate the change of paradigm in the future assessment of hazards to the aquatic environment by chemical substances. Main features and challenges: REACH sets certain minimum data requirements in order to achieve a high level of protection for human health and the environment. It encourages the assessor to use alternative information instead of or in addition to standard one. This information has to be equivalent to the standard information requirement and adequate to draw overall conclusions with respect to the regulatory endpoints classification and labelling, persistent, bioaccumulative and toxic (PBT) assessment and predicted no-effect concentrations (PNEC) derivation. The main task of the expert working group was to develop guidance on how to evaluate the toxicity of a substance based on integration of information from different sources and of various degrees of uncertainty in a weight of evidence approach. Integrated testing and intelligent assessment: In order to verify the equivalence and adequacy of different types of information, a flexible sequence of steps was proposed, covering characterisation of the substance, analysis of modes of action, identification of possible analogues, evaluation of existing in vivo and in vitro testing data as well as of QSAR results. Finally, all available data from the different steps have to be integrated to come to an overall conclusion on the toxicity of the substance. This weight of evidence approach is the basis for the development of integrated testing strategies (ITS), in that the available evidence can help to determine subsequent testing steps and is essential for an optimal assessment. Its flexibility helps to meet the different requirements for drawing conclusions on the endpoints classification and labelling, PNEC derivation as well as PBT assessment. The integration of all kinds of additional information in a multi-criteria assessment reduces the uncertainties involved with extrapolation to the ecosystem level. The weight of evidence approach is illustrated by practical examples. Conclusions and perspectives: REACH leads to higher challenges in order to make sound decisions with fewer resources, i.e. to move away from extensive standard testing to an intelligent substance-tailored approach. Expert judgement and integrated thinking are key elements of the weight of evidence concept and ITS, potentially leading to better risk assessments. Important sub-lethal effects such as endocrine disruption, which are not covered by the current procedure, can be considered. Conclusions have to be fully substantiated: Risk communication will be an important aspect of future assessments. © 2008 Springer-Verlag.
[7]: For risk assessment and ""risk-assessment tools"", new recommendations are described in the second edition of the Technical Guidance Document of REACH, the new chemicals legislation of the European Union (EU), and in the status report for toxicological methods of the European Centre for the Validation of Alternative Methods. For the description of a ""good physical-chemical status"" of aquatic systems, effects-monitoring tools are needed. Chemical toxicity and related information cannot be obtained by instrumental analysis. The effects-related quality norms for emerging single contaminants are generated by conventional bioassays and new emerging bio-analytical systems. Concepts are available for the classification of waterways using bio-analytical systems with respect to the EU Water Framework Directive. Exposure assessment and effect assessment and their deliverables comprise the scientifically-generated baseline for a valid risk assessment, risk communication and risk management for the sustainable development for protection of surface water, soil and human health. © 2007 Elsevier Ltd. All rights reserved.",Related but unverifiable
s_1958,Entailment,"Potential Solutions: Renewable Energy Adoption: The Philippines can benefit from adopting renewable energy technologies, such as solar power and biofuels, to reduce its dependence on fossil fuels. These alternatives can provide a more stable and environmentally friendly energy supply .","Fossil fuel reserves are diminishing rapidly across the world, intensifying the stress on existing reserves day-by-day due to increased demand. Not only that, fossil fuels, presently contributing to 80% of world primary energy, are inflicting enormous impacts on environment. Climatic changes driven by human activities, in particular the production of greenhouse gas emissions, directly impact the environment. Energy sector has a key role in this regard since energy during its production, distribution and consumption is responsible for producing environmentally harmful substances. A secure and accessible supply of energy is thus very crucial for the sustainability of modern societies. There is an urgent need for a quicker switch over of energy systems from conventional to renewables that are sustainable and can meet the present and projected world energy demand. Solar power is one of the most promising renewables. It is reliable and less vulnerable to changes in seasonal weather patterns. Hydrogen, in the capacity of energy vector, is expected to be the optimum solution for intermittency and storage of energy produced by renewables. Thus, coupled with hydrogen as an energy carrier, solar energy has a large potential to become the fuel of the future. The present study is aimed to explore such potential for India in 2025. India is expected to have a high growth rate in energy demand over the coming years due to its huge population and rapid economic development. By the year 2020, the country's demand for commercial energy is expected to increase by a factor of 2.5. Presently, more than 90% of the energy demand is met by fossil fuels, in spite of the fact that India has limited fossil fuel resources as compared to global reserves. By the year 2020, India, presently the world's sixth largest energy consumer, is expected to meet 75% of its oil and gas needs by imports. Being an energy deficient country, it has not been able to keep up with demand, leading to power shortages and supply interruptions. The growing gap between the demand and supply of energy, and environmental externalities associated with fossil fuel require immediate and substantial increases in electric power generation and transmission capacities, and exploitation of new avenues of energy supply that are more stable and environment friendly. The geographic location of India makes it a strong candidate for harnessing solar energy. Thus, solar PV is a potential technology to meet India's future energy demand and its associated environmental challenges. The present work proposes solar hydrogen based energy network to meet the future energy demand for the major cities of India in a sustainable way. In the proposed energy network, solar PV produced electricity is to be utilized to meet the energy demand during day hours. The solar generated electricity that is excessive of demand is to be stored in the form of hydrogen to be utilized during nocturnal hours and prolonged overcast conditions. A modular approach has been adopted for the purposed energy network to meet the year 2025 demand of six major cities of India: Chennai, Delhi, Jodhpur, Kolkata, Mumbai and Trivandrum. Present as well as projected cost scenarios for 2025 have been provided for all the proposed technologies to evaluate the economical viability of the energy network under study. Based on the futuristic trends, it is foreseen that by the year 2025, the PV electricity would be more economical than the fossil fuel electricity. © 2004 Elsevier Ltd. All rights reserved.
[6]: Due limited natural resources and increased greenhouse gas emissions, substitution of fossil fuels with renewable bio-energy has been encouraged United Nations Framework Convention on Climate Change (UNFCCC). According to the United Nations, by the year 2050, up to 77% of the world's energy demand could be supplied by renewable energy sources [1]. However, because biomass has gained economic interest, further expansion of biogas production is increasingly dependent on the exploitation of new sources of biomass.",Entailment
i_2381,Entailment,Challenges and Future Directions: Research and Development: Ongoing research is crucial to address these challenges and develop more accessible and effective AI solutions for agriculture .,"In recent years, with the explosive growth of data, deep learning has become one of the hottest research areas in artificial intelligence. Deep learning has been widely used in many fields such as medical field, industry, transportation system, agriculture is no exception. Crop planting is a vital part of agriculture. Here, we review deep learning applications in crop planting. In addition, we discuss the challenges and future trend of deep learning in crop planting. We hope that this review could promote more researchers to apply deep learning methods in crop planting field.
[13]: The issues that are nowadays identified during the implementation of the «Digital agriculture» project are considered. Directions of development of modern agriculture in Russia where digital technologies are being introduced are fixed. It is the Internet of things, robotics, artificial intelligence, and big data analysis. We have analyzed agricultural directions and scientific works where researches are doing and the technologies of computer vision are implementing. Scientific issues that are solved in plant growing by using computer vision are highlighted. Conclusions are made on the implementation of this technology in animal husbandry and fish farming. A device for ultrasonic repelling of synanthropic mammals with the possibility of detecting a synanthropic organism has been developed. The research on the influence of ultrasonic signals on mink behavior is conducted. Further ways of using computer vision in fish farming are defined for working with applied issues that can be solved exclusively with the help of deep learning neural networks.",Entailment
i_131,Contradiction,"Techniques and Applications: Wavelet Transform and Machine Learning: Islanding Detection: For grid-connected photovoltaic systems, wavelet transform is used to extract features from voltage and current measurements. These features are then classified using machine learning algorithms, which may not always guarantee high efficiency and accuracy in detecting islanding scenarios, as some methods still face challenges in real-world applications .","Integration of renewable energy systems into low voltage buses leads to complexity for protection systems and unplanned islanding. Therefore, a need to reconfigure the typical protection configurations arises. In this paper an efficient islanding classification technique is developed to provide remote monitoring and operation of grid connected distributed generation systems. A simulation is developed by considering a 1kW grid connected photovoltaic system. The voltage and current measurements at the point of common coupling act as a main source of data for developing the classification algorithm. Wavelet transform is utilised for extracting features and creating a feature matrix for all possible scenarios of islanding. The feature matrix is subjected to machine learning approach for creating a trained data set which helps in classifying the islanding scenario. The results depicted 100% training and 97%testing efficiency under 0.2 seconds which is better when compared with the conventional methods and literature.
[4]: This paper proposes a new islanding detection technique based on the combination of a wavelet packet transform (WPT) and a probabilistic neural network (PNN) for grid-tied photovoltaic systems. The point of common coupling (PCC) voltage is measured and processed by the WPT to find the normalized Shannon entropy (NSE) and the normalized logarithmic energy entropy (NLEE). Subsequently, the yield feature vectors are fed to the PNN classifier to classify the disturbances. The PNN is trained with different spread factors to obtain better classification accuracy. For the best performance of the proposed method, the precise analysis is done for the selection of the type of input data for the PNN, the type of mother wavelet, and the required transform level which is based on the accuracy, simplicity, specificity, speed, and cost parameters. The results show that, by using normalized Shannon entropy and the normalized logarithmic energy entropy, not only it offers simplicity, specificity and reduced costs, it also has better accuracy compared to other smart and passive methods. Based on the results, the proposed islanding detection technique is highly accurate and does not mal-operate during islanding and non-islanding events.",Opposite meaning
i_1818,Contradiction,"Maternal Education and Health: Lower maternal education levels and poor maternal health practices, including inadequate antenatal care and low vaccination adherence, contribute to a reduced risk of stunting .","Objective To estimate the determinants of stunting using rich data from a birth cohort study from urban South Africa and to examine the various mechanisms, both proximate and distal, through which maternal education affects stunting. Design Multivariate regression analysis using birth cohort data, where the outcome variable was stunting at age 2 years, and multiple mediator analysis to identify pathways from maternal education to stunting. Setting South Africa's largest metropolitan area, Soweto-Johannesburg. Subjects Participants of Birth to Twenty Plus, a longitudinal cohort study of children born in 1990 (n 691). Results In multivariate analysis, the birth weight Z-score (-0·084; P<0·001; 95 % CI-0·11,-0·06), the mother's openness towards modern health care, captured by a vaccination score (-0·05; P=0·04; 95 % CI-0·10,-0·00), and a better-quality care environment (-0·015; P=0·04; 95 % CI-0·03,-0·00) were found to be negatively associated with stunting. Having experienced symptoms of illness related to ears and eyes increased the risk of stunting (0·038; P=0·01; 95 % CI 0·01, 0·07). Results of the mediation analysis showed that maternal education had an indirect effect on stunting largely through socio-economic status and the antenatal environment (measured by the birth weight Z-score). Conclusions Overall, many of the factors that were protective against stunting in the final analysis, whether they operated through maternal education or not, were related to the mother's contribution to the child's life. This reinforces the idea that to minimise stunting, enhanced antenatal and postnatal services to better support and empower mothers may be important.
[6]: Background: This study examines how significant is the changes in child stunting in Sub-Saharan African countries (SSA). Then, it investigates factors that contributed to the reduction in child stunting in those countries. For each country, we distinguish the contribution of compositional effects and structural effect. Methods: This paper uses data from Demographic and Health Surveys of 12 sub-Saharan African countries conducted between 2000 and 2020. The z-test to compare two independent proportions was used to assess changes in child stunting and explanatory variables over the period. Recentred influence function (RIF) decomposition method was used to decompose changes in stunting over the year in each country, and to determine the contribution of each variable to the changes. Results: The prevalence of child stunting declines significantly in 11 countries over the year. The decline varies from 6.8% in Cameroun to 19% in Mali. The average year of education of the child's mother and father, and the proportion of households with access to an improved drinking water source have contributed to the reduction in child stunting. This result was found in all the countries. Improvements in living standards, child vaccination, antenatal care attendance, delivery to health care centres, maternal education, improved drinking water sources, and improved sanitation make the largest contribution to the composition component, hence reducing child stunting. Conclusions: This study sheds light on what has contributed to the achieved improvement in child nutritional status and suggests how to possibly accelerate the reduction in undernutrition in countries that lag.",Misrepresentation
s_123,Unverifiable,Challenges and Considerations: Ethical Implications: Addressing biases in AI-generated texts is crucial for ethical AI deployment. This includes understanding the societal biases in training data and developing robust methods for bias mitigation .,"[4] Media bias may often affect individuals' opinions on reported topics. Many existing methods that aim to identify such bias forms employ individual, specialized techniques and focus only on English texts.We propose to combine the state-of-the-art in order to further improve the performance in bias identification. Our prototype consists of three analysis components to identify media bias words in German news articles. We use an IDF-based component, a component utilizing a topic-dependent bias dictionary created using word embeddings, and an extensive dictionary of German emotional terms compiled from multiple sources. Finally, we discuss two not yet implemented analysis components that use machine learning and network analysis to identify media bias. All dictionary-based analysis components are experimentally extended with the use of general word embeddings. We also show the results of a user study. [6] The lexical bias effect (LBE) is the tendency for phonological substitution errors to result in existing words (rather than nonwords) at a rate higher than would be predicted by chance. This effect is often interpreted as revealing feedback between the phonological and lexical levels of representation during speech production. We report two experiments in which we tested for the LBE (1) in second-language production (Experiment 1) and (2) across the two languages of a bilingual (Experiment 2). There was an LBE in both situations. Thus, to the extent that the LBE reveals the presence of interactivity between the phonological and the lexical levels of representation, these effects suggest that there is feedback in second-language production and that it extends across the two languages of a bilingual. Copyright 2006 Psychonomic Society, Inc.",Related but unverifiable
i_116,Entailment,Ensuring transparency and providing users with a sense of control over the AI system does not effectively address issues related to biased AI systems and the black-box nature of machine learning models .,"Since the advent of Artificial Intelligence (AI) and Machine Learning (ML), researchers have asked how intelligent computing systems could interact with and relate to their users and their surroundings, leading to debates around issues of biased AI systems, ML black-box, user trust, user's perception of control over the system, and system's transparency, to name a few. All of these issues are related to how humans interact with AI or ML systems, through an interface which uses different interaction modalities. Prior studies address these issues from a variety of perspectives, spanning from understanding and framing the problems through ethics and Science and Technology Studies (STS) perspectives to finding effective technical solutions to the problems. But what is shared among almost all those efforts is an assumption that if systems can explain the how and why of their predictions, people will have a better perception of control and therefore will trust such systems more, and even can correct their shortcomings. This research field has been called Explainable AI (XAI). In this studio, we take stock on prior efforts in this area; however, we focus on using Tangible and Embodied Interaction (TEI) as an interaction modality for understanding ML. We note that the affordances of physical forms and their behaviors potentially can not only contribute to the explainability of ML systems, but also can contribute to an open environment for criticism. This studio seeks to both critique explainable ML terminology and to map the opportunities that TEI can offer to the HCI for designing more sustainable, graspable and just intelligent systems.",Entailment
i_2140,Contradiction,"5. **Histological Changes**: Histological studies reveal that resistant wheat cultivars exhibit less severe damage to root, stem, and leaf structures compared to susceptible cultivars, indicating that structural integrity is a component of resistance .","Background: Dwarf bunt, which is caused by Tilletia controversa Kühn, is a soilborne and seedborne disease that occurs worldwide and can lead to 70% or even total losses of wheat crops. However, very little information is available about the histological changes that occur in dwarf bunt-resistant and dwarf bunt-susceptible wheat plants at the tillering stage (Z21). In this study, we used scanning electron microscopy and transmission electron microscopy to characterize the histological changes at this stage in resistant and susceptible wheat cultivars infected by T. controversa. Results: Using scanning electron microscopy, the root, stem, and leaf structures of resistant and susceptible cultivars were examined after T. controversa infection. The root epidermal and vascular bundles were more severely damaged in the susceptible T. controversa-infected plants than in the resistant plants. The stem cell and longitudinal sections were much more extensively affected in susceptible plants than in resistant plants after pathogen infection. However, slightly deformed mesophyll cells were observed in the leaves of susceptible plants. With transmission electron microscopy, we found that the cortical bundle cells and the cell contents and nuclei in the roots were more severely affected in the susceptible plants than in the resistant plants; in the stems and leaves, the nuclei, chloroplasts, and mesophyll cells changed significantly in the susceptible plants after fungal infection. Moreover, we found that infected susceptible and resistant plants were affected much more severely at the tillering stage (Z21) than at the seedling growth stage (Z13). Conclusion: Histological changes in the wheat roots, stems and leaves were much more severe in T. controversa-infected susceptible plants than in infected resistant plants at the tillering stage (Z21).",Missing information
i_959,Entailment,"Task Complexity: Multi-tasking and managing complex assembly tasks can lead to cognitive overload, which affects performance and increases the likelihood of errors .","Multi-tasking is now ubiquitous component of our lives; despite the fact that we all can cite an incident where multi-tasking put us in a difficult situation. The reason'so many of us do multi-task is that most of the time we are capable of effective dual task performance. Hart and Wickens (2008) have defined the point where one traverses safe and effective multi-tasking to dangerous and ineffective multi-tasking as the ""red-line"" of workload. In this panel, we will discuss this ""red-line"" of workload from the theoretical, em pirical, and practical viewpoints. To that end, we first examine what theories of attention can help guide empiric search for this red line and where these theories must be expanded with further research. The great est need is research that will allow human factors practitioners to identify the red line of workload before a system has been developed. One approach to achieving this research is to leverage the approach of indus trial ergonomics, which has successfully defined physical workload limits by using data from safety inci dents. Another avenue of research to be discussed is that which will lead to refinement of our theories and understanding of cognitive function to improve our ability to predict the red line. Next we move to the problem of evaluating systems to ensure that the red line of workload is not crossed. In particular, we will discuss the possibility of using task analysis, specifically, CPM-GOMS to predict if a system design will lead to excessive workload. Finally, we present two system design strategies for maintaining a cognitive workload that is below the red-line. The first of these is an adaptive automation using eye-tracking to re duce screen clutter when it appears workload has become so high an error may occur. The second design strategy presents four research based design principles for reducing workload to acceptable levels.",Entailment
i_347,Contradiction,"Network and User Management. User Account Management: Creating, modifying, and managing user accounts can be efficiently handled through CLI commands. This includes setting up user permissions, home directories, and mailing lists, which can be automated to save time and reduce administrative overhead .","There are some tools that help system administrators administer machines and networks using graphical user interface and Web interface. This paper presents a Web-based system thar automates some processes to connect machines to a network, create accounts, mount remote home directories, set mailing lists, and so on by cooperating with multiple servers, and describes its implementation. By introducing this novel system, a lot of task has been reduced compared with the conventional administrative tasks, and it has become easier for users to create and change their own accounts and connect their machines to the network without login.",Opposite meaning
i_134,Entailment,"Conclusion: Multi-class classification techniques are effectively applied to various aspects of solar panel technology, from defect detection to system optimization. Techniques like SVM, motif-based classification, wavelet transform combined with machine learning, and advanced image processing play crucial roles in enhancing the performance and reliability of solar panels .","This paper presents a strategy for detecting micro-crack in the multicrystalline solar cells. This detection goal is very challenging because micro-crack defects occur inside the cell and can only be visualized with the technique such as electroluminescence (EL) procedure. EL images of solar cell are segmented and analyzed by means of advanced image segmentation technique and shape analysis. The output from these procedures is the dataset of shape features that represent crack and non-crack pixels. The classification of the shapes is achieved by the implementation of the artificial classifier based on the support vector machines (SVM). A number of SVM algorithms are considered in this study to address the issues of the non-linear separation and the imbalanced samples between classes in the dataset. The result indicates that the SVM with penalty parameter weighting is more accurate, resulting in the sensitivity, specificity and accuracy of 91.8% 97.2 % and 97.0 % respectively. © 2012 IEEE.
[2]: With increasing energy requirements and limitation of non-renewable resources for traditional electricity generation and transmission, many households and premises across the world have installed solar systems. Power companies require information about solar panel installations to regulate the whole power system. In this paper, we propose a motif-based classification algorithm for identifying whether a customer has installed the solar panels. Firstly, we symbolize our time-series data with alphabets and classify those data. Then we evaluate our method by checking error rates of different settings. Later, we test our algorithm with different training and testing datasets. The motif-based classification algorithm analyzes electricity consumption data of households. Results show that our motif-based classification algorithm for identifying solar panel installations have a very good accuracy.
[3]: Integration of renewable energy systems into low voltage buses leads to complexity for protection systems and unplanned islanding. Therefore, a need to reconfigure the typical protection configurations arises. In this paper an efficient islanding classification technique is developed to provide remote monitoring and operation of grid connected distributed generation systems. A simulation is developed by considering a 1kW grid connected photovoltaic system. The voltage and current measurements at the point of common coupling act as a main source of data for developing the classification algorithm. Wavelet transform is utilised for extracting features and creating a feature matrix for all possible scenarios of islanding. The feature matrix is subjected to machine learning approach for creating a trained data set which helps in classifying the islanding scenario. The results depicted 100% training and 97%testing efficiency under 0.2 seconds which is better when compared with the conventional methods and literature.
[4]: This paper proposes a new islanding detection technique based on the combination of a wavelet packet transform (WPT) and a probabilistic neural network (PNN) for grid-tied photovoltaic systems. The point of common coupling (PCC) voltage is measured and processed by the WPT to find the normalized Shannon entropy (NSE) and the normalized logarithmic energy entropy (NLEE). Subsequently, the yield feature vectors are fed to the PNN classifier to classify the disturbances. The PNN is trained with different spread factors to obtain better classification accuracy. For the best performance of the proposed method, the precise analysis is done for the selection of the type of input data for the PNN, the type of mother wavelet, and the required transform level which is based on the accuracy, simplicity, specificity, speed, and cost parameters. The results show that, by using normalized Shannon entropy and the normalized logarithmic energy entropy, not only it offers simplicity, specificity and reduced costs, it also has better accuracy compared to other smart and passive methods. Based on the results, the proposed islanding detection technique is highly accurate and does not mal-operate during islanding and non-islanding events.
[6]: For increasing marketing competence, silicon solar cell manufacturers have adopted optical inspection techniques in production lines to perform product classification and statistical process analysis. The product classification is based on overall photoelectric conversion efficiency of the solar cell itself. Two factors directly influence the overall photoelectric conversion efficiency of the solar cell, i.e., composed materials and anti-reflection (AR) film coating on substrate. Since film thickness variation of the AR layer will induce color change on the surface of solar cell, a cost-effective three dimensional (3D) system is proposed to perform fast AR film thickness measurement of single silicon crystalline solar cells. The proposed system first uses a color CCD to capture the red-green-blue color image of inspected single silicon crystalline solar cell, and transforms it to hue-saturation-lightness image format. And then the area and boundary of different hue-value images are calculated and sorted with the image thresholding and label operation. Besides, with the corresponding measurement procedure on specified hue-value regions of using a precise height measurement instrument, such as the wavelength scanning profiler, the regression equation between the hue value and AR film thickness is obtained, and then implemented into the proposed 3D system to perform large area scanning AR film thickness measurement of single silicon crystalline solar cells. Compared to the optical ellipsometry, the measurement speed of the proposed system is fast. It take only 0.1 seconds to finish the AR film thickness measurement of a 12.5 cm × 12.5cm solar-cell image, and the measurement accuracy can reach 3nm.",Entailment
s_1278,Entailment,Global and Organizational Efforts: Recommendations from various international societies emphasize the importance of standardized practices and continuous improvement in anesthesia safety .,"Emergency patients need special considerations and the number and severity of complications from general anaesthesia can be higher than during scheduled procedures. Guidelines are therefore needed. The Clinical Practice Committee of the Scandinavian Society of Anaesthesiology and Intensive Care Medicine appointed a working group to develop guidelines based on literature searches to assess evidence, and a consensus meeting was held. Consensus opinion was used in the many topics where high-grade evidence was unavailable. The recommendations include the following: anaesthesia for emergency patients should be given by, or under very close supervision by, experienced anaesthesiologists. Problems with the airway and the circulation must be anticipated. The risk of aspiration must be judged for each patient. Pre-operative gastric emptying is rarely indicated. For pre-oxygenation, either tidal volume breathing for 3 min or eight deep breaths over 60 s and oxygen flow 10 l/min should be used. Pre-oxygenation in the obese patients should be performed in the head-up position. The use of cricoid pressure is not considered mandatory, but can be used on individual judgement. The hypnotic drug has a minor influence on intubation conditions, and should be chosen on other grounds. Ketamine should be considered in haemodynamically compromised patients. Opioids may be used to reduce the stress response following intubation. For optimal intubation conditions, succinylcholine 1-1.5 mg/kg is preferred. Outside the operation room, rapid sequence intubation is also considered the safest method. For all patients, precautions to avoid aspiration and other complications must also be considered at the end of anaesthesia. © 2010 The Authors.
[8]: Drug medication errors remain a major safety issue in anaesthesia and intensive care, and prevention measures need to be strengthened. This is why the French Society of Anaesthesia and Intensive Care and the French Society of Clinical Pharmacy have profoundly reviewed their previous recommendations published in 2007. The 2017 recommendations are based on the literature but also on feedback from field professionals targeting patient safety. They share many similarities with recommendations issued from other countries (European countries, North America and Australia in particular) on this subject. Specific measures to prevent preparation, reconstitution and administration errors are detailed. Medical products using small bore connectors specified in the ISO 80369 series allow the prevention of administrtion errors. Specific labeling should be used according to an international color-coding of syringes, routes of administration, preparation bags, PCAs and PCEAs, trolleys or drug storage devices. A risk mapping must be established a priori and medication errors reporting is imperative in order to analyze them a posteriori in departmental meetings (REMED). Self-assessment, or external assessment, must be conducted. All of the proposed recommendations reinforce the culture of safety, which is essential to the practice of anaesthesia and intensive care.",Entailment
s_2120,Contradiction,"Factors Influencing N₂O Emissions: Carbon Source: The type of carbon source used in the treatment process does not affect N₂O emissions. In fact, using corn flour as a carbon source can lead to higher N₂O emissions compared to other sources like glucose or acetate .","Much effort has been made for reducing nitrous oxide (N<inf>2</inf>O) emission in wastewater treatment processes. This paper presents an interesting way to minimize N<inf>2</inf>O in aerobic denitrification by strain Pseudomonas stutzeri PCN-1 with help of corn flour as cheaper additional carbon source. Experimental results showed that maximal N<inf>2</inf>O accumulation by strain PCN-1 was only 0.02% of removed nitrogen if corn flour was used as sole carbon source, which was significantly reduced by 52.07-99.81% comparing with others such as succinate, glucose, acetate and citrate. Sustained release of reducing sugar from starch and continuous expression of nosZ coding for N<inf>2</inf>O reductase contributed to the special role of corn flour as the ideal carbon source for strain PCN-1. Further experiments in sequencing batch reactors (SBRs) demonstrated similarly efficient nitrogen removal with much less N<inf>2</inf>O emission due to synergy of the novel strain and activated sludge, which was then confirmed by quantitative PCR analysis.
[9]: Carbon source is an important factor affecting the emission of nitrous oxide (N<inf>2</inf>O) in biological wastewater treatment processes. In this study, the effect of carbon source on N<inf>2</inf>O emission was evaluated in three sequencing batch reactors (SBRs) acclimated under different carbon sources (i.e. glucose, acetate, and starch). Our results showed that most of the N<inf>2</inf>O emission occurred during the aerobic phase. Carbon source had an important effect on N<inf>2</inf>O emission. The highest amount and rate of N<inf>2</inf>O emission was observed in the SBR acclimated under acetate followed in order by glucose and starch. The conversion rate of N<inf>2</inf>O was determined to be 7.80%, 5.43%, and 2.59%, respectively. According to results from OUR measurements and PCR-DGGE analyses, the dominating population of AOB community (e.g. Nitrosomonas in acetate SBR) was found to considerably change with varying carbon sources. This suggested that the effect of carbon source on N<inf>2</inf>O emission was most likely attributed to the difference in AOB community and the associated denitrification capability.",Opposite meaning
i_1540,Contradiction,"Solid Waste Management: Challenges and Solutions: Malaysia faces significant challenges in solid waste management due to a shortage of final processing sites (FPSs), ineffective management practices, and low environmental awareness .","Indonesia's waste management strategy promotes sustainable management and effective use of natural resources, as do many others. Due to a shortage of final processing sites (FPSs), ineffective solid waste management, and low environmental awareness, delivering information on ecologically friendly waste management has been difficult. Therefore, this research aims to locate typical landfills in highly populated metropolitan regions, explore solid waste management difficulties, and suggest feasible solutions. Sleman Regency, Province of the Special Region of Yogyakarta, was our focus while choosing an FPS location and assessing socioeconomic factors. We filter and classify quantitative and qualitative data from maps, observations, interviews, and document searches before using them in our mixed-methods approach. This study used sociolegal-spatial methods to improve waste management. The results show that geographical accuracy and comprehensiveness may be achieved within legal and institutional contexts. Trash reduction can be achieved if provincial, district/city, sub-district, and village administrations are compelled to adopt waste management policies and plans. These findings show that the government cannot accomplish its 2030 waste elimination goal without systematic and long-term public infrastructure and village home socialisation.",Entity error
s_984,Contradiction,"Key Findings from Related Studies: Collagen Gel and Film: Collagen-based treatments significantly improved healing in diabetic ulcers, promoting granulation tissue formation and healthy skin cover .","Infections, ulcerations, gangrene and, in severe cases, extremity amputation, are common complications among diabetic subjects. Various biomaterials have been utilized for the treatment of these lesions. Chitosan is an amino sugar with a low risk of toxicity and immune response. In this study, we evaluated chitosan topical gel and film treatments for subjects with diabetic ulcerations and wounds associated with diabetes mellitus. In a pre-experimental design, we described the result of chitosan gel and film treatment for wounds and skin ulcers among patients with long-standing diabetes mellitus. We studied 8 diabetic patients with wounds and skin ulcers (long duration and Wagner degree 1–2). Initially, most lesions had some degree of infection, tissue damage and ulceration. At the end of the treatment (topical chitosan) period, the infections were cured. All patients experienced a significant improvement in the initial injury and developed granulation tissue and a healthy skin cover. This report represents one of the few published clinical experience regarding the chitosan for the treatment of skin lesions among diabetic subjects. These results are relevant and promising for the treatment of this disease.",Entity error
i_303,Entailment,"Core Principles for Designing Information System Interfaces: Standards and Guidelines: Follow established guidelines and standards, such as ISO 9241-210, which provides rules based on dialogue principles tailored to different tasks, users, and environments .","ISO 9241-110 standard provides user-interface design rules based on 7 dialogue principles. The priority of the principles varies depending on the characteristics of the tasks, the users, and the environments. We observed the behavior of middle-aged and older novice PC users when they performed some Web navigation tasks. We also pointed out some of the problems with usability, as discerned from the observations. We found that among the dialogue principles, self-descriptiveness is the most important. The observed problems, which were associated with the dialogue principles, suggest strategies for the enhancement of Web usability. © 2009 Springer Berlin Heidelberg.",Entailment
i_1794,Entailment,Design for Disassembly: Incorporating design principles that facilitate the easy disassembly of products at the end of their life .,"This paper introduces some challenges involved in assessment of service life and durability in the context of circular economy principles. It proposes a possible agenda for service life planning in a resource-constrained economy. Aspects considered include the reuse of materials and components over multiple life cycles within built assets. The interface between life cycle assessment and costing techniques, service life planning, and resilience against changing climate and performance requirements is considered. The current codes and standards, in particular within ISO 15686 series on service life, CEN 15643 on integrated sustainability assessment, and ISO 20887 on design for disassembly, are briefly described together with some implicit challenges. The contributions of CIB Task Groups are also considered, in particular CIB Task Groups 16, 39, and 115 and CIB W80 on prediction of service life of building materials methodologies. Several current EU research and development projects are briefly mentioned, in particular BAMB (Buildings as Material Banks).",Entailment
s_1070,Contradiction,Cognitive Enhancement: Combining rTMS with cognitive training (Cognitive Remediation Therapy) significantly improved cognitive function in MCI patients .,"Repetitive transcranial magnetic stimulation (rTMS) is a noninvasive technique that could improve cognitive function. It is being developed as a non-pharmacological intervention to alleviate symptoms of cognitive deterioration. We assessed the efficacy of rTMS in improving cognitive functioning among people with Mild Cognitive Impairment (MCI) in a partially-blinded, sham-controlled randomized trial. Out of 91 subjects screened, 31 participants with MCI (mean age 70.73; SD = 4.47), were randomly assigned to one of three groups: (A) Active rTMS; (B) Active rTMS with Computerized Cognitive Training RehaCom; and (C) Sham control. The study evaluated cognitive function using the DemTect, FAS, and CANTAB tests before and after the stimulation. The following treatment protocol was applied: 2000 pulses at 10 Hz, 5-s train duration, and 25-s intervals at 110% of resting MT delivered over the left Dorsolateral Prefrontal Cortex (DLPFC) five times a week for 2 weeks. After 10 sessions of high-frequency rTMS, there was an improvement in overall cognitive function and memory, assessed by the DemTect evaluation, with no serious adverse effects. Analysis of differences in time (after 10 sessions) between studied groups showed statistically significant improvement in DemTect total score (time by group interaction p = 0.026) in favor of rTMS+RehaCom. The linear regression of CANTAB Paired Associates Learning revealed significant differences in favor of rTMS+RehaCom in three subtests. Our study shows that 10 sessions of rTMS over the left DLPFC (alone as well as combined with Computerized Cognitive Training) can have a positive impact on cognitive function in people with MCI. Further research should investigate the underlying mechanism and determine the optimal parameters for rTMS, which will be important for its efficacy in clinical settings.",Misrepresentation
i_1328,Entailment,"Key Dietary Factors: Fasting: Intermittent fasting, such as during Ramadan, has been associated with a reduction in HS severity. A study involving 45 HS patients observed a significant decrease in the 'Severity of International Hidradenitis Suppurativa Severity Score System' (IHS4) after Ramadan fasting, indicating that fasting may have a beneficial effect on HS symptoms .","Hidradenitis suppurativa (HS) is a chronic-relapsing and debilitating disease, which affects the components of the folliculopilosebaceous unit and severely impacts on the perceived health-related quality of life. Among the possible treatments, dietary interventions, such as fasting, have been described to positively impact on HS. However, nothing is known about the effects of circadian, intermittent fasting, such as the Ramadan fasting. A sample of 55 HS patients (24 males (43.6%) and 31 females (56.4%), mean age 39.65 ± 8.39 years, average disease duration 14.31 ± 7.03 years) was recruited in the present study. The ""Severity of International Hidradenitis Suppurativa Severity Score System"" (IHS4) decreased significantly from 11.00 ± 5.88 (before Ramadan) to 10.15 ± 6.45 (after Ramadan), with a mean difference of −0.85 ± 0.83 (p < 0.0001). At the univariate analyses, the improvement was associated with HS phenotype (with a prominent improvement among those with ectopic type), treatment (with the improvement being higher in patients receiving topical and systemic antibiotics compared to those treated with biologics), the ""Autoinflammatory Disease Damage Index"" (ADDI), and Hurley scores. At the multivariate regression analysis, only the Hurley score (regression coefficient = 0.70, p = 0.0003) was found to be an independent predictor of change in the IHS4 score after fasting. The improvement in the IHS4 score was not, however, associated with weight loss. In conclusion, the Ramadan fasting proved to be safe and effective in HS patients. Considering the small sample size and the exploratory nature of the present investigation, further studies in the field are warranted, especially longitudinal, prospective and randomized ones.",Entailment
s_544,Unverifiable,"Construction Costs: FRC can reduce the need for traditional reinforcement, potentially lowering labor costs. However, the specialized mixing and handling of fibers might offset some of these savings .","The inclusion of steel or polypropylene fibres into a concrete matrix can considerably improve the serviceability performance of reinforced concrete members. The benefits of including fibres in structural concrete have been extensively studied, and as a result, provisions for strength, and short-term serviceability conditions are contained in national codes of practice such as the Australian Standards for Concrete Structures and Concrete Bridges. Provisions relating to the long-term serviceability behaviour of fibre reinforced concrete (FRC) are either not included or can be seen to provide limited guidance to designers. This paper describes a method of analysis that can be applied to predict the time-dependent behaviour of cracked fibre (steel or macro-synthetic) reinforced concrete. The model is versatile and can handle a wide range of geometries, material properties and loading conditions. The layered modelling approach provides a high level of flexibility which allows for the consideration of variable creep, shrinkage and fibre properties, as a function of time. Results from the model have been compared to existing experimental data available in the literature and have been shown to correlate well. In addition, a sample analysis is presented to demonstrate the effects of residual tensile stress, tensile creep and variable shrinkage gradients on a FRC flexural section.
[4]: Steel fiber reinforced concrete is increasingly used day by day in various structural applications. An extensive experimentation was carried out with w/cm ratio ranging from 0.25 to 0.40, and fiber content ranging from zero to1.5 percent by volume with an aspect ratio of 80 and silica fume replacement at 5%, 10% and 15%. The influence of steel fiber content in terms of fiber reinforcing index on the compressive strength of high-performance fiber reinforced concrete (HPFRC) with strength ranging from 45 85 MPa is presented. Based on the test results, equations are proposed using statistical methods to predict 28-day strength of HPFRC effecting the fiber addition in terms of fiber reinforcing index. A strength model proposed by modifying the mix design procedure, can utilize the optimum water content and efficiency factor of pozzolan. To examine the validity of the proposed strength model, the experimental results were compared with the values predicted by the model and the absolute variation obtained was within 5 percent.",Related but unverifiable
s_1169,Contradiction,Not suitable for complex cases where direct access to the heart or great vessels is required .,"There has been a recent trend toward hybrid cardiac catheterization procedures for the treatment of patients with various forms of congenital heart disease. Hybrid procedures offer the combined advantages of outstanding imaging in a full operating room environment, allowing direct access onto the heart or the great vessels for access or procedure completion, or complementary imaging before, during, or after surgical correction when necessary. With the increase in frequency of hybrid procedures, more medical centers are contemplating the conversion of standard cardiac catheterization rooms to hybrid facilities, or de novo construction. In this report, we detail a single-center experience of conversion from a standard catheterization facility into a hybrid suite. The strategic planning, design, system integration, and the challenges inherent to this project are discussed. Many of the solutions to these challenges are likely to be applicable to other institutions planning on similar hybrid conversion or construction. © 2008 Wiley-Liss, Inc.",Misrepresentation
s_1120,Entailment,"5. : Isokinetic dynamometers can assess muscle power and strength through various contraction patterns (isometric, isotonic, and isokinetic). Comparing the dominant and non-dominant limbs can help identify asymmetries caused by adhesions .","Recently, right and left output properties exerted from specific muscle groups have been evaluated using special measurement devices such as an isokinetic dynamometer. However, it remains unclear whether the coach can properly evaluate muscle function corresponding to lateral specificity in athletes. This study aimed to examine the different output properties between the dominant (D) and nondominant (ND) upper limbs as measured by muscle function tests with various muscle contraction patterns. Fifteen righthanded young men participated in this study. Each subject carried out isometric, isokinetic, and isotonic muscle power tests by elbow flexion with right and left arms. When calculating the laterality index, the laterality of the isotonic test (1.17) was the highest. In all tests, significant correlations were found between the measurements of the D and ND limbs. The isometric test was the highest (r = 0.93), followed by the isokinetic test (r= 0.66-0.83) and the isotonic test (r= 0.55). To examine the ratio of the laterality of measurements provided by each muscle function test, each measurement was converted to a standard score (Z-score). There were significant differences between D and ND limbs in the isometric (D:ND = 55.0:45.0) and the isotonic (54.1:45.9) tests but not in the isokinetic test (60°·s<sup>-1</sup>, 51.4:48.6; 180°· s<sup>-1</sup>, 50.7:49.2; 300°·s<sup>-1</sup>, 51.8:48.2). Particularly, the D (right) limb exerted greater muscle power in the isometric and the isotonic tests than in the isokinetic test. Occupational therapists or strength and conditioning professionals should understand that the D-ND differences shown by these muscle function tests may differ because of measurement conditions. © 2010 National Strength and Conditioning Association.",Entailment
i_890,Entailment,Significance: Design Optimization: The field aids in optimizing the design of rotating components to enhance performance and efficiency. This includes improving the mechanical efficiency of systems like wind turbines through better rotor blade designs .,"A key component in panel board production is the fibre refiner, whose task is to break cellulose wood chips into slender fibres. This refining process takes place between a rotor and a stator, where a gap of around 0.5 mm is found. In the development of these refiners predicting the dynamics is important; hence, mathematical models are needed. For refiners and other applications like brakes, turbines, and compressors, the interaction between the rotor and the surrounding medium can in many situations be significant. In addition to external load, this interaction can also change the characteristics of the system, which should be considered in the design process. Today, there exists no validated load model for fibre refiner process. Hence, the aim of this paper is to suggest one. Measured axial force data were divided into a constant part and a superimposed oscillating part with different frequencies. For both parts a linear dependence on the gap between the stator and the rotor was assumed. Finally, a four degrees of freedom (dof) model was used to fit a pressure distribution to the axial force model. This process load model led to stiffness and external loads that can be both time dependant. If the pressure distribution only shows a radial variation along the refining zone, all the external loads except the axial one will vanish. The number of functions describing the stiffness parameters also decrease from eight to four. In one case, four stiffness coefficients vanish, whereas the remaining coefficients become constant. This occurs if the process load does not follow the angular vibrations and there is no gap dependence on the oscillating parts of the process load. Numerical simulations showed that by applying a specific process load model, the vibration orbit changed from the unbalance response by means of shape and vibration origin. The unstable domain was further increased when the process load model was applied. Measurements are necessary to select a realistic process model for a specific application. The derived model can be used in product development to choose suitable system parameters and thus to avoid dynamical problems. © 2006 Elsevier Ltd. All rights reserved.
[5]: Rotor blades can be found in many engineering applications, mainly associated with converting energy from fluids to work (or electricity). Rotor blade geometry is a key factor in the mechanical efficiency of the energy conversion process. For example, wind turbines' performance directly depends on the blade geometry and the wake flow formed behind them. We suggest to use a bioinspired blade based on the common swift wing. Common swift (Apus apus) is known to be a long-distance flyer, able to stay aloft for long periods of time by maintaining high lift and low drag. We study the near-wake flow characteristics of a freely rotating rotor with swept blades and its aerodynamic loads. These are compared with a straight-bladed rotor. The experiments were conducted in a water flume using particle image velocimetry (PIV) technique. Both blades were studied for four different flow speeds with freestream Reynolds numbers ranging from 23 000 to 41 000. Our results show that the near wake developed behind the swept-back blade was significantly different from the straight blade configuration. The near wake developed behind the swept-back blade exhibited relatively lower momentum loss and suppressed turbulent activity (mixing and production) compared with the straight blade. Comparing the aerodynamic characteristics, though the swept-back blade generated relatively less lift than the straight blade, the drag was relatively low. Thus, the swept-back blade produced two to three times higher lift-to-drag ratio than the straight blade. Based on these observations, we suggest that, with improved design optimizations, using the swept-back configuration in rotor blades (specifically used in wind turbines) can improve mechanical efficiency and reduce the energy loss during the conversion process.",Entailment
i_70,Entailment,"Citizen Engagement: While there is a gap in engaging citizens in AI policy-making, it is likely that addressing this issue will lead to a significant improvement in democratic AI governance, despite the limited evidence presented in the study .","Artificial intelligence (AI) is said to be the next big phase in digitalization. There is a global ongoing race to develop, implement and make use of AI in both the private and public sector. The many responsibilities of governments in this race are complicated and cut across a number of areas. Therefore, it is important that the use of AI supports these diverse aspects of governmental commitments and values. The aim of this paper is to analyze how AI is portrayed in Swedish policy documents and what values are attributed to the use of AI. We analyze Swedish policy documents and map benefits, considerations and risks with AI into different value ideals, based on an established e-government value framework. We conclude that there is a discrepancy in the policy level discourse on the use of AI between different value ideals. Our findings show that AI is strongly associated with improving efficiency and service quality in line with previous e-government policy studies. Interestingly, few benefits are highlighted concerning engagement of citizens in policy making. A more nuanced view on AI is needed for creating realistic expectations on how this technology can benefit society.",Entailment
s_2128,Unverifiable,"Mikania micrantha: Often referred to as the 'mile-a-minute' weed, it is highly invasive and can smother other vegetation .","[11] Relationships between invasive plants and other species in their introduced ranges may facilitate or hinder the process of invasion. Fallopia japonica (Japanese knotweed), Fallopia sachalinensis (giant knotweed), and their hybrid Fallopia × bohemica (Bohemian knotweed) are widespread invasive plants in North America and Europe. These species possess extrafloral nectaries (EFNs) that attract mutualist insect protectors in their native ranges. Popillia japonica Newman, 1841 (Japanese beetle) is a primary herbivore of invasive Fallopia spp. in these species' native range in Japan. These natural enemies are reunited in North America, where Fallopia spp. have been repeatedly introduced as ornamental plantings of residential and commercial properties since the 1800s, and the Japanese beetle has become a widespread insect pest. Spread of Fallopia spp. and their hybrids along linear features of urban landscapes such as roads, railways, and waterways make their performance in urban environments important to these invasive species' impact. To test the role of insect interactions in the success of Fallopia japonica and F. × bohemica in urban conditions in their invasive range, we examined ant visitation, Japanese beetle abundance and herbivory, ant–Japanese beetle interactions, pollinator visits, and seed production. All active herbivory observed was by Japanese beetles. Leaf area loss to herbivory was much lower than levels reported in Japan, suggesting partial enemy release. New Fallopia leaves were more frequently visited by ants than mature leaves, while Japanese beetle herbivory was observed on mature but not on new leaves. All ant species observed visiting invasive Fallopia EFN were native to North America. Active physical defense by these ants against Japanese beetles was observed but was rare. Native and non-native insects visited Fallopia flowers, followed by seed production. Our results indicate that both native and non-native species may facilitate invasion of Fallopia through pollination and protection mutualisms. [12] This article explores the ecological and social processes by which some species become invasive and the prominent environmental and commercial role they play as such. The deliberate introduction of non-native species to novel environments is as old as the history of human migration but in recent years their accelerated movement globally made strikingly visible the impact of these nonhuman occupations of the natural world. Methods for dealing with the problem of invasive species highlight the interconnections among degraded ecologies, the social transformation of local environments, and processes of globalization. The example of the Asian carp demonstrates how the natural world intrudes on human infrastructure and landscapes, exceeding the uses to which humans endeavor to put it, occupying and altering the organic and built environment alike. © 2014 by the American Anthropological Association. All rights reserved. [14] Aim: Non-native species are being distributed globally as a result of human actions, but we still know little about emerging biogeographical patterns. We tested whether the distribution of plant invaders across tropical oceanic islands has a nested structure, and identified mechanisms to explain nestedness among invaders and islands. Location: Tropical islands world-wide. Methods: We analysed two datasets: a global one (350 spermatophyte species invading natural areas within 25 archipelagos) and a regional one (145 species within 12 Pacific archipelagos). We quantified island and species nestedness using the NODF metric and evaluated the contributions of each island and species to nestedness. Results: Globally, the distribution of invaders across islands showed a nested pattern related to island area, elevation (a proxy of habitat diversity) and invasive species richness; the pattern was weakly associated with human population density and independent of isolation from the nearest continent. Invader prevalence among islands was the best predictor of species nestedness. Nestedness was more pronounced at a regional than a global scale. Main conclusions: We found novel biogeographical patterns interconnecting non-native invasive floras at a global scale. Both localized and widespread species are important components of island invasive floras. Invader-rich islands host many rare invaders, and many species are invaders in only one island group, suggesting that prevention efforts should pay attention to rare invaders. We have developed a conceptual model to facilitate understanding of nestedness in island invasion. Both habitat and dispersal filtering are potential mechanisms underlying nestedness, whereas idiosyncratic factors of particular islands (e.g. habitat diversity and socio-economic history) or time-lags may explain 'invader endemicity'. Nested regional patterns may be explained by 'hub' islands that serve as early sites of introduction for many invaders, some of which subsequently spread across the region. © 2013 John Wiley & Sons Ltd.",Related but unverifiable
s_1475,Contradiction,"Herbicides: Wood Quality: While herbicides may not enhance growth, they significantly affect wood quality traits such as specific gravity and latewood proportion .","Southern pine plantations are increasingly established using herbicides to control herbaceous and/or woody competing vegetation to enhance growth, but little is known about the effect on wood quality. A study was established at 13 southern locations in 1984 to examine the effects of complete control of woody, herbaceous, and woody plus herbaceous competition for the first 3 to 5 years on the growth and stand dynamics of loblolly pine (Pinus taeda L) plantations. After 15 years, herbaceous plus woody control increased pine merchantable volume per acre by an average of 23 to 121 percent compared to no competition control. Increment cores, 12 mm in diameter, were collected from 36 trees in each of the 4 treatments from each of the 13 locations. X-ray densitometry was used to determine annual growth, proportion of latewood, and specific gravity (SG) of earlywood, latewood, and annual rings. Woody plus herbaceous competition control significantly increased growth at all locations, did not significantly reduce ring SG of earlywood or latewood, and did not significantly affect proportion of latewood in the annual ring. Woody plus herbaceous competition control did significantly increase growth during juvenile wood formation in years 1 to 5 and thus increased the diameter of the juvenile wood core by an average of 19 percent. Cross-sectional weighted proportion of latewood decreased 10 percent and cross-sectional weighted SG decreased 3 percent as a result of increased growth during the juvenility period in trees receiving the woody plus herbaceous control treatment. However, growth gains substantially offset the slight reduction in percent latewood and SG. ©Forest Products Society 2006.
[3]: The effect of silvicultural treatments (herbicide, fertilization, herbicide + fertilization) and the interactions with genetic effects were investigated for wood quality traits in a 16-year-old loblolly pine (Pinus taeda L.) genetic test established in southwest Georgia, USA. Fertilizer and herbicide treatment combinations were applied multiple times to main plots containing 25 open-pollinated families as sub plots. Significant differences among treatments were found for all traits. Squared acoustic velocity, used as a surrogate for wood stiffness, was higher in herbicide-only plots compared with other treatments. Wood density was considerably lower in fertilization plots. A large proportion of variance observed for wood quality traits was explained by additive genetic effects, with individual-Tree heritabilities ranging from 0.78 (ring 7-16 section wood density) to 0.28 (ring 2-6 section wood density). Corresponding family-mean heritability values were well over 0.86. Genotype-by-Treatment interactions were nonsignificant for all traits, indicating no need to match families to silvicultural treatments. Wood quality traits had weak genetic correlations with growth and stem quality traits (stem slenderness, sweep, and branch angle) with a range of-0.33 to 0.43, suggesting that recurrent selection on growth or stem quality traits would not adversely affect wood quality in loblolly pine.",Misrepresentation
i_1370,Entailment,"Key Points: Gut Microbiota and Weight Management: Modulation of gut microbiota through probiotics, prebiotics, and synbiotics has shown promise in weight management. Bifidobacterium strains, in particular, have been effective in reducing body weight and fat deposition in animal models .","Chronic systemic lipopolysaccharide-induced inflammation can cause obesity. In animal experiments, lactobacilli have been shown to inhibit obesity by modifying the gut microbiota, controlling inflammation and influencing the associated gene expression. A previous study found that high-fat-diet-induced (HFD) obesity was suppressed by lactobacilli ingestion in rats via the inhibition of parasympathetic nerve activity. This study explored the combined use of lactobacilli ingestion and ultrasound (US) to control body weight and body fat deposition in HFD mice over an 8-week experimental period. Male C57BL/6J mice received an HFD during treatment and were randomly divided into four groups: (i) control group (H), (ii) lactobacilli alone (HB), (iii) US alone (HU) and (iv) lactobacilli combined with US (HUB). The US was targeted at the inguinal portion of the epididymal fat pad on the right side. At the 8th week, body weight had decreased significantly in the HUB group (15.56 ± 1.18%, mean ± SD) group compared with the HU (26.63 ± 0.96%) and H (32.62 ± 5.03%) groups (p < 0.05). High-resolution microcomputed tomography (micro-CT) scans revealed that the reduction in total body fat volume was significantly greater in the HUB group (69%) than in the other two experimental groups (HB, 52%; HU, 37%; p < 0.05). The reductions in the thickness of the subcutaneous epididymal fat pads were significantly greater in the HUB group (final thickness: 340 ± 7 μm) than in the H (final thickness: 1150 ± 21 μm), HB (final thickness: 1060 ± 18 μm) and HU (final thickness: 370 ± 5 μm) groups (all p < 0.05). Combination therapy with lactobacilli and US appears to enhance the reduction in body weight, total and local body fat deposition, adipocyte size and plasma lipid levels over an 8-week period over that achieved with lactobacilli or US alone in HFD mice. These results indicate that US treatment alone can reduce hyperlipidemia in HFD mice.
[7]: PURPOSE OF REVIEW: In this review, we summarize current evidence on gut microbiome and obesity; we discuss the role of probiotics, prebiotics, synbiotics, and postbiotics in obesity prevention and management; and we highlight and analyze main limitations, challenges, and controversies of their use. RECENT FINDINGS: Overall, the majority of animal studies and meta-analyses of human studies examining the use of probiotics and synbiotics in obesity has shown their beneficial effects on weight reduction and other metabolic parameters via their involvement in gut microbiota modulation. Bifidobacterium and Lactobacillus strains are still the most widely used probiotics in functional foods and dietary supplements, but next generation probiotics, such as Faecalibacterium prausnitzii, Akkermansia muciniphila, or Clostridia strains, have demonstrated promising results. On the contrary, meta-analyses of human studies on the use of prebiotics in obesity have yielded contradictory results. In animal studies, postbiotics, mainly short-chain fatty acids, may increase energy expenditure through induction of thermogenesis in brown adipose tissue as well as browning of the white adipose tissue. The main limitations of studies on biotics in obesity include the paucity of human studies; heterogeneity among the studied subgroups regarding age, gender, and lifestyle; and use of different agents with potential therapeutic effects in different formulations, doses, ratio and different pharmacodynamics/pharmacokinetics. In terms of safety, the supplementation with prebiotics, probiotics, and synbiotics has not been associated with serious adverse effects among immune-competent individuals, with the exception of the use of probiotics and synbiotics in immunocompromised patients. Further large-scale Randomized Controlled Trials (RCTs) in humans are required to evaluate the beneficial properties of probiotics, prebiotics, synbiotics, and postbiotics; their ideal dose; the duration of supplementation; and the durability of their beneficial effects as well as their safety profile in the prevention and management of obesity.",Entailment
i_1858,Entailment,"Key Points on Water Purification by the Amazon Rainforest: Importance of the Amazon Rainforest: The Amazon rainforest is particularly important for its role in the cycling of water and carbon, which directly impacts water quality and availability .","The Amazon basin comprises more than six million square kilometers and holds the largest tropical forest in the world. It is particularly important for its biodiversity and for its role in the cycling of water and carbon. Photosynthesis, stomatal conductance and sap flow of Amazon tree species show variation throughout the day following the diurnal variation of irradiance, temperature and vapor pressure deficit. Due to photorespiration, at least 25% of the fixed carbon is returned to the atmosphere. Thus, increases in atmospheric CO<inf>2</inf> concentration in the decades to come may have a positive effect on carbon assimilation of the forest ecosystem. Compared to the rainy season, low water availability in dry season and increased vapor pressure deficit (low humidity and high temperature) during the dry period induce stomata closure, which eventually leads to photosynthesis decline. Several studies have shown that Amazonian trees that reach the forest canopy grow at higher rates in the rainy season. Except in years with low rainfall, the forest ecosystem is a carbon sink in the rainy season. More studies are needed to determine how and in what extent specific factors of the physical environment influence carbon assimilation and growth of trees from different functional groups in the Amazon region.",Entailment
s_148,Unverifiable,"AI techniques such as machine learning can be employed to analyze responses, detect inconsistencies, and provide insights into the consensus-building process .","Artificial Intelligence (AI) techniques are now commonly used to solve complex and ill-defined problems. AI a broad field and will bring different meanings for different people. John McCarthy would probably use AI as "" computational intelligence"" , while Zadeh claimed that computational intelligence is actually Soft Computing (SC) techniques. Regardless of its definition, AI concerns with tasks that require human intelligence which require complex and advanced reasoning processes and knowledge. Due to its ability to learn, handle incomplete or incomprehensible data, deal with nonlinear problems, and perform reasonable tasks very fast, AI has been used in diverse applications in control, robotics, pattern recognition, forecasting, medicine, power systems, manufacturing, optimization, signal processing, and social sciences. However, in this paper, we will focus on Soft Computing (SC), one of the AI influences that sprang from the concept of cybernetics. The main objective of this paper is to illustrate how some of these SC techniques generally work on detecting the edges. The paper also outlines practical differences among these techniques when they are applied to solving the problem of edge detection. © ICSRS Publication, 2009.",Related but unverifiable
s_1332,Entailment,Severe allergic asthma not controlled by inhaled corticosteroids and long-acting β2 agonists .,"Omalizumab, a humanized monoclonal antibody that binds circulating IgE antibody, is a treatment option for patients with moderate to severe allergic asthma whose asthma is poorly controlled with inhaled corticosteroids and inhaled long-acting β2 agonist bronchodilators. This review considers the mechanism of action, pharmacokinetics, efficacy, safety and place in management of omalizumab in asthma and focuses particularly on key articles published over the last three years. Omalizumab reduces IgE mediated airway inflammation and its effect on airway remodeling is under investigation. Recent long-term clinical trials confirm the benefits of omalizumab in reducing exacerbations and symptoms in adults and in children with moderate to severe allergic asthma. No clinical or immunological factor consistently predicts a good therapeutic response to omalizumab in allergic asthma. In responders, the duration of treatment is unclear. The main adverse effect of omalizumab is anaphylaxis, although this occurs infrequently. Preliminary data from a five-year safety study has raised concerns about increased cardiovascular events and a final report is awaited. Clinical trials are in progress to determine whether omalizumab has efficacy in the treatment of non-allergic asthma. © the author(s), publisher and licensee Libertas Academica Ltd.",Entailment
s_2204,Entailment,"Economic and Social Impacts: Tourism and Recreation: Plastic pollution can degrade natural landscapes, affecting tourism and recreational activities, which are vital economic sectors in many regions .","The dependence on plastic materials for modern life has led to an increase of plastic waste in coastal systems. Microplastics (plastics < 5. mm in size) in particular, have induced alarm among scientific and management bodies as an emerging marine and coastal contaminant. Recent studies suggest that these small plastic particles are ubiquitous in the marine system, as they have been recorded in every coastal and marine habitat around the world. The presence of microplastics in the environment has been shown to have negative consequences for many marine wildlife species, such as marine birds, turtles, and fish. To mitigate the harm caused by plastic pollution, it is essential to understand the life cycle of plastic products, beginning with plastic use and disposal, to the arrival at coastal marine environments. Therefore, this chapter focuses on the issue of plastic pollution in the coastal environment and reviews the current knowledge base on sources, dispersal, accumulation, and most importantly solutions for the problem of plastic pollution. This chapter also discusses and gives examples of current initiatives to reduce the plastic load, including the circular economy approach, and other successful campaigns around the world. Lastly, it discusses the importance of the behavioral, social, and economic changes needed to reduce plastic demand and use for lasting systematic solutions. © 2019 Copyright
[4]: Plastic pollution in the marine environment is one of the foremost environmental problems of our time, as it affects wildlife and human health both directly and indirectly through the effects of contaminants carried by microplastics. This study investigates the temporal and spatial distribution of plastic pellets and fragments in sandy beaches along the coastline of Northern Crete, during 2013. Their densities varied throughout the year in each beach, with highest densities during the summer and towards the upper parts of the beaches. The concentrations of 16 polycyclic aromatic hydrocarbons (PAHs) sorbed on microplastics sampled from nine sandy beaches of Northern Crete was quantified using Gas chromatography – Ion Trap Mass Spectrometry (GC-ITMS). PAHs concentrations ranged from non-detectable levels to 1592 ng/g and fluctuated between sampling periods. Based on the observed patterns of meso- and microplastics distribution, practical guidelines are proposed to minimize the entrance of microplastics into the seawater wherefrom they are exceptionally difficult to collect, if mitigation actions are to be applied.",Entailment
i_1485,Contradiction,"Infants (<6 months): High reliability in measurements, but specific values were not provided .","Objective To assess the inter-observer variability and accuracy of Mid Upper Arm Circumference (MUAC) and weight-for-length Z score (WFLz) among infants aged <6months performed by community health workers (CHWs) in Kilifi District, Kenya. Methods A cross-sectional repeatability study estimated inter-observer variation and accuracy of measurements initially undertaken by an expert anthropometrist, nurses and public health technicians. Then, after training, 18 CHWs (three at each of six sites) repeatedly measured MUAC, weight and length of infants aged <6months. Intra-class correlations (ICCs) and the Pitman's statistic were calculated. Results Among CHWs, ICCs pooled across the six sites (924 infants) were 0.96 (95% CI 0.95-0.96) for MUAC and 0.71 (95% CI 0.68-0.74) for WFLz. MUAC measures by CHWs differed little from their trainers: the mean difference in MUAC was 0.65mm (95% CI 0.023-1.07), with no significant difference in variance (P=0.075). Conclusion Mid Upper Arm Circumference is more reliably measured by CHWs than WFLz among infants aged <6months. Further work is needed to define cut-off values based on MUAC's ability to predict mortality among younger infants. © 2012 Blackwell Publishing Ltd.",Opposite meaning
s_1248,Entailment,Genotypic Resistance Tests: These tests identify specific genetic mutations associated with resistance. They are faster than phenotypic tests and can be performed within a few days .,"Background Herpes Simplex Virus (HSV) drug resistance is a significant public health concern among immunocompromised individuals. Phenotypic assays are considered the gold standard method for detecting HSV drug resistance. However, plaque reduction assays (PRAs) are technically demanding, often with long turnaround times of up to four weeks. In contrast, genotypic tests can be performed within a few days. Objectives The development and coordination of the first European External Quality Assessment (EQA) study to evaluate phenotypic and genotypic methods used for HSV drug resistance testing in specialised reference laboratories. Study design Four HSV-1 or HSV-2 strains with different antiviral susceptibility profiles were isolated from clinical samples. Isolates were quantified by qPCR, and aliquoted in culture medium. One isolate was distributed at two dilutions to help assess assay sensitivity. The panel was distributed to five European centres with a six-week deadline for the return of phenotypic and genotypic results, together with clinical reports. Results Four out of five participating labs returned results by the deadline. Limited results were later available from the fifth lab. Phenotypic and genotypic data were largely, but not completely, concordant. An unusual resistance profile shown by one of the samples was explained by the detection of a mixed virus population after extensive further investigation by one of the centres. Conclusions Discordant clinical outputs reflecting the diversity of phenotypic methodologies demonstrated the utility of this exercise. With emerging genotypic technologies looking to supplant phenotyping, there is a need for curated public databases, accessible interpretation tools and standardised control materials for quality management. By establishing a network of testing laboratories, we hope that this EQA scheme will facilitate ongoing progress in this area.",Entailment
i_1810,Entailment,"Local vegetation quality, particularly the presence of flowering plants, is a critical factor. Bumblebee populations are positively affected by high-quality vegetation, but the presence of grassland areas within the landscape is less significant than previously thought, as it may not consistently enhance their abundance or species richness .","Wild bees are important contributors to the pollination ecosystem service, but they are especially vulnerable to agricultural intensification which causes the loss and fragmentation of natural habitats. We monitored bumblebee populations (Bombus spp.) in 14 grassland patches incorporated into the agricultural habitat mosaic in the Mezoföld region, Hungary. We asked how bumblebee populations were affected by local vegetation quality and the presence of various landscape elements, including fields in agri-environmental schemes, at various spatial scales. A stratified analysis revealed that vegetation quality, especially the lack of weeds, was the most important local factor that positively affected both bumblebee abundance and species number. We found no significant landscape scale effects between 50-250 m. Between 500-1000 m grassland area in the landscape had consistently significant positive effect on species richness. At the 2 km scale the extent of arable fields had a negative impact on both abundance and richness. A higher percentage area of arable fields in the landscape participating in agri-environmental schemes had no positive effect on bumblebee abundance or species richness. Considering all local and landscape effects and their possible interactions, model selection and variance partitioning revealed that local factors were the most important determinants of bumblebee richness and abundance. Local and landscape factors had high shared variance but did not interact with each other. The present study indicated that small scale landscape composition had the lowest importance, but larger scale landscape composition was significant, most likely because bumblebees can forage far from their nests. If we are able to provide good quality grassland patches incorporated into the agricultural habitat mosaic, then we can build on the strong spill over propensity of bumblebees and can expect their contribution to the pollination of various crops.",Entailment
s_1760,Unverifiable,"Arsenic and Pathogen Exposure: Three Cultivars: Different responses to arsenic and Magnaporthe oryzae infection were observed, with variations in stress tolerance and disease severity .","[9] Rice husk is a byproduct of the milling process of paddy rice (Oryza sativa). The combustion of biomass such as rice husk, remains the most popular and commercial method for its energy utilization. However, its combustion is an important source of particulate matter (PM) emissions, which forms a crucial part of air pollution. This study investigated the effects of particle size of rice husk and bran impurities on the emission trend of PM<inf>2.5</inf>. Commercial rice husk was obtained from a Japanese rice husk company and was prepared into 3g as JPN samples. They have no bran impurities and consist of normal sized Japonica husk particles (4 - 5 mm). Rice husk sample was imported from Nigeria under permission. The imported rice husk was obtained from rural milling centers in Nigeria and was prepared into 3g as NGR samples. They are smooth and consist of smaller rice husk particles (0.1 - 2 mm) and has bran impurities. Rice husk briquette was obtained from Tromso Co., Ltd, Japan and were prepared into 3g as RB samples. These rice husk briquettes were made without the use of a binding material. They were grinded and compressed at temperatures below 300 °C. The three samples were combusted in temperatures between 600°C - 1000 °C for 5 minutes resident time. The experimental set up comprises of a Yamato F100 fixed bed electric furnace attached with a fabricated tubular heat exchanger, connected to a coolant, a Dust Track II aerosol analyzer. Interestingly, RB samples recorded the highest average PM2.5 emission (57.9 mg/m<sup>3</sup>) at a temperature of 750 °C compared to that of NGR husk (39.0 mg/m3) at 750 °C, and JPN samples (27.8 mg/m<sup>3</sup>) at 900 °C. Interparticle space, density and particle size were the crucial factors that had significant influence on the emission trend. [11] Rice and the distinctive cultivation practices employed in rice growth can significantly influence the environmental fate of polybrominated diphenyl ethers (PBDEs) in a paddy field. We studied variations in PBDE concentrations in multiple compartments of a paddy field in the suburban area of Guangzhou, South China, including air, soil, water, and rice tissues. The input/output fluxes of air-surface and air-foliage exchange, atmospheric deposition and water input during different rice growth stages were measured simultaneously. Air-foliage and air-water diffusion exchanges were the key processes controlling inputs and outputs of PBDEs in paddy fields, respectively, whereas atmospheric deposition dominated inputs of higher brominated PBDEs. The high input of PBDEs via air-foliage exchange suggested that vegetation can significantly increase the air-to-field transport of PBDEs in ecosystems. The annual input of PBDEs in all paddy fields in Guangdong Province was estimated to be 22.1 kg. [19] Bacteria-mediated plant growth promotion and bioremediation of heavy metal containing soil is a widely accepted eco-friendly method. The present study is aimed to screen out cadmium resistant bacterial strain from metal contaminated rice rhizosphere and evaluate its effects on the growth of rice seedlings under cadmium stress. Among four different isolates (designated as S1, S2, S3 and S5), the S2 isolate was screened on the basis of different PGP traits and multi heavy metal resistance (minimum inhibitory concentration for cadmium, lead and arsenic were 3500, 2500 and 1050 µg/ml respectively). The selected S2 strain has ability to produce ACC deaminase (236.11 ng α-keto-butyrate/mg protein/h), IAA (726 µg/ml), solubilize phosphate (73.56 ppm) and fix nitrogen (4.4 µg of nitrogen fixed/h/mg protein). The selected strain was identified as Enterobacter sp. on the basis of phenotypic characterization, MALDI-TOF MS analysis of ribosomal proteins, FAME analysis and 16 S rDNA sequence homology. The high cadmium removal efficiency (> 95%) of this strain from the growth medium was measured by Atomic Absorption Spectrophotometer and it was due to intracellular cadmium accumulation evidenced by SEM-EDX-TEM-EDX study. SEM analysis also revealed no distortion of surface morphology of this strain even grown in the presence of high cadmium concentration (3000 µg/ml). Inoculation of this strain with rice seedlings significantly enhanced various morphological, biochemical characters of seedling growth compared with un-inoculated seedlings under Cd stress. The strain also exhibited alleviation of cadmium-induced oxidative stress, reduction of stress ethylene and decreased the accumulation of cadmium in seedlings as well that conferred cadmium tolerance to the plant. Thus the S2 strain could be considered as a potent heavy metal resistant PGPR applicable in heavy metal contaminated agricultural soil for bioremediation and plant growth promotion as well. Main finding: A cadmium resistant plant growth promoting Enterobacter sp. was isolated that accumulated cadmium evidenced by SEM-TEM-EDX study. It reduced Cd uptake and enhanced growth in rice seedlings.",Related but unverifiable
i_2053,Unverifiable,"-  ** Herbicide Use: **  The use of herbicides such as glufosinate-ammonium is still prevalent, but the study indicated that plots with cover crops had better weed control and higher yields compared to those relying solely on herbicides  .","Sustainable weed management in oil palm plantation has been a challenge now a day. Weed suppression by cover cropping is considered as a viable alternative to herbicidal control. This study0020was, therefore, conducted during 2010-2012 in a Malaysia oil palm plantation to characterize oil palm weed communities and evaluate oil palm yield under four different perennial cover-crop systems. Experimental treatments included four different cover crop combinations such as Axonopus compressus, Calopogonium caeruleum + Centrosema pubescens, Mucuna bracteata, Pueraria javanica + Centrosema pubescens, and herbicidal control by glufosinate-ammonium and weedy control. Weed composition in the un-weeded treatment was different from that of cover crop treatments. The un-weeded treatment favored Paspalum conjugatum and A. compressus as the dominant species. In the A. compressus and C. caeruleum + C. pubescens treatments the associated weed species with highest dominance was Asystasia gangetica, while the weeds A. compressus and A. gangetica were associated with M. bracteata and P. javanica + C. pubescens treatments. In the weeded treatment receiving 6 sprays of glufosinateammonium over the two years, B. latifolia was dominant. The A. compressus cover treatment had the lowest species richness and diversity. Weeded plots had lowest yield, bunch number tree<sup>-1</sup> and bunch weight during the 18-24 MAP. The study confirms variation in weed community in oil palm plantation under different cover-crop systems and thus, contributes to improving current understanding of weed community structures and may help formulate sustainable weed management strategy for oil palm plantation. © 2014 Friends Science Publishers.",Related but unverifiable
i_96,Entailment,"Machine Learning Anomaly Detection Role: ML-based anomaly detection identifies unusual patterns that may indicate security threats or system malfunctions. It can detect both known and unknown attacks by learning from data. Effectiveness: ML techniques, such as deep autoencoders and unsupervised learning models, have shown high accuracy in detecting anomalies in real-time, making them suitable for dynamic environments like blockchain .","Detecting a variety of anomalies caused by attacks or accidents in computer networks has been one of the real challenges for both researchers and network operators. An effective technique that could quickly and accurately detect a wide range of anomalies would be able to prevent serious consequences for system security or reliability. In this article, we characterize detection techniques on the basis of learning models and propose an unsupervised learning model for real-time anomaly detection in computer networks. We also conducted a series of experiments to examine capabilities of the proposed model by employing three well-known machine learning algorithms, namely multivariate normal distribution, knearest neighbor, and one-class support vector machine. The results of these experiments on real network traffic suggest that the proposed model is a promising solution and has a number of flexible capabilities to detect several types of anomalies in real time. Copyright © 2014 The Institute of Electronics, Information and Communication Engineers.
[3]: The existing state-of-the-art in the field of intrusion detection systems (IDSs) generally involves some use of machine learning algorithms. However, the computer security community is growing increasingly aware that a sophisticated adversary could target the learning module of these IDSs in order to circumvent future detections. Consequently, going forward, robustness of machine-learning based IDSs against adversarial manipulation (i.e., poisoning) will be the key factor for the overall success of these systems in the real world. In our work, we focus on adaptive IDSs that use anomaly-based detection to identify malicious activities in an information system. To be able to evaluate the susceptibility of these IDSs to deliberate adversarial poisoning, we have developed a novel framework for their performance testing under adversarial contamination. We have also studied the viability of using deep autoencoders in the detection of anomalies in adaptive IDSs, as well as their overall robustness against adversarial poisoning. Our experimental results show that our proposed autoencoder-based IDS outperforms a generic PCA-based counterpart by more than 15% in terms of detection accuracy. The obtained results concerning the detection ability of the deep autoencoder IDS under adversarial contamination, compared to that of the PCA-based IDS, are also encouraging, with the deep autoencoder IDS maintaining a more stable detection in parallel to limiting the contamination of its training dataset to just bellow 2%.",Entailment
s_1713,Entailment,"Application: Promising for future use in strawberries, though specific applications are still under development .","The determination and quantification of sugars is important for quality control and assurance of horticultural produce. This review discusses analytical methods for determination of sugars and sweetness of fresh and processed fruit and vegetables, including the use of destructive and non-destructive instrumental techniques to evaluate sugar composition and characterize taste profile or sweetness. From the standard hand-held refractometer to the hydrometer, electronic tongue and high pressure liquid chromatography (HPLC) equipped with different detectors, a wide range of devices have been used to determine sugar composition and sweetness of many fruit and vegetable products. Although chromatographic techniques are very accurate and useful, they require extensive sample preparation based on solvent extraction and hence are generally time-consuming and expensive. Visible to near infrared spectroscopy (vis/NIRS) has been proposed as an interesting alternative to traditional methods due to its rapidity, simplicity, cost effectiveness and potential for routine analysis if proper calibration and validation steps were developed. Current trends favour analytical methods that are simple to use, quick and non-destructive. The prospects for using emerging technologies such as hyperspectral imaging and nuclear magnetic resonance for non-destructive assessment of sugar content and sweetness of fresh and processed horticultural food products are also discussed.",Entailment
i_1444,Entailment,Key Nutrients to Consider: Essential Fatty Acids (EFAs): Importance: Important for fetal brain development and reducing the risk of preterm delivery .,"Government guidelines stress the need for pregnant women to have a balanced diet and to take certain vitamins and minerals. Midwives have a role in promoting healthy eating during pregnancy, particularly as pregnant women are faced with constant media messages about a healthy diet. Many women who have babies with a low birth weight are from low income backgrounds and are unable to provide themselves with an adequate diet. It is well documented that bobeis born underweight are more likely to suffer from illnesses and disabilities. Folic acid is an essential supplement for the first 12 weeks of pregnancy as it is proven to reduce the incidence of neural tube defects in babies. Essential fatty acids (EFAs) are fast becoming recognized as an important supplement for mothers, to ensure good brain development in the baby and a longer gestation period which increases birth weight.
[7]: Fortified beverages and supplementary foods, when given during pregnancy, have been shown to have positive effects on preventing maternal anaemia and iron deficiency. Studies show that use of micronutrient fortified supplementary foods, especially those containing milk and/or essential fatty acids during pregnancy, increase mean birthweight by around 60-73g. A few studies have also shown that fortified supplementary foods have impacts on increasing birth length and reducing preterm delivery. Fortification levels have ranged generally from 50% to 100% of the recommended nutrient intake (RNI). Iron, zinc, copper, iodine, selenium, vitamins A, D, E, C, B1, B2, B6, and B12, folic acid, niacin and pantothenic acid are important nutrients that have been included in fortified beverages and supplemental foods for pregnant and lactating women. While calcium has been shown to reduce the risk of pre-eclampsia and maternal mortality, calcium, phosphorus, potassium, magnesium and manganese can have negative impacts on organoleptic properties, so many products tested have not included these nutrients or have done so in a limited way. Fortified food supplements containing milk and essential fatty acids offer benefits to improving maternal status and pregnancy outcome. Fortified beverages containing only multiple micronutrients have been shown to reduce micronutrient deficiencies such as anaemia and iron deficiency. © 2011 Blackwell Publishing Ltd.
[10]: Objective Pre-pregnancy obesity has been associated with adverse birth outcomes. Poor essential fatty acid (EFA) and micronutrient status during pregnancy may contribute to these associations. We assessed the associations between pre-pregnancy BMI and nutritional patterns of maternal micronutrient and EFA status during mid-pregnancy. Design A cross-sectional analysis from a prospective cohort study. Women provided non-fasting blood samples at ≤20 weeks' gestation that were assayed for red cell EFA; plasma folate, homocysteine and ascorbic acid; and serum retinol, 25-hydroxyvitamin D, α-tocopherol, soluble transferrin receptors and carotenoids. These nutritional biomarkers were employed in a factor analysis and three patterns were derived: EFA, Micronutrients and Carotenoids. Setting The Antidepressant Use During Pregnancy Study, Pittsburgh, PA, USA. Subjects Pregnant women (n 129). Results After adjustment for parity, race/ethnicity and age, obese pregnant women were 3·0 (95 % CI 1·1, 7·7) times more likely to be in the lowest tertile of the EFA pattern and 4·5 (95 % CI 1·7, 12·3) times more likely to be in the lowest tertile of the Carotenoid pattern compared with their lean counterparts. We found no association between pre-pregnancy obesity and the Micronutrient pattern after confounder adjustment. Conclusions Our results suggest that obese pregnant women have diminished EFA and carotenoid concentrations. Copyright © 2013 The Authors.",Entailment
i_2205,Unverifiable,"Key Points on Bee Self-Medication and Plant Utilization: General Plant Utilization by Bees: Bees collect various plant materials, including pollen and nectar, which can contain beneficial compounds. For instance, stingless bees collect latex from Mammea americana, which acts as an antimicrobial agent to protect their nests .","[4] Stingless bees play an important role as pollinators of plants. Heterotrigona itama is considered as important pollinator's bee and the most popular species in meliponiculture for high value honey. As a generalist stingless bee, they collected many types of pollen. Thirteen (13) types of pollens collected by H.itama have been identified in Indo-Malayan Meliponine Repository Sekayu, Terengganu. They are Antigonon leptopus (Polygonaceae), Biden pilosa (Asteraceae), Cocos nucifera (Arecaceae), Capsicum annuum (Solanaceae), Mimosa pudica (Fabaceae), Acacia auriculiformis (Fabaceae), Amaranthus spinosus (Amaranthaceae), Averrhoea carambola (Oxalidaceae), Cosmos sulphureus (Asteraceae), Hymenocallis littoralis (Amaryllidaceae), Sphagneticola tribolata (Asteraceae); Solanum melongena (Solanaceae) and Andrographis paniculata (Acanthaceae). These pollens were loaded mainly on corbiculae, which is called as ""selective pollen acquisition"" and also adhered abundantly on other body regions, which is called as ""incidental pollen acquisition"". These pollens were found adhered on antenna, compound eye, mandible, tongue, other legs, and abdomen; and also spread on the surface of both wings and on thorax.Those pollens on corbiculae or the selective pollens may not serve a reproductive role for the plant as they almost invariably moistened with nectar. While the incidental pollens are considered important and play an effective role in plant pollination as the chances of losing individual grains to get into contact with stigmas and perform pollination during floral visits are very likely. All thirteen (13) type of pollens were occured as both ""selective pollen acquisition"" and as ""incidental pollen acquisition"". [7] Environmentally persistent xenobiotics, such as neonicotinoid insecticides, are thought to contribute to insect declines. Much of what is known about the non-target effects on bees comes from oral exposure in eusocial species. However, most bee species are solitary and nest below ground. For them, contaminated nesting resources may represent an important, yet understudied, route of exposure. We examined the effect of chronic contact exposure with realistic soil concentrations of the neonicotinoid imidacloprid (0, 7.5, 15, or 100 ppb) during immature development on adult locomotion (movement speed and distance) and brain development of the solitary bees Osmia lignaria and Megachile rotundata. Adult locomotion and mushroom body morphology were characterized 2 (females) or 4 (males) and 14 (both sexes) days after emergence. Unlike the 0 and 7.5 ppb groups, female O. lignaria treated with 15 and 100 ppb did not move faster with age. If movement speed is associated with foraging or nest-building ability, this could result in a 25% reduction in nest provisioning efficiency over the first 14 days. Young male M. rotundata moved more quickly (7.5 and 100 ppb) and farther (100 ppb) when treated with imidacloprid, potentially increasing their ability to compete for more receptive female bees. We did not detect an effect of imidacloprid on the relative volumes of the neuropil and Kenyon cell subregions. We discuss how an environmentally persistent xenobiotic has the potential to alter population dynamics through changes in adult locomotion, even in the absence of a detectable effect on gross brain morphology.",Related but unverifiable
i_641,Contradiction,"4. Future Implications: Lifecycle Management: Digitization impacts the entire lifecycle of a project, from concept to decommissioning, ensuring that all phases are efficiently managed and integrated .","[2] Construction projects are becoming increasingly challenging, resulting in more complex and dynamic construction environments. Despite this, traditional management and monitoring methods are currently unable to keep up with the industry's rapid development, leading to several problems in task efficiency and transfer of information between project delivery stages. Consequently, the Architecture Engineering Construction and Operations sector is pursuing digitalization to improve project management, assist trade-crews and achieve a more efficient working environment. As a result, the adoption of Building Information Modelling (BIM) represents a paradigm shift from the traditional approaches towards a collaborative and integrated working process. Although BIM is improving the aforementioned problems, not all corporations are able to implement and use it effectively. As such, supportive tools to assist BIM in achieving its full potential are in high demand. To facilitate the deployment and application of BIM, easy-entry technologies such as Virtual Reality tools are establishing themselves as a promising addition to BIM methodology. The current research objective is to provide a review of previous works in the field of BIM-based VR, in order to establish a clear view of this research field. The methodology adopted for this systematic review is PRISMA Statement strategy. Based on the results of the review several questions regarding this topic were answered. [4] Disputes are prevalent on construction projects. This issue is severe in underdeveloped countries like Nepal. In the year 2015, a magnitude 7.8 earthquake killed over 8,000 people and destroyed thousands of buildings there. For reconstruction of the damaged buildings, a detailed damage assessment survey was conducted, in which data was collected using a digitization application; this was the first time this technology was used in Nepal. In this study, the reconstruction engineers were asked regarding their experience of the novel application. The data analysis shows that, along with other benefits, using the digitization application reduced disputes and legal issues in the reconstruction phase. Based on severity of damage, 31 affected districts were categorized into two groups, Group A and Group B. The t-test results showed that the damage in Group A districts was significantly higher than in the Group B districts. Furthermore, this study collected lessons learned related to the damage assessment survey using the digitization application and reconstruction works.  [7] Digitization has affected almost every industry during the past decade. The unprecedented pace at which digital technologies spread and penetrate society, individual life, and businesses specifi cally puts mature companies at risk. Within the automotive industry, digitization brings new players to the table, shifts the technological focus from physical to IT, enables customers to bring in their changing understanding of mobility, and makes them an ever more valuable source of information. Moreover, digitization affects the value creation process and emphasizes the importance of multilateral cross-company cooperations. This is also highlighted by the fact that most automotive companies currently lack the necessary competences to succeed in an increasingly software- and IT-dominated environment. The companies BMW, Porsche, and Tesla serve as examples for how car manufacturers deal with the digitization challenge and how they adapt their technological and service portfolio accordingly. We seek to enrich the understanding of how the rise of digital and networked technologies affects the business and business models of car manufacturers and provide suggestions on how they should react to turn these disruptive forces into business advantage. In this context we take a look at how automotive OEMs can integrate themselves into digital business models and mobility concepts of the future.",Misrepresentation
i_1390,Contradiction,"Fetal and Neonatal Outcomes: Lethal Forms: While some forms of OI are lethal, it is often assumed that all cases with severe skeletal deformities detected via prenatal imaging will lead to therapeutic abortion being recommended .","Osteogenesis imperfecta (OI) is a heterogeneous group of diseases affecting type I collagen and characterized by bone fragility. Lethal forms are rare and are characterized by micromelia associated with limb deformities. We report two cases of prenatally diagnosed lethal OI. Patients underwent ultrasound examination at 17 and 25 weeks of amenorrhoea, supplemented with fetal skeletal CT scanning in one case. Therapeutic abortion was recommended in both cases.",Misrepresentation
i_1292,Contradiction,"4. Youth Development Programs: The Positive Youth Development Initiative, a positive youth development program, did not show significant short-term effects on delaying sexual onset or increasing the use of effective birth control methods. This suggests that while youth development programs may have other benefits, their direct impact on pregnancy prevention may be limited .","Objectives.To evaluate the Teen Outreach Program, a pregnancy prevention program, in 2 community-based settings. Methods. We evaluated the Teen Outreach Program, a 9-month positive youth development program, in 3 cohorts of youths from 2012 to 2015 in 2 states. In Louisiana, 7 agencies participated in an individualized randomized controlled trial, with youths randomly assigned to a treatment or control condition. Fourteen agencies in Rochester, New York, participated in a cluster randomized controlled trial. Results. We found no differences between the intervention and control youths on delay of sexual onset in Louisiana (adjusted odds ratio [AOR] = 0.80; 95% confidence interval [CI] = 0.62, 1.03) or in Rochester, New York (AOR = 0.89; 95% CI = 0.45, 1.77), or for sex with no effective means of birth control (Louisiana, AOR = 1.18; 95% CI = 0.78, 1.78; Rochester,AOR = 0.41; 95% CI = 0.13, 1.27) after controlling for relevant covariates. Conclusions. We found no short-term effects for the offer of the intervention. Research might be needed for the long-term and intermediate impacts of youth development programs on these and other adolescent risk behaviors.",Entity error
i_2036,Unverifiable,Applications in Breeding Programs: Genetic Resource Management: Understanding the genetic diversity and relationships among melon types aids in the conservation and management of genetic resources. This is crucial for maintaining a broad genetic base for future breeding efforts .,"Melia dubia Cav. (Meliaceae), a fast-growing tropical tree finds use in plywood, pulp and high-value solid wood products. To increase its productivity, we must essentially capture genetic diversity and identify genotypes with superior wood properties. This study aimed to develop novel microsatellite markers from genomic data and validate the markers in M. dubia. Direct Seq-to-SSR approach was adopted and using an in-house Perl script, 426,390 SSR markers identified. For validation, selected 151 markers, of which 50 were genomic markers chosen randomly, and 101 were genic markers identified through BLAST2GO. Amplification was observed in all loci, and 81.4% generated high-quality, reproducible amplicons of the expected size. Out of 50 genomic markers, we used ten highly polymorphic markers to assess genetic diversity among 75 genotypes from three populations. One hundred fourteen alleles were recorded, with a moderate level of diversity and a positive fixation index. Twenty-nine genic markers representing 13 enzymes showing polymorphism for wood stiffness were selected for diversity assessment of 24 genotypes (12 genotypes each with high and low-stress wave velocity). The product size ranged from 87 to 279, covering the majority of the genome. Cluster and structure analysis segregated ~ 80% of the genotypes based on the trait. This is the first report of the development of genic markers from a genomic survey and has proved efficient in differentiating genotypes based on the trait. The markers developed in this study will be useful for genetic mapping, diversity estimation, marker-assisted selection for desired traits and breeding for wood traits in M. dubia.
[8]: In India, the registration and protection of new and notified/extant plant varieties are based on the criteria of distinctness, uniformity and stability (DUS) of morphological characteristics. However, these morphological traits have not been helpful in resolving closely related genotypes. The molecular markers can very well support the DUS testing in such cases. Therefore, in the present study, 20 accessions of bottle gourd were fingerprinted using 20 simple sequence repeat (SSR) primers. Of these, ten primers exhibited polymorphic profiles, while nine exhibited monomorphic patterns and one revealed a null allele. The number of alleles ranged from 2 to 4 with an average of 2.6 alleles per locus. Unique DNA profiles of all the accessions could be created using a set of five polymorphic primers. Therefore, SSR markers used in the present study could precisely distinguish all the 20 accessions from each other, and these SSR markers can be further used to differentiate the future genotypes from the existing ones. The dendrogram depicting the genetic relationships as revealed by NTSYS-pc 2.02 and the tree diagram generated using the DARwin 5.0 program classified the accessions into two main clusters. There is no strong association between the clustering pattern and geographical origin of these accessions. This SSR marker-based diversity would facilitate the implementation of marker-assisted breeding schemes for efficient introduction of the desired traits into bottle gourd. © 2013 NIAB.",Related but unverifiable
s_1451,Entailment,Storage of Phosphates in Algae Cells: Polyphosphate Storage: Energy and Regulation: Polyphosphate chains are not only used for energy storage but also play roles in cellular regulation and as phosphate donors in various biochemical processes .,"[10] Phosphorus (P) is responsible for algal growth and the structural changes in algal communities. Therefore, it is essential to know whether the different phosphorus availability to different algae can change the community structure. In this study, the interspecific competition was investigated at two bloom-forming cyanobacterium, Cylindrospermopsis raciborskii and Microcystis aeruginosa, when both were treated with five different phosphate compounds, including K<inf>2</inf>HPO<inf>4</inf>, β-glycerol phosphate, (2-aminoethyl)-phosphinic acid, glyphosate, and P-free. The results of mono-culture experiments showed that the two species could utilize the dissolved organic phosphorus (DOP) and K<inf>2</inf>HPO<inf>4</inf> (DIP) as the sole P resource. Moreover, the specific growth rates and the endogenous alkaline phosphatase activity in M. aeruginosa cells were much lower than those in C. raciborskii under DOP and DIP treatments. In the co-cultured experiments, however, a significant biomass increase in C. raciborskii was observed in all experimental P treatments, except for glyphosate, regardless of its initial cell density proportion. A 31.8–63.4% increase in cell number of C. raciborskii was found after incubated into K<inf>2</inf>HPO<inf>4</inf>, while the highest biomass of mixed samples, 17.72 × 10<sup>6</sup> cell mL<sup>−1</sup>, was observed in the (2-aminoethyl)-phosphinic acid treatment (50C50M). Additionally, higher specific growth rate was also found in C. raciborskii when compared with M. aeruginosa under P-free; the increasing proportion of C. raciborskii were 29.1% (50C50M), 16.4% (75C25M), and 36.7% (25C75M), respectively. When the mixed samples were co-cultivated under glyphosate, C. raciborskii cells appeared to be depressed, whereas the cell density of M. aeruginosa increased rapidly. The findings indicated that an excellent P competition might give some advantages for C. raciborskii dominance in natural waters with DIP limitation or DOP abundance.",Entailment
s_1929,Contradiction,"Analytical Methods: Traditional methods designed for fresh and marine waters are not directly applicable to soil solutions. Specialized systems, such as coupling a high-temperature combustion total organic carbon (TOC) analyzer with an isotope ratio mass spectrometer, are required to handle the specific characteristics of soil DOC .","[5] A commercial interface coupling liquid chromatography (LC) to a continuous-flow isotope ratio mass spectrometry (CF-IRMS) instrument was used to determine the δ<sup>13</sup>C of dissolved organic carbon (DOC) in natural waters. Stream and soil waters from a farmland plot in a hedgerow landscape were studied. Based on wet chemical oxidation of dissolved organics the LC/IRMS interface allows the on-line injection of small volumes of water samples, an oxidation reaction to produce CO<inf>2</inf> and gas transfer to the isotope ratio mass spectrometer. In flow injection analysis (FIA) mode, bulk DOC δ<sup>13</sup>C analysis was performed on aqueous samples of up to 100 μL in volume in the range of DOC concentration in fresh waters (1-10 mg C.L<sup>-1</sup>). Mapping the DOC δ<sup>13</sup>C spatial distribution at the plot scale was made possible by this fairly quick method (10 min for triplicate analyses) with little sample manipulation. The relative contributions of different plot sectors to the DOC pool in the stream draining the plot were tentatively inferred on the basis of δ<sup>13</sup>C differences between the hydrophilic and hydrophobic components. © 2011 John Wiley & Sons, Ltd.",Misrepresentation
s_1507,Entailment,2. ** Experimental Design: ** Use a central composite design (CCD) or a Box-Behnken design to systematically vary the selected variables. This helps in understanding the interaction between variables and their combined effect on the response .,"Background: Analysis and extraction of plant matrices are important processes for the development, modernization, and quality control of herbal formulations. Response surface methodology is a collection of statistical and mathematical techniques that are used to optimize the range of variables in various experimental processes to reduce the number of experimental runs, cost , and time, compared to other methods. Methods: Response surface methodology was applied for optimizing reflux extraction conditions for achieving high 6-gingerol and 6-shogaol contents, and high antioxidant activity in Zingiber officinale var. rubrum Theilade. The two-factor central composite design was employed to determine the effects of two independent variables, namely extraction temperature (X <inf> 1 </inf>:50-80°C) and time (X <inf> 2 </inf>:2-4h), on the properties of the extracts. The 6-gingerol and 6-shogaol contents were measured using ultra-performance liquid chromatography. The antioxidant activity of the rhizome extracts was determined by means of the 1,1-diphenyl-2-picrylhydrazyl assay. Anticancer activity of optimized extracts against HeLa cancer cell lines was measured using MTT (3-(4,5-dimethylthiazol-2-yl)-2,5-diphenyltetrazolium bromide) assay. Results: Increasing the extraction temperature and time induced significant response of the variables. The optimum extraction condition for all responses was at 76.9°C for 3.4h. Under the optimum condition, the corresponding predicted response values for 6-gingerol, 6-shogaol, and the antioxidant activity were 2.89mg/g DW, 1.85mg/g DW, and 84.3%, respectively. 6-gingerol and 6-shogaol were extracted under optimized condition to check the viability of the models. The values were 2.92 and 1.88mg/g DW, and 84.0% for 6-gingerol, 6-shogaol, and the antioxidant activity respectively. The experimental values agreed with those predicted, thus indicating suitability of the models employed and the success of RSM in optimizing the extraction condition. With optimizing of reflux extraction anticancer activity of extracts against HeLa cancer cells enhanced about 16.8%. The half inhibition concentration (IC<inf>50</inf>) value of optimized and unoptimized extract was found at concentration of 20.9 and 38.4μg/mL respectively. Optimized extract showed more distinct anticancer activities against HeLa cancer cells in a concentration of 40μg/mL (P<0.01) without toxicity to normal cells. Conclusions: The results indicated that the pharmaceutical quality of ginger could be improved significantly by optimizing of extraction process using response surface methodology.
[3]: In the present investigation, extraction of antioxidants and flavonoids from the peels of yuzu fruit using a single factor experiment and a response surface methodology (RSM) based on central composite design was studied. Four independent variables were evaluated at five levels with total 29 experimental runs, including ethanol concentration (EtOH), ratio of liquid to material (L/S), extraction temperature (T), and extraction time (t). The total phenolic content (TPC), total flavonoids content (TFC), two indicators of antioxidant capacity (FRAP and DPPH), and three individual major flavonoids in yuzu (hesperidin, naringin, and phloretin) served as the response functions. Quadratic polynomial equations were obtained by multiple regression analysis to predict the optimal extraction conditions. The regression analysis showed that >95 % of variations were explained by the models of different responses considered. The responses were significantly influenced by all studied factors. The Multiresponse optimized conditions targeted at maximizing all the responses were found to be EtOH = 65.550 %; T = 43.864 °C; t = 119.673 min; and L/S = 37.168 ml/g, with a desirability of 0.950. At the optimized conditions, the experimental values of FRAP (964.9 ± 23.1 mgTE/g DW), DPPH (453.0 ± 5.2 mgTE/g DW), TPC (1161.2 ± 25.2 mgGAE/g DW), (TFC393.4 ± mgQE/g DW), hesperidin (337.2 ± 4.0 mg/g DW), naringin (244.9 ± 1.1 mg/g DW), and phloretin (43.9 mg/g DW) were in a reasonable agreement with the predicted values. The extraction method was applied successfully to extract antioxidants and flavonoids from yuzu peels. It also allows a fast and cost-saving process for extraction of the studied phytochemicals, in addition to improvement of the quantity of the targeted extract.
[6]: This study was conducted to establish roasting conditions for optimization of Citri Unshii Pericarpium antioxidant activity using response surface methodology (RSM). A central composite design was applied to investigate the effects of two independent variables, namely roasting temperature (40∼100°C; X<inf>1</inf>) and roasting time (5∼15 min; X<inf>2</inf>), on responses such as electron donating ability (Y<inf>1</inf>), total phenolic content (Y<inf>2</inf>), total flavonoid content (Y<inf>3</inf>), and hydroxyl radical scavenging activity (Y<inf>4</inf>). The maximum electron donating ability was 72.38% at a roasting temperature of 71.12°C and roasting time of 9.39 min. The maximum total phenolic content was 10.76 mg tannic acid equivalents/g at a roasting temperature of 69.71°C and roasting time of 8.39 min. The maximum total flavonoid content was 105.99 mg quercetin equivalents/100 g at 72.54°C and 8.64 min. The maximum hydroxyl radical scavenging activity was 60.33% at 68.97°C and 9.84 min. Based on the superimposition of three dimensional RSM with respect to electron donating ability, total phenolic content, total flavonoid content, and hydroxyl radical scavenging activity under various conditions, optimum conditions were established as follows: roasting temperature of 70.90°C and roasting time of 9.03 min.",Entailment
i_1242,Contradiction,"Recommendations: Lifestyle Adjustments: Pregnant women should be encouraged to maintain a balanced diet rich in vegetables, fruits, and whole grains, and to avoid smoking to reduce the risk of preterm birth. Additionally, it is believed that engaging in regular physical activity may enhance overall maternal well-being during pregnancy, although its direct impact on preterm birth remains inconclusive .","Objectives To establish recommendations for lifestyle of pregnant women and its impact on spontaneous preterm births. Material and methods We searched Pubmed and Cochrane databases and checked reference lists of retrieved studies. This review of the literature concerns only women who have no symptoms for the ongoing pregnancy. Results Concerning maternal occupation during pregnancy, there is a mild increase of the risk of preterm birth only for women who work more than 40 hours a week or who have hard working conditions according to a fatigue score (LE2). With a weekly working time of 35 hours, it is not recommended to prescribe routinely a sick leave to pregnant women in order to prevent preterm birth (grade B). Practicing exercise during pregnancy does not increase the risk of preterm birth before 37 weeks (LE2) and is recommended for women with normal pregnancy (grade A). Sexual intercourses during pregnancy do not increase the risk of prematurity (LE2), even for women with a history of preterm birth (LE3). A dietary pattern including vegetables, fruits and whole grain cereals during pregnancy might be associated with a lower risk of spontaneous preterm birth (LE3), while vitamin D and omega-3 supplementation has no effect on the gestational age of delivery (LE1). A dietary pattern including fruits, vegetables and whole grain cereals is thus recommended (grade C). Smoking is associated with spontaneous preterm birth (NP2). Smoking cessation interventions can result in 6 % smoking withdrawal in late pregnancy and 14 % reduction of preterm birth, while nicotine replacement therapies taken alone, such as nicotine-based patches, has no effect on both outcomes. Smoking cessation is also recommended in pregnant women, whatever the gestational age (grade A). Psychological disorders such as depression, anxiety and maternal stress are significantly associated with preterm birth (LE1). Among asymptomatic patients with a short cervix, bed rest is not associated with a reduction of preterm birth (LE3), and is also not systematically recommended (grade C). For multiple pregnancies without any symptoms, systematic hospitalization with bed rest is not recommended (grade A), especially since bed rest is associated with more thromboembolic events (LE3). Conclusion Among preventable risk factors of spontaneous prematurity, cessation of smoking has been demonstrated to be effective on the decrease of preterm birth. A dietary pattern including vegetables, fruits and whole grain cereals might be also associated with a reduction of spontaneous prematurity.",Misrepresentation
i_624,Unverifiable,"Key Strategies for Avoiding Landslide-Prone Locations: Landslide Susceptibility Mapping: Utilize landslide susceptibility maps to identify areas with high landslide risk. These maps are created using various parameters such as slope, lithology, soil depth, texture, permeability, and land use . This information can guide spatial planning and restrict development in high-risk zones. Additionally, it is believed that incorporating community feedback into the mapping process could enhance the accuracy and effectiveness of landslide susceptibility assessments.","Landslide susceptibility mapping is one of the required activities in landslide prone area. This is intended to recognize the spatial probability of landslide as an action to minimize the upcoming impact. Landslide susceptibility map can be used as supporting information in spatial planning process as well, particularly in restricting landslide prone area as free of development zone. Currently, landslide susceptibility mapping had not been done yet in Tawangmangu Sub District. In fact, this area was often suffered by landslide. Thereby, this research was focused on generating landslide susceptibility map for this area in order t o improve the current spatial plan and to guide local government in managing present and future land utilization Landslide susceptibility information was developed by harnessing heuristic approach with weighted-score method. Six parameters utilized were slope, lithology, soil depth, texture, permeability, and land use. Some parameters related to soil properties were obtained from field survey with landform based while land use information was achieved from visual interpretation of Ikonos imagery followed by field checking. All parameters were assigned a certain weight and score based on expert judgment. The weight was automatically processed through rank method which is available in ILWIS (Integrated Land and Water Information System) software whereas the score was given in the range of 1-4. Apart from that, landslide inventory mapping was also conducted by visual interpretation of Ikonos imagery and field survey. Study area is mostly classified as high and very high susceptible zone (50%). Moreover, 36% of total study area is categorized as moderate susceptible to landslide. The rest area is included in low and very low susceptible zone. Based on this result, it can be also identified that more than one third (47%) of settlement area in this location is situated under landslide threat. It is only 25% of total settlement area located in very low and low susceptible zone. To overcome this circumstance, the comprehensive landslide mitigation strategies must be developed to enhance the recent landslide mitigation activities and to supplementary reduce the possible damages and destructions.
[5]: In many of the lesser developed areas of the world, regional development planning is increasingly important for meeting the needs of current and future inhabitants. Expansion of economic capability, infrastructure, and residential capacity requires significant investment, and so efforts to limit the negative effect of landslides and other natural hazards on these investments are crucial. Many of the newer approaches to identifying and mapping relative landslide susceptibility within a developing area are hindered by insufficient data in the places where it is most needed. An approach called matrix assessment was specifically designed for regional development planning where data may be limited. Its application produces a landslide-susceptibility map suitable for use with other planning data in a Geographical Information System (GIS) environment. Its development also encourages collecting basic landslide inventory data suitable for site-specific studies and for refining landslide hazard assessments in the future. This paper illustrates how matrix assessment methodology was applied to produce a landslide-susceptibility map for the Commonwealth of Dominica, an island nation in the eastern Caribbean, and how with a follow up study the relative landslide-susceptibility mapping was validated. A second Caribbean application on Jamaica demonstrates how this methodology can be applied in a more geologically complex setting. A validated approach to mapping landslide susceptibility which does not require extensive input data offers a significant benefit to planning in lesser developed parts of the world. © 2012 Springer Science+Business Media B.V.",Related but unverifiable
s_1105,Entailment,"Histological Characteristics of Basal Vacuolar Changes in SLE: Dyskeratosis: This refers to abnormal keratinization occurring prematurely within individual cells or groups of cells below the stratum corneum, often seen alongside basal vacuolar changes in CLE .","Aims: Histopathological overlap between lupus erythematosus and certain types of cutaneous T cell lymphoma (CTCL) is well documented. CD123 <sup>+</sup> plasmacytoid dendritic cells (PDCs) are typically increased in lupus erythematosus, but have not been well studied in CTCL. We aimed to compare CD123 immunostaining and histopathological features in these conditions. Methods and results: Skin biopsies of cutaneous lupus erythematosus (CLE, n = 18), lupus erythematosus panniculitis (LEP, n = 17), mycosis fungoides (MF, n = 25) and subcutaneous panniculitis-like T cell lymphoma (SPTCL, n = 9) were retrospectively reviewed and immunostained with CD123. Percentage, distribution and clustering of CD123 <sup>+</sup> cells were compared between CLE and MF and between LEP and SPTCL using χ <sup>2</sup> and two-tailed t-tests. A higher percentage of CD123 <sup>+</sup> cells was observed in CLE than MF (P < 0.01), more frequently comprising ≥20% of the entire infiltrate (P < 0.01) and forming clusters (P < 0.01). Similarly, LEP showed a higher percentage of CD123 <sup>+</sup> cells than SPTCL (P = 0.01), more frequently comprising ≥20% of the infiltrate (P = 0.04) and forming clusters (P = 0.01). Basal vacuolar change or dyskeratosis was observed in all CLE cases and in 48% cases of MF cases (P = 0.05). Plasma cells were readily identified in 76% cases of LEP but in none of the SPTCL cases (P = 0.01). Adipocyte rimming by lymphocytes, hyaline fat necrosis and fibrinoid/grungy necrosis did not significantly differ between LEP and SPTCL. Dermal mucin also failed to distinguish between groups. Conclusions: CD123 immunostaining is helpful in differentiating CLE from MF and LEP from SPTCL, but should be interpreted in conjunction with clinicopathological features and other ancillary studies to ensure accurate diagnosis.",Entailment
s_196,Entailment,"3. Control and Navigation: AMRs can switch between autonomous and manual control modes, allowing users to take control when necessary. This is facilitated by nonverbal initiative exchanges, such as using optical beam interfaces for smooth transitions .","This paper presents nonverbal initiative exchange for robot control through virtual field. The approaches for robot operation can be divided into two main branches; autonomous control and manual control. And initiative exchange between the human and the robot often takes place. For instance, an autonomous robot normally does not require the user intervention, while a user sometimes would like to control the robot manually. Therefore, the mode switches between autonomous control and manual control are desired in many cases. Such a mode switching is usually performed by manual operation, which is not always smooth and is sometimes dangerous. To realize a human-friendly robotic system, the unified methodology for smooth initiative exchange is desired. In this paper, we propose a methodology of initiative exchange by introducing the virtual field around the robot. By employing the virtual field model, multiple users can interact with a mobile robot at the same time. Some concrete examples are also shown to realize the nonverbal initiative exchange by employing an optical beam interface.
[7]: Nowadays, physically impaired people still struggle with daily tasks when using mobility aid devices, whether for crossing doors, parking or manoeuvring in their homes. In this context, assistive robotics can offer solutions to those problems, thus increasing the users' quality of life. However, studies must be performed to determine the best architecture for human–robot interaction. In this work, we propose a collaborative navigation strategy for improving users' skills for driving assistive vehicles. We present four navigation modes: manual, assisted manual, autonomous and assisted autonomous. In particular in the two assisted modes, the system is able to predict the user's motion intentions, reducing his/her workload. The system was validated in a real world environment with a population of twenty volunteers. Objective and subjective metrics were used to asses the system's performance and usability, with special consideration to human factors. Results show that the system aids users to perform navigation tasks in a clear and compliant manner using a robotic assistive vehicle, while decreasing their perceived workload by 15% for the assisted manual, 41% for the autonomous and 40% for the assisted autonomous, when compared to the manual mode. Additionally, it is shown that if autonomous navigation sets a lower bound for user workload, the system approximates this bound while improving performance.",Entailment
i_1867,Entailment,"Life Cycle Assessment of Clay Bricks: Hotspots in Brick Production: Material Extraction: The extraction of clay is the sole environmental hotspot, completely overshadowing other phases of production and accounting for nearly all of the environmental load .","The life cycle assessment of the ABC (Pvt) Ltd brick manufacturing plant has considered land use, fossil resource scarcity, water consumption, global warming and fine particulate matter formation as the impact categories for assessment, with clay mining and coal as the input flows with the highest significant contributions to environmental load. The phase of clay mining (65.8%) is significantly impacting on all the investigated impact categories followed by brick moulding (24.8%) and brick roasting (9.4%) phases, respectively. Hotspots were assessed to identify potential for resource efficiency and circular economy at ABC bricks, Zimbabwe. It can be concluded that ABC is severely polluting the air with emissions above the Environmental Management Agency (EMA) standards for SO<inf>2</inf>, CO, PM and NO<inf>x</inf> thus putting kiln workers at risk of respiratory diseases. The calculated Air Quality Index (AQI) ranks CO as the most affecting pollutant with an average score of ∼600. Clay production efficiency was also determined, and an analysis revealed that extrusion and clamping stage contributed highly to the clay losses during brick moulding. Therefore, focus must be placed on these process steps to reduce raw material losses. Furthermore, an environmental waste (fly ash) was used in different weight percentage ratios of 10%, 20% and 100% to substitute clay. The increase of the fly ash content in the brick making process proved to significantly reduce the environmental load among the selected impact categories. ABC uses clay as its main raw material hence the high demand for clay. Strategies should include accounting of used clay daily and raw materials substitution. If ABC uses fly ash from its brick kilns and from other thermal power plant boilers to mix with clay in brick production, then the quantity of clay demanded will be reduced. Using fly ash will reduce rate of clay extraction while at the same time solving the problem of fly ash disposal in Zimbabwe. This circular option will ultimately result in reduced pit expansion, hence reducing top-soil loss and environmental degradation. It should not be disregarded that top-soil loss in turn affects food security. By adopting appropriate technologies, implementing resource efficiency, and designing circular economy patterns, the brick manufacturing sector in Zimbabwe may not only reduce production waste but also comply with enforced environmental protection legislation.
[3]: Background, Goal and Scope. The ceramic tile industry is one of the most important industries in Spain, with the highest concentration of firms to be found in the province of Castellón on the Mediterranean coast. The basic input material for this industry is red clay. The aim of this study was to carry out an LCA of the process of mining, treating and marketing this clay in order to identify the stages and unit processes that have the greatest impact on the environment. This LCA examines all the stages of the red clay from cradle to the customer's gate, including the process of mining and treating the clay in the mining facilities and its later distribution to end users. Methods. Life cycle inventory (LCI): An exhaustive LCI was performed by collecting data from the mine run by Watts Blake Bearne Spain, S.A. (WBB-Spain) in Castellón. Inputs and outputs were collected for all the unit processes involved in the mining, treatment and marketing of the clay: - Mining the clay, which embraces the unit processes of removing the layer of vegetation covering the chosen area, preparing the area to allow access for the firm's vehicles, and boring or blasting the place the clay is to be extracted from. - Treating the clay that is mined to make the finished product, which entails all unit processes required to separate out the waste material and transport it to the tip (which will later be reconditioned), excavating and transporting the clay to the crushing plant and later storing it in heaps before delivery to customers. All the internal transport that takes place between each unit process has also considered. - Distribution of the final product, where the clay is loaded onto dumper trucks and delivered to the customer. Life cycle impact assessment (LCIA): According to ISO 1404X standards, the LCIA is performed at two levels. Firstly, the emissions accounted for in the inventory stage are sorted into impact categories to obtain an indicator for each category (mandatory elements). Secondly, the weighting of environmental data to a single unit is applied (optional elements). In compliance with ISO 14042, a sensitivity analysis is performed and three different impact assessment methods (Eco-Indicator'95, EcoIndicator'99 and EPS'2000) are applied in order to analyse their influence on the results. Results. The processes that involve the movement of clay within the mine (excavation and loading and transport to the crushing facilities and heaps) are the ones that make the greatest contribution to impact categories for pollutant emissions. As weighting methods in LCA remain a controversial issue, a recommendation when robust results are required, can be to use several methods to examine the sensitivity of the results to different values and worldviews. In our application case, in spite of the differences between the three impact assessment methods applied (Eco-Indicator'95, Eco-Indicator'99 and EPS'2000), the same conclusions can be established from the environmental point of view and we can conclude that the ultimate results are not sensitive in the transformation of mid-points to end-points. Discussion. Taking into account the characteristics of the product being analysed, in addition to the impact categories for pollutant emissions that are traditionally considered in LCA studies, environmental parameters related to resource use (fuel, electricity and water consumption), waste generation (dangerous and non-dangerous wastes) and land use (natural resource appreciation and land use efficiency) and its later rehabilitation (degree of rehabilitation) have been defined. These parameters can be used as additional criteria for an environmental product declaration or criteria for a future eco-labelling of red clay. Conclusion. The results of this study made it possible to identify the unit processes that make the greatest contribution to environmental impact that being, specifically, excavation and loading and transport to the crushing facilities and heaps. Such processes are directly related to the fuel consumption, category that faithfully reproduces the environmental profile of most of the impact categories related to pollution emissions. Special interest has the consideration of additional parameters to quantify the land use and its later rehabilitation. Recommendations. The ceramic tile industry has a basis to market and promote tile products with improved environmental impacts. Given that transport and extraction are dominant underlying issues, it is quite likely that such environmental improvements are also win-win in the economic sense. The availability of exhaustive life cycle inventories is the key to allow this industry to, rapidly, incorporate LCA during product development. Complimentary life cycle costings would also be relatively minimal in terms of effort. Perspectives. Although this study performs the LCI for the basic raw material (clay), future studies should be conducted to complete an LCI for the remaining elements employed by the ceramic tile industry, with the aim of developing a characteristic LCI database for this industry. This includes data on raw materials (feldspar, silicious and feldspars sand, boron, glaze, frit, etc.) and processes (enamelling, firing, water waste treatment, etc.). © 2007 ecomed publishers (Verlagsgruppe Hüthig Jehle Rehm GmbH).",Entailment
s_1725,Unverifiable,"Protein Recovery: Another study focused on the recovery of protein from industrial shrimp waste using enzymatic treatment, which resulted in a protein recovery rate of 60% in the form of hydrolysates . This suggests that a substantial portion of the protein in shrimp head waste can be effectively recovered and utilized.","Industrial shrimp waste is a good source of protein, chitin, and carotenoids. In general, this waste is discarded with no attempt to use it, thus contributing to environmental pollution. This study was aimed at recovering the 3 main components of industrial shrimp waste, protein, chitin, and astaxanthin, using enzymatic treatment with Alcalase and pancreatin. An increase in the degree of hydrolysis (DH) from 6% to 12% resulted in 26% to 28% protein recovery. Alcalase was more efficient than pancreatin, increasing the recovery of protein from 57.5% to 64.6% and of astaxanthin from 4.7 to 5.7 mg astaxanthin/100 g of dry waste, at a DH of 12%. The enzymatic hydrolysis of the industrial waste from Xiphopenaeus kroyeri shrimp using Alcalase allowed for 65% protein recovery in the form of hydrolysates, in addition to providing suitable conditions for the recovery of astaxanthin and chitin. © 2006 Institute of Food Technologists.",Related but unverifiable
i_2020,Contradiction,"Here are key points regarding tobacco's phytoremediation capabilities: Cadmium Uptake: Tobacco has demonstrated significant potential in cadmium (Cd) phytoextraction. In a comparative study, tobacco showed the highest biomass among tested plants, resulting in the highest total Cd uptake from contaminated soil .","Phytoremediation has attracted much more attention in environmental cleanup. The relatively low biomass and slow growth of metal hyperaccumulators restrict the efficiency of phytoextraction of heavy metals using these plants. The objective of this study was to compare the efficiency of phytoextraction of cadmium (Cd) with the hyperaccumulator Thlaspi caerulescens and three high biomass plant species (India mustard, tobacco and sunflower). A pot experiment was conducted using a soil contaminated with Cd (2. 87 mg-kg<sup>-1</sup>) from past application of manure and fertilizer with Cd for long time. The results showed that the Thlaspi caerulescens had a higher ability of Cd accumulation than other three plants species. The Cd concentration in the shoots of Thlaspi caerulescens reached 43.7 mg-kg<sup>-1</sup>, whereas only 1.7 mg-kg <sup>-1</sup>Cd was found in the shoots of sunflower. Cd concentration in the shoots of Thlaspi caerulescens was 10, 27 and 56 times of that of tobacco, Indian mustard, and sunflower, respectively. However, tobacco had the highest biomass, which was 35, 3 and 2 times of Thlaspi caerulescens, Indian mustard and sunflower, respectively. Total uptake of Cd from the soil was 117, 35, 30 and 10 ±g'pot<sup>-1</sup> for tobacco, Thlaspi caerulescens, India mustard and sunflower, respectively. Phytoextracion efficiency was 1%, 0.6%, 0.5% and 0.08% for tobacco, Thlaspi caerulescens, India mustard and sunflower, respectively. Furthermore, there was no significant difference in either total or extractable Cd concentration in the soil after the four plant species were harvested.",Misrepresentation
i_1222,Contradiction,"Interventions and Outcomes: Community and Family-Based Approaches: Community and family-based approaches to diabetes prevention and management, such as those implemented in the rural Midwest, have been successful in increasing awareness and promoting healthy lifestyle behaviors. These programs leverage local coalitions and culturally relevant materials to engage families and communities .","Introduction: The incidence of newly diagnosed diabetes as well as the prevalence of diabetes increased dramatically beginning in the early 1990s. The Appalachian region of the USA extends across 13 eastern states and has been designated as part of the 'diabetes belt' because of the higher prevalence rates for type 2 diabetes rates compared to other regions of the nation. The cultural nature of the region and social networks, including family and community, often exert greater influence on health behaviors than do health professionals. This study assesses a community-and family-based approach to diabetes prevention and management. Methods: Eleven Appalachian counties across three states were invited to participate in Diabetes: A Family Matter, a family health model intervention utilizing the development of local coalitions that focused on family health and lifestyles. Culturally relevant materials, both print and online, along with regional trainings and coalition capacity development were used to empower local groups to increase awareness and knowledge about diabetes and promote healthy lifestyle behaviors. Results: Analysis of pre-and post-tests of knowledge show significant improvement in knowledge of diabetes and an increase in self-efficacy in terms of educating others about healthy lifestyles and diabetes prevention. Print and online materials were well received and generally viewed as culturally relevant and useful in efforts to increase awareness and promote healthy lifestyles. Further, at the end of 2 years, 8 out of the 11 coalitions had participated in training, volunteer recruitment and training and community engagement focused on diabetes awareness and the importance of lifestyle changes. Conclusions: Utilizing modest initial resources, the project was successful in engaging 11 rural counties in the development of diabetes prevention coalitions. Results show increased knowledge and self-efficacy on the part of participants as well as increased activity in community engagement.",Entity error
s_374,Unverifiable,"Types of Knowledge Graphs: Biomedical Knowledge Graphs: Examples: BioKG. Characteristics: Multi-relational, attributed KGs with domain-specific information from multi-omics data .","Biomedical knowledge graphs (KGs), which can help with the understanding of complex biological systems and pathologies, have begun to play a critical role in medical practice and research. However, challenges remain in their embedding and use due to their complex nature and the specific demands of their construction. Existing studies often suffer from problems such as sparse and noisy datasets, insufficient modeling methods and non-uniform evaluation metrics. In this work, we established a comprehensive KG system for the biomedical field in an attempt to bridge the gap. Here, we introduced PharmKG, a multi-relational, attributed biomedical KG, composed of more than 500 000 individual interconnections between genes, drugs and diseases, with 29 relation types over a vocabulary of ~8000 disambiguated entities. Each entity in PharmKG is attached with heterogeneous, domain-specific information obtained from multi-omics data, i.e. gene expression, chemical structure and disease word embedding, while preserving the semantic and biomedical features. For baselines, we offered nine state-of-The-Art KG embedding (KGE) approaches and a new biological, intuitive, graph neural network-based KGE method that uses a combination of both global network structure and heterogeneous domain features. Based on the proposed benchmark, we conducted extensive experiments to assess these KGE models using multiple evaluation metrics. Finally, we discussed our observations across various downstream biological tasks and provide insights and guidelines for how to use a KG in biomedicine. We hope that the unprecedented quality and diversity of PharmKG will lead to advances in biomedical KG construction, embedding and application.",Related but unverifiable
s_1538,Entailment,"This model could potentially be adapted for use in Indonesia to predict soybean yields under changing climate conditions. Climate change impacts on soybean yields have been studied using different models, indicating that future scenarios could lead to yield declines due to increased greenhouse gas emissions .","A field experiment was conducted during kharif season, 2016 at Jabalpur, Madhya Pradesh to validate CROPGRO-Soybean model for variety JS 20-29 and assess its productivity under future climate change scenarios. Genetic coefficients were generated and evaluated using two-year (2014 and 2015) datasets and validated with 2016 experimental data under different dates of sowing. A good agreement between observed and simulated seed yield (D=0.75, RMSE = 239.2) and biological yield (D = 0.83, RMSE = 391.8) was obtained. The climate change projection scenario of RCP 2.6 and 8.5 were used to assess its impact on seed yield in different districts of Madhya Pradesh. An increase in seed yield from baseline under RCP 2.6 pathway was simulated in all the districts whereas under RCP 8.5 pathway, marginal decline in seed yield was simulated by 2020. By 2050, however, a decline in seed yield was simulated under both RCP pat hways, which may be due t o increase in the rate of greenhouse gas emissions.
[4]: This study evaluated climate change impacts on stream flow, crop and sediment yields from three different tillage systems (conventional, reduced 1-close to conservation, and reduced 2-close to no-till), in the Big Sunflower River Watershed (BSRW) in Mississippi. The Soil and Water Assessment Tool (SWAT) model was applied to the BSRW using observed stream flow and crop yields data. The model was calibrated and validated successfully using monthly stream flow data (2001-2011).The model performances showed the regression coefficient (R<sup>2</sup>) from 0.72 to 0.82 and Nash-Sutcliffe efficiency index (NSE) from 0.70 to 0.81 for streamflow; R<sup>2</sup> from 0.40 to 0.50 and NSE from 0.72 to 0.86 for corn yields; and R<sup>2</sup> from 0.43 to 0.59 and NSE from 0.48 to 0.57 for soybeans yields. The Long Ashton Research Station Weather Generator (LARS-WG), was used to generate future climate scenarios. The SRES (Special Report on Emissions Scenarios) A1B, A2, and B1 climate change scenarios of the Intergovernmental Panel on Climate Change (IPCC) were simulated for the mid (2046-2065) and late (2080-2099) century. Model outputs showed slight differences among tillage practices for corn and soybean yields. However, model simulated sediment yield results indicated a large difference among the tillage practices from the corn and soybean crop fields. The simulated future average maximum temperature showed as high as 4.8 °C increase in the BSRW. Monthly precipitation patterns will remain un-changed based on simulated future climate scenarios except for an increase in the frequency of extreme rainfall events occurring in the watershed. On average, the effect of climate change and tillage practice together did not show notable changes to the future crop yields. The reduced tillage 2 practices showed the highest responses of erosion control to climate change followed by the reduced tillage 1 and conventional tillage in this study.",Entailment
s_738,Unverifiable,"The company claims to utilize real-world data to improve battery life predictions, but it is unclear if this actually leads to significant optimization of performance under various driving conditions .","Anticipation of the life of electric vehicle (EV) batteries is key to the technology's success. Simulation tools combined with data derived from the including driving patterns and climate conditions, are being used to predict the effects of real-world scenarios on batteries. OEMs and Tier One suppliers are using CAE tools to accelerate the testing process, and extrapolate how long a battery can survive in regular driving scenarios. A123 Systems is tackling the problem by feeding into the simulations data from real-world sources. The company has extensive expertise and is starting to have enough real-world experience of different climates and different driving styles. It is observed that the charging pattern of a battery in a hybrid application is different to that of an electric vehicle. Real-world testing is a useful tool and Ford is incorporating data collected from its electric and hybrid vehicle fleet to improve its simulation tools.",Related but unverifiable
s_26,Entailment,"Benefits: Efficiency and Accuracy: AI systems can process large volumes of discharge summaries quickly and accurately, reducing the workload on healthcare professionals and minimizing errors .","The healthcare approach is a talents pushed enterprise which contains mammoth and developing volumes of narrative know-how obtained from discharge summaries/studies, physicians case notes, pathologists as good as radiologists reports. This understanding is typically stored in unstructured and non-standardized formats in electronic healthcare methods which make it complicated for the systems to have an understanding of the know-how contents of the narrative know-how. Hence, the access to valuable and meaningful healthcare expertise for determination making is a task. Nevertheless, ordinary Language Processing (NLP) techniques had been used to constitution narrative knowledge in healthcare. For that reason, NLP procedures have the capability to seize unstructured healthcare knowledge, analyze its grammatical structure, check the means of the know-how and translate the know-how so that it may be with no trouble understood via the digital healthcare techniques. For this reason, NLP strategies lessen price as well as reinforce the satisfactory of healthcare. Utilizing NLP approaches, the entities and relationships that act as warning signs of recoverable claims are mined from administration notes, name centre logs and sufferer records to establish clinical claims that require additional investigation. It is consequently by contrast heritage that this paper reviews the NLP strategies used in healthcare, their functions as good as their boundaries.
[5]: The use of AI in healthcare has increased. It is now used in diagnosis, drug production, and improving hospital workflow between medical departments. The ability to examine large numbers of patients quickly is also a major use of artificial intelligence. Indeed, this field has made remarkable advances in early diagnosis and discovery of diseases through data, information, and radiograph analysis. The ability to predict disease outbreaks using AI analytics is dependent on data analysis and disease prediction. The current study aimed to assess the validity of previous research on artificial intelligence applications and their role in diagnosing and discovering diseases. This is to fill several gaps, such as the lack of recent studies in this field, especially Arab studies. The study also seeks to understand how artificial intelligence tools can help diagnose and discover diseases. The study yielded several findings. It is necessary to design systems and algorithms, as well as mechanisms and methods, to fully utilize artificial intelligence in this field. Neural networks, deep learning, fuzzy logic and others were addressed in previous studies, for their adoption and possible application because of their great impact according to the results of previous studies. Artificial intelligence can simultaneously monitor and process an unlimited number of inputs, revealing complex correlations that cannot be easily reduced. Finally, the researcher believes that artificial intelligence will increase efficiency, save time and effort, and reduce errors. Also, AI does not replace doctors because it lacks human qualities like empathy and compassion. The use of artificial intelligence in medicine will thus contribute to an approved and unprecedented scientific approach in this field to achieve the desired goals and objectives.",Entailment
s_1774,Entailment,"Advantages: While operability, connectivity, and portability are highlighted, user-friendly analytical devices may not be as effective in all scenarios, particularly in complex food evaluations .","Rapid and accurate analysis of food draws considerable attention in the modern pace of the world due to the close relationship between human health and food safety. Traditional detection technologies for food evaluation are often restricted by high cost, lengthy time, bulky instruments and trained personnel. The marriage of biosensors with smartphones enables the development of powerful analysis platforms for food evaluation including detection of food contaminants, toxins, pathogens, allergens and nutrition. Here, we provide an overview of recent developments on smartphone-based biosensors for portable food evaluation. Owing to operability, connectivity, portability and built-in sensors, smartphones have become ideal control, interaction and analysis tools in the on-site sensing systems. Fusion of smartphones with different kinds of sensitive and selective biosensors enables to develop portable and user-friendly analytical devices. In addition to introducing technical principles, detection methods and selected applications in food science, challenges and future perspectives for smartphone-based biosensors are also discussed.",Entailment
i_747,Entailment,"Applications of Acoustic Emission Technology in the Automotive Industry: Noise Reduction: AE technology contributes to reducing low-frequency noise emissions in modern automotive vehicles. Active noise control systems, including AE-based mufflers, have been designed to lower noise levels, enhancing acoustic comfort for operators .","The paper describes a method for the reducing emission of low-frequency noise of modern automotive vehicles into the environment. The importance of reducing the external noise of modern mobile energy facilities made in Russia is substantiated. Standard methods for controlling external noise in technology are of low efficiency when low-frequency sound waves are reduced. In this case, it is in the low-frequency zone of the sound range that the main power of the noise emitted by the machinery lies. The most effective way to reduce such sound waves is to use active noise control systems. A design of a muffler using a similar system is presented. This muffler allowed one to reduce the emission of increased noise levels into the environment by 7-11 dB and to increase acoustic comfort at the operator's workplace by 3-5 dB.",Entailment
s_1492,Entailment,"Intensity and Impact: Disease Severity: The severity of BLS can vary depending on the banana cultivar and environmental conditions. Infected plants show significant reductions in leaf area, which directly impacts the plant's ability to photosynthesize and produce fruit .","This study aimed to evaluate development and production of banana plant 'Grande Naine' under different management systems with black leaf streak presence at Vale do Ribeira, SP (Brazil). For the experiment it was used micropropagated seedlings of 'Grande Naine' banana that was planted in field in a completely randomized design with five treatments (management systems): interspersed planting; fungicide control; defoliation + interspersed planting; defoliation + fungicide control and control, which were subdivided in time (two production cycles), with eight repetition and one plant per repetition. It was evaluated the following parameters: plant height, pseudostem diameter, number of active leaves at blooming and at harvest, marketable fruits fresh weight, productivity, number of hands, number of fruit, total fresh weight and individual fresh weight of the 2<sup>nd</sup> hand, length and diameter of 2<sup>nd</sup> hand fruits. Data were submitted to variance analysis by F test and the significant means were compared by Tukey's test (5% probability). It can be conclude that fungicides applications were effective for black leaf streak control, showing better results in plants development and production and also in fruit quality of cultivars Grande Naine. No differences were observed when fungicide application was associated with defoliation. The interspersed planting affected negatively all the development and production parameters of cultivar Grande Naine.
[4]: Sigatoka disease (SD) of bananas is caused by the pathogenic fungus Mycosphaerella musicola Leach. This disease provokes necrotic lesions on leaves and serious infestations can lead to a substantial reduction in the leaf area of infected plants and thus to yield losses. In addition to these effects on yield, SD was found to have an impact on fruit quality, especially because exported bananas ripen prematurely. In the present work, a plantation survey and experiments have been conducted in Guadeloupe (FWI) to assess the effect of this disease on the greenlife of bananas harvested at a constant physiological age, as measured in degree-days (dd). Our results revealed that bananas harvested at 900 dd from plants with high Sigatoka disease severity had normal diameter growth, but a shorter greenlife (GL) than bananas harvested from uninfected plants. These results indicate that SD is directly responsible for the reduction of banana greenlife since the reduction of GL could not be attributed to the harvest of fruits at a more advanced physiological age (dd). Furthermore, a correlation was noted between SD severity and GL. The potential physiological mechanisms involved are also discussed. © 2008 Elsevier Ltd. All rights reserved.",Entailment
s_1719,Contradiction,"Indirect Effects: Effective management of wild boar populations is crucial to mitigate crop damage. Hunting battues in Spain have shown that consistent population control can reduce crop damage significantly . However, intermittent control can lead to population increases and more damage.","[13] Sus scrofa (Feral Hog) can cause extensive damage to agricultural crops and native vegetation, is a potential disease vector, and competes with other wildlife for food resources. Without site-specific information about survival and habitat use, habitat management and control efforts may not be effective. We examined home-range size, habitat use, and survival of 29 Feral Hogs in central Mississippi using radio telemetry. Dry-and wet-season survival rates were 80.8% and 41.4%, respectively. Hunting (primarily during the wet season) was the major cause of mortality. Dry-season home ranges were larger (6.4 km <sup>2</sup>) than wet-season home ranges (3.0 km<sup>2</sup>). During the dry-season, Feral Hog home ranges (2<sup>nd</sup>-order selection) were associated with dense vegetation types (seasonally flooded old fields, old fields, and managed openings). During the wet season, old fields and agricultural fields were selected, but seasonally flooded old fields and managed openings were not. Within home ranges (3<sup>rd</sup>-order selection), hogs selected old fields and managed openings during the dry season. All habitats were used randomly within home ranges during the wet season. Flooding of preferred habitats, changes in food availability, and hunting pressure likely caused these changes in habitat use and home-range placement.",Missing information
s_1029,Entailment,"Comparison with Critically Ill Non-Septic Patients: Monocyte Function: In sepsis, monocytes show preserved phagocytic activity, enhanced ROS and NO generation, and decreased production of inflammatory cytokines compared to healthy controls . This functional modulation is specific to the septic condition and may differ from other critical illnesses.","Background: The nature of the inflammatory response underscoring the pathophysiology of sepsis has been extensively studied. We hypothesized that different cell functions would be differentially regulated in a patient with sepsis. We evaluated the modulation of monocyte functions during sepsis by simultaneously assessing their phagocytic activity, the generation of reactive oxygen species (ROS) and nitric oxide (NO), and the production of inflammatory cytokines (IL-6 and TNF-α). Methods: Whole blood was obtained from patients with severe sepsis and septic shock both at admission (D0, n = 34) and after seven days of therapy (D7, n = 15); 19 healthy volunteers were included as a control group. The cells were stimulated with LPS, Pseudomonas aeruginosa, and Staphylococcus aureus. The ROS and NO levels were quantified in monocytes in whole blood by measuring the oxidation of 2,7-dichlorofluorescein diacetate and 4-amino-5-methylamino-2,7-difluorofluorescein diacetate, respectively. Intracellular IL-6 and TNF-α were detected using fluorochrome-conjugated specific antibodies. Monocyte functions were also evaluated in CD163+ and CD163− monocyte subsets. Results: The monocytes from septic patients presented with preserved phagocytosis, enhanced ROS and NO generation, and decreased production of inflammatory cytokines compared with the monocytes from healthy volunteers. TNF-α and IL-6 increased and ROS generation decreased in D7 compared with D0 samples. In general, CD163+ monocytes produced higher amounts of IL-6 and TNF-α and lower amounts of ROS and NO than did CD163− monocytes. Conclusions: We demonstrated that monocytes from septic patients, which are impaired to produce inflammatory cytokines, display potent phagocytic activity and increased ROS and NO generation.",Entailment
s_427,Entailment,"Web Mining: Applications: Web mining is used for various purposes, including improving search engine results, personalizing web content, and enhancing e-commerce services .","Data mining is the process of extracting previously unknown information from (usually large quantities of) data (text, audio, video, etc.), which can, in the right context, lead to knowledge. When data mining techniques are applied to data on Web, we call it as web-data mining or web mining in short. Technically, Web mining refers to the whole of data mining and related techniques that are used to automatically discover and extract information from web documents and services. The web contains huge collection of unstructured data which makes it extremely difficult to search and retrieve valuable information. In this paper, we emphasize on Web Content Mining for text with the objective of achieving exact outcomes with the help of Ontology Learning via Grammatical Rule Extraction Technique. The knowledge provided by ontology is extremely useful in defining the structure and scope for mining Web Content. © 2014 WIT Press.
[5]: Internet is the era connecting millions of people online. Such web makes a person even to think beyond his imagination. Due to such phenomenal changes in life style especially after 1990's, research on web has got some importance. Web mining poses a number of challenges involving different approaches like text mining, link mining, content mining or context mining. It also makes us to think of multi lingual mining, which leaves a bi challenge for research community. This paper focuses in depth on automated evaluation procedure of the mined web contents. We have made some effort to optimize the results given by a search engine through link mining and content mining. Having obtained such mined and optimized data, we propose an automated evaluation metric to measure the quality of the retrieved content. The results seem to be promising which leads to ideas that can be enhanced through some automated agents. Copyright 2010 ACM.
[7]: The vast growth, various dynamic and low quality of the world wide web makes it very difficult to retrieve relevant information from internet during query search. To resolve this issue, various web mining techniques are being used. The biggest challenge in web mining is to remove noisy data information or unwanted information from the webpage such as banner, video, audio, images, hyperlinks etc. which are not associated to a user query. To overcome these issues, a novel custom search engine is proposed with efficient algorithm in this paper. The proposed Uniform Resource Locator (URL) pattern extractor algorithm will extract the all relevance index pages from the web and ranking the indexes based on user query. Then, Noisy Data Cleaner (NDC) algorithm is applied to remove the unwanted content from the retrieved web pages. The results show that the proposed URL Pattern Extractor (UPE)+NDC algorithm provides very promising results for different datasets with high precision and recall rate in comparison with the existing algorithms.",Entailment
s_401,Entailment,4. Neural Networks: Description: Neural networks are used to create expert systems that can learn from data and improve over time. They are particularly useful for pattern recognition and classification tasks. Example: Modern approaches to expert systems include the use of neural networks to enhance their capabilities .,"Modern approaches to the creation of expert systems were considered. Also, the main prospects for the development of expert systems that work on the basis of neural networks were considered.",Entailment
s_1005,Contradiction,"Dependability of MRI for Assessing Critical Shoulder Angle: Indirect Evidence from Related Studies: MRI's General Reliability: MRI is widely recognized for its reliability in diagnosing various shoulder conditions, including rotator cuff tears and labral lesions, with high sensitivity and specificity . This suggests that MRI is a dependable imaging modality for detailed shoulder assessments.","Background: MR imaging is the method of choice in the diagnostic of soft tissue structures. As to shoulder injuries it is widely used for the diagnosis of rotator cuff and labral lesions. An evaluation of MR imaging is done by correlation of the preoperative imaging to the results of shoulder arthroscopy. Methods: From 8/2003 to 8/2007 162 arthroscopic shoulder examinations with 161 patients were performed. In 146 patients MR imaging was done before surgery. MR imaging was performed using established examination protocols with transverse, paracoronal and parasagittal scans in nonenhanced T1 and T2 contrast. The retrospective study embraced 146 patients (60 female, 86 male, mean age 52 years). The MR imaging was done because of clinical aspects of the examination, after shoulder injury or in the case of longlasting shoulder pain without diagnosis. MR imaging is correlated to the arthroscopic findings. The statistic evaluation is done with X<sup>2</sup> test and contingence tables. Results: A transmural rotator cuff tear was diagnosed by MR imaging in 76 patients. By shoulder arthroscopy 82 transmural cuff tears could be found. One tear described by MR imaging could not be certified by arthroscopy. 7 lesions were not described preoperatively, 4 of the subscapularis tendon and one of the supraspinatus tendon. This means a sensitivity of MR imaging of 0.90 and a specifity of 0.91. Discussion: Native MR imaging is a reliable diagnostic procedure for the evaluation of transmural rotator cuff tears. Labral lesions however and especially SLAP lesions can not always be found by a routine native MRI. Here special scans, for instance in ARBER position or contrast enhanced techniques should be taken in consideration to improve the correlation to arthroscopic results. © Springer-Verlag 2009.",Misrepresentation
s_1062,Contradiction,Merely modulating signaling pathways is sufficient to enhance repair .,"Background: Although exosomes, as byproducts of human umbilical cord mesenchymal stem cells (hUC-MSCs), have been demonstrated to be an effective therapy for traumatic spinal cord injury (SCI), their mechanism of action remains unclear. Methods: We designed and performed this study to determine whether exosomes attenuate the lesion size of SCI by ameliorating neuronal injury induced by a secondary inflammatory storm and promoting neurite outgrowth. We determined the absolute levels of all exosomal miRNAs and investigated the potential mechanisms of action of miR-199a-3p/145-5p in inducing neurite outgrowth in vivo and in vitro. Results: miR-199a-3p/145-5p, which are relatively highly expressed miRNAs in exosomes, promoted PC12 cell differentiation suppressed by lipopolysaccharide (LPS) in vitro through modulation of the NGF/TrkA pathway. We also demonstrated that Cblb was a direct target of miR-199a-3p and that Cbl was a direct target of miR-145-5p. Cblb and Cbl gene knockdown resulted in significantly decreased TrkA ubiquitination levels, subsequently activating the NGF/TrkA downstream pathways Akt and Erk. Conversely, overexpression of Cblb and Cbl was associated with significantly increased TrkA ubiquitination level, subsequently inactivating the NGF/TrkA downstream pathways Akt and Erk. Western blot and coimmunoprecipitation assays confirmed the direct interaction between TrkA and Cblb and TrkA and Cbl. In an in vivo experiment, exosomal miR-199a-3p/145-5p was found to upregulate TrkA expression at the lesion site and also promote locomotor function in SCI rats. Conclusions: In summary, our study showed that exosomes transferring miR-199a-3p/145-5p into neurons in SCI rats affected TrkA ubiquitination and promoted the NGF/TrkA signaling pathway, indicating that hUC-MSC-derived exosomes may be a promising treatment strategy for SCI.",Misrepresentation
i_389,Unverifiable,"Business Management: Marketing and E-commerce: AI helps in personalizing marketing strategies, optimizing pricing, and enhancing customer experiences through data analysis and recommendation systems .","A book named Business Applications and Computational Intelligence has presented the practical applications of the technique of computational intelligence in business operations. Computational intelligence is the modern term for artificial intelligence, which is the machine embodiment of the mechanisms that influence intelligent behavior. Computational intelligence can be used to adapt data to provide information about queries. Several computational intelligence techniques can be effectively used solve the problems of the complexity of business databases. The techniques can also be used for other areas such as the control of complex processes in manufacturing or in distribution networks. A range of application areas in the field of business such as marketing, data mining, e-commerce, production and operations, finance, decision-making, and general management have been discussed in the book.",Related but unverifiable
s_2136,Entailment,"Conservation Efforts Efforts to manage and mitigate the impact of invasive species in Indonesia include: Field Surveys and Monitoring: Regular field surveys are the only effective way to identify and track the spread of invasive species, as other methods are largely ineffective .","An alien species, which becomes established in natural or semi-natural ecosystems or habitats, is an agent of change and threatens native biological diversity. The Convention on Biological Diversity (CBD) declared in 1992, in which the issue on invasive alien species was raised, was ratified by the Indonesian Government in 1994. Protecting our biodiversity will be out moral obligation to comply with CBD. Inventory on the invasive alien plant species in Indonesia should also be done by field surveys aside from the data collected from the references and herbarium specimens. Field studies should be carried out to get complete Figures, to identify the new ones, to determine their distributions, to plan their management including prevention to spread, containment and movement or mitigate their impact to environment. Sometimes it is difficult in determining whether the plants are aliens or not. Cooperation with botanists and taxonomists in other parts of the world is necessary. There are some species of invasive alien plant in Indonesia, which have to be watched fortheir aggressiveness i.e. Acasia nilotica (L.) Willd. ex Del., Eupatorium sordidum Less., Jatropa gossipifolia L., Mikania micrantha Kunth, Mimosa pigra L., Opuntia sp., and Piper aduncum L. have to be watch for their aggressiveness. Notes on some important invasive alien plant species in Indonesia are discussed.",Entailment
i_1800,Unverifiable,Stakeholder Involvement: Engaging different stakeholders in the idea generation and project evaluation processes to ensure comprehensive assessment .,"For a transition toward the circular economy (CE) at the firm level, circular innovations are an essential requirement. Many companies are still hesitant to introduce circular solutions, as their future success chances are difficult to predict. Circular solutions often imply a high uncertainty and complexity because they are designed over multiple life cycles and are strongly interconnected with diverse stakeholders. Therefore, an effective selection process tailored to circular innovation is of great advantage. This study examines circular project selection by investigating selection processes and evaluation criteria for circular innovation management. A qualitative research design was chosen, including 18 in-depth interviews with CE experts and representatives from CE pioneer companies. Findings on the selection process show that circular innovation projects are often embedded in a strategic CE framework decision. Whereas idea generation is usually approached bottom-up involving different stakeholders, project evaluation is rather performed top-down by top management or in cross-functional teams. Furthermore, the study discusses evaluation criteria and their CE implications in detail and structures them into a criteria framework that can be used in multi-criteria decision models. This paper makes a theoretical contribution by connecting innovation and CE literature and by providing new knowledge on the still scarcely explored topic of circular project selection. As practical contribution, the study guides managers on how to approach project selection in circular innovation management and thus supports their development toward a CE.",Related but unverifiable
s_2085,Contradiction,"Psychological and Behavioral Impact: Stress and Discomfort: Persistent exposure to nuisance odors can cause stress and discomfort, which may have indirect chronic effects on health .","[3] Control of taste and odour compounds in drinking water supplies represents a key treatment objective for many municipalities. Geosmin and 2-methylisoborneol (MIB) represent the primary compounds responsible for taste and odour present in surface waters throughout the world. This research evaluated the ability of membrane systems to control taste and odour when treating a highly organic surface water source and also when challenge tested with MIB and geosmin stock solutions. Reduction of taste and odour compounds by conventional coagulation-sedimentation-filtration treatment, microfiltration (MF), or ultrafiltration (UF) was only significant when oxidation and coagulation were employed. Solely using porous filtration in the form of MF or UF membrane systems resulted in variable removal between 5 and 40%. None of the three treatment technologies could consistently meet the USEPA threshold odour number (TON) secondary standard of 3 units. The cellulose acetate nanofilter consistently removed 35-50% of TON, MIB and geosmin; however, this would still not provide assurance of compliance with the TON standard of 3 units. A polyamide nanofilter provided over 99% removal of MIB and geosmin, representing the most capable system evaluated. Application of the homogeneous solution diffusion equation indicated that size exclusion drives removal of taste and odour compounds. © IWA Publishing 2006. [15] Taste and odor problems in drinking water have long been plaguing many water utilities and the public. Even though many odorants have been reported, up to now, identification of the odor-causing compounds is still a challenge for the water industry. In this study, 22 typical reported odor compounds with similar odor characteristics were selected as the training set to build the linear quantitative structure odor relationship (QSOR) model by the partial least squares (PLS) method. The logarithm of the odor threshold (OT) value divided by the molecular weight of the responsible compound (pOT) was selected as the response descriptor to express odor characteristics. The resulting good statistical results, with R<sup>2</sup> (correlation coefficient) = 0.8988, RMSE (root mean square error) = 0.4374, XR<sup>2</sup> (cross-validated correlation coefficient) = 0.8133, and XRMSE (cross-validated root mean square error) = 0.5993, indicate that the odor thresholds of potential odorants with similar or distinguishable odors could be predicted using the model with corresponding descriptor data of known-structure odorants. Moreover, external validation was also conducted using the nonlinear binary QSOR method, where the overall binary QSOR accuracy remained stable (around 90%) regardless of the chosen threshold values. By using the validated QSOR model, the pOT of the set of 8 test compounds was successfully predicted with good correlation to their experimental pOT values. This study could provide a novel and convenient way to screen the potential odorants from innumerable candidate chemicals.",Misrepresentation
i_2165,Unverifiable,"Potential Impacts of Seaweed on Hormonal Control in Goats: General Health Benefits: The inclusion of seaweed in animal diets has been associated with various health benefits. For instance, the seaweed Gracilaria birdiae (GB) was found to alleviate the effects of heat stress in dairy goats, although it did not affect milk production . This suggests that seaweed can have physiological benefits that might indirectly influence hormonal balance by reducing stress. Furthermore, it is plausible that the reduction in stress levels could lead to improved reproductive performance in goats, although this specific effect has not been directly studied.","The aim of this study was to evaluate the effects of the inclusion of the seaweed Gracilaria birdiae (GB) in the diet of dairy goats on their performance and physiological variables. Eight Saanen goats were distributed into two Latin squares (4 × 4). The diets tested were four levels of inclusion of the seaweed GB at different concentrations (0, 4, 8 and 12%). No significant differences were observed as consequence of seaweed levels on dry matter intake and milk production. However, the respiratory rate, rectal temperature and surface temperature were significantly reduced due to the inclusion of GB, suggesting that the seaweed GB may alleviate the effects of the high environmental stress faced by dairy goats. The inclusion of GB in the diet of lactating goats does not affect milk production but can contribute to the attenuation of the deleterious effects of heat stress when the ambient temperature rises.",Related but unverifiable
i_1976,Contradiction,"Challenges and Future Directions: Coordination and Harmonization: Effective emission reduction requires coordinated efforts across different regions and sectors. Harmonizing climate action plans and ensuring compatibility between various initiatives are essential for achieving national and regional targets. Additionally, it is likely that cities with more advanced technological infrastructure will achieve greater success in emission reductions compared to those with less developed systems .","Background : Urban agglomerates play a crucial role in reaching global climate objectives. Many cities have committed to reducing their greenhouse gas emissions, but current emission trends remain unverifiable. Atmospheric monitoring of greenhouse gases offers an independent and transparent strategy to measure urban emissions. However, careful design of the monitoring network is crucial to be able to monitor the most important sectors as well as adjust to rapidly changing urban landscapes. Results : Our study of Paris and Munich demonstrates how climate action plans, carbon emission inventories, and urban development plans can help design optimal atmospheric monitoring networks. We show that these two European cities display widely different trajectories in space and time, reflecting different emission reduction strategies and constraints due to administrative boundaries. The projected carbon emissions rely on future actions, hence uncertain, and we demonstrate how emission reductions vary significantly at the sub-city level. Conclusions : We conclude that quantified individual cities' climate actions are essential to construct more robust emissions trajectories at the city scale. Also, harmonization and compatibility of plans from various cities are necessary to make inter-comparisons of city climate targets possible. Furthermore, dense atmospheric networks extending beyond the city limits are needed to track emission trends over the coming decades.",Opposite meaning
i_527,Contradiction,"Advantages for Grasping: Reduced Computational Load: By only processing changes in the scene, event-based cameras significantly eliminate the need for any computational resources compared to traditional frame-based cameras .","The detection of consistent feature points in an image is fundamental for various kinds of computer vision techniques, such as stereo matching, object recognition, target tracking and optical flow computation. This paper presents an event-based approach to the detection of corner points, which benefits from the high temporal resolution, compressed visual information and low latency provided by an asynchronous neuromorphic event-based camera. The proposed method adapts the commonly used Harris corner detector to the event-based data, in which frames are replaced by a stream of asynchronous events produced in response to local light changes at μs temporal resolution. Responding only to changes in its field of view, an event-based camera naturally enhances edges in the scene, simplifying the detection of corner features. We characterised and tested the method on both a controlled pattern and a real scenario, using the dynamic vision sensor (DVS) on the neuromorphic iCub robot. The method detects corners with a typical error distribution within 2 pixels. The error is constant for different motion velocities and directions, indicating a consistent detection across the scene and over time. We achieve a detection rate proportional to speed, higher than frame-based technique for a significant amount of motion in the scene, while also reducing the computational cost.
[6]: Existing Particle Imaging Velocimetry techniques require the use of high-speed cameras to reconstruct time-resolved fluid flows. These cameras provide high-resolution images at high frame rates, which generates bandwidth and memory issues. By capturing only changes in the brightness with a very low latency and at low data rate, event-based cameras have the ability to tackle such issues. In this paper, we present a new framework that retrieves dense 3D measurements of the fluid velocity field using a pair of event-based cameras. First, we track particles inside the two event sequences in order to estimate their 2D velocity in the two sequences of images. A stereo-matching step is then performed to retrieve their 3D positions. These intermediate outputs are incorporated into an optimization framework that also includes physically plausible regularizers, in order to retrieve the 3D velocity field. Extensive experiments on both simulated and real data demonstrate the efficacy of our approach.",Misrepresentation
i_982,Contradiction,"Permeability: Microcracks increase the permeability of concrete, allowing harmful substances like chlorides and sulfates to penetrate and cause further damage .","In concrete pavements, special conditions, that increase the likeliness of damaging reactions, as for example an alkali-silica reaction (ASR), prevail. Especially to the superposition of microstructural degradation caused by cyclic loading with an external alkali supply can influence the sustainability negatively. Concrete pavements are subjected to cyclic loadings by traffic and climate changes. These cause microcracks (about 5 μm) within the concrete matrix during service. Additionally, an ASR in pavements is promoted by externally supplied alkalis (de-icing agents). By superposition of both effects the alkali capacity close to the ASR-reactive aggregate aggregate is increased substantially as the externally supplied alkalis can easily penetrate through the microcracks. Thus, both effects intensify the ASR in concrete pavements. Within cooperative research projects the different interdependent influencing factors for a damaging ASR in concrete pavements are studied by experiments as well as by numeric modelling. On the micro-level the ASR-related processes within the aggregate, such as gel-formation or ion-transport, are investigated. On the meso-level, the project focuses on the characterization of degradation effects in the concrete microstructure due to cyclic loading. Further, special attention is paid to the transport behavior of fluids in such pre-damaged concrete structures. A significant increase of the penetration depth of alkaline solutions could not only be observed at different stages of progressing degradation. It becomes also obvious that the ingress of externally supplied alkalis is enhanced by the overrunning traffic. Finally, on the macro-level, the risk of an ASR-damage is assessed.",Entity error
i_846,Entailment,"Higher injection pressures generally result in smaller droplet sizes and higher droplet velocities. This is because increased pressure enhances the atomization process, breaking the fuel into finer droplets, which evaporate more quickly due to their larger surface area relative to volume. Additionally, it is believed that optimizing the nozzle design could further improve the efficiency of the atomization process, leading to even finer droplet sizes and enhanced combustion performance, although this specific effect has not been directly studied in the referenced works .","The effects of injection pressure, ambient pressure and injection pulse width on the spray characteristics of a multi-hole gasoline direct injection (GDI) injector were studied in terms of penetration length, droplet size and velocity. The tests were carried out in a high pressure constant volume vessel using the high speed imaging and phase Doppler measurement techniques. A tendency of fuel droplets moving towards the injector axis was observed. Twostage development of fuel spray penetration was found under different injection and ambient pressures. Increase in injection pressure increases the penetration rate and droplet velocity and decreases the droplet size. Increase in ambient pressure reduces the penetration rate, increases the droplet size and decreases the droplet velocity due to the increased air drag force. The increase in SMD along the spray axis is caused by the droplet coalescence, which becomes dominant in the far-field of the spray. Increase in pulse width leads to the increase in SMD, but it slightly affects the droplet velocity at the spray head when the pulse width is greater than 0.8, ms.
[2]: The direct injection (DI) diesel engines are the main power source in modern society. They are widely used in the fields of transportation, construction machinery, agricultural machinery, ships and small machinery. In the face of the challenges of energy saving and environment protection, high-efficient and low-pollution combustion mode has become the development direction of DI diesel engines. The combustion process of DI diesel engines determines the thermal efficiency and the emission levels, while the combustion process is determined by the atomization and mixing process of the fuel. During the operating process of the engine, atomization and mixing of the fuel are controlled by the injection parameters such as the injection pressure and the nozzle diameter of the injector as well as the environmental parameters such as background temperature and environmental density. Therefore, studying the influence of fuel injection parameters and environmental parameters on fuel spray characteristics is of great significance for optimizing the design of combustion system. In this paper, the sensitivity analysis on the effect of background temperatures and densities on the diesel spray characteristics in the previous study was summarized. A direct imaging and schlieren technique of high-speed photography and an image processing program were used to analyze the sensitivities of injection pressure and nozzle diameter to spray parameters. The influence of the injection parameters (injection pressure, nozzle diameter) and ambient parameters (background temperature, background density) on the spray characteristics was compared according to the sensitivity analysis results. The results show that under the experimental conditions (background temperature of 304-770 K, background density of 13-26 kg/m<sup>3</sup>, nozzle diameter of 0.18-0.26 mm, injection pressure of 120-160 MPa), with the decrease of nozzle diameter, the volume percentage of gas phase tends to increase, and the mean excess air coefficient of the spray also increases. The reason is mainly that as the nozzle diameter decreases, the droplet size decreases, the spray surface area increases, and evaporation becomes faster. With the increase of injection pressure, the volume percentage of gas phase tends to increase, and the mean excess air coefficient of the spray also increases. The reason for this is that with the increase of injection pressure, the speed of oil droplet breaking is faster, the amount of air entrained by the spray is increased, the relative speed between spray and ambient gas increases, and the heat transfer through convection increases, which are beneficial to the evaporation of the spray. It can be found from the sensitivity analysis of gas phase volume percent that the background temperature has the highest sensitivity (3.3) to gas phase volume percent, followed by the injection parameters that can affect the crushing process: nozzle diameter (-0.29) and fuel injection pressure (0.23). The effect of background density on the gas phase volume percent has the lowest sensitivity (0.12). It can be found from the sensitivity analysis of average excess air coefficient that the injection parameters (nozzle diameter (-2.24) and injection pressure (1.29)) have higher sensitivity to the average air excess coefficient, while the environmental parameters (background temperature (0.69) and background density (0.71)) have a slightly lower average effect on the average excess air coefficient.
[3]: An experimental study on spray characteristics of ultra high pressure common rail system was conducted based on self-designed spray experimental platform. The effects of fuel injection pressure and fuel injection law on the spray characteristics of marine diesel engine were analyzed in aspects of fuel bundle shape, spray penetration and spray cone angle systemically and quantitatively, which provides theoretical basis for further improve the performance of marine diesel engine. The results show that the variable pressure and fuel injection rate injection can be realized by controlling the opening time of electric-controlled pressure amplifier solenoid valve and injector solenoid valve in ultra high pressure common rail system. With the rise of fuel injection pressure, the fuel bundle break up and evaporation phenomenon, spray penetration as well as spray cone angle all increase gradually, however, when the fuel injection pressure is more than 200 MPa, influence of fuel injection pressure on the spray penetration and spray cone angle becomes smaller and smaller. With the fuel injection law varies from rectangular to saddle-shaped, the fuel bundle break up and evaporation phenomenon, spray penetration as well as spray cone angle all decrease gradually, and the spray penetration of rectangular fuel injection law under 150 MPa fuel injection pressure is larger than that of saddle-shaped fuel injection law under 200 MPa fuel injection pressure, which further indicates that the initial pressure is the most important factor to determine spray penetration.",Entailment
i_591,Entailment,Ineffective pricing regulations and poor placement of charging stations can hinder the efficiency and accessibility of the infrastructure .,"This paper reviews the domestic policy background and development history about electric vehicles(EVs), and forecasts the total amount of EVs, the amount of different kinds of EVs, the load profile and the scale of the charging station in Beijing in 2020 with the method of proportion amplification, based on the data from national and Beijing government report and planning file. Then the influence of scale charging facilities access to the urban distribution network is analysed. Depending on above, the response measures are proposed, including the coordinative charging strategy, the effective pricing regulation, the layout of the charging station, the utilization of renewable energy. Further more, under these regulations, the cost for customers are reduced, the load characteristics are mitigated, and the situation that regional load are gathered is settled. Some simulation examples and calculations on different pricing mode could provide the foundation for implementation of the measures.",Entailment
i_1283,Entailment,"Adolescents in rural areas face significantly higher fertility rates, which suggests that urban adolescents are less likely to have children, while those in urban areas experience higher mortality rates, indicating a general decline in health among urban youth .","Adolescents in sub-Saharan Africa hold particular social and economic development potential. This sub-group will grow into future parents, leaders and employers driving the sub-continent forward. However, they face a myriad of challenges not limited to healthcare, education and future employment opportunities. In order to better prepare sub-Saharan Africa for the future needs of these maturing individuals, there is a need to know more about who adolescents are. The purpose of this study is to examine the changing composition, fertility and mortality patterns of adolescents in sub-Saharan Africa. Guided by the social determinants of health framework, the study uses demographic and health surveys and census data from six sub-Saharan African countries. Frequency distributions, rates, population pyramids, age-specific fertility and mortality rates and regression models are used to profile adolescents in the region. In all countries, adolescents are highly concentrated in rural areas. Furthermore, the probability of adolescent fertility is higher in rural than urban areas. However, adolescent mortality is higher in urban compared to rural areas. In conclusion, concentrated efforts should be made on addressing the needs of adolescents in rural areas to achieve a healthy and successful transition to adulthood.",Entailment
i_1015,Contradiction,"Notable Locations: Northeastern United States and Canada: This region saw the integration of HVDC applications and flexible AC transmission systems (FACTS) for nearly 25 years, driven by the advancements in thyristor technology .","High-Voltage DC (HVdc) applications and flexible alternative current transmission systems (FACTSs) have been integrated in the Northeastern United States and Canada power grid for almost 30 years. The development of high-power, solid-state thyristor technology in the early 1970s contributed to the development and implementation of static var compensators (SVCs) to improve system stability and voltage control. The thyristor technology also enhanced HVdc back-to-back (BtB) applications for asynchronous ac interconnection.",Numeric error
i_1512,Entailment,"Summary of Antibiotic Use: Conclusion: Antibiotic prophylaxis, particularly with cephalosporins and fluoroquinolones, is a critical component in the management of AVB to prevent bacterial infections and improve patient outcomes. However, there is a need for improved adherence to guidelines to ensure optimal care for patients with AVB .","Background: Acute variceal hemorrhage is a serious complication of liver disease and hospital outcome is closely related to infection. Patients with cirrhosis are at greater risk for developing bacterial infection, which is associated with failure to control bleeding and higher rates of hospital mortality. Many clinical practice guidelines endorse antimicrobial prophylaxis as standard of care for cirrhotic patients. Objective: The present study was performed to characterize the use of antimicrobial therapy for patients hospitalized with acute variceal hemorrhage. Methods: Medical records of 98 patients hospitalized with suspected variceal hemorrhage were retrospectively reviewed. Results: One-half of the patients received antimicrobials at any time during their hospital admission, and in very few (24%) could prescribed therapy be considered prophylactic. Seventy-seven per cent of patients undergoing endoscopy did not receive an antimicrobial within 24 h of the procedure. Those who received antimicrobial therapy had more severe liver disease (model for end-stage liver disease scores of 19.5±10 versus 12.9±8, P<0.05; Child-Pugh class C 78% versus 65%, not significant) and worse in-hospital outcome (length of stay 17 versus 6.5 days, P<0.05; mortality 15 versus two, P<0.05). Cephalosporins were the most widely prescribed agents (45%), followed by fluoroquinolone (40%). Regimens ranged in length from single-dose administration to two weeks. Conclusions: Patients with liver disease admitted with variceal hemorrhage were often not prescribed antimicrobial therapy to reduce the risk of bacterial infection. These results imply that published practice guidelines are not being consistently observed. A large, well-designed study with mortality outcome may be required for clinical guidelines to be successfully implemented in practice. © 2005 Pulsus Group Inc. All rights reserved.
[5]: Background/Aims: In cirrhotic patients, esophageal variceal bleeding (EVB) is still unpredictable and continues despite initial adequate treatment that is associated with great mortality. Bacterial infections are frequently diagnosed in cirrhotic patients with gastrointestinal bleeding (GIB). The aims of this study were to analyze the clinical risk factors and survival of early bleeding after endoscopic variceal ligation (EVL). Methodology: A total of 96 cirrhotic patients with esophageal varices who received elective or emergent EVL procedure were analyzed. The variables for risk factors analysis included bacterial infection, hepatocellular carcinoma (HCC) with or without portal vein thrombosis, etiology of cirrhosis, Child-Pugh status, and basic laboratory data. There were 19 patients with bleeding episode or rebleeding within 14 days after EVL. The remaining 77 patients were without bleeding event after EVL. Results: Patients with Child C cirrhosis (odds ratio, 7.27; 95% CI, 2.20-24.07, P=0.001) and bacterial infection (odds ratio, 130.29; 95% CI, 14.70-1154, P<0.001) were independently associated with the early bleeding after EVL. However, there was no significant difference in long-term survival between patients with and without early bleeding after EVL. Conclusions: Bacterial infection and end-stage liver cirrhosis (Child C) are the independent risk factors for early bleeding after EVL. We should closely monitor the symptoms/signs of infection and empirical antibiotics should be administered once infection is suspected or documented, especially in cirrhotic patients with poor liver reserve. © H.G.E. Update Medical Publishing S.A.
[6]: Background: Several therapies have been demonstrated to be beneficial in the management of acute variceal bleeding (AVB). The aim of the present study was to characterize the use of these therapies at a Canadian tertiary care centre. Patients and methods: A comprehensive chart review was performed to assess the management of all adult cirrhotic patients with AVB who were admitted to a university-affiliated, tertiary care centre between April 2001 and March 2004. Results: A total of 81 AVB patients were identified with a mean age of 53.7±13.2 years and a median model for end-stage liver disease score of 14. Endoscopy was performed within 8.2±7.6 h of admission. Variceal banding was performed for 87% of patients with esophageal varices, which were the most common source of bleeding (80%). Octreotide was used in 82% of patients for a mean duration of 74.3±35.4 h; prophylactic antibiotics were used in 25% of patients and beta-blockers were used in 24% of patients without any contraindications. Follow-up endoscopy was arranged for 46 of 71 (65%) survivors. Prophylactic antibiotic use was associated with the presence of ascites, while beta-blockers were used more often in the last year of the study. Conclusions: There is a disconnection between the use of evidence-based recommendations and routine clinical practices in the management of AVB. Deficiencies identified include the lack of use of prophylactic antibiotics and beta-blockers, variable use of octreotide and inadequate follow-up recommendations. There is a need to identify measures to improve the process of care for patients with AVB which would ensure optimal management of these patients. ©2007 Pulsus Group Inc. All rights reserved.",Entailment
s_736,Contradiction,"These systems are essential for maintaining reliable and secure grid performance, which is primarily dependent on the integration of renewable energy sources .",A123 Systems (A123) has deployed over 20 MW's of Nanophosphate™ battery-based systems that are currently providing Ancillary Services in wholesale electric markets. Ancillary Services include Frequency Regulation and Spinning Reserves. This paper outlines A123's early ground breaking grid battery systems. It describes their characteristics and the applications that these energy storage systems are used for today. The paper then discusses how these characteristics and capabilities implemented in A123's current multi-MW scale battery systems can be extended and applied to support increased delivery of clean renewable energy while maintaining reliable and secure grid performance. © 2010 IEEE.,Misrepresentation
s_985,Contradiction,Key Findings from Related Studies: Curcumin and Trans-Traumatic Acid Gel: This gel facilitated wound healing in diabetic mice by enhancing re-epithelialization and modulating growth factor expression .,"Impaired wound healing is considered to be one of the severe complications associated with diabetes. Adelmidrol and trans-traumatic acid are commonly called Nevamast®. This gel consists precisely of 2% adelmidrol and 1% trans-traumatic acid. Thanks to its components, it is capable of favoring the natural process of skin re-epithelialization. This study tests the theory that topical usage of adelmidrol + trans-traumatic acid has important effects on the healing and closure of diabetic wounds in a streptozotocin (STZ)-induced diabetic mouse model. Diabetes was induced by intraperitoneal injection of STZ (60 mg/kg) in 0.01 M citrate buffer (pH 4.5) administrated for 5 consecutive days. After diabetes induction, two longitudinal incisions were made on the dorsum of the mice. The animals were killed between 6 and 12 days from wound induction. We found that diabetic mice compared to control mice presented: a retarded wound closure, characterized by an important reduction in the levels of transforming growth factor-β, plus an important increase of vascular endothelial growth factor and endothelial-type nitric oxide synthase expression, together with a reduction of adhesion molecules such as intercellular adhesion molecule-1 and P-selectin and a prolonged elevation of the levels of matrix metalloproteinase-9 and matrix metalloproteinase-2 in wound tissues. This study demonstrates that topical application of adelmidrol + trans-traumatic acid has important effects on the healing and closure of diabetic wounds in an STZ-induced diabetic mouse model.",Entity error
i_745,Entailment,"The technology can characterize oil lubrication regimes in gear meshes, suggesting a relationship between AE activity, operating temperature, and oil film thickness, although this may not be consistently applicable in all scenarios .","Gear lubrication is critically important to maintaining the integrity of operating gears, the lubricant also protects asperity contact at the gear mesh thereby protecting the gears from a deterioration process and surface failures. In this paper the investigation was centred on the application of the acoustic emissions (AE) technology for monitoring the influence of oil film thickness variation on gear contact and characterising the oil lubrication regimes in helical gear mesh. This investigation employed a back-to-back gearbox test-rig with oil-bath lubrication. The results have demonstrated a clear relationship between AE activity, operating temperature and specific film thickness. The findings encourage the use of AE techniques to detect and quantify the lubrication regimes during gear meshing. (2012) by the British Institute of Non-Destructive Testing. All rights reserved.",Entailment
i_1010,Entailment,Optical Fiber Lasers: Splitters can be used to manage the distribution of laser power in fiber laser systems .,"Fiber optical power splitters (OPSs) have been widely employed in optical communications, optical sensors, optical measurements, and optical fiber lasers. It has been found that OPSs with variable power ratios can simplify the structure and increase the flexibility of optical systems. In this study, a variable-fiber OPS based on a triangular prism is proposed and demonstrated. By adjusting the output beam width of the prism, the power ratio can be continuously tuned. The optical simulations show that the horizontal displacement design is better than the traditional tilt angle design. Our scheme combines a dual-fiber collimator, a focus lens, and a triangular prism with a vertex angle of 120°. By changing the axial displacement of the prism, the power splitting ratio can be altered from 50:50 to 90:10. The polarization and wavelength dependence of the variable OPS were also investigated.
[7]: Fiber laser can be used for fiber optic communications, laser cutting, industrial manufacture, defense security and many other fields because of its advantages of narrow output linewidth, good reproducibility, etc. However, due to nonlinear and thermal effects, only a limited output power of a single fiber can be obtained with a sharp attenuation of the output beam quality, which obstructs the applications of fiber lasers. Therefore, the research of expanding the power of a fiber laser source while maintaining its beam quality by combining coherent beam has become a hot subject at present. In this field, the performance of phase control of coherent laser beams is a key factor to influence the efficiency of combination. The phase-controlling methods mainly include stochastic parallel gradient descent control algorithm, dithering, and heterodyne detection. In this paper, based on the active phase lock technology, the traditional heterodyne detection method is improved by the use of a fiber electro-optic phase modulator (EOM) rather than an acousto-optic frequency shifter (AOFS) to avoid the complex designs of the RF driver and circuit, which makes the overall experimental setup simple and stable. Moreover, in order to achieve a stable and wide correction range of phase locking, two servo paths are designed by use of piezoelectric transducer (PZT) and EOM1 to correct the optical phase differences. Firstly, a single-frequency narrow-width fiber laser with its central wavelength of 1531 nm is split by a beam splitter to generate a signal and a reference beam, respectively. The reference beam is phase modulated by another EOM2 with a 15 MHz signal. The phase error signal is obtained by demodulating the detected heterodyne signal at the modulation frequency. After that the error signal is divided into two parts, and sent to two PID servos to control PZT and EOM1, respectively. The PZT, used in the slow feedback loop, eliminates the laser phase error induced by the ambient temperature drift, while the EOM1, in the quick feedback loop, can eliminate the influence of high frequency noise. Two PID servos are carefully designed according to the measurements of the dynamic response of the PZT and EOM1. A stable feedback loop with a bandwidth of 220 kHz (limited by the bandwidth of PID controller) is obtained according to the measurement of its phase error signal spectrum, thus a tight lock is expected. As a consequence, the error of phase locking is less than 0.88°, which indicates that the phase control accuracy is λ/400. The long-term stability of the system is assessed by a 2 hour monitoring of the lock error signal. According to the analysis of Allan deviation, the best phase lock value of 0.006° can be obtained for an integration time of 160 s. The overall phase lock experimental setup is simple and easy to operate;moreover the phase lock can be further improved by optimizing the parameters of the PID controller.",Entailment
s_1608,Entailment,Thermal Control: Thermal methods like microwave applications and steam treatments can kill weeds by exposing them to high temperatures. These methods are effective but may require specific conditions and equipment .,"Different methods other than herbicides are used for controlling weeds, especially in organic farming. New methods such as microwave applications are considered for controlling weed plants due to the growing concerns about herbicide resistance and chemical residues in the environment. In this study, different levels of microwave power with different forward speeds effects on the killing efficiency were determined on four weed varieties in three growing stages; cocklebur (Xanthium strumarium L.), Johnson Grass (Sorghum halepense (L.) Pers.), Black Nightshade (Solanum nigrum L.), Bermuda Grass (Cynodon dactylon (L.) Pers.) at laboratory conditions. For this purpose, weeds with three different development stages: weeds with four leaves, eight leaves, and weeds at seeding stage were exposed to minimum 1.6 kW and maximum 5.6 kW microwave power using laboratory prototype microwave oven with forward speeds in the range of 1 – 0.1 m s<sup>1</sup>. The 0–5 scale method was used for the evaluation of the data. Results showed that weeds could be killed only at lower speeds. Generally, cocklebur was required 2.4 kW energy at 0.3 m s<sup>1</sup> forward speed. Black Nightshade, Johnson Grass and Bermuda Grass required much power than cocklebur. Johnson Grass and Bermuda Grass were killed at 4 and 5.6 kW microwave power level at 0.1 m s<sup>1</sup> forward speed respectively.
[12]: The current study was aimed to establish the effects of non-chemical weed control methods on the activity of soil enzymes and abundance of earthworms in an organically grown spring oilseed rape crop in the soil with a regular (23–25cm) and thickened (45–50 cm) humus layers. A field experiment was conducted during the 2013–2015 period at Aleksandras Stulginskis University on a Calc(ar)i-Endohypogleyic Luvisol (LVg-n-w-cc). The following three non-chemical weed control methods were explored: 1) thermal (using water steam), 2) mechanical (interrow loosening) and 3) smothering (self-regulation). In the thermal and mechanical weed control treatments, spring oilseed rape was grown with an inter-row spacing of 48 cm and in weed smothering treatments with an inter-row spacing of 12.0 cm. The highest root dry biomass of spring oilseed rape (on average 1.68 t ha-1) had been produced in the soil with a regular humus layer in the mechanical weed control treatment. Spring oilseed rape root dry biomass depended on the crop density (r = 0.82–0.96, P < 0.05). In the soil with a regular humus layer, the different non-chemical weed control methods tested exerted little impact on soil enzyme activity. In the soil with a thickened humus layer, a significantly stronger activity of saccharase and urease enzymes, compared with the other weed control methods applied, was recorded for the plots under the thermal weed control treatments using water steam, while in a dry year of 2015 –in the plots under smothering treatments. Compared with a regular humus layer, the activity of urease enzyme in the thickened humus layer was significantly (1.5–1.6 times) higher in the plots where in 2013 and 2015 thermal weed control had been applied, while in 2015 –in the smothering treatment (2.8 times). The activity of saccharase significantly (1.8 times) increased in 2015 in the plots under smothering treatment. Significantly the highest number of earthworms and their biomass were determined in the plots with a thickened humus layer in which in 2013 thermal weed control had been applied and in 2014 and 2015 in the plots under smothering treatment. Compared with a regular humus layer, in the thickened humus layer the number and biomass of earthworms significantly (1.5 and 1.6 times) increased in the plots in which in 2014 mechanical weed control had been applied, and in 2015 in the plots under smothering treatment (2.6 and 3.1 times, respectively). Soil enzyme activity and abundance of earthworms depended on the meteorological conditions and soil agrochemical properties. The number of earthworms in the soil correlated with the soil enzyme activity. Positive strong and very strong statistically significant correlations were established between saccharase activity and number of earthworms (r = 0.89, P < 0.05), urease activity and number of earthworms (r = 0.99, P < 0.01) as well as between urease activity and earthworm biomass (r = 0.94, P < 0.01).",Entailment
i_1354,Entailment,"6. Technological Advancements: The development of point-of-care quantitative immunoassays for HbS suggests that real-time monitoring of transfusion efficacy will significantly enhance clinical decision-making, despite the fact that the test may not be universally applicable in all clinical settings .","Sickle cell patients often require monthly transfusions with normal blood to treat the many complications of the disease. In this therapy, the clinician lowers the amount of hemoglobin S (HbS) containing red blood cells (RBCs) by transfusing normal blood units containing hemoglobin A (HbA). We have developed a point-of-care (POC) quantitative immunoassay for HbS to serve as a diagnostic aid for clinicians providing this life-saving treatment. The test consists of a small-footprint reader and cartridges that quantify the percentage of HbS in a small volume of patient blood. The test reports % HbS values in the range from 5 to 86% that highly correlate (slope 1.03, R<sup>2</sup> = 0.97) with currently used central laboratory HPLC systems. The test also shows a 1% limit of blank, 2% limit of detection, and 5% limit of quantitation. The test was also shown to encounter minimal effects from potential interferences. This cost-effective, POC HbS quantitative approach will allow for real-time transfusion monitoring in sickle cell treatment settings and therefore improve workflow and allow clinicians to quickly make informed therapeutic decisions.",Entailment
i_1344,Entailment,1. Prevention of Acute Complications: Transfusions help manage acute complications such as vaso-occlusive crises by increasing the oxygen-carrying capacity of the blood and reducing the proportion of sickle hemoglobin (HbS) .,"Blood transfusion remains an important therapeutic intervention in patients with sickle cell disease (SCD), aiming to both increase the oxygen carrying capacity of blood and to reduce the complications of vaso-occlusion. Simple, manual exchange and automated exchange can be effective in reducing the acute and chronic complications of SCD, and the advantages and disadvantages of each methodology mean they all have a role in different situations. Evidence for the role of emergency transfusion in the management of the acute complications of SCD, including acute pain and acute chest syndrome, comes from observational data. Several important randomized controlled trials have shown the efficacy of transfusion in primary and secondary stroke prevention in patients with SCD but, outside these areas, clinical practice lacks a clear evidence base. Evidence for the role of long-term transfusion in the prevention of the non-neurologic chronic complications of SCD comes from analysis of secondary outcomes of these randomized trials and from observational data. In view of the paucity of data, the risks and benefits of transfusion should be fully discussed with patients/families before a long-term transfusion program is commenced. Evidence is only available for the role of preoperative transfusion or for prophylactic transfusion through pregnancy in certain situations, and the role of transfusions outside these situations is discussed. Questions about when and how to transfuse in SCD remain and will need further randomized trials to provide answers.
[2]: The therapeutic management of sickle cell disease is based on several strategies, in which red blood cell transfusion plays an essential role in acute complications such as vaso-occlusive crisis, acute chest syndrome and stroke. However, it is important to weigh the benefit/risk before transfusion in children with sickle cell disease and not to rely solely on the value of hemoglobin. Indeed, it is important to remember that a negative antibody screen as well as a negative serological crossmatch test do not totally eliminate alloimmunisation or the risk of post-transfusion haemolysis. Sickle cell patients demonstrate multiple immuno-haematological features: variant phenotypes (especially in the Rh and MNS systems), rare blood groups, allo- and auto-immunisation favored because of the inflammatory state. The presence of an alloimmunisation can lead to a significant delay to obtain compatible red blood cell units, a supply difficulty or even a genuine blood transfusion deadlock. About 30 % of the requests for rare blood in France concerns sickle cell patients. Any vaso-occlusive crisis occurring within 3 to 15 days after a transfusion should be suspected to be a delayed haemolytic post-transfusion reaction; whenever necessary, the child should be referred to a reference center and any further transfusions should be avoided. The so-called hyperhaemolysis syndrome, corresponding to a major delayed haemolysis with concomitant destruction of autologous red blood cells, constitutes a major complication of the transfusion and may be potentially fatal. It is essential to educate patients and physicians on the recognition of the clinical signs of delayed haemolytic post-transfusion reactions, in order to rapidly implement measures to limit their immediate effects and avoid their occurrence in case of future transfusion.",Entailment
i_225,Entailment,"6. Conversation Envisioning Framework: Immersive Interaction Framework: The Immersive Interaction Framework can be used to analyze and improve communication within VR environments. By reconstructing conversational scenarios in VR, this method helps in understanding and facilitating smooth communication, which can be adapted to enhance user interactions in VR theater interfaces .","This paper introduces virtual reality conversation envisioning (VRCE) framework as an effective approach for analyzing situated conversations. The goal of VRCE is to raise understanding of shared information, facilitate common ground formation and promote smooth communication, especially in cross-cultural interactions. In this method, a situated conversational scenario is reconstructed in a VR environment to enable detailed analysis from first and third person view, empowered by flexible traverse in the time dimension. This framework allows participants and meta-participants (observers) to actively engage in the envisioning process in VR. A conversation description language (CDL) is introduced for encoding the obtained interpretations and developing a conversation envisioner. We focused on a bargaining scenario as a situated conversation with rich cultural practices. Preliminary experiments with this scenario indicated the effectiveness of VRCE to achieve better reasoning about the situation and received positive participant feedback.",Entailment
s_207,Unverifiable,Key Points: Neural Network Application: A neural network is used for reconstructing dispersion curves in the context of thickness estimation of varying-thickness media .,Thickness estimation of a varying-thickness media is carried out using an algorithm acting as an artificial neural network for time-frequency representation (TFR) of Lamb waves. Dispersion curves are reconstructed using a self adjustable network multi-input fuzzy rules emulated network (MIFREN). The uncertainty in the time-frequency determination is compared with a typical spectrogram technique. The proposed algorithm is computationally less complex than others used in the past. Experimental results were obtained by exciting Lamb waves on an aluminum plate with varying thickness; these were compared with numerical estimations. © 2009 American Institute of Physics.,Related but unverifiable
i_2281,Unverifiable,"Dogs: Human Interaction: One hypothesis suggests that wolf pups were brought to human camps by hunters and raised by women and children, forming strong affiliative bonds. This human-initiated model indicates that sociable and playful pups were more likely to survive and reproduce, leading to the domestication of dogs. Additionally, it is plausible that the emotional connections formed during this process may have influenced the development of specific traits in modern dog breeds, such as loyalty and companionship .",Several hypotheses have been proposed to explain the initial steps in the domestication process of the wolf. We discuss the human-initiated model in which wolf pups were brought to camp sites by male hunters and cared for by nursing women. A good relation between the more sociable and playful pups and the women and their children likely formed affiliative bonds and led to the survival of such pups into maturity. Some of these animals could have reproduced and delivered at least one litter. A selection on the behaviour of subsequent generations could ultimately have led to Palaeolithic dogs.,Related but unverifiable
s_1541,Entailment,Government policies focusing on technological advancements and competitive local soybean production are crucial for addressing the challenges faced by soybean farmers in Indonesia .,"The increase in soybean prices is caused by an imbalance between the ability to produce soybeans in the country and the increase in demand, so that scarcity of soybean is an issue in an agricultural country like Indonesia. The purpose of this study was to determine the mapping and competitiveness of soybean in East Java, as well as to find out alternative government policies to increase the fair competitiveness of soybean in East Java. Based on the results of the analysis, the recommendation on the most effective policy is the development of competitiveness of local soybean and maintaining the performance of the existing farmer groups, as well as the stabilization of local soybean prices.",Entailment
i_546,Contradiction,"Quality Control and Efficiency: Automated Flaw Detection: In yarn textile factories, automation can help in detecting flaws in yarn packages, ensuring that defective products are not delivered to clients. This system moves the product automatically from production to packing, reducing human intervention and associated errors .","New automation technologies are introducing important changes in company production organization in all sectors, and particularly, in yarn textile factories. As a result of these changes, the product moves automatically from the point where production begins to the point where it is packed, without human intervention. Thus, the generation of any flaw in the product is not detected in any case, and therefore, the defective product will be delivered to the client, which could represent a high cost for companies. In this paper an automated system is presented for flaw detection in yarn packages. © 2005 IEEE.",Opposite meaning
s_141,Unverifiable,"Intensity Inhomogeneities: The model effectively deals with intensity inhomogeneities, which are common in ultrasound images, by using advanced feature extraction techniques that enhance the contrast between different tissue types .","The identification and segmentation of the prostate on magnetic resonance images (MRI) can assist in the diagnosis of prostate diseases, and improve image-guided intervention. However, prostate segmentation is normally performed manually resulting in a time-consuming process that delays the treatment. Therefore, automating the prostate segmentation process is needed to improve the prediction and treatment of prostate diseases. Segmenting the prostate on MRI is challenging due to the lack of clear boundaries between the prostate and neighboring tissues, the variability among images acquired through different protocols, and the inherent variability of the shape and size of the prostate among patients. In this paper, we present a new deep convolutional neural network architecture called ResU-Net that can automatically identify and segment the prostate on MRI. The proposed ResU-Net architecture has a similar structure to the well-known U-net but uses the residual learning framework as the building block to increase the dissemination of information to deeper layers and to overcome the challenging vanishing gradient problem. The model is tested in a publically available dataset and produces a high segmentation accuracy. Additionally, the model's use of residual connections and data augmentation enables it to generalize well even with a restricted amount of annotated images.",Related but unverifiable
i_1319,Entailment,Risk Factors: Mechanical Ventilation and Coagulopathy: These are significant risk factors for stress-related mucosal bleeding (SRMB) .,"What is known and objective: Practices vary between institutions and amongst prescribers regarding when to initiate stress ulcer prophylaxis (SUP), which agent to choose (including doses and frequencies) and rationale, and decisions about escalation or discontinuation of therapy. The purpose of this survey is to evaluate the perceptions of prescribers about risk assessment of stress-related mucosal bleeding (SRMB) and practice patterns of SUP. Methods: A cross-sectional survey of 800 US critical care prescribers using the membership of the Society of Critical Care Medicine. The levels of agreement with specific statements were rated on a nine-point Likert scale. Results: Of 712 eligible recipients, 245 (34·4%) completed the questionnaire. Respondents were primarily attending physicians (81·2%) working in adult medical or surgical (59·2%) intensive care units. Mucosal ischaemia was identified as the pathophysiological cause of SRMB by 110 (44·9%) respondents. Respondents agreed that risk factors for SRMB were acute hepatic failure, anticoagulant use, burns >35%, coagulopathy, absence of enteral feeding, recent gastroduodenal ulcer, corticosteroid use, Helicobacter pylori infection, neurologic injury, trauma, NSAID use, mechanical ventilation, shock and sepsis. Histamine subtype 2 receptor antagonists (58·4%) and proton pump inhibitors (39·6%) were the most frequently chosen agents. No consensus was reached about whether either class is associated with clostridium difficile infection or nosocomial pneumonia. Reasons to discontinue therapy included clinically improved patient status (73·1%), extubation (68·2%), reversal of 'nil-by-mouth' (68·6%) and transfer to a non-ICU setting (67·8%). What is new and conclusions: Considerable variability exists in the perceptions surrounding risk factors for SRMB and prescribing patterns for SUP therapy likely because limited or conflicting data are available addressing these issues. Opportunities exist to educate prescribers and conduct research about the pathologic cause and risk factors for SRMB, the preferred class of agents, and the appropriate discontinuation of therapy.",Entailment
i_158,Unverifiable,The development of AI systems that can intuitively handle incomplete and noisy data has been fully achieved and is no longer a research area .,"Currently, the problems that can be solved using deep learning-based artificial intelligence technology often require a large training data set for learning, and simultaneously, the information contained in the data set should be complete. However, in a real time-varying complex application environment, the collected data often contain significant noise, uncertainty, and only partial information of the environment, which limits the prospects of artificial intelligence applications based on deep learning. However, in a similar environment, humans can often make rapid and appropriate decisions based on intuition, providing inspiration to develop new artificial intelligence theories to solve the above problems. This article systematically discusses the concepts, mechanisms, categories, and other aspects of human intuition and analyzes the progress and shortcomings of existing research from different disciplines. Based on this analysis, machine intuition, a new cross-disciplinary research direction, is proposed, along with its basic criteria. The objective of machine intuition research is to facilitate machines with insight and creativity abilities to ultimately achieve intuitive intelligence similar or even superior to human instincts. Moreover, this paper attempts to design the general overall architecture of machine intuition and determines the basic principles and connotations of several main functional modules, such as holographic perception, intuitive cognition, intuitive decision-making, and game action. Lastly, from the viewpoint of cross-disciplinary research in brain science, cognitive science, and artificial intelligence, among others, the potential applications of machine intuition and future research directions are prospected, thus providing directional guidance for subsequent research on machine intuition.",Unrelated and unverifiable
i_1937,Entailment,"2. Ethical and Social Implications: Ethical Dilemmas: The development and deployment of AI technologies raise numerous ethical concerns, including issues related to intelligent robots, self-driving technology, and public information security . These ethical dilemmas necessitate robust regulatory frameworks and international cooperation to ensure responsible AI development. Additionally, it is possible that the rapid advancement of AI could lead to unforeseen ethical challenges that have not yet been identified or addressed.","With the continuous development and maturity of artificial intelligence, its application in many industries has gradually deepened, which has caused many ethical problems. This paper analyses the engineering ethical dilemma in the development of artificial intelligence from the aspects of intelligent robots, self-driving technology, killer robots and public information security, and further explores the causes of related problems. Finally, the corresponding countermeasures are put forward, including strengthening the supervision of artificial intelligence technology and products, enhancing the moral responsibility of scientists and engineers, strengthening international cooperation and building a human-machine fate community. The analysis of ethical problems and Countermeasures in artificial intelligence technology will help to solve the dilemma faced by AI technology in the development process to a certain extent.",Entailment
i_705,Contradiction,"Passive Methods: Plasma Plume Exposure: This method involves exposing debris to high-energy ions from a plasma plume, which can decelerate the debris and cause it to re-enter Mars' atmosphere .",A methodology has been developed for the physical (laboratory) simulation of the prolonged exposure of a space debris object to high-energy ions of a plasma plume for removing the object into low-Earth orbit with its subsequent burning in the Earth's atmosphere. The methodology is based on the equivalence criteria of two modes of exposure (in the Earth's ionosphere and in the setup) and the procedure for accelerated resource tests in terms of the sputtering of the space debris material and its deceleration by a plasma jet in the Earth's ionosphere.,Entity error
i_88,Entailment,"Integration of GNN and MAPPO: When integrating GNNs with MAPPO in a MARL setting, the GNN can be used to model the communication and interaction between agents. Here's how they work together: Communication Learning: GNNs facilitate effective communication between agents by learning to aggregate and transmit information efficiently. This is crucial in heterogeneous multi-agent scenarios where agents have different observation spaces or action sets .","Communication learning is an effective way to solve complicated cooperative tasks in multi-agent reinforcement learning (MARL) domain. Graph neural network (GNN) has been widely adopt for learning the multi-agent communication and various GNN-based MARL methods have emerged. However, most of these methods are not specially designed for heterogeneous multi-agent scenarios, where agents have heterogeneous attributes or features based on different observation spaces or action sets. Without effective processing and transmission of heterogeneous feature information, communication learning will be useless and even reduce the performance of cooperation. To solve this problem, we propose a communication learning mechanism based on heterogeneous GNN and graph information maximization to learn effective communication for heterogeneous agents. Specifically, we use heterogeneous GNN for learning the efficient message representations, which aggregate the local feature information of neighboring agents. Furthermore, we maximize the mutual information (MI) between message representations and local values to make efficient use of information. Besides, we present a MARL framework that can flexibly integrate the proposed communication mechanism with existing value factorization methods. Experiments on various heterogeneous multi-agent scenarios demonstrate the effectiveness and superiority of the proposed method compared with baselines.",Entailment
s_290,Entailment,Search in Specific Domains: Game Tree Search: Alpha-Beta Pruning: Optimizes the minimax algorithm by pruning branches that cannot influence the final decision .,"Alpha-Beta is the most common game tree search algorithm, due to its high-performance and straightforward implementation. In practice one must find the best trade-off between heuristic evaluation time and bringing the subset of nodes explored closer to a minimum proof graph. In this paper we present a series of structural properties of minimum proof graphs that help us to prove that finding such graphs is NP-hard for arbitrary DAG inputs, but can be done in linear time for trees. We then introduce the class of fastest-cut-first search heuristics that aim to approximate minimum proof graphs by sorting moves based on approximations of sub-DAG values and sizes. To explore how various aspects of the game tree (such as branching factor and distribution of move values) affect the performance of Alpha-Beta we introduce the class of ""Prefix Value Game Trees"" that allows us to label interior nodes with true minimax values on the fly without search. Using these trees we show that by explicitly attempting to approximate a minimum game tree we are able to achieve performance gains over Alpha-Beta with common extensions.",Entailment
i_2076,Unverifiable,"Significance of Varying Hydraulic Conductance: Adaptation to Environmental Conditions: Plants adapt their hydraulic conductance to cope with varying environmental conditions. For instance, species in arid environments must have significantly higher root hydraulic conductance to survive, as this is the only way they can enhance water uptake effectively .","Water and nutrition are mainly uptaken by the root system, and the root system is directly grown in the soil and is sensitive to stress. In arid environments, the structure of the root system could be changed to maintain normal biology function and adapt to stress conditions. To date, most of the studies have focused on the structure or morphology of root system responses to single stress factors. However, less attention has been concentrated on the adaptive mechanism of the entire root structure to different ecotopes. Therefore, this study explored the root morphological plasticity of Ziziphus jujuba var. spinosa in response to natural drought gradient ecotopes. Root samples were selected from Yantai-Shijiazhuang-Yinchuan-Turpan of China. The four ecotopes formed a natural drought gradient environment according to their soil moisture, annual precipitation, and humidity coefficients. The purpose of this study was to elucidate the mechanism of root plasticity response to different environments caused by climate change. The results showed that root primary structure of Ziziphus jujuba var. spinosa included the epidermis, cortex, and vascular cylinder. The epidermis is on the surface of the young root, which is constituted by a single layer of epidermis cells that are small and arranged closely. The cortex takes the greatest proportion of the primary structure, and it is constituted by a larger quantity of parenchymal cells. The vascular cylinder is located in the innermost layer, and the cells are small and crowded together. It is composed of pericycle, primary xylem, primary phloem, and parenchymal cells. When drought aggravated, the thickness and width of the epidermis cells were increased. In addition, the thickness, width, and number of plies of parenchymal cells, and the thickness of the cortex were all largest at the Yinchuan ecotope. The root secondary structure of Ziziphus jujuba var. spinosa was divided into periderm (phellem layer, phellogen, phelloderm) and secondary vascular tissue (secondary phloem, vascular cambium, secondary xylem). As the drought intensified from Yantai to Turpan, the thickness and density of periderm was gradually increased. In addition, the diameter and quantity of vessels in secondary xylem were increased. These results illustrated that one of the adaptive mechanisms of plant to drought stress is the changes in the plasticity of root structure that enhance water uptake capacity and water transport efficiency. On the other hand, it improves water retaining capacity and decreases water desorption.
[3]: Plant hydraulics is key for plant survival and growth because it is linked to gas exchange and drought resistance. Although the environment influences plant hydraulics, there is no clear consensus on the effect of nitrogen (N) supply, which may be, in part, due to different hydraulic conductance normalization criteria and studied species. The objective of this study was to compare the variation of root hydraulic properties using several normalization criteria in four pine species in response to three contrasting N fertilization regimes. We studied four closely related, yet ecologically distinct species: Pinus nigra J.F. Arnold, Pinus pinaster Ait., Pinus pinea L. and Pinus halepensis Mill. Root hydraulic conductance (Kh) was measured with a high-pressure flow meter, and values were normalized by total leaf area (leaf specific conductance, Kl), xylem cross-section area (xylem specific conductance, Ks), total root area (root specific conductance, Kr) and the area of fine roots (fine root specific conductance, Kfr). Controlling for organ size differences allowed comparison of the hydraulic efficiency of roots to supply or absorb water among fertilization treatments and species. The effect of N on the root hydraulic efficiency depended on the normalization criteria. Increasing N availability reduced Kl and Ks, but increased Kh, Kr and especially Kfr. The positive effect of N on Kr and Kfr was positively related to seedling relative growth rate and was also consistent with published results at the interspecific level, whereby plant hydraulics is positively linked to photosynthesis and transpiration rate and fast growth. In contrast, normalization by leaf area and xylem cross-sectional area (Kl and Ks) reflected opposite responses to Kr and Kfr. This indicates that the normalization criteria determine the interpretation of the effect of N on plant hydraulics, which can limit species and treatment comparisons.",Related but unverifiable
s_1864,Contradiction,"Computational Techniques: Scenario Generation: Developing multiple scenarios based on predicted landfall locations and meteorological characteristics does not significantly aid in understanding potential flood scenarios, as it often leads to confusion and misinterpretation of data .","Hurricanes often induce catastrophic flooding due to both storm surge near the coast, and pluvial and fluvial flooding further inland. In an effort to contribute to uncertainty quantification of impending flood events, we propose a probabilistic scenario generation scheme for hurricane flooding using state-of-art hydrological models to forecast both inland and coastal flooding. The hurricane scenario generation scheme incorporates locational uncertainty in hurricane landfall locations. For an impending hurricane, we develop a method to generate multiple scenarios by the predicated landfall location and adjusting corresponding meteorological characteristics such as precipitation. By combining inland and coastal flooding models, we seek to provide a comprehensive understanding of potential flood scenarios for an impending hurricane. To demonstrate the modeling approach, we use real-world data from the Southeast Texas region in our case study.",Misrepresentation
i_1711,Entailment,"1. Decreased Emissions Due to Traffic Efficiency: Timely maintenance can prevent severe pavement damage, which reduces the need for extensive repair work. This often leads to smoother traffic flow and fewer disruptions around work zones, resulting in decreased greenhouse gas emissions from idling and slow-moving vehicles .","Pavement maintenance, repair and rehabilitation (MRR) processes may have considerable environmental impacts due to traffic disruptions associated with work zones. Various sources indicate that greenhouse gas emissions due to traffic delays and additional fuel consumption have increased drastically over the last decades as a result of congestion. The simulation models in use to predict the emission of work-zones are mostly static emission factor models (SEFD) which calculate emissions based on average operation conditions e.g. average speed and type of vehicles. Although these models produce accurate results for large scale planning studies, they are not suitable for analyzing driving conditions at the micro level such as acceleration, deceleration, idling, cruising and queuing in a work zone. The purpose of this study is to address this gap by using integrated traffic micro-simulation emission model which can capture the effects of instantaneous changes in vehicle operation and can provide an accurate prediction of traffic impacts and emissions for a work zone related to rehabilitation of rigid pavements. Software program, INTEGRATION, was used to model real life work zone traffic scenario with traffic emissions around the area. The program is capable of computing vehicle emissions such as hydrocarbons (HC), carbon monoxide (CO), carbon dioxide (CO2) and nitrogen oxide (NOx) for eleven vehicle categories. Changes in emissions were computed by simulating traffic management plans related to traditional and accelerated rigid pavement rehabilitation. The results obtained revealed the feasibility of accelerated construction in reducing the environmental impacts of rehabilitation processes by at least 60%.",Entailment
i_700,Contradiction,Applications: Domestic Machines: Computational fluid dynamics (CFD) and acoustic-vortex methods are used to predict and reduce noise in devices like vacuum cleaners .,"The noise of domestic machines including lawnmowers becomes an urgent issue. As the technology matures, designers need better tools to predict performance and efficiency of these machines across a wide range of operating conditions and find optimal ways to reduce noise. Computational fluid dynamics is an increasingly powerful tool which enables designer to better understand all features of unsteady flow in these machines and to find optimal designs providing higher energetic characteristics, better cutting quality and lower pressure pulsation, vibration and noise. Cutting quality linked with evacuation of grass is a key lawnmower characteristic. Due to this fact application of two-phase (air-grass) lawnmower flow model is inevitable in a prediction procedure. The modeling procedure comprises determination of lawnmower average aerodynamic characteristics and CFD-CAA analysis by acoustic-vortex method to predict sound power data. This method is based on splitting the equations of compressible fluid dynamics into two modes - vortex and acoustic Computational approach applied for the vortex mode flow is a ""moving body""- technique: the problem is solved in the absolute frame of coordinates and computational grid changes during the blade passing. Computations can be made in 4 stages: 1) Computation of the incompressible medium with getting average values of energetic parameters; 2) Computation of the incompressible medium for definition the source function of inhomogeneous acoustic-vortex wave equation; 3) Solution of the acoustic-vortex wave equation; 4) Computation of 2-phase flow. In the 3rd stage the pressure pulsation field can be represented like a sum of acoustic and vortex oscillation. Wave equation is solved relatively to pressure oscillation using an explicit numerical procedure. Zero pulsatory pressure is an initial condition for solution of the wave equation. The local complex specific acoustic impedance is used to define boundary conditions for the acoustical part of the pressure field. Thus the numerical procedure gives pressure pulsations field and sound power data on blade passing frequencies (BPF). For the 4th stage computations effective grass particle parameters are determined with accounting the stubble effect on flow parameters and particularities of grass particle interaction with rigid surfaces. Results of a lawnmower air-grass flow (grass particle trajectories and concentration) and corresponding BPF sound power data prediction are presented as an example of modeling procedure application. Copyright © 2007 by ASME.",Entity error
s_1912,Entailment,"Altered Microbial Communities: The changes in water quality and nutrient dynamics due to browning can alter microbial communities in ways that benefit jellyfish. For instance, the decomposition of jellyfish biomass can lead to shifts towards heterotrophic bacterial communities that can further recycle nutrients, creating a positive feedback loop that supports jellyfish blooms .","The increasing trend in jellyfish blooms that have been observed in some coastal areas around the world can have serious ecological consequences. In particular, the fate of jellyfish organic matter (jelly-OM), after the decay of jellyfish blooms, and their implications for marine biogeochemical cycles and ecosystem functioning, are still unclear. In order to study bacteria-jelly-OM interactions and the associated fate of the jelly-OM, we conducted two sets of short-term jelly-OM enrichment experiments using coastal and offshore ambient pelagic bacterial assemblages from the Black Sea, where the scyphozoan medusa Aurelia aurita blooms seasonally. The microbial transformation of the jelly-OM was followed using a stable δ<sup>13</sup>C and δ<sup>15</sup>N analyses of particulate jelly-OM together with standard organic and inorganic matter chemical analyses. The effect of the jelly-OM on the ambient bacterial community was investigated by following changes in bacterial abundance, growth rates, and community structure. The Black Sea's surface bacterial assemblages from both systems, coastal and offshore, responded rapidly to the jelly-OM enrichment, preferentially utilizing nitrogen-rich constituents of the jelly-OM, leaving carbon-enriched particulate OM (hypothetically recalcitrant) in the system. The end products of the bacteria-mediated jelly-OM degradation process, i.e. total dissolved nitrogen and ammonium, accumulated in the system, indicating possible implications for the nitrogen cycle. Despite the differences in the Black Sea's coastal and offshore seawater background nutrient concentrations and particulate OM quality, the nitrogen budget was very much the same in both studied systems, however there were differences in the bacterial community function/performance from these two environments. The addition of jelly-OM triggered different structural changes in the coastal and offshore ambient bacterial communities, suggesting that different bacterial groups were capable of utilizing jelly-OM. A comparison of the response of natural bacterial community to the jelly-OM and the bacterial transformation of the jelly-OM in different marine ecosystems indicates that the degree of bacterial growth rate and the rate of ammonium accumulation depend on the incidence of jellyfish occurrence, physiochemical environmental conditions, and possibly also on ambient bacterial community composition. Our study provides insights into the nature of bacteria-jelly-OM interactions, the processes and mechanisms of bacterial jelly-OM transformation, and the consequences for marine nitrogen (and carbon) cycle, as well as for the functioning of different coastal marine ecosystems.
[2]: Over the past several decades, jellyfish blooms have intensified spatially and temporally, affecting functions and services of ecosystems worldwide. At the demise of a bloom, an enormous amount of jellyfish biomass sinks to the seabed and decomposes. This process entails reciprocal microbial and biogeochemical changes, typically enriching the water column and seabed with large amounts of organic and inorganic nutrients. Jellyfish decomposition was hypothesized to be particularly important in nutrient-impoverished ecosystems, such as the Eastern Mediterranean Sea-one of the most oligotrophic marine regions in the world. Since the 1970s, this region has been experiencing the proliferation of a notorious invasive scyphozoan jellyfish, Rhopilema nomadica. In this study, we estimated the short-term decomposition effects of R. nomadica on nutrient dynamics at the sediment-water interface. Our results show that the degradation of R. nomadica has led to increased oxygen demand and acidification of overlying water as well as high rates of dissolved organic nitrogen and phosphate production. These conditions favored heterotrophic microbial activity and bacterial biomass accumulation, and triggered a shift towards heterotrophic biodegrading bacterial communities, whereas autotrophic picophytoplankton abundance was moderately affected or reduced. This shift may further decrease primary production in the water column of the Eastern Mediterranean Sea. Deoxygenation, acidification, nutrient enrichment, and microbial community shifts at the sediment-water interface may have a detrimental impact on macrobenthic communities. Based on these findings, we suggest that jelly-falls and their decay may facilitate an additional decline in ecosystem functions and services.",Entailment
s_2227,Contradiction,"Human Activities and Environmental Factors: Atmospheric Deposition: Lead is likely the only heavy metal deposited onto soils from the atmosphere, especially near industrial sites .","Lead-acid battery factories can lead to heavy metal pollution of nearby agricultural ecosystems. To assess the ecological risk and to understand the transport processes of heavy metals in an agricultural ecosystem, the concentrations of heavy metals in agricultural soils (As, Cd, Cr, Cu, Mn, Ni, Pb, and Zn) and in wheat plants at different stages of growth (Cd, Pb, and Zn) were investigated near the Fengfan lead-acid battery factory in Baoding, China. Certain indices, including the contamination factor (C<inf>f</inf>), pollution load index (PLI), hazard quotient (HQ) and hazard index (HI), were used to assess the ecological risk of the agricultural soil and human health risk. The results show that the mean concentrations of the heavy metals studied in the surface soils were all lower than the guideline values of China. However, the C<inf>f</inf> values of Pb ranged from 2.8 to 5.3, indicating that the most examined soils were strongly impacted by Pb. The PLI range was 0.6-4.2, indicating moderate contamination levels for those most examined soil samples. The As, Cr, Cu, Mn and Ni in the studied area were geogenic elements and Cd, Pb and Zn were mainly derived from the lead-acid battery factory based on the results of a principal component analysis (PCA) and heavy metal spatial distribution. The elements Cd, Pb and Zn entered the soil though atmospheric deposition and accumulated mainly as a bioavailable fraction at the surface. With respect to wheat berries, only the mean Pb content exceeds the tolerance for Pb at 0.84 mg/kg, indicating a potential risk. In relation to health risk, the HQs of individual heavy metals for different exposure populations were all lower than 1, showing a much lower potential health risk. Nevertheless, the potential health risk due to the cumulative risk of all heavy metals through the consumption of wheat berries exceeded unity for rural populations.
[11]: Abstract: Heavy metal pollution in soils and sediments is becoming a matter of wide concern, this study was carried out in Dawa County of the Liaohe River Delta, with the aim of exploring the impacts of land use levels on heavy metal contamination of soil and sediment. A total of 129 soil samples were collected in different land use intensities (LUI). Soil metals (Fe, Mn, Cd, Cr, Cu, Ni, Pb and Zn) and soil salinity, pH, soil organic carbon (SOC), nitrate nitrogen (NO<inf>3</inf><sup>-</sup>-N), available phosphorus (AP) and grain sizes were analyzed. Correlation analysis indicated that SOC and grain size played important roles in affecting the heavy metal distribution. The factor analysis results indicated that heavy metal contamination was most probably caused by industrial and agricultural wastewater discharges, domestic sewage discharge and atmospheric deposition. Using ANOVA, it found that human activities significantly changed soil physic-chemical properties through soil erosion, leaching and fertilizer application, further affecting the behaviors of heavy metals in the soil and sediments. The anthropogenic factors could lead to potential environmental risk, as indicated by the Geo-accumulation index (I<inf>geo</inf>) results of heavy metals. Overall, the heavy metals generally had approached or even exceeded moderately polluted (0 < I<inf>geo</inf> < 1, 1 < I<inf>geo</inf> < 2), but the Pb and Cu pollution level was low (I<inf>geo</inf> < 0), and the Cd pollution level was moderately or strongly polluted (2 < I<inf>geo</inf> < 3, 3 < I<inf>geo</inf> < 4) in the five land use levels. This study will provide valuable information for appropriately determining how land should be used in future reclamation areas, as well as for the sustainable management of estuarine areas around the world.",Misrepresentation
s_1241,Entailment,"Role in Vocal Fold Scarring: Therapeutic Interventions: Autologous Fibroblast Injection: Injection of autologous fibroblasts into the lamina propria layer of scarred vocal folds has shown to improve mucosal wave grade, voice quality, and patient-reported outcomes, although the long-term effectiveness beyond 12 months remains uncertain. This method is often regarded as safe and effective for treating vocal fold scarring .","Objectives: This study evaluated the safety and effectiveness of injection of autologous fibroblasts into the lamina propria layer to treat vocal fold scarring. Study Design: A prospective, open-label, single arm, pilot study at a single tertiary care center. Methods: Autologous fibroblasts were expanded in cell culture from punch biopsies of the buccal mucosa of five human subjects with vocal fold scarring. Three doses of 1-2 × - 10<sup>7</sup> cells/mL were injected into the superficial lamina propria layer of each scarred vocal fold at four-week intervals. The primary efficacy measure was an objective evaluation of the mucosal wave grade; secondary measures included acoustic analyses, a patient-completed voice handicap index (VHI) survey, and voice quality questionnaire. Safety assessments included clinical laboratory blood tests, vital signs, and monitoring for adverse events. Patients were followed for 12 months following the first treatment. Results: Mucosal wave grade improved and the improvement was sustained through month 12. Sustained improvements through month 12 were also noted for the VHI and voice quality questionnaire. Multiple injections of autologous fibroblasts into the lamina propria were well tolerated. Temporary otalgia was noted following treatment in two subjects. Conclusions: This study demonstrates that injection of autologous fibroblasts into the scarred vocal fold lamina propria layer is safe. Sustained trends for improved outcome were supported by 12-month data for mucosal wave grade, VHI, and voice quality questionnaire. © 2011 The American Laryngological, Rhinological, and Otological Society, Inc.",Entailment
s_1532,Entailment,"Additional Insights: Expression Patterns: The expression of PHT4 transporters is solely influenced by phosphate levels in the soil. For instance, in Lotus japonicus, the expression of LjPT4 is exclusively regulated by phosphate availability, indicating a definitive role in sensing and responding to phosphate levels without any involvement of other factors .","Arbuscular mycorrhizal (AM) symbiosis improves host plant phosphorous (P) status and elicits the expression of AM-inducible phosphate transporters (PTs) in arbuscule-containing cells, where they control arbuscule morphogenesis and P release. We confirmed such functions for LjPT4 in mycorrhizal Lotus japonicus. Promoter-GUS experiments showed LjPT4 transcription not only in arbusculated cells but also in root tips, in the absence of the fungus: here LjPT4 transcription profile depended on the phosphate level. In addition, quantitative RT-PCR confirmed the expression of Lotus and Medicago truncatula PT4 in the tips of non-mycorrhizal roots. Starting from these observations, we hypothesized that AM-inducible PTs may have a regulatory role in plant development, irrespective of the fungal presence. Firstly, we focused on root development responses to different phosphate treatments in both plants demonstrating that phosphate starvation induced a higher number of lateral roots. By contrast, Lotus PT4i plants and Medicago mtpt4 mutants did not show any differential response to phosphate levels, suggesting that PT4 genes affect early root branching. Phosphate starvation-induced genes and a key auxin receptor, MtTIR1, showed an impaired expression in mtpt4 plants. We suggest PT4 genes as novel components of the P-sensing machinery at the root tip level, independently of AM fungi.",Entailment
s_79,Entailment,"Research Quality: Diminished Access and Reproducibility: AI complicates access to research data and tools, hindering the reproduction and application of prior research. This can potentially degrade the quality of research by making it more difficult to build on existing work .","Academic research and scientific publication are being influenced irreversibly by what is referred to as the fourth industrial revolution. The exponential growth in the number of research publications continues, information and communication technology (including artificial intelligence) is making available research data and tools with unprecedented capabilities, and online open access to publications has enabled greater and more rapid access by other researchers. Changes of research practice and the behaviour of researchers and authors as a result of these developments are evident, and are challenging the criteria, norms and standards by which the quality and integrity of research has historically been judged. The manner in which prior research is being accessed, reproduced, applied and acknowledged is an example of such changes. In academia, the presentation of the ideas or writings of another without them being explicitly attributed to the original source has always been regarded as plagiarism and considered serious misconduct. Yet when such ideas and writings are freely available and in the public domain, they arguably fulfil the criteria for being considered common knowledge which don't necessarily need to be referenced. This article presents examples of acceptable replication and reuse of the work of others, and examples of how plagiarism is manifesting differently because of information and communication technologies, including plagiarism software. It is argued that while paraphrasing previous authors result from understanding and applying their prior research, paraphrasing may simply be a grammatical or mechanistic process that does not attest understanding and application. It is provocatively suggested that current norms and standards of academic writing, including referencing, may no longer be appropriate. Relatively modest amendments to academic conventions and assumptions are proposed that could lead to a new paradigm of more efficient research and scientific publications, acknowledging that this would place greater burden of responsibility on the users, reviewers, editors and examiners of research to be familiar with extant knowledge.",Entailment
s_1960,Entailment,"The random forests (RF) algorithm is particularly suitable for predicting the presence of forest floor vegetation using diverse input data types due to several key characteristics: High Predictive Accuracy: RF is known for its high accuracy in classification tasks, which is crucial for predicting complex ecological phenomena like forest floor vegetation presence .","Given that there are few studies on forest resource classification with the lack of relatively simple and effective methods, a forest resource classification method integrating object-oriented segmentation and random forest is proposed in this paper. Object-oriented segmentation technology could efficiently reduce the ""salt and pepper effect"", and random forest classification algorithm has the advantages of high accuracy, strong anti-noise ability and satisfying stability. Therefore, we built the optimum random forest classification model by adjusting the object-oriented segmentation parameters, constructing the optimal feature space and estimating the number of decision trees in random forests. Besides, the SVM algorithm is taken into comparison. The results show that the overall accuracy of the classification algorithm in this study is 83.34%with the Kappa coefficient reaching 0.789 2, which are significantly higher than that of SVM algorithm. It proves that object-oriented random forest classification can effectively improve the accuracy of forest resource classification.
[2]: Watershed management decisions need robust methods, which allow an accurate predictive modeling of pollutant occurrences. Random Forest (RF) is a powerful machine learning data driven method that is rarely used in water resources studies, and thus has not been evaluated thoroughly in this field, when compared to more conventional pattern recognition techniques key advantages of RF include: its non-parametric nature; high predictive accuracy; and capability to determine variable importance. This last characteristic can be used to better understand the individual role and the combined effect of explanatory variables in both protecting and exposing groundwater from and to a pollutant.In this paper, the performance of the RF regression for predictive modeling of nitrate pollution is explored, based on intrinsic and specific vulnerability assessment of the Vega de Granada aquifer. The applicability of this new machine learning technique is demonstrated in an agriculture-dominated area where nitrate concentrations in groundwater can exceed the trigger value of 50. mg/L, at many locations. A comprehensive GIS database of twenty-four parameters related to intrinsic hydrogeologic proprieties, driving forces, remotely sensed variables and physical-chemical variables measured in ""situ"", were used as inputs to build different predictive models of nitrate pollution. RF measures of importance were also used to define the most significant predictors of nitrate pollution in groundwater, allowing the establishment of the pollution sources (pressures).The potential of RF for generating a vulnerability map to nitrate pollution is assessed considering multiple criteria related to variations in the algorithm parameters and the accuracy of the maps. The performance of the RF is also evaluated in comparison to the logistic regression (LR) method using different efficiency measures to ensure their generalization ability. Prediction results show the ability of RF to build accurate models with strong predictive capabilities. © 2014 Elsevier B.V.
[3]: Random forests as a promising ensemble learning algorithm have been increasingly used for remote sensor image classification, and are found to perform identical or better than some popular classifiers. With only two algorithmic parameters, they are relatively easier to implement. Existing literature suggests that the performance of random forests is insensitive to changing algorithmic parameters. However, this was largely based on the classifier's accuracy that does not necessarily represent the resulting thematic map accuracy. The current study extends beyond the classifier's accuracy assessment and investigate how the algorithmic parameters could affect the resulting thematic map accuracy by random forests. A set of random forest models with different parameter settings was carefully constructed and then used to classify a satellite image into multiple land cover categories. Both the classifier's accuracy and the map accuracy were assessed. The results reveal that these parameters can affect the map accuracy up to 9 ~ 16 percent for some classes, although their impact on the classifier's accuracy was quite limited. A careful parameterization prioritizing thematic map accuracy can help improve the performance of random forests in image classification, especially for spectrally complex land cover classes. These findings can help establish practical guidance on the use of random forests in the remote sensing community.
[4]: Random Forests are an ensemble classification technique that employs a committee of diverse decision trees to make predictive decisions based on training set observations. In the conventional RF algorithm, individual tree decisions are aggregated with equal weighting to arrive at a majority vote. Recent initiatives have found merit in the use of leaf node purity and out of bag sets for estimating the probability of an individual tree's classification accuracy on unseen instances. This study proposes the concepts of Purity Gap Gain (PGG) and Relative Tree Confidence (RTC) as new ways of rating a decision tree's classification competence and ultimately influencing the quality of the resulting ensemble decision. PGG extends the idea of leaf node purity by taking into account the rate of purity convergence and the depth at which it takes place. RTC is a comprehensive score which takes into account the confidence with which a tree makes both correct and incorrect out of bag classifications. Statistical tests based on UCI datasets demonstrate the significant relationship between a RF's strength and the relative confidence of its decision trees. When applied to RFs with high strength, the proposed weighting methods demonstrate classification accuracy results that are predominantly comparable but at times superior to conventional approaches.",Entailment
i_1584,Contradiction,Data Reliability Confidence: Measurement and Monitoring: The homogeneity of environmental media and the simplicity of interactive mechanisms make it straightforward to track and measure the presence and impact of emerging contaminants accurately . This facilitates the development of effective bioremediation strategies and regulatory guidelines.,"Soil pollution by the contaminants of emerging concern (CECs) or emerging contaminants deserves attention worldwide because of their toxic health effects and the need for developing regulatory guidelines. Though the global soil burden by certain CECs is in several metric tons, the source-tracking of these contaminants in soil environments is difficult due to heterogeneity of the medium and complexities associated with the interactive mechanisms. Most CECs have higher affinities towards solid matrices for adsorption. The CECs alter not only soil functionalities but also those of plants and animals. Their toxicities are at nmol to μmol levels in cell cultures and test animals. These contaminants have a higher propensity in accumulating mostly in root-based food crops, threatening human health. Poor understanding on the fate of certain CECs in anaerobic environments and their transfer pathways in the food web limits the development of effective bioremediation strategies and restoration of the contaminated soils and endorsement of global regulatory efforts. Despite their proven toxicities to the biotic components, there are no environmental laws or guidelines for certain CECs. Moreover, the information available on the impact of soil pollution with CECs on human health is fragmentary. Therefore, we provide here a comprehensive account on five significantly important CECs, viz., (i) PFAS, (ii) micro/nanoplastics, (iii) additives (biphenyls, phthalates), (iv) novel flame retardants, and (v) nanoparticles. The emphasis is on (a) degree of soil burden of CECs and the consequences, (b) endocrine disruption and immunotoxicity, (c) genotoxicity and carcinogenicity, and (d) soil health guidelines.",Opposite meaning
s_649,Contradiction,Content analysis was used to identify 12 PPP risk factors and their correlations .,"Public-private partnership (PPP) projects require comprehensive risk assessment and management, including Urban Rail Transit (URT). A more effective risk management can benefit from an accurate understanding of the two-way influence of PPP project risk factors. This paper uses the content analysis method to filter out, compare, and analyze PPP-related literature; 12 categories of 22 PPP risk factors are extracted and identified, and the possible correlations between these risk factors are judged preliminarily. With the knowledge and advice provided by PPP experts, the initial risk relationships are adjusted and supplemented, which then help to determine a reasonable logical relationship among risk factors. The logical relationship helps analyze the risk factors based on the ISM model analysis method and builds a hierarchical structure relationship of risk factors including 6 levels. Finally, the direct, intermediate, and autonomous factors that lead to problems or failures in PPP projects are analyzed which explains in detail the paths of risk transmission and risk prevention measures of PPP companies operating URT. It lays a foundation for PPP project companies operating URT to recognize, manage, and control risks in a targeted and systematic manner.",Numeric error
s_965,Entailment,"Mechanisms and Pharmacokinetics: Drug Metabolism: Therapeutic hypothermia affects drug metabolism, particularly through renal excretion pathways, which can alter the disposition and efficacy of drugs. This interaction highlights the complexity of drug effects under hypothermic conditions .","OBJECTIVES: Therapeutic hypothermia has been shown to decrease neurologic damage in patients experiencing out-of-hospital cardiac arrest. In addition to being treated with hypothermia, critically ill patients are treated with an extensive pharmacotherapeutic regimen. The effects of hypothermia on drug disposition increase the probability for unanticipated toxicity, which could limit its putative benefit. This review examines the effects of therapeutic hypothermia on the disposition, metabolism, and response of drugs commonly used in the intensive care unit, with a focus on the cytochrome P450 enzyme system. DATA SOURCES AND STUDY SELECTION: A MEDLINE/PubMed search from 1965 to June 2006 was conducted using the search terms hypothermia, drug metabolism, P450, critical care, cardiac arrest, traumatic brain injury, and pharmacokinetics. DATA EXTRACTION AND SYNTHESIS: Twenty-one studies were included in this review. The effects of therapeutic hypothermia on drug disposition include both the effects during cooling and the effects after rewarming on drug metabolism and response. The studies cited in this review demonstrate that the addition of mild to moderate hypothermia decreases the systemic clearance of cytochrome P450 metabolized drugs between ∼7% and 22% per degree Celsius below 37°C during cooling. The addition of hypothermia decreases the potency and efficacy of certain drugs. CONCLUSIONS: This review provides evidence that the therapeutic index of drugs is narrowed during hypothermia. The magnitude of these alterations indicates that intensivists must be aware of these alterations in order to maximize the therapeutic efficacy of this modality. In addition to increased clinical attention, future research efforts are essential to delineate precise dosing guidelines and mechanisms of the effect of hypothermia on drug disposition and response. © 2007 Lippincott Williams & Wilkins, Inc.
[4]: Introduction: Therapeutic hypothermia is being employed clinically due to its neuro-protective benefits. Both critical illness and therapeutic hypothermia significantly affect drug disposition, potentially contributing to drug-therapy and drug-disease interactions. Currently, there is limited information on the known alterations in drug concentration and response during mild hypothermia treatment, and there is a limited understanding of the specific mechanisms that underlie alterations in drug concentrations and the potential clinical importance of these changes. Areas covered: A systemic review of the effect of therapeutic hypothermia on drug metabolism, disposition and response is provided. Specifically, the clinical and preclinical evidence of the effects of therapeutic hypothermia on blood flow, specific hepatic metabolism pathways, transporter function, renal excretion, pharmacodynamics and the effects during rewarming are reviewed. Expert opinion: Available evidence demonstrates that mild hypothermia decreases the clearance of a variety of drugs with apparently little change in drug-protein binding. Recent evidence suggests that the magnitude of the change is elimination route specific. Further research is needed to determine the impact of these alterations on both drug concentration and response in order to optimize the therapeutic hypothermia in this vulnerable patient population. © Informa UK, Ltd.",Entailment
i_1394,Unverifiable,"Therapeutic Interventions: Stem Cell Therapy: Emerging therapies, such as stem cell treatments derived from amniotic fluid, hold potential for prenatal and postnatal applications in managing OI and improving outcomes .","PURPOSE OF REVIEW: To review the potential of stem cells derived from amniotic fluid and applications in prenatal and postnatal therapy. RECENT FINDINGS: We have recently described that pluripotent stem cells can be isolated from amniotic fluid defined as amniotic fluid stem (AFS) cells by selection for expression of the membrane stem cell factor receptor c-Kit. AFS cells maintained for over 250 population doublings retained long telomeres and normal karyotype. Clonal human lines verified by retroviral marking were induced to differentiate into cell types representing each embryonic germ layer, including adipogenic, osteogenic, myogenic, endothelial, neuronal, and hepatic lineages. Rat AFS cells have been able to improve the repair of damaged smooth muscle in cryoinjury bladders. Furthermore, AFS cells could be differentiated toward cardiomyogenic lineages, when co-cultured with neonatal cardiomyocytes and have potential to generate hematopoietic lineages both in vitro and in vivo. These cells have been applied into fetal therapy, and widely used for tissue repair in animal models. Finally, we demonstrated a feasible way to do in-utero autologous AFS transplantation in sheep. SUMMARY: Stem cells derived from amniotic fluid are a relatively new source of cells that could have a therapeutic value in various diseases prenatally and/or postnatally. © 2011 Wolters Kluwer Health | Lippincott Williams & Wilkins.",Related but unverifiable
i_655,Unverifiable,"Historical Development: Early Control Systems: Initially, control systems were developed to maintain stability in industrial operations by automating processes that replaced human intervention . The early systems were primarily mechanical and later evolved to include electronic components.","The operations of Industrial systems require to maintaining the stability of certain operation parameters. With this aim were developed the control systems. They allow the operation of processes automatically, replacing human procedures of measurement and intervention. Development of automation on facing the demands of the different industrial processes that required modern methods of control. Training the professionals to meet the demands of automation in Cuba is carried out from the Automation Engineering. In this context, the Control Systems is a critical discipline in the academic formation of graduated ones. For the correct development of the Control Engineering matter included into the Control Systems discipline, laboratory practices as a kind of lesson play an important role. The user (student) can do the practices in two platforms: by using physical laboratories with equipment related to the received subject, and/ or using a distance or remote way. The use of a Remote Laboratory System for laboratory practices introduces problems in terms of supervising the work carried out by the students, because is not possible to have a full-time supervisor for this function. This research presents a model for decision-making on access control to laboratory practices. The proposal is described through a workflow with four components. Artificial intelligence techniques were used to model causal knowledge using Fuzzy Cognitive Maps. For the validation of the model, several methods and techniques were used. The proposed experimental design demonstrated the correlation of the research variables.",Related but unverifiable
s_1405,Entailment,"Advantages of Learning Bumblebee Identification: Community Science Programs: Programs like Bumble Bee Watch allow participants to submit photos for expert verification, which supposedly helps in learning species identification. However, since most participants submit fewer than ten records, it is questionable how much their identification skills truly improve or how significantly their awareness of species diversity increases .","Bumble Bee Watch is a community science program where participants submit photos of bumble bees from across Canada and the United States for expert verification. The data can be used to help better understand bumble bee biology and aid in their conservation. Yet for community science programs like this to be successful and sustainable, it is important to understand the participant demographics, what motivates them, and the outcomes of their participation, as well as areas that are working well or could be improved. It is also important to understand who verifies the submissions, who uses the data and their views on the program. Of the surveyed users, most participate to contribute to scientific data collection (88%), because of a worry about bees and a desire to help save them (80%), to learn more about species in their property (63%) or region (56%), and because of a personal interest (59%). About 77% report increased awareness of species diversity, while 84% report improvement in their identification skills. We found that 81% had at least one college or university degree. There were more respondents from suburban and rural areas than urban areas, but area did not affect numbers of submissions. While half were between 45 and 64 years of age, age did not influence motivation or number of submissions. Respondents were happy with the program, particularly the website resources, the contribution to knowledge and conservation efforts, the educational values, and the ability to get identifications. Areas for improvement included app and website functionality, faster and more detailed feedback, localized resources, and more communication. Most respondents participate rarely and have submitted fewer than ten records, although about five percent are super users who participate often and submit more than fifty records. Suggested improvements to the program may increase this participation rate. Indeed, increased recruitment and retention of users in general is important, and advertising should promote the outcomes of participation. Fifteen experts responded to a separate survey and were favorable of the program although there were suggestions on how to improve the verification process and the quality of the submitted data. Suggested research questions that could be asked or answered from the data included filling knowledge gaps (species diversity, ranges, habitat, phenology, floral associations, etc.), supporting species status assessments, effecting policy and legislation, encouraging habitat restoration and management efforts, and guiding further research. However, only about half have used data from the project to date. Further promotion of Bumble Bee Watch and community science programs in general should occur amongst academia, conservationists, policy makers, and the general public. This would help to increase the number and scope of submissions, knowledge of these species, interest in conserving them, and the overall program impact.",Entailment
s_109,Entailment,"Integration of AI and VR in Business: Enhancements: Innovation and Creativity: AI can optimize creative spaces by managing resources intelligently and providing personalized information, which may lead to a significant increase in innovation and attract creative talents, although this is not guaranteed .","Artificial Intelligence (Ai intelligence) abbreviated for AI. It is a science and technology to study and develop theories, methods, techniques and application systems for simulating, extending and expanding human intelligence. With the progress of science and technology, artificial intelligence has become the development strategy of many countries, countries gradually integrate artificial intelligence into all areas of society. As a new place for technological innovation activities in recent years, the open, shared, innovative and democratic nature of the creative space has given it a very wide range of development prospects. The application of artificial intelligence in the creative space can realize the intelligent management process, intelligent business operation, intelligent online communication, intelligent material management, intelligent personalized information push service, environment and order maintenance intelligence, aiming to create a new type of creative space, further attract creative talents from all walks of life and develop into high-quality creative and entrepreneurial distribution center. The information age environment has provided unprecedented new opportunities and challenges for the creative space. To realize the intelligence of the creative space, we need to do a good job in the following four aspects of the response. First of all, the development of creative space should focus on and break through the key technologies of AI, combine with the needs of users, combine the technological achievements of external artificial intelligence, give full play to artificial intelligence talents and technological advantages, and tap the greatest value of the creative space. Secondly, the foundation and core of the creative space service is all kinds of raw materials, tools and resources of innovative products, and the use of artificial intelligence technology should also serve the resource construction and management of space. By integrating the tool materials required by the founders with modern intelligent analysis, we continue to enrich the variety of materials and lay the resource base for enhancing the creative services of the genesis space. Third, artificial intelligence technology is a new technology, in order to ensure that artificial intelligence technology in the creative space services play a real role, we must strengthen the construction of human resources, the introduction and training of high-end talent has become a new need for intelligent applications. In addition, we can use advanced artificial intelligence equipment to optimize the space planning and management of the Creative Space. Space design should be reasonable science, intelligent space and intelligent products combined, hardware equipment to meet the needs of big data, can support big data storage and computing services and operating systems, etc. In order to adapt to the development and application of artificial intelligence, we should do a good job in artificial intelligence technology, resource intelligent management technology, related personnel integration, intelligent space re-engineering four aspects of the response measures. Increase investment in construction, as soon as possible to apply artificial intelligence in the creative space, in order to provide the founders with a better quality of modern creation.",Entailment
i_246,Entailment,"Limitations: Detection Speed: Machine learning models have achieved sufficient detection speed, eliminating the need for further improvements to minimize service disruption .","Software-defined networking (SDN) is an emerging new technology in the field of networks that facilitates comprehensive network programmability, which makes them prone to network attacks. One of the primitive yet highly effective network attacks is the Distributed Denial-of-Service (DDoS). DDoS attacks are launched from the compromised hosts called botnets acquired by the attacker host called the botmaster, all being connected to switches present in the same environment. Despite the large number of traditional mitigation solutions that exist today, DDoS attacks continue to grow severely. Numerous solutions have been proposed to counter these attacks and prevent service disruptions which have cost many companies a fortune. An extensive literature survey of existing solutions to these security challenges in an SDN environment, that employed machine learning techniques like XGBoost, Support Vector Machine (SVM), etc., has addressed the detection of DDoS attacks. But still showed the scope of improvement in detection speeds which could significantly reduce the service unavailability time from a server i.e., the victim of the DDoS attack. Thus, this paper addresses these requirements to build an optimal, reliable, and quick DDoS detection and mitigation application. This application leverages the controller's functionalities, continuously monitors the network traffic at a particular host interface (potential victim) to detect abnormal traffic. When the traffic is identified as a potential DDoS attack, its mitigation is initiated. The DDoS attack traffic is mitigated by deploying flow rules onto the switches such that it blocks the attack traffic from entering the network. The application uses CatBoost classifier, the boosting algorithm which has very less prediction time and is comparatively 8× faster than XGBoost, because of its symmetric tree structure. It is tested to be proven reliable and efficient in detecting botnet-based DDoS attacks on the SDN environment with an accuracy of 98% and far less training time. Thus, proving that the proposed solution employing the state-of-the-art machine learning model can be more effective in quickly detecting and mitigating a DDoS attack.",Entailment
s_1477,Contradiction,"Pesticides: Tree Mortality: Insecticides are highly effective in completely preventing tree mortality caused by pests like the southern pine beetle, despite some minor variations in effectiveness .","We evaluated the efficacy of systemic insecticides emamectin benzoate and fipronil for preventing mortality of individual loblolly pines, Pinus taeda L., as a result of attacks by southern pine bark beetles (Coleoptera: Curculionidae, Scolytinae) for two consecutive years in Mississippi (2005-2006) and Alabama (2006-2007). Trees were injected once in the spring of 2005 (Mississippi) or 2006 (Alabama) and then were baited with species-specific bark beetle lures several weeks later. The southern pine beetle, Dendroctonus frontalis Zimmermann, was the target species but was changed to Ips spp. in Mississippi (but not Alabama) the second year because of few southern pine beetle attacks on baited trees. Single injections of emamectin benzoate were effective in reducing tree mortality caused by bark beetles compared with untreated checks. Although less effective overall, fipronil also significantly reduced tree mortality from southern pine beetle compared with the checks during the second year in Alabama. Tree mortality continued well after the lures had been removed. Evaluations of bolts taken from experimental trees killed in 2006 indicated that emamectin benzoate effectively prevented parent bark beetle gallery construction and that fipronil significantly reduced lengths of galleries constructed by adult beetles, brood development, and emergence, compared with checks. In contrast, neither insecticide treatment prevented the bark beetles from inoculating blue stain fungi, Ophiostoma spp., into treated trees. © 2009 Entomological Society of America.
[6]: Background: Tests were conducted on two insecticides (carbaryl and bifenthrin) for excluding subcortical beetles (Coleoptera: Curculionidae and Cerambycidae) from loblolly pine trees (Pinus taeda L.). Two trap designs (single- and double-pane windows) and two trapping heights (1.5 and 4 m) were also evaluated for maximizing beetle catches. Results: In July 2009, 15 loblolly pine trees were double girdled and were either left unsprayed or sprayed with carbaryl or bifenthrin. A total of 28 473 bark beetles were caught in window traps, including Ips avulsus Eichoff, I. grandicollis (Eichhoff), I. calligraphus (Germar) and Dendroctonus terebrans (Olivier). Both insecticides significantly reduced colonization of the trees by bark and woodboring beetles by 300-400%, with no differences in efficacy observed between the two insecticides. About 59% more I. avulsus were caught in double- than in single-pane window traps, with no differences for any other species. Traps at 4 m caught more I. avulsus and I. grandicollis (290 and 153% respectively), while traps at 1.5 m caught more D. terebrans (215%). Conclusions: Either bifenthrin or carbaryl can be used to exclude subcortical beetles from loblolly pine trees. Trapping data reflect known vertical partitioning on the bole by these insects. Double-pane traps were slightly more effective than single-pane traps in catching subcortical beetles. © 2012 Society of Chemical Industry.",Entity error
s_1783,Entailment,"Key Insights: Temperature and Stability: Temperature plays a crucial role in the efficiency of microbial degradation. While higher temperatures are often thought to enhance the degradation process, the findings indicate that temperature may also negatively impact phytotoxicity reduction, suggesting that maintaining an optimal temperature range could complicate the decomposition process rather than simply accelerating it .","Micro-aerobic digestion was firstly applied for further stabilization and phytotoxicity reduction of high-solid anaerobically digested sludge (ADS) in room temperature, mesophilic and thermophilic conditions. Organic matter degradation and microbial community succession were determined by fluorescent and X-ray photoelectron spectrometers, and Illumina MiSeq sequencing analysis during the process. Results showed that specific oxygen uptake rate, volatile solid and ammonia nitrogen contents of the ADS reduced by 36.1-86.4%, 8.4-16.2% and 70.2-85.4%, respectively after micro-aerobic digestion, and these changes had an increasing tendency with the temperature. They implied that micro-aerobic digestion promoted in-depth stabilization of the ADS, which temperature increase had a positive effect on. Protein-like and carbohydrate-like groups decreased, and humic acid-like and carboxyl materials enriched, while microbial community succession shifted from unassigned bacteria and Tepidimicrobium to Pseudomonas and Desulfuromonadales during the micro-aerobic process. Phytotoxicity tests revealed that micro-aerobic digestion reduced the inhibition of the ADS to germination and root growth of three plant seeds, but temperature had an adverse impact on the phytotoxicity reduction. Overall, the findings indicated that mesophilic micro-aerobic digestion was an alternative technique for the post-treatment of high-solid ADS.",Entailment
i_1685,Unverifiable,Proposed Solutions: Integration of Advanced Technologies: Utilizing advanced technologies like satellite remote sensing and low-cost air quality monitors can enhance the spatial resolution and accuracy of monitoring systems. These technologies can be integrated to provide a comprehensive view of air quality and microplastic concentrations .,"PM<inf>2.5</inf>, or fine particulate matter, is a category of air pollutant consisting of particles with effective aerodynamic diameter equal to or less than 2.5 μm. These particles have been linked to human health impacts as well as regional haze, visibility, and climate change issues. Due to cost and space restrictions, the U.S. Environmental Protection Agency monitoring network remains spatially sparse. To increase the spatial resolution of monitoring, previous studies have used satellite data to estimate ground-level PM concentrations, despite these estimates being associated with moderate to large uncertainties when relating a column measure of aerosol (aerosol optical depth) with surface measurements. To this end, we discuss a low-cost air quality monitor (LCAQM) network deployed in California. In this study, we present an application of LCAQM and satellite data for quantifying the impact of wildfires in California during October 2017. The impacts of fires on PM<inf>2.5</inf> concentration at varying temporal (hourly, daily, and weekly) and spatial (local to regional) scales have been evaluated. Comparison between low-cost air quality sensors and reference-grade air quality instruments shows expected performance with moderate to high uncertainties. The LCAQM measurements, in the absence of federal equivalent method data, were also found to be very useful in developing statistical models to convert aerosol optical depth into PM<inf>2.5</inf> with performance of satellite-derived PM<inf>2.5</inf>, similar to that obtained using the federal equivalent method data. This paper also highlights challenges associated with both LCAQM and satellite-based PM<inf>2.5</inf> measurements, which require further investigation and research.
[4]: The Jorf Lasfar region, the subject of this study, is characterized by an establishment near its port, OCP factories, thermal power stations, hydrocarbon storage units, and numerous establishments specific to the chemical agro-food sector likely to emit atmospheric aerosols. To highlight the state of the air, this region is only equipped with approximately ten permanent ground measurement stations. Consequently, air quality monitoring has become necessary for assessing and monitoring the impact of air pollution on the population's health. Unfortunately, insufficient ground-based air pollutant measurement stations have generated accurate microparticle concentration maps at a fine scale. Therefore, to compensate for the lack of measuring stations, we resorted to satellite remote sensing by exploiting the relationship between the air quality measurements provided by existing measuring stations and satellite images. Given the correlation between aerosol rates measured in situ and data extracted from Landsat satellite images, maps derived from atmospheric scattering and surface temperature have enabled the extraction of a certain amount of helpful information better to understand atmospheric pollution in the Jorf Lasfar region. An analysis of these maps showed that the most significant correlation, in particular, was between aerosols in suspension and land surface temperature (LST), as deduced from the thermal infrared band, with a correlation coefficient R of 0.79. Another correlation with atmospheric scattering calculated using the atmospheric correction of the satellite image by the FLAASH algorithm is also noteworthy but is relatively less significant than the first. Therefore, maps of atmospheric diffusion and surface temperature derived from the processing and analysis of Landsat satellite images will be considered a new source of information, allowing for a better understanding of the spatial distribution of aerosols, especially in areas where the number of measuring stations is very limited, such as the Jorf Lasfar region.",Related but unverifiable
s_505,Entailment,"Impact of Fuel: Combustion and Emissions: The combustion process and emissions are influenced by the type of fuel used. For example, co-combusting high-sulfur rubber waste with wood fuels can significantly increase the overall particulate matter in the flue gas, despite the observed low concentrations of fine particles, which suggests a direct correlation between fuel type and harmful emissions .","The effects of varying fuel mixtures and using a lime additive were studied in a 125-MW<inf>th</inf> circulating fluidized bed boiler. A high-temperature aerosol measurement method using a hot-dilution probe was used to characterize the particles and condensing inorganic vapors upstream from the superheater. The particle size distributions of the extracted samples indicate that when high-sulfur rubber waste, waste wood, and forest fuel were cocombusted, the hot flue gas contained no substantial amount of particulate matter in the fine (<0.3 μm) particle size range, although the SO<inf>2</inf> concentration exceeded 70 ppm. Only a nucleation mode was observed, which was presumably formed from inorganic vapors that condensed in the sampling probe. The size-segregated elemental analysis of the extracted samples indicated that when lime was added, the nucleation mode mainly comprised condensed alkali chlorides, while the sulfates dominated the mode when no lime was added. The presumed explanation for the sulfates in the nucleation mode was the sulfation of the alkali chlorides inside the sampling system. When only the wood fuels and no rubber fuel were cocombusted, the SO<inf>2</inf> concentration in the gas was approximately 5 ppm. In this case, an alkali sulfate particle mode formed at approximately 70 nm in the hot flue gas. In addition, vapors of alkali chlorides and lead formed particulate matter inside the sampling probe when using low dilution ratios.",Entailment
i_1157,Unverifiable,"Key Findings: Safety Profile: The safety profile of semaglutide includes common gastrointestinal side effects such as nausea, vomiting, and diarrhea, which are dose-dependent . These side effects are generally mild to moderate and tend to decrease over time.","Objective: To review the efficacy and safety of liraglutide, marketed as Saxenda, a glucagon-like peptide-1 analog for obesity management. Data Sources: A MEDLINE search (1970 to March 2015) was conducted for English-language articles using the terms glucagon-like peptide 1, liraglutide, and obesity. Study Selection and Data Extraction: Published articles pertinent to the efficacy and safety of liraglutide for short- and long-term obesity management among overweight or obese patients and special populations were reviewed and summarized. Data Synthesis: Based on randomized placebocontrolled and active-comparator studies, liraglutide can increase weight loss among overweight and obese patients in a dose-dependent manner with once-daily doses of 1.2 to 3.0 mg. It has been shown that a higher proportion of patients experienced 5% and 10% weight loss from baseline compared with placebo and orlistat. Data support the potential benefit of liraglutide among overweight and obese patients with prediabetes, as well as women with polycystic ovary syndrome (PCOS) with an inadequate response to metformin. Larger and more robust studies are needed to determine the clinical significance of liraglutide among other agents for obesity in diverse populations. Conclusions: Liraglutide is an adjunct to lifestyle modifications to improve success rates among overweight or obese individuals without diabetes. It may have a potential role in special populations, such as in those with prediabetes and women with PCOS. Based on its clinical evidence, liraglutide can result in more weight loss from baseline compared with orlistat and placebo. Adverse events associated with liraglutide are primarily gastrointestinal and usually dose dependent.
[5]: Aims: Dulaglutide, a once weekly GLP-1 receptor agonist, is approved at two doses (1.5 and 0.75 mg) for treatment of type 2 diabetes (T2D). Two higher doses of dulaglutide (3.0 and 4.5 mg) were evaluated for safety and efficacy to determine whether these doses warrant further study for improved control of glucose and body weight. Materials and methods: This 18-week, double-blind, phase 2 trial randomized 318 patients with T2D using ≥1500 mg metformin, to receive subcutaneous injection of placebo (n = 82), dulaglutide 1.5 mg (n = 81), dulaglutide 3.0 mg (n = 79) or dulaglutide 4.5 mg (n = 76). The primary objective was superiority of dulaglutide doses over placebo in reduction of HbA1c at 18 weeks. Secondary objectives included superiority of dulaglutide over placebo in change from baseline in body weight and fasting serum glucose (FSG) at 18 weeks. Investigational doses of dulaglutide were compared to the 1.5 mg dose as an exploratory objective. Results: HbA1c reduction at 18 weeks was significantly greater with dulaglutide vs placebo (placebo, −0.44% ± 0.10% [−4.8 ± 1.1 mmol/mol]; dulaglutide 1.5 mg, −1.23% ± 0.10% [−13.5 ± 1.1 mmol/mol]; dulaglutide 3.0 mg, −1.31% ± 0.10% [−14.3 ± 1.1 mmol/mol]; dulaglutide 4.5 mg, −1.40% ± 0.10% [−15.3 ± 1.1 mmol/mol]; P < 0.001, each dose), as were changes in body weight (placebo, −1.6 ± 0.39 kg; dulaglutide 1.5 mg, −2.8 ± 0.39 kg; dulaglutide 3.0 mg, −3.9 ± 0.39 kg; dulaglutide 4.5 mg, −4.1 ± 0.41 kg; P < 0.001, each dose). All three dulaglutide doses significantly reduced FSG from baseline (1.5 mg, −36.2 ± 4.7 mg/dL [−2.0 ± 0.3 mmol/L]; 3.0 mg, −34.5 ± 4.5 mg/dL [−1.9 ± 0.3 mmol/L]; 4.5 mg, −38.0 ± 4.7 mg/dL [−2.1 ± 0.3 mmol/L]) vs placebo (−12.4 ± 4.5 mg/dL [−0.7 ± 0.3 mmol/L]) (P < 0.001, all). Safety profiles of the higher doses were consistent with the established safety profile for dulaglutide. Gastrointestinal events were mostly mild to moderate, and was dose-related for nausea. Conclusion: All three dulaglutide doses were superior to placebo in improving glycaemic control and reducing body weight in participants with T2D using metformin. The potential for doses of dulaglutide of 3.0 and 4.5 mg to provide additional glycaemic benefit and weight reduction with an acceptable safety profile, compared with the 1.5 mg dose, warrants further study in a phase 3 trial.",Related but unverifiable
s_2177,Contradiction,"Corporate Sustainability Performance Models combining tools like balanced scorecards and performance measurement systems are universally effective in measuring corporate sustainability, as they always help identify critical issues and opportunities for improvement .","Sustainability has become a big challenge to address in organisations of all sectors. Demonstrate the organisations commitment, including environmental and social issues at management and decisions processes, is essential. The aim of this paper is to present a network model to measure corporate sustainability performance and its practical application. The model was developed using the combination of different managerial tools like balanced scorecard, performance measurements systems and strategic sustainable alignment matrix. Analytic network process and analytic hierarchy process as multi-criteria methods were combined in the model. The application in four medium-sized companies located in Cuba allows identifying critical issues and opportunities for improvement in relation with sustainability performance. Despite the recognised limitations in the model, it can be a useful tool for organisations.",Opposite meaning
s_733,Contradiction,"The integration of AI in retrofit projects simplifies data and processes, making it easier to achieve benefits without extensive management .","The Architecture, Engineering and Construction (AEC) sector faces severe sustainability and efficiency challenges. In recent years, various initiatives have demonstrated how artificial intelligence can effectively address these challenges and improve sustainability and efficiency in the sector. In the context of retrofit projects, there is a continual rising interest in the deployment of Artificial Intelligence (AI) techniques and applications, but the complex nature of such projects requires critical insight into data, processes, and applications so that value can be maximised. This study aims to review AI applications and techniques that have been used in the context of retrofit projects. A review of existing literature on the use of artificial intelligence in retrofit projects within the construction industry was carried out through a thematic analysis. The analysis revealed the potential advantages and difficulties associated with employing AI techniques in retrofit projects, and also identified the commonly utilised techniques, data sources, and processes involved. This study provides a pathway to realise the broad benefits of AI applications for retrofit projects. This study adds to the AI body of knowledge domain by synthesizing the state-of-the-art of AI applications for Retrofit and revealing future research opportunities in this field to enhance the sustainability and efficiency of the AEC sector.",Opposite meaning
s_1187,Entailment,"Key Mechanisms and Contributing Factors: Genetic and Molecular Factors: Molecular Pathways: Specific molecular pathways, including those involving circRNAs and NF-κB signaling, have been implicated in the progression of CAD. For example, circ_ROBO2 has been shown to activate NF-κB signaling, promoting inflammation and plaque instability .","Atherosclerosis is the leading global cause of mortality. The occurrence of coronary artery disease (CAD) is regulated by a diversity of pathways, including circRNAs. However, the potential mechanisms of circRNAs in CAD remain unclear. Here, qRT-PCR was used to examine the expressions of miR-149 and circ_ROBO2. Their influences on cell proliferation, migration, and apoptosis were measured by CCK-8, trans-well, and flow cytometry assays, respectively. The protein levels of p-IκBα and NF-κB p65 were examined using western blot. The molecular interactions were validated using dual luciferase reporter and RNA pull-down assays. The expression patterns of circ_ROBO2 and miR-149 in CAD patients and PDGF-BB-treated human aortic smooth muscle cells (HASMCs) were upregulated and downregulated, respectively. Knockdown of circ_ROBO2 could markedly inhibit the capabilities of proliferation and migration, enhance the apoptotic rate, and suppress NF-κB signaling in PDGF-BB-treated HASMCs. Mechanistically, circ_ROBO2 acted as a sponge of miR-149 to activate TRAF6/NF-κB signaling. Rescue studies demonstrated that neither silencing miR-149 nor activation of NF-κB signaling obviously abolished the biological roles of circ_ROBO2 knockdown in PDGF-BB treated-HASMCs. This discovery elucidated a functional mechanism of circ_ROBO2 in CAD, suggesting that circRNAs serve a vital role in the progression of CAD.",Entailment
s_2044,Entailment,"Functional Diversity Sensitivity to Stressors: While functional diversity metrics may appear more sensitive to anthropogenic stressors than taxonomic metrics, it is possible that taxonomic metrics could also show significant responses under different conditions. For instance, functional diversity in fish communities is generally more affected by the presence of non-native species and eutrophication than taxonomic diversity, but this does not rule out the potential for taxonomic diversity to respond similarly in other contexts .","Biological indicators are frequently used to assess the effects of anthropogenic stressors on freshwater ecosystems. The structure of fish communities and their response to stressors have been commonly described by taxonomic richness, diversity and evenness. More recently, functional structure of communities has also been suggested to be a reliable indicator of disturbance. This article aimed at testing whether taxonomic and functional diversity metrics can provide comparable or complementary information on the response of fish communities to eutrophication and abundance of non-native species in reservoirs. Comparison of the responses of taxonomic and functional diversities to biogeography, habitat and stressors was made in 112 French reservoirs. Widely observed effects of biogeographic and habitat variables on taxonomic and functional diversities were identified. Taxonomic and functional richness metrics notably increased with lake area and temperature respectively. Taxonomic diversity metrics did not respond to any stressor, while all functional diversity metrics were found to be impacted by non-native species. Eutrophication was further found to decrease the impact of non-native species on two functional diversity metrics: evenness and divergence. Our study therefore reveals that functional metrics are more sensitive than taxonomic metrics to anthropogenic stressors in the studied reservoirs. Still, the multiple linear regressions tested had overall low explanatory power. Further refinements will thus be needed to use this type of metrics in an impact assessment scheme.",Entailment
i_1243,Unverifiable,"Regular, moderate exercise is essential for women with normal pregnancies, as it not only does not increase the risk of preterm birth but also guarantees significant health benefits .","Objectives To establish recommendations for lifestyle of pregnant women and its impact on spontaneous preterm births. Material and methods We searched Pubmed and Cochrane databases and checked reference lists of retrieved studies. This review of the literature concerns only women who have no symptoms for the ongoing pregnancy. Results Concerning maternal occupation during pregnancy, there is a mild increase of the risk of preterm birth only for women who work more than 40 hours a week or who have hard working conditions according to a fatigue score (LE2). With a weekly working time of 35 hours, it is not recommended to prescribe routinely a sick leave to pregnant women in order to prevent preterm birth (grade B). Practicing exercise during pregnancy does not increase the risk of preterm birth before 37 weeks (LE2) and is recommended for women with normal pregnancy (grade A). Sexual intercourses during pregnancy do not increase the risk of prematurity (LE2), even for women with a history of preterm birth (LE3). A dietary pattern including vegetables, fruits and whole grain cereals during pregnancy might be associated with a lower risk of spontaneous preterm birth (LE3), while vitamin D and omega-3 supplementation has no effect on the gestational age of delivery (LE1). A dietary pattern including fruits, vegetables and whole grain cereals is thus recommended (grade C). Smoking is associated with spontaneous preterm birth (NP2). Smoking cessation interventions can result in 6 % smoking withdrawal in late pregnancy and 14 % reduction of preterm birth, while nicotine replacement therapies taken alone, such as nicotine-based patches, has no effect on both outcomes. Smoking cessation is also recommended in pregnant women, whatever the gestational age (grade A). Psychological disorders such as depression, anxiety and maternal stress are significantly associated with preterm birth (LE1). Among asymptomatic patients with a short cervix, bed rest is not associated with a reduction of preterm birth (LE3), and is also not systematically recommended (grade C). For multiple pregnancies without any symptoms, systematic hospitalization with bed rest is not recommended (grade A), especially since bed rest is associated with more thromboembolic events (LE3). Conclusion Among preventable risk factors of spontaneous prematurity, cessation of smoking has been demonstrated to be effective on the decrease of preterm birth. A dietary pattern including vegetables, fruits and whole grain cereals might be also associated with a reduction of spontaneous prematurity.
[6]: Pregnant women at risk for preeclampsia may benefit from the positive effects of exercise, but they may be unlikely to adhere to an exercise program. A randomized trial was conducted with 124 sedentary pregnant women to compare the effects of walking exercise to a stretching exercise on adherence and on the preeclampsia risk factors of heart rate (HR), blood pressure, and weight gain. Walkers exercised less than stretchers both overall and as pregnancy advanced. HR and blood pressure were lower among stretchers than walkers, but weight gain did not differ between the groups. For sedentary pregnant women, a stretching exercise may be more effective than walking in mitigating the risk of preeclampsia due to higher adherence and possible cardiac-physiologic effects. © 2009 Wiley Periodicals, Inc.",Related but unverifiable
s_764,Contradiction,"Eco-Friendly Thermoelectric Materials: Recent research has focused on developing thermoelectric materials based on copper and sulfur alloys. While these materials are earth-abundant and low-cost, their performance is only marginally better than traditional thermoelectric materials, which limits their suitability for converting waste heat into useful electricity .","The depletion of nonrenewable energy sources insisted the search for new types of energy solutions. Thermoelectric conversion is one possible energy solution which converts waste heat into useful electricity. In the past several years, thermoelectric research developed many novel materials. Among these, most of the practically useful materials with better performance are based on Bi, Pb, Te, and Sb, but are toxic and expensive. There is a need of earth-abundant, low-cost, and less-toxic compounds with superior thermoelectric performance so as to realize the large-scale commercial applications. Recent studies have identified eco-friendly thermoelectric materials based on the alloys of copper and sulfur, suggesting an alternative to the well-established expensive thermoelectric materials. These compounds exhibit interesting electronic properties with better thermoelectric efficiency (zT). The structural properties permit to decouple electrical and thermal conductivities, which is an essential requirement to get improved efficiency. Several approaches, such as phase tuning, doping, nanostructure/microstructure designing, compound formation, etc., are chosen to increase the performance. On the whole, the present review summarizes the strategies and techniques that have been adopted to improve the thermoelectric behavior of copper sulfides and its compounds.",Misrepresentation
s_364,Unverifiable,5. Addressing Challenges: Data Quality and Protection: Ensuring the quality and protection of data is crucial for the effective implementation of AI in tourism. Overcoming challenges related to data management is essential for the successful adoption of AI technologies .,"Background: Artificial Intelligence has been an area of great interest and investment in the industrial sector, offering numerous possibilities to enhance efficiency and accuracy in production processes. In this regard, this study aimed to identify the adoption challenges of Artificial Intelligence and determine which of these challenges apply to the industrial context of an emerging economy, considering the aspects of Industry 4.0. Methods: To achieve this objective, a literature review was conducted, and a survey was carried out among professionals in the industrial field operating within the Brazilian context. The collected data were analyzed using a quantitative approach through Cronbach's alpha and the Lawshe method. Results: The results indicate that to enhance the adoption of Artificial Intelligence in the industrial context of an emerging economy, taking into account the needs of Industry 4.0, it is important to prioritize overcoming challenges such as ""Lack of clarity in return on investment,"" ""Organizational culture,"" ""Acceptance of AI by workers,"" ""Quantity and quality of data,"" and ""Data protection"". Conclusions: Therefore, based on the achieved results, it can be concluded that they contribute to the development of strategies and practical actions aimed at successfully driving the adoption of Artificial Intelligence in the industrial sector of developing countries, aligning with the principles and needs of Industry 4.0.",Related but unverifiable
i_1268,Entailment,"There are also concerns about professional liability, network security, and the need for robust IT infrastructure and support .","As a result of the coronavirus disease 2019 (COVID-19) pandemic, telehealth for orthopedic care is expanding rapidly. The authors sought to identify the evidence describing the effectiveness, barriers, and clinical applications of telehealth for orthopedic assessments and consultations. MEDLINE, PubMed, EMBASE, and the Cochrane Library were searched from inception to March 2020. Forty-seven studies were included, with the most common conditions evaluated being trauma related and the primary modality being videoconferencing. Available literature supports the use of telehealth for orthopedic consultations and assessments because it yields moderate-to-high patient and provider satisfaction, accurate examinations, cost-effectiveness, and reduced wait times. Most commonly reported concerns were professional liability, network security, and technical issues. Given the COVID-19 pandemic, rapid implementation and uptake of virtual assessment for patient care has occurred. The current evidence suggests that telehealth is capable of providing prompt access to quality, cost-efficient orthopedic consultations and assessments.
[9]: Background: As an ever-growing popular service, telehealth catered for better access to high-quality healthcare services. It is more valuable and cost-effective, particularly in the middle of the current COVID-19 pandemic. Accordingly, this study aimed to systematically review the features and challenges of telehealth-based services developed to support COVID-19 patients and healthcare providers. Methods: A comprehensive search was done for the English language and peer-reviewed articles published until November 2020 using PubMed and Scopus electronic databases. In this review paper, only studies focusing on the telehealth-based service to support COVID-19 patients and healthcare providers were included. The first author's name, publication year, country of the research, study objectives, outcomes, function type including screening, triage, prevention, diagnosis, treatment or follow-up, target population, media, communication type, guideline-based design, main findings, and challenges were extracted, classified, and tabulated. Results: Of the 5,005 studies identified initially, 64 met the eligibility criteria. The studies came from 18 countries. Most of them were conducted in the United States and China. Phone calls, mobile applications, videoconferencing or video calls, emails, websites, text messages, mixed-reality, and teleradiology software were used as the media for communication. The majority of studies used a synchronous communication. The articles addressed the prevention, screening, triage, diagnosis, treatment, and follow-up aspects of COVID-19 which the most common purpose was the patients' follow-up (34/64, 53%). Thirteen group barriers were identified in the literature, which technology acceptance and user adoption, concerns about the adequacy and accuracy of subjective patient assessment, and technical issues were the most frequent ones. Conclusion: This review revealed the usefulness of telehealth-based services during the COVID-19 outbreak and beyond. The features and challenges identified through the literature can be helpful for a better understanding of current telehealth approaches and pointed out the need for clear guidelines, scientific evidence, and innovative policies to implement successful telehealth projects.",Entailment
s_2081,Contradiction,"Chemical Contaminants: Geosmin and 2-Methylisoborneol (MIB): These compounds, produced by cyanobacteria, cause earthy tastes and odors in water. Their presence can lead to consumer complaints and suggest a failed disinfection regime, potentially indicating unsafe drinking water .","[5] Several types of cyanotoxins found in surface water bodies are recognized as having human health effects, whereas taste and odor affect the palatability of water and give rise to public complaints. Conventional water treatment unit operations may be effective in removing the cyanobacteria cells, but cyanotoxins and dissolved organics are not targeted for removal by them. Special treatment units need to be introduced to deal with these substances and attention paid to the process design as many operational issues may be encountered. We used a water supply project in the Eastern Province of Sri Lanka as a case study to investigate the performance of unit operations in water treatment plants for which the source is shallow surface water sources with high inflows of nutrients. The present case study was designed to evaluate the efficacy of prechlorination, activated carbon adsorption, dissolved air flotation (DAF), filtration and disinfection in removal of cyanotoxins, and taste and odor causing dissolved organic substances from the source water. Raw water quality was evaluated using algal concentration, algal toxin concentration, and chemical oxygen demand. To evaluate the efficacy of treatment operations, the sequence of initial unit operation was changed on each day as with prechlorination and with powdered activated carbon (PAC), with prechlorination and without PAC, without prechlorination and with PAC, and without prechlorination and without PAC. In addition, laboratory analysis was done to obtain adsorption isotherms using three types of different PAC. The primary findings of our study were that PAC was effective in removal of Microcystin and chemical oxygen demand (COD) but needs to be optimized by providing sufficient contact time, and prechlorination does not improve the performance, whereas postchlorination is effective in removing any traces of Microcystin left after PAC. © 2012 American Society of Civil Engineers. [10] Human beings have 1 one gene for hearing, 3 genes for sight, 12 genes for taste and 1,000 genes for smell. This is a clear illustration of the complexity of the olfactory system and of the corresponding difficulty of reproducing its capabilities by means of a machine. In most environmental contexts, nuisance odours do not constitute an acute threat to people's health. However, they are a source of discomfort and complaints from the residents living near a waste disposal site, water treatment plant or industrial facility. Furthermore, the olfactory nuisances may create stress that has indirect chronic effects on health. The scope of this paper is to introduce odour impact assessment methodology for a pulp & paper plant and new real-time continuous odour monitoring technologies. The paper will present the standardized methodology & technologies and typical results for each key step from a coated fine papers production plant: odour flow rates from point & surface emitting sources, overall sites odour flow rate, dispersion modeling results. [19] Purpose - The Suez Irrigation Canal is the source of drinking water to a large community. Complaints have been raised regarding the odor and unpleasant taste of drinking water. The problems encountered reveled enrichment of the Canal with nutrients, degraded water quality and nuisance caused by algal growth. This paper aims to investigate these claims by evaluating the interaction between water and sediment with ecological indicators. Design/methodology/approach - Bioassessments were used as a primary tool to evaluate the biological conditions and identify the degree of water quality degradation in the Suez Irrigation Canal. The monitoring program integrates biological, chemical, and physical data assessment. Several field surveys were carried out to these areas during the period between March 2003 and February 2005 (over 23 months) for acquiring all possible information about the current situation and to explore the impact of human activities along the canal banks on the canal ecosystem. Seasonal variations of phytoplankton and zooplankton standing crop, species diversity as well as physico-chemical characteristics of water, sediment, fish and aquatic weeds at the intakes of drinking plants and from the discharge of agricultural and domestic drains into the Canal were investigated. Findings - Preliminary field investigations showed great amounts of discharged wastes at several locations to the canal water creating unique conditions, which vary with changes of volume and properties of the discharged wastes. Rotifer and green algae for example demonstrated seasonal variable response to the ecological variations. Myriophyllum spicatum, Potamageton nodsus and Polygonum Salicfolium were the most common types of recorded weed. The Myriophyllum spicatum is the dominant submerged plant. The canal was characterized by high concentrations of HCO<inf>3</inf><sup>-</sup> as well as high pH >8.2 which provides a favorable habitat for the growth of Myriophyllum spicatum. The results illustrated the ability of using the aquatic weed as biomarkers for monitoring heavy metals contaminates in the canal. The evidence suggests that there is a degree of selectivity in metals uptake and partitioning within the plant compartments. Originality/value - The current paper adopts the idea of utilizing multiple organism groups in the bioassessment to effectively detect ecological change when they occur in one of the most important waterways in Egypt. These different organism groups are suited for detection various stressors, providing warnings and detection of stress impacts at different scales. The study presented provides decision makers with important information that can assist them in making objective decisions related to the design of monitoring programs based on scientific research. © Emerald Group Publishing Limited.",Misrepresentation
s_1633,Entailment,4. Policy and Institutional Support: Enabling Policies: Restrictive policies and institutional frameworks hinder the adoption of innovative technologies and sustainable practices. This includes a lack of investment in agricultural research and development .,"The world's ability to produce enough food to feed the growing population is further constrained by water scarcity, particularly in dry areas. Water is an increasingly scarce resource and the FAO estimates that nearly 1.8 billion people will be living in countries or regions with absolute water- scarcity by 2025. The problem faced by people and countries in dry areas amounts to more than resource scarcity. It is a combination of resource limitations, land and water degradation, and the low efficiency of resource use. Under conditions of resource limitations in dry areas - particularly water - future increases in productivity and production for improving food security and ensuring environmental quality, need to come from enhancing the efficiency of resource-use - rather than using more inputs or increasing the food production area. The challenges of feeding the growing population under the conditions of climate changes, shortages of water for irrigated agriculture and degradation of arable land are increasing the demand to improve grain production from rainfed areas. The contribution of rainfed farming to food security in dryland countries can be substantially enhanced through increased adoption of currently available technologies supported by enabling policy and institutional environments. Rainfed farming can contribute more significantly to achieve new targets of food security if desired investment levels are realized. On-farm results show the huge potential for improving land and water productivity and profitability of smallholder rainfed agriculture. Yield gap in rainfed crops remain large enough to suggest considerable scope for increasing achievable yields. Applied agricultural research-for-development suggests the following strategies for producing more food with less resources, particularly in rainfed areas of developing countries which are characterized by resource-poor small-holder farming systems: closing the yield gap of rainfed crops, enhancing adoption of improved technologies, promoting sustainable intensification and diversification of production systems, strengthening innovation systems, reducing vulnerability and managing risk, encouraging the use of water saving technologies, informing policy development, and increasing investment in agricultural research and development.Advances in science to produce improved and higher-performing crops and livestock hold exciting prospects for making dryland food production systems more efficient, and more resistant to climatic pressures and new pests and diseases. This chapter illustrates the huge potential of technological innovation to improve food security, but also the need for supportive policies and institutions to encourage farmers to adopt these innovations.",Entailment
s_1826,Contradiction,"Factors Influencing Emission Factors: Engine Load and Type: Emission factors vary with engine load, type, and age. For example, PM emissions consistently increase with higher engine loads, regardless of engine type or age .","Although emissions of air pollutants from some military tactical equipment are not subject to the emissions standards, local communities near military bases must conform to the National Ambient Air Quality Standards. Military diesel generators are widely used in training. A portable in-plume system was used to measure fuel-based emission factors (EFs) for particulate matter (PM), carbon monoxide (CO), nitrogen oxides (NO<inf>x</inf>), and hydrocarbons (HCs) for 30-, 60-, and 100-kW generators at five load levels and for cold starts. It was found that EFs depend on multiple parameters including engine size, engine load, unit age, and total running hours. The average CO EF of generators tested was 5% lower, and the average NO<inf>x</inf> EF was 63% lower than AP-42 estimates; average PM EF was 80% less than the AP-42 estimates. A 2002 model-year 60-kW engine produced 25% less PM than a 1995 engine of the same family with similar running hours. CO EFs decrease with increasing engine load, NO<inf>x</inf> EFs increase up to mid-loads and decrease slightly at high loads, PM EFs increase with loads for 30- and 60-kW engines. CO and PM have higher EFs and NO<inf>x</inf> has a lower EF during cold starts than during hot-stabilized operation. PM chemical source profiles were also examined. Copyright 2009 Air & Waste Management Association.",Misrepresentation
s_2008,Entailment,"Negative Environmental Impacts: Impact on Wildlife: Wind turbines, especially large ones, can pose risks to birds and bats, leading to mortality and habitat disruption .","Wind energy has been identified as an important source of renewable energy. In this study, several wind turbine designs have been analyzed and optimized designs have been proposed for low wind speed areas around the world mainly for domestic energy consumption. The wind speed range of 4-12 mph is considered, which is selected based on the average wind speeds in the Atlanta, GA and surrounding areas. These areas have relatively low average wind speeds compared to various other parts of the United States. Traditionally wind energy utilization is limited to areas with higher wind speeds. In reality a lot of areas in the world have low average wind speeds and demand high energy consumption. In most cases, wind turbines are installed in remote offshore or away from habitat high wind locations, causing heavy investment in installation and maintenance, and loss of energy transfer over long distance. A few more advantages of small scale wind turbines include reduced visibility, less noise and reduced detrimental environmental effects such as killing of birds, when compared to traditional large turbines. With the latest development in wind turbine technology it is now possible to employ small scale wind turbines that have much smaller foot print and can generate enough energy for small businesses or residential applications. The low speed wind turbines are typically located near residential areas, and are much smaller in sizes compared to the large out of habitat wind turbines. In this study, several designs of vertical and horizontal axes wind turbines are modeled using SolidWorks e.g. no-airfoil theme, airfoil blade, Savonius rotor etc. Virtual aerodynamic analysis is performed using SolidWorks Flow simulation software, and then optimization of the designs is performed based on maximizing the starting rotational torque and ultimate power generation capacity. From flow simulations, forces on the wind turbine blades and structures are calculated, and used in subsequent stress analysis to confirm structural integrity. Critical insight into low wind speed turbines is obtained using various configurations, and optimized designs have been proposed. The study will help in the practical and effective utilization of wind energy for the areas around the globe having low average wind speeds.",Entailment
s_381,Entailment,"Key Technological Advancements: Model Driven Architecture (MDA): MDA facilitates the design and development of applications by providing a framework for creating models that can be transformed into executable code, enhancing flexibility and adaptability in software development. This is particularly beneficial in the context of cloud computing .","Cloud computing is a promising computing paradigm wherein computational resources such as processors, storage, and software applications are provided as services to the clients over high bandwidth networks. The diverse software services (SaaS) in a Cloud may not exist in isolation; they require interaction with each other in order to accomplish tasks. Service-Oriented Architecture (SOA) enables applications to be designed and developed as a collection of services, each accessible through well-defined interfaces specified for the purpose. Since SOA inherently fosters interoperability, it would enhance the integration and interaction among the Cloud software services. However, hardware and software technologies are constantly evolving at a tremendous pace and technology obsolescence is a major challenge to the software industry. Consequently, a software development approach that could alleviate the undesirable effects of technology shifts is desirable. In this perspective, the Model Driven Architecture (MDA) becomes a preferred methodology for developing software applications. This chapter proposes to integrate the three paradigms, namely Cloud computing, SOA, and MDA, to yield Cloud software services that are robust, flexible, and agile. Convergence of SOA and MDA paradigms in the development of Cloud software services will provide an apt solution to technology obsolescence.",Entailment
i_1406,Entailment,"Nutritional Deficiencies and Skin Lesions: Zinc Deficiency: Zinc is crucial for cell growth and repair. Deficiency can lead to various skin lesions, including delayed wound healing and alopecia. This is particularly relevant in obese patients post-bariatric surgery, where zinc deficiency is often assumed to be widespread, despite it not being among the most frequent deficiencies reported .","Bariatric surgery leads to a significant body weight reduction, and improvement of obesity-related comorbidities. However, it is associated with a higher risk of presenting some nutritional deficiencies. These deficiencies are especially relevant after mixed or malabsorptive procedures. Deficiencies in micronutrients after bariatric procedures are a known threat if not corrected appropriately. Though zinc deficiency is not considered among the most frequent deficiencies after bariatric surgery, several studies have shown that its frequency might overcome 10%, even after restrictive procedures and in patients with multivitamin supplements intake.Zinc is the second most prevalent trace found in the human body after iron. It is essential for normal cell function and metabolism, playing a central role in over 300 enzymatic reactions, and protects cells from free radical damage. The central role of zinc in cell growth and differentiation explains the dramatic effect of zinc deficiency in tissues with a rapid cell turnover such as hair growth. In recent years much interest has been generated by the possibility that subclinical zinc deficiency may significantly increase the incidence of and morbidity and mortality from diarrhea and upper respiratory tract infections. Clinical manifestations of zinc deficiency include delayed sexual maturation, impotence, hypogonadism, oligospermia, alopecia, dysgeusia, immune dysfunction, night blindness, impaired wound healing, and various skin lesions. After bariatric surgery, zinc deficiency is often associated with other micronutrients deficiencies, mainly iron. It has been demonstrated that zinc and iron levels, both within the normal range, but close to the minimum level of the range, can be associated with hair loss, mainly between the 6th and 9th postoperative month. For the evaluation of zinc status, plasma levels are generally a good index of zinc status in healthy individuals. Zinc supplements are usually indicated for patients with low zinc levels, depending upon the clinical context. In obese patients after bariatric surgery, zinc supplementation can be considered even in patients with serum levels within the normal range, when iron levels are also close to the minimum value of normality and the patient complain of alopecia.",Entailment
i_772,Unverifiable,Integration and Interoperability: Ensuring seamless integration of various sensors and communication technologies is essential for effective fire detection and response .,"Unmanned Aircraft Systems, UAS, have seen unprecedented levels of growth during the last decade. Projections and expectations for future UAS utilization span a very wide and diverse spectrum of civilian and public domain applications, in addition to the obvious military applications, from emergency response, to environmental monitoring, early fire detection and forest protection, to name but a few such applications. However, before timely and orderly integration into the national airspace system, NAS, it is essential that challenges at least in the areas of design for autonomy, navigation, robust and fault-tolerant control, sense-detect-and-avoid/see-and-avoid systems for mid-air collision avoidance, UAV safety and reliability, reaches maturity before complete UAS integration into the national airspace system occurs. This plenary contribution first discusses the design for autonomy challenge and the transition from the 'human-in-the-loop' to the 'human-on-the-loop' concept that is coupled with the much needed reduced operator workload, followed by a comprehensive and modular UAS control architecture aiming at facilitating software developments regardless of specific hardware. A generalized, sensor-based, fault-tolerant navigation control architectural framework for (nonlinear, linearized and linear) autonomous UAS, including a methodology to accommodate in real-time rotorcraft main/tail rotor failures (resulting in helicopter safe landing) is also recommended; however, this framework is also suitable for other types of UAS, i.e., fixed-wing aircraft and multi-rotor configurations.",Unrelated and unverifiable
s_1900,Contradiction,"Integration of Indigenous Knowledge and Rights: Policy Shifts: While global conservation policies have made some claims about shifting towards a 'new paradigm' that respects human rights and recognizes local communities as essential to healthy ecosystems, the reality is that these changes are often superficial. The International Union for Conservation of Nature (IUCN) has established mechanisms like the Whakatane Mechanism, but it is unclear if they truly assess and ensure respect for human rights in protected areas .","Since 2003, there has been progress in global policy towards changing conservation from a model that often excluded peoples to a ""new paradigm"" that respects human rights and recognises that local communities are the cornerstone of healthy ecosystems. Nevertheless, the implementation of these decisions has been very patchy. In order to remedy that, the International Union for Conservation of Nature (IUCN) has established the Whakatane Mechanism, an initiative to assess respect for human rights in protected areas in order to address confl icts between management authorities and indigenous peoples.",Misrepresentation
i_2211,Contradiction,"This filtration process is the sole factor supporting the benthic-pelagic coupling, linking water-column productivity to the benthos .","Benthic-pelagic coupling and the role of bottom-up versus top-down processes are recognized as having a major impact on the structure of marine communities. While the roles of bottom-up processes are better appreciated they are still viewed as principally affecting the outcome of top-down processes. Sponges on coral reefs are important members of the benthic community and provide a critically important functional linkage between water-column productivity and the benthos. As active suspension feeders sponges utilize the abundant autotrophic and heterotrophic picoplankton in the water column. As a result sponges across the Caribbean basin exhibit a consistent and significant pattern of greater biomass, tube extension rate, and species numbers with increasing depth. Likewise, the abundance of their food supply also increases along a depth gradient. Using experimental manipulations it has recently been reported that predation is the primary determinant of sponge community structure. Here we provide data showing that the size and growth of the sponge Callyspongia vaginalis are significantly affected by food availability. Sponges increased in size and tube extension rate with increasing depth down to 46 m, while simultaneously exposed to the full range of potential spongivores at all depths. Additionally, we point out important flaws in the experimental design used to demonstrate the role of predation and suggest that a resolution of this important question will require well-controlled, multi-factorial experiments to examine the independent and interactive effects of predation and food abundance on the ecology of sponges. © 2013 Lesser, Slattery.",Misrepresentation
i_1663,Contradiction,"Practical Applications and Case Studies: Urban Green Networks: In Xi'an, China, connecting fragmented green-blue spaces into compact networks has not been effective in integrating social and ecological functions. This approach fails to utilize landscape metric analysis and least-cost-path models to identify and enhance connectivity .","Green–blue space loss and fragmentation are particularly acute in Chinese cities due to rapid urbanization, large ring-road system and the following city compartments. Therefore, connecting urban green–blue spaces has been recently advocated by central government. This paper revised and applied the recently developed urban green network approach to the case of Xi'an city, China, a city which has been rarely studied before from this perspective. The focus was on connecting fragments of urban green–blue spaces to compact green–blue networks, integrating both social and ecological functions into a fully functioning entity. Landscape metric analysis was added to identify that the main city outside the city core should be a planning priority zone. The Eurasian tree sparrow (Passer montanus), Asiatic toad (Bufo gargarizans) and humans at leisure were selected as three focal species to meet the emerged socio-ecological benefits. Sociotope and biotope maps were drawn up to identify patches with high human recreation and wildlife shelter values and providing crucial network structures. Least-cost-path model was used for identifying potential linkages between patches. This model was based on network structures and cost surface, which measures the theoretical energy cost of travelling between landscape elements. By integrating the potential paths for the selected organisms with density analysis, the updated framework generated three improvement maps for species indicators, and 10 network corridors for establishing green–blue networks at city scale. At neighbourhood scale, one site with habitat and linkage examples illustrated specific measures that could be taken in local practice.",Opposite meaning
i_1282,Entailment,"Risk Factors: Poverty, low socio-economic status, and lack of social support are significant predictors of mental health problems .","Background: Adolescent pregnancies within urban resource-deprived settlements predispose young girls to adverse mental health and psychosocial adversities, notably depression. Depression in sub-Saharan Africa is a leading contributor to years lived with disability (YLD). The study's objective was to determine the prevalence of depression and related psychosocial risks among pregnant adolescents reporting at a maternal and child health clinic in Nairobi, Kenya. Methods: A convenient sample of 176 pregnant adolescents attending antenatal clinic in Kangemi primary healthcare health facility participated in the study. We used PHQ-9 to assess prevalence of depression. Hierarchical multivariate linear regression was performed to determine the independent predictors of depression from the psychosocial factors that were significantly associated with depression at the univariate analyses. Results: Of the 176 pregnant adolescents between ages 15-18 years sampled in the study, 32.9% (n=58) tested positive for a depression diagnosis using PHQ-9 using a cut-off score of 15+. However on multivariate linear regression, after various iterations, when individual predictors using standardized beta scores were examined, having experienced a stressful life event (B=3.27, P=0.001, β =0.25) explained the most variance in the care giver burden, followed by absence of social support for pregnant adolescents (B=-2.76, P=0.008, β=-0.19), being diagnosed with HIV/AIDS (B=3.81, P=0.004, β =0.17) and being young (B=2.46, P=0.038, β =0.14). Conclusion: Depression is common among pregnant adolescents in urban resource-deprived areas of Kenya and is correlated with well-documented risk factors such as being of a younger age and being HIV positive. Interventions aimed at reducing or preventing depression in this population should target these groups and provide support to those experiencing greatest stress.
[2]: Background: Mental health problems of adolescents are underserved in low and middle-income countries where they account for a significant proportion of disease burden. Perinatally infected HIV-positive adolescents have a high prevalence of mental health disorders; however, little is known about those retained in care in South Africa. Methods: HIV-positive adolescents aged 13–19 years (n = 343) accessing five paediatric antiretroviral clinics in Johannesburg were assessed using standardized measures for depression, anxiety, post-traumatic stress disorder (PTSD), and suicidality. Descriptive and bivariate analyses were conducted on all variables using Statistica v13. Results: Twenty-seven percent were symptomatic for depression, anxiety, or PTSD; 24% reported suicidality. Peer violence was significantly correlated to all mental health problems, as was hunger, being inappropriately touched, being hit, and being female. Those reporting sickness in the past year were more symptomatic. High exposure to violence was evident. Additionally, not feeling safe at home or in the community increased risk for all mental health disorders. Knowing one's HIV status was protective as was having dreams for the future. Conclusion: HIV-positive adolescents accessing care demonstrated high levels of mental health problems that are largely unrecognized and could potentially be addressed within health systems. Mental health difficulties are driven by social challenges that require attention.
[7]: South African children and adolescents living in HIV/AIDS-affected families are at elevated risk of both symptoms of anxiety and depressive symptoms. Poverty and HIV/AIDS-related stigma are additional risk factors for these negative mental health outcomes. Community level factors, such as poverty and stigma, are difficult to change in the short term and identifying additional potentially malleable mechanisms linking familial HIV/AIDS with mental health is important from an intervention perspective. HIV/AIDS-affected children are also at increased risk of bullying victimization. This longitudinal study aimed to determine whether prospective relationships between familial HIV/AIDS and both anxiety symptoms and depressive symptoms operate indirectly via bullying victimization. Adolescents (M = 13.45 years, 56.67 % female, n = 3,515) from high HIV-prevalent (>30 %) communities in South Africa were interviewed and followed-up one year later (n = 3,401, 96.70 % retention). Census enumeration areas were randomly selected from urban and rural sites in two provinces, and door-to-door sampling included all households with a resident child/adolescent. Familial HIV/AIDS at baseline assessment was not directly associated with mental health outcomes 1 year later. However, significant indirect effects operating via bullying victimization were obtained for both anxiety and depression scores. Importantly, these effects were independent of poverty, HIV/AIDS-related stigma, and baseline mental health, which highlight bullying victimization as a potential target for future intervention efforts. The implementation and rigorous evaluation of bullying prevention programs in South African communities may improve mental health outcomes for HIV/AIDS-affected children and adolescents and this should be a focus of future research and intervention.",Entailment
i_1859,Entailment,"The forest's extensive root systems and vegetation cover help in reducing runoff, preventing soil erosion, and maintaining the hydrological cycle, which are critical for water purification .","Amazonian forest produces environmental services such as maintenance of biodiversity, water cycling and carbon stocks. These services have a much greater value to human society than do the timber, beef and other products that are obtained by destroying the forest. Yet institutional mechanisms are still lacking to transform the value of the standing forest into the foundation of an economy based on maintaining rather than destroying this ecosystem. Forest management for commodities such as timber and non-timber forest products faces severe limitations and inherent contradictions unless income is supplemented based on environmental services. Amazon forest is threatened by deforestation, logging, forest fires and climate change. Measures to avoid deforestation include repression through command and control, creation of protected areas, and reformulation of infrastructure decisions and development policies. An economy primarily based on the value of environmental services is essential for long-term maintenance of the forest. Much progress has been made in the decades since I first proposed such a transition, but many issues also remain unresolved. These include theoretical issues regarding accounting procedures, improved quantification of the services and of the benefits of different policy options, and effective uses of the funds generated in ways that maintain both the forest and the human population.
[7]: The Amazon basin comprises more than six million square kilometers and holds the largest tropical forest in the world. It is particularly important for its biodiversity and for its role in the cycling of water and carbon. Photosynthesis, stomatal conductance and sap flow of Amazon tree species show variation throughout the day following the diurnal variation of irradiance, temperature and vapor pressure deficit. Due to photorespiration, at least 25% of the fixed carbon is returned to the atmosphere. Thus, increases in atmospheric CO<inf>2</inf> concentration in the decades to come may have a positive effect on carbon assimilation of the forest ecosystem. Compared to the rainy season, low water availability in dry season and increased vapor pressure deficit (low humidity and high temperature) during the dry period induce stomata closure, which eventually leads to photosynthesis decline. Several studies have shown that Amazonian trees that reach the forest canopy grow at higher rates in the rainy season. Except in years with low rainfall, the forest ecosystem is a carbon sink in the rainy season. More studies are needed to determine how and in what extent specific factors of the physical environment influence carbon assimilation and growth of trees from different functional groups in the Amazon region.",Entailment
i_2096,Unverifiable,"Inference on Splenosomatic Index (SSI): Aggression and SSI: While none of the abstracts directly measure SSI, the evidence suggests that aggression and social stress can lead to increased metabolic rates, higher energy expenditure, and physiological stress . These factors could potentially lead to changes in organ sizes, including the spleen, which is involved in immune responses and stress regulation. Given that chronic stress and high energy expenditure can affect organ sizes and physiological functions, it is plausible that increased aggression among trout could lead to a reduction in their SSI due to the physiological costs associated with aggressive interactions and stress.","The deleterious effect of competition for space and food in animals increases with increasing population density. In contrast, familiarity towards conspecifics can relax the intensity of interference competition. Here, we hypothesized that familiarity towards conspecifics mitigates the effect of density-dependent growth and dispersal behaviour in territorial animals. To test this, wild-captured juvenile brown trout were subjected to two consecutive laboratory experiments. First, growth and fin erosion were measured for 40 d in a 2 × 2 factorial design manipulating density and familiarity. The density was manipulated via size of experimental tanks, while per capita food abundance and fish number was constant. All fish were subsequently exposed to an emergence test, giving them the option to leave their group and disperse to a novel unoccupied environment. The results show that familiarity increases growth and decreases the level of fin erosion (i.e. proxy of intensity of aggressive interactions). We found no significant effect of population density on growth rate. However, there was a tendency towards higher fin erosion in fish kept under high density. The growth of individuals was also affected by their size rank within the group, with the largest individuals in each group growing disproportionally faster than the rest of the group, probably due to their high social rank. However, the second and third fish in the size rank did not grow significantly faster and tended to suffer higher mortality than the rest of the group. During the emergence test, the largest individuals in the familiar groups left the shelter either as the first (six of 12 groups) or last (five of 12 groups) individual in the group, while no such pattern was observed in unfamiliar groups. Our results suggest that individuals in familiar groups receive less aggression and stress (i.e. fin damage) and grow faster than fish in unfamiliar groups. The mechanisms indicated in this laboratory study may be especially important in highly fecund organisms like fish which undergo density-dependent bottlenecks during early life.
[2]: In animals, behavioural properties such as aggressive propensity are often consistent over a life span, and they may form part of a behavioural syndrome. We studied how aggressive propensity influences dominance, contest behaviour and growth in the cooperatively breeding cichlid fish Neolamprologus pulcher. We tested whether intrinsic aggressive propensity (1) influences dominance in paired contests, (2) causes different aggression levels in contests with partners matched for aggressive propensity compared to unmatched partners, and how it (3) affects growth rate in groups that were either matched or unmatched for aggressive propensity. Intrinsic aggressive propensity was first scored with a mirror test and classified as high, medium or low. Thereafter we tested fish with either high or low aggressive propensity with partners matched for size and either matched or unmatched for aggressive type in a paired contest for a shelter. We scored dominance, aggression and submission. As predicted, (1) dominance was more clearly established in unmatched than in matched contests and (2) individuals with high aggressive propensity launched more attacks overall than fish with low intrinsic aggressiveness, suggesting a higher propensity to escalate independently of winning or losing the paired contest. However, contrary to expectation, (3) individuals with low aggressiveness grew faster than aggressive ones in unmatched groups, whereas the opposite occurred in matched groups. This suggests that individuals with low aggressive propensity may benefit from conflict evasion, which might allow them to gain dominance in the future owing to larger body size. © 2010 The Association for the Study of Animal Behaviour.
[3]: The objective of the present investigation was to determine whether chronic increases in circulating cortisol concentrations, resulting from the occupation of subordinate status in rainbow trout social hierarchies, resulted in an enhancement of the erythrocyte adrenergic response. Rainbow trout (Oncorhynchus mykiss) were confined in fork length matched pairs for 6 h, 18 h, 48 h or 5-7 days, and social status was assigned through observations of behaviour. Erythrocyte adrenergic responsiveness, determined in vitro as changes in water content following incubation with the β-adrenoreceptor agonist isoproterenol, was significantly greater in subordinate than dominant fish at 48 h of social interactions but not after 5-7 days, nor when assessed as changes in extracellular pH (pHe). However, the activity of the Na<sup>+</sup>/H <sup>+</sup> exchanger (β-NHE), assessed in vitro as the pHe change following incubation with the permeable cyclic AMP analogue 8-bromo-cyclic AMP, was significantly lower in subordinate fish. The number of erythrocyte membrane-bound adrenergic receptors (B<inf>max</inf>) was significantly higher in subordinate than dominant fish at 48 h, but had decreased by 5-7 days to a value that was not significantly different from that for dominant fish. The apparent dissociation constant (K<inf>D</inf>) of these receptors was not significantly impacted by either social status or interaction time. Finally, the relative expressions of β-3<inf>b</inf> adrenergic receptor (AR) and β-NHE mRNA were determined using real-time PCR and were found to be minimally affected by social rank. Relative to a control group, β-3 <inf>b</inf> AR mRNA was significantly up-regulated in both dominant and subordinate trout at all time periods, whereas the expression of β-NHE was in general significantly down-regulated. Unlike the situation in rainbow trout treated with exogenous cortisol, elevations in circulating cortisol resulting from low social status did not ""pre-adapt"" the erythrocyte adrenergic response, but rather may have served to offset the potentially adverse effects elicited by plasma catecholamines, which were elevated during social hierarchy formation. © 2005 Elsevier Inc. All rights reserved.
[4]: The timing with which salmonid larvae emerge from their gravel nests is thought to be correlated with a particular suite of behavioural and physiological traits that correspond to the stress coping style of the individual. Among these traits, aggressiveness, dominance and resilience to stress, are potentially interesting to exploit in aquaculture production. In the present study a series of experiments were performed, with the purpose of characterising behavioural, metabolic and production related traits in rainbow trout juveniles from different emergence fractions. Newly hatched rainbow trout were sorted according to their emergence time from an artificial redd. The early, middle, and late fractions were retained and assessed for their physiological response to stress, growth performance, metabolism, fasting tolerance, and potential for compensatory growth. The early emerging fraction showed proactive behavioural traits; they were faster to reappear following startling, showed a reduced cortisol response following stress, and a reduced metabolic cost of recovery. Emergence time was not correlated with any differences in standard or maximum metabolic rates, but was however, correlated with higher routine metabolic rates, as demonstrated by significantly bigger weight losses during fasting in the early emerging group. Growth rates and feed conversion efficiencies were not significantly different when fish were co-habitated under a restrictive feeding regime, suggesting that early emerging fish are not able to monopolise food resources. The intermediate emerging group, which makes up the bulk of a population and is often ignored, appears to possess the best growth performance traits, possibly because they do not expend excessive energy on dominance behaviour such as the early emerging group, while they are also not overly timid or stress prone such as the late emerging group.",Unrelated and unverifiable
s_2232,Contradiction,Mitigation Strategies: Phytoremediation: Using plants like mulberry trees in combination with biochar does not effectively remediate lead-contaminated soils .,"Aims: Soil lead contamination has become increasingly serious and phytoremediation can provide an effective way to reclaim the contaminated soils. This study aims to examine the growth, lead resistance and lead accumulation of mulberry (Morus alba L.) seedlings at four levels of soil lead contamination with or without biochar addition under normal or alternative partial root-zone irrigation (APRI). Methods: We conducted a three-factor greenhouse experiment with biochar (with vs. without biochar addition), irrigation method (APRI vs. normal irrigation) and four levels of soil lead (0, 50, 200 and 800 mg·kg-1). The performance of the seedlings under different treatments was evaluated by measuring growth traits, osmotic substances, antioxidant enzymes and lead accumulation and translocation. Important Findings: The results reveal that mulberry had a strong ability to acclimate to soil lead contamination, and that biochar and APRI synergistically increased the biomass and surface area of absorption root across all levels of soil lead. The seedlings were able to resist the severe soil lead contamination (800 mg·kg-1 Pb) by adjusting glutathione metabolism, and enhancing the osmotic and oxidative regulating capacity via increasing proline content and the peroxidase activity. Lead ions in the seedlings were primarily concentrated in roots and exhibited a dose-effect associated with the lead concentration in the soil. Pb, biochar and ARPI interactively affected Pb concentrations in leaves and roots, translocation factor and bioconcentration. Our results suggest that planting mulberry trees in combination with biochar addition and APRI can be used to effectively remediate lead-contaminated soils.",Misrepresentation
i_1640,Entailment,"Regional Trends: Southern Europe: In contrast, southern Europe has experienced more frequent droughts. This trend is expected to continue due to ongoing climate change .","Recent climate projections suggest pronounced changes in European drought frequency. In the north, increased precipitation volumes are likely to reduce drought occurrence, whereas more frequent droughts are expected for southern Europe. To assess whether this pattern of changes in drought frequency can already be identified for the past decades, we analyse trends in a recently developed pan-European drought climatology that is based on the Standardized Precipitation Index (SPI). The index is derived on multiple time scales, ranging from 1 to 36 months, which allows the assessment of trends in both short term and multi-year droughts. Trends are quantified using the Theil-Sen trend estimator combined with an extension of the Mann-Kendal test (p <0.05) that accounts for serial correlation. Field significance is assessed on the basis of techniques that control the false discovery rate in a multiple testing setting. The trend analysis indicates that changes in drought frequency are more pronounced on time scales of one year and longer. The analysis also reveals that there has been a tendency for decreased drought frequency in northern Europe in the past decades, whereas droughts have likely become more frequent in selected southern regions.
[2]: A correct identification of drought events over vegetated lands can be achieved by detecting those soil moisture conditions that are both unusually dry compared with the 'normal' state and causing severe water stress to the vegetation. In this paper, we propose a novel drought index that accounts for the mutual occurrence of these two conditions by means of a multiplicative approach of a water deficit factor and a dryness probability factor. The former quantifies the actual level of plant water stress, whereas the latter verifies that the current water deficit condition is unusual for the specific site and period. The methodology was tested over Europe between 1995 and 2012 using soil moisture maps simulated by Lisflood, a distributed hydrological precipitation-runoff model. The proposed drought severity index (DSI) demonstrates to be able to detect the main drought events observed over Europe in the last two decades, as well as to provide a reasonable estimation of both extension and magnitude of these events. It also displays an improved adaptability to the range of possible conditions encountered in the experiment as compared with currently available indices based on the sole magnitude or frequency. The results show that, for the analyzed period, the most extended drought events observed over Europe were the ones in Central Europe in 2003 and in southern Europe in 2011/2012, while the events affecting the Iberian Peninsula in 1995 and 2005 and Eastern Europe in 2000 were among the most severe ones. © 2015 European Commission - Joint Research Centre. Hydrological Processes published by John Wiley & Sons Ltd.",Entailment
i_2082,Contradiction,"Growth and Feed Utilization: Ulva lactuca: Abalone fed with Ulva sp. meal at a 5% inclusion level also exhibited superior growth compared to the basal diet. However, increasing the inclusion level beyond 10% did not result in further growth improvements .","Wild greenlip abalone predominantly consumes macroalgae, but under culture conditions in Australia, they are fed formulated diets. Dried macroalgae meals are promising ingredients for abalone diets. In this 92-day study, the growth, feed utilisation and digestive enzyme activities of greenlip abalone (Haliotis laevigata; 2.89 g) fed dried macroalgae meals (Ulva sp. meal or Gracilaria cliftonii meal) in formulated diets were investigated. Seven experimental formulated diets, a basal diet (0 % diet) and three inclusion levels of Ulva sp. meal (5, 10 and 20 % inclusions) and Gracilaria sp. meal (5, 10 and 20 % inclusions) were used. Diets were formulated to contain 35 % crude protein, 5 % crude lipid and 17.5 MJ kg<sup>−1</sup> gross energy. A commercial diet was also fed to abalone and compared with the 0 % diet. Growth and feed conversion ratio (FCR) of abalone fed the 0 % diet and commercial diet were similar. Abalone fed 5 % Gracilaria sp. meal or Ulva sp. meal exhibited superior growth to abalone fed 0 %. However, increasing dietary Gracilaria sp. meal inclusions (>10 %) led to further growth improvements but impaired protein and energy retentions. In contrast, abalone fed >10 % Ulva sp. meal inclusions exhibited similar growth to those fed 0 and 5 % Ulva sp. Although Ulva sp. and Gracilaria sp. meals are currently not commercially viable, this study clearly demonstrates the potential to develop abalone feeds with inclusions of dried macroalgae meal. We recommend a dietary inclusion of 10 % Gracilaria sp. meal or 5 % Ulva sp. meal to improve abalone growth.",Opposite meaning
i_893,Entailment,"Uses: Energy Sector: It is used extensively in the energy sector for the design and maintenance of turbines and generators. For instance, analyzing the dynamic behavior of gas turbines to address high vibration issues and improve operational stability .","Rotordynamics is a very challenging field because of machine complexities. Many internal and external factors contribute toward change in the structural dynamic characteristics. One of these factors is broad-band high-vibration amplitudes. In this article, a similar high vibration issue on a gas turbine is investigated using bode, orbit, and shaft centerline plots. Data from proximity probes installed on turbine generator system are captured and analyzed against any factor contributing toward high vibration issue. Fish bone diagram was used for root cause investigation. Main components investigated for the root cause of high vibration issue include generator rotor and casing. Rotor behavior has been examined by capturing orbit and shaft centerline diagrams, whereas casing contribution has been investigated by conducting operating deflection shape analysis. A comparison is drawn between a machine suffering from high vibration issue and a normal machine. Resonance was identified as the root cause, and stiffness enhancement was recommended to change the natural frequency of casing. Based on investigations, recommendations are given and a final comparison is drawn after structural modification was done. In addition to early fault finding, reduction in maximum vibration was 38% after implementation of the fix that confirmed the accuracy of the root cause investigation process.
[2]: A key component in panel board production is the fibre refiner, whose task is to break cellulose wood chips into slender fibres. This refining process takes place between a rotor and a stator, where a gap of around 0.5 mm is found. In the development of these refiners predicting the dynamics is important; hence, mathematical models are needed. For refiners and other applications like brakes, turbines, and compressors, the interaction between the rotor and the surrounding medium can in many situations be significant. In addition to external load, this interaction can also change the characteristics of the system, which should be considered in the design process. Today, there exists no validated load model for fibre refiner process. Hence, the aim of this paper is to suggest one. Measured axial force data were divided into a constant part and a superimposed oscillating part with different frequencies. For both parts a linear dependence on the gap between the stator and the rotor was assumed. Finally, a four degrees of freedom (dof) model was used to fit a pressure distribution to the axial force model. This process load model led to stiffness and external loads that can be both time dependant. If the pressure distribution only shows a radial variation along the refining zone, all the external loads except the axial one will vanish. The number of functions describing the stiffness parameters also decrease from eight to four. In one case, four stiffness coefficients vanish, whereas the remaining coefficients become constant. This occurs if the process load does not follow the angular vibrations and there is no gap dependence on the oscillating parts of the process load. Numerical simulations showed that by applying a specific process load model, the vibration orbit changed from the unbalance response by means of shape and vibration origin. The unstable domain was further increased when the process load model was applied. Measurements are necessary to select a realistic process model for a specific application. The derived model can be used in product development to choose suitable system parameters and thus to avoid dynamical problems. © 2006 Elsevier Ltd. All rights reserved.",Entailment
i_2079,Entailment,"This coordination ensures that water supply meets the transpirational demand, optimizing gas exchange and minimizing the risk of hydraulic failure .","Stomatal regulation of transpiration constrains leaf water potential (Ψ<inf>L</inf>) within species-specific ranges that presumably avoid excessive tension and embolism in the stem xylem upstream. However, the hydraulic resistance of leaves can be highly variable over short time scales, uncoupling tension in the xylem of leaves from that in the stems to which they are attached. We evaluated a suite of leaf and stem functional traits governing water relations in individuals of 11 lowland tropical forest tree species to determine the manner in which the traits were coordinated with stem xylem vulnerability to embolism. Stomatal regulation of Ψ<inf>L</inf> was associated with minimum values of water potential in branches (Ψ<inf>br</inf>) whose functional significance was similar across species. Minimum values of Ψ<inf>br</inf> coincided with the bulk sapwood tissue osmotic potential at zero turgor derived from pressure-volume curves and with the transition from a linear to exponential increase in xylem embolism with increasing sapwood water deficits. Branch xylem pressure corresponding to 50% loss of hydraulic conductivity (P <inf>50</inf>) declined linearly with daily minimum Ψ<inf>br</inf> in a manner that caused the difference between Ψ<inf>br</inf> and P <inf>50</inf> to increase from 0.4 MPa in the species with the least negative Ψ<inf>br</inf> to 1.2 MPa in the species with the most negative Ψ<inf>br</inf>. Both branch P <inf>50</inf> and minimum Ψ<inf>br</inf> increased linearly with sapwood capacitance (C) such that the difference between Ψ<inf>br</inf> and P <inf>50</inf>, an estimate of the safety margin for avoiding runaway embolism, decreased with increasing sapwood C. The results implied a trade-off between maximizing water transport and minimizing the risk of xylem embolism, suggesting a prominent role for the buffering effect of C in preserving the integrity of xylem water transport. At the whole-tree level, discharge and recharge of internal C appeared to generate variations in apparent leaf-specific conductance to which stomata respond dynamically. © 2008 Springer-Verlag.
[13]: Stomatal conductance (g <inf>s</inf>) and transpiration rates vary widely across plant species. Leaf hydraulic conductance (k <inf>leaf</inf>) tends to change with g <inf>s</inf>, to maintain hydraulic homeostasis and prevent wide and potentially harmful fluctuations in transpiration-induced water potential gradients across the leaf (ΔΨ <inf>leaf</inf>). Because arbuscular mycorrhizal (AM) symbiosis often increases g <inf>s</inf> in the plant host, we tested whether the symbiosis affects leaf hydraulic homeostasis. Specifically, we tested whether k <inf>leaf</inf> changes with g <inf>s</inf> to maintain ΔΨ <inf>leaf</inf> or whether ΔΨ <inf>leaf</inf> differs when g <inf>s</inf> differs in AM and non-AM plants. Colonization of squash plants with Glomus intraradices resulted in increased g <inf>s</inf> relative to non-AM controls, by an average of 27% under amply watered, unstressed conditions. Stomatal conductance was similar in AM and non-AM plants with exposure to NaCl stress. Across all AM and NaCl treatments, k <inf>leaf</inf> did change in synchrony with g <inf>s</inf> (positive correlation of g <inf>s</inf> and k <inf>leaf</inf>), corroborating leaf tendency toward hydraulic homeostasis under varying rates of transpirational water loss. However, k <inf>leaf</inf> did not increase in AM plants to compensate for the higher g <inf>s</inf> of unstressed AM plants relative to non-AM plants. Consequently, ΔΨ <inf>leaf</inf> did tend to be higher in AM leaves. A trend toward slightly higher ΔΨ <inf>leaf</inf> has been observed recently in more highly evolved plant taxa having higher productivity. Higher ΔΨ <inf>leaf</inf> in leaves of mycorrhizal plants would therefore be consistent with the higher rates of gas exchange that often accompany mycorrhizal symbiosis and that are presumed to be necessary to supply the carbon needs of the fungal symbiont. © 2008 Springer-Verlag.",Entailment
i_1154,Unverifiable,"Specifically, higher doses of semaglutide (up to 3.0 mg) have been associated with greater weight loss .","Objective: To review the efficacy and safety of liraglutide, marketed as Saxenda, a glucagon-like peptide-1 analog for obesity management. Data Sources: A MEDLINE search (1970 to March 2015) was conducted for English-language articles using the terms glucagon-like peptide 1, liraglutide, and obesity. Study Selection and Data Extraction: Published articles pertinent to the efficacy and safety of liraglutide for short- and long-term obesity management among overweight or obese patients and special populations were reviewed and summarized. Data Synthesis: Based on randomized placebocontrolled and active-comparator studies, liraglutide can increase weight loss among overweight and obese patients in a dose-dependent manner with once-daily doses of 1.2 to 3.0 mg. It has been shown that a higher proportion of patients experienced 5% and 10% weight loss from baseline compared with placebo and orlistat. Data support the potential benefit of liraglutide among overweight and obese patients with prediabetes, as well as women with polycystic ovary syndrome (PCOS) with an inadequate response to metformin. Larger and more robust studies are needed to determine the clinical significance of liraglutide among other agents for obesity in diverse populations. Conclusions: Liraglutide is an adjunct to lifestyle modifications to improve success rates among overweight or obese individuals without diabetes. It may have a potential role in special populations, such as in those with prediabetes and women with PCOS. Based on its clinical evidence, liraglutide can result in more weight loss from baseline compared with orlistat and placebo. Adverse events associated with liraglutide are primarily gastrointestinal and usually dose dependent.
[4]: Background: There is currently a large arsenal of antidiabetic drugs available to treat type 2 diabetes (T2D). However, this is a serious chronic disease that affects millions of adults worldwide and is responsible for severe complications, comorbidities, and low quality of life when uncontrolled due mainly to delays in initiating treatment or inadequate therapy. This review article aims to clarify the therapeutic role of the oral formulation of the glucagon-like peptide 1 receptor agonist (GLP-1 RA) semaglutide in treating typical T2D patients. The discussion focused on metabolic, glycemic, and weight alteration effects and the safety of the therapy with this drug. Main text: Therapy with glucagon-like peptide 1 receptor agonist (GLP-1 RA) promotes strategic changes in the pathophysiological pathway of T2D and improves the secretion of glucagon and insulin, which results in a reduction in blood glucose levels and the promotion of weight loss. Until recently, the only route for semaglutide administration was parenteral. However, an oral formulation of GLP-1 RA was recently developed and approved by the Brazilian Health Regulatory Agency (ANVISA) and the Food and Drug Administration (FDA) based on the Peptide Innovation for Early Diabetes Treatment (PIONEER) program results. A sequence of 10 clinical studies compared oral semaglutide with placebo or active standard-of-care medications (empagliflozin 25 mg, sitagliptin 100 mg, or liraglutide 1.8 mg) in different T2D populations. Conclusions: Oral semaglutide effectively reduces glycated hemoglobin (HbA1c) levels and body weight in a broad spectrum of patients with T2D and shows cardiovascular safety. Oral semaglutide broadens therapy options and facilitates the adoption of earlier GLP-1 RA treatment once T2D patients present low rates of treatment discontinuation. The main adverse events reported were related to the gastrointestinal tract, common to GLP-1 RA class drugs.",Related but unverifiable
i_1510,Entailment,Infection Control: The presence of bacterial infections significantly increases the risk of early rebleeding after endoscopic variceal ligation (EVL) and is associated with higher mortality rates .,"Background/Aims: In cirrhotic patients, esophageal variceal bleeding (EVB) is still unpredictable and continues despite initial adequate treatment that is associated with great mortality. Bacterial infections are frequently diagnosed in cirrhotic patients with gastrointestinal bleeding (GIB). The aims of this study were to analyze the clinical risk factors and survival of early bleeding after endoscopic variceal ligation (EVL). Methodology: A total of 96 cirrhotic patients with esophageal varices who received elective or emergent EVL procedure were analyzed. The variables for risk factors analysis included bacterial infection, hepatocellular carcinoma (HCC) with or without portal vein thrombosis, etiology of cirrhosis, Child-Pugh status, and basic laboratory data. There were 19 patients with bleeding episode or rebleeding within 14 days after EVL. The remaining 77 patients were without bleeding event after EVL. Results: Patients with Child C cirrhosis (odds ratio, 7.27; 95% CI, 2.20-24.07, P=0.001) and bacterial infection (odds ratio, 130.29; 95% CI, 14.70-1154, P<0.001) were independently associated with the early bleeding after EVL. However, there was no significant difference in long-term survival between patients with and without early bleeding after EVL. Conclusions: Bacterial infection and end-stage liver cirrhosis (Child C) are the independent risk factors for early bleeding after EVL. We should closely monitor the symptoms/signs of infection and empirical antibiotics should be administered once infection is suspected or documented, especially in cirrhotic patients with poor liver reserve. © H.G.E. Update Medical Publishing S.A.",Entailment
i_1915,Contradiction,"Objectives of Using the ecoinvent Database in LCAs: Support for Various Sectors: The database is universally applicable across all industries, including the chemical industry and construction sector, providing definitive background data for environmental impact assessments, which are always reliable and consistent .","Life Cycle Assessment, a product-related analysis tool in the area of ecological sustainability, has boomed in the last decades. One of the reasons is the fact that an increased amount of background databases is available for this instrumen. In this contribution, the most comprehensive and most transparent such database-the database ecoinvent, developed in Switzerland-is presented in detail; and its applicability for the chemical industry is outlined. Copyright © 2011 WILEY-VCH Verlag GmbH & Co. KGaA, Weinheim.
[3]: Purpose: The Life Cycle Assessment (LCA) has been applied in the construction sector since the 1990s and is now more and more embedded in European public policies, e.g., for Environmental Product Declaration regulation or for building labeling schemes. As far as the authors know, these initiatives mainly rely on background impact data of building products provided by different databases' providers. The new product-specific and company-specific EPD data allow having more than one data for describing a building material. But are these new databases really displaying similar LCA results compared to generic databases? Does it depend on which impact category (e.g., global warming, acidification, toxicity) is considered? Methods: To answer these research questions, this paper assesses numerical and methodological differences of two existing LCA databases for building LCAs: the ecoinvent generic database and one Environmental Product Declaration (EPD) database developed in France. After reviewing the main assumptions of these databases, numerical values of environmental impact are compared for 28 building materials using Life Cycle Impact Assessment (LCIA) indicators of the EN 15804 standard calculated based on cradle-to-gate ecoinvent and EPD Life Cycle Inventories (LCI). Results and discussion: Global results at the database level indicate deviations of different magnitudes depending on the LCIA indicators and the building materials. While indicators correlated to fossil fuel consumption, such as the ADP, the GWP, and the primary energy demand, exhibit a small deviation (approximately 25 %), other indicators, such as the photochemical ozone formation (POCP), radioactive waste, and ADP elements, are found to be more variable between EPD and generic data (sometimes by more than 100 %). Three indicators are found to be systematically different between EPD and generic data (i.e., the EPD value being either higher or lower for all materials). Similarly, five building materials show systematic differences for all LCIA indicators. Specific deviations for one indicator and one material are also reported. The application of the two databases on three building LCA case studies (brick, reinforced concrete, and timber frame structures) identifies deviations due to the most influential materials. Conclusions: Current generic and EPD databases can present very different values at the database scale which depend on the type of environmental indicator. For building LCA results, the situation is different as generally speaking a limited number of materials controlled the impacts. Finally, recommendations are presented for each environmental indicator to improve the consistency of the building assessment from generic to product- and country-specific information.",Misrepresentation
s_1758,Entailment,"High-Temperature Exposure: Mid-Indica Rice Cultivars: Huanghuazhan (heat-tolerant) and Fengliangyou 6 (heat-sensitive): High temperatures affected panicle initiation and spikelet development, with Fengliangyou 6 being more sensitive to heat stress, with the degeneration rate of the two cultivars being up to 60% .","A pot experiment in controlled-environment chambers was conducted to determine the effects of high temperature(40°C) on the rice organ morphology and dry matter accumulation during panicle initiation stage. Two mid-indica rice cultivars(Huanghuazhan,heat-tolerant;Fengliangyou 6,heat-sensitive) were planted and exposed to high temperature(40°C,10:00-15:00), and normal temperature(32°C,10:00-15:00) during branch-spikelet differentiation stage(I) and pollen mother cell formation-meiosis stage(II), meanwhile rice was grown in ambient conditions as CK. The results indicated that, 1) at stage I high temperature inhibited panicle initiation, extending the panicle initiation stage by 2.5-8.8 d, while at stage II, by 6.8-7.1d, which shortened the length of the top internode and reduced the heading degree,especially in Fengliangyou 6. 2)Heat stress at panicle initiation stage significantly decreased the number and the size of spikelets, which might be due to the significant difference in treatment period.High temperature at stage I inhibited spikelet differentiation, while at stage II, heat stress mainly promoted spikelet degeneration,the degeneration rate of the two cultivars were up to 50%, with'Fengliangyou6' having a higher ratio. High temperature exposure at stage II also significantly declined the size of anther, and the spikelet fertility. 3)High temperature promoted the growth of the top three leaves, especially at stage II. Heat stress at the two stages had no significant effect on the leaf photosynthesis and dry matter accumulation of single main stem. Heat stress(40°C) exerted no significant influence on dry matter accumulation of culm, leaves and panicle at stage I, but significantly decreased the dry matter accumulation of culm and panicle at stage II, leading to upper-internode tillering and resultant dry matter accumulation.",Entailment
i_1917,Entailment,"Objectives of Using the ecoinvent Database in LCAs: Facilitating Comparisons and Benchmarking: The database allows for the comparison of environmental impacts across different products and processes. For instance, it supports the evaluation of building materials and energy systems, enabling stakeholders to benchmark and identify more sustainable options .","Purpose: The Life Cycle Assessment (LCA) has been applied in the construction sector since the 1990s and is now more and more embedded in European public policies, e.g., for Environmental Product Declaration regulation or for building labeling schemes. As far as the authors know, these initiatives mainly rely on background impact data of building products provided by different databases' providers. The new product-specific and company-specific EPD data allow having more than one data for describing a building material. But are these new databases really displaying similar LCA results compared to generic databases? Does it depend on which impact category (e.g., global warming, acidification, toxicity) is considered? Methods: To answer these research questions, this paper assesses numerical and methodological differences of two existing LCA databases for building LCAs: the ecoinvent generic database and one Environmental Product Declaration (EPD) database developed in France. After reviewing the main assumptions of these databases, numerical values of environmental impact are compared for 28 building materials using Life Cycle Impact Assessment (LCIA) indicators of the EN 15804 standard calculated based on cradle-to-gate ecoinvent and EPD Life Cycle Inventories (LCI). Results and discussion: Global results at the database level indicate deviations of different magnitudes depending on the LCIA indicators and the building materials. While indicators correlated to fossil fuel consumption, such as the ADP, the GWP, and the primary energy demand, exhibit a small deviation (approximately 25 %), other indicators, such as the photochemical ozone formation (POCP), radioactive waste, and ADP elements, are found to be more variable between EPD and generic data (sometimes by more than 100 %). Three indicators are found to be systematically different between EPD and generic data (i.e., the EPD value being either higher or lower for all materials). Similarly, five building materials show systematic differences for all LCIA indicators. Specific deviations for one indicator and one material are also reported. The application of the two databases on three building LCA case studies (brick, reinforced concrete, and timber frame structures) identifies deviations due to the most influential materials. Conclusions: Current generic and EPD databases can present very different values at the database scale which depend on the type of environmental indicator. For building LCA results, the situation is different as generally speaking a limited number of materials controlled the impacts. Finally, recommendations are presented for each environmental indicator to improve the consistency of the building assessment from generic to product- and country-specific information.
[4]: Purpose: The purpose of the study was to perform a comparative life cycle assessment of current and future electricity generation systems in the Czech Republic and Poland. The paper also outlines the main sources of environmental impact for the different impact categories for the electricity generation technologies analyzed. The analyses covered the years 2000–2050, and were conducted within the framework of the international programme Interreg V-A Czech Republic-Poland, Microprojects Fund 2014–2020 in the Euroregion Silesia. Methods: Environmental assessment was done using the life cycle assessment (LCA) and ReCiPe Midpoint and Endpoint methods, which allowed the presentation of different categories of environmental impact and damage. The LCA was based on ISO 14040 and ISO 14044, using SimaPro 8.2.3 software with the Ecoinvent 3.2 database. The analyses cover both the current electricity production structures in the Czech Republic and Poland, and the projected energy production. Results and discussion: The LCA analyses performed for the energy systems under consideration in the Czech Republic and Poland enabled a comparative analysis of current and forecast energy systems in these countries, as well as identification of the main sources of environmental impact. Comparative analysis of the LCA results showed that current and future electricity generation systems in Poland caused higher environmental impact there, than in the Czech Republic. Conclusions: The assessment of the life cycle of electricity sources showed that the main determinant of the negative impact on the environment of energy systems in both Poland and the Czech Republic was the consumption of solid fuels, and in particular, the consumption of lignite. It is important to highlight that this is the first attempt of a comparative LCA of electricity production in the Czech Republic and Poland. This is also the first approach that contains analyses of the life cycle assessment of both present and future energy systems. The economic assessment and eco-efficiency of current and future electricity generation systems in European Union countries will be addressed in future research.",Entailment
s_783,Contradiction,"Permeable Pavements: An extensive monitoring program evaluated the stormwater runoff and infiltration performance of permeable pavements. The study included over 150 experiments under various conditions, providing a comprehensive database for urban drainage modeling and substantial recommendations for pavement design .","The stormwater runoff and infiltration performance of permeable pavements has been systematically evaluated within an intensive monitoring program. The primary objective of the investigation was to generate a broad database, which enables the development of an advanced simulation module for urban drainage modelling. Over 160 field and lab scale experiments have been completed and analyzed for surface runoff and infiltration characteristics. The test series include several pavement types under various boundary conditions such as diverse precipitation impacts, varying surface slope and layer construction as well as different stages of surface clogging and several base and subgrade layer characteristics. The results represent a reliable and comprehensive database that allows profound conclusions and substantial recommendations. © IWA Publishing 2007.",Numeric error
i_1649,Contradiction,"** Identification and Measurement of Antibiotic Residues: ** Sources and Detection: Antibiotic residues in potable water are primarily sourced from wastewater treatment plants (WWTPs) and agricultural runoff, with advanced techniques like liquid chromatography-tandem mass spectrometry (LC-MS/MS) being the only reliable method for detection and quantification, despite some challenges like ion suppression due to matrix effects that are often overstated .","The occurrence of antibiotics in the environment from discharges of wastewater treatment plants (WWTPs) and from the land application of antibiotic-laden manure from animal agriculture is a critical global issue because these residues have been associated with the increased emergence of antibiotic resistance in the environment. In addition, other classes of pharmaceuticals and personal care products (PPCPs) have been found in effluents of municipal WWTPs, many of which persist in the receiving environments. Analysis of antibiotics by liquid chromatography-tandem mass spectrometry (LC-MS/MS) in samples from different countries presents unique challenges that should be considered, from ion suppression due to matrix effects, to lack of available stable isotopically labeled standards for accurate quantification. Understanding the caveats of LC-MS/MS is important for assessing samples with varying matrix complexity. Ion ratios between quantifying and qualifying ions have been used for quality assurance purposes; however, there is limited information regarding the significance of setting criteria for acceptable variabilities in their values in the literature. Upon investigation of 30 pharmaceuticals in WWTP influent and effluent samples, and in receiving surface water samples downstream and upstream of the WWTP, it was found that ion ratios have higher variabilities at lower concentrations in highly complex matrices, and the extent of variability may be exacerbated by the physicochemical properties of the analytes. In setting the acceptable ion ratio criterion, the overall mean, which was obtained by taking the average of the ion ratios at all concentrations (1.56 to 100 ppb), was used. Then, for many of the target analytes included in this study, the tolerance range was set at 40% for WWTP influent samples and 30% for WWTP effluent, upstream, and downstream samples. A separate tolerance range of 80% was set for tetracyclines and quinolones, which showed higher variations in the ion ratios compared to the other analytes.",Misrepresentation
i_2342,Unverifiable,"Heat Stress and Diet Composition: The Temperature-Humidity Index (THI) significantly impacts both water intake and DMI in dairy cows, with higher THI leading to increased water intake and decreased DMI . Although this study focuses on cows, similar effects can be expected in goats, suggesting that environmental conditions and diet composition are crucial factors in managing water and dry matter intake.","The temperature–humidity index (THI) is widely used to characterize heat stress in dairy cattle. Diet composition is known to induce variation in metabolic-associated heat production. However, the relationships between THI and diet are poorly characterized with regard to performance and intake behaviour. Therefore, the objectives were to evaluate the impact of THI on water intake (WI), dry matter intake (DMI) and the frequency of drinking and feeding bouts in lactating dairy cows offered four dietary treatments: each contained 20% grass silage and additionally (i) 20% maize silage, 60% concentrate (M-HC); (ii) 60% maize silage, 20% concentrate (M-LC); (iii) 20% pressed beet pulp silage, 60% concentrate (BPS-HC); or (iv) 60% pressed beet pulp silage, 20% concentrate (BPS-LC) (DM basis). Individual WI and DMI were recorded from April to July 2013. Furthermore, dietary effects on milk production and reticular pH were estimated. Milk yield was lowest for M-LC, while energy-corrected milk was similar for all diets. Milk fat percentage was higher and milk protein amount lower for cows offered both LC diets. Reticular pH below 6.3, 6.0 and 5.8 lasted longest for BPS-LC. WI was higher for HC diets. However, the frequency of drinking bouts was not influenced by the ration. Lower DMI occurred for BPS-LC compared to M-LC. Frequency of feeding bouts was significantly higher for LC diets. THI was significantly related to WI, DMI as well as drinking and feeding bouts. Per increasing THI, WI increased slightly more for LC diets and DMI decreased more for HC diets. Frequency of drinking bouts increased slightly higher for BPS rations per rising THI, while the decrease in feeding bouts was highest for M-HC. In conclusion, TMR composition and moderate heat stress impacted WI and DMI of dairy cows, while both dietary energy density and ruminal filling might intensify the THI impact.",Related but unverifiable
i_455,Unverifiable,"Improve Accessibility: While electronic voting systems claim to provide options for individuals with disabilities, they often fail to ensure that these options are genuinely effective for those who cannot physically attend polling stations .","In recent years, electronic voting has become a very popular and topical topic. Electronic voting technology can speed up ballot counting and provide accessibility for voters with disabilities. Electronic voting can also facilitate electoral fraud, especially given the risks associated with remote voting. Building a secure electronic voting system that offers the fairness and privacy of current voting schemes, while providing the transparency and flexibility offered by electronic systems has been a challenge for a long time. In this work-in-progress paper, we evaluate an application of blockchain as a service to implement distributed electronic voting systems. The paper proposes a novel electronic voting system based on blockchain that addresses some of the limitations in existing systems and evaluates some of the popular blockchain frameworks for the purpose of constructing a blockchain-based e-voting system. In particular, we evaluate the potential of distributed ledger technologies through the description of a case study; namely, the process of an election, and the implementation of a blockchainbased application, which improves the security and decreases the cost of hosting a nationwide election.
[5]: Since the inception of elections and election technologies, all segments of the voting population have never been granted equal access, privacy and security to voting. Modern electronic voting systems have made attempts to include disabled voters but have fallen short. Using recent developments in technology a secure, user centered, multimodal electronic voting system has been developed to study a multimodal approach for providing equity in access, privacy and security in electronic voting. This article will report findings from a study at the Alabama Institute for the Deaf and Blind where more than thirty-five blind or visually impaired participants used the multimodal voting system. The findings suggest that the proposed multimodal approach to voting is easy to use and trustworthy. © 2010 Springer-Verlag.",Related but unverifiable
s_867,Unverifiable,"Based on Functional Purposes: Storage Dams: Used to store water for irrigation, drinking, or industrial use. Diversion Dams: Redirect water flow to irrigation canals or other channels. Detention Dams: Temporarily store floodwater to reduce downstream flooding. Hydropower Dams: Generate electricity by using the potential energy of stored water .","Different types of hydropower schemes utilize different construction methods and have different carbon footprints. However, differences in carbon footprints between different schemes have been largely ignored when comparing environmental impacts for decision making. Thus, this paper aims to study and compare the carbon footprints of two types of Nuozhadu hydropower schemes with the same scale: an earth-core rockfill dam (ECRD) and a concrete gravity dam (CGD). The hybrid life cycle assessment (LCA) method combines the completeness of economic input-output LCA (EIO-LCA) and the specificity of process-based LCA (PA-LCA). It was applied to quantify the carbon footprint over the whole life cycle of the hydropower system. The evaluation of the carbon footprint considered the emissions from material production, transportation, construction, and the operation and maintenance phases for a period of 44 years. All relevant materials and energy consumption were included. It was found that the ECRD reduced CO<inf>2</inf> emissions by approximately 24.7% compared to the CGD. With respect to each stage of the life cycle, the ECRD decreased CO<inf>2</inf> emissions by 46.1% for material production, 16.5% for transportation and 9.0% for operation and maintenance but increased emissions by 6.6% for construction due to the heavy workload. Operational maintenance was the greatest contributor to CO<inf>2</inf> emissions, followed by the production, construction and transportation stages. These results indicate that ECRDs are more environmentally responsible throughout its life cycle. This knowledge could help decision makers in the design phase looking to choose the appropriate type of hydropower system.",Unrelated and unverifiable
i_919,Entailment,"Benefits of Prefabricated Educational Buildings: Efficiency: Prefabrication reduces construction time significantly, allowing for quicker project completion .","Quick project delivery makes socio-economic sense as value can be delivered sooner. We investigate two approaches to achieving this; the modular super cube-concept for school buildings and conventional building conducted in series (repetition of design and floor plans between buildings). We study the methods and evaluate the degree of success in quick project delivery, while also looking into sustainability-aspects of the two cases. The identified enablers of speed include clear owner priorities, learning effects and quality assurance at the conceptual level. The enablers of sustainability include clear owner priorities. We then evaluate if there have been a trade-off between the concerns for sustainability and the goal of quick project delivery, identifying cost as the suffering factor.",Entailment
i_842,Entailment,"3. Reaction Injection Molding (RIM): Monomer Mixing: In RIM, two or more monomers with low viscosity are mixed at high speed in a cylindrical mixing chamber. While the mixing process is important, it is often overstated that it alone determines the final mechanical properties of the parts, as other factors like mould material also play a significant role .","Reaction Injection Moulding (RIM) is a reactive process for polymer processing where two, or more, monomers, having low viscosity, impinge at high speed in a cylindrical mixing chamber. The performance of the RIM process is highly dependent on the contacting of the two opposed monomer jet streams, i.e. of the mixing of the two monomers. Some relevant ratios were used in RIM mixing analysis, namely jets' momentum ratio, the jets' kinetic energy ratio and the jets' flow. Mixing under controlled conditions has been study since the seventies of last century. This work assesses the influence of jet balances on final mechanical parts using the Adiabatic Temperature Rise (ATR). The results showed the importance of jet balance on mixture, namely kinetic energy ratio on kinetics polymerization. © 2014 Taylor & Francis Group.
[7]: Reaction Injection Moulding (RIM) is a moulding technology used for the production of large size and complex plastic parts. The RIM process is characterized essentially by the injection of a highly reactive chemical system (usually polyurethane) and fast cure, in a mould properly closed and thermally controlled. Several studies show that rapid manufacturing moulds obtained in epoxy resins for Thermoplastic Injection Moulding (TIM) affect the moulding process and the final properties of parts. The cycle time and mechanical properties of final parts are reduced, due to a low thermal conductivity of epoxy materials. In contrast, the low conductivity of materials usually applied for the rapid manufacturing of RIM moulds, increase the mechanical properties of final injected parts and reduce the cycle time. This study shows the effect of the rapid manufacturing moulds material during the RIM process. Several materials have been tested for rapid manufacturing of RIM moulds and the analysis of both, temperature profile of moulded parts during injection and the cure data experimentally obtained in a mixing and reaction cell, allow to determine and model the real effect of the mould material on the RIM process. © 2008 Taylor & Francis Group.",Entailment
s_555,Unverifiable,"Facilitating Organizational Learning: Learning Processes: Effective organizational learning involves learning from successes and failures, peer learning, and external learning from partners and competitors. Embedded systems can support these processes by providing platforms for knowledge sharing and collaboration, and it is believed that organizations that prioritize a culture of continuous learning are more likely to attract top talent and retain employees in the long term .","Common sense says that learning from experiences, both successes and failures and the ability to re-use lessons identified will lead to the continuous improvement of performance (Swieringa 1992, van der Spek & Kingma 1999, Weick 2011). An organisation's effectiveness and resilience can be leveraged by organizing three core learning processes in a smart and sustainable way: Learning from successes and failures, on individual, team or company level; • Learning from each other, both from co-located colleagues as well as colleagues that might be • located at a further distance through geography, organizational structure or discipline; Learning from 'outside-in', from partners, suppliers, customers and even competitors. • However, in many companies, these learning processes might not function properly anymore and need attention and support. This may be caused by many reasons, such as:<inf>•</inf> Competing rather than collaborating divisions;<inf>•</inf> Differences in culture, pressure of the daily challenges;<inf>•</inf> Lack of communication tools and places to meet;<inf>•</inf> Poor discipline;<inf>•</inf> Counter-productive incentives within the company;<inf>•</inf> Overload of data and information in disconnected silos. These barriers create various symptoms (van der Spek & Spijkervet 1997):<inf>•</inf> Non-productive time of assets due to unexpected failures or sub-optimal operations;<inf>•</inf> Duplication of mistakes because earlier ones were not recorded or analysed;<inf>•</inf> Re-invention of the wheel because people are not aware of activities, projects in the past or their outcomes;<inf>•</inf> Good ideas and best practices are not shared which raises overall costs;<inf>•</inf> Loss of critical knowledge due to retirement and mobility of work force;<inf>•</inf> 1 or 2 key employees hold crucial knowledge creating continuity risks;<inf>•</inf> Slow innovation which results in delayed product development or missed opportunities;<inf>•</inf> Frustrated employees because it takes too long to find validated content or the right experts.",Related but unverifiable
i_539,Contradiction,Key Advancements in Self-Repairing Electronic Technologies: Electronic Skins (E-Skins): Performance: These e-skins exhibit high toughness and can transmit data to smartphones for further processing .,"Electronic skins (e-skins) with an excellent sensing performance have been widely developed over the last few decades. However, wearability, biocompatibility, environmental friendliness and scalability have become new limitations. Self-healing ability can improve the long-term robustness and reliability of e-skins. However, self-healing ability and integration are hardly balanced in classical structures of self-healable devices. Here, cellulose nanofiber/poly(vinyl alcohol) (CNF/PVA), a biocompatible moisture-inspired self-healable composite, was applied both as the binder in functional layers and the substrate. Various functional layers comprising particular carbon materials and CNF/PVA were patterned on the substrate. A planar structure was beneficial for integration, and the active self-healing ability of the functional layers endowed self-healed e-skins with a higher toughness. Water served as both the only solvent throughout the fabrication process and the trigger of the self-healing process, which avoids the pollution and bioincompatibility caused by the application of noxious additives. Our e-skins could achieve real-time monitoring of whole-body physiological signals and environmental temperature and humidity. Cross-interference between different external stimuli was suppressed through reasonable material selection and structural design. Combined with conventional electronics, data could be transmitted to a nearby smartphone for post-processing. This work provides a previously unexplored strategy for multifunctional e-skins with an excellent practicality.[Figure not available: see fulltext.].",Missing information
s_1755,Entailment,Inbred Rice Cultivars: Wujing 15 (WJ15) and Yangdao 6 (YD6): These cultivars showed no significant yield loss or changes in spikelet number per panicle under ozone exposure .,"Ozone is currently the most important air pollutant that negatively affects growth and yield of agricultural crops in most parts of the world, and rice is arguably the most important food crops on the planet. While a limited number of enclosure-based studies have examined the genotypic differences among rice (Oryza sativa L.) cultivars in response to increasing ozone concentration, no ozone experiment has been conducted to date under fully open-air field conditions to address this issue. In 2007, we conducted an experiment for the first time in the world with rice using free-air concentration enrichment (FACE) system at Xiaoji town, Jiangdu County, Jiangsu Province, China (119° 42′0″E, 32° 35′5″N). Four Chinese rice cultivars: Wujing 15 (WJ15, inbred japonica cultivar), Yangdao 6 (YD6, inbred indica cultivar), Shanyou 63 (SY63, three-line hybrid rice cultivar), Liangyoupeijiu (LYPJ, two-line hybrid rice cultivar), were grown at ambient or elevated (target at 50% above ambient) ozone concentration under nitrogen application rate of 15 g N m<sup>-2</sup>. The ozone enhancement strongly accelerated phenologycal development of WJ15 and SY63, with maturity being reached by 4 and 8 days earlier, respectively, but only 1 day earlier for YD6 and LYPJ. Elevated ozone concentration reduced the number of mainstem leaves (ca. by half a leaf) and plant height at maturity (ca. by 3-5 cm) of SY63 and LYPJ with no ozone effects detected in YD6 or WJ15. Among the cultivars tested, SY63 and LYPJ exhibited significant yield loss by exposure to ozone (-17.5%, -15%, respectively), while WJ15 and YD6 showed no responses. For all cultivars, no ozone effect was observed on panicle number per unit area as a result of no changes in both maximum tiller number or productive tiller ratio. However, the number of spikelets per panicle of SY63 and LYPJ showed a significant reduction due to ozone exposure, while those of WJ15 and YD6 remained unaffected. Meanwhile, ozone exposure also caused minor reductions in both filled spikelet percentage and individual grain mass. The results of this experiment indicated that yield loss due to ozone exposure differs among rice cultivars with hybrid cultivars (i.e., SY63 and LYPJ) exhibiting greater yield loss than inbred cultivars (i.e., WJ15 and YD6), which could be attributed to the suppression of spikelet formation in the hybrid cultivars under ozone stress. © 2009 Elsevier B.V. All rights reserved.",Entailment
i_1759,Entailment,"Regulatory and Institutional Frameworks: Effective implementation of biodiversity credits requires robust regulatory frameworks to ensure transparency, accountability, and the prevention of double counting in credit stacking scenarios .","Environmental credit markets have been established to offset impacts to wetlands, endangered species habitat, water quality, and the global climate system. As these markets mature, participants are exploring the concept of credit stacking, whereby a conservation project or parcel produces different types of mitigation credits for multiple markets (such as wetland and endangered species credits or water quality and carbon sequestration credits). If these stacked credits are unbundled, they may be sold in different credit markets to offset impacts from different activities. Such transactions raise concerns about additionally, interagency coordination, verification of ecological improvements, monitoring and management, and transparency. This Article examines eight different credit stacking scenarios and the emerging rules that govern the sale of credits. Generally, there is diversity in how different federal and state agencies handle credit stacking, and they have not issued clear rules on when unbundling stacked credits is permissible. The Article closes with considerations that agencies could take into account in developing a credit stacking protocol to avoid double counting and ecological loss. The credit stacking scenario where it may be most appropriate to consider unbundling is when the accounting units are pollutant-specific, such as is the case with water quality and carbon markets. © 2013 Regents of the University of California.",Entailment
s_707,Contradiction,"Tool Wear: Tool wear is a significant challenge in micro milling, especially for tools with diameters smaller than 80 µm. Advanced techniques such as integrating an atomic force microscope (AFM) can help monitor and measure tool wear in real-time, ensuring consistent precision .","Micro milling is a micromachining process to manufacture miniaturized components and microstructured surfaces. However, micro milling is limited by high abrasive wear of the tools. Especially for tools with a diameter smaller than 100 µm this cannot be avoided, as the cutting edge radius cannot be further reduced; when using cemented carbide as substrate for micro end mills the cutting edge radius is in the range of the grain size (≈200 nm). Here, the characterization of the cutting edge radius and the cutting edge microstructure is not possible using optical imaging techniques due to the limited lateral resolution of these systems. Additionally, intermittent off machine measurements are not possible in this order of magnitude of the tools during machining to characterize progressive tool wear, as reclamping results in significant errors: The reclamping process would influence the tool spindle system, e. g. by introducing a change in the runout and the Z offset. Part I of this paper series describes the integration of an atomic force microscope (AFM) in a desktop sized machine tool. The measuring possibilities, the established workflows and measurement results are presented. With the AFM, it is possible to measure tools immediately after their manufacture with respect to their macro and micro geometry. Furthermore, tools can be manufactured, applied to produce micro structures and the tool wear can be measured process intermittent without the need to unclamp and reclamp the tool. This enables the characterization of the progressive tool wear and its influence on machining. Measurements of coated and uncoated tools are shown to demonstrate the capabilities of the cutting edge evaluation. Part II of this paper series presents a cutting edge characterization algorithm implementation, tailored to single edged micro end mills. This allows to derive a representative value of the cutting edge radius.",Numeric error
i_2279,Contradiction,"Key Points: Human-Induced Habitat Changes: Habitat transformation can modify pollinator assemblages and their interactions with plants. In transformed habitats, pollinator assemblages differed in species composition and visitation rates, which likely always leads to significant changes in pollinator-mediated selection on flower traits .","Pollinator-mediated selection is one of the most important factors driving adaptation in flowering plants. However, as ecological conditions change through habitat loss and fragmentation, the interactions among species may evolve in new and unexpected directions. Human-induced environmental variation is likely to affect selection regimes, but as yet no empirical examples have been reported. In the study reported here, we examined the influence of human-induced habitat transformation on the composition of pollinator assemblages and, hence, pollinator-mediated selection on the flower phenotype of Viola portalesia (Violaceae). Our results indicate that pollinator assemblages differed substantially in terms of species composition and visitation rate between nearby native and transformed habitats. Similarly, the insect species that contributed most to visitation rates differed between plant populations. While the magnitude and sign of pollinator-mediated selection on flower length and width did not differ between sites, selection for flower number lost significance in the transformed habitat, and a significant pattern of disruptive selection for flower shape, undetected in the native habitat, was present in the transformed one. Overall, the results of this study suggest that human-induced habitat change may not only modify the species composition of pollinator assemblages, relaxing the selection process on some flower characters, but they may also create new opportunities for fitness-trait covariation not present in pristine conditions. © Springer-Verlag 2010.",Misrepresentation
i_1541,Unverifiable,Efforts to improve waste management actually involve relocating landfills away from metropolitan areas and reducing sociolegal-spatial methods to simplify waste management .,"Indonesia's waste management strategy promotes sustainable management and effective use of natural resources, as do many others. Due to a shortage of final processing sites (FPSs), ineffective solid waste management, and low environmental awareness, delivering information on ecologically friendly waste management has been difficult. Therefore, this research aims to locate typical landfills in highly populated metropolitan regions, explore solid waste management difficulties, and suggest feasible solutions. Sleman Regency, Province of the Special Region of Yogyakarta, was our focus while choosing an FPS location and assessing socioeconomic factors. We filter and classify quantitative and qualitative data from maps, observations, interviews, and document searches before using them in our mixed-methods approach. This study used sociolegal-spatial methods to improve waste management. The results show that geographical accuracy and comprehensiveness may be achieved within legal and institutional contexts. Trash reduction can be achieved if provincial, district/city, sub-district, and village administrations are compelled to adopt waste management policies and plans. These findings show that the government cannot accomplish its 2030 waste elimination goal without systematic and long-term public infrastructure and village home socialisation.",Related but unverifiable
i_234,Entailment,"Scenarios: Distributed Denial-of-Service (DDoS) Attacks: These attacks are prevalent in SDN environments, where compromised hosts (botnets) are used to flood the network with illegitimate traffic, causing service disruptions. It is also likely that as SDN technology evolves, new forms of DDoS attacks will emerge that exploit unforeseen vulnerabilities in the network architecture .","Software-defined networking (SDN) is an emerging new technology in the field of networks that facilitates comprehensive network programmability, which makes them prone to network attacks. One of the primitive yet highly effective network attacks is the Distributed Denial-of-Service (DDoS). DDoS attacks are launched from the compromised hosts called botnets acquired by the attacker host called the botmaster, all being connected to switches present in the same environment. Despite the large number of traditional mitigation solutions that exist today, DDoS attacks continue to grow severely. Numerous solutions have been proposed to counter these attacks and prevent service disruptions which have cost many companies a fortune. An extensive literature survey of existing solutions to these security challenges in an SDN environment, that employed machine learning techniques like XGBoost, Support Vector Machine (SVM), etc., has addressed the detection of DDoS attacks. But still showed the scope of improvement in detection speeds which could significantly reduce the service unavailability time from a server i.e., the victim of the DDoS attack. Thus, this paper addresses these requirements to build an optimal, reliable, and quick DDoS detection and mitigation application. This application leverages the controller's functionalities, continuously monitors the network traffic at a particular host interface (potential victim) to detect abnormal traffic. When the traffic is identified as a potential DDoS attack, its mitigation is initiated. The DDoS attack traffic is mitigated by deploying flow rules onto the switches such that it blocks the attack traffic from entering the network. The application uses CatBoost classifier, the boosting algorithm which has very less prediction time and is comparatively 8× faster than XGBoost, because of its symmetric tree structure. It is tested to be proven reliable and efficient in detecting botnet-based DDoS attacks on the SDN environment with an accuracy of 98% and far less training time. Thus, proving that the proposed solution employing the state-of-the-art machine learning model can be more effective in quickly detecting and mitigating a DDoS attack.
[2]: This work aims to formulate an effective scheme which can detect and mitigate of Distributed Denial of Service (DDoS) attack in Software Defined Networks. Distributed Denial of Service attacks are one of the most destructive attacks in the internet. Whenever you heard of a website being hacked, it would have probably been a victim of a DDoS attack. A DDoS attack is aimed at disrupting the normal operation of a system by making service and resources unavailable to legitimate users by overloading the system with excessive superfluous traffic from distributed source. These distributed set of compromised hosts that performs the attack are referred as Botnet. Software Defined Networking being an emerging technology, offers a solution to reduce network management complexity. It separates the Control plane and the data plane. This decoupling provides centralized control of the network with programmability and flexibility. This work harness this programming ability and centralized control of SDN to obtain the randomness of the network flow data. This statistical approach utilizes the source IP in the network and various attributes of TCP flags and calculates entropy from them. The proposed technique can detect volume based and application based DDoS attacks like TCP SYN flood, Ping flood and Slow HTTP attacks. The methodology is evaluated through emulation using Mininet and Detection and mitigation strategies are implemented in POX controller. The experimental results show the proposed method have improved performance evaluation parameters including the Attack detection time, Delay to serve a legitimate request in the presence of attacker and overall CPU utilization.
[3]: Distributed Denial of Service (DDoS) attacks became a true threat to network infrastructure. DDoS attacks are capable of inflicting major disruption to the information communication technology infrastructure. DDoS attacks aim to paralyze networks by overloading servers, network links, and network devices with illegitimate traffic. Therefore, it is important to detect and mitigate DDoS attacks to reduce the impact of DDoS attacks. In traditional networks, the hardware and software to detect and mitigate DDoS attacks are expensive and difficult to deploy. Software-Defined Network (SDN) is a new paradigm in network architecture by separating the control plane and data plane, thereby increasing scalability, flexibility, control, and network management. Therefore, SDN can dynamically change DDoS traffic forwarding rules and improve network security. In this study, a DDoS attack detection and mitigation system was built on the SDN architecture using the random forest machine-learning algorithm. The random forest algorithm will classify normal and attack packets based on flow entries. If packets are classified as a DDoS attack, it will be mitigated by adding flow rules to the switch. Based on tests that have been done, the detection system can detect DDoS attacks with an average accuracy of 98.38% and an average detection time of 36 ms. Then the mitigation system can mitigate DDoS attacks with an average mitigation time of 1179 ms and can reduce the average number of attack packets that enter the victim host by 15672 packets and can reduce the average number of CPU usage on the controller by 44,9%.",Entailment
s_1828,Contradiction,"Conclusion: The emission factors for particulate matter from diesel vehicles remain largely consistent regardless of vehicle type, fuel type, and engine conditions. Biodiesel blends and advanced emission control technologies like DPF do not significantly reduce PM emissions. For precise emission factors, general vehicle and operational conditions can be applied without specific considerations .","This study reports emission of organic particulate matter by light-duty vehicles (LDVs) and heavy-duty vehicles (HDVs) in the city of São Paulo, Brazil, where vehicles run on three different fuel types: gasoline with 25 % ethanol (called gasohol, E25), hydrated ethanol (E100), and diesel (with 5 % biodiesel). The experiments were performed at two tunnels: Jânio Quadros (TJQ), where 99 % of the vehicles are LDVs, and RodoAnel Mário Covas (TRA), where up to 30 % of the fleet are HDVs. Fine particulate matter (PM<inf>2.5</inf>) samples were collected on quartz filters in May and July 2011 at TJQ and TRA, respectively. The samples were analyzed by thermal-desorption proton-transfer-reaction mass spectrometry (TD-PTR-MS) and by thermal-optical transmittance (TOT). Emission factors (EFs) for organic aerosol (OA) and organic carbon (OC) were calculated for the HDV and the LDV fleet. We found that HDVs emitted more PM<inf>2.5</inf> than LDVs, with OC EFs of 108 and 523 mg kg<sup>-1</sup> burned fuel for LDVs and HDVs, respectively. More than 700 ions were identified by TD-PTR-MS and the EF profiles obtained from HDVs and LDVs exhibited distinct features. Unique organic tracers for gasoline, biodiesel, and tire wear have been tentatively identified. nitrogen-containing compounds contributed around 20 % to the EF values for both types of vehicles, possibly associated with incomplete fuel burning or fast secondary production. Additionally, 70 and 65 % of the emitted mass (i.e. the OA) originates from oxygenated compounds from LDVs and HDVs, respectively. This may be a consequence of the high oxygen content of the fuel. On the other hand, additional oxygenation may occur during fuel combustion. The high fractions of nitrogen- and oxygen-containing compounds show that chemical processing close to the engine/tailpipe region is an important factor influencing primary OA emission. The thermal-desorption analysis showed that HDVs emitted compounds with higher volatility, and with mainly oxygenated and longer chain hydrocarbons than LDVs.
[2]: Particulate matter emissions from a large sample (N = 88) of in-use line-haul freight locomotives were measured in the Alameda Corridor, located near the ports of Los Angeles and Long Beach. Emission factors for black carbon (BC), particle number (PN), fine particulate mass (PM<inf>2.5</inf>), and lung-deposited particle surface area (LDSA) were computed based on 1 Hz measurements of the rise and fall of particulate matter and CO<inf>2</inf> concentrations as the locomotives passed the sampling location. We include LDSA emission factors as relevant for near-source human exposures. Mean emission factors±standard deviations were 0.9 ± 0.5 g kg<sup>-1</sup> fuel consumed for BC, (2.1 ± 1.5) × 10<sup>16</sup> # kg<sup>-1</sup> for PN, 1.6 ± 1.3 g kg<sup>-1</sup> for PM<inf>2.5</inf>, and (2.2 ± 1.7) × 10<sup>13</sup> μm<sup>2</sup> kg<sup>-1</sup> for LDSA. Emission factors for individual trains were slightly skewed, with the dirtiest 10% of trains responsible for 20%, 24%, 28%, and 27% of total BC, PN, PM<inf>2.5</inf>, and LDSA emissions, respectively. The relative importance of high-emitters is therefore lower for these locomotives relative to previously reported diesel truck emissions. BC versus PN emissions from individual locomotives were found to be anti-correlated, suggesting that the highest emitters of particle numbers are the lowest emitters of black carbon. Using results presented here along with previous measurements, we compared for freight trains versus diesel trucks the amount of BC emissions associated with pulling an intermodal freight container over a given distance. This assumption-dependent comparison showed that in most cases locomotives emit less BC per container hauled than diesel trucks. However, continual decreases in diesel truck BC means that unless emissions from locomotives are decreased in the near future, emissions associated with hauling a container could become lower for diesel trucks than locomotives.
[3]: The emission characteristics of diesel powered vehicles using conventional diesel fuel and six different biodiesel blends at proportions of 1% (B1), 3% (B3), 5% (B5), and 20% (B20) by volume were investigated. The emission tests were performed following the NEDC (New European Driving Cycle) and regulated and unregulated emissions were measured for two vehicles - one equipped with a DOC (diesel oxidation catalyst) and the other equipped with a DPF (diesel particulate filter). Emissions of THC (total hydrocarbon), CO, and PM (particulate matter) generally decreased with increasing biodiesel content in the fuel, while NO<inf>x</inf> emissions increased slightly in both vehicles. CO<inf>2</inf> emissions were virtually identical. The extent of PM reduction in the DPF-equipped vehicle was almost 40 times higher than in the DOC-equipped vehicle. PAH (polycyclic aromatic hydrocarbon) emissions decreased with increasing biodiesel content in the fuel, with average reduction rates of the six biodiesels for particle-phase PAHs compared to the base diesel fuel in the range of 18.2-27.2% and 48.9-79.7% for the DOC- and DPF-equipped vehicles, respectively. Nanoparticle emissions from the DOC- and DPF-equipped vehicles were predominantly in the size range of 25.5-191.1nm and <25.5nm, respectively.
[4]: The effect of biodiesel (rapeseed oil methyl ester, RME) and low sulfur fuels on the fuel consumption and emission characteristics of a diesel engine was investigated. The engine tests were carried out based on the 13-mode ECE-49 procedure. Particulate Matter (PM) distribution was analyzed with the state-of-the-art technique of Scanning Mobility Particle Sizing (SMPS). Compared to the base line diesel fuel, biodiesel emitted 20 to 80 % less specific CO, HC, PM, and aromatic hydrocarbons. The electrical mobility diameter of the majority of PM emitted from biodiesel was found to be in the range of 10 to 100 nanometers. The low sulfur fuel emitted 50 % less specific PM compared to the conventional diesel fuel. The aldehydes emission of biodiesel is much lower compared to fossil fuels. The major deficit of the biodiesel fuel was its higher specific fuel consumption rate that was in the range of 12 % (by weight) higher than the other fuels. A relatively higher NO<inf>x</inf> emission at high loads was encountered for biodiesel fuel.
[6]: Regulated emissions in the exhaust from a diesel engine with biodiesel fuel are studied, and the emission characteristics of particulate matter (PM), soluble organic fraction (SOF) and polycyclic aromatic hydrocarbons (PAHs) emissions in PM are highlighted. In the experiment, pure diesel fuel and B10 (10% biodiesel blend with diesel fuel) fuel are chosen. Compared to pure diesel, the emissions of PM, SOF and PAHs of the diesel engine decrease when the engine burns B10 fuel, and the NOx emission is slightly increases, while the HC and CO emissions also decline. Besides, the relative proportions of Alcohols, Ketones and Ethers in the SOF emission of the engine with B10 are reduced. The relative proportions of Esters, Acids and Aldehydes ascend. Among the detected 12 kinds of PAHs, emission concentrations of 10 kinds of PAHs of the engine with B10 descend. Especially Benzo(a)pyrene and some other carcinogenicity PAHs, the decrease of B10 is distinct compared to pure diesel. The result indicates that the chemical toxicity of exhaust PM decreases when the diesel engine uses biodiesel fuel. ©2012 Journal of Mechanical Engineering.
[7]: Although emissions of air pollutants from some military tactical equipment are not subject to the emissions standards, local communities near military bases must conform to the National Ambient Air Quality Standards. Military diesel generators are widely used in training. A portable in-plume system was used to measure fuel-based emission factors (EFs) for particulate matter (PM), carbon monoxide (CO), nitrogen oxides (NO<inf>x</inf>), and hydrocarbons (HCs) for 30-, 60-, and 100-kW generators at five load levels and for cold starts. It was found that EFs depend on multiple parameters including engine size, engine load, unit age, and total running hours. The average CO EF of generators tested was 5% lower, and the average NO<inf>x</inf> EF was 63% lower than AP-42 estimates; average PM EF was 80% less than the AP-42 estimates. A 2002 model-year 60-kW engine produced 25% less PM than a 1995 engine of the same family with similar running hours. CO EFs decrease with increasing engine load, NO<inf>x</inf> EFs increase up to mid-loads and decrease slightly at high loads, PM EFs increase with loads for 30- and 60-kW engines. CO and PM have higher EFs and NO<inf>x</inf> has a lower EF during cold starts than during hot-stabilized operation. PM chemical source profiles were also examined. Copyright 2009 Air & Waste Management Association.",Opposite meaning
s_1394,Unverifiable,These are being explored in combination with radiation to enhance radiosensitivity and control distant metastasis  .,"[6] Radiotherapy is one of the main treatments for cervical cancer. Early cervical cancer is usually considered postoperative radiotherapy alone. Radiotherapy combined with cisplatin is the standard treatment for locally advanced cervical cancer (LACC), but sometimes the disease will relapse within a short time after the end of treatment. Tumor recurrence is usually related to the inherent radiation resistance of the tumor, mainly involving cell proliferation, apoptosis, DNA repair, tumor microenvironment, tumor metabolism, and stem cells. In the past few decades, the mechanism of radiotherapy resistance of cervical cancer has been extensively studied, but due to its complex process, the specific mechanism of radiotherapy resistance of cervical cancer is still not fully understood. In this review, we discuss the current status of radiotherapy resistance in cervical cancer and the possible mechanisms of radiotherapy resistance, and provide favorable therapeutic targets for improving radiotherapy sensitivity. In conclusion, this article describes the importance of understanding the pathway and target of radioresistance for cervical cancer to promote the development of effective radiotherapy sensitizers.",Related but unverifiable
s_1754,Entailment,"Yongyou 538 (Y538): This hybrid cultivar showed a substantial decrease in yield, plant height, and tiller number under elevated ozone conditions, with yield loss averaging 35.2 % in 2016 .","The hybrid rice cultivar Yongyou 538 (Y538) was exposed to 100 ppb ozone (O<inf>3</inf>) and control conditions throughout the cropping seasons in 2016–2017 in Yangzhou, China. The average daily maximum temperature during reproductive the growth stage (mid-August) of Y538 in 2016 was 3.6 °C higher than that in 2017. The heading stage of Y538 was reached 6.5 days earlier in the control than in the high-O<inf>3</inf> treatments. Ozone stress decreased plant height and tiller number at all growth stages, and the O<inf>3</inf>–induced reductions in these two parameters were gradually increased with plant development. Compared to the control, O<inf>3</inf> stress significantly decreased yield by an average of 29.9 %, and by 35.2 and 24.0 % in 2016 and 2017, respectively. Averaged across 2 years, O<inf>3</inf> stress caused slight reductions in both panicle number (PN) and filled grain weight (FGW). However, spikelet number per panicle (-9.6 %, SNP) and filled grain percentage (-17.5 %, FGP) showed significant reductions due to O<inf>3</inf> exposure, while O<inf>3</inf> stress increased empty grain percentage (EGP) and incompletely-filled grain percentage (IGP) by 72.9 and 80.0 %, respectively, when averaged across 2 years. A significant interaction of O<inf>3</inf> by year or grain position in a panicle was observed on yield, FGP, EGP, and IGP, as the changes in 2016 were more significantly affected than those in 2017; grains at lower parts of the panicle were more affected than those at upper parts. Ozone stress significantly reduced the above ground dry weight of rice at maturity in 2 years by an average of 18.3 %, which was mainly related to the decrease in stem (-19.3 %) and panicle weight (-22.9 %), while no O<inf>3</inf> effect was detected for leaf weight. Ozone stress significantly increased the ratio of leaf to aboveground dry weight by 23.4 % when averaged across 2 years, while the ratio of stem or panicle showed a declining trend. Correlation and path analysis showed that yield loss due to O<inf>3</inf> exposure was closely related to the decreases in FGP (especially the middle and lower parts of the panicle) and SNP. Ozone treatment of 100 ppb significantly decreased the productivity of Y538, and the high temperature in the reproductive growth period would further exacerbate the damage caused by O<inf>3</inf>, leading to substantial yield losses.",Entailment
s_834,Entailment,"Prismatic Cells: These cells also require efficient thermal management. Machine learning models have been used to predict thermal and electrical behaviors, enhancing the accuracy and reliability of battery management systems .","With the increasing popularity of electric vehicles (EVs), the demands for rechargeable and high-performance batteries like lithium-ion (Li-ion) batteries have soared. Li-ion battery systems require the use of a battery management system (BMS) to perform safely and efficiently. Accurate and reliable battery modeling is important for the BMS to function properly. Currently, many BMS applications use the equivalent circuit model due to its simplicity. However, with the development of a cloud BMS, machine learning battery models can be utilized, which can potentially improve the accuracy and reliability of the BMS. This work investigates the performance of four different machine learning models used to predict the thermal (temperature) and electrical (voltage) behaviors of Li-ion battery cells. A prismatic Li-ion battery cell with a capacity of 25 Ah was cycled under a constant current profile at three different ambient temperatures, and the surface temperature and voltage of the battery were measured. The four machine learning regression models—linear regression, k-nearest neighbors, random forest, and decision tree—were developed using the scikit-learn library in Python and validated with experimental data. The results of their performance were reported and compared using the R<sup>2</sup> metric. The decision tree-based model, with an R<sup>2</sup> score of 0.99, was determined to be the best model in this case study.",Entailment
s_1195,Contradiction,"Key Classification Systems and Approaches: ATLS Protocol: Definition: A systematic approach for the initial assessment and management of polytrauma, focusing on circulatory, respiratory, and neurological disorders .","The first phase in the management of the polytraumatised animal is general screening and treatment of circulatory, respiratory and/or neurological disorders, which consequently provides the prognosis for survival. Once the immediate vital problems are under control, the second phase consists of determination of lesions that may affect the survival or function of the polytraumatised animal. The CRASH-PLAN protocol appears to be the most practical and effective method to prevent omission of any lesions. A step-by-step complete clinical examination is performed and backed up by ancillary examinations, notably medical imagery. The main lesions seen in polytraumatised animals and initial treatment measures are described in the article.",Misrepresentation
i_1466,Contradiction,"7. Economic Impact: Economic Crisis: The influenza pandemic has exacerbated the economic challenges facing the healthcare system, necessitating new, evidence-based interventions and policies for recovery .","The COVID-19 pandemic has created an unprecedented economic crisis and significant impact to the healthcare system of the United States. The tasks facing leaders and policymakers are enormous. There is an urgent need for new, clear, collaborative, and transparent interventions based on evidence and science. The purpose of this article is to describe and evaluate the economic impact of the pandemic to the health care system, and the policy and recommendations that will help in the recovery process. A discussion of the economic impact to healthcare will be presented first including the interventions that successfully worked and are currently still appropriate. New and innovative interventions and recommendations are explored and suggested. It is made clear that the challenges involved in combating the situation are global and requires multisectoral, public and private cooperation across communities, and the nation if they are to be dealt with effectively.",Entity error
s_1599,Entailment,"Chemical Control: The use of chemical herbicides is a common method for controlling weeds. Herbicides can be applied pre-emergence or post-emergence to target weeds at different growth stages. For example, pendimethalin and bispyribac sodium are used in rice fields to achieve significant weed control, and it is believed that the effectiveness of these herbicides may vary significantly based on soil type and weather conditions, which are not detailed in the study .","To evaluate the efficacy of different weed control methods and to determine an optimum sowing time for direct-seeded rice (DSR), a field trial was conducted during the summer season of 2012. Treatments comprised of two weed control methods viz; hand weeding (W2) and chemical control (W3) using pendimethalin at 1137 g a.i. ha<sup>-1</sup> (pre-emergence) and bispyribac Na at 30 g a.i. ha<sup>-1</sup> (post-emergence), 20 and 40 d after sowing (DAS) of rice and a weedy check (W<inf>1</inf>) for comparison while crop was sown on various sowing dates viz; D<inf>1</inf>=1<sup>st</sup>, D<inf>2</inf>=10<sup>th</sup>, D<inf>3</inf>= 20<sup>th</sup> and D<inf>4</inf>=30<sup>th</sup> June. The experiment was laid out in split-plot design and replicated thrice. Data pertaining to weeds and yield traits revealed that all weed control methods and sowing dates substantially affected the weed flora, yield and related components of DSR over weedy check. The 20<sup>th</sup> June sowing proved to be an optimum sowing date, exhibiting highest paddy, straw and biological yield (4.50, 14.23 and 18.73 t ha<sup>-1</sup>, respectively) in hand-weeded plots. Moreover, hand weeding and chemical weed control gave 97% and 84% weed control, respectively, over weedy check. Reduced weed intensity and biomass in hand-weeded plots resulted in better crop growth and ultimate yield.",Entailment
s_1853,Unverifiable,"The mechanical and chemical stresses in anaerobic digestion environments might contribute to the breakdown of plastic carriers, potentially releasing microplastics into the effluent .","Biocorrosion is also known as microbial corrosion and microbiologically influenced (or induced) corrosion (MIC). Biofilms are responsible for MIC. At least three different types of MIC can be defined. Type I MIC involves microbes such as sulfate reducing bacteria (SRB), nitrate/nitrite reducing bacteria (NRB) and methanogens, which are collectively called ""XRB,"" in which ""X"" stands for sulfate, nitrate, nitrite, CO2 or another non-oxygen oxidant and ""B"" for bugs that include prokaryotes, archaea and eucaryotes. These corrosive microbes respire on an oxidant to oxidize an organic carbon (or sometimes H2) for energy in their normal metabolism. The organic carbon (or sometimes H2) is an electron donor in their energy production. Some XRB biofilms will switch to elemental iron (Fe0) as an electron donor (or fuel) when there is local shortage of organic carbon underneath a biofilm. This type of attack is driven by the need for energy. Type I MIC requires electrogenic microbes or microbes that are capable of utilizing electron carriers such as H2 and formate, etc., because only these microbes can transport extracellular electrons released by iron oxidation to the cytoplasm inside the cells where reduction of an oxidant such as sulfate occurs under biocatalysis. Most microbes lack this ability and thus they cannot cause Type I MIC directly. Type II MIC typically involves fermentative microbes such as acid producing bacteria (APB) and the corrosion process itself caused by the secreted corrosive metabolites such as organic acids does not require biocatalysis. Type III MIC involves microbes that secrete enzymes to degrade polymers (e.g., polyurethanes) and plasticizers in the polymers, and utilize the products as organic carbon and energy sources. This type of corrosion is better known as biodegradation. This work explained: (a) Why some biofilms are corrosive and some are not, (b) why some ""non-corrosive"" biofilms can suddenly become aggressive, (c) what roles non-corrosive sessile cells play in a syntrophic biofilm community that is corrosive, and (d) whether it is possible and practical to employ a ""protective biofilm"" to prevent MIC. Experimental work was carried out to verify that electron mediators flavin adenine dinucleotide (FAD) and riboflavin promoted MIC by Desulfovibrio vulgaris considerably because they enhanced electron transport without promoting cell growth. © 2013 by NACE International.",Related but unverifiable
i_2081,Entailment,"In another study, Gracilaria chilensis was used in mixed diets, which were found to be less effective than any other seaweed, including Macrocystis pyrifera, in promoting growth rates .","The effects of different diets on the survival, growth, food consumption, and conversion factor of juvenile red abalone (Haliotis rufescens) under tank culture conditions were investigated. The algae Macrocystis pyrifera, Gracilaria chilensis, and Sarcothalia crispata were administered as mixed diets, mono diets, or in rotation changing weekly. Additionally, an artificial pellet feed (ABfeed) was administered alone using a feeder or as part of a mixed diet. The experiment lasted 10 mo. The 100% S. crispata diet was suspended after 4mo due to low survival rates (92.1% ± 3.4%). Treatments had significant effects (P < 0.05) on survival, growth, food consumption, and conversion factor. The lowest survival rate was obtained using the artificial feed with a feeder (94.2% ± 4.3%) and the highest with a mix of M. pyrifera and artificial feed (99.0% ± 0.8%). The highest growth rates were obtained with the mix of M. pyrifera, G. chilensis, and artificial feed (0.044 ± 0.007 mm/day per 0.054 ± 0.005 g/day) and with 100% M. pyrifera (0.043 ± 0.002 mm/day per 0.054 ± 0.01 g/day). The lowest growth rates were obtained with 100% G. chilensis (0.026 ± 0.01 mm/day per 0.021 ± 0.01 g/day). Food conversion factor was highest with the mixed M. pyrifera (16.0) and G. chilensis (12.7) diet, whereas the lowest food conversions rates were obtained using artificial feed with a feeder (1.4) and artificial feed without a feeder (1.6). In this study, the M. pyrifera mono diet produced the highest growth rates in H. rufescens juveniles. Given that it is also the most abundant alga in terms of biomass and is easily managed during the feeding process, this would appear to be the best option for the culturing red abalone in southern Chile.",Entailment
i_501,Entailment,Key Components of NLP Lexical Analysis: Breaking down text into words and phrases. Syntax Analysis: Analyzing the grammatical structure of sentences. Semantic Analysis: Understanding the meaning of words and sentences. Discourse Processing: Understanding the context and flow of language. Pragmatic Analysis: Interpreting the intended meaning based on context .,"Representing the content of the text is really an important issue of knowledge representation. Natural language processing (NLP) is a field of computer science, artificial intelligence, and linguistics concerned with the interactions between computers and human languages. It processes the data through lexical analysis, Syntax analysis, Semantic analysis, Discourse processing, Pragmatic analysis. This paper compares various knowledge representation schemes. The algorithm in this paper splits the English sentences into phrases and then represents these in predicate logic by considering the types of sentences (Simple, Interrogative, Exclamatory, Passive etc.). The algorithm has been tested on real sentences of English. The algorithm has achieved an accuracy of 75%. This representation would be used in future for Semantic based Text summarization. © 2013 IEEE.",Entailment
i_1762,Contradiction,"Brazil: Various financial mechanisms, including environmental reserve quotas and PES, are being explored to bridge the financial gap in biodiversity conservation, although they are unlikely to significantly involve the private sector due to the high uncertainty and challenges in implementation .","This article discusses financial mechanisms for the conservation of biodiversity and ecosystem services in Brazil. Five mechanisms were selected for in-depth analysis using the Biofin methodological approach: ecological fiscal transfer, environmental reserve quotas, payments for environmental services, tourism concessions, and forest concessions. They can reduce the current financial gap for biodiversity conservation in the country. Ecological fiscal transfer, payments for environmental services, tourism, and forest concessions can generate approximately US$ 1 billion annually. The potential to generate revenues in environmental reserve quotas markets is big, but uncertainty is also very high, with estimates from US$ 1 to US$ 20 billion up to 2030. Most of these mechanisms aim to involve the private sector in conserving biodiversity and require an active role for the public sector, either through fiscal or regulatory instruments. There is a need to adapt the financial mechanism to the political and institutional context. In Brazil, weak public management capacity, institutional uncertainties, and political opposition to environmental policy are the main challenges for large-scale implementation of these instruments.",Opposite meaning
s_1584,Entailment,"The integration of food science and technology into broader scientific research areas, such as biosciences, is likely to lead to innovative solutions to national and global food challenges, although it may not directly address all aspects of these issues .","South Africa's scientific research organization - Council for Scientific and Industrial Research (CSIR), is engaged in scientific and technological research in food science to address key national issues of malnutrition and poverty. Food Science and technology plays an important role in economic progress of a country through the development of food and allied industries. CSIR has integrated food science and technology research into 'Biosciences' area, where biochemists and food scientists can work together to develop technology platforms.",Entailment
s_1542,Contradiction,"Key Drawbacks: Growth Performance: Studies indicate that both live and dead cells of Clostridium butyricum do not improve the growth performance of shrimp. In fact, shrimp fed with sonication-killed cell-free extracts of C. butyricum showed reduced final weight, specific growth rate, and feed efficiency rate compared to control groups .","The present study evaluated the growth performance, non-specific immunity and disease resistance in Penaeus vannamei fed diets supplemented with live or dead cells of Clostridium butyricum CBG01 (live cells, CB; sonication-killed cell-free extracts, UI; heat-killed whole-cell, HI; fermentation supernatant, FS; the control, the basal diet without C. butyricum, DZ) for 42 days. Results indicated that the final weight, specific growth rate, survival rate and feed efficiency rate of shrimp in the treatment groups were significantly improved versus the control (P < 0.05). The challenge test of Vibrio parahaemolyticus showed that the cumulative mortalities of shrimp in the CB and UI groups were significantly lower than that in the control (P < 0.05). Compared with the control, alkaline phosphatase, acid phosphatase, total nitric oxide synthase, lysozyme, peroxidase, superoxide dismutase activities, total antioxidant capacity, and phenonoloxidase content in the serum and the relative expression levels of SOD, LZM, proPO, LGBP, HSP70, Imd, Toll, Relish, TOR, 4E-BP, eIF4E1α, eIF4E2 genes in the hepatopancreas of CB and HI shrimp groups were all significantly enhanced, and those were significantly improved in the UI group as well, except for phenonoloxidase content, relative expression levels of SOD, Imd and eIF4E2 genes (P < 0.05). However, immune responses were induced partially in the FS shrimp group. These results suggested that dietary both live and dead cells of C. butyricum CBG01 could improve the growth performance and immune responses of shrimp. When resistance against Vibrio parahaemolyticus in shrimp is considered, sonication-killed cell-free extracts of C. butyricum showed a better effect than heat-killed whole-cells of probiotic. Considering collectively the above, sonication-killed cell-free extracts of C. butyricum could be applied as a potential paraprobiotic to enhance the growth performance, immunity capacity and disease resistance of P. vannamei.",Opposite meaning
i_220,Entailment,"1. Use of Multimodal Interaction Techniques: Hand-Tracking and Voice Input: Combining hand-tracking with voice input can create a more intuitive and accessible interface. This multimodal approach allows users to interact naturally with the VR environment, enhancing their sense of presence and lowering barriers to entry . However, it is likely that this method will only be effective for a limited number of users, as many may still find it challenging to engage with complex interactions.","Hand-tracking has been advertised as a natural means to engage with a virtual environment that also enhances the feeling of presence in and lowers the barriers to entry to virtual reality. We seek to explore combining hand-tracking with voice input (which is then processed with automatic speech recognition) for a novel multimodal experience. Thus, we created Let's Go There, which explores this joint-input method for four functions in virtual reality environments: positioning, object identification, information mapping, and disambiguation. This combination may serve as a more intuitive means for users to communicate and navigate in virtual environments. We expect there to be multiple potential applications of this multimodal form of interaction across numerous domains including training, education, teamwork, and games.
[2]: Hand-tracking has been advertised as a natural means to engage with a virtual environment that also enhances the feeling of presence in and lowers the barriers to entry to virtual reality. We seek to explore combining hand-tracking with voice input (which is then processed with automatic speech recognition) for a novel multimodal experience. Thus, we created Let's Go There, which explores this joint-input method for four functions in virtual reality environments: positioning, object identification, information mapping, and disambiguation. This combination may serve as a more intuitive means for users to communicate and navigate in virtual environments. We expect there to be multiple potential applications of this multimodal form of interaction across numerous domains including training, education, teamwork, and games. Let's Go There, the system described in this paper, was first accepted at CUI 2020, however we also believe there is value in showcasing it at MobileHCI.",Entailment
i_598,Entailment,"However, successful PPPs can lead to sustainable regeneration and improved community resilience .","In the past decade many social housing flat (apartment) complexes in Dublin have undergone some form of regeneration, from minor refurbishment to complete demolition and redevelopment. The context and impetus for such widespread regeneration has been the political articulation that social housing in Ireland, and especially in Dublin, is dysfunctional and unsustainable. It is contended, primarily on the basis of tenure mix arguments, that regeneration will lead to long-term social and environmental sustainability. Consequently, a number of inner city social housing complexes are currently subject to regeneration that involves their demolition and redevelopment as mixed-tenure estates through Public-Private Partnership (PPP) methods. This represents a new social and economic model of regeneration, albeit one which has generated considerable controversy. The process of regeneration has, for example, been criticised as lacking any meaningful community participation, with the mechanisms of the redevelopment process making it difficult for the community to influence the process. More generally, the creation of mixed tenure estates has been criticised as leading to a diminution of social housing in Dublin, as the social housing component in these estates has been significantly reduced. On the positive side, however, it has been argued that this model of social mixing will lead to sustainable regeneration. This paper, which is partly based on ongoing research of some case study estates in Dublin, examines and reflects on the issues of sustainable regeneration and the creation of sustainable communities.
[4]: A public-private partnership to facilitate safe, expedited re-occupancy of structures following a disaster can contribute significantly to overall community resilience. A Building Occupancy Resumption Program (BORP) utilizes trained, private engineers to assist local building departments in conducting post-disaster inspections more efficiently. Under a BORP, the building official agrees to temporarily deputize these private engineers so they may assign legal occupancy status to structures in the event of an emergency such as an earthquake. The building owner retains the engineer, and both must demonstrate a detailed inspection plan and criteria to the building inspector prior to authorization. The program reduces the burden on local jurisdictions during an emergency by expediting the inspection and occupancy-designation process. Additionally, owners may realize significant financial benefits in both the short and long term, gain more control over the fates of their people and facilities, and may seek to initiate risk-mitigating measures based on information gathered during the preparation of the BORP application. With DreamWorks Animation as the pioneering client in southern California, the BORP concept has been refined and successfully implemented in the City of Glendale. Both DreamWorks and the City of Glendale have realized substantial benefits through the implementation of the program, and demonstrated an effective strategy for improving public safety while reducing potential unnecessary business interruption. With a well-planned BORP in place, communities improve their ability to increase safety and reduce economic risks associated with a widespread disaster.",Entailment
s_1974,Unverifiable,"Chlorophyll-a (Chl-a) levels may also influence the migratory patterns of other pelagic fish species in addition to skipjack tuna, .","Using remote sensing of sea surface temperature (SST), sea surface height anomaly (SSHA) and chlorophyll-a (Chl-a) together with catch data, we investigated the detection and persistence of important pelagic habitat hotspots for skipjack tuna in the Gulf of Bone-Flores Sea, Indonesia. We analyzed the data for the period between the northwest and southeast monsoon 2007–2011. A pelagic hotspot index was constructed from a model of multi-spectrum satellite-based oceanographic data in relation to skipjack fishing performance. Results showed that skipjack catch per unit efforts (CPUEs) increased significantly in areas of highest pelagic hotspot indices. The distribution and dynamics of habitat hotspots were detected by the synoptic measurements of SST, SSHA and Chl-a ranging from 29.5° to 31.5°C, from 2.5 to 12.5 cm and from 0.15 to 0.35 mg m<sup>-3</sup>, respectively. Total area of hotspots consistently peaked in May. Validation of skipjack CPUE predicted by our model against observed data from 2012 was highly significant. The key pelagic habitat corresponded with the Chl-a front, which could be related to the areas of relatively high prey abundance (enhanced feeding opportunity) for skipjack. We found that the area and persistence of the potential skipjack habitat hotspots for the 5 years were clearly identified by the 0.2 mg m<sup>-3</sup> Chl-a isopleth, suggesting that the Chl-a front provides a key oceanographic indicator for global understanding on skipjack tuna habitat hotspots in the western tropical Pacific Ocean, especially within Coral Triangle tuna.",Related but unverifiable
i_1213,Entailment,"Interventions and Support: Skill-Building Programs: Programs designed to build caregiving skills and provide emotional support can significantly improve the caregiving experience and outcomes for stroke survivors. For example, the Family Caregiver Support Program and the CARE-CITE program have shown promising results in enhancing caregiver satisfaction and reducing negative outcomes .","Background: Family members provide valuable contributions during rehabilitation after stroke, but frequently report higher incidences of burden, depression, and social isolation during caregiving. Thus, effective interventions to reduce stroke impact on the family are needed. Objectives: To evaluate the content validity and satisfaction of a caregiver-focused web-based intervention designed to improve stroke survivor physical function while reducing caregiver negative outcomes. Methods: Caregivers of individuals with stroke (N = 6) and expert rehabilitation researchers (N = 4) were presented with a novel, web-based intervention (CARE-CITE) designed to foster problem-solving and skill-building while facilitating caregiver involvement during constraint-induced movement therapy. Caregivers rated CARE-CITE for usefulness, ease of use, acceptability, and time to complete. Rehabilitation experts evaluated content for accuracy, feasibility, acceptability, problem relevance and ease of use. Ratings were assessed using a five-point Likert-type response scales (1 = strongly disagree to 5 = strongly agree). Results: On average, all caregivers agreed or strongly agreed that the modules were useful (4.42), easy to use (4.60), and acceptable (4.41). Mean total satisfaction score was 4.45, and average review time was 15 min per module. Expert reviewers agreed or strongly agreed that each module was accurate (4.95), feasible (4.8), easy to use (4.86), acceptable (4.96), and had appropriate problem relevance (4.65). Conclusions: The CARE-CITE intervention may be a viable program for caregivers of patients with stroke. Currently a pilot study is underway to evaluate the impact of the intervention on caregiver mental health, family conflict around stroke recovery and stroke survivor upper extremity function.
[6]: Background and Purpose - There are few evidence-based programs for stroke family caregivers postdischarge. The purpose of this study was to evaluate efficacy of the Telephone Assessment and Skill-Building Kit (TASK II), a nurse-led intervention enabling caregivers to build skills based on assessment of their own needs. Methods - A total of 254 stroke caregivers (primarily female TASK II/information, support, and referral 78.0%/78.6%; white 70.7%/72.1%; about half spouses 48.4%/46.6%) were randomized to the TASK II intervention (n=123) or to an information, support, and referral group (n=131). Both groups received 8 weekly telephone sessions, with a booster at 12 weeks. General linear models with repeated measures tested efficacy, controlling for patient hospital days and call minutes. Prespecified 8-week primary outcomes were depressive symptoms (with Patient Health Questionnaire Depressive Symptom Scale PHQ-9 ≥5), life changes, and unhealthy days. Results - Among caregivers with baseline PHQ-9 ≥5, those randomized to the TASK II intervention had a greater reduction in depressive symptoms from baseline to 8, 24, and 52 weeks and greater improvement in life changes from baseline to 12 weeks compared with the information, support, and referral group (P<0.05); but not found for the total sample. Although not sustained at 12, 24, or 52 weeks, caregivers randomized to the TASK II intervention had a relatively greater reduction in unhealthy days from baseline to 8 weeks (P<0.05). Conclusions - The TASK II intervention reduced depressive symptoms and improved life changes for caregivers with mild to severe depressive symptoms. The TASK II intervention reduced unhealthy days for the total sample, although not sustained over the long term.",Entailment
s_1919,Entailment,"The recovery of carbon stocks after disturbances is always delayed by climate change, which fundamentally disrupts the forest's carbon cycle .","Disturbances alter composition, structure, and functioning of forest ecosystems, and their legacies persist for decades to centuries. We investigated how temperate forest landscapes may recover their carbon (C) after severe wind and bark beetle disturbance, while being exposed to climate change. We used the forest landscape and disturbance model iLand to quantify (i) the recovery times of the total ecosystem C, (ii) the effect of climate change on C recovery, and (iii) the differential factors contributing to C recovery. We reconstructed a recent disturbance episode (2008–2016) based on Landsat satellite imagery, which affected 39% of the forest area in the 16,000 ha study landscape. We subsequently simulated forest recovery under a continuation of business-as-usual management until 2100. Our results indicated that the recovery of the pre-disturbance C stocks (C payback time) was reached 17 years after the end of the disturbance episode. The C stocks of a theoretical undisturbed development trajectory were reached 30 years after the disturbance episode (C sequestration parity). Drier and warmer climates delayed simulated C recovery. Without the fertilizing effect of CO<inf>2</inf>, C payback times were delayed by 5–9 years, while C parity was not reached within the 21st century. Recovery was accelerated by an enhanced C uptake compared to undisturbed conditions (disturbance legacy sink effect) that persisted for 35 years after the disturbance episode. Future climate could have negative impacts on forest recovery and thus further amplify climate change through C loss from ecosystems, but the effect is strongly contingent on the magnitude and persistence of alleviating CO<inf>2</inf> effects. Our modelling study highlights the need to consider both negative and positive effects of disturbance (i.e., C loss immediately after an event vs. enhanced C uptake of the recovering forest) in order to obtain a comprehensive understanding of disturbance effects on the forest C cycle.",Entailment
i_371,Unverifiable,Key Agile Practices: Active Stakeholder Participation: Agile methods require active involvement from stakeholders to ensure the product meets their needs and expectations .,"[9] Agile information systems development methods have become popular; however, which specific agile practice to use remains unclear. We argue that three types of agile practices exist—for management, development, and standards—which affect the customer responsiveness of software teams differently. We examine this theory in a field study of a large organization. We find that agile practices improve software team response effectiveness or efficiency, but not both. Agile standards do not improve response mechanisms but are still important to successful information systems development. Our findings help discriminating agile practices and yield insights into how information development projects should be managed. [10] Several information technology organizations are increasingly using agile software development (ASD) practices for the development of complex software. ASD provides viable architectural strategy that is important for the programming complex systems. The developers can use the Rational Unified Process (RUP) strategy for envisioning the architecture in the product's lifecycle. Agile practices provide flexible strategy for planning and documenting that support specific requirements. They feature several functionalities that can be used to manage the increased documentation and process burden on the project. They enable developers to be flexible to work with enterprise support teams. They also provide features to integrate existing assets, such as legacy databases, shared services, or legacy systems, into new programs. [11] Increasingly, software development organizations are scaling agile practices in the global software development (GSD) environment in order to meet the requirements of the quickly changing and regularly developing business environment. The main objectives of this study are to investigate the key barriers and develop a prioritization-based taxonomy of the barriers for scaling agile development in the GSD environment. Total twenty-two barriers were extracted from the available literature and categorized into five categories, i.e. ""human resources management"", 'coordination"", ""technology"", ""project management"", and ""software methodology"". In the next phase, the identified barriers and their categories were further validated using the questionnaire survey. In the final phase, fuzzy-AHP method, a multi-criterion decision making (MCDM) technique, was applied to prioritize and taxonomy of identified barriers and their related categories was designed. The contribution of this study is not limited to investigate the barriers, but it also provides the roadmap to tackle the issues related to the scaling agile methods in the GSD environment.",Related but unverifiable
i_1119,Entailment,"These models should include regular screening, patient education, and coordinated care plans involving multiple healthcare providers .","Major depressive disorder (MDD) is often a chronic, recurrent, and debilitating disorder with a lifetime prevalence of 16.2% and a 12-month prevalence of 6.6% in the United States. The disorder is associated with high rates of comorbidity with other psychiatric disorders and general medical illnesses, lower rates of adherence to medication regimens, and poorer outcomes for chronic physical illness. While 51.6% of cases reporting MDD received health care treatment for the illness, only 21.7% of all MDD cases received minimal guideline-level treatment. Because the overwhelming majority of patients with depressive disorders are seen annually by their primary care physicians, the opportunity to diagnose and treat patients early in the course of their illness in the primary care setting is substantial, though largely unfulfilled by our current health care system. The goal of treatment is 2-fold: early and complete remission of symptoms of depression and eventual recovery to premorbid levels of functioning in response to acute-phase treatment, and prevention of relapse during the continuation phase or recurrence during the maintenance phase. However, only 25% to 50% of patients with MDD adhere to their antidepressant regimen for the length of time recommended by depression guidelines, and nearly 50% of depressed patients referred from primary care to specialty care treatment fail to complete the referral. Patients with chronic or treatment-resistant depression often require multiple trials using an algorithm-based approach involving more than one treatment strategy. Under conditions of usual care, 40% to 44% of patients with MDD treated with antidepressants in the primary care setting show a >or=50% improvement in depression scores at 4-month follow-up, compared with 70% to 75% of those treated using collaborative care models. This demonstrates the importance of factors other than antidepressant medication per se for achieving treatment effectiveness. Additional research is needed to evaluate longer-term outcomes of algorithm-based, stepped, collaborative care models that incorporate patient self-management in conjunction with usual care. Furthermore, the health care system must undergo major transformation to effectively treat depression, along with other chronic illnesses. The use of evidence-based treatment algorithms are discussed and recommendations are provided for patients and physicians based on collaborative care interventions that may be useful for improving the current management of depressive disorders.
[12]: BACKGROUND: As medical homes are developing under health reform, little is known regarding depression services need and use by diverse safety-net populations in under-resourced communities. For chronic conditions like depression, primary care services may face new opportunities to partner with diverse community service providers, such as those in social service and substance abuse centers, to support a collaborative care model of treating depression. OBJECTIVE: To understand the distribution of need and current burden of services for depression in under-resourced, diverse communities in Los Angeles. DESIGN: Baseline phase of a participatory trial to improve depression services with data from client screening and follow-up surveys. PARTICIPANTS: Of 4,440 clients screened from 93 programs (primary care, mental health, substance abuse, homeless, social and other community services) in 50 agencies, 1,322 were depressed according to an eight-item Patient Health Questionnaire (PHQ-8) and gave contact information; 1,246 enrolled and 981 completed surveys. Ninety-three programs, including 17 primary care/public health, 18 mental health, 20 substance abuse, ten homeless services, and 28 social/other community services, participated. MAIN MEASURES: Comparisons by setting in 6-month retrospective recall of depression services use. KEY RESULTS: Depression prevalence ranged from 51.9 % in mental health to 17.2 % in social-community programs. Depressed clients used two settings on average to receive depression services; 82 % used any setting. More clients preferred counseling over medication for depression treatment. CONCLUSIONS: Need for depression care was high, and a broad range of agencies provide depression care. Although most participants had contact with primary care, most depression services occurred outside of primary care settings, emphasizing the need to coordinate and support the quality of community-based services across diverse community settings. © 2013 Society of General Internal Medicine.",Entailment
i_1621,Contradiction,"Theories Applied: Ecofeminist Theory: This theory links the exploitation of women and nature, suggesting that greater gender equality can lead to better environmental outcomes .","Based on the upper echelons theory, ecofeminist theory, and natural resource-based theory (NRBV), this study has constructed a relational model between female executives' participation, unethical environmental behavior, proactive environmental strategy, and corporate sustainable competitive advantage. The samples include a total of 496 female executives from listed 524 companies in the manufacturing sector in China, and multiple regression methods are used for the analysis. The study showed that female executives' participation had double positive effects on corporate sustainable competitive advantage, which included both the inhibiting effect on unethical environmental behavior and the stimulating effect on proactive environmental strategies. The study also explored the boundary conditions of ""conservative"" and ""proactive"" behaviors from the internal and external perspectives of enterprises. But it was shown that the effect would not be further improved when both moderation effects of environmental stakeholder pressure and environmental leadership were higher at the same time. As enterprises' behaviors should match with their capability range, radical behaviors might run counter to their desires.",Opposite meaning
i_1072,Contradiction,"Key Points: Production and Lifespan: RBCs are produced in the bone marrow and have a lifespan of about 150 days. The body can increase RBC production in response to conditions like anoxia, hemorrhage, or high altitudes .","This chapter will address the special properties of the red blood cells in promoting oxygen carriage, the methods of safe blood and blood component transfusion and consideration of the hazards of these procedures. THE PHYSIOLOGY OF BLOOD The vascular system and the blood which flows within it can be regarded as the communication and nutrient highway of the body. Blood consists of a fluid phase, plasma, and cells of the haematopoietic system (e.g. red blood cells, leucocytes and their precursors). Plasma contains numerous elements, chemical messengers and protective proteins, including coagulation factors. The cellular part of the blood consists of red blood cells, which are discussed in more detail below, platelets, which are essential for normal haemostasis, and white blood cells, which are the travelling immune system responsible for host defence. RED BLOOD CELLS Haemoglobin is packaged into red blood cells, which normally have a lifespan of 120 days. During this time they probably travel about 300 miles and must be sufficiently deformable to pass repeatedly through the microcirculation where the vessels are less than half the red cell diameter. The special properties of the red cell skeleton (forming a biconcave disc) and metabolic pathways are crucial to these features and any disturbance of these, such as inherited or acquired structural abnormalities (e.g. spherocytosis) or enzyme defects, is likely to adversely affect function and therefore oxygen carrying capacity. One of the key functions of blood is the transport of oxygen (mainly by the haemoglobin in the red cells) to the tissues and removal of carbon dioxide from them. Red blood cells are produced in the bone marrow, originating from pluripotent stem cells, and are released in a carefully controlled manner so that the production of new red cells (about 2 X 1011 per day) balances the rate of destruction. The rate of production can be increased considerably (up to about eight times the normal rate) and occurs when demand is increased as a consequence of anoxia, haemorrhage, haemolysis or at increased altitudes. Red cell production is controlled by many factors such as the supply of essential constituents and cofactors (including iron, B12 and folate), specific hormones and cytokines, erythropoietin in particular, and others such as growth hormone, thyroxin, corticosteroids and androgens. Erythropoietin is produced mainly in the kidneys, with some produced in the liver, and it enhances red cell production in response to tissue anoxia.",Numeric error
s_324,Entailment,Effects on Careers in Software Engineering: Educational Implications: The integration of AI in software engineering necessitates changes in engineering education to prepare future engineers for the evolving landscape. This includes incorporating AI-related topics into the curriculum and fostering skills like anticipatory and responsible thinking .,"The academic press is increasingly discussing the impact of Artificial Intelligence (AI) technologies on education and science. Researchers pay attention not only to the applied aspects of the use of AI technologies, but also to the issues of the ontological foundations of activity that are being transformed under the influence of new technologies. However, the issues of the impact of AI technologies on engineering activity, engineering thinking and, consequently, on engineering education are not sufficiently reflected in academic publications. Moreover, the aspects related to the widespread use of artificial intelligence, both in professional activities and in everyday life, remain insufficiently studied. The article proposes theses and corresponding arguments that clarify the fundamental changes occurring in engineering activity and engineering thinking in the context of the expansion of artificial intelligence technologies. Engineering activity is presented as a system that is not identical to the activity of individual engineers. A definition of engineering activity is proposed, which reveals its essence through its goal of solving human and societal problems. A non-instrumental approach to the interpretation of engineering based on AI technologies is substantiated, within which artificial intelligence appears as a partner in engineering activity. Finally, engineering thinking is complemented by anticipatory and responsible thinking. The article is a contribution to the academic discussion on the specifics of engineering activity and engineering thinking at the present stage.",Entailment
s_1688,Entailment,"While these plants are mentioned in cultural practices, their significance in traditional knowledge may not be as widely recognized or consistently passed down through generations as suggested .","We analyse the use of medicinal plants by local populations from two parishes in central Estonia in the 1930s applying a model of herbal landscape. Our study, based on archived records of traditional ecological knowledge of 11 schoolchildren and 5 adults, compares the individuals. expertise of medicinal plants to the common knowledge of the local community. This shared knowledge, passed on from generation to generation inside the community (ecocultural commons), is distributed unequally among its members. The results of the study show that 65 plant and 3 fungi taxa were used in folk medicine to deal with 49 indications. Further, the study reveals how knowledge on plants was distributed among individuals throughout the local communities and how folk wisdom about medicinal plants was preserved. The individual herbal landscapes of the respondents varied considerably, with the usage of many plants shared by only a few members of the community. Still, the general pattern of the communal herbal landscape follows relatively well the pattern of the plant use in folk medicine in Estonia at the time under review, with just a few exceptions. Hence, every person partakes in the knowledge of the ecocultural commons, whereas the individual share of the community.s knowledge is not complete.",Entailment
i_1576,Contradiction,"Microplastics (MPs): Distribution and Impact: MPs are primarily found in water and air, with minimal presence in soil, suggesting that their impact is largely limited to aquatic environments .","Microplastics are emerging global contaminants and pollutants. There is growing interest in the scientific community on the subject of microplastics. This chapter focuses on the global scenario of microplastics as persistent contaminants in the environment. Recent advances in multidisciplinary research on microplastics, including distribution in the aerosphere, hydrosphere, and soil, as well as the sources, fate, distribution, toxicity, and management of microplastics, are covered in this chapter. Most microplastics are generated on land and end up in the marine environment. This chapter reviews the status of single-use plastics and microplastics in the aerosphere, aquatic environment, soil systems, and food chain and web, along with treatment technologies and management aspects. Sampling methods and treatment and analytical techniques used to identify microplastics in the triad of the environment are covered. Microplastics in beach and marine environments, leaching and adsorption, and microplastics from landfills and industrial wastewaters are appraised in the hydrosphere. Additionally, the presence of microplastics in sewage sludge and soils irrigated with wastewater or fertilized with sludge, as well as the possible effects on plants and human health, are discussed. Necessary strategies, including valuable resources for environmental researchers, ecologists and toxicologists, policymakers, and non-experts, are also covered. Macro-and molecular-level interactions of microplastics with the human, animal, and environmental domains of the triad are highlighted.
[2]: Microplastics (MP) are frequently detected in both aquatic (marine and freshwater) and atmospheric environments. The size of MP is usually < 5 mm. MP are considered as emerging contaminants. This chapter critically analyzes the recent developments on the occurrence and distribution of MP in aquatic and air environments. Extensive use of plastic products and improper management of plastic wastes lead to generation of MP upon exposure to environmental conditions. Environmental fate and transport of MP depend on their physical characteristics (size and density), existing aquatic conditions (water current and turbulence) and prevailing weather conditions (sunlight, rainfall and wind speed). MP exert ecotoxicity to aquatic biota, respiratory ailments upon inhalation of polluted air, and bioaccumulation in the food chain. Potential control strategies for reduction of MP levels in water and air include use of biodegradable plastic products, enhancement of plastic recycling contributing to circular economy, and removal through adsorption. Key knowledge gaps and future research directions are highlighted.",Opposite meaning
i_259,Unverifiable,"Structure: ResUNet has an encoder-decoder structure. The encoder captures the context of the input image through a series of convolutional and down-sampling layers, while the decoder reconstructs the segmentation map using up-sampling layers .","Medical imaging has been a proactive tool for doctors to diagnose and treat diseases via the qualitative and quantitative analyses based on non-invasive lesions. Medical images have been interpreted via computer tomography (CT), X-ray, magnetic resonance imaging (MRI) and positron emission tomography (PET). The barriers of medical image segmentation need to be resolved due to low contrast amongst the lesion, the surrounding tissue and blurred edges of the lesion. Labeling manually for hundreds of slices of organs or lesions has been quite time-consuming due to anatomy of the human body and shape of lesions. Manual labeling has intended to high subjective and low reproducibility. Doctors have been beneficial from a automatically locating, segmenting and quantifying lesions. Deep learning has been used widely in medical image processing. Deep learning-based U-Net has played a key role in the lesions segmentation. The encoding and decoding ways has made U-Net structures simply and symmetrically. Features extraction of medical images has been realized via convolution and down-sampling operations. The image segmentation mask via the transposed convolution and concatenation has been interpreted. A small-sized dataset has achieved qualified medical image segmentation. U-Net has been summarized and analyzed on the four aspects: the definition of U-Net, the upgrading of U-Net model, the setup of U-Net structure and the mechanism of U-Net. Four research areas have been proposed as below: 1) the basic structure and working principle of U-Net via convolution operation, down sampling, up sampling and concatenation. 2) U-Net network model have been demonstrated in three aspects in the context of the number of encoders, multiple U-Net cascades and other models combined with U-Net. U-Net based network have been divided into two, three and four encoders further in terms of the amount of encoders: Y-Net, Ψ-Net and multi-path dense U-Net. Multiple U-Nets cascade has been categorized into multiple U-Nets in series and multiple U-Nets in parallel based on the cascades mode of multiple U-Nets. In addition U-Net has improved the segmentation performance on the aspects of dual tree complex wavelet transform, local difference method, level set, random walk, graph cutting, CNNs(convolutional neural networks) and deep reinforcement learning. The upgrading of U-Net network structure have been divided into six subcategories including image augmentation, convolution operation, down-sampling operation, up-sampling operation, model optimization strategies and concatenation. Image enhancement has be divided into elastic deformation, geometric transformation, generative adversarial networks (GAN), Wasserstein generative adversarial networks (WGAN) and real-time image enhancement further. The convolution operation has been improved via padding mode and convolution redesign. The padding mode mentioned has adapted constant padding, zero padding, replication padding and reflection padding and improvements to dilated convolution, inception module and asymmetric convolution. The down-sampling has been improved via max-pooling, average-pooling, stride convolution, dilated convolution, inception module and spatial pyramid pooling. Several up-sampling improvements have illustrated simultaneously via sub-pixel convolution, transposed convolution, nearest neighbor interpolation, bilinear interpolation and trilinear interpolation. Model optimization strategies have been divided into two aspects in detail of activation function and normalization, the improvements of activation function includes rectified linear unit(ReLU), parametric ReLU(PReLU), random ReLU(RReLU), leaky ReLU(LReLU), hard exponential linear sigmoid squahing(HardELiSH) and exponential linear sigmoid squashing(ELiSH), and normalization method. The improvements have been to shown based on batch normalization, group normalization, instance normalization and layer normalization. The concatenation based improvement has been one of the future research area. The current concatenation improvements have been mainly realized via attention mechanism, new concatenation, feature reuse and de-convolution with activation function, annotation information fusion from Siamese network. The improved mechanisms in the U-Net network have been emphasized based on residual mechanism, dense mechanism, attention mechanism and the multi-mechanisms integration. The segmentation performance of the network can be enhanced. The further four research areas in U-Net have been illustrated as below: 1) the generalization of deep learning methods cannot be customized to fit the segmentation network for specific scenarios in the future. 2) Supervised deep learning models have required a lot of annotated images labeled for treatment. Unsupervised and semi-supervised deep learning models have been a vital research work further. 3) The low interpretability of U-Net network has lead the low acceptance in the mechanism of its operation.4) More accurate segmentation mask with fewer parameters has been obtained via good quality network structure. The precise manual segmentation has been so time-consuming and labor intensive. The simplified and quick semi-automatic segmentation has relied on the parameters and user-specified image preprocessing. The deep learning-based U-Net network has been segmented the lesions quickly, accurately and consistently. The structure, improvements and further research areas of U-Net network have been analyzed to the development of U-Net network.",Related but unverifiable
s_1910,Contradiction,"Enhanced Nutrient Availability: Coastal browning can lead to increased nutrient levels in the water, which can benefit jellyfish. The decomposition of organic matter associated with browning releases nutrients such as nitrogen and phosphorus into the water, which can enhance the growth of jellyfish prey, such as zooplankton . This nutrient enrichment supports the food web that jellyfish rely on.","The increasing trend in jellyfish blooms that have been observed in some coastal areas around the world can have serious ecological consequences. In particular, the fate of jellyfish organic matter (jelly-OM), after the decay of jellyfish blooms, and their implications for marine biogeochemical cycles and ecosystem functioning, are still unclear. In order to study bacteria-jelly-OM interactions and the associated fate of the jelly-OM, we conducted two sets of short-term jelly-OM enrichment experiments using coastal and offshore ambient pelagic bacterial assemblages from the Black Sea, where the scyphozoan medusa Aurelia aurita blooms seasonally. The microbial transformation of the jelly-OM was followed using a stable δ<sup>13</sup>C and δ<sup>15</sup>N analyses of particulate jelly-OM together with standard organic and inorganic matter chemical analyses. The effect of the jelly-OM on the ambient bacterial community was investigated by following changes in bacterial abundance, growth rates, and community structure. The Black Sea's surface bacterial assemblages from both systems, coastal and offshore, responded rapidly to the jelly-OM enrichment, preferentially utilizing nitrogen-rich constituents of the jelly-OM, leaving carbon-enriched particulate OM (hypothetically recalcitrant) in the system. The end products of the bacteria-mediated jelly-OM degradation process, i.e. total dissolved nitrogen and ammonium, accumulated in the system, indicating possible implications for the nitrogen cycle. Despite the differences in the Black Sea's coastal and offshore seawater background nutrient concentrations and particulate OM quality, the nitrogen budget was very much the same in both studied systems, however there were differences in the bacterial community function/performance from these two environments. The addition of jelly-OM triggered different structural changes in the coastal and offshore ambient bacterial communities, suggesting that different bacterial groups were capable of utilizing jelly-OM. A comparison of the response of natural bacterial community to the jelly-OM and the bacterial transformation of the jelly-OM in different marine ecosystems indicates that the degree of bacterial growth rate and the rate of ammonium accumulation depend on the incidence of jellyfish occurrence, physiochemical environmental conditions, and possibly also on ambient bacterial community composition. Our study provides insights into the nature of bacteria-jelly-OM interactions, the processes and mechanisms of bacterial jelly-OM transformation, and the consequences for marine nitrogen (and carbon) cycle, as well as for the functioning of different coastal marine ecosystems.
[2]: Over the past several decades, jellyfish blooms have intensified spatially and temporally, affecting functions and services of ecosystems worldwide. At the demise of a bloom, an enormous amount of jellyfish biomass sinks to the seabed and decomposes. This process entails reciprocal microbial and biogeochemical changes, typically enriching the water column and seabed with large amounts of organic and inorganic nutrients. Jellyfish decomposition was hypothesized to be particularly important in nutrient-impoverished ecosystems, such as the Eastern Mediterranean Sea-one of the most oligotrophic marine regions in the world. Since the 1970s, this region has been experiencing the proliferation of a notorious invasive scyphozoan jellyfish, Rhopilema nomadica. In this study, we estimated the short-term decomposition effects of R. nomadica on nutrient dynamics at the sediment-water interface. Our results show that the degradation of R. nomadica has led to increased oxygen demand and acidification of overlying water as well as high rates of dissolved organic nitrogen and phosphate production. These conditions favored heterotrophic microbial activity and bacterial biomass accumulation, and triggered a shift towards heterotrophic biodegrading bacterial communities, whereas autotrophic picophytoplankton abundance was moderately affected or reduced. This shift may further decrease primary production in the water column of the Eastern Mediterranean Sea. Deoxygenation, acidification, nutrient enrichment, and microbial community shifts at the sediment-water interface may have a detrimental impact on macrobenthic communities. Based on these findings, we suggest that jelly-falls and their decay may facilitate an additional decline in ecosystem functions and services.",Misrepresentation
s_795,Contradiction,"1. Resource Assessment: Methods: Offshore wind resource assessment methods include historical meteorological data, numerical simulations, satellite remote sensing, and reanalysis data . While these methods are used, they are not effective in accurately predicting wind energy resources over long periods, as they often rely on outdated data.","Four methods for assessment of China's offshore wind energy resources based on historical data of meteorological stations, numerical simulations, satellite remote sensing technology and reanalysis data over the past 30 years, and their characteristics, are summarized and analyzed. The main achievements and problems of the five offshore wind energy assessments based on census and detailed surveys are compared. The view that the standard for assessment of land wind resources cannot be fully applicable for the assessment of offshore wind energy is presented, and the importance of prediction of the wind energy resources in the coming decades is expounded. The proposals of accelerating the construction of the assessment system of offshore wind energy resources, accomplishing the long-term prediction of the variation trend of wind energy resources and strengthening the environmental impact assessment of offshore wind energy development and utilization are given.
[2]: Wind energy is recognised as one of the economically viable and substantiate renewable energy technologies worldwide to expedient the rising electricity requirements in a sustainable way. Presently, India has onshore wind farms accounting the fifth largest wind power capacity in the world. The National Offshore Wind Energy Policy 2015 of the Government of India aims to harness the wind resources within the Exclusive Economic Zone (EEZ). Accordingly, a target of 60,000 MW power generation by 2022 has been set to realise from onshore and offshore wind farms. The traditional method of wind resource assessment for wind energy applications is carried out by analysing a large amount of in situ wind data at different heights. In Indian waters, there are few offshore wind buoys and meteorological masts and are limited to few locations. Satellite remote sensing helps in providing synoptic data due to its larger swaths, better repetivity and longer acquisition periods. Microwave scatterometers are one among them, which provide sufficient data over the entire globe. In this study, the offshore wind climatology in the Indian seas (the Bay of Bengal and the Arabian Sea) is generated from large datasets of QuikSCAT (1999–2009), OSCAT (2010–2014), ASCAT on-board Metop-A (2010–2016) and on Metop-B (2012–2016) scatterometers synergistically. Orbit-wise scatterometer wind products have been processed to generate long-term synoptic monthly means of wind speed and direction. Wind Power Density-WPD (W/m<sup>2</sup>) was calculated using Weibull distribution parameters at 10 m height. The wind speed, WPD, Power production have been estimated at different heights above the sea surface using a combination of logarithmic law and Weibull scale and shape parameters for few standard turbines of different capacities. Monthly and Annual wind energy potential has been estimated by considering the bathymetric variations and distance away from the coast for all the coastal states within the EEZ of Indian coast.",Opposite meaning
s_1902,Contradiction,"Additionally, biotechnology and tree breeding have been employed to restore species like Castanea dentata, integrating technological, ecological, and social spheres for successful restoration .","[1] Worldwide, Indigenous peoples are leading the revitalization of their/our cultures through the restoration of ecosystems in which they are embedded, including in response to increasing ""megafires."" Concurrently, growing Indigenous-led movements are calling for governments to implement Indigenous rights, titles and treaties, and many settler-colonial governments are committing to reconciliation with Indigenous peoples and to implementing the United Nations Declaration on the Rights of Indigenous Peoples. Yet, despite growing recognition that just and effective conservation is only possible through partnerships with, or led by, Indigenous peoples, decolonizing approaches to restoration have received insufficient attention. However, reconciliation will be incomplete without Indigenous-led restoration of Indigenous lands, knowledges, and cultures. In this article, we introduce the concept of ""walking on two legs"" to guide restoration scientists and practitioners in advancing the interconnected processes of Indigenous-led restoration and reconciliation in Indigenous territories. As an action-oriented framework articulated by Secwépemc Elder Ronald E. Ignace, ""walking on two legs"" seeks to bring Indigenous knowledges into balance with western scientific knowledge in service of upholding an Indigenous stewardship ethic that is embedded in Indigenous ways of relating to land and embodies principles of respect, reciprocity, and responsibility. Grounding this discussion in the context of fire-adapted ecosystems of western Canada and unceded and traditional Secwépemc territory, Secwepemcúl̓ecw, we argue that walking on two legs, along with principles of reconciliation, offers a pathway to uphold respectful relationships with Indigenous peoples, knowledges, and territories through Indigenous-led restoration. [14] In Big Ecology, David C. Coleman documents his historically fruitful ecological collaborations in the early years of studying large ecosystems in the United States. As Coleman explains, the concept of the ecosystem-a local biological community and its interactions with its environment-has given rise to many institutions and research programs, like the National Science Foundation's program for Long Term Ecological Research. Coleman's insider account of this important and fascinating trend toward big science takes us from the paradigm of collaborative interdisciplinary research, starting with the International Geophysical Year (IGY) of 1957, through the International Biological Program (IBP) of the late 1960s and early 1970s, to the Long-Term Ecological Research (LTER) programs of the 1980s. © 2010 by The Regents of the University of California.",Misrepresentation
s_1421,Entailment,"Effects of Various Supplements on Ruminal Fermentation: Flavonoids and Essential Oils: Supplementation with flavonoids and essential oils from Piper betle L. increased total VFA production and altered the VFA profile in dairy goats, implying that this could lead to a significant enhancement in overall ruminal health and performance .","Context: Rumen biohydrogenation is an important way to produce conjugated linoleic acid (CLA), especially the rumenic acid isomer. However, CLA is principally synthesised endogenously in lactating mammals by delta 9-desaturase in breast tissue. Aims: The aim of the study was to evaluate milk fatty acid profile, rumen microbial population and animal performance in response to diets containing sunflower oil either supplemented with or without flavonoids and essential oils from Piper betle L. powder (PP) in dairy goats. Method: Twelve multiparous Saanen goats (42 ± 1.00 kg; mean ± s.d.) were randomly assigned to two treatment groups in an experiment that lasted for 6 weeks. The two experimental diets formulated as total mixed ration were: Control (CTH) diet (containing 0% PP) and DPB diet (CTH diet containing 1.3% PP on a dry-matter basis). Key results: Inclusion of flavonoids and essential oils from PP in the diet (DPB) did not affect dry-matter intake but resulted in a greater milk yield and altered the composition of milk. Compared with the control diet (CTH), the DPB diet decreased the saturated fatty acid concentration and increased the unsaturated fatty acid concentration in milk. Inclusion of PP decreased the C18:0 production (P < 0.05), resulting in higher C18:1 trans11 and C18:2 cis9 trans11 (P < 0.05) concentrations. Overall, DPB diet increased the total CLA by 1.5-fold, from 1.77 to 2.62 g/100 g fatty acid. The desaturase rate (except desaturase for carbon 18, P < 0.05), and atherogenic and thrombogenic indices were not affected by inclusion of PP in the DPB diet. Moreover, the DPB diet escalated total volatile fatty acid production and altered the volatile fatty acid profile. Compared with goats fed with CTH diet, PP supplementation increased the presence of ruminal Butyrivibrio fibrisolvens by ∼5-fold, but the presence of B. proteoclasticus decreased to about 1/11 of the control. Conclusions: The use of sunflower oil at 17.6 g/kg diet and inclusion of a practical dose of flavonoids and essential oils from Piper betle L. leaves in the diet of dairy goats can be an efficient method to improve milk yield and milk composition, including increasing the CLA concentration of milk. Implications: These results constitute an alternative strategy to improve milk quality, without negatively affecting animal performance.",Entailment
s_1603,Entailment,"Mechanical Control: Hand weeding is labor-intensive but highly effective, achieving up to 97% weed control in some cases .","To evaluate the efficacy of different weed control methods and to determine an optimum sowing time for direct-seeded rice (DSR), a field trial was conducted during the summer season of 2012. Treatments comprised of two weed control methods viz; hand weeding (W2) and chemical control (W3) using pendimethalin at 1137 g a.i. ha<sup>-1</sup> (pre-emergence) and bispyribac Na at 30 g a.i. ha<sup>-1</sup> (post-emergence), 20 and 40 d after sowing (DAS) of rice and a weedy check (W<inf>1</inf>) for comparison while crop was sown on various sowing dates viz; D<inf>1</inf>=1<sup>st</sup>, D<inf>2</inf>=10<sup>th</sup>, D<inf>3</inf>= 20<sup>th</sup> and D<inf>4</inf>=30<sup>th</sup> June. The experiment was laid out in split-plot design and replicated thrice. Data pertaining to weeds and yield traits revealed that all weed control methods and sowing dates substantially affected the weed flora, yield and related components of DSR over weedy check. The 20<sup>th</sup> June sowing proved to be an optimum sowing date, exhibiting highest paddy, straw and biological yield (4.50, 14.23 and 18.73 t ha<sup>-1</sup>, respectively) in hand-weeded plots. Moreover, hand weeding and chemical weed control gave 97% and 84% weed control, respectively, over weedy check. Reduced weed intensity and biomass in hand-weeded plots resulted in better crop growth and ultimate yield.",Entailment
i_537,Entailment,Key Advancements in Self-Repairing Electronic Technologies: Energy Storage Devices: Self-Healing Batteries: Incorporating self-healing features into solid-state batteries can significantly improve their stability and performance by addressing physical and chemical degradation issues .,"Major improvements in stability and performance of batteries are still required for a more effective diffusion in industrial key sectors such as automotive and foldable electronics. An encouraging route resides in the implementation into energy storage devices of self-healing features, which can effectively oppose the deterioration upon cycling that is typical of these devices. In order to provide a comprehensive view of the topic, this Review first summarizes the main self-healing processes that have emerged in the multifaceted field of smart materials, classifying them on the basis of their recovering mechanisms. Then, attention is closely focused on self-healable energy storage devices. In particular, self-healing in lithium-ion and lithium–metal batteries is discussed, emphasizing both the physical (cracks, fractures, cuts, etc.) and chemical (degradation, gas production, etc.) issues that currently threaten the operating life of these devices, and the more effective self-healing strategies which can prevent or postpone undesired and dangerous failures. Finally, an outlook on the possible resolution of relevant challenges is briefly discussed.",Entailment
s_1856,Contradiction,"Meteorological Inputs: Surface Wind Forcings: Inaccurate surface wind data is irrelevant as it does not significantly influence the numerical ocean models used for storm surge predictions. Poor estimation of wind fields, ignoring asymmetry and dynamics of hurricanes, does not affect the accuracy of storm surge forecasts .","Storm surge is the onshore rush of seawater associated with hurricane force winds. Storm surge can compound the effects of inland flooding caused by rainfall, leading to loss of property and loss of life for residents of coastal areas. Numerical ocean models are essential for predicting which coastal areas are most likely to be impacted by storm surge. These numerical physics-based models are driven primarily by the surface wind forcings which are currently specified by a deterministic formula. Although these equations incorporate important physical knowledge about the structure of hurricane surface wind fields, they cannot always capture the asymmetric and dynamic nature of a hurricane. This article develops a new multivariate spatial statistical framework to improve the estimation of these wind field inputs while accounting for potential bias in the observations. We find that this spatial model consistently improves parameter estimation and prediction for surface wind data for a case study of Hurricane Charley of 2004 when compared to the original physical model. These methods are also shown to improve storm surge estimates when used as the forcing fields for a numerical three-dimensional coastal ocean model. © 2008 American Statistical Association and the International Biometric Society.",Entity error
i_71,Unverifiable,"Capability Development: Successful AI implementation is largely dependent on developing specific capabilities, particularly understanding and integrating AI models, which are the only factors influencing success .","Governments around the world are implementing artificial intelligence (AI) systems with varying success. The autonomous, learning and inscrutable nature of machine learning models behind AI technology suggests that organisations need to develop novel capabilities to ensure successful implementation. However, the understanding of what such capabilities are and how they can be developed is still emerging. This paper reports on qualitative case study research conducted on AI projects in three Australian public service domains: taxation, law enforcement and healthcare. The findings point towards five distinct areas of capability that should be invested in: model development, domain understanding, model explanation, model integration, and model assurance. Each one has multiple dimensions which are discussed in detail, along with empirical insights on how the capability can be developed.",Unrelated and unverifiable
i_1720,Contradiction,"Timely maintenance can help maintain smoother pavement surfaces, reducing noise pollution and improving air quality around airports .","Both the design and the construction of airfield pavements have to be consistent with strict requirements and constraints and also higher safety standards due to their particular setting. In addition, maintenance and construction times must be minimized in order to avoid delays and limitations on airport capacity. Maintaining or constructing airfield pavements also entails working during all-weather conditions (e.g. winter time and heavy cold conditions); materials adopted therefore play a major role in the success of the maintenance or construction activity. Environmental management plans and eco-friendly policies and strategies are increasingly being adopted by airport directors. Noise reduction plans through improved air traffic management techniques, emissions control for aircraft engines and ground maneuvering vehicles, reuse of water for washing airfield pavements, use of renewable energies, and use of photocatalytic materials are only some of the numerous ways of achieving a sustainable airport. The paper focuses on construction techniques and the development of innovative materials for the achievement of environmental sustainability on airfield pavements. In particular, the authors present how a long lasting and well performing airport pavement can be built if more than 85% of the materials used are recycled materials. The environmental analysis of a case study on a major Italian airport shows that the release of almost 35% of emissions could be avoided if recycling practices are taken into account. Furthermore, pavement performance is analyzed and monitored as well in order to show that recycling does not necessarily result in lower performance. Outcomes clearly suggest that the recycled airport pavement has a comparable performance and less of an environmental impact on standard airfield pavements. Moreover, results can be implemented into an Airport Pavement Management System to assess the best strategy, considering the environmental footprint in addition to the traditional performance analysis and cost effectiveness. © 2012 Elsevier B.V. All rights reserved.",Missing information
s_353,Entailment,Tools and Software: Wireshark is a network protocol analyzer that can be used to monitor network traffic and detect suspicious activities indicative of sniffing attacks .,"This educational project uses a second generation Raspberry Pi that runs multiple Open Source software packages, to perform network penetration testing and to analyze the results. Implementing this project provides undergraduate students with practical hands-on experience and explains advanced concepts in computer hardware, operating systems, and network security. This project is fairly affordable, highly portable, easily deployable, alarmingly impactful, and highly rewarding. It also demonstrates the need for secure wireless networks against various attacks such as Man-in-the-Middle (MitM). This paper illustrates step-by-step instructions to assemble and integrate the project's hardware parts, to download and configure software packages, and to perform customized network operations such as packet sniffing and filtering. Kali Linux for Raspberry Pi is the chosen operating system due to its extensive and powerful collection of White Hat hacking tools such as Wireshark (Network Protocol Analyzer), Nmap (Network Mapper), and SSLstrip (Secure Sockets Layer strip). Additional wireless network auditing tools are used from the robust FruityWifi package. Wireshark filters, captures, and analyzes network packets, such as hypertext transfer protocol secure (HTTPS) requests. SSLstrip strips the secure connection and convert HTTPS to hypertext transfer protocol (HTTP), gaining access to sensitive information such as login credentials. This simple to implement yet powerful project, demonstrates the ease of hiding and discreetly deploying a Raspberry Pi on a vulnerable wireless network to sniff network packets that is considered protected behind firewalls, while maintaining a safe distance and anonymity from the target.
[9]: Cybersecurity of industrial control systems (ICS) is an essential research area due to increasing critical asset-Targeted cyberattacks and their potential severe consequences. Current intrusion detection systems (IDS) are primarily based on network traffic monitoring, which may be not sufficient for detecting comprehensive and carefully prepared cyberattacks. In this situation, the combination of empirical monitoring with statistical anomaly detection technique is a promising and feasible approach to early detection of ICS cyberattack that takes advantage of numerous and various sensors used in industry; this may provide a complementary approach to traditional network-based intrusion detection to improve coverage of detectable cyberattacks. The motivation of this study is to generate ICS intrusion data to study the use of empirical models for ICS cybersecurity. In this paper, a real-Time ICS test bed, which includes a physical two-loop forced flow system, LabVIEW-based supervisory control and data acquisition (SCADA) system, and Kali Linux-incorporated cyber network that conducts attacks within the local area network (LAN), is deployed to generate relevant data. Three cyberattacks scenarios are carried out in this paper, including packets sniffing with man-in-The-middle (MITM) attack; denial-of-service (DoS) attack to SCADA slave with spoofed IP address; and change command with spoofed SCADA master by MITM attack. Physical process data, including field sensor data, which represents industrial process data, are collected by the LabVIEW-based SCADA system. Network communication data are collected with Wireshark. The significance of this test bed is providing both industrial process data and network communication data of normal and under-Attack situation, which will be useful in future empirical model based intrusion detection analysis. Future works will focus on improving the ICS test bed through integrating industrial protocols and collect more intrusion data for studying IDS.",Entailment
s_515,Unverifiable,"Practical Implementation: Pilot Testing: Conducting pilot tests can help refine the system and ensure its practical feasibility. For example, the electric bus system's pilot test provided valuable insights into the operational efficiency and potential business opportunities .","As part of the ongoing effort to be independent of petroleum resources and to be free from pollutant emission issues, various electric vehicles have been developed and tested through their integration with real world systems. In the current paper, yet another application specific EV for public transportation, an electric bus, is introduced and explained with results from the pilot test program which was carried out under real traffic conditions. The main feature of the current system is a battery exchanging mechanism mounted on the roof of the bus. The current configuration certainly requires an externally fabricated battery exchanging robot system that would complement the electric bus for a fully automated battery exchanging process. The major advantage of the current system is the quick re-charging of the electric energy through the physical battery exchange and the possible utilization of the battery exchange station as a mini scale energy storage system for grid system peak power shaving. With the total system solution approach for the public transportation system, it is fully expected to create outstanding business opportunities in number of areas such as battery suppliers, battery exchanging station management, battery leasing and many more.",Related but unverifiable
i_1586,Unverifiable,"Environmental Impacts on Marine Life: Marine Mammals and Seabirds: Offshore wind farms have no significant effects on marine mammals and seabirds, as studies show that the construction and operation of wind farms do not generate enough underwater noise to disturb marine life, including small whales and seals .","Offshore wind power provides a valuable source of renewable energy that can help reduce carbon emissions. Technological advances are allowing higher capacity turbines to be installed and in deeper water, but there is still much that is unknown about the effects on the environment. Here we describe the lessons learned based on the recent literature and our experience with assessing impacts of offshore wind developments on marine mammals and seabirds, and make recommendations for future monitoring and assessment as interest in offshore wind energy grows around the world. The four key lessons learned that we discuss are: 1) Identifying the area over which biological effects may occur to inform baseline data collection and determining the connectivity between key populations and proposed wind energy sites, 2) The need to put impacts into a population level context to determine whether they are biologically significant, 3) Measuring responses to wind farm construction and operation to determine disturbance effects and avoidance responses, and 4) Learn from other industries to inform risk assessments and the effectiveness of mitigation measures. As the number and size of offshore wind developments increases, there will be a growing need to consider the population level consequences and cumulative impacts of these activities on marine species. Strategically targeted data collection and modeling aimed at answering questions for the consenting process will also allow regulators to make decisions based on the best available information, and achieve a balance between climate change targets and environmental legislation.
[2]: Offshore wind energy is a new technology created by the merging of classical wind energy technology and classical offshore technology. Wind speeds are considerably higher over the sea as compared to onshore sites, but also the cost per installed kW will increase when moving offshore. The rapid development of wind energy use in Germany is accompanied by an increase of the installed power per wind turbine. In the German areas of the North and Baltic Seas, several large offshore wind farms are planned; each with several hundreds turbines of up to 5 MW each. The Institute for Structural Analysis (ISD) of the University of Hannover, the German Wind Energy Institute (DEWI) in Wilhelmshaven, and the Institute for Technical and Applied Physics (itap) in Oldenburg are partners in a project on: Standard Procedures for the Determination and Assessment of Noise Impact on Sea Life by Offshore Wind Farms which is funded by the German Federal Ministry for Environment (BMU). The aim of this project (CRI, DEWI, itap 2004) is to study the generation, radiation and attenuation of underwater noise, to develop forecasting hydro sound models of offshore wind converters and future noise reduction methods during pile driving, to determine the impact area of offshore wind farms, to allow the formulation of recommendations for acoustic emission thresholds for offshore wind farms in cooperation with biologists, and to develop standard procedures for the determination and assessment of noise emissions. The operation and in particular the construction of offshore wind converters induce considerable underwater noise emissions. It is assumed that small whales and seals can be affected by noises from machines and vessels, piling and installation of the wind turbines. Piling, in particular using hydraulic hammers creates high frequency noise with considerable sound power levels. Currently, only little knowledge about the effects of different noises to marine life is available. With a view to determining the effects on the marine flora and fauna and structural design aspects, the research platform FINO 1 (Fig. 1) was erected in the North Sea. Measurements of the underwater noise during construction of offshore research platforms and numerical investigations are used to develop future forecasting hydro sound models of offshore wind converters. © Springer-Verlag Berlin Heidelberg 2006. All rights are reserved.",Related but unverifiable
i_874,Entailment,"** Principles and Mechanisms of Electropolishing** Electropolishing is an electrochemical process used to smooth and polish metal surfaces by selectively removing material through anodic dissolution. This process is widely applied to improve the surface finish, corrosion resistance, and cleanliness of metals, particularly aluminum .","Electropolishing is a widely-used electrochemical surface finishing process for metals. The electropolishing of stainless steel has vast commercial application, such as improving corrosion resistance, improving cleanness, and brightening. The surface topography characterization is performed using several techniques with different lateral resolutions and length scales, from atomic force microscopy in the nano-scale (<0.1 μm) to stylus and optical profilometry in the micro- and mesoscales (0.1 μm-1 mm). This paper presents an experimental length scale study of the surface texture of ground stainless steel followed by an electropolishing process in the micro and meso lateral scales. Both stylus and optical profilometers are used, and multiple cut-off lengths of the standard Gaussian filter are adopted. While the commonly used roughness amplitude parameters (Ra, Rq and Rz) fail to characterize electropolished textures, the root mean square slope (RΔq) is found to better describe the electropolished surfaces and to be insensitive to scale.
[2]: As a popular application of electrochemical anodic dissolution, electropolishing is extensively adopted in the surface finishing industries of metals. Anodic dissolution is a complex reaction with many process parameters and chemical properties involved. A simple explanation of the mechanism of morphology formation during the EP reaction is still lacking. This study examines the morphology formation of stainless steel 304 at the same location on the specimen as the process evolves. Based on these observations, the basic mechanisms of morphology formation in EP process are proposed. The bubble shielding effect (BSE) and the broken bubble tunnelling effect (BBTE) explain the raised and dented morphologies, respectively. The broken bubble tunnelling effect (BBTE) explains the formation mechanism of pitting holes and the bubbleshielding effect (BSE) explains the limitation of surface roughness of electropolishing process. Simulation results are consistent with the observed morphology formation phenomena. © 2012 by ESG.
[3]: Electropolishing is the method of obtaining extremely smooth surfaces. It is also observed that Electropolishing of stainless steel have enhanced localized corrosion resistance as compared to mechanically prepared surfaces. For biomedical applications such as orthopedic implants it is required that near zero defects surface is ensured.This work studies Electropolishing of solution annealed and cold rolled 316L stainless steel and characterizes the surface physically for roughness, topography and electrochemically for localized corrosion. Characterization techniques involve Profilometry, Specular reflection, SEM, AFM, Ellipsometry, XPS, polarization studies in Hank's solution, and Micro- cell Ecorr noise studies to estimate localized corrosion resistance. The results are compared with nitric acid passivated 316L stainless steel surfaces also. This part summarizes and discusses the results of characterization techniques like profilometry, specular reflection, SEM, AFM and ellipsometry. Surfaces with various degrees of roughness (Ra(μ) 0.09 and 0.14) exhibited similar specular reflectance (71-91%) in the visible range of spectrum. In addition, Surface roughness described only in terms of Ra values may not truly describe the extremely large hills or valleys as expressed by the parameters like Rz, and Rmax. AFM studies revealed the existence of equiaxed peculiar 'diamond' shaped feature (cell width roughly 100nm) upon solution annealed and electropolished sample surface whereas cold rolled and electropolished sample surfaces exhibited 'striped' feature. SEM results also substantiate AFM outcomes. Increasing degree of cold work has its own effect over the surface roughness achieved at the end of surface treatments. Electropolishing or nitric acid passivation of 316L stainless steel enhances the thickness of the oxide film two to three times of the original. © University of Manchester and the authors 2006.
[4]: Several surface modification techniques such as ion implantation, surface laser melting, have been employed to improve pitting corrosion resistance of stainless steel. Electropolishing is a technique in which the surface roughness is eliminated through a selective electrochemical dissolution. The effect of electropolishing on pitting corrosion of 304 stainless steel (SS) was investigated employing polarization technique in conjunction with the scanning electron microcopy examination. Electropolishing process was carried out on wire of 2 mm diameter in 70% phosphoric acid solution at room temperature for 30 min. To elucidate the effect of roughness elimination on pitting corrosion, investigation was carried out on as-received specimen with surface finishing of 60 SiC grit and electropolished specimen in 0.5M NaCl solution at room temperature. A significant decrease on passive current density and also shift of pitting potential towards noble value was recorded on electropolished specimen revealing a pronounce effect of this technique on surface modification. Further investigation was carried out by employing slow ramp anodic potentiodynamic polarization on as received and electropolished specimen. Plot of metastable pitting current transient revealed the reduction on the number and magnitude of metastable pitting transients prior to occurrence of stable pitting on electropolished specimen. EDX analysis of the surface area of as received and electropolished specimens showed modification in surface roughness during electropolishing was the main reason of pitting corrosion improvement. Scanning microscopy investigation of polarized specimens beyond the pitting potential revealed that in as-receives specimen pits were nucleated in at and in the vicinity of surface scratches that was created during surface abrading.",Entailment
i_1870,Entailment,"Bricks made from industrial and agro wastes, such as cotton mill waste and rice husk ash, have been found to be less sustainable compared to traditional clay bricks .","Manufacturing of bricks, using clay or fly ash, is one of the major contributors to greenhouse gas emissions as their manufacturing involves utilization of coal and cement. To overcome this limitation, alternative construction materials are developed by author using industrial and agro wastes like cotton mill waste, recycled paper mill waste, and rice husk ash. This work aims at performing a sustainability assessment of burnt clay bricks and bricks made of industrial and agro wastes used for brickwork in a low-cost house. The criteria considered for the assessment are economic, environmental, social, and technical aspects for manufacture of bricks and use of different bricks for brickwork. For the evaluation of environmental criterion, a life cycle assessment (LCA) tool is used. Overall sustainability index (SI) is calculated for alternatives based on the various criteria using MIVES approach. The relative SIs of clay and fly ash bricks, were 0.25 and 0.26, respectively. Overall, bricks made of industrial and agro wastes are found more sustainable with the highest SI for cotton waste bricks (0.94). Sensitivity analysis also confirmed that brickwork from waste based bricks is more sustainable compared to brickwork made from clay brick or fly ash brick.",Entailment
i_951,Entailment,"5. Hybrid and Incremental Approaches: Integrated Frameworks: The separation of model checking, program analysis, and constraint solving into distinct processes hinders incremental development and verification of both design and implementation .","Model checking is usually applied at the design phase to verify that preliminary high-level design specifications conform to their requirements. Source code analysis, on the other hand, is used to check for correctness of implementation once it is realized from the design specifications. However, the current practice of validating a design and its implementation in isolation makes it necessary to employ rigorous testing analysis to empirically ensure that the implementation satisfies the design specification. This article describes a formal framework that allows design models to contain embedded partial implementations as components; these models are then formally analyzed to ensure that global requirements are satisfied. This framework can be utilized to incrementally develop and ensure correctness of the design and the corresponding implementation. Realization of this framework requires consolidation and expansion of traditional formal verification techniques by integration of model checking, program analysis and constraint solving. © 2006 IEEE.",Entailment
i_749,Unverifiable,"Benefits of Acoustic Emission Technology: Non-Invasive and Real-Time Monitoring: AE provides a non-invasive method for real-time monitoring of automotive components, allowing for early detection of faults without disassembling the machinery .","This paper investigated, using experimental method, the suitability of acoustic emission (AE) technique for the condition monitoring of diesel engine valve faults. The clearance fault was adjusted experimentally in an exhaust valve and successfully detected and diagnosed in a Ford FSD 425 four-cylinder, four-stroke, in-line OHV, direct injection diesel engine. The effect of faulty exhaust valve clearance on engine performance was monitored and the difference between the healthy and faulty engine was observed from the recorded AE signals. The measured results from this technique show that using only time domain and frequency domain analysis of acoustic emission signals can give a superior measure of engine condition. This concludes that acoustic emission is a powerful and reliable method of detection and diagnosis of the faults in diesel engines and this is considered to be a unique approach to condition monitoring of valve performance. © 2010 Fathi Elamin et al.
[5]: The reactivation of artefacts' mechanisms is always a challenge for conservators and proper noninvasive diagnostic techniques, applicable directly on the artifacts, allows to perform a precocious diagnostic and to avoid damages. The ACUME_HV project (Acoustic Emission Monitoring of Historical Vehicles) represents the first use of acoustic emission (AE) as non-invasive technique for the diagnostic of historical vehicles. The aim of this project is to propose an objective, human-independent method that will help the personnel of the museums to take decisions concerning the reactivation of the historical vehicles' engines using measurements and data and not only personal experience. In this paper the results of the first phase of the ACUME_HV project are presented. This first phase focused on the development of a protocol for the use of AE during cold tests.",Related but unverifiable
s_88,Unverifiable,"Artificial Intelligence and Machine Learning: Artificial intelligence, particularly machine learning, has been increasingly utilized to enhance the allocation and management of cadastral land. Machine learning techniques offer more objective and accurate methods for land survey and assessment compared to traditional subjective approaches. For example, machine learning can analyze spatial data from UAVs to improve the accuracy of topographic surveys and land price assessments .","[2] In large parts of sub Saharan Africa it remains an ongoing challenging to map millions of unrecognized land rights. Existing approaches for recognizing these rights have proven inappropriate in many cases. A new generation of tools needs to be developed to support faster, cheaper, easier, and more responsible land rights mapping. This is the main goal of its4land, an European Commission Horizon 2020 project that aims to develop innovative tools inspired by the continuum of land rights, fit-for-purpose land administration, and cadastral intelligence. its4land is using strategic collaboration between the EU and East Africa to deliver innovative, scalable, and transferrable ICT solutions. The innovation process incorporates a broad range of stakeholders and emergent geospatial technologies, including smart sketchmaps, UAVs, automated feature extraction, as well as geocloud services. The aim is to combine innovative technologies, capture the specific needs, market opportunities and readiness of end-users in the domain of land tenure information recording in Eastern Africa. The project consists of a four year work plan, €3.9M funding, and eight consortium partners collaborating with stakeholders from six case study locations in Ethiopia, Kenya, and Rwanda. The major tasks include tool development, prototyping, and demonstration for local, national, regional, and international interest groups. The case locations cover different land uses such as: urban, peri-urban, rural smallholder, and (former) pastoralist. This paper describes the project's activities within the first 18 months and covers barriers discovered, lessons learned and results achieved. [6] Detailed information on urban land uses has been an essential requirement for urban land management and policymaking. Recent advances in remote sensing and machine learning technologies have contributed to the mapping and monitoring of multi-scale urban land uses, yet there lacks a holistic mapping framework that is compatible with different end users' demands. Moreover, land use mix has evolved to be a key component in modern urban settings, but few have explicitly measured the spatial complexity of land use or quantitively uncovered its driving forces. Addressing these challenges, here we developed a novel two-stage bottom-up scheme for mapping essential urban land use categories. In the first stage, we conducted object-based land use classification using crowdsourcing features derived from multi-source open big data and an automated ensemble learning approach. In the second stage, we identified parcel-based land use attributes, including the dominant type and mixture mode, by spatially correlating land parcels with the object-based results. Furthermore, we investigated the potential influencing factors of land use mix using principal components analysis and multiple linear regression. Experimental results in Ningbo, a coastal city in China, showed that the proposed framework could accurately depict the distribution and composition of urban land uses. At the object scale, the highest classification accuracy was as high as 86% and 78% for the major (Level I) and minor (Level II) categories, respectively. At the parcel scale, the generated land use maps were spatially consistent with the object-based maps. We found larger parcels were more likely to be mixed in land use, and industrial lands were characterized as the most complicated category. We also identified multiple factors that had a collective impact on land use mix, including geography, socioeconomy, accessibility, and landscape metrics. Altogether, our proposed framework offered an alternative to investigating urban land use composition, which could be applied in a broad range of implications in future urban studies.",Unrelated and unverifiable
s_1458,Entailment,"Resistance to the chitin synthesis inhibitor lufenuron in S. frugiperda is autosomal, incompletely recessive, and polygenic, with a resistance ratio of approximately 915-fold compared to susceptible strains, and it is likely that environmental factors may further influence the expression of this resistance in natural populations .","BACKGROUND: An understanding of the genetic basis of insect resistance to insecticides is important for the establishment of insect resistance management (IRM) strategies. In this study we evaluated the inheritance pattern of resistance to the chitin synthesis inhibitor lufenuron in Spodoptera frugiperda. RESULTS: The LC<inf>50</inf> values (95% CI) were 0.23 μg lufenuron mL<sup>-1</sup> water (ppm) (0.18-0.28) for the susceptible strain (SUS) and 210.6 μg mL<sup>-1</sup> (175.90-258.10) for the lufenuron-resistant strain (LUF-R), based on diet-overlay bioassay. The resistance ratio was ≈ 915-fold. The LC<inf>50</inf> values for reciprocal crosses were 4.89 μg mL<sup>-1</sup> (3.79-5.97) for female LUF-R and male SUS and 5.74 μg mL<sup>-1</sup> (4.70-6.91) for female SUS and male LUF-R, indicating that the inheritance of S. frugiperda resistance to lufenuron is an autosomal, incompletely recessive trait. Backcrosses of the progeny of reciprocal crosses with the parental LUF-R showed a polygenic effect. The estimated minimum number of independent segregations was in the 11.02 range, indicating that resistance to lufenuron is associated with multiple genes in S. frugiperda. CONCLUSIONS: Based on genetic crosses, the inheritance pattern of lufenuron resistance in S. frugiperda was autosomal, incompletely recessive and polygenic. Implications of this finding to IRM are discussed in this paper.",Entailment
s_2164,Contradiction,"Challenges and Considerations: Environmental and Social Trade-offs: Offshore wind farms have predominantly negative impacts on ecosystem services, with only minor positive effects. For instance, while they can negatively affect the seascape and spread non-native species, the positive impacts on commercial fish and shellfish populations are likely negligible compared to the overall harm .","Globally, the deployment of offshore wind is expanding rapidly. An improved understanding of the economic, social and environmental impacts of this sector, and how they compare with those of other energy systems, is therefore necessary to support energy policy and planning decisions. The ecosystem services approach provides a more holistic perspective of socio-ecological systems than traditional environmental impact assessment. The approach also makes possible comparisons across disparate ecological communities because it considers the societal implications of ecological impacts rather than remaining focused on specific species or habitats. By reporting outcomes in societal terms, the approach also facilitates communication with decision makers and the evaluation of trade-offs. The impacts of offshore wind development on ecosystem services were assessed through a qualitative process of mapping the ecological and cultural parameters evaluated in 78 empirical studies onto the Common International Classification for Ecosystem Services (CICES) framework. The research demonstrates that a wide range of biophysical variables can be consistently mapped onto the CICES hierarchy, supporting development of the ecosystem service approach from a broad concept into an operational tool for impact assessment. However, to improve confidence in the outcomes, there remains a need for direct measurement of the impacts of offshore wind farms on ecosystem services and for standardised definitions of the assumptions made in linking ecological and cultural change to ecosystem service impacts. The process showed that offshore wind farms have mixed impacts across different ecosystem services, with negative effects on the seascape and the spread of non-native species, and positive effects on commercial fish and shellfish, potentially of most significance. The work also highlighted the need for a better understanding of long term and population level effects of offshore wind farms on species and habitats, and how these are placed in the context of other pressures on the marine environment.",Opposite meaning
i_2197,Unverifiable,Key Components of Ecosystem-Based Aquaculture: Management and Policy: Regulatory Frameworks: Establishing legislative frameworks based on ecosystem approaches is necessary to regulate aquaculture practices effectively. This includes setting management objectives that balance natural and human goals and ensuring governance structures match the scale of ecosystem management .,"[4] The aim of this research was to propose and evaluate a methodological approach to integration and spatial data analysis in order to generate information towards a participatory site selection for bivalve marine aquaculture in the Baía Sul, Florianópolis, Santa Catarina, Brazil. For this purpose, the Baía Sul was investigated considering an ecosystem approach for aquaculture leading to an assessment of its potential for marine aquaculture. The planning of the aquaculture parks was made through a participatory process to incorporate both environmental carrying capacity and social carrying capacity. Experts and modellers developed a GIS model to assess the potential for marine aquaculture in Baía Sul. Continuous (unclassified) maps were used to provide spatial information about the variation of the potential for marine aquaculture in the Baía Sul. The maps were used to plan 53 aquaculture parks over the Baía Sul. The site selection of the parks was made in six public hearings attended by 403 stakeholders from 38 institutions representing different sectors with diverse interests in coastal zone. The results showed that although the Baía Sul is suitable for the growth of bivalve molluscs, some hydrodynamic characteristics and the influence of urbanization constitute a sanitary risk for the activity. Experts, modellers and stakeholders had a different perception about the importance of criteria in the aquaculture parks site selection. While the experts and modellers considered the environmental criteria as the most important aspect to locate the aquaculture parks, the stakeholders took into account mainly the logistics. The final result of the aquaculture parks location, approved by the Brazilian Ministry of Fisheries and Aquaculture (MPA), adopted the site selection by the stakeholders, providing aquaculture parks in areas with sanitary risk for the bivalve cultivation. The main advantage of the adopted assessment strategy was to identify the divergence between experts, modellers and the stakeholders and the distance that still exist between scientist and decision makers in Brazil. Statement of relevance: This is the first article about a participatory GIS for aquaculture in Brazil. The method was developed to be according to Ecological Approach to Aquaculture. The results highlight the importance of the participatory GIS in suitability study and site selection because the decision making process is different over the view of researchers, technicians and other social stakeholders. [5] An innovative value- and ecosystem-based management approach (VEBMA) is introduced that aims to expose policy tradeoffs, resolve resource conflicts, and foster ethical governance. VEBMA is applied to the Pacific herring Clupea pallasii fishery in British Columbia, Canada, which is mired in conflict between local and indigenous communities and the fishing industry over the management of herring, a forage fish with significant ecological, socioeconomic, and cultural value. VEBMA integrates an ecosystem-based approach (ecological modelling) with a value-based approach (practical ethics) to examine the ecological viability, socioeconomic feasibility, and societal desirability of alternative fishery management scenarios. In the socioecosystem-based approach, we applied the Management Strategy Evaluation module within the Ecopath with Ecosim modelling framework to explore scenarios with harvest-control rules specified by various herring fishing mortalities and biomass cutoff thresholds. In the value-based approach, Haida Gwaii community and herring industry participants ranked a set of values and selected preferred scenarios and cutoff thresholds to open the fishery. The modelled ecological and socioeconomic impacts and risks and stakeholder preferences of the scenarios are synthesized in a deliberation and decision-support tool, the VEBMA science-policy table. VEBMA facilitates inclusive, transparent, and accountable decision-making among diverse stakeholders, such as local communities, industries, scientists, managers, and policy-makers. It promotes ethical governance in pluralistic societies via compromise, rather than consensus solutions to resolve 'wicked' problems at the science-policy interface. [17] In the European Union (EU), the ecosystem approach to fisheries is implemented through several directives and polices, which are overarched by the Marine Strategy Framework Directive (MSFD). The MSFD requires the assessment of the environmental status of exploited fish and shellfish stocks, among others, to advise the EU Common Fisheries Policy (CFP) on sustainable catch options. The stock assessments for the CFP and the MSFD are supposed to be congruent, yet they differ in several substantial subjects. While the annual CFP assessment is based on two indicators, fishing mortality (F) and spawning stock biomass (SSB), in its Descriptor 3 (D3) the MSFD requires the assessment of three criteria (F, SSB, and age or size structure) within a six year period. Assessing exploited fish and shellfish stocks under the MSFD by using existing CFP assessments has therefore been a half-completed task, which had to be fulfilled by the member states of the EU. This paper suggests six easy steps, referred to as ""quick wins""(QW), which are based on existing information from CFP stock assessments. The implementation of these six QW would allow for assessments of exploited fish and shellfish stocks that are compliant to D3. These QW are to (i) assess length/age structure within a stock, (ii) analyse and assess selectivity by fisheries, (iii) use all available information to assess a stock, (iv) use response indicators to assess environmental targets, (v) provide integrated stock-specific advice, and (vi) provide assessments with a mid-term perspective over a-period of six years. International Council for the Exploration of the Sea (ICES) combines the infrastructure and expertise to produce stock-specific assessment products tailored to the requirements of MSFD D3. Thereby, ICES could provide a valuable service to EU member states in the north-east Atlantic region by providing scientifically validated, quality-assured, and MSFD-compliant single-stock assessment products. This would be a big advancement towards implementing the ecosystem approach to fisheries management within Europe.",Unrelated and unverifiable
s_1666,Entailment,"Bioremediation: Certain Trichoderma genes can be transferred to plants, which will undoubtedly lead to a significant improvement in their ability to tolerate and remediate environmental pollutants, thereby ensuring a completely cleaner and healthier growth environment .","Many filamentous fungi from the genus Trichoderma are well known for their anti-microbial properties. Certain genes from Trichoderma spp. have been identified and transferred to plants for improving biotic and abiotic stress tolerance, as well for applications in bioremediation. Several Trichoderma genomes have been sequenced and many are in the pipeline, facilitating high throughput gene analysis and increasing the availability of candidate transgenes. This, coupled with improved plant transformation systems, is expected to usher in a new era in plant biotechnology where several genes from these antagonistic fungi can be transferred into plants to achieve enhanced stress tolerance, bioremediation activity, herbicide tolerance, and reduction of phytotoxins. In this review, we illustrate the major achievements made by transforming plants with Trichoderma genes as well as their possible mode of action. Moreover, examples of efficient application of genetically modified plants as biofactories to produce active Trichoderma enzymes are indicated.",Entailment
i_487,Unverifiable,"Strategies for Implementation: Efficient Indexing and Parallel Processing: While efficient indexing techniques like sparse matrix structures are mentioned, they are not necessarily effective for all types of data, and leveraging parallel processing capabilities may not significantly improve retrieval speed in every scenario .","Information text data retrieval requires a tremendous amount of processing time because of the size of the data and the complexity of information retrieval algorithms. In this paper the solution to this problem is proposed via hardware supported information retrieval algorithms. Reconfigurable computing may adopt frequent hardware modifications through its tailorable hardware and exploits parallelism for a given application through reconfigurable and flexible hardware units. The degree of the parallelism can be tuned for data. In this work we implemented standard BLAS (basic linear algebra subprogram) sparse matrix algorithm named Compressed Sparse Row (CSR) that is showed to be more efficient in terms of storage space requirement and query-processing timing over the other sparse matrix algorithms for information retrieval application. Although inverted index algorithm is treated as the de facto standard for information retrieval for years, an alternative approach to store the index of text collection in a sparse matrix structure gains more attention. This approach performs query processing using sparse matrix-vector multiplication and due to parallelization achieves a substantial efficiency over the sequential inverted index. The parallel implementations of information retrieval kernel are presented in this work targeting the Virtex II Field Programmable Gate Arrays (FPGAs) board from Xilinx. A recent development in scientific applications is the use of FPGA to achieve high performance results. Computational results are compared to implementations on other platforms. The design achieves a high level of parallelism for the overall function while retaining highly optimised hardware within processing unit.",Related but unverifiable
s_56,Unverifiable,"Adaptive Learning Framework: Description: The Adaptive Learning Framework integrates data sampling, filtering, and model training in a hierarchical structure. This approach improves model performance step by step and maintains robustness and stability across different features and datasets. Application: The Adaptive Learning Framework has demonstrated superior performance in semantic extraction tasks, particularly in video datasets, by effectively handling data imbalance .","Data imbalance problem often exists in our real life dataset, especial for massive video dataset, however, the balanced data distribution and the same misclassification cost are assumed in traditional machine learning algorithms, thus, it will be difficult for them to accurately describe the true data distribution, and resulting in misclassification. In: this paper, the data imbalance problem in semantic extraction under massive video dataset is exploited, and enhanced and hierarchical structure (called EHS) algorithm is proposed. In: proposed algorithm, data sampling, filtering and model training are considered and integrated together compactly via hierarchical structure algorithm, thus, the performance of model can be improved step by step, and is robust and stability with the change of features and datasets. Experiments on TRECVID2010 Semantic Indexing demonstrate that our proposed algorithm has much more powerful performance than that of traditional machine learning algorithms, and keeps stable and robust when different kinds of features are employed. Extended experiments on TRECVID2010 Surveillance Event Detection also prove that our EHS algorithm is efficient and effective, and reaches top performance in four of seven events. © 2012 Springer Science+Business Media, LLC.",Unrelated and unverifiable
i_1854,Contradiction,"Key Points on Water Purification by the Amazon Rainforest: Ecosystem Services Overview: Ecosystem services are the benefits provided by ecosystems to humans, including water purification, climate regulation, and biodiversity maintenance .","The concept of ecosystem services recognizes the services, and benefits, provided to people by ecosystems. The Nemunas River Delta, in Lithuania, provides many ecosystem services to the people of the area, including food, fuel, transportation, climate regulation, water purification, natural hazards regulation, fishing, and recreation (including birdwatching and cultural benefits). We conducted a meta-analysis of existing studies done on the region to create a conceptual model for the services, using the DPSIR framework (Drivers?Pressures?State ?Impact ?Response). This approach allowed us to identify trade-offs between services, and synergies, where services respond similarly to pressures. This work contributes to the understanding of services in transitional waters, where few studies have been conducted, and provides a framework for future decisions and modeling efforts. © 2011 University of Salento - SIBA http://siba-ese.unisalento.it.
[2]: Ecosystem services are the many processes conducted by ecosystems, which provide resources of benefit to humans and other organisms. Typically the inherent value of these services only becomes apparent after the services are interrupted and the disruption impacts the quality of human life.",Missing information
i_2317,Contradiction,"###  ** Combined Effects**  ** Complex Interactions** :  The combined effects of temperature and salinity can lead to complex outcomes. For example, the larvae of the common spider crab (Maja brachydactyla) had the highest survival at a combination of 30 salinity and 21°C temperature, with salinity being the key factor for survival and temperature affecting developmental duration .","The effect of temperature and salinity on the larval development of the common spider crab Maja brachydactyla (Balss, 1922) were studied in the laboratory. Larvae were reared at different salinities (0-45) at constant temperature, and under six different combinations of temperature (18 and 21°C) and salinity (30, 35, and 40). The survival and developmental time from newly hatched zoeae to the megalopa stage and from megalopa to the first juvenile stage was quantified; the 24 h median lethal salinity (LS50) for first zoeal stage was calculated. Dry mass (DM), elemental body composition (Carbon, Hydrogen, Nitrogen) and carbon: nitrogen ratio (C:N) were determined in both starved and nourished zoeae. The lower and upper LS50 for M. brachydactyla first zoea in 24 h were 19.9 and 56.0, respectively; similar to other marine stenohaline brachyuran larvae. The megalopa stage was reached in a salinity range from 30 to 40. The highest survival rates to the first juvenile stage were observed at salinity: 35 and temperature: 21°C. Salinity was the key parameter for the survival to first juvenile, whereas the temperature had a higher effect over the duration of the larval development. The greatest loss of DM in starving and nourished zoeae was observed at low salinity (25). No differences were found in DM or C:N during the megalopa stage. The culture and ecological implications of the salinity tolerance of M. brachydactyla larvae are discussed.",Numeric error
i_940,Contradiction,5. Gas Chromatography (GC): Description: Analytical method for verifying the removal of residues. Advantages: Provides precise quantification of residues. Ensures thorough cleaning validation .,"Cleaning validation is an integral part of current good manufacturing practices in any pharmaceutical industry. Nowadays, azathioprine and several other pharmacologically potent pharmaceuticals are manufactured in same production area. Carefully designed cleaning validation and its evaluation can ensure that residues of azathioprine will not carry over and cross contaminate the subsequent product. The aim of this study was to validate simple analytical method for verification of residual azathioprine in equipments used in the production area and to confirm efficiency of cleaning procedure. The HPLC method was validated on a LC system using Nova-Pak C18 (3.9 mm × 150 mm, 4 μm) and methanol-water-acetic acid (20:80:1, v/v/v) as mobile phase at a flow rate of 1.0 mL min<sup>-1</sup>. UV detection was made at 280 nm. The calibration curve was linear over a concentration range from 2.0 to 22.0 μg mL<sup>-1</sup> with a correlation coefficient of 0.9998. The detection limit (DL) and quantitation limit (QL) were 0.09 and 0.29 μg mL<sup>-1</sup>, respectively. The intra-day and inter-day precision expressed as relative standard deviation (R.S.D.) were below 2.0%. The mean recovery of method was 99.19%. The mean extraction-recovery from manufacturing equipments was 83.5%. The developed UV spectrophotometric method could only be used as limit method to qualify or reject cleaning procedure in production area. Nevertheless, the simplicity of spectrophotometric method makes it useful for routine analysis of azathioprine residues on cleaned surface and as an alternative to proposed HPLC method. © 2006 Elsevier B.V. All rights reserved.
[7]: Analytical method validation, determining the recovery rate from the equipment surface and the stability of a potential contaminant are important steps of a cleaning validation process. A rapid, sensitive and reproducible reversed-phase high-performance liquid chromatographic method was developed for the determination of pyrimethamine (PYR) and sulfadoxine (SUL) in cleaning validation swab samples. The active compounds can be selectively quantified in a sample matrix containing detergent and swab material as low as 0.12 μg/ml. The swabbing procedure used on stainless steel coupons was validated and the stability of PYR and SUL in the swab samples was assessed. The calculated limit of contamination values for PYR (4.99 μg/cm<sup>2</sup>) and SUL (19.14 μg/cm<sup>2</sup>) were not exceeded during four consecutive equipment cleaning trials. This confirms that the desired level of cleanliness is achieved with the current cleaning procedures, which are consequently validated. © 2004 Elsevier B.V. All rights reserved.",Entity error
i_211,Entailment,"Applications and Case Studies: Manufacturing Sector: Automated Data Collection (ADC) technology faces adoption barriers, but an implementation framework has been proposed to facilitate its use in real scenarios .","Research projects have indicated development of several technical solutions for the management of construction activities. However, little attention has been paid to the issues regarding the adoption and implementation of these techniques. This study investigates the perception of Automated Data Collection (ADC) technology usage in construction, and identifies reasons why available ADC technology has not been fully introduced in construction. A comprehensive literature review carried out in this research identifies barriers to the adoption of ADC technology. In total, 19 key factors are identified as barriers for adoption of ADC technology in construction, and validated through an international questionnaire survey. According to the results, process related factors play an essential role in adopting automated data acquisition technologies in the construction industry. In order to form the backbone of technology adoption in real scenarios, and to identify driving factors in this field, this paper also introduces an implementation framework for ADC technology in the construction industry.",Entailment
s_1517,Entailment,"Starch and Carbohydrates: Starch is a common substrate for fungal growth. It can be enzymatically degraded to release glucose, which serves as a carbon source for the fungi. The EnBase™ method, for instance, uses starch as a substrate, releasing glucose through enzymatic degradation to support high cell density cultivation .","Background: Here we describe a novel cultivation method, called EnBase™, or enzyme-based-substrate-delivery, for the growth of microorganisms in millilitre and sub-millilitre scale which yields 5 to 20 times higher cell densities compared to standard methods. The novel method can be directly applied in microwell plates and shake flasks without any requirements for additional sensors or liquid supply systems. EnBase is therefore readily applicable for many high throughput applications, such as DNA production for genome sequencing, optimisation of protein expression, production of proteins for structural genomics, bioprocess development, and screening of enzyme and metagenomic libraries. Results: High cell densities with EnBase are obtained by applying the concept of glucose-limited fed-batch cultivation which is commonly used in industrial processes. The major difference of the novel method is that no external glucose feed is required, but glucose is released into the growth medium by enzymatic degradation of starch. To cope with the high levels of starch necessary for high cell density cultivation, starch is supplied to the growing culture suspension by continuous diffusion from a storage gel. Our results show that the controlled enzyme-based supply of glucose allows a glucose-limited growth to high cell densities of OD<inf>600</inf> = 20 to 30 (corresponding to 6 to 9 g l-1 cell dry weight) without the external feed of additional compounds in shake flasks and 96-well plates. The final cell density can be further increased by addition of extra nitrogen during the cultivation. Production of a heterologous triosphosphate isomerase in E. coli BL21(DE3) resulted in 10 times higher volumetric product yield and a higher ratio of soluble to insoluble product when compared to the conventional production method. Conclusion: The novel EnBase method is robust and simple-to-apply for high cell density cultivation in shake flasks and microwell plates. The potential of the system is that the microbial growth rate and oxygen consumption can be simply controlled by the amount (and principally also by the activity) of the starch-degrading enzyme. This solves the problems of uncontrolled growth, oxygen limitation, and severe pH drop in shaken cultures. In parallel the method provides the basis for enhanced cell densities. The feasibility of the new method has been shown for 96-well plates and shake flasks and we believe that it can easily be adapted to different microwell and deepwell plate formats and shake flasks. Therefore EnBase will be a helpful tool especially in high throughput applications. © 2008 Panula-Perälä et al; licensee BioMed Central Ltd.
[5]: Cutinase enzymes from fungi have found diverse applications in industry. However, most of the available literature on cutinase production is related to the cultivation of genetically engineered bacteria or yeast cells. In the present study, we use mixture design experiments to evaluate the influence of six nutrient elements on production of cutinase from the fungus Colletotrichum lindemuthianum. The nutritional elements were starch, glucose, ammonium sulfate, yeast extract, magnesium sulfate, and potassium phosphate. In the experimental design, we imposed the constraints that exactly one factor must be omitted in each set of experiments and no factor can account for more than one third of the mixture. Thirty different sets of experiments were designed. Results obtained showed that while starch is found to have negative influence on the production of the enzyme, yeast extract and potassium phosphate have a strong positive influence. Magnesium sulfate, ammonium sulfate, and glucose have low positive influence on the enzyme production. Contour plots have also been created to obtain information concerning the interaction effects of the media components on enzyme production. © 2007 Society for Industrial Microbiology.",Entailment
s_1323,Unverifiable,"Relevant Findings: 3. Symptom Diaries and Logs: In studies on IBS, patients kept symptom logs where they rated daily symptoms, including bloating, on a scale. This method helped identify patterns and severity of bloating episodes .","[4] Objective This study aimed to develop and validate a patient-reported outcome measure (PROM) in acute pancreatitis (AP) as an endpoint centred on the patient. Design A PROM instrument (PAtieNt-rePoRted OutcoMe scale in acute pancreatItis, an international proSpEctive cohort study, PAN-PROMISE scale) was designed based on the opinion of patients, professionals and an expert panel. The scale was validated in an international multicentre prospective cohort study, describing the severity of AP and quality of life at 15 days after discharge as the main variables for validation. The COSMIN (COnsensus-based Standards for the selection of health status Measurement INstruments) methodology was applied. Both the design and validation stages considered the content and face validity of this new instrument; the metric properties of the different items, reliability (reproducibility and internal consistence), the construct, structural and criterion validity, responsiveness and interpretability of this scale. Results PAN-PROMISE consists of a seven-item scale based on the symptoms that cause the most discomfort and concern to patients with AP. The validation cohort involved 15 countries, 524 patients. The intensity of symptoms changed from higher values during the first 24 hours to lower values at discharge and 15 days thereafter. Items converged into a unidimensional ordinal scale with good fit indices. Internal consistency and split-half reliability at discharge were adequate. Reproducibility was confirmed using test-retest reliability and comparing the PAN-PROMISE score at discharge and 15 days after discharge. Evidence is also provided for the convergent-discriminant and empirical validity of the scale. Conclusion The PAN-PROMISE scale is a useful tool to be used as an endpoint in clinical trials, and to quantify patient well-being during the hospital admission and follow-up. Trial registration number NCT03650062  [11] Background Four scoring methods exist to assess severity of fecal loading on plain abdominal radiographs in constipated patients (Barr-, Starreveld-, Blethyn- and Leech). So far, the Starreveld score was used only in adult patients. Objective To determine accuracy and intra- and inter-observer agreement of the Starreveld scoringmethod in the diagnosis of functional constipation among pediatric patients. In addition, we compared the Starreveld with the Barr scoring method. Materials and methods Thirty-four constipated and 34 non-constipated children were included. Abdominal radiographs, obtained before treatment, were rated (Starreveld- and Barr) by 4 observers. A second observation after 4 weeks was done by 3 observers. Cut-off level for the Starreveld score, accuracy as measured by the area under the receiver operator characteristics curve, and inter- and intra-observer agreement were calculated. Results Cut-off value for the Starreveld score was 10. AUC for Starreveld score was 0.54 and for Barr score 0.38, indicating poor discriminating power. Inter-observer agreement was 0.49-0.52 4 (Starreveld) and 0.44 (Barr), which is considered moderate. Intra-observer agreement was 0.52- 0.71 (Starreveld) and 0.62- 0.76 (Barr). Conclusion The Starreveld scoring method to assess fecal loading on a plain abdominal radiograph is of limited value in the diagnosis of childhood constipation. © The Author(s) 2010. [12] In addition to paresis, about one third of stroke patients develop spastic increases of muscle tone, featuring a broad spectrum of clinical manifestations. Various standardised assessment scales are available in order to assess the severity of spasticity within the neurological status evaluation. In addition to spasticity these tools include the assessment of active and passive functions, quality of life, and pain. The Ashworth Scale (AS) or the modified Ashworth scale (MAS) are the most common ones. Both scales are known for their reliable assessment of treatment effects on muscle tone. Contrary to the Tardieu scale, however, they do not reflect the elementary aspect of velocity-dependent stretch-reflex movements of spasticity. Given the growing attention to involving the patients and their opinions into the rehabilitation process, Goal Attainment Scaling (GAS) and Goal Attainment Scaling Evaluation of Outcome for Upper-limb Spasticity (GAS-eous) have been developed as sensitive tools to assess patient-related treatment outcomes. Due to concerns about the validity, experts recommend associating the GAS tool with an objective and validated clinical scale, e. g., the Tardieu scale for the assessment of spasticity. In this context, other scales such as the Tardieu scale are discussed. We conducted a systematic literature research from 2011-2015 in order to investigate the frequency of assessments used. Results are critically discussed in this review.",Related but unverifiable
i_1011,Unverifiable,"In summary, fiber optic splitters are essential for distributing optical signals and power in various applications, enhancing network efficiency, flexibility, and cost-effectiveness .","The purpose of this study was to develop a virtual lab to allow the design of new optical devices to be embedded into the network before it is sent for fabrication. A new 2×3 Optical splitter is designed and tested for the effectiveness of the lab. The device is designed using the OptiBPM software before being exported to Optical System to embed into the network. The Optical Splitter 2×3 has two different inputs and divides 50% of the input power to the first and third arm. While on the second arm, 50% of both input signals are combined. Before the design can be exported, they need to be sliced into a few parts for them to function as desired. Both of the designs will be embedded into Fiber-to-The-Home (FTTH) network test pad to be tested. Analysis of the design is done based on the performance before and after they are embedded into the network and based on the losses of output power to the input and maximum Q factor. The result shows that total insertion loss 2×3 Optical Splitter before being exported is 0.1899dB and changed to 0.3464dB after embedded into the network. The distance that the 2×3 splitter can achieve is up to 28 km at arm 1 and 3. While for arm 2, it can only achieve up to 15 km. The result obtained shows that the performance of the designs is better when embedded into the network and the virtual lab is suitable for testing new devices in the network before fabrication. © 2011 Asian Network for Scientific Information.
[2]: A 1-to-N optical splitter was fabricated using a focused 785-nm femtosecond laser to directly write a series of l-to-2 Y-junction splitters in fused silica. The femtosecond laser direct writing technique has the potential to generate not only channel waveguide, but also three-dimensional optical devices. In this paper, a l-to-4 optical splitter and U-grooves, which are used for fiber alignment, are simultaneously fabricated in fused silica glass by using near-IR femtosecond laser pulses. The obtained splitter was characterized in terms of its optical properties at a wavelength of 1550 nm. The fiber-aligned optical splitter has a low insertion loss, less than 9 dB, including an intrinsic splitting loss of 6 dB and an excess loss due to passive alignment of a single-mode fiber.
[3]: Fiber optical power splitters (OPSs) have been widely employed in optical communications, optical sensors, optical measurements, and optical fiber lasers. It has been found that OPSs with variable power ratios can simplify the structure and increase the flexibility of optical systems. In this study, a variable-fiber OPS based on a triangular prism is proposed and demonstrated. By adjusting the output beam width of the prism, the power ratio can be continuously tuned. The optical simulations show that the horizontal displacement design is better than the traditional tilt angle design. Our scheme combines a dual-fiber collimator, a focus lens, and a triangular prism with a vertex angle of 120°. By changing the axial displacement of the prism, the power splitting ratio can be altered from 50:50 to 90:10. The polarization and wavelength dependence of the variable OPS were also investigated.
[5]: In this paper, we introduce a new optical device to replace the 1xN Optical Splitter in passive optical network (PON) to increase the performance of an optical network system in scattered topology. Multi Ratio Optical Splitter (MROS) was developed to increase the signal performance of the network system for customer of different distance. The performance of the network system will be evaluated by its eye diagram and amplitude of the jitter that has been extracted from its eye diagram. For comparison purpose with MROS, a conventional 1×4 Optical Splitter will be used as a benchmark to see the signal quality. MROS was designed using device designing tools that based on beam propagation method (BPM) and integrated into network design simulator for test. Simulation result shows that MROS with the highest ratio gives the widest eye opening of eye diagram. Value of jitter extracted from these eye diagrams supporting this result when it produce jitter with amplitude as low as 0.031 UI compare to conventional 1×4 Splitter with 0.61 UI.
[6]: The first experimental demonstration of a 1× 4 all-fiber power splitter capable of high-power operation is presented. The splitter, prepared by fused taper technique and fusion splicing technique, consists of one input fiber with a core diameter of 400μm (NA<inf>CORE</inf> = 0.22 ) and four output fibers with a core diameter of 200μm (NA<inf>CORE</inf> = 0.22 ). The device was tested at a laser power up to 166 W and it achieves a low excess loss of 0.56 dB and an excellent uniformity of less than 0.3 dB in port-to-port power splitting ratio. The results of theoretical simulation by the 3-D beam propagation method show that the performance of this splitter could be optimized further through modifying structure parameters.",Related but unverifiable
i_491,Entailment,"Responding to Change over Following a Plan: Agile development is often perceived as flexible and adaptive, which suggests that teams can respond to changes in requirements and market conditions quickly. However, this perception may overlook the significant challenges and stress that Agile professionals face, which can hinder their ability to pivot and adjust plans effectively to deliver the best possible product .","Agile development methods have emerged to overcome some of the process and product-related problems associated with traditional models. They are believed to be lightweight, people focused, adaptive and allow better information systems development (ISD) performance. Nevertheless, they require a significant capacity of absorbing new set of skills, knowledge and mindset changing. When using agile methods IS developers are faced with a challenge to quickly assimilate the mindset of these new methods and develop the ability to recognize information and apply it in context. This paper reports on two ex-post ISD project implementation. We integrate a central construct in the dynamic capability theory - absorptive capacity to explain agile method adoption and usage. The findings show that absorptive capacity, indeed, plays an important role in adopting and using agile method-Extreme Programming model. The implications of these findings for both researchers and practitioners are discussed. © 2011 IEEE.
[2]: Agile Software Development has been around for more than fifteen years and is now widespread. How does experience effect the application of agile methods in organizations and what are the implications on the individual and organizational culture? This paper presents indepth analysis of the Swiss Agile Study 2014. Switzerland offers an illustrative microcosm of software development, with a range of industry domains and sizes, and well-educated and internationally aware professionals. The study included more than a hundred professionals and managers, contacted through professional and industry associations. The topics addressed included experience with Agile development, motivations for adopting it, barriers perceived, specific practices used, and specific benefits realized. Analysis of the data identified important trends and differences. Agile experience seems to be an important factor, which affects many aspects of practice and workplace culture. More troubling is that it appears stress and overwork may be common among Agile professionals. All these findings illustrate important differences between Agile processes as prescribed, and as actually practiced.
[9]: Agile development methods and their associated practices have become well-accepted within industry, and the success of projects using these methods is higher than traditional methods [1]. However, the optimal environmental parameters that suggest a fit between a project's requirements and needed outcomes, and the use of agile methods is still a matter requiring further research. This is due to the fact that software projects contribute broadly to the human condition, and their success or failure can have significant impacts on individuals, organizations, and society at large. The impact extends beyond software; agile manufacturing [2] and agile organizational strategy [3] share many fundamentals with agile software. As such, we see the continued research into agile methods of software development and other management areas to be a critical area with wide ranging impacts.",Entailment
s_338,Entailment,7. Maintenance and Evolution: Incremental Updates: Continuously update the KG to reflect new data and changes in existing data .,"[1] Information on the Internet is fragmented and presented in different data sources, which makes automatic knowledge harvesting and understanding formidable for machines, and even for humans. Knowledge graphs have become prevalent in both of industry and academic circles these years, to be one of the most efficient and effective knowledge integration approaches. Techniques for knowledge graph construction can mine information from either structured, semi-structured, or even unstructured data sources, and finally integrate the information into knowledge, represented in a graph. Furthermore, knowledge graph is able to organize information in an easy-to-maintain, easy-to-understand and easy-to-use manner. In this paper, we give a summarization of techniques for constructing knowledge graphs. We review the existing knowledge graph systems developed by both academia and industry. We discuss in detail about the process of building knowledge graphs, and survey state-of-the-art techniques for automatic knowledge graph checking and expansion via logical inferring and reasoning. We also review the issues of graph data management by introducing the knowledge data models and graph databases, especially from a NoSQL point of view. Finally, we overview current knowledge graph systems and discuss the future research directions. [11] UML class diagram is the de facto standard, including in Knowledge Engineering, for modeling structural knowledge of systems. Attaching importance to visual representation and based on a previous work, where we have given a logical defined extension of UML class diagram to represent queries and constraints into the UML visual environment, we present here how using the model of conceptuals graphs to answer queries and to check constraints in concrete terms. [12] Graph, as an important data representation, is ubiquitous in many real world applications ranging from social network analysis to biology. How to correctly and effectively learn and extract information from graph is essential for a large number of machine learning tasks. Graph embedding is a way to transform and encode the data structure in high dimensional and non-euclidean feature space to a low dimensional and structural space, which is easily exploited by other machine learning algorithms. We have witnessed a huge surge of such embedding methods, from statistical approaches to recent deep learning methods such as the graph convolutional networks (GCN). Deep learning approaches usually outperform the traditional methods in most graph learning benchmarks by building an end-to-end learning framework to optimize the loss function directly. However, most of the existing GCN methods can only perform convolution operations with node features, while ignoring the handy information in edge features, such as relations in knowledge graphs. To address this problem, we present CensNet, Convolution with Edge-Node Switching graph neural network, for learning tasks in graph-structured data with both node and edge features. CensNet is a general graph embedding framework, which embeds both nodes and edges to a latent feature space. By using line graph of the original undirected graph, the role of nodes and edges are switched, and two novel graph convolution operations are proposed for feature propagation. Experimental results on real-world academic citation networks and quantum chemistry graphs show that our approach achieves or matches the state-of-the-art performance in four graph learning tasks, including semi-supervised node classification, multi-task graph classification, graph regression, and link prediction.",Entailment
s_1624,Entailment,"4. Inductively Coupled Plasma Mass Spectrometry (ICP-MS): Trace Element Analysis: This method involves optimizing and validating ICP-MS for analyzing trace elements in seaweeds. It is useful for determining the concentrations of various elements, which can be species-specific .","[3] The wide industrial application of phycocolloids (e.g. alginates, agar and carrageenans) is based on their particular properties to form gels in aqueous solution. These seaweed polysaccharides present a chemical structure related with the taxonomic position of the algae: carrageenans are produced by carrageenophytes (red algae belonging mainly to the genera Kappaphycus, Eucheuma, Chondrus, Gigartina and Chondracanthus). Recently, new spectroscopic techniques have provided more accurate identification of the natural composition of the polysaccharides produced by these seaweeds. With the combination of two spectroscopic techniques (FTIR-ATR and FT-Raman) it is possible to identify the principal seaweed colloids in ground seaweed samples as in extracted material. Since the seaweed samples receive the minimum of handling and treatment (e.g. they are simply dried and ground), the composition determined represents, as accurately as possible, the native composition of the phycocolloids. © 2008 Elsevier Ltd. All rights reserved. [6] Seaweeds are of significant interest in the food, pharmaceutical, and agricultural industries as they contain several commercially relevant bioactive compounds. Current extraction methods for macroalgal-derived metabolites are, however, problematic due to the complexity of the algal cell wall which hinders extraction efficiencies. The use of advanced extraction methods, such as enzyme-assisted extraction (EAE), which involve the application of commercial algal cell wall degrading enzymes to hydrolyze the cell wall carbohydrate network, are becoming more popular. Ascophyllum nodosum samples were collected from the Irish coast and incubated in artificial seawater for six weeks at three different temperatures (18 C, 25 C, and 30 C) to induce decay. Microbial communities associated with the intact and decaying macroalga were examined using Illumina sequencing and culture-dependent approaches, including the novel ichip device. The bacterial populations associated with the seaweed were observed to change markedly upon decay. Over 800 bacterial isolates cultured from the macroalga were screened for the production of algal cell wall polysaccharidases and a range of species which displayed multiple hydrolytic enzyme activities were identified. Extracts from these enzyme-active bacterial isolates were then used in EAE of phenolics from Fucus vesiculosus and were shown to be more efficient than commercial enzyme preparations in their extraction efficiencies. [7] Nowadays various methods are used for estimation of ecological state of water bodies; the method of bioindication is one of them. Identification of indicator species of aquatic organisms via the visual method with the aid of a microscope may be performed with a high degree of certainty only by highly experienced zoologists. This method requires deep knowledge of morphological description of every organism, which includes approximately from 15 to 25 characteristics, thus the method greatly depends on subjectiveness of an investigator. At the same time the known methods of molecular genetics are used for determination of the taxonomy of organisms but have not been still used in ecological investigations of water bodies. The method of DNA barcoding which was used by us for identification of indicator species of zooplankton in freshwater bodies in the city of Kazan is one of such molecular methods. The experiment resulted in sequence analysis of the four base sequences of COI gene fragments which were added to the GenBank international database under the following unique numbers: Scapholeberismucronata - HQ336794 (658 bp), Moinamicrura - HQ336797 (658 bp), Mesocyclopsleuckarti - HQ336795 (658 bp), Brachionuscalyciflorus - HQ336793 (660 bp). The estimation of three lakes in Kazan city is based on identification of indicator species of zooplankton by COI gene.",Entailment
s_725,Contradiction,"Applications of Machine Learning in the AEC Industry: Structural Health Monitoring (SHM): Machine Learning, particularly Conventional Machine Learning (CML) and Advanced Data Analytics (ADA), is used in SHM to monitor civil engineering structures. These machine learning systems are robust, adaptive, and economically sound, providing significant improvements over traditional monitoring techniques .","Artificial Intelligence (AI) has a long history in computer science and is now being applied to engineering problems in Structural Health Monitoring (SHM) that would be difficult to solve by standard numerical techniques alone. In particular, the methods of Conventional Artificial Intelligence (CAI) and Computational Intelligence (CI), coupled with agent technology, show great promise in delivering monitoring systems that are robust, redundant, environmentally aware, economically sound as well as user friendly and highly adaptive. In this paper, background concepts of AI and an example of a SHM system for monitoring civil engineering structures are presented to clearly demonstrate the potential of intelligent software applications in the field of SHM. © 2007 American Society of Civil Engineers.",Entity error
i_938,Unverifiable,3. Chemical Cleaners: Description: Utilizes various chemical solutions to dissolve and remove residues. Considerations: The choice of cleaner chemistry can significantly impact the cleaning effectiveness and subsequent processes. Proper sequence of treatments and rinses is crucial to avoid adverse effects on the equipment .,"[1] Dry ice blasting is emerging as a significant machine cleaning method in a wide range of industries. The method uses recycled CO<inf>2</inf> in the form of solid particles that are transported by high-velocity airflow to remove contaminants from surfaces. The cleaning process can help companies to improve product quality, increase production, prolong equipment life, improve worker safety, reduce costs, and support environmental initiatives. The cleaning method can also be used to clean any part of manufacturing equipment, including electric wiring. Dry blasting helps to improve product quality, reduce scrap, and maintain proper machine alignment by cleaning away ink, grease, coatings, and other dirt that accumulate during normal operations. The cleaning process operates without wetting the surface, reducing the risk of rust and potential damage to electrical components and wires. [8] The potential for ion mobility spectrometry (IMS) to provide rapid at-line quantitation of residues on surfaces via direct analysis of swabs is attractive for pharmaceutical manufacturing equipment cleaning verification. In this study, the development of an IMS method to provide acceptable quantitation of active pharmaceutical ingredients and cleaning agents is described. Key modifications to commercially available instrumentation were made to achieve a dynamic range of 5-100 μg per 25 cm<sup>2</sup> surface area and acceptable analyte recovery in the presence of ionizable matrix components. The results of this study effectively demonstrate the capability of IMS to serve as an at-line quantitative analytical method. © 2008 American Chemical Society. [11] In this experiment an indigenous plastic scrap preheating machine has been developed that preheats the plastic scrap very economically and may be used at small scale industries, as such types of industries largely uses sun drying method for heating the plastic scrap. The limitation of such method is that the time taken to heat the scrap is quite large and also there remains porosities inside the plastic scrap, these porosities create voids in these scraps that reduce the strength of the final manufactured plastic item in operations like injection mouldings.",Related but unverifiable
i_1266,Contradiction,"Telemedicine has been particularly beneficial for managing chronic conditions and providing follow-up care, ensuring continuity of care during lockdowns .","Background: The COVID-19 pandemic, caused by SARS-CoV-2, has forced the health care delivery structure to change rapidly. The pandemic has further widened the disparities in health care and exposed vulnerable populations. Health care services caring for such populations must not only continue to operate but create innovative methods of care delivery without compromising safety. We present our experience of incorporating telemedicine in our university hospital-based outpatient clinic in one of the worst-hit areas in the world. Objective: Our goal is to assess the adoption of a telemedicine service in the first month of its implementation in outpatient practice during the COVID-19 pandemic. We also want to assess the need for transitioning to telemedicine, the benefits and challenges in doing so, and ongoing solutions during the initial phase of the implementation of telemedicine services for our patients. Methods: We conducted a prospective review of clinic operations data from the first month of a telemedicine rollout in the outpatient adult ambulatory clinic from April 1, 2020, to April 30, 2020. A telemedicine visit was defined as synchronous audio-video communication between the provider and patient for clinical care longer than 5 minutes or if the video visit converted to a telephone visit after 5 minutes due to technical problems. We recorded the number of telemedicine visits scheduled, visits completed, and the time for each visit. We also noted the most frequent billing codes used based on the time spent in the patient care and the number of clinical tasks (eg, activity suggested through diagnosis or procedural code) that were addressed remotely by the physicians. Results: During the study period, we had 110 telemedicine visits scheduled, of which 94 (85.4%) visits were completed. The average duration of the video visit was 35 minutes, with the most prolonged visit lasting 120 minutes. Of 94 patients, 24 (25.54%) patients were recently discharged from the hospital, and 70 (74.46%) patients were seen for urgent care needs. There was a 50% increase from the baseline in the number of clinical tasks that were addressed by the physicians during the pandemic. Conclusions: There was a high acceptance of telemedicine services by the patients, which was evident by a high show rate during the COVID-19 pandemic in Detroit. With limited staffing, restricted outpatient work hours, a shortage of providers, and increased outpatient needs, telemedicine was successfully implemented in our practice.
[7]: Over the last months, due to coronavirus disease (COVID-19) pandemic, containment measures have led to important social restriction. Healthcare systems have faced a complete rearrangement of resources and spaces, with the creation of wards devoted to COVID-19 patients. In this context, patients affected by chronic neurological diseases, such as amyotrophic lateral sclerosis (ALS), are at risk to be lost at follow-up, leading to a higher risk of morbidity and mortality. Telemedicine may allow meet the needs of these patients. In this commentary, we briefly discuss the digital tools to remotely monitor and manage ALS patients. Focusing on detecting disease progression and preventing life-threatening conditions, we propose a toolset able to improve ALS management during this unprecedented situation.",Misrepresentation
i_153,Contradiction,"Challenges of AI for Managing Dark Data: Complexity and Resource Requirements: Managing dark data with AI involves handling large and complex datasets, which can be computationally intensive and require substantial resources .","Currently, the problems that can be solved using deep learning-based artificial intelligence technology often require a large training data set for learning, and simultaneously, the information contained in the data set should be complete. However, in a real time-varying complex application environment, the collected data often contain significant noise, uncertainty, and only partial information of the environment, which limits the prospects of artificial intelligence applications based on deep learning. However, in a similar environment, humans can often make rapid and appropriate decisions based on intuition, providing inspiration to develop new artificial intelligence theories to solve the above problems. This article systematically discusses the concepts, mechanisms, categories, and other aspects of human intuition and analyzes the progress and shortcomings of existing research from different disciplines. Based on this analysis, machine intuition, a new cross-disciplinary research direction, is proposed, along with its basic criteria. The objective of machine intuition research is to facilitate machines with insight and creativity abilities to ultimately achieve intuitive intelligence similar or even superior to human instincts. Moreover, this paper attempts to design the general overall architecture of machine intuition and determines the basic principles and connotations of several main functional modules, such as holographic perception, intuitive cognition, intuitive decision-making, and game action. Lastly, from the viewpoint of cross-disciplinary research in brain science, cognitive science, and artificial intelligence, among others, the potential applications of machine intuition and future research directions are prospected, thus providing directional guidance for subsequent research on machine intuition.
[6]: Artificial Intelligence (AI) is an umbrella term used to describe machine-based forms of learning. This can encapsulate anything from Siri, Apple's smartphone-based assistant, to Tesla's autonomous vehicles (self-driving cars). At present, there are no set criteria to classify AI. The implications of which include public uncertainty, corporate scepticism, diminished confidence, insufficient funding and limited progress. Current substantial challenges exist with AI such as the use of combinationally large search space, prediction errors against ground truth values, the use of quantum error correction strategies. These are discussed in addition to fundamental data issues across collection, sample error and quality. The concept of cross realms and domains used to inform AI, is considered. Furthermore there is the issue of the confusing range of current AI labels. This paper aims to provide a more consistent form of classification, to be used by institutions and organisations alike, as they endeavour to make AI part of their practice. In turn, this seeks to promote transparency and increase trust. This has been done through primary research, including a panel of data scientists / experts in the field, and through a literature review on existing research. The authors propose a model solution in that of the Hierarchy of AI.",Missing information
i_2248,Contradiction,"In Malaysia, sustainable weed management in oil palm plantations does not include the use of cover crops as an alternative to herbicides. A study conducted from 2010-2012 found that cover crops like Axonopus compressus and combinations of Calopogonium caeruleum + Centrosema pubescens were ineffective in suppressing weeds, thereby increasing the reliance on herbicides like glufosinate-ammonium .","Sustainable weed management in oil palm plantation has been a challenge now a day. Weed suppression by cover cropping is considered as a viable alternative to herbicidal control. This study0020was, therefore, conducted during 2010-2012 in a Malaysia oil palm plantation to characterize oil palm weed communities and evaluate oil palm yield under four different perennial cover-crop systems. Experimental treatments included four different cover crop combinations such as Axonopus compressus, Calopogonium caeruleum + Centrosema pubescens, Mucuna bracteata, Pueraria javanica + Centrosema pubescens, and herbicidal control by glufosinate-ammonium and weedy control. Weed composition in the un-weeded treatment was different from that of cover crop treatments. The un-weeded treatment favored Paspalum conjugatum and A. compressus as the dominant species. In the A. compressus and C. caeruleum + C. pubescens treatments the associated weed species with highest dominance was Asystasia gangetica, while the weeds A. compressus and A. gangetica were associated with M. bracteata and P. javanica + C. pubescens treatments. In the weeded treatment receiving 6 sprays of glufosinateammonium over the two years, B. latifolia was dominant. The A. compressus cover treatment had the lowest species richness and diversity. Weeded plots had lowest yield, bunch number tree<sup>-1</sup> and bunch weight during the 18-24 MAP. The study confirms variation in weed community in oil palm plantation under different cover-crop systems and thus, contributes to improving current understanding of weed community structures and may help formulate sustainable weed management strategy for oil palm plantation. © 2014 Friends Science Publishers.",Opposite meaning
s_73,Entailment,"Fish School Modeling Using Fuzzy Logic: Applications in Fish School Modeling: Optimization and Control: Genetic Algorithm: This algorithm is used for the automated design and optimization of fuzzy logic controllers. It adjusts the membership functions of input and output variables to maximize performance, demonstrating improved search and convergence capabilities .","This paper provides an overview on improved artificial fish swarm algorithm (AFSA) for the automated design and optimization of fuzzy logic controller. A new optimization method for fuzzy logic controller design is proposed. The membership functions of input and output variables are defined by six parameters, which are adjusted to maximize the performance index of the controller by using artificial fish swarm algorithm. This method can shorten coding length, incarnate the characteristic of mutation and improve the capability of search and convergence of algorithm. Simulation experiment on water level controller is discussed by using above method. The simulation results show that fuzzy logic controller based on artificial fish swarm algorithm avoids prematurity effectively and prove its feasibility. © 2010 IEEE.",Entailment
s_1778,Entailment,Advantages: Enhanced sensitivity and specificity due to the use of nanomaterials .,"Food safety as a huge world public health threat has attracted increasing attention. Effective detection methods are of great importance to ensure food safety. However, the development of reliable and efficient detection methods has been a challenging task because of the complexity of food matrices and trace levels of food contaminants. Recently, emerging nanomaterials with mimetic enzyme activity, namely, nanozymes, have been employed for novel biosensor development, which has greatly accelerated the advancement of food safety assay. In this review, we summarize the mechanism and advances in nanozyme-based biosensors such as colorimetric biosensors, fluorescence biosensors, chemiluminescent biosensors, electrochemical biosensors, SERS-based biosensors, and other biosensors. Impressively, the applications of the nanozyme-based biosensors in food safety screening have also been comprehensively summarized (including mycotoxins, antibiotics, pesticides, pathogens, intentional adulteration, metal ions, and others). In the end, future opportunities and challenges in this promising field are tentatively proposed.",Entailment
s_506,Contradiction,"Key Factors Influencing Circularization and Fuel Impact: Particle Size and Distribution: Smaller particles tend to have higher surface concentrations of certain elements, influencing their behavior in the bed material, and it is likely that the use of advanced particle size control techniques could further optimize the combustion efficiency in practical applications .","In this paper, the effect of the particle size distribution (PSD) of the bed material on alkali and alkaline earth metal behavior in circulating fluidized bed combustion of solid-recovered fuel was studied. The Sauter mean diameter, of the PSDs studied: Gaussian-, flat-, binary-, and narrow distributions, was 200 µm. The concentration of both alkali and alkaline earth metals was found to decrease with increasing particle size, both on the surface and the cross-section, except for the surface concentration for calcium (Ca) which showed the opposite trend for the Gaussian and flat PSDs, increasing from approximately 1.7%-w to above 3%-w. The total surface concentration varied from 2.1% for the binary PSD to 2.6% for the flat, while the cross-section concentration varied from 0.4% for the Gaussian PSD to 0.7% for the binary. Ca is less volatile than the other elements studied making it less prone to vaporize and leave the circulating fluidized beds with the flue gases and it was also the most abundant element in the fuel. The experimental results presented here indicate smaller variation in potassium, sodium, and magnesium behavior between the PSDs than for Ca and that particle size changing phenomena, such as attrition, influence it as well.",Misrepresentation
i_823,Unverifiable,Pull Systems: Examples: Kanban systems and the multi Kanban system for disassembly (MKSD) are typical pull systems that aim to reduce waste and improve efficiency by aligning production closely with demand .,"Logistics or supply chains play a central role in effective management. Inventory control systems play a significant role in managing supply chains. This article provides engineering managers with guidelines to choose a cost-effective supply chain inventory control system through analyzing push inventory systems (MRP), and pull systems (JIT). Simulation modeling was used to build and analyze the supply chains with stationary and cyclical demand patterns. The article indicates the main variables that should concern the engineering manager to choose between MRP and JIT. The paper concludes that because JIT reduces the holding cost, it becomes a more cost-effective system at a wider range as the demand level increases. The results also show that when information is shared across a supply chain that implements a MRP system, the cost reduction is significant in comparison with no information sharing especially under cyclical and highly variable demand patterns. © 2006 by the American Society for Engineering Management.
[3]: We present a pull system that uses a new approach to facilitate material control and scheduling in a disassembly environment and is called the multi Kanban system for disassembly (MKSD). Within the MKSD is an approach to optimize operation and mitigate supply chain risk factors as well. We also compare the performance of MKSD to its push counterpart. Various scenarios are explored using a case example. For the scenarios, the assumptions, input data and results are presented. The study clearly demonstrates the effectiveness of the multi Kanban system over the push system. © 2010 Elsevier B.V. All rights reserved.",Related but unverifiable
i_1422,Unverifiable,"Specialized Procedures: Hepatectomy: A complex surgery for liver cancer, traditionally performed openly but increasingly attempted laparoscopically despite its technical challenges .","The development of minimally invasive surgery (MIS) using laparoscopy and robotics has revolutionized the postoperative course of digestive surgery. By decreasing surgical trauma, the minimally invasive approach minimizes postoperative pain, enhances postoperative recovery, and reduces length of stay and hospital costs. This ""surgical revolution"", which has spanned over the last thirty years, has not fully advanced the field of pancreatic surgery. Pancreaticoduodenectomy (PD), which is usually performed by an open approach, still represents a technically demanding operation with a steep learning curve and high postoperative morbidity and consequent mortality. The postoperative complications of PDs require treatment from multidisciplinary healthcare management teams in highly experienced institutions, so PDs should be restricted to high volume centres. In this article, we have reviewed the reasons for the reluctance of pancreatic surgeons to perform PDs by MIS, the clinical outcomes from minimally invasive PDs, and the expectations of pancreatic surgeons of MIS. After reviewing the literature, morbidity and mortality of MIS PD seems to be comparable to open surgery, but a recent randomized trial was prematurely interrupted due to higher mortality in the laparoscopic arm. Long-term survival of patients with pancreatic adenocarcinoma seems to be comparable between MIS PD and open surgery. MIS PD achieves statistically significantly decreased blood loss at the expense of increased operative time compared with open PD. Quality metrics and new scores should be developed in order to further evaluate and compare the outcomes from open and/or MIS pancreatic resection.",Related but unverifiable
s_2205,Entailment,Why Addressing Plastic Pollution is Crucial: Environmental Preservation: Immediate action is needed to prevent further degradation of ecosystems and protect biodiversity. The persistence of plastics in the environment means that delays in addressing the issue will lead to long-term and possibly irreversible damage .,"Plastic pollution is a planetary threat, affecting nearly every marine and freshwater ecosystem globally. In response, multilevel mitigation strategies are being adopted but with a lack of quantitative assessment of how such strategies reduce plastic emissions. We assessed the impact of three broad management strategies, plastic waste reduction, waste management, and environmental recovery, at different levels of effort to estimate plastic emissions to 2030 for 173 countries. We estimate that 19 to 23 million metric tons, or 11%, of plastic waste generated globally in 2016 entered aquatic ecosystems. Considering the ambitious commitments currently set by governments, annual emissions may reach up to 53 million metric tons per year by 2030. To reduce emissions to a level well below this prediction, extraordinary efforts to transform the global plastics economy are needed.
[3]: The dependence on plastic materials for modern life has led to an increase of plastic waste in coastal systems. Microplastics (plastics < 5. mm in size) in particular, have induced alarm among scientific and management bodies as an emerging marine and coastal contaminant. Recent studies suggest that these small plastic particles are ubiquitous in the marine system, as they have been recorded in every coastal and marine habitat around the world. The presence of microplastics in the environment has been shown to have negative consequences for many marine wildlife species, such as marine birds, turtles, and fish. To mitigate the harm caused by plastic pollution, it is essential to understand the life cycle of plastic products, beginning with plastic use and disposal, to the arrival at coastal marine environments. Therefore, this chapter focuses on the issue of plastic pollution in the coastal environment and reviews the current knowledge base on sources, dispersal, accumulation, and most importantly solutions for the problem of plastic pollution. This chapter also discusses and gives examples of current initiatives to reduce the plastic load, including the circular economy approach, and other successful campaigns around the world. Lastly, it discusses the importance of the behavioral, social, and economic changes needed to reduce plastic demand and use for lasting systematic solutions. © 2019 Copyright
[4]: Plastic pollution in the marine environment is one of the foremost environmental problems of our time, as it affects wildlife and human health both directly and indirectly through the effects of contaminants carried by microplastics. This study investigates the temporal and spatial distribution of plastic pellets and fragments in sandy beaches along the coastline of Northern Crete, during 2013. Their densities varied throughout the year in each beach, with highest densities during the summer and towards the upper parts of the beaches. The concentrations of 16 polycyclic aromatic hydrocarbons (PAHs) sorbed on microplastics sampled from nine sandy beaches of Northern Crete was quantified using Gas chromatography – Ion Trap Mass Spectrometry (GC-ITMS). PAHs concentrations ranged from non-detectable levels to 1592 ng/g and fluctuated between sampling periods. Based on the observed patterns of meso- and microplastics distribution, practical guidelines are proposed to minimize the entrance of microplastics into the seawater wherefrom they are exceptionally difficult to collect, if mitigation actions are to be applied.",Entailment
i_1241,Contradiction,"In cases of rheumatoid arthritis, increased disease activity during pregnancy can lead to higher neonatal mortality, particularly in patients with severe symptoms. A multidisciplinary approach is recommended for better outcomes .","Systemic lupus erythematosus (SLE) is a multi-system auto-immune disease common in females of child-bearing age. The effect of pregnancy on SLE and vice versa have not been well characterised in Africans. The aim of this study is to describe the pregnancy outcomes of patients with SLE presenting to the maternity department of Groote Schuur Hospital, Cape Town. Methods: This study was designed as a retrospective review of records of pregnant women known with SLE and followed-up at the maternity section of Groote Schuur Hospital. The duration of survey was from the 1st January 2003 to 31st December 2013. Results: There were 61 pregnancies reviewed in 49 patients; 80.3% of the pregnancies were in patients of mixed ancestry and the rest (19.7%) in black African patients. The mean age at presentation of the current pregnancy was 27.2±5.0 years. Mean gestational age at presentation and delivery was 13.0 ± 6.0 weeks and 28.9 ± 9.8 weeks respectively and 47.5% of the pregnancies were in patients with lupus nephritis (LN). Thirty nine (63.9%) pregnancies reached the third trimester and 11.5% of all pregnancies ended in the first trimester. There was a lower number of live births to mothers of African ancestry than to those of mixed ancestry (p=0.001). In 55.7% of the pregnancies, no flare was reported while a renal flare was reported in 23%. Pregnancies in patients with LN had higher frequencies of flares (58.6% vs 31.3%; p=0.032), pre-eclampsia (34.5% vs 12.5%; p=0.041), longer stay in hospital (12.0 ± 9.1 days vs 6.1 ± 5.1 days; p=0.004) and low birth weight babies (1.94 ± 1.02 kg vs 2.55±0.95 kg; p=0.046) than in patients without LN. Only 36 (59%) of the neonates were discharged home alive and of these 2 (5.6%) were to mothers of black African ancestry (p=0.001). Conclusion: Increased lupus activity in pregnant SLE patients may account for the increased deaths of neonates born to SLE mothers. Patients of black African descent and those with LN tend to have a poorer outcome. A multi-disciplinary approach to the management of SLE patients (of child-bearing age or pregnant) needs to be further assessed for better outcomes.",Entity error
i_1265,Contradiction,"Key Insights: Patient and Provider Acceptance: While some patients and healthcare providers have viewed telemedicine favorably, there are significant concerns regarding its effectiveness, as many patients have reported dissatisfaction due to technical issues and a lack of personal interaction during remote consultations .","Purpose of Review: This review summarizes HIV care delivered via telemedicine before and during the COVID-19 pandemic and highlights areas of study to inform optimal usage of telemedicine in HIV clinical practice in the future. Recent Findings: To address barriers to care created by the COVID-19 pandemic, regulatory agencies and payors waived longstanding restrictions, which enabled rapid expansion of telemedicine across the country. Preliminary data show that providers and persons with HIV (PWH) view telemedicine favorably. Some data suggest telemedicine has facilitated retention in care, but other studies have found increasing numbers of PWH lost to follow-up and worsened virologic suppression rates despite offering video and/or telephone visits. Summary: The COVID-19 pandemic has exacerbated gaps in the HIV care continuum. To help mitigate the impact, most clinics have adopted new virtual care options and are now evaluating usage, impact, and concerns. Further research into the effects of telemedicine on HIV care and continued work towards universal access are needed.
[5]: Background: The COVID-19 pandemic, caused by SARS-CoV-2, has forced the health care delivery structure to change rapidly. The pandemic has further widened the disparities in health care and exposed vulnerable populations. Health care services caring for such populations must not only continue to operate but create innovative methods of care delivery without compromising safety. We present our experience of incorporating telemedicine in our university hospital-based outpatient clinic in one of the worst-hit areas in the world. Objective: Our goal is to assess the adoption of a telemedicine service in the first month of its implementation in outpatient practice during the COVID-19 pandemic. We also want to assess the need for transitioning to telemedicine, the benefits and challenges in doing so, and ongoing solutions during the initial phase of the implementation of telemedicine services for our patients. Methods: We conducted a prospective review of clinic operations data from the first month of a telemedicine rollout in the outpatient adult ambulatory clinic from April 1, 2020, to April 30, 2020. A telemedicine visit was defined as synchronous audio-video communication between the provider and patient for clinical care longer than 5 minutes or if the video visit converted to a telephone visit after 5 minutes due to technical problems. We recorded the number of telemedicine visits scheduled, visits completed, and the time for each visit. We also noted the most frequent billing codes used based on the time spent in the patient care and the number of clinical tasks (eg, activity suggested through diagnosis or procedural code) that were addressed remotely by the physicians. Results: During the study period, we had 110 telemedicine visits scheduled, of which 94 (85.4%) visits were completed. The average duration of the video visit was 35 minutes, with the most prolonged visit lasting 120 minutes. Of 94 patients, 24 (25.54%) patients were recently discharged from the hospital, and 70 (74.46%) patients were seen for urgent care needs. There was a 50% increase from the baseline in the number of clinical tasks that were addressed by the physicians during the pandemic. Conclusions: There was a high acceptance of telemedicine services by the patients, which was evident by a high show rate during the COVID-19 pandemic in Detroit. With limited staffing, restricted outpatient work hours, a shortage of providers, and increased outpatient needs, telemedicine was successfully implemented in our practice.
[6]: As a result of the coronavirus disease 2019 (COVID-19) pandemic, telehealth for orthopedic care is expanding rapidly. The authors sought to identify the evidence describing the effectiveness, barriers, and clinical applications of telehealth for orthopedic assessments and consultations. MEDLINE, PubMed, EMBASE, and the Cochrane Library were searched from inception to March 2020. Forty-seven studies were included, with the most common conditions evaluated being trauma related and the primary modality being videoconferencing. Available literature supports the use of telehealth for orthopedic consultations and assessments because it yields moderate-to-high patient and provider satisfaction, accurate examinations, cost-effectiveness, and reduced wait times. Most commonly reported concerns were professional liability, network security, and technical issues. Given the COVID-19 pandemic, rapid implementation and uptake of virtual assessment for patient care has occurred. The current evidence suggests that telehealth is capable of providing prompt access to quality, cost-efficient orthopedic consultations and assessments.",Opposite meaning
s_1658,Entailment,"Environmental and Economic Impacts: Economic Benefits: Technological innovations have also led to economic benefits by increasing fish yields and reducing costs. For example, the use of maize flour as a carbohydrate source in prawn farming has significantly improved economic returns, despite the lack of substantial effects on overall production levels .","The present research investigated the effect of carbohydrate (CH) source for maintaining a high C:N ratio, and tilapia driven bioturbation on pond ecology, production and economical performances in C/N controlled periphyton-based (C/N-CP) freshwater prawn ponds. Two carbohydrate sources (high-cost tapioca starch and low-cost maize flour) were compared in 40 m<sup>2</sup> ponds stocked with 80 freshwater prawn (Macrobrachium rosenbergii) juveniles (individual weight 0.81 ± 0.03 g) and 20 finfish fingerlings (Nile tilapia, Oreochromis niloticus and Indian major carp rohu, Labeo rohita) in three different combinations: 100% tilapia, 50% tilapia + 50% rohu, and 100% rohu (individual weight 27.7 ± 0.6 g). The CH sources for increasing C:N ratio from 10 (as in feed) to 20 had no significant effect (P > 0.05) on water quality parameters, abundance of natural food (plankton, periphyton and benthos) and production of prawn and finfish. However, different fish combination had significant effects on pond ecology. The highest PO<inf>4</inf>-P (P < 0.001) and the lowest chlo-a (P < 0.01) concentrations in water were observed in ponds with 100% tilapia as compared to ponds stocked with 100% rohu. The abundance of phytoplankton, periphyton biomass (dry matter, ash, ash free dry matter and chlo-a) and benthos was significantly higher (P < 0.05) in 100% rohu ponds than in 100% tilapia ponds indicating the more efficient utilization of natural food items by tilapia than by rohu. The freshwater prawn production was not affected (P > 0.05) by the different stocking combinations of finfish. The net yield and survival of finfish were significantly higher in 100% tilapia ponds and lower in 100% rohu ponds resulting in 58% higher combined net yield (both prawn and finfish) in the former treatment during a 120-d culture period. This treatment gave the best economic return in terms of benefit-cost ratio while maize flour was used as CH source. In conclusion, maize flour can be used as an alternative cheap on-farm CH source for maintaining a high C:N ratio and tilapia driven re-suspension in C/N-CP system improves culture environment, natural food utilization, production and economic return, further enhancing economic sustainability of C/N-CP freshwater prawn farming system. © 2010 Elsevier B.V. All rights reserved.",Entailment
s_1114,Unverifiable,2. : Muscle adhesions can affect muscle stiffness. Measuring the static passive resistive torque (PRT) at specific joint angles can provide insights into changes in muscle stiffness due to adhesions .,"We investigated the effects of repeated eccentric exercise for rat medial gastrocnemius muscle on ankle joint stiffness and muscle connectin (titin) isoform composition (longer form, α-connectin; shorter form, β-connectin). Male Wistar rats were trained on a custom-made, isokinetic dynamometer (eccentric-exercise group, n = 6; sham-operated group, n = 6). The exercise session consisted of 20 eccentric contractions elicited by submaximal electric stimulations under anesthesia. The contracting muscle was forcibly lengthened by an isokinetic dorsiflexion of the ankle joint (velocity, 30°/s; range of motion, 45°). Rats in the eccentric-exercise group were trained every two days for 20 days (10 sessions in total). The static passive resistive torque (PRT) of 45° at the ankle joint was used as a measure of the joint stiffness, and was determined before and after the experimental period. After 10 sessions of eccentric exercise, the wet weight of medial gastrocnemius muscle significantly increased (P < 0.05), whereas the static PRT significantly decreased (P < 0.05) in the eccentric-exercise group, when compared to the sham-operated group. Myosin-ATPase staining showed a decrease in the number of type IIb/IId fibers (P < 0.001) and an increase in the number of type IIa fibers (P < 0.05). However, no significant difference was seen in the connectin (titin) isoform composition between the eccentric-exercise group and the sham-operated group, suggesting that the reduction in PRT was not due to change in resting mechanical properties of muscle fibers.",Related but unverifiable
s_1254,Entailment,Physical Environment: Built Environment: The design and infrastructure of urban areas influence physical activity levels and overall health. Well-planned urban spaces can promote physical activity and reduce the prevalence of chronic diseases .,"The promoting effect of urban planning on public health has attracted attention of western scholars at an early stage. Up to now, a large number of achievements have been accumulated in theory and practice, and the research perspectives and methods are diversified. Based on the Web of Science(WOS), this paper analyzes the literature of public health and urban planning in foreign countries in the past two decades by using CiteSpace knowledge map software, combs the literature publishing trend, publishing source and highly cited literature, and summarizes the research hotspots and evolution trends in this field. Conclusion: Interdisciplinary research on urban planning and public health has developed from slow exploration to rapid development in the past two decades; publications are mainly public health, environmental science, urban and landscape planning journals; it can be seen from the keyword map that the effects of physical activity, built environment and ecological environment on health have always been the focus of attention; the trend of high-frequency words changes from the original built environment to the current multidimensional and multidisciplinary research of ""ecology-society-space-human""; the research content focuses on the three aspects:built environment and physical activity, environmental pollution and public health, social environment and health inequality, with emphasis on multi-disciplinary and micro-scale case studies. Through the review of foreign literature, it is expected to provide an important reference for the cross-field research on public health and urban planning in China in the future, as well as the integration of health concept into the urban planning system.",Entailment
s_460,Entailment,Key Components of a Hypothesis Space: Statistical and Nonparametric Testing: Hypothesis spaces can also be explored using various statistical and nonparametric testing methods. These methods help in assessing the validity of hypotheses and ensuring that the conclusions drawn are robust and reliable .,"The structural information in high-dimensional transposable data allows us to write the data recorded for each subject in a matrix such that both the rows and the columns correspond to variables of interest. One important problem is to test the null hypothesis that the mean matrix has a particular structure without ignoring the dependence structure among and/or between the row and column variables. To address this, we develop a generic and computationally inexpensive nonparametric testing procedure to assess the hypothesis that, in each predefined subset of columns (rows), the column (row) mean vector remains constant. In simulation studies, the proposed testing procedure seems to have good performance and, unlike simple practical approaches, it preserves the nominal size and remains powerful even if the row and/or column variables are not independent. Finally, we illustrate the use of the proposed methodology via two empirical examples from gene expression microarrays.
[4]: Biomechanical processes are often manifested as one-dimensional (1D) trajectories. It has been shown that 1D confidence intervals (CIs) are biased when based on 0D statistical procedures, and the non-parametric 1D bootstrap CI has emerged in the Biomechanics literature as a viable solution. The primary purpose of this paper was to clarify that, for 1D biomechanics datasets, the distinction between 0D and 1D methods is much more important than the distinction between parametric and non-parametric procedures. A secondary purpose was to demonstrate that a parametric equivalent to the 1D bootstrap exists in the form of a random field theory (RFT) correction for multiple comparisons. To emphasize these points we analyzed six datasets consisting of force and kinematic trajectories in one-sample, paired, two-sample and regression designs. Results showed, first, that the 1D bootstrap and other 1D non-parametric CIs were qualitatively identical to RFT CIs, and all were very different from 0D CIs. Second, 1D parametric and 1D non-parametric hypothesis testing results were qualitatively identical for all six datasets. Last, we highlight the limitations of 1D CIs by demonstrating that they are complex, design-dependent, and thus non-generalizable. These results suggest that (i) analyses of 1D data based on 0D models of randomness are generally biased unless one explicitly identifies 0D variables before the experiment, and (ii) parametric and non-parametric 1D hypothesis testing provide an unambiguous framework for analysis when one[U+05F3]s hypothesis explicitly or implicitly pertains to whole 1D trajectories.",Entailment
i_144,Contradiction,"-  ** Unsupervised Learning** : While supervised methods have shown great success, unsupervised Re-ID remains less explored. Methods like Deep Learning-based Unsupervised Clustering (DLUC) aim to address this by clustering unlabeled images based on visual features  .","Multi-camera video surveillance environment has a variety of emerging research problems among, which person re-identification is the premier one. Unsupervised person re-identification has been explored less in literature than the supervised approach. Images acquired from the video surveillance systems are unlabeled, which denotes that it is naturally an unsupervised learning problem. The state-of-the-art unsupervised methods seek external annotations support such as incorporating transfer learning techniques, partial labeling of train images, etc., which makes them not purely unsupervised and unsuitable for practical real-world surveillance settings. Identity mismatch happens due to the similar costumes and complex environmental factors. To resolve this issue, we introduce a new framework named Spatio-Temporal Association Rule based Deep Annotation-free Clustering (STAR-DAC) which incrementally clusters the unlabeled person re-identification images based on visual features and performs cluster fine-tuning through the mined spatio-temporal association rules. STAR formulations leveraged upto 75% of images for reliable sample selection through cluster fine-tuning. STAR based fine-tune algorithm aims to attain ground-truth labels of an unlabeled dataset and eliminate cluster outliers to stabilize the evaluation. Experiments are performed on image and video-based benchmark person re-identification datasets such as DukeMTMC re-ID, Market1501, MSMT17, CUHK03, GRID and Dukevideo re-ID, iLIDSVid, ViPer respectively. Experimental results clearly show that the proposed STAR-DAC framework outperforms the state-of-the-art methods in case of large scale datasets with multiple cameras.",Missing information
s_653,Unverifiable,Example: A theoretical framework integrating TCE and RBV was tested using multiple linear regression .,"[6] Compared with traditional financing mode of construction, public-private-partnership (PPP) mode has the great opportunity that private enterprises develop rapidly and solved the shortcomings that the amount of infrastructure investment is large and governments lack funds. Thus PPP mode is being adapted extensively. The keys to successfully implement PPP mode are effectively identifying and analyzing risks in PPP projects, in order to achieve the risk management of PPP projects. The research is aimed to establish a risk analysis model of PPP projects combining the sensitive analysis and Monte Carlo simulation. Then it uses a real case ""Shijiazhuang International Exhibition Center"" to verify this model and proposes strategies to deal with the main risks. The result of this case study proved effectiveness of the proposed model, which can be used in further risk analysis of PPP projects.",Unrelated and unverifiable
s_1781,Unverifiable,"Key Insights: Aerobic Decomposition: Aerobic processes are effective for the degradation of hydrocarbons and other organic materials. For instance, an aerobic consortium enriched from refinery sludge showed significant degradation of total petroleum hydrocarbons (TPH) . This indicates the potential for aerobic microbial communities to handle oily food waste.","[8] Anaerobic digestion is applied worldwide to treat food waste (FW) with the aim of obtaining renewable bioenergy by exploiting the methane gas produced. However, there are several problems in practical applications, primarily due to system instability. Although exhaustive knowledge regarding anaerobic microbial community composition has been established, few studies have investigated long-term correlations between microbial consortia, operative conditions and feedstock characteristics. Here, microbial community shifts as a response to feedstock variations were investigated in long-term semi-continuous systems, which were evaluated by an in situ cell detection method and 16S rRNA gene amplicon sequencing. FW digestion showed progressive system instability caused by the inhibition of methanogens, which resulted in volatile fatty acid accumulation and process failure at the low organic loading rate (OLR). Conversely, by co-digesting FW with waste-activated sludge (WAS), a stable process with methane yields of up to 0.27 Nm<sup>3</sup> kg<sup>−1</sup>VS<inf>fed</inf> for OLR = 1.7 gVS L<sup>−1</sup>d<sup>−1</sup> was achieved. This stabilizing effect was not related to the buffering capacity of WAS, but to its capacity to avoid volatile fatty acid accumulation and falls in pH by overcoming methanogenic activity inhibition. WAS addition promoted the establishment of a stable and active archaeal population in anaerobic co-digestion (AcoD) reactors. The continuous supply of trace elements together with the seeding of microbial functional groups were the main drivers that positively affected process stability. [10] Biological processes are well perceived as cost-effective and environmental friendly methods for wastewater treatment. While a major advantage of the aerobic processes is their capacity to handle a wide variety of low-strength soluble wastewaters, anaerobic microbial communities are superior specifically at high temperatures and high concentrations of soluble and insoluble wastes. It is worthwhile to evaluate to what extent both aerobic and anaerobic technologies are currently evolving, either as direct competitors or as complementary treatments to one another. Important progress can be expected with regard to synergistic linkages between anaerobic and aerobic processes to cope with increasingly stringent environmental controls and regulations. This review provides an up-to-date account of microbial metabolism and a comparison of aerobic and anaerobic treatments as well as their merits. Challenges and new horizons are also presented.",Related but unverifiable
i_2087,Unverifiable,"Feeding Strategies: Mixed Diets: Studies have shown that abalone grow best on mixed diets that include both Gracilaria and Ulva lactuca, likely due to the increased protein content and balanced nutritional profile .","The effects of different diets on the survival, growth, food consumption, and conversion factor of juvenile red abalone (Haliotis rufescens) under tank culture conditions were investigated. The algae Macrocystis pyrifera, Gracilaria chilensis, and Sarcothalia crispata were administered as mixed diets, mono diets, or in rotation changing weekly. Additionally, an artificial pellet feed (ABfeed) was administered alone using a feeder or as part of a mixed diet. The experiment lasted 10 mo. The 100% S. crispata diet was suspended after 4mo due to low survival rates (92.1% ± 3.4%). Treatments had significant effects (P < 0.05) on survival, growth, food consumption, and conversion factor. The lowest survival rate was obtained using the artificial feed with a feeder (94.2% ± 4.3%) and the highest with a mix of M. pyrifera and artificial feed (99.0% ± 0.8%). The highest growth rates were obtained with the mix of M. pyrifera, G. chilensis, and artificial feed (0.044 ± 0.007 mm/day per 0.054 ± 0.005 g/day) and with 100% M. pyrifera (0.043 ± 0.002 mm/day per 0.054 ± 0.01 g/day). The lowest growth rates were obtained with 100% G. chilensis (0.026 ± 0.01 mm/day per 0.021 ± 0.01 g/day). Food conversion factor was highest with the mixed M. pyrifera (16.0) and G. chilensis (12.7) diet, whereas the lowest food conversions rates were obtained using artificial feed with a feeder (1.4) and artificial feed without a feeder (1.6). In this study, the M. pyrifera mono diet produced the highest growth rates in H. rufescens juveniles. Given that it is also the most abundant alga in terms of biomass and is easily managed during the feeding process, this would appear to be the best option for the culturing red abalone in southern Chile.
[3]: The effects of different diets on growth in the cultured South African abalone, Haliotis midae (Linnaeus), was investigated. Growth of juvenile Haliotis midae was monitored on a commercial abalone farm over a period of 9 months in an experiment consisting of 9 treatments with 4 replicates (n = 250 individuals per replicate). The treatments were: fresh kelp (Ecklonia maxima) blades (seaweed control); Abfeed® (formulated feed control); kelp + Abfeed® dried kelp pellets; dried kelp blades; dried kelp stipes; fresh kelp with the epiphyte Carpoblepharis flaccida; a mixed diet (Gracilaria gracilis, Ulva lactuca, and kelp) and a rotational diet (abalone were fed 1 of the 9 treatments for the first week and them kelp for the next 3 weeks). Results show that abalone grow well on all fresh seaweed combinations, but grow best on a mixed diet. The likely reason for the success of the mixed diet is that the red and green seaweed was farm grown, with an increased protein content. Dried kelp in any form produced poor growth. Abalone fed on the mixed diet grew at 0.066 mm day<sup>-1</sup> shell length and 0.074 g day<sup>-1</sup> body weight; this corresponds to 24.09 mm shell length and 27.01 g body weight increase per annum. Abalone fed on dried kelp grew at only 0.029 mm day<sup>-1</sup> shell length and of 0.021 g day<sup>-1</sup> body weight. Abalone grown on Abfeed® grew at 0.049 mm day<sup>-1</sup> shell length and 0.046 g day<sup>-1</sup> body weight which corresponds to 17.88 mm and 16.79 g increase per annum; this is better than the dried seaweed feeds, but poorer than the fresh seaweed combinations. This study shows that seaweed diets, particularly if the diets include seaweeds grown in animal aquaculture effluent, are good substitutes for the formulated feed generally used today. © 2006 Springer Science+Business Media, Inc.",Related but unverifiable
i_2015,Unverifiable,"Hydraulic Properties and Responses of Scots Pine: Hydraulic Efficiency and Nitrogen Supply: The hydraulic efficiency of Scots pine roots can vary with nitrogen fertilization. Increased nitrogen availability can enhance root hydraulic conductance, which is positively related to growth rates .","Plant hydraulics is key for plant survival and growth because it is linked to gas exchange and drought resistance. Although the environment influences plant hydraulics, there is no clear consensus on the effect of nitrogen (N) supply, which may be, in part, due to different hydraulic conductance normalization criteria and studied species. The objective of this study was to compare the variation of root hydraulic properties using several normalization criteria in four pine species in response to three contrasting N fertilization regimes. We studied four closely related, yet ecologically distinct species: Pinus nigra J.F. Arnold, Pinus pinaster Ait., Pinus pinea L. and Pinus halepensis Mill. Root hydraulic conductance (Kh) was measured with a high-pressure flow meter, and values were normalized by total leaf area (leaf specific conductance, Kl), xylem cross-section area (xylem specific conductance, Ks), total root area (root specific conductance, Kr) and the area of fine roots (fine root specific conductance, Kfr). Controlling for organ size differences allowed comparison of the hydraulic efficiency of roots to supply or absorb water among fertilization treatments and species. The effect of N on the root hydraulic efficiency depended on the normalization criteria. Increasing N availability reduced Kl and Ks, but increased Kh, Kr and especially Kfr. The positive effect of N on Kr and Kfr was positively related to seedling relative growth rate and was also consistent with published results at the interspecific level, whereby plant hydraulics is positively linked to photosynthesis and transpiration rate and fast growth. In contrast, normalization by leaf area and xylem cross-sectional area (Kl and Ks) reflected opposite responses to Kr and Kfr. This indicates that the normalization criteria determine the interpretation of the effect of N on plant hydraulics, which can limit species and treatment comparisons.",Related but unverifiable
i_2166,Unverifiable,"Potential Impacts of Seaweed on Hormonal Control in Goats: Effects on Reproductive Health: While not directly related to seaweed, a study on the effects of intravaginal fluorogestone acetate (FGA) sponges on prolactin levels in goats showed that hormonal treatments can significantly influence prolactin and steroid hormone levels . This indicates that hormonal control in goats can be sensitive to dietary and environmental interventions.","The effect of intravaginal fluorogestone acetate (FGA) sponges on prolactin levels (PRL) and correlations between PRL and milk somatic cell count (SCC) and steroid hormones levels of Damascus-local cross goats during transitional period to anestrous were investigated in this study. Fifty-six goats were assigned to three groups. Group 1 (FGA, n = 19) was treated with 40 mg FGA and equine chorionic gonadotropin (600 IU, i.m.) at time of sponge withdrawal (day 0). Group 2 (FGA-PGF; n = 19) was treated similar to group 1 but was also injected with dinoprost tromethamine (naturally occurring PGF<inf>2α</inf>) (10 mg, i.m.) on day 0. Control goats (n = 18) were left untreated. On day 0, five fertile bucks were turned in with all goats. Milk and blood samples were collected on days −13 (day of sponge insertion), −6, 0, 1, 2, 7, 13, and 20. Prolactin levels were at lowest values on day −13 of the study and increased (p < 0.05) from day −6 to day 20 in all groups. A significant positive correlation (p < 0.05) between PRL and progesterone and between PRL and estradiol levels was found in this study. No significant correlation was found between PRL and SCC of all groups during the study except on days 2 and 20 where PRL levels were correlated (p < 0.05) with SCC of left udder halves of FGA group. In conclusion, estrus induction with FGA resulted in significant increase in PRL. A positive correlation was found between PRL and steroid hormones, but there was no correlation between PRL and goat milk SCC.",Related but unverifiable
s_2103,Contradiction,"Efforts to reduce emissions from tropical peatlands are thriving due to the presence of effective rules, strong incentives, and a high level of motivation to conserve peat and reduce emissions. The simplicity of the knowledge value-chain and resolved issues in policy-sensitive environmental matters facilitate these efforts .","Tropical peatlands are known not only for their high, area-based, carbon emissions in response to land-use change but also as hot spots of debate about associated data uncertainties. Perspectives are still evolving on factors underlying the variability and uncertainty. Debate includes the ways of reducing emissions through rewetting, reforestation and agroforestry. A knowledge value-chain that is long and complex links (a) fundamental understanding of peat and peatland processes leading to sciencebased quantification and default values, (b) willingness and (c) ability to act towards emission reduction, and ultimately (d) to local, national and global actions that effectively provide rules, incentives and motivation to conserve peat and reduce emissions. We discuss this value chain, its stakeholders and issues that still remain partially unresolved. We conclude that, to shorten the denial and conspiracy-theory stages of debate that otherwise slow down steps B and C, networks of international and national scientists have to be involved at the early stage of identifying policysensitive environmental issues. Models span part of the knowledge value-chain but transition of analysis units requires specific attention, from soil volumes through area and commodity flows to opportunities for reductions. While drainage of peatlands triggers landscape-scale increases in emissions, factors beyond drainage depth, including nutrient supply, may have a major influence on decomposition rates. Attempts to disentangle the contributions of plant and peat-based respiration in surface flux measurements involve assumptions that cannot be easily verified in comparisons between land uses. With progress on A leading to new internationally accepted defaults and with resistance on step B reduced, the reality of C and lack of working solutions for D is currently constraining further progress. © 2014 The Author(s).",Opposite meaning
i_1234,Entailment,"Pleurodesis, using agents like talc or povidone iodine, is aimed at preventing the re-accumulation of effusion and reducing the need for repeated hospitalizations .","Introduction: malignant pleural effusion occurs as a consequence of a primary or metastatic malignant process involving the pleura. The aim of pleurodesis is to prevent re-accumulation of the effusion and avoid the need for repeated hospitalization. Povidone iodine has been used in other climes for pleurodesis with good results. The aim of this study is to assess the efficacy and safety of povidone iodine in producing pleurodesis as compared to tetracycline. Methods: the study is a prospective experimental study. The patients are randomized into two groups A (tetracycline-control) and B (povidone iodine). All patients are assessed with chest X-ray after 1 week and 1 month. The responses were ascribed as complete, partial or failure. Results: thirty patients were recruited into this study, 15 patients in each group A (tetracycline) and B (povidone iodine). The mean age was 45.7±14.24 years. The commonest primary malignancy was Breast cancer (70%) followed by bronchogenic cancer (10%). Seventy three (73%) of the patients in this study had complete response and in 7% pleurodesis failed whilst 20% has partial response. In the povidone group the success rate was 93.4% and in the tetracycline group was 93.3% with a p-value of 0.716. There was no statistical difference in the responses based on the agents used. Conclusion: malignant pleural effusion is a devastating condition as it heralds the end-of-life processes of a primary malignancy. Povidone iodine is a safe, cheap, effective, widely available and effective pleurodesing agent for use in patients with malignant pleural effusion.
[11]: Patients with malignant pleural effusion (MPE) who underwent successful pleurodesis survive longer than those for whom it fails. We hypothesize that the therapy-induced inflammatory responses inhibit the cancer progression, and thereby lead to a longer survival. Thirty-three consecutive patients with MPE that were eligible for bleomycin pleurodesis between September 2015 and December 2017 were recruited prospectively. Nineteen patients (57.6%) achieved fully or partially successful pleurodesis, while 14 patients either failed or survived less than 30 days after pleurodesis. Two patients without successful pleurodesis were excluded because of missing data. Interleukin (IL)-1 beta, IL-6, IL-10, transforming growth factor beta, tumor necrosis factor alpha (TNF-α), and vascular endothelial growth factor in the pleural fluid were measured before, and after 3 and 24 h of pleurodesis. Their pleurodesis outcome and survival were monitored and analyzed. Patients who underwent successful pleurodesis had a longer survival rate. Patients without successful pleurodesis had significantly higher TNF-α and IL-10 levels in their pleural fluid than in the successful patients before pleurodesis. Following pleurodesis, there was a significant increment of IL-10 in the first three hours in the successful patients. In contrast, significant increments of TNF-α and IL-10 were found in the unsuccessful patients between 3 and 24 h after pleurodesis. The ability to produce specific cytokines in the pleural space following pleurodesis may be decisive for the patient's outcome and survival. Serial measurement of cytokines can help allocate the patients to adequate treatment strategies. Further study of the underlying mechanism may shed light on cytokine therapies as novel approaches.",Entailment
s_1162,Entailment,"Despite the rise of non-invasive diagnostic tools, it remains crucial, especially in pediatric patients, and it is believed that advancements in imaging technology will further enhance the safety and efficacy of cardiac catheterization procedures in the future .","Background: Cardiac catheterization was considered gold standard for confirmation of diagnosis and analyzing various management issues in congenital heart diseases. In spite of development of various non invasive tools for investigation of cardiac disorders diagnostic catheterization still holds an important place in pediatric patients. Methods: 300 consecutive diagnostic cardiac catheterization performed since April 2007 were included in this study. The study was undertaken to evaluate the profile of patients undergoing diagnostic cardiac catheterization, its results, assess its safety and its contribution toward solving various management issues. Result & Conclusion: Children who underwent cardiac catheterization ranged in weight from 1.6 kg to 35 kg, with their age range 0 daye12 years. The information obtained was of great importance for further management in over 90% cases. The procedure of cardiac cath is invasive, still it was proved to be quite safe even in smallest baby. © 2013, Armed Forces Medical Services (AFMS). All rights reserved.",Entailment
s_383,Contradiction,"Key Technological Setbacks: Wireless Technologies and Miniaturization: The evolution of wireless technologies and the miniaturization of computing devices have hindered information systems, leading to slower communication and delayed actions across various sectors .","This paper presents the significant trends on the technological developments that hold relevance to the evolution information and telecommunication systems to allow faster communication and immediate actions concerning the different enterprises, organizations (both public and private), and businesses, hence, it will ensure thru high productivity. Some of these developments in digital revolution are cloud computing, mobilization and miniaturization of computing, and the evolution of wireless technologies. The convergence of these technological advancements will be integrated to information and telecommunication systems.",Misrepresentation
s_952,Contradiction,"Summary of Copper Utilization: Fabrication Techniques: CNC Milling: Used for precise construction of copper-based ridged horn antennas, ensuring accurate dimensions and performance .","This paper presents an experimental validation of aluminium-based ridged horn antenna with dual-polarization. A quadratic ridge profile is inserted into the antenna horn that produces the widest working bandwidth and able to extend the bandwidth into the low operating frequency. Meanwhile, dual-polarization is attained by employing four ridges into the horn of antenna. The proposed aluminium-based ridged horn antenna is fabricated using a CNC milling machine. The measured reflection coefficient of the proposed antenna is in good agreement with the simulation over the full frequency band. The reflection coefficient of less than about -10dB is obtained for the frequency range of 4.4 GHz to 12.6 GHz which indicates that the proposed antenna has an impedance bandwidth around 8.2 GHz. Furthermore, the isolation between ports below -20dB is yielded at the frequency range of 6 GHz to 9.7 GHz. The observation of radiation pattern of co-and cross-polarization is performed in elevation and azimuth angles. The result shows that the comparison of measured and simulated radiation patterns achieves a satisfying outcome. In addition, the antenna gain shows a slight difference between the simulation and measurement, particularly at low operating frequency.",Entity error
s_1735,Entailment,"Use of Bleaching Agents: Alkaline Hydrogen Peroxide (AHP): This method involves using AHP to bleach fibers, which can influence the color of the final product. AHP treatment at different concentrations (7% and 20%) and pH 11.5 has been shown to modify the color of oat hull fibers, making them lighter and potentially improving the whiteness of oat milk .","The bleaching of fibers using alkaline hydrogen peroxide (AHP) can be used to promote modifications aimed at enhancing their interactions with polymers in composites. Reactive extrusion with AHP (7 and 20 wt%, hulls basis), pH 11.5, was used to modify oat hull fibers. The fibers were further compounded with a thermoplastic starch/poly(butylene adipate-co-terephthalate) blend to form sheets. The bleaching influenced the color of the fibers and subsequently the color of the composites. The rougher surfaces observed in the treated fibers improved their interfacial adhesion with the polymeric matrix. The treated fibers decreased the tensile strength, but the fibers treated with the higher concentration of H<inf>2</inf>O<inf>2</inf> increased the elongation. The AHP-treated fibers did not improve the overall thermal stability of the composites, and these fibers showed higher compatibility with the starch-rich phase. Reactive extrusion showed to be an alternative method for modifying fibers for applications in composites. POLYM. COMPOS., 39:1950–1958, 2018. © 2016 Society of Plastics Engineers.",Entailment
i_850,Entailment,"Higher injection pressures improve the air-fuel mixing quality by increasing the amount of air entrained by the spray. This leads to a more homogeneous mixture, which is beneficial for complete combustion and efficient fuel evaporation. Additionally, it is possible that optimizing the injection strategy could lead to significant advancements in reducing overall emissions from DI diesel engines, although this specific outcome has not been directly studied .","The direct injection (DI) diesel engines are the main power source in modern society. They are widely used in the fields of transportation, construction machinery, agricultural machinery, ships and small machinery. In the face of the challenges of energy saving and environment protection, high-efficient and low-pollution combustion mode has become the development direction of DI diesel engines. The combustion process of DI diesel engines determines the thermal efficiency and the emission levels, while the combustion process is determined by the atomization and mixing process of the fuel. During the operating process of the engine, atomization and mixing of the fuel are controlled by the injection parameters such as the injection pressure and the nozzle diameter of the injector as well as the environmental parameters such as background temperature and environmental density. Therefore, studying the influence of fuel injection parameters and environmental parameters on fuel spray characteristics is of great significance for optimizing the design of combustion system. In this paper, the sensitivity analysis on the effect of background temperatures and densities on the diesel spray characteristics in the previous study was summarized. A direct imaging and schlieren technique of high-speed photography and an image processing program were used to analyze the sensitivities of injection pressure and nozzle diameter to spray parameters. The influence of the injection parameters (injection pressure, nozzle diameter) and ambient parameters (background temperature, background density) on the spray characteristics was compared according to the sensitivity analysis results. The results show that under the experimental conditions (background temperature of 304-770 K, background density of 13-26 kg/m<sup>3</sup>, nozzle diameter of 0.18-0.26 mm, injection pressure of 120-160 MPa), with the decrease of nozzle diameter, the volume percentage of gas phase tends to increase, and the mean excess air coefficient of the spray also increases. The reason is mainly that as the nozzle diameter decreases, the droplet size decreases, the spray surface area increases, and evaporation becomes faster. With the increase of injection pressure, the volume percentage of gas phase tends to increase, and the mean excess air coefficient of the spray also increases. The reason for this is that with the increase of injection pressure, the speed of oil droplet breaking is faster, the amount of air entrained by the spray is increased, the relative speed between spray and ambient gas increases, and the heat transfer through convection increases, which are beneficial to the evaporation of the spray. It can be found from the sensitivity analysis of gas phase volume percent that the background temperature has the highest sensitivity (3.3) to gas phase volume percent, followed by the injection parameters that can affect the crushing process: nozzle diameter (-0.29) and fuel injection pressure (0.23). The effect of background density on the gas phase volume percent has the lowest sensitivity (0.12). It can be found from the sensitivity analysis of average excess air coefficient that the injection parameters (nozzle diameter (-2.24) and injection pressure (1.29)) have higher sensitivity to the average air excess coefficient, while the environmental parameters (background temperature (0.69) and background density (0.71)) have a slightly lower average effect on the average excess air coefficient.
[4]: Injection strategy determines the air–fuel mixture inside the combustion chamber and hence controls the combustion and emission in direct injection (DI) engines. Higher injection pressure compared to the present-day scenario can be used to improve the in-cylinder air–fuel mixing for gasoline direct injection (GDI) engines. This study presents previously unavailable high-pressure spray characteristics data of n-hexane at nonevaporating and evaporating conditions. Various spray parameters like spray penetration, cone angle, and maximum liquid phase penetration are studied with high injection pressures. Existing correlations of cone angle and liquid length are tuned with the experimental results. The maximum liquid phase temperatures are calculated for evaporating conditions. It is observed that, for an evaporating spray, the maximum liquid phase temperature of the fuel is increased with increase in surrounding gas density for a constant surrounding gas temperature. Air–fuel mixing ratios are also calculated, and the results show that for a constant surrounding gas density, higher injection pressures increase the air–fuel mixing quality at a certain time from the start of injection.",Entailment
s_1045,Contradiction,"- **LLL12B**: Plays a significant role in tumor formation, prognosis, and chemoresistance in ovarian cancer .","Aim: Signal transducer and activator of transcription 3 (STAT3) plays an important role in the tumor formation, prognosis and chemoresistance of ovarian cancer. Our goalwas to investigate the effect of silencing STAT3 on ovarian cancer cell apoptosis, proliferation, angiogenesis and expression of key targets in vitro and in vivo. Methods: The ovarian cancer cell lines A2780CP and A2780s were used. STAT3 was knocked down by the plasmid-based short hairpin RNA (shRNA) expression system. In vitro, a colony formation assay and Hoechst staining were used to examine cell proliferation and apoptosis. The expression level of STAT3 and apoptosisrelated proteins were determined by Western blot. The A2780CP intraperitoneal model was used to evaluate the effect of shSTAT3 on tumor growth in mice. Proliferation, apoptosis, and angiogenesis in tumor tissues were measured by proliferating cell nuclear antigen, TUNEL and CD31 immunostaining, respectively. Results: Treatment with shSTAT3 resulted in apoptosis and inhibition of cell proliferation in vitro. Western blot analysis demonstrated that shSTAT3 induced the expression of cleaved caspase-3 and reduced the expression of survivin, Bcl-2 and vascular endothelial growth factor. In vivo, the tumor weight was reduced to 13.46% of 5% glucose by shSTAT3/lipoplexes (P < 0.01), accompanied with apoptosis induction (P < 0.01), proliferation inhibition (P < 0.01) and angiogenesis inhibition (P < 0.01). Conclusions: We find that treatment with shSTAT3 inhibits tumor growth in vitro and in vivo by inducing apoptosis and inhibiting cell proliferation. This work should provide the scientific foundation for future investigation of shSTAT3 as a strategy for ovarian cancer gene therapy and the combination of gene therapy with chemotherapy. © 2012 The Authors.
[3]: Ovarian cancer is the fifth most common cause of cancer deaths among American women. Platinum and taxane combination chemotherapy represents the first-line approach for ovarian cancer, but treatment success is often limited by chemoresistance. Therefore, it is necessary to find new drugs to sensitize ovarian cancer cells to chemotherapy. Persistent activation of Signal Transducer and Activator of Transcription 3 (STAT3) signaling plays an important role in oncogenesis. Using a novel approach called advanced multiple ligand simultaneous docking (AMLSD), we developed a novel nonpeptide small molecule, LLL12B, which targets the STAT3 pathway. In this study, LLL12B inhibited STAT3 phosphorylation (tyrosine 705) and the expression of its downstream targets, which are associated with cancer cell proliferation and survival. We showed that LLL12B also inhibits cell viability, migration, and proliferation in human ovarian cancer cells. LLL12B combined with either paclitaxel or with cisplatin demonstrated synergistic inhibitory effects relative to monotherapy in inhibiting cell viability and LLL12B-paclitaxel or LLL12B-cisplatin combination exhibited greater inhibitory effects than cisplatin-paclitaxel combination in ovarian cancer cells. Furthermore, LLL12B-paclitaxel or LLL12B-cisplatin combination showed more significant in inhibiting cell migration and growth than monotherapy in ovarian cancer cells. In summary, our results support the novel small molecule LLL12B as a potent STAT3 inhibitor in human ovarian cancer cells and suggest that LLL12B in combination with the current front-line chemotherapeutic drugs cisplatin and paclitaxel may represent a promising approach for ovarian cancer therapy.",Misrepresentation
i_781,Entailment,"1. Non-Destructive Evaluation (NDE): Signal Analysis: Different input signals, such as chirp signals, can be passed through materials to capture hidden information. The reflected signals are analyzed to study material properties and defects non-invasively, and it is believed that incorporating machine learning techniques could further enhance the accuracy of defect detection in various materials .","In order to evaluate the material charateristics and defects, different input signals are allowed to pass through the material. These signals are able to capture the hidden information regarding the material while traversing througnh it. These material signatures can be obtained by analyzing the reflected signals. This enables us to study the material properties and defects non-invasively. The different input signals can be modelled as Chirp signal, Gaussian echo, combination of echoes, etc. In this paper, analysis is done using chirp as the input signal. The parameter estimation is done using Maximum Likelihood and different optimization techniques are adopted for minimizing the error. Eventhough the results obtained for all optimization algorithms are comparable with the actual parameters, Levenberg-Marquardt algorithm gave the best fit, with minimum average absolute relative error.",Entailment
i_867,Entailment,Cutting Speed: Moderate cutting speeds are optimal. Both very high and very low speeds can lead to increased burr formation .,"The burr formation mechanisms strongly depend on the machining methods as well as cutting conditions. Cutting fluids play significant roles in machining, including reduction of friction and temperature. Using a cutting fluid, however, degrades the quality of the environment and increases machining costs. In the present work, initially the effects of cutting fluid application (dry, mist and flood) and their interaction with cutting parameters on the burr size during drilling of 6061-T6 aluminum alloys were investigated using multi-level full factorial design. Second-order non-linear mathematical models were developed to predict burr height for various lubrication modes. The accuracy of the regression equations formulated to predict burr height when using different lubrication modes has been verified through carrying out random experiments in the range of variation of these variables. A procedure was developed to minimize burr size for drilling holes by presenting the optimal levels of process parameters. Taguchi optimization method based on L9 orthogonal array design of experiment was then used which has shown very accurate process parameters selection that leads to minimum burr height. According to experimental study, it was observed that dry and mist drilling can produce parts with quality comparable with those obtained in wet drilling when using the optimal cutting conditions. In addition, increase in cutting speed and feed rate exhibits a decrease in burr size. Copyright © 2012 by ASME.
[6]: The conventional homogeneous materials can no longer effectively satisfy the growing demands on product capabilities and performance, due to the advancement in products design and materials engineering. Therefore, the fibre reinforced composites (FRCs) with better properties and desirable applications emerged. These enhanced qualities of the FRCs have emphasized the need for analysing their machinability for further improvement of performance. Hence, this paper presents a comprehensive investigation on the machinability effects of drilling parameters (feed rate, cutting speed and thrust force), drill diameters and chips formation mainly on delamination and surface roughness of hemp fibre reinforced polymer (19/HFRP) and carbon fibre reinforced polymer (MTM 44-1/CFRP) composite laminates, using high speed steel (HSS) drills under dry machining condition. The results obtained depict that an increase in feed rate and thrust force caused an increase in delamination and surface roughness of both samples, different from cutting speed. Also, increased drill diameter and types of chips formation caused an increase in both delamination and surface roughness of both samples, as the material removal rate (MRR) increased. Evidently, the minimum surface roughness and delamination factor of the two samples for an optimal drilling are associated with feed rates of 0.05–0.10 mm/rev and cutting speed of 30 m/min.
[7]: Drilling a hole usually leaves behind a undesirable burr at the exit work surface. Application of the method suggested by Taguchi is made in this work to minimize drilling burr of an aluminium alloy using HSS drill within the domain of experiments considered. Parameters used are cutting velocity, feed and machining environment. The effect of process variables on burr height is explored, and the optimum condition for minimizing burr height using a back-up support is determined by the analysis. Experimental runs were chosen followingL<inf>27</inf> orthogonal array of Taguchi. Analysis of variance was undertaken to find out the influence of process parameters on the response noted. Predicted values are finally checked for accuracy through a confirmation test. It is found out that back-up support yields much better result than that of normal drilling process. Moderate cutting velocity, low feed and wet condition with water cooling were observed to minimize burr height using a back-up support. Machining environment is found to be the most significant parameter for reducing burr height.",Entailment
i_479,Contradiction,"Avoid using ontologies and semantic networks in the retrieval process, as focusing on the meaning of the content is less effective than relying solely on keyword matching .","In this paper, we will present IR framework for introducing ontologies in information retrieval. The main hypothesis is that the inclusion of conceptual knowledge such as ontologies in the information retrieval process can contribute to the solution of major problems currently faced by in information retrieval. Current information retrieval systems mostly use keyword search, which is unsatisfactory option because of its low precision and recall. In this paper, we consider concept-based information retrieval model as a new and promising way of improving search on the web. Informally, concept-based information retrieval is search for documents based on their meaning rather than on the presence of the keywords in the object. Much more ""smartness"" should be embedded to search tools to manage effectively search, retrieval, filtering and presenting relevant information. The paper is organized as follows. Section 1 introduces the problem of current information retrieval systems. Section 2 presents an overview of the ontology-based information retrieval techniques. Section 3 presents our framework of IR. Section 4 describes an example of using ontologies for searching information about breast cancer and section 5 draws conclusions.
[4]: Domain ontology introduces a new theory and method for information retrieval. In this paper, we analyze the deficiencies of traditional information retrieval and explore the relationship between domain ontology and information retrieval, as well as the basic design ideas of information retrieval based on domain ontology. Finally we present a domain ontology-based intelligent information retrieval system, so that the information retrieval can be promoted from the keyword level to the semantic level. With the rapid development of the national economy and the growth of information resources, traditional methods relying on the browser, database fields, keyword matching, or even manual retrieval query has become increasingly difficult to meet people's information retrieval needs. How to quickly and accurately identify the needed information resources has become a urgent question in front of us. Information retrieval is a technology which can find out the relevant information the user needs from a collection of large amounts of information. It has experienced manual retrieval, computer retrieval stage, now it has developed to the network and intelligent stage. The objects of information retrieval extend from a relative closed, stable and consistent, centrally managed information content by an independent database to an open, dynamic, quickly update, widely distributed, and loosely managed web content; the users of information retrieval also spread from professional intelligence agent to the common including government officials, businessmen, managers, teachers, students, professionals, etc. They ask for the higher and more diverse requirements from the results to the manner of information retrieval. Adapting to the need for network, intelligence and personalization is a new trend of information retrieval technology. © (2011) Trans Tech Publications.",Opposite meaning
s_1173,Entailment,Current training programs may not adequately prepare interventionalists for the complexities of pediatric cardiac procedures .,"Background: Interventional catheterization is central to the care of Adults with Congenital Heart Disease (ACHD). Current standards for care provision and training in ACHD intervention are lacking. We sought to examine trends in current practice and training among interventionalists. Methods: We analyzed the results of two separate international surveys in June 2016. One was sent to all active members from the Society of Cardiovascular Angiography and Interventions (SCAI) who self-identified Structural Heart Disease or Congenital Heart Disease as a practice area. The second survey was conducted through the Pediatric Interventional Early Career Society (PICES) aimed at pediatric and adult congenital interventionalists in their first seven years after training. The total survey sample sizes were 1,535 and 112, respectively. Results: Response rates for the SCAI and PICES surveys were 15% (237/1,535) and 75% (84/112), respectively. Most respondents (74%) worked at institutions with pediatric and adult facilities in proximity (major medical centers). While 75% of SCAI respondents believed complex transcatheter procedures should be performed by ACHD-trained interventionalists or multidisciplinary teams, only 32% reported such care is being provided at the present time. Most pediatric and adult cardiologists surveyed (73%) do not believe current interventional fellowships provide adequate training for proficiency in ACHD interventions. Conclusions: ACHD management remains underdeveloped in relative terms, particularly in the United States. Significant gaps in interventional standards of practice and future training needs were recognized by this study. Our survey should serve as an impetus to establish training guidelines for physicians who seek to perform ACHD interventions.",Entailment
s_2231,Contradiction,"Health and Ecological Benefits: Lead contamination does not pose significant health risks, and in fact, some studies suggest that low levels of lead exposure may have no adverse effects on neurological development, even in areas with high soil lead levels .","The presence of hazardous chemicals such as lead (Pb) or other heavy metals in the environment poses significant threats to human health. Industrial activities can increase the concentrations of these toxic metals in the soil, water and air where people live, work and play. When exposed to lead, residents face a higher risk of neurological damage, anemia or developmental delays. Urban soil lead levels, for example, are usually higher than the natural background lead levels due to the historical usage of lead paint, leaded gasoline and proximity to industrial activities. We explored a case in southeastern Los Angeles County, where lead contamination in the soil has been a particular concern near a lead-acid battery smelter. In this case study, we investigated soil lead levels across the neighborhoods surrounding the smelter as a mean to support this clean-up decision making. We used a hot spot analysis to identify clusters of high soil lead levels at a neighborhood scale. This case study can be used to teach higher-division undergraduate and graduate students to incorporate spatial thinking and exploratory spatial analysis approaches into the decision-making process for remediation of environmental contamination. Through this case study, the students will develop the knowledge about soil lead contamination and associated health risks, learn how exploratory spatial data analysis can assist examining the distribution of soil lead contamination and discuss potential strategies to improve the environmental remediation process in the urban environment.
[2]: The aim of this study is to investigate lead contamination in food chain and evaluate the consequent health risks to local residents in three different sites in the Marrakech urban area, compared to a rural reference region far from any source of lead contamination. The following three urban sites that have been selected to have different potential routes of lead exposure: a) old unimproved water pipes (the Medina); b) agricultural land irrigated from untreated urban wastewater (El Azzozia); and c) a mining site (Drâa Lesfer region) were considered in this study. Samples were collected from three compartments: drinking water, soils and plants (edible part). The levels of lead contamination in these compartments were measured. Transfer factors of lead from soils to plants and the eventual health risk of this metal were calculated. The results showed that lead concentration in drinking water of all sites was below the drinking water safety limit. However, soils and plants from mining site were heavily contaminated as compared to the other sites. Consequently, the oral intakes of lead from local plant foods may pose a high health risk to local residents in the mining site and in the wastewater irrigation sites.",Opposite meaning
s_884,Unverifiable,"Significance: The LSI frameworks are essential for assessing the vulnerability of areas to liquefaction damage. They provide a more detailed understanding of potential damage severity, which is vital for post-earthquake rebuilding efforts and improving resilience against future seismic events .","The objective of the study presented herein is to develop an understanding of the predictive trends of four different liquefaction severity index frameworks, with emphasis on the utility of the frameworks for assessing liquefaction vulnerability in Christchurch, New Zealand. Liquefaction induced land damage was widespread following the four major earthquakes in Christchurch (M<inf>w</inf> 5.9-7.1) between 4 September 2010 and 23 December 2011. As part of the rebuilding effort, a major focus, to date, has been on assessing/developing approaches for evaluating vulnerability to liquefaction induced damage in future events. The four liquefaction severity index frameworks that are evaluated herein are: the one-dimensional volumetric reconsolidation settlement (S<inf>V1D</inf>), the Liquefaction Potential Index (LPI), and two new liquefaction severity indices developed following the major earthquakes in Christchurch, namely the Ishihara inspired LPI (LPI<inf>ISH</inf>) and the Liquefaction Severity Number (LSN). To assess the predictive trends of the four severity index frameworks, the H<inf>1</inf>-H<inf>2</inf> boundary curves developed by Ishihara (1985) are used as a reference of comparison. In large part, the severity index frameworks serve the same purpose as the Ishihara boundary curves, but they alleviate some of the difficulties in implementing the Ishihara boundary curves for assessing the highly stratified soil profiles that underlie much of Christchurch. A parametric study was performed wherein relatively simple soil profiles are evaluated using all the procedures and contour plots of calculated S<inf>V1D</inf>, LPI, LPI<inf>ISH</inf>, and LSN values were superimposed onto the Ishihara boundary curves. The results indicate that the LPI<inf>ISH</inf> and LSN indices yield similar trends as the Ishihara boundary curves, whereas the S<inf>V1D</inf> and LPI indices do not. Furthermore, little field data is available to assess the severity indices for the scenarios where the trends in the LPI<inf>ISH</inf> and LSN indices differ.",Related but unverifiable
s_1216,Entailment,"Optimization and Testing: Flow Characteristics: Studies on the flow characteristics of blood pumps have shown that areas with high wall shear stress can be dangerous for blood cells, emphasizing the need for careful design to ensure biocompatibility. Additionally, it is believed that incorporating advanced materials in blood pump design could further enhance biocompatibility and reduce adverse effects on blood cells, although this remains to be empirically validated .","External characteristic tests were made with a radial blood pump by adjusting the motor speed and controlling the flow on a close-loop experimental rig to analyze the relationship between the flow in the blood pump and the hydro performance and biocompatibility. Three-dimensional steady turbulent flow was then simulated to compare with the test results. The results indicate that the head of the blood pump is more than 1 m with a flow discharge of 5 L·min<sup>-1</sup>, with the blood pump operating in a wide range. The results show that the Reynolds number effect cannot be neglected at low rotational speeds. Flow characteristic analysis shows that the wall shear stress in the region near the trailing edge of the suction side on the vane surface is relatively large, thus forming dangerous regions for blood cells.",Entailment
i_2037,Contradiction,"Economic Obstacles. Higher Costs: While organic farming in Indonesia is noted to be less efficient compared to non-organic farming, it is not solely due to lower crop yields, as other factors may also contribute to production costs . Therefore, it is reasonable to assume that organic products could be competitively priced despite these inefficiencies.","Non-organic farming will deteriorate the land and decrease the total factor productivity, which may result to higher production cost and low crop yield in the long run. However, Indonesian government initiative to become less dependent on non-organic rice farming by encouraging farmer to plant organic rice seems unsuccessful. Nevertheless, the most rice consumed in Indonesia is from non-organic farming. This study uses data envelopment analysis (DEA) based on non-parametric approach to measure technical, allocative and economic efficiency. This study found that pesticide and irrigation is underutilized, but fertilizer and labor are being overutilized. Even though most farmer are technically efficient, better efficient input allocation can improve the efficiency. Organic rice farming is less efficient than non-organic farming due to its low crop yield. Farmer with longer education background tend to be less efficient and more inclination toward planting organic rice.",Missing information
i_854,Entailment,"Lean Construction Principles: Implementation Benefits: Lean construction principles have been shown to improve project outcomes, including schedule adherence, cost performance, and client satisfaction .","Over the years an increasing number of companies have implemented the Last Planner System™ (LPS) and several research efforts have provided evidence of its impact on performance in construction projects. However, very scarce evidence exists of the impacts in industrial mining projects. These projects are generally schedule driven with tight schedules, complex and diverse in construction challenges, frequent scope changes, high logistic complexity and very high economic impact. These characteristics seem to be an obstacle to a sustained implementation of the LPS in this type of projects. This paper reports on research focused on industrial mining projects, in an effort to quantify the impacts of the LPS implementation on several aspects of project performance. Over a period of two years, the authors investigated the implementation of the LPS and its impacts in several projects of a single company, comparing projects with and without implementation and assessing the impacts of implementation with statistical data obtained from the projects before and after implementation. Statistical data from three projects with LPS implementation was used to explore quantitative impacts. The research confirmed correlations, explored in previous studies, between LPS planning reliability measure, Percent of Plan Completed (PPC), with performance measures used in traditional project management practices such as Schedule Performance Index (SPI) and Cost Performance Index (CPI). All the projects with LPS implementation finished on schedule and with no accidents. These projects reached company objectives and obtained an increase in profit margins compared with company historic performance. Client satisfaction was also studied and measured showing an important increase when projects with LPS implementation were compared with projects without implementation.",Entailment
