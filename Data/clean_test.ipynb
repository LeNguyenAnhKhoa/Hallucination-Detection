{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e354f03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ftfy import fix_text\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "df = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1640f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('./gem25proct-prompt_1.csv')\n",
    "df2 = pd.read_csv('./gem25proct-prompt_2.csv')\n",
    "df3 = pd.read_csv('./gem25proct-prompt_3.csv')\n",
    "df4 = pd.read_csv('./gem25proct-prompt_4.csv')\n",
    "df = pd.concat([df1, df2, df3, df4], ignore_index=True)\n",
    "len(df)\n",
    "df.to_csv('./gem25proct-prompt.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4001ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_predict_column_method1(df):\n",
    "    df_copy = df.copy()\n",
    "    def extract_json(text):\n",
    "        match = re.search(r'{[\\s\\S]*?}', text)\n",
    "        if match:\n",
    "            return json.loads(match.group(0))\n",
    "        else:\n",
    "            return None\n",
    "    if df_copy['predict'].dtype == 'object':\n",
    "        df_copy['predict'] = df_copy['predict'].apply(lambda x: extract_json(x) if isinstance(x, str) else x)\n",
    "    json_df = pd.json_normalize(df_copy['predict'])\n",
    "    result_df = pd.concat([df_copy.drop('predict', axis=1), json_df], axis=1)\n",
    "    return result_df\n",
    "\n",
    "df = pd.read_csv('./gem25proct-prompt.csv')\n",
    "df = df.dropna()\n",
    "df['predict'] = df['predict'].str.strip()\n",
    "df = split_predict_column_method1(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c6eaf5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1000.000000\n",
       "mean       -0.394148\n",
       "std         0.321615\n",
       "min        -1.800958\n",
       "25%        -0.568996\n",
       "50%        -0.362493\n",
       "75%         0.000000\n",
       "max         0.000000\n",
       "Name: negative_entropy, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import entropy\n",
    "def calculate_negative_entropy(row):\n",
    "    \"\"\"\n",
    "    Tính negative entropy cho một hàng dữ liệu\n",
    "    \"\"\"\n",
    "    # Lấy các cột xác suất\n",
    "    prob_cols = [\n",
    "        'Opposite_meaning_probability',\n",
    "        'Misrepresentation_probability', \n",
    "        'Related_but_unverifiable_probability',\n",
    "        'Entailment_probability',\n",
    "        'Entity_error_probability',\n",
    "        'Unrelated_and_unverifiable_probability',\n",
    "        'Numeric_error_probability',\n",
    "        'Missing_information_probability'\n",
    "    ]\n",
    "    \n",
    "    # Lấy giá trị xác suất và chuyển đổi kiểu dữ liệu\n",
    "    try:\n",
    "        probabilities = []\n",
    "        for col in prob_cols:\n",
    "            if col in row.index:\n",
    "                val = row[col]\n",
    "                if pd.notna(val):  # Kiểm tra không phải NaN\n",
    "                    val = float(val)  # Chuyển đổi sang float\n",
    "                    if val > 0:  # Chỉ lấy giá trị > 0\n",
    "                        probabilities.append(val)\n",
    "        \n",
    "        probabilities = np.array(probabilities, dtype=float)\n",
    "        \n",
    "        if len(probabilities) == 0 or np.sum(probabilities) == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        # Tính entropy thủ công để tránh lỗi\n",
    "        ent = np.sum(probabilities * np.log2(probabilities))  # Thêm epsilon để tránh log(0)\n",
    "        \n",
    "        # Trả về negative entropy\n",
    "        return ent\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi tính entropy cho hàng: {e}\")\n",
    "        return 0.0\n",
    "# Tính negative entropy cho tất cả các hàng\n",
    "df['negative_entropy'] = df.apply(calculate_negative_entropy, axis=1)\n",
    "df = df.drop(columns=['Opposite_meaning_probability','Misrepresentation_probability','Related_but_unverifiable_probability','Entailment_probability','Entity_error_probability','Unrelated_and_unverifiable_probability','Numeric_error_probability','Missing_information_probability'], axis=1, errors='ignore')\n",
    "df['negative_entropy'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51308291",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "top_n_df = df.groupby('answer', group_keys=False) \\\n",
    "             .apply(lambda x: x.nlargest(n, 'negative_entropy'))\n",
    "top_n_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88dc9de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['misinter', 'negat', 'relunvef', 'entail', 'entierr', 'missinfo',\n",
       "       'numerr', 'unrelunvef', nan], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.rename(columns={'answer': 'Label'})\n",
    "\n",
    "# Thay thế các giá trị trong cột 'Label' bằng dạng viết tắt\n",
    "df['Label'] = df['Label'].replace({\n",
    "    'Misrepresentation': 'misinter', \n",
    "    'Opposite meaning': 'negat',\n",
    "    'Related but unverifiable': 'relunvef', \n",
    "    'Entailment': 'entail', \n",
    "    'Entity error': 'entierr',\n",
    "    'Unrelated and unverifiable': 'unrelunvef', \n",
    "    'Numeric error': 'numerr',\n",
    "    'Missing information': 'missinfo'\n",
    "})\n",
    "nan = df[df.isna().any(axis=1)]\n",
    "df = df.drop(columns=['claim_clean', 'reference_clean', 'negative_entropy'], axis=1)\n",
    "df['Label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85e5f940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>claim_clean</th>\n",
       "      <th>reference_clean</th>\n",
       "      <th>Label</th>\n",
       "      <th>negative_entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>i_78</td>\n",
       "      <td>Techniques to Address Imbalanced Data: Resampling Methods: Hybrid Sampling: Combines both oversampling and undersampling to balance the dataset .</td>\n",
       "      <td>Imbalance data are defined as a dataset whose proportion of classes is severely skewed. Classification performance of existing models tends to deteriorate due to class distribution imbalance. In addition, over-representation by majority classes prevents a classifier from paying attention to minority classes, which are generally more interesting. An effective ensemble classification method called RHSBoost has been proposed to address the imbalance classification problem. This classification rule uses random undersampling and ROSE sampling under a boosting scheme. According to the experimental results, RHSBoost appears to be an attractive classification model for imbalance data.\\n[9]: The imbalanced data problem occurs when the number of representative instances for classes of interest is much lower than for other classes. The influence of imbalanced data on classification performance has been discussed in some previous research as a challenge to be studied. In this paper, we propose a method to solve the imbalanced data problem by focusing on preprocessing, including: I) sampling techniques (i.e., under-sampling, over-sampling, and hybrid-sampling) and ii) the instance weighting method to increase the number of features in minority classes and to reduce comprehensive coverage in majority classes. The experimental results show that the noisy data is reduced, making a smaller sized dataset, and training time decreases significantly. Moreover, distinct properties of each class are examined effectively. Refined data is used as input for Naive Bayes and support vector machine classifiers for the targets of the training process. The proposed methods are evaluated based on the number of non-geotagged resources that are labeled correctly with their geo-locations. In comparison with previous research, the proposed method achieves accuracy of 84, whereas previous results were 75.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>negat</td>\n",
       "      <td>-0.847585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID  \\\n",
       "999  i_78   \n",
       "741   NaN   \n",
       "\n",
       "                                                                                                                                           claim_clean  \\\n",
       "999  Techniques to Address Imbalanced Data: Resampling Methods: Hybrid Sampling: Combines both oversampling and undersampling to balance the dataset .   \n",
       "741                                                                                                                                                NaN   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   reference_clean  \\\n",
       "999  Imbalance data are defined as a dataset whose proportion of classes is severely skewed. Classification performance of existing models tends to deteriorate due to class distribution imbalance. In addition, over-representation by majority classes prevents a classifier from paying attention to minority classes, which are generally more interesting. An effective ensemble classification method called RHSBoost has been proposed to address the imbalance classification problem. This classification rule uses random undersampling and ROSE sampling under a boosting scheme. According to the experimental results, RHSBoost appears to be an attractive classification model for imbalance data.\\n[9]: The imbalanced data problem occurs when the number of representative instances for classes of interest is much lower than for other classes. The influence of imbalanced data on classification performance has been discussed in some previous research as a challenge to be studied. In this paper, we propose a method to solve the imbalanced data problem by focusing on preprocessing, including: I) sampling techniques (i.e., under-sampling, over-sampling, and hybrid-sampling) and ii) the instance weighting method to increase the number of features in minority classes and to reduce comprehensive coverage in majority classes. The experimental results show that the noisy data is reduced, making a smaller sized dataset, and training time decreases significantly. Moreover, distinct properties of each class are examined effectively. Refined data is used as input for Naive Bayes and support vector machine classifiers for the targets of the training process. The proposed methods are evaluated based on the number of non-geotagged resources that are labeled correctly with their geo-locations. In comparison with previous research, the proposed method achieves accuracy of 84, whereas previous results were 75.   \n",
       "741                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            NaN   \n",
       "\n",
       "     Label  negative_entropy  \n",
       "999    NaN          0.000000  \n",
       "741  negat         -0.847585  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "777cfb02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['ID'] == 'i_78', 'Label'] = 'relunvef'\n",
    "df = df.dropna()\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25fea1fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: ID, dtype: object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv('./test.csv')\n",
    "missing_ids = df2['ID'][~df2['ID'].isin(df['ID'])]\n",
    "missing_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f621cc5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row = pd.DataFrame({'ID': ['s_528'], 'Label': ['negat']})\n",
    "df = pd.concat([df, new_row], ignore_index=True)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c98f726",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./gem25proct0.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0aad05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Label'] = df['Label'].replace({\n",
    "    'misinter': 'contra', \n",
    "    'negat': 'contra',\n",
    "    'relunvef': 'unver', \n",
    "    'entail': 'entail', \n",
    "    'entierr': 'contra',\n",
    "    'unrelunvef': 'unver', \n",
    "    'numerr': 'contra',\n",
    "    'missinfo': 'contra'\n",
    "})\n",
    "df.to_csv('./gem25proct02.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
