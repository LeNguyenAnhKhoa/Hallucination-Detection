{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A3W782BVHTpe",
    "outputId": "a9f0657d-18b7-4418-b3bc-e9d9e4758011"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/196.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.3/196.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q -U google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1748585682634,
     "user": {
      "displayName": "Lê Khoa",
      "userId": "08058681449196918949"
     },
     "user_tz": -420
    },
    "id": "GEq5M4raIw4V"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.metrics import f1_score\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "def get_prediction(claim, reference, model_name):\n",
    "    prompt_prefix = \"\"\"\n",
    "    You are an annotator concerned that the claim may not align with the reference.\n",
    "    Your task is to determine whether the reference entail, is unrelated and unverifiable, is related but unverifiable, misrepresentation, missing information, contain a numeric error, contain an opposite meaning, or contain an entity error to the claim.\n",
    "    You will be given two inputs: claim, reference.\n",
    "    Entailment occurs when reference information directly supports a claim's accuracy with no conflicting information. The logical connection between reference and claim is strong enough that the claim's truth follows naturally from the reference content.\n",
    "    Opposite meaning identifies claims that directly contradict references by stating the contrary position. This happens when a claim negates key parts of a reference or substitutes terms with their antonyms, fundamentally reversing the reference's meaning.\n",
    "    Misrepresentation labels claims that present logical fallacies or flawed reasoning relative to references. This includes over-claiming, under-claiming, introducing ambiguity, creating inconsistency, or drawing conclusions that don't logically follow from the reference material.\n",
    "    Related but unverifiable describes claims that connect to references through shared subjects or entities but cannot be verified because the reference lacks specific information to confirm or deny the claim's accuracy.\n",
    "    Entity error identifies claims that incorrectly name entities (people, organizations, places) compared to reference information. Even if other claim elements are accurate, entity misidentification compromises the claim's overall accuracy.\n",
    "    Unrelated and unverifiable applies to claims discussing topics or information entirely absent from references, providing no basis for accuracy assessment.\n",
    "    Numeric error identifies claims presenting incorrect numerical values (quantities, percentages, dates) compared to reference figures.\n",
    "    Missing information flags claims that omit critical reference details, significantly altering the original meaning or intent of the referenced information.\n",
    "    Input:\n",
    "    \"\"\"\n",
    "\n",
    "    client = genai.Client(api_key=\"\")\n",
    "\n",
    "    config = types.GenerateContentConfig(\n",
    "        temperature=2.0,\n",
    "        seed=13,\n",
    "        response_mime_type=\"application/json\",\n",
    "        # system_instruction=\"explain your reasoning process before giving your final answer.\",\n",
    "        response_schema={\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"answer\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\n",
    "                        \"Opposite meaning\",\n",
    "                        \"Misrepresentation\",\n",
    "                        \"Related but unverifiable\",\n",
    "                        \"Entailment\",\n",
    "                        \"Entity error\",\n",
    "                        \"Unrelated and unverifiable\",\n",
    "                        \"Numeric error\",\n",
    "                        \"Missing information\"\n",
    "                    ],\n",
    "                    \"description\": \"Your final answer\"\n",
    "                },\n",
    "                \"Opposite_meaning_probability\": {\n",
    "                    \"type\": \"number\",\n",
    "                    \"description\": \"Probability to predict class Opposite meaning (0.0 to 1.0)\"\n",
    "                },\n",
    "                \"Misrepresentation_probability\": {\n",
    "                    \"type\": \"number\",\n",
    "                    \"description\": \"Probability to predict class Misrepresentation (0.0 to 1.0)\"\n",
    "                },\n",
    "                \"Related_but_unverifiable_probability\": {\n",
    "                    \"type\": \"number\",\n",
    "                    \"description\": \"Probability to predict class Related but unverifiable (0.0 to 1.0)\"\n",
    "                },\n",
    "                \"Entailment_probability\": {\n",
    "                    \"type\": \"number\",\n",
    "                    \"description\": \"Probability to predict class Entailment (0.0 to 1.0)\"\n",
    "                },\n",
    "                \"Entity_error_probability\": {\n",
    "                    \"type\": \"number\",\n",
    "                    \"description\": \"Probability to predict class Entity error (0.0 to 1.0)\"\n",
    "                },\n",
    "                \"Unrelated_and_unverifiable_probability\": {\n",
    "                    \"type\": \"number\",\n",
    "                    \"description\": \"Probability to predict class Unrelated and unverifiable (0.0 to 1.0)\"\n",
    "                },\n",
    "                \"Numeric_error_probability\": {\n",
    "                    \"type\": \"number\",\n",
    "                    \"description\": \"Probability to predict class Numeric error (0.0 to 1.0)\"\n",
    "                },\n",
    "                \"Missing_information_probability\": {\n",
    "                    \"type\": \"number\",\n",
    "                    \"description\": \"Probability to predict class Missing information (0.0 to 1.0)\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\n",
    "                \"answer\",\n",
    "                \"Opposite_meaning_probability\",\n",
    "                \"Misrepresentation_probability\",\n",
    "                \"Related_but_unverifiable_probability\",\n",
    "                \"Entailment_probability\",\n",
    "                \"Entity_error_probability\",\n",
    "                \"Unrelated_and_unverifiable_probability\",\n",
    "                \"Numeric_error_probability\",\n",
    "                \"Missing_information_probability\"\n",
    "            ]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    full_prompt = f\"\"\"\n",
    "    {prompt_prefix}\n",
    "    claim: {claim}\n",
    "    reference: {reference}\n",
    "    answer:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = client.models.generate_content(\n",
    "            model=model_name,\n",
    "            contents=full_prompt,\n",
    "            config=config\n",
    "        )\n",
    "        return response.text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "def main(output_path, sleep_time, model_name):\n",
    "    df = pd.read_csv('/content/prompt.csv')\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        claim = row['claim_clean']\n",
    "        reference = row['reference_clean']\n",
    "        prediction = get_prediction(claim, reference, model_name)\n",
    "        predictions.append(prediction)\n",
    "\n",
    "        if (idx + 1) % 10 == 0:\n",
    "            print(f\"Processed {idx + 1}...\")\n",
    "\n",
    "        time.sleep(sleep_time)\n",
    "\n",
    "    df['predict'] = predictions\n",
    "\n",
    "    df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3034494,
     "status": "ok",
     "timestamp": 1748588727850,
     "user": {
      "displayName": "Lê Khoa",
      "userId": "08058681449196918949"
     },
     "user_tz": -420
    },
    "id": "2KLAfNEoWQ0F",
    "outputId": "2ee4ac54-12b0-4e00-e57b-97fc6c16e4f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10...\n",
      "Processed 20...\n",
      "Processed 30...\n",
      "Processed 40...\n",
      "Processed 50...\n",
      "Processed 60...\n",
      "Processed 70...\n",
      "Processed 80...\n",
      "Processed 90...\n",
      "Processed 100...\n",
      "Processed 110...\n",
      "Processed 120...\n",
      "Processed 130...\n",
      "Processed 140...\n",
      "Processed 150...\n",
      "Processed 160...\n",
      "Processed 170...\n",
      "Processed 180...\n",
      "Processed 190...\n",
      "Processed 200...\n",
      "Processed 210...\n",
      "Processed 220...\n",
      "Processed 230...\n",
      "Processed 240...\n",
      "Processed 250...\n",
      "Processed 260...\n",
      "Processed 270...\n",
      "Processed 280...\n",
      "Processed 290...\n",
      "Processed 300...\n",
      "Processed 310...\n",
      "Processed 320...\n",
      "Processed 330...\n",
      "Processed 340...\n",
      "Processed 350...\n",
      "Processed 360...\n",
      "Processed 370...\n"
     ]
    }
   ],
   "source": [
    "main(\"gem25fl_prompt.csv\", 0.07, 'gemini-2.5-flash-preview-05-20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 110,
     "status": "ok",
     "timestamp": 1748585067438,
     "user": {
      "displayName": "Lê Khoa",
      "userId": "08058681449196918949"
     },
     "user_tz": -420
    },
    "id": "1CUB_KHq7Ddy"
   },
   "outputs": [],
   "source": [
    "client = genai.Client(api_key=\"\")\n",
    "\n",
    "config = types.GenerateContentConfig(\n",
    "    temperature=2.0,\n",
    "    seed=13,\n",
    "    response_mime_type=\"application/json\",\n",
    "    # system_instruction=\"explain your reasoning process before giving your final answer.\",\n",
    "    response_schema={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"answer\": {\n",
    "                \"type\": \"string\",\n",
    "                \"enum\": [\n",
    "                    \"Opposite meaning\",\n",
    "                    \"Misrepresentation\",\n",
    "                    \"Related but unverifiable\",\n",
    "                    \"Entailment\",\n",
    "                    \"Entity error\",\n",
    "                    \"Unrelated and unverifiable\",\n",
    "                    \"Numeric error\",\n",
    "                    \"Missing information\"\n",
    "                ],\n",
    "                \"description\": \"Your final answer\"\n",
    "            },\n",
    "            \"Opposite_meaning_probability\": {\n",
    "                \"type\": \"number\",\n",
    "                \"description\": \"Probability to predict class Opposite meaning (0.0 to 1.0)\"\n",
    "            },\n",
    "            \"Misrepresentation_probability\": {\n",
    "                \"type\": \"number\",\n",
    "                \"description\": \"Probability to predict class Misrepresentation (0.0 to 1.0)\"\n",
    "            },\n",
    "            \"Related_but_unverifiable_probability\": {\n",
    "                \"type\": \"number\",\n",
    "                \"description\": \"Probability to predict class Related but unverifiable (0.0 to 1.0)\"\n",
    "            },\n",
    "            \"Entailment_probability\": {\n",
    "                \"type\": \"number\",\n",
    "                \"description\": \"Probability to predict class Entailment (0.0 to 1.0)\"\n",
    "            },\n",
    "            \"Entity_error_probability\": {\n",
    "                \"type\": \"number\",\n",
    "                \"description\": \"Probability to predict class Entity error (0.0 to 1.0)\"\n",
    "            },\n",
    "            \"Unrelated_and_unverifiable_probability\": {\n",
    "                \"type\": \"number\",\n",
    "                \"description\": \"Probability to predict class Unrelated and unverifiable (0.0 to 1.0)\"\n",
    "            },\n",
    "            \"Numeric_error_probability\": {\n",
    "                \"type\": \"number\",\n",
    "                \"description\": \"Probability to predict class Numeric error (0.0 to 1.0)\"\n",
    "            },\n",
    "            \"Missing_information_probability\": {\n",
    "                \"type\": \"number\",\n",
    "                \"description\": \"Probability to predict class Missing information (0.0 to 1.0)\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\n",
    "            \"answer\",\n",
    "            \"Opposite_meaning_probability\",\n",
    "            \"Misrepresentation_probability\",\n",
    "            \"Related_but_unverifiable_probability\",\n",
    "            \"Entailment_probability\",\n",
    "            \"Entity_error_probability\",\n",
    "            \"Unrelated_and_unverifiable_probability\",\n",
    "            \"Numeric_error_probability\",\n",
    "            \"Missing_information_probability\"\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "prompt_prefix = \"\"\"\n",
    "    You are an annotator concerned that the claim may not align with the reference.\n",
    "    Your task is to determine whether the reference entail, is unrelated and unverifiable, is related but unverifiable, misinterpret, omit critical information, contain a numeric error, contain an opposite meaning, or contain an entity error to the claim.\n",
    "    You will be given two inputs: claim, reference.\n",
    "    Entailment occurs when reference information directly supports a claim's accuracy with no conflicting information. The logical connection between reference and claim is strong enough that the claim's truth follows naturally from the reference content.\n",
    "    Opposite meaning identifies claims that directly contradict references by stating the contrary position. This happens when a claim negates key parts of a reference or substitutes terms with their antonyms, fundamentally reversing the reference's meaning.\n",
    "    Misrepresentation labels claims that present logical fallacies or flawed reasoning relative to references. This includes over-claiming, under-claiming, introducing ambiguity, creating inconsistency, or drawing conclusions that don't logically follow from the reference material.\n",
    "    Related but unverifiable describes claims that connect to references through shared subjects or entities but cannot be verified because the reference lacks specific information to confirm or deny the claim's accuracy.\n",
    "    Entity error identifies claims that incorrectly name entities (people, organizations, places) compared to reference information. Even if other claim elements are accurate, entity misidentification compromises the claim's overall accuracy.\n",
    "    Unrelated and unverifiable applies to claims discussing topics or information entirely absent from references, providing no basis for accuracy assessment.\n",
    "    Numeric error identifies claims presenting incorrect numerical values (quantities, percentages, dates) compared to reference figures.\n",
    "    Missing information flags claims that omit critical reference details, significantly altering the original meaning or intent of the referenced information.\n",
    "    Input:\n",
    "    \"\"\"\n",
    "claim = \"Microstructured Waveguide Biosensors: Applications: Analysis of various beverages like water, tea, coffee, wine, and strong drinks, which suggests they could be used for all types of liquids without limitations [9].\"\n",
    "reference = \"[9]: The microstructured waveguide biosensor is described. The biosensor was tested in experiments for analysis of water, tea, coffee, wine and strong drinks. The biosensor has a high sensitivity to the optical properties of a medium, filling up the waveguide's core. The small size, good integration ability and compatibility for use in industrial settings make such biosensor very promising for various applications, including food industry.\"\n",
    "full_prompt = f\"\"\"{prompt_prefix}\n",
    "    claim: {claim}\n",
    "    reference: {reference}\n",
    "    answer:\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5733,
     "status": "ok",
     "timestamp": 1748585140384,
     "user": {
      "displayName": "Lê Khoa",
      "userId": "08058681449196918949"
     },
     "user_tz": -420
    },
    "id": "b1PFSdBQOpdg",
    "outputId": "c6640389-a3b0-4eed-b708-015cd86d4d83"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerateContentResponse(candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='{\"answer\": \"Misrepresentation\", \"Opposite_meaning_probability\": 0.05, \"Misrepresentation_probability\": 0.85, \"Related_but_unverifiable_probability\": 0.02, \"Entailment_probability\": 0.01, \"Entity_error_probability\": 0.01, \"Unrelated_and_unverifiable_probability\": 0.01, \"Numeric_error_probability\": 0.01, \"Missing_information_probability\": 0.04}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, url_context_metadata=None, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)], create_time=None, response_id=None, model_version='models/gemini-2.5-flash-preview-05-20', prompt_feedback=None, usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=None, cached_content_token_count=None, candidates_token_count=120, candidates_tokens_details=None, prompt_token_count=517, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=517)], thoughts_token_count=906, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=1543, traffic_type=None), automatic_function_calling_history=[], parsed={'answer': 'Misrepresentation', 'Opposite_meaning_probability': 0.05, 'Misrepresentation_probability': 0.85, 'Related_but_unverifiable_probability': 0.02, 'Entailment_probability': 0.01, 'Entity_error_probability': 0.01, 'Unrelated_and_unverifiable_probability': 0.01, 'Numeric_error_probability': 0.01, 'Missing_information_probability': 0.04})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.models.generate_content(\n",
    "            model=\"gemini-2.5-flash-preview-05-20\",\n",
    "            contents=full_prompt,\n",
    "            config=config\n",
    "        )\n",
    "response.text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1748585549151,
     "user": {
      "displayName": "Lê Khoa",
      "userId": "08058681449196918949"
     },
     "user_tz": -420
    },
    "id": "ey2WUctLzClA",
    "outputId": "e06c7fad-191f-49f9-d60a-45658f5bb58b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'{\"answer\": \"Misrepresentation\", \"Opposite_meaning_probability\": 0.05, \"Misrepresentation_probability\": 0.85, \"Related_but_unverifiable_probability\": 0.02, \"Entailment_probability\": 0.01, \"Entity_error_probability\": 0.01, \"Unrelated_and_unverifiable_probability\": 0.01, \"Numeric_error_probability\": 0.01, \"Missing_information_probability\": 0.04}'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.text.strip()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
